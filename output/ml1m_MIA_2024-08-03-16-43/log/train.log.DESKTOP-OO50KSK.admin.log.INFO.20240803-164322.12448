I0803 16:43:29.143540 16480 trainer.py:119] Test: [{'precision': 0.09249582637729557, 'recall': 0.1077475567197928, 'hit_ratio': 0.6410684474123539, 'ndcg': 0.12353435315810148}]
I0803 16:44:18.299331 16480 trainer.py:139] Epoch[0/1000] loss: 0.3560348403453827
I0803 16:45:07.915522 16480 trainer.py:139] Epoch[1/1000] loss: 0.3131324548191494
I0803 16:45:55.128392 16480 trainer.py:139] Epoch[2/1000] loss: 0.2798780828052097
I0803 16:46:39.926167 16480 trainer.py:139] Epoch[3/1000] loss: 0.26897718720965913
I0803 16:47:24.124254 16480 trainer.py:139] Epoch[4/1000] loss: 0.26681500527593827
I0803 16:48:08.133421 16480 trainer.py:139] Epoch[5/1000] loss: 0.26253595650196077
I0803 16:48:52.528732 16480 trainer.py:139] Epoch[6/1000] loss: 0.26042178432146706
I0803 16:49:36.817120 16480 trainer.py:139] Epoch[7/1000] loss: 0.2563756274514728
I0803 16:50:20.901844 16480 trainer.py:139] Epoch[8/1000] loss: 0.2527212613158756
I0803 16:51:05.084518 16480 trainer.py:139] Epoch[9/1000] loss: 0.25091616425249313
I0803 16:51:49.147949 16480 trainer.py:139] Epoch[10/1000] loss: 0.24665569365024567
I0803 16:52:33.053086 16480 trainer.py:139] Epoch[11/1000] loss: 0.24260951624976265
I0803 16:53:17.807413 16480 trainer.py:139] Epoch[12/1000] loss: 0.23936405148771073
I0803 16:54:02.490245 16480 trainer.py:139] Epoch[13/1000] loss: 0.2361700235472785
I0803 16:54:47.438182 16480 trainer.py:139] Epoch[14/1000] loss: 0.23431730661127304
I0803 16:55:32.552996 16480 trainer.py:139] Epoch[15/1000] loss: 0.2300408297777176
I0803 16:56:16.732139 16480 trainer.py:139] Epoch[16/1000] loss: 0.22953934874799517
I0803 16:57:00.799950 16480 trainer.py:139] Epoch[17/1000] loss: 0.22524956934981877
I0803 16:57:45.558728 16480 trainer.py:139] Epoch[18/1000] loss: 0.2243203898270925
I0803 16:58:30.362591 16480 trainer.py:139] Epoch[19/1000] loss: 0.22258700337674883
I0803 16:59:13.956023 16480 trainer.py:139] Epoch[20/1000] loss: 0.21848887509769863
I0803 16:59:58.902949 16480 trainer.py:139] Epoch[21/1000] loss: 0.21679065724213917
I0803 17:00:42.976766 16480 trainer.py:139] Epoch[22/1000] loss: 0.2149949292341868
I0803 17:01:27.822336 16480 trainer.py:139] Epoch[23/1000] loss: 0.21277145286401114
I0803 17:02:12.308078 16480 trainer.py:139] Epoch[24/1000] loss: 0.21148067500856188
I0803 17:02:57.274440 16480 trainer.py:139] Epoch[25/1000] loss: 0.2103430672486623
I0803 17:03:41.334754 16480 trainer.py:139] Epoch[26/1000] loss: 0.20870617787043252
I0803 17:04:25.897297 16480 trainer.py:139] Epoch[27/1000] loss: 0.20734877288341522
I0803 17:05:10.212785 16480 trainer.py:139] Epoch[28/1000] loss: 0.20607103539837732
I0803 17:05:54.866017 16480 trainer.py:139] Epoch[29/1000] loss: 0.2026193920771281
I0803 17:06:39.278555 16480 trainer.py:139] Epoch[30/1000] loss: 0.20160415404372745
I0803 17:07:24.015495 16480 trainer.py:139] Epoch[31/1000] loss: 0.20228810648123424
I0803 17:08:08.899529 16480 trainer.py:139] Epoch[32/1000] loss: 0.1999164115058051
I0803 17:08:52.264130 16480 trainer.py:139] Epoch[33/1000] loss: 0.19833683517244127
I0803 17:09:36.753731 16480 trainer.py:139] Epoch[34/1000] loss: 0.19775527629587386
I0803 17:10:20.658660 16480 trainer.py:139] Epoch[35/1000] loss: 0.1960031094815996
I0803 17:11:05.317014 16480 trainer.py:139] Epoch[36/1000] loss: 0.19520148701137965
I0803 17:11:48.630607 16480 trainer.py:139] Epoch[37/1000] loss: 0.19338476055198245
I0803 17:12:33.290660 16480 trainer.py:139] Epoch[38/1000] loss: 0.1927898440758387
I0803 17:13:17.742900 16480 trainer.py:139] Epoch[39/1000] loss: 0.19183702866236368
I0803 17:14:02.268320 16480 trainer.py:139] Epoch[40/1000] loss: 0.1911252095301946
I0803 17:14:46.812778 16480 trainer.py:139] Epoch[41/1000] loss: 0.18911502281824746
I0803 17:15:31.277583 16480 trainer.py:139] Epoch[42/1000] loss: 0.18883351643880208
I0803 17:16:15.663114 16480 trainer.py:139] Epoch[43/1000] loss: 0.18888541022936503
I0803 17:17:00.050366 16480 trainer.py:139] Epoch[44/1000] loss: 0.18649863998095195
I0803 17:17:44.254883 16480 trainer.py:139] Epoch[45/1000] loss: 0.18648494078053368
I0803 17:18:28.531998 16480 trainer.py:139] Epoch[46/1000] loss: 0.1850407087802887
I0803 17:19:13.245455 16480 trainer.py:139] Epoch[47/1000] loss: 0.18363672104146744
I0803 17:19:57.631467 16480 trainer.py:139] Epoch[48/1000] loss: 0.18323511004447937
I0803 17:20:42.129258 16480 trainer.py:139] Epoch[49/1000] loss: 0.18353725479708777
I0803 17:20:42.717291 16480 trainer.py:145] Test: [{'precision': 0.16979131886477467, 'recall': 0.22994751154088053, 'hit_ratio': 0.8676126878130217, 'ndcg': 0.26057909522404105}]
I0803 17:21:27.374399 16480 trainer.py:139] Epoch[50/1000] loss: 0.18302752037843067
I0803 17:22:11.443882 16480 trainer.py:139] Epoch[51/1000] loss: 0.18118926770157284
I0803 17:22:55.430758 16480 trainer.py:139] Epoch[52/1000] loss: 0.18070562283198038
I0803 17:23:38.630762 16480 trainer.py:139] Epoch[53/1000] loss: 0.17894142866134644
I0803 17:24:23.022527 16480 trainer.py:139] Epoch[54/1000] loss: 0.17834454476833345
I0803 17:25:07.165962 16480 trainer.py:139] Epoch[55/1000] loss: 0.17803864015473259
I0803 17:25:51.108639 16480 trainer.py:139] Epoch[56/1000] loss: 0.17752197331852382
I0803 17:26:35.690974 16480 trainer.py:139] Epoch[57/1000] loss: 0.17582454409864215
I0803 17:27:20.423695 16480 trainer.py:139] Epoch[58/1000] loss: 0.17549524188041687
I0803 17:28:04.892436 16480 trainer.py:139] Epoch[59/1000] loss: 0.17438559313615162
I0803 17:28:48.779405 16480 trainer.py:139] Epoch[60/1000] loss: 0.17439282688829633
I0803 17:29:33.534757 16480 trainer.py:139] Epoch[61/1000] loss: 0.17218959437476264
I0803 17:30:18.280094 16480 trainer.py:139] Epoch[62/1000] loss: 0.17306774927510155
I0803 17:31:02.993629 16480 trainer.py:139] Epoch[63/1000] loss: 0.17237926264603934
I0803 17:31:47.361403 16480 trainer.py:139] Epoch[64/1000] loss: 0.17254659910996756
I0803 17:32:31.825864 16480 trainer.py:139] Epoch[65/1000] loss: 0.17079085171222685
I0803 17:33:16.073174 16480 trainer.py:139] Epoch[66/1000] loss: 0.17095025718212128
I0803 17:33:59.799571 16480 trainer.py:139] Epoch[67/1000] loss: 0.17043424831496345
I0803 17:34:43.346553 16480 trainer.py:139] Epoch[68/1000] loss: 0.17014114757378895
I0803 17:35:28.432757 16480 trainer.py:139] Epoch[69/1000] loss: 0.1700291982624266
I0803 17:36:12.685121 16480 trainer.py:139] Epoch[70/1000] loss: 0.16976012216673958
I0803 17:36:57.323523 16480 trainer.py:139] Epoch[71/1000] loss: 0.16853060126304625
I0803 17:37:41.671009 16480 trainer.py:139] Epoch[72/1000] loss: 0.16849464952945709
I0803 17:38:25.737086 16480 trainer.py:139] Epoch[73/1000] loss: 0.16739743027422163
I0803 17:39:09.363452 16480 trainer.py:139] Epoch[74/1000] loss: 0.16782806813716888
I0803 17:39:53.326946 16480 trainer.py:139] Epoch[75/1000] loss: 0.16736096130477057
I0803 17:40:36.933924 16480 trainer.py:139] Epoch[76/1000] loss: 0.1667677249511083
I0803 17:41:21.687659 16480 trainer.py:139] Epoch[77/1000] loss: 0.1665000753932529
I0803 17:42:05.946763 16480 trainer.py:139] Epoch[78/1000] loss: 0.16577456812063854
I0803 17:42:49.700853 16480 trainer.py:139] Epoch[79/1000] loss: 0.16671228057808346
I0803 17:43:34.098664 16480 trainer.py:139] Epoch[80/1000] loss: 0.16429375575648414
I0803 17:44:18.518843 16480 trainer.py:139] Epoch[81/1000] loss: 0.16495211051570044
I0803 17:45:02.652016 16480 trainer.py:139] Epoch[82/1000] loss: 0.16435743418004778
I0803 17:45:46.878171 16480 trainer.py:139] Epoch[83/1000] loss: 0.1641220724582672
I0803 17:46:30.868201 16480 trainer.py:139] Epoch[84/1000] loss: 0.16518178906705644
I0803 17:47:14.942238 16480 trainer.py:139] Epoch[85/1000] loss: 0.16308250877592298
I0803 17:47:59.301913 16480 trainer.py:139] Epoch[86/1000] loss: 0.16376832074589198
I0803 17:48:43.524043 16480 trainer.py:139] Epoch[87/1000] loss: 0.16448528077867297
I0803 17:49:27.732404 16480 trainer.py:139] Epoch[88/1000] loss: 0.16387733538945515
I0803 17:50:11.683871 16480 trainer.py:139] Epoch[89/1000] loss: 0.16347106556097665
I0803 17:50:55.457590 16480 trainer.py:139] Epoch[90/1000] loss: 0.16308869116836125
I0803 17:51:39.134574 16480 trainer.py:139] Epoch[91/1000] loss: 0.1628457263443205
I0803 17:52:23.199379 16480 trainer.py:139] Epoch[92/1000] loss: 0.16175159143077003
I0803 17:53:07.426766 16480 trainer.py:139] Epoch[93/1000] loss: 0.16145847850375705
I0803 17:53:51.686594 16480 trainer.py:139] Epoch[94/1000] loss: 0.1612601986196306
I0803 17:54:35.943491 16480 trainer.py:139] Epoch[95/1000] loss: 0.1618283905585607
I0803 17:55:20.087927 16480 trainer.py:139] Epoch[96/1000] loss: 0.16206096549828847
I0803 17:56:04.033688 16480 trainer.py:139] Epoch[97/1000] loss: 0.16127738926145765
I0803 17:56:48.095743 16480 trainer.py:139] Epoch[98/1000] loss: 0.16169900351100497
I0803 17:57:32.014128 16480 trainer.py:139] Epoch[99/1000] loss: 0.16093543383810255
I0803 17:57:32.595183 16480 trainer.py:145] Test: [{'precision': 0.18050918196994994, 'recall': 0.2493440683323461, 'hit_ratio': 0.8879799666110184, 'ndcg': 0.27957608255376304}]
I0803 17:58:16.555868 16480 trainer.py:139] Epoch[100/1000] loss: 0.16046078781286877
I0803 17:58:59.768398 16480 trainer.py:139] Epoch[101/1000] loss: 0.1616438306040234
I0803 17:59:43.582210 16480 trainer.py:139] Epoch[102/1000] loss: 0.1600759403573142
I0803 18:00:28.104173 16480 trainer.py:139] Epoch[103/1000] loss: 0.16125738110807206
I0803 18:01:12.692529 16480 trainer.py:139] Epoch[104/1000] loss: 0.1601038843393326
I0803 18:01:56.708635 16480 trainer.py:139] Epoch[105/1000] loss: 0.1602804160780377
I0803 18:02:40.096894 16480 trainer.py:139] Epoch[106/1000] loss: 0.15977958414289686
I0803 18:03:24.940516 16480 trainer.py:139] Epoch[107/1000] loss: 0.15967198252677917
I0803 18:04:09.444773 16480 trainer.py:139] Epoch[108/1000] loss: 0.16000170032183328
I0803 18:04:53.654068 16480 trainer.py:139] Epoch[109/1000] loss: 0.15927848868899874
I0803 18:05:36.648020 16480 trainer.py:139] Epoch[110/1000] loss: 0.15833447754383087
I0803 18:06:21.009186 16480 trainer.py:139] Epoch[111/1000] loss: 0.15976241760783724
I0803 18:07:05.726488 16480 trainer.py:139] Epoch[112/1000] loss: 0.1590620271364848
I0803 18:07:50.018680 16480 trainer.py:139] Epoch[113/1000] loss: 0.15830634964836968
I0803 18:08:33.538041 16480 trainer.py:139] Epoch[114/1000] loss: 0.15760296834839715
I0803 18:09:16.533071 16480 trainer.py:139] Epoch[115/1000] loss: 0.15814873039722444
I0803 18:10:00.795159 16480 trainer.py:139] Epoch[116/1000] loss: 0.15863822559515636
I0803 18:10:44.045834 16480 trainer.py:139] Epoch[117/1000] loss: 0.15938907027244567
I0803 18:11:26.491474 16480 trainer.py:139] Epoch[118/1000] loss: 0.15895068969991472
I0803 18:12:10.918207 16480 trainer.py:139] Epoch[119/1000] loss: 0.1588811378346549
I0803 18:12:55.504223 16480 trainer.py:139] Epoch[120/1000] loss: 0.15870476133293576
I0803 18:13:39.270479 16480 trainer.py:139] Epoch[121/1000] loss: 0.1585276645421982
I0803 18:14:23.061838 16480 trainer.py:139] Epoch[122/1000] loss: 0.1574776236216227
I0803 18:15:06.163406 16480 trainer.py:139] Epoch[123/1000] loss: 0.15882763187090557
I0803 18:15:50.303869 16480 trainer.py:139] Epoch[124/1000] loss: 0.15687768512301975
I0803 18:16:33.545266 16480 trainer.py:139] Epoch[125/1000] loss: 0.157223150200314
I0803 18:17:16.302003 16480 trainer.py:139] Epoch[126/1000] loss: 0.157196963429451
I0803 18:17:59.804457 16480 trainer.py:139] Epoch[127/1000] loss: 0.15654342459307777
I0803 18:18:43.939030 16480 trainer.py:139] Epoch[128/1000] loss: 0.1572954718934165
I0803 18:19:27.788504 16480 trainer.py:139] Epoch[129/1000] loss: 0.15789771146244472
I0803 18:20:11.177649 16480 trainer.py:139] Epoch[130/1000] loss: 0.1561638316180971
I0803 18:20:54.493305 16480 trainer.py:139] Epoch[131/1000] loss: 0.15745345307721031
I0803 18:21:38.379369 16480 trainer.py:139] Epoch[132/1000] loss: 0.15685328092839984
I0803 18:22:21.863197 16480 trainer.py:139] Epoch[133/1000] loss: 0.157175150513649
I0803 18:23:05.661178 16480 trainer.py:139] Epoch[134/1000] loss: 0.15634083330631257
I0803 18:23:49.459333 16480 trainer.py:139] Epoch[135/1000] loss: 0.1569603830575943
I0803 18:24:33.730360 16480 trainer.py:139] Epoch[136/1000] loss: 0.15650290780597262
I0803 18:25:18.232917 16480 trainer.py:139] Epoch[137/1000] loss: 0.15687100582652622
I0803 18:26:01.731406 16480 trainer.py:139] Epoch[138/1000] loss: 0.156956578095754
I0803 18:26:44.922471 16480 trainer.py:139] Epoch[139/1000] loss: 0.15691513260205586
I0803 18:27:28.354116 16480 trainer.py:139] Epoch[140/1000] loss: 0.15622115982903376
I0803 18:28:12.469139 16480 trainer.py:139] Epoch[141/1000] loss: 0.15584951433870528
I0803 18:28:55.633168 16480 trainer.py:139] Epoch[142/1000] loss: 0.15579407652219138
I0803 18:29:39.165068 16480 trainer.py:139] Epoch[143/1000] loss: 0.1563133672873179
I0803 18:30:22.654845 16480 trainer.py:139] Epoch[144/1000] loss: 0.15558209664291806
I0803 18:31:06.406856 16480 trainer.py:139] Epoch[145/1000] loss: 0.15567371593581306
I0803 18:31:50.327127 16480 trainer.py:139] Epoch[146/1000] loss: 0.1554322428835763
I0803 18:32:33.521958 16480 trainer.py:139] Epoch[147/1000] loss: 0.15545137339168125
I0803 18:33:17.001996 16480 trainer.py:139] Epoch[148/1000] loss: 0.15586051331626044
I0803 18:34:00.889780 16480 trainer.py:139] Epoch[149/1000] loss: 0.15611809558338588
I0803 18:34:01.440936 16480 trainer.py:145] Test: [{'precision': 0.1836560934891486, 'recall': 0.2544556720969807, 'hit_ratio': 0.8929883138564274, 'ndcg': 0.2850025636399766}]
I0803 18:34:44.642541 16480 trainer.py:139] Epoch[150/1000] loss: 0.15524250706036885
I0803 18:35:27.205471 16480 trainer.py:139] Epoch[151/1000] loss: 0.154876352681054
I0803 18:36:10.932064 16480 trainer.py:139] Epoch[152/1000] loss: 0.1561139616701338
I0803 18:36:54.960311 16480 trainer.py:139] Epoch[153/1000] loss: 0.155512252913581
I0803 18:37:39.174305 16480 trainer.py:139] Epoch[154/1000] loss: 0.15489117238256667
I0803 18:38:22.784596 16480 trainer.py:139] Epoch[155/1000] loss: 0.15614987909793854
I0803 18:39:06.530464 16480 trainer.py:139] Epoch[156/1000] loss: 0.15487099058098264
I0803 18:39:50.296180 16480 trainer.py:139] Epoch[157/1000] loss: 0.15494237449434067
I0803 18:40:33.828835 16480 trainer.py:139] Epoch[158/1000] loss: 0.15529115690125359
I0803 18:41:17.713404 16480 trainer.py:139] Epoch[159/1000] loss: 0.15463473757108054
I0803 18:42:01.810289 16480 trainer.py:139] Epoch[160/1000] loss: 0.1547422778606415
I0803 18:42:45.960637 16480 trainer.py:139] Epoch[161/1000] loss: 0.15519332720173729
I0803 18:43:29.897151 16480 trainer.py:139] Epoch[162/1000] loss: 0.1549924796157413
I0803 18:44:13.467011 16480 trainer.py:139] Epoch[163/1000] loss: 0.1543069185813268
I0803 18:44:57.111021 16480 trainer.py:139] Epoch[164/1000] loss: 0.15491454084714254
I0803 18:45:40.796466 16480 trainer.py:139] Epoch[165/1000] loss: 0.1543605034881168
I0803 18:46:24.579368 16480 trainer.py:139] Epoch[166/1000] loss: 0.15472215387556287
I0803 18:47:08.737359 16480 trainer.py:139] Epoch[167/1000] loss: 0.1538285732931561
I0803 18:47:52.718437 16480 trainer.py:139] Epoch[168/1000] loss: 0.153401876423094
I0803 18:48:36.624254 16480 trainer.py:139] Epoch[169/1000] loss: 0.1543823943535487
I0803 18:49:20.610040 16480 trainer.py:139] Epoch[170/1000] loss: 0.155670648349656
I0803 18:50:04.609457 16480 trainer.py:139] Epoch[171/1000] loss: 0.1545061879687839
I0803 18:50:48.449777 16480 trainer.py:139] Epoch[172/1000] loss: 0.15486597703562843
I0803 18:51:31.871954 16480 trainer.py:139] Epoch[173/1000] loss: 0.15392331732643974
I0803 18:52:16.137231 16480 trainer.py:139] Epoch[174/1000] loss: 0.1534416103363037
I0803 18:52:59.819983 16480 trainer.py:139] Epoch[175/1000] loss: 0.15476047734419504
I0803 18:53:44.176361 16480 trainer.py:139] Epoch[176/1000] loss: 0.15355579833189648
I0803 18:54:27.985706 16480 trainer.py:139] Epoch[177/1000] loss: 0.15354754116800096
I0803 18:55:12.014008 16480 trainer.py:139] Epoch[178/1000] loss: 0.15410747587680818
I0803 18:55:55.881430 16480 trainer.py:139] Epoch[179/1000] loss: 0.15455032918188308
I0803 18:56:39.614610 16480 trainer.py:139] Epoch[180/1000] loss: 0.1539151966571808
I0803 18:57:23.208895 16480 trainer.py:139] Epoch[181/1000] loss: 0.15321085823906794
I0803 18:58:07.368770 16480 trainer.py:139] Epoch[182/1000] loss: 0.1537365186214447
I0803 18:58:51.337328 16480 trainer.py:139] Epoch[183/1000] loss: 0.15362039181921217
I0803 18:59:35.829569 16480 trainer.py:139] Epoch[184/1000] loss: 0.153931545747651
I0803 19:00:20.185173 16480 trainer.py:139] Epoch[185/1000] loss: 0.15481083432833354
I0803 19:01:04.376940 16480 trainer.py:139] Epoch[186/1000] loss: 0.15252726899252997
I0803 19:01:48.202201 16480 trainer.py:139] Epoch[187/1000] loss: 0.1542621127764384
I0803 19:02:31.795148 16480 trainer.py:139] Epoch[188/1000] loss: 0.15323915282885234
I0803 19:03:15.235233 16480 trainer.py:139] Epoch[189/1000] loss: 0.15323069208198123
I0803 19:03:59.502573 16480 trainer.py:139] Epoch[190/1000] loss: 0.15391324791643354
I0803 19:04:43.555555 16480 trainer.py:139] Epoch[191/1000] loss: 0.15358142329586877
I0803 19:05:27.409473 16480 trainer.py:139] Epoch[192/1000] loss: 0.15375333587328593
I0803 19:06:11.337090 16480 trainer.py:139] Epoch[193/1000] loss: 0.15367651244004568
I0803 19:06:55.272749 16480 trainer.py:139] Epoch[194/1000] loss: 0.1535540787378947
I0803 19:07:39.347998 16480 trainer.py:139] Epoch[195/1000] loss: 0.15326493601004282
I0803 19:08:23.185894 16480 trainer.py:139] Epoch[196/1000] loss: 0.1536125108268526
I0803 19:09:06.765305 16480 trainer.py:139] Epoch[197/1000] loss: 0.15366835799482134
I0803 19:09:50.650671 16480 trainer.py:139] Epoch[198/1000] loss: 0.15342471844620176
I0803 19:10:34.650530 16480 trainer.py:139] Epoch[199/1000] loss: 0.15370024429427254
I0803 19:10:35.233148 16480 trainer.py:145] Test: [{'precision': 0.1850500834724541, 'recall': 0.2572564622761283, 'hit_ratio': 0.8956594323873122, 'ndcg': 0.2884368333074374}]
I0803 19:11:19.047880 16480 trainer.py:139] Epoch[200/1000] loss: 0.15337349130047692
I0803 19:12:03.326584 16480 trainer.py:139] Epoch[201/1000] loss: 0.15377720918920304
I0803 19:12:47.313323 16480 trainer.py:139] Epoch[202/1000] loss: 0.15264064815309314
I0803 19:13:30.793803 16480 trainer.py:139] Epoch[203/1000] loss: 0.15280758943822648
I0803 19:14:14.373403 16480 trainer.py:139] Epoch[204/1000] loss: 0.153069618874126
I0803 19:14:57.831270 16480 trainer.py:139] Epoch[205/1000] loss: 0.15208602355586157
I0803 19:15:41.956433 16480 trainer.py:139] Epoch[206/1000] loss: 0.1528924819495943
I0803 19:16:25.575403 16480 trainer.py:139] Epoch[207/1000] loss: 0.1531701417101754
I0803 19:17:09.339962 16480 trainer.py:139] Epoch[208/1000] loss: 0.1529858289824592
I0803 19:17:52.923993 16480 trainer.py:139] Epoch[209/1000] loss: 0.1522544804546568
I0803 19:18:37.183333 16480 trainer.py:139] Epoch[210/1000] loss: 0.15323808047506543
I0803 19:19:21.178392 16480 trainer.py:139] Epoch[211/1000] loss: 0.15302150189876557
I0803 19:20:05.250101 16480 trainer.py:139] Epoch[212/1000] loss: 0.1521023796664344
I0803 19:20:48.993130 16480 trainer.py:139] Epoch[213/1000] loss: 0.15319610542721218
I0803 19:21:32.495376 16480 trainer.py:139] Epoch[214/1000] loss: 0.15145893037319183
I0803 19:22:15.850246 16480 trainer.py:139] Epoch[215/1000] loss: 0.15263132585419548
I0803 19:22:59.613348 16480 trainer.py:139] Epoch[216/1000] loss: 0.15295120636622112
I0803 19:23:43.775395 16480 trainer.py:139] Epoch[217/1000] loss: 0.15193290332953135
I0803 19:24:27.642576 16480 trainer.py:139] Epoch[218/1000] loss: 0.1526453113555908
I0803 19:25:11.718989 16480 trainer.py:139] Epoch[219/1000] loss: 0.15320466101169586
I0803 19:25:55.187468 16480 trainer.py:139] Epoch[220/1000] loss: 0.15318493525187174
I0803 19:26:39.139853 16480 trainer.py:139] Epoch[221/1000] loss: 0.15401099410321978
I0803 19:27:22.852561 16480 trainer.py:139] Epoch[222/1000] loss: 0.15160707500245835
I0803 19:28:06.444169 16480 trainer.py:139] Epoch[223/1000] loss: 0.15256880243619284
I0803 19:28:50.559301 16480 trainer.py:139] Epoch[224/1000] loss: 0.15288342197736104
I0803 19:29:34.443283 16480 trainer.py:139] Epoch[225/1000] loss: 0.1536447344885932
I0803 19:30:18.548619 16480 trainer.py:139] Epoch[226/1000] loss: 0.15216785060034857
I0803 19:31:02.799260 16480 trainer.py:139] Epoch[227/1000] loss: 0.15294375803735522
I0803 19:31:46.583681 16480 trainer.py:139] Epoch[228/1000] loss: 0.15280247959825727
I0803 19:32:30.351541 16480 trainer.py:139] Epoch[229/1000] loss: 0.1522650010055966
I0803 19:33:14.057018 16480 trainer.py:139] Epoch[230/1000] loss: 0.15251059002346462
I0803 19:33:58.021639 16480 trainer.py:139] Epoch[231/1000] loss: 0.15228906095027925
I0803 19:34:42.222223 16480 trainer.py:139] Epoch[232/1000] loss: 0.15307420836554633
I0803 19:35:26.552924 16480 trainer.py:139] Epoch[233/1000] loss: 0.153200341463089
I0803 19:36:10.827973 16480 trainer.py:139] Epoch[234/1000] loss: 0.1527744721704059
I0803 19:36:54.749789 16480 trainer.py:139] Epoch[235/1000] loss: 0.15294464700751834
I0803 19:37:38.408413 16480 trainer.py:139] Epoch[236/1000] loss: 0.15182268937428792
I0803 19:38:22.189593 16480 trainer.py:139] Epoch[237/1000] loss: 0.1526802693472968
I0803 19:39:05.574220 16480 trainer.py:139] Epoch[238/1000] loss: 0.153140815032853
I0803 19:39:49.801528 16480 trainer.py:139] Epoch[239/1000] loss: 0.15309024665090773
I0803 19:40:33.846031 16480 trainer.py:139] Epoch[240/1000] loss: 0.15343598716788823
I0803 19:41:17.551013 16480 trainer.py:139] Epoch[241/1000] loss: 0.1522119618786706
I0803 19:42:01.751673 16480 trainer.py:139] Epoch[242/1000] loss: 0.1523340810007519
I0803 19:42:45.565070 16480 trainer.py:139] Epoch[243/1000] loss: 0.15259514715936448
I0803 19:43:29.260271 16480 trainer.py:139] Epoch[244/1000] loss: 0.15199153244495392
I0803 19:44:12.862432 16480 trainer.py:139] Epoch[245/1000] loss: 0.15204553978310692
I0803 19:44:56.626273 16480 trainer.py:139] Epoch[246/1000] loss: 0.15285054385662078
I0803 19:45:40.606489 16480 trainer.py:139] Epoch[247/1000] loss: 0.1518265977833006
I0803 19:46:24.215723 16480 trainer.py:139] Epoch[248/1000] loss: 0.15140224271350436
I0803 19:47:07.908428 16480 trainer.py:139] Epoch[249/1000] loss: 0.1521529839436213
I0803 19:47:08.494467 16480 trainer.py:145] Test: [{'precision': 0.1863939899833055, 'recall': 0.258570939536633, 'hit_ratio': 0.8953255425709515, 'ndcg': 0.29079297065718945}]
I0803 19:47:52.484580 16480 trainer.py:139] Epoch[250/1000] loss: 0.15144222643640307
I0803 19:48:36.673925 16480 trainer.py:139] Epoch[251/1000] loss: 0.15158356573846604
I0803 19:49:20.453983 16480 trainer.py:139] Epoch[252/1000] loss: 0.15275726927651298
I0803 19:50:03.917248 16480 trainer.py:139] Epoch[253/1000] loss: 0.15196949402491253
I0803 19:50:47.633693 16480 trainer.py:139] Epoch[254/1000] loss: 0.15093328926298352
I0803 19:51:31.588056 16480 trainer.py:139] Epoch[255/1000] loss: 0.1524119089709388
I0803 19:52:15.269031 16480 trainer.py:139] Epoch[256/1000] loss: 0.1518111287554105
I0803 19:52:58.816243 16480 trainer.py:139] Epoch[257/1000] loss: 0.15140312784247928
I0803 19:53:42.627096 16480 trainer.py:139] Epoch[258/1000] loss: 0.15273447434107462
I0803 19:54:26.564111 16480 trainer.py:139] Epoch[259/1000] loss: 0.15275169955359566
I0803 19:55:10.581957 16480 trainer.py:139] Epoch[260/1000] loss: 0.15124681135018667
I0803 19:55:54.400142 16480 trainer.py:139] Epoch[261/1000] loss: 0.1521347493595547
I0803 19:56:37.980856 16480 trainer.py:139] Epoch[262/1000] loss: 0.1525201776292589
I0803 19:57:21.776315 16480 trainer.py:139] Epoch[263/1000] loss: 0.15226056973139446
I0803 19:58:06.007183 16480 trainer.py:139] Epoch[264/1000] loss: 0.15262037310335372
I0803 19:58:50.050534 16480 trainer.py:139] Epoch[265/1000] loss: 0.15210919201374054
I0803 19:59:34.539801 16480 trainer.py:139] Epoch[266/1000] loss: 0.1515153463019265
I0803 20:00:18.543624 16480 trainer.py:139] Epoch[267/1000] loss: 0.15152742207050324
I0803 20:01:03.033494 16480 trainer.py:139] Epoch[268/1000] loss: 0.1522230134407679
I0803 20:01:46.612629 16480 trainer.py:139] Epoch[269/1000] loss: 0.1526196872525745
I0803 20:02:30.389082 16480 trainer.py:139] Epoch[270/1000] loss: 0.1507177460855908
I0803 20:03:13.812123 16480 trainer.py:139] Epoch[271/1000] loss: 0.15199551946587034
I0803 20:03:57.953327 16480 trainer.py:139] Epoch[272/1000] loss: 0.15162523554431068
I0803 20:04:42.159527 16480 trainer.py:139] Epoch[273/1000] loss: 0.1521662437915802
I0803 20:05:26.150848 16480 trainer.py:139] Epoch[274/1000] loss: 0.15060193214151593
I0803 20:06:10.560859 16480 trainer.py:139] Epoch[275/1000] loss: 0.15087020569377474
I0803 20:06:54.709466 16480 trainer.py:139] Epoch[276/1000] loss: 0.15182285477717716
I0803 20:07:38.531897 16480 trainer.py:139] Epoch[277/1000] loss: 0.15132271594471403
I0803 20:08:22.318459 16480 trainer.py:139] Epoch[278/1000] loss: 0.15206469708018833
I0803 20:09:06.390760 16480 trainer.py:139] Epoch[279/1000] loss: 0.15184936304887137
I0803 20:09:50.615561 16480 trainer.py:139] Epoch[280/1000] loss: 0.15068258477581872
I0803 20:10:34.748803 16480 trainer.py:139] Epoch[281/1000] loss: 0.15024276137351988
I0803 20:11:19.056014 16480 trainer.py:139] Epoch[282/1000] loss: 0.1507578670978546
I0803 20:12:03.436942 16480 trainer.py:139] Epoch[283/1000] loss: 0.15190283960766263
I0803 20:12:47.511173 16480 trainer.py:139] Epoch[284/1000] loss: 0.15132849719789293
I0803 20:13:31.395931 16480 trainer.py:139] Epoch[285/1000] loss: 0.15125313546922473
I0803 20:14:15.090465 16480 trainer.py:139] Epoch[286/1000] loss: 0.15111534764369328
I0803 20:14:58.456999 16480 trainer.py:139] Epoch[287/1000] loss: 0.15180272307660844
I0803 20:15:42.309845 16480 trainer.py:139] Epoch[288/1000] loss: 0.150989139146275
I0803 20:16:25.782541 16480 trainer.py:139] Epoch[289/1000] loss: 0.15129668096701304
I0803 20:17:09.261383 16480 trainer.py:139] Epoch[290/1000] loss: 0.15132542603545718
I0803 20:17:53.481323 16480 trainer.py:139] Epoch[291/1000] loss: 0.15141480538580152
I0803 20:18:37.974173 16480 trainer.py:139] Epoch[292/1000] loss: 0.15203307608763378
I0803 20:19:22.347008 16480 trainer.py:139] Epoch[293/1000] loss: 0.15211577143934038
I0803 20:20:06.285424 16480 trainer.py:139] Epoch[294/1000] loss: 0.15124917460812462
I0803 20:20:50.220624 16480 trainer.py:139] Epoch[295/1000] loss: 0.15137344426578947
I0803 20:21:34.339937 16480 trainer.py:139] Epoch[296/1000] loss: 0.1507724412282308
I0803 20:22:17.803741 16480 trainer.py:139] Epoch[297/1000] loss: 0.1512466953198115
I0803 20:23:01.373073 16480 trainer.py:139] Epoch[298/1000] loss: 0.15151300377315946
I0803 20:23:45.407693 16480 trainer.py:139] Epoch[299/1000] loss: 0.15188640925619337
I0803 20:23:45.996265 16480 trainer.py:145] Test: [{'precision': 0.18723706176961605, 'recall': 0.2606033586062191, 'hit_ratio': 0.896160267111853, 'ndcg': 0.29225628778398094}]
I0803 20:24:30.436013 16480 trainer.py:139] Epoch[300/1000] loss: 0.15162942204210494
I0803 20:25:14.875020 16480 trainer.py:139] Epoch[301/1000] loss: 0.15211213721169367
I0803 20:25:58.590791 16480 trainer.py:139] Epoch[302/1000] loss: 0.15169054819477928
I0803 20:26:42.644982 16480 trainer.py:139] Epoch[303/1000] loss: 0.1514008855819702
I0803 20:27:26.973491 16480 trainer.py:139] Epoch[304/1000] loss: 0.15094537807835473
I0803 20:28:11.317137 16480 trainer.py:139] Epoch[305/1000] loss: 0.15129281547334458
I0803 20:28:55.538489 16480 trainer.py:139] Epoch[306/1000] loss: 0.1513743903901842
I0803 20:29:40.015286 16480 trainer.py:139] Epoch[307/1000] loss: 0.151922241780493
I0803 20:30:25.193490 16480 trainer.py:139] Epoch[308/1000] loss: 0.15146224757035573
I0803 20:31:10.163739 16480 trainer.py:139] Epoch[309/1000] loss: 0.15177736341953277
I0803 20:31:54.252982 16480 trainer.py:139] Epoch[310/1000] loss: 0.15145721475283305
I0803 20:32:38.450400 16480 trainer.py:139] Epoch[311/1000] loss: 0.15172519478533003
I0803 20:33:22.473977 16480 trainer.py:139] Epoch[312/1000] loss: 0.1511485128932529
I0803 20:34:07.135483 16480 trainer.py:139] Epoch[313/1000] loss: 0.15153113464514414
I0803 20:34:51.227177 16480 trainer.py:139] Epoch[314/1000] loss: 0.15133950352668762
I0803 20:35:35.428547 16480 trainer.py:139] Epoch[315/1000] loss: 0.15073338601324293
I0803 20:36:20.039663 16480 trainer.py:139] Epoch[316/1000] loss: 0.15188123451338875
I0803 20:37:05.174173 16480 trainer.py:139] Epoch[317/1000] loss: 0.15111098097430334
I0803 20:37:49.844552 16480 trainer.py:139] Epoch[318/1000] loss: 0.1502574336528778
I0803 20:38:34.118293 16480 trainer.py:139] Epoch[319/1000] loss: 0.15146472838189867
I0803 20:39:18.204083 16480 trainer.py:139] Epoch[320/1000] loss: 0.15163074904017979
I0803 20:40:02.406731 16480 trainer.py:139] Epoch[321/1000] loss: 0.15161229067378573
I0803 20:40:46.614964 16480 trainer.py:139] Epoch[322/1000] loss: 0.15060952723026275
I0803 20:41:31.127417 16480 trainer.py:139] Epoch[323/1000] loss: 0.15084432615174187
I0803 20:42:15.930469 16480 trainer.py:139] Epoch[324/1000] loss: 0.15155926442808576
I0803 20:43:00.783205 16480 trainer.py:139] Epoch[325/1000] loss: 0.15015212330553268
I0803 20:43:45.257371 16480 trainer.py:139] Epoch[326/1000] loss: 0.15116660277048746
I0803 20:44:29.452213 16480 trainer.py:139] Epoch[327/1000] loss: 0.1513046979241901
I0803 20:45:13.685354 16480 trainer.py:139] Epoch[328/1000] loss: 0.15087369445297452
I0803 20:45:58.241955 16480 trainer.py:139] Epoch[329/1000] loss: 0.15089636282788382
I0803 20:46:42.426371 16480 trainer.py:139] Epoch[330/1000] loss: 0.1508314123418596
I0803 20:47:27.061887 16480 trainer.py:139] Epoch[331/1000] loss: 0.15176885161134931
I0803 20:48:11.960993 16480 trainer.py:139] Epoch[332/1000] loss: 0.15180840803517234
I0803 20:48:56.376105 16480 trainer.py:139] Epoch[333/1000] loss: 0.15086095531781515
I0803 20:49:40.540540 16480 trainer.py:139] Epoch[334/1000] loss: 0.15112193041377597
I0803 20:50:24.976040 16480 trainer.py:139] Epoch[335/1000] loss: 0.1519186908006668
I0803 20:51:08.926684 16480 trainer.py:139] Epoch[336/1000] loss: 0.15128408127360873
I0803 20:51:53.005128 16480 trainer.py:139] Epoch[337/1000] loss: 0.15057575272189247
I0803 20:52:37.654228 16480 trainer.py:139] Epoch[338/1000] loss: 0.15151461905903285
I0803 20:53:21.857269 16480 trainer.py:139] Epoch[339/1000] loss: 0.15163033876154158
I0803 20:54:06.511490 16480 trainer.py:139] Epoch[340/1000] loss: 0.15118213136990866
I0803 20:54:51.376445 16480 trainer.py:139] Epoch[341/1000] loss: 0.14999980125162338
I0803 20:55:35.614373 16480 trainer.py:139] Epoch[342/1000] loss: 0.15109405272536808
I0803 20:56:19.843595 16480 trainer.py:139] Epoch[343/1000] loss: 0.15191397971577114
I0803 20:57:04.141365 16480 trainer.py:139] Epoch[344/1000] loss: 0.15065839608510334
I0803 20:57:48.406775 16480 trainer.py:139] Epoch[345/1000] loss: 0.15162380867534214
I0803 20:58:33.006730 16480 trainer.py:139] Epoch[346/1000] loss: 0.15110100428263346
I0803 20:59:17.618070 16480 trainer.py:139] Epoch[347/1000] loss: 0.15106565015183554
I0803 21:00:01.918870 16480 trainer.py:139] Epoch[348/1000] loss: 0.15011608613861932
I0803 21:00:46.212447 16480 trainer.py:139] Epoch[349/1000] loss: 0.15103702823321025
I0803 21:00:46.814023 16480 trainer.py:145] Test: [{'precision': 0.18723706176961602, 'recall': 0.26137461358029385, 'hit_ratio': 0.8968280467445743, 'ndcg': 0.2930200482368886}]
I0803 21:01:30.897952 16480 trainer.py:139] Epoch[350/1000] loss: 0.15116855998833975
I0803 21:02:15.324729 16480 trainer.py:139] Epoch[351/1000] loss: 0.15134825713104672
I0803 21:03:00.012819 16480 trainer.py:139] Epoch[352/1000] loss: 0.15126356508996752
I0803 21:03:45.031324 16480 trainer.py:139] Epoch[353/1000] loss: 0.15105707830852932
I0803 21:04:29.972501 16480 trainer.py:139] Epoch[354/1000] loss: 0.1508163849512736
I0803 21:05:14.358088 16480 trainer.py:139] Epoch[355/1000] loss: 0.15180605795648364
I0803 21:05:59.849249 16480 trainer.py:139] Epoch[356/1000] loss: 0.15053516182634566
I0803 21:06:45.104196 16480 trainer.py:139] Epoch[357/1000] loss: 0.15142894526322684
I0803 21:07:30.156516 16480 trainer.py:139] Epoch[358/1000] loss: 0.15165115621354844
I0803 21:08:15.299250 16480 trainer.py:139] Epoch[359/1000] loss: 0.15111007213592528
I0803 21:09:00.110697 16480 trainer.py:139] Epoch[360/1000] loss: 0.15039075202412075
I0803 21:09:45.140050 16480 trainer.py:139] Epoch[361/1000] loss: 0.15109087003601923
I0803 21:10:30.293933 16480 trainer.py:139] Epoch[362/1000] loss: 0.15138076000743442
I0803 21:11:15.481185 16480 trainer.py:139] Epoch[363/1000] loss: 0.15096419711907705
I0803 21:12:00.761703 16480 trainer.py:139] Epoch[364/1000] loss: 0.15045279165109
I0803 21:12:46.116228 16480 trainer.py:139] Epoch[365/1000] loss: 0.1507415395975113
I0803 21:13:31.062505 16480 trainer.py:139] Epoch[366/1000] loss: 0.15164362960391575
I0803 21:14:16.299877 16480 trainer.py:139] Epoch[367/1000] loss: 0.14945113665527768
I0803 21:15:01.155772 16480 trainer.py:139] Epoch[368/1000] loss: 0.1511496247847875
I0803 21:15:46.007207 16480 trainer.py:139] Epoch[369/1000] loss: 0.1503324145740933
I0803 21:16:31.255289 16480 trainer.py:139] Epoch[370/1000] loss: 0.15086550494035086
I0803 21:17:16.217129 16480 trainer.py:139] Epoch[371/1000] loss: 0.1512662794854906
I0803 21:18:01.361817 16480 trainer.py:139] Epoch[372/1000] loss: 0.15117301351494258
I0803 21:18:46.465150 16480 trainer.py:139] Epoch[373/1000] loss: 0.1510444078180525
I0803 21:19:31.530164 16480 trainer.py:139] Epoch[374/1000] loss: 0.15044867310259077
I0803 21:20:16.453384 16480 trainer.py:139] Epoch[375/1000] loss: 0.1503622603416443
I0803 21:21:01.451814 16480 trainer.py:139] Epoch[376/1000] loss: 0.14967758682039048
I0803 21:21:46.503526 16480 trainer.py:139] Epoch[377/1000] loss: 0.15073726216952005
I0803 21:22:31.432638 16480 trainer.py:139] Epoch[378/1000] loss: 0.15126467042499117
I0803 21:23:16.499142 16480 trainer.py:139] Epoch[379/1000] loss: 0.1511962811814414
I0803 21:24:01.658082 16480 trainer.py:139] Epoch[380/1000] loss: 0.15039453910456763
I0803 21:24:46.873221 16480 trainer.py:139] Epoch[381/1000] loss: 0.15184890409310658
I0803 21:25:31.680043 16480 trainer.py:139] Epoch[382/1000] loss: 0.15054806815253363
I0803 21:26:16.356422 16480 trainer.py:139] Epoch[383/1000] loss: 0.15041779028044808
I0803 21:27:01.370619 16480 trainer.py:139] Epoch[384/1000] loss: 0.1512370631429884
I0803 21:27:46.080916 16480 trainer.py:139] Epoch[385/1000] loss: 0.15014068881670634
I0803 21:28:31.176590 16480 trainer.py:139] Epoch[386/1000] loss: 0.15063880655500625
I0803 21:29:15.795065 16480 trainer.py:139] Epoch[387/1000] loss: 0.1512682440545824
I0803 21:30:00.916514 16480 trainer.py:139] Epoch[388/1000] loss: 0.1500239414638943
I0803 21:30:46.223378 16480 trainer.py:139] Epoch[389/1000] loss: 0.1509435237116284
I0803 21:31:31.264374 16480 trainer.py:139] Epoch[390/1000] loss: 0.15131065209706623
I0803 21:32:16.093495 16480 trainer.py:139] Epoch[391/1000] loss: 0.1489461079902119
I0803 21:33:01.047204 16480 trainer.py:139] Epoch[392/1000] loss: 0.15108620564142863
I0803 21:33:45.826007 16480 trainer.py:139] Epoch[393/1000] loss: 0.1519495654768414
I0803 21:34:30.724960 16480 trainer.py:139] Epoch[394/1000] loss: 0.151304699116283
I0803 21:35:15.163756 16480 trainer.py:139] Epoch[395/1000] loss: 0.15079075309965345
I0803 21:36:00.079753 16480 trainer.py:139] Epoch[396/1000] loss: 0.15097875992457072
I0803 21:36:44.955096 16480 trainer.py:139] Epoch[397/1000] loss: 0.15145390411218007
I0803 21:37:29.668409 16480 trainer.py:139] Epoch[398/1000] loss: 0.15016076385974883
I0803 21:38:14.093846 16480 trainer.py:139] Epoch[399/1000] loss: 0.15202684157424504
I0803 21:38:14.662941 16480 trainer.py:145] Test: [{'precision': 0.18792988313856424, 'recall': 0.26295914733746223, 'hit_ratio': 0.8986644407345576, 'ndcg': 0.293547957140547}]
I0803 21:38:59.085603 16480 trainer.py:139] Epoch[400/1000] loss: 0.15162017405033112
I0803 21:39:43.270274 16480 trainer.py:139] Epoch[401/1000] loss: 0.15082541631327734
I0803 21:40:28.150901 16480 trainer.py:139] Epoch[402/1000] loss: 0.1507084067000283
I0803 21:41:12.698992 16480 trainer.py:139] Epoch[403/1000] loss: 0.15111807690726387
I0803 21:41:57.825431 16480 trainer.py:139] Epoch[404/1000] loss: 0.1513115570942561
I0803 21:42:42.939267 16480 trainer.py:139] Epoch[405/1000] loss: 0.1509260744518704
I0803 21:43:27.933391 16480 trainer.py:139] Epoch[406/1000] loss: 0.15171144598060185
I0803 21:44:12.694779 16480 trainer.py:139] Epoch[407/1000] loss: 0.15074475599659815
I0803 21:44:56.822305 16480 trainer.py:139] Epoch[408/1000] loss: 0.15057977742618986
I0803 21:45:41.548507 16480 trainer.py:139] Epoch[409/1000] loss: 0.15125782251358033
I0803 21:46:26.684232 16480 trainer.py:139] Epoch[410/1000] loss: 0.1514458943075604
I0803 21:47:11.452744 16480 trainer.py:139] Epoch[411/1000] loss: 0.15077382253275978
I0803 21:47:56.554586 16480 trainer.py:139] Epoch[412/1000] loss: 0.15132216976748572
I0803 21:48:41.866041 16480 trainer.py:139] Epoch[413/1000] loss: 0.150840446319845
I0803 21:49:27.152591 16480 trainer.py:139] Epoch[414/1000] loss: 0.1503808476527532
I0803 21:50:12.307350 16480 trainer.py:139] Epoch[415/1000] loss: 0.14952802883254157
I0803 21:50:56.945935 16480 trainer.py:139] Epoch[416/1000] loss: 0.14918971257077324
I0803 21:51:41.718103 16480 trainer.py:139] Epoch[417/1000] loss: 0.15079553915394678
I0803 21:52:26.696885 16480 trainer.py:139] Epoch[418/1000] loss: 0.149743639893002
I0803 21:53:11.632257 16480 trainer.py:139] Epoch[419/1000] loss: 0.15091186006863913
I0803 21:53:56.834882 16480 trainer.py:139] Epoch[420/1000] loss: 0.15025747146871354
I0803 21:54:42.151211 16480 trainer.py:139] Epoch[421/1000] loss: 0.15091662400298647
I0803 21:55:26.438742 16480 trainer.py:139] Epoch[422/1000] loss: 0.15035107327832117
I0803 21:56:11.126260 16480 trainer.py:139] Epoch[423/1000] loss: 0.15023083918624455
I0803 21:56:55.131930 16480 trainer.py:139] Epoch[424/1000] loss: 0.14980536268817055
I0803 21:57:37.963326 16480 trainer.py:139] Epoch[425/1000] loss: 0.15073208298948076
I0803 21:58:22.037540 16480 trainer.py:139] Epoch[426/1000] loss: 0.15090240014923945
I0803 21:59:05.527120 16480 trainer.py:139] Epoch[427/1000] loss: 0.15033090750376382
I0803 21:59:49.990660 16480 trainer.py:139] Epoch[428/1000] loss: 0.15007677515347798
I0803 22:00:34.506580 16480 trainer.py:139] Epoch[429/1000] loss: 0.15038680202431148
I0803 22:01:19.118976 16480 trainer.py:139] Epoch[430/1000] loss: 0.15099673834111954
I0803 22:02:03.266037 16480 trainer.py:139] Epoch[431/1000] loss: 0.15054381357298957
I0803 22:02:47.306368 16480 trainer.py:139] Epoch[432/1000] loss: 0.15072374727990892
I0803 22:03:31.286445 16480 trainer.py:139] Epoch[433/1000] loss: 0.15015030317836336
I0803 22:04:16.123224 16480 trainer.py:139] Epoch[434/1000] loss: 0.15112672136889563
I0803 22:04:59.371615 16480 trainer.py:139] Epoch[435/1000] loss: 0.15088943315876854
I0803 22:05:43.892980 16480 trainer.py:139] Epoch[436/1000] loss: 0.1511800179216597
I0803 22:06:28.405956 16480 trainer.py:139] Epoch[437/1000] loss: 0.14956326689985064
I0803 22:07:12.969543 16480 trainer.py:139] Epoch[438/1000] loss: 0.15029567268159655
I0803 22:07:57.275995 16480 trainer.py:139] Epoch[439/1000] loss: 0.15100584381156498
I0803 22:08:41.870086 16480 trainer.py:139] Epoch[440/1000] loss: 0.1493614716000027
I0803 22:09:24.874215 16480 trainer.py:139] Epoch[441/1000] loss: 0.1510003157456716
I0803 22:10:09.179294 16480 trainer.py:139] Epoch[442/1000] loss: 0.15019772913720872
I0803 22:10:53.594572 16480 trainer.py:139] Epoch[443/1000] loss: 0.1512222565544976
I0803 22:11:37.421174 16480 trainer.py:139] Epoch[444/1000] loss: 0.14993904299206204
I0803 22:12:21.959985 16480 trainer.py:139] Epoch[445/1000] loss: 0.15023287329408858
I0803 22:13:06.488698 16480 trainer.py:139] Epoch[446/1000] loss: 0.15103764494260152
I0803 22:13:49.601691 16480 trainer.py:139] Epoch[447/1000] loss: 0.14973409162627327
I0803 22:14:33.419375 16480 trainer.py:139] Epoch[448/1000] loss: 0.150854474902153
I0803 22:15:17.709881 16480 trainer.py:139] Epoch[449/1000] loss: 0.1504403383202023
I0803 22:15:18.271578 16480 trainer.py:145] Test: [{'precision': 0.18744574290484148, 'recall': 0.2610525219962554, 'hit_ratio': 0.8958263772954925, 'ndcg': 0.29323895750581835}]
I0803 22:16:02.605998 16480 trainer.py:139] Epoch[450/1000] loss: 0.14971985406345792
I0803 22:16:46.273554 16480 trainer.py:139] Epoch[451/1000] loss: 0.15131366266144647
I0803 22:17:29.357743 16480 trainer.py:139] Epoch[452/1000] loss: 0.1503689855337143
I0803 22:18:13.717228 16480 trainer.py:139] Epoch[453/1000] loss: 0.14954330927795834
I0803 22:18:58.103722 16480 trainer.py:139] Epoch[454/1000] loss: 0.14985179172621832
I0803 22:19:42.801198 16480 trainer.py:139] Epoch[455/1000] loss: 0.15102105710241528
I0803 22:20:26.827460 16480 trainer.py:139] Epoch[456/1000] loss: 0.15028067217932808
I0803 22:21:09.812464 16480 trainer.py:139] Epoch[457/1000] loss: 0.15008523576789431
I0803 22:21:53.249791 16480 trainer.py:139] Epoch[458/1000] loss: 0.15154306292533876
I0803 22:22:36.828046 16480 trainer.py:139] Epoch[459/1000] loss: 0.15058926297558678
I0803 22:23:18.675792 16480 trainer.py:139] Epoch[460/1000] loss: 0.150317418773969
I0803 22:24:01.441407 16480 trainer.py:139] Epoch[461/1000] loss: 0.15056734098328484
I0803 22:24:46.235341 16480 trainer.py:139] Epoch[462/1000] loss: 0.15002026855945588
I0803 22:25:30.716891 16480 trainer.py:139] Epoch[463/1000] loss: 0.15096252262592316
I0803 22:26:15.293525 16480 trainer.py:139] Epoch[464/1000] loss: 0.1498480112022824
I0803 22:26:59.635804 16480 trainer.py:139] Epoch[465/1000] loss: 0.15125252405802408
I0803 22:27:43.801936 16480 trainer.py:139] Epoch[466/1000] loss: 0.15093239823977153
I0803 22:28:28.269262 16480 trainer.py:139] Epoch[467/1000] loss: 0.15109545552068288
I0803 22:29:11.605817 16480 trainer.py:139] Epoch[468/1000] loss: 0.15014401184187995
I0803 22:29:56.104785 16480 trainer.py:139] Epoch[469/1000] loss: 0.15022804624504513
I0803 22:30:40.675137 16480 trainer.py:139] Epoch[470/1000] loss: 0.15066017886002858
I0803 22:31:25.271410 16480 trainer.py:139] Epoch[471/1000] loss: 0.15034059623877208
I0803 22:32:09.980828 16480 trainer.py:139] Epoch[472/1000] loss: 0.1503386738565233
I0803 22:32:54.536574 16480 trainer.py:139] Epoch[473/1000] loss: 0.1498661861154768
I0803 22:33:39.052519 16480 trainer.py:139] Epoch[474/1000] loss: 0.15062921199533674
I0803 22:34:23.189166 16480 trainer.py:139] Epoch[475/1000] loss: 0.15033955600526597
I0803 22:35:07.408991 16480 trainer.py:139] Epoch[476/1000] loss: 0.15053637617164187
I0803 22:35:51.796231 16480 trainer.py:139] Epoch[477/1000] loss: 0.14984746777349048
I0803 22:36:36.201428 16480 trainer.py:139] Epoch[478/1000] loss: 0.15056517289744484
I0803 22:37:20.728822 16480 trainer.py:139] Epoch[479/1000] loss: 0.15120925684769948
I0803 22:38:05.371210 16480 trainer.py:139] Epoch[480/1000] loss: 0.1505432246790992
I0803 22:38:49.624913 16480 trainer.py:139] Epoch[481/1000] loss: 0.15071022848288218
I0803 22:39:34.387959 16480 trainer.py:139] Epoch[482/1000] loss: 0.1511537394258711
I0803 22:40:18.723688 16480 trainer.py:139] Epoch[483/1000] loss: 0.15024954670005375
I0803 22:41:03.025902 16480 trainer.py:139] Epoch[484/1000] loss: 0.1493815886312061
I0803 22:41:47.445115 16480 trainer.py:139] Epoch[485/1000] loss: 0.15027860787179734
I0803 22:42:32.446940 16480 trainer.py:139] Epoch[486/1000] loss: 0.1502769657307201
I0803 22:43:17.528446 16480 trainer.py:139] Epoch[487/1000] loss: 0.15089978059132894
I0803 22:44:02.074234 16480 trainer.py:139] Epoch[488/1000] loss: 0.15046112855275473
I0803 22:44:46.663934 16480 trainer.py:139] Epoch[489/1000] loss: 0.15002827399306828
I0803 22:45:31.095330 16480 trainer.py:139] Epoch[490/1000] loss: 0.15008711457252502
I0803 22:46:15.503441 16480 trainer.py:139] Epoch[491/1000] loss: 0.1507552804549535
I0803 22:46:59.900977 16480 trainer.py:139] Epoch[492/1000] loss: 0.15103021833631727
I0803 22:47:44.175873 16480 trainer.py:139] Epoch[493/1000] loss: 0.15106817563374839
I0803 22:48:28.272007 16480 trainer.py:139] Epoch[494/1000] loss: 0.149846074713601
I0803 22:49:12.578818 16480 trainer.py:139] Epoch[495/1000] loss: 0.14981718917687734
I0803 22:49:56.371181 16480 trainer.py:139] Epoch[496/1000] loss: 0.15073399325211842
I0803 22:50:41.090932 16480 trainer.py:139] Epoch[497/1000] loss: 0.15039051532745362
I0803 22:51:25.210209 16480 trainer.py:139] Epoch[498/1000] loss: 0.1505967320336236
I0803 22:52:09.320453 16480 trainer.py:139] Epoch[499/1000] loss: 0.15088948422008092
I0803 22:52:09.904094 16480 trainer.py:145] Test: [{'precision': 0.1879632721202003, 'recall': 0.2623469282550773, 'hit_ratio': 0.8971619365609349, 'ndcg': 0.2943922156281639}]
I0803 22:52:53.575362 16480 trainer.py:139] Epoch[500/1000] loss: 0.15025819791687858
I0803 22:53:38.050613 16480 trainer.py:139] Epoch[501/1000] loss: 0.15005022711224025
I0803 22:54:23.090579 16480 trainer.py:139] Epoch[502/1000] loss: 0.14949569602807364
I0803 22:55:07.417370 16480 trainer.py:139] Epoch[503/1000] loss: 0.15055773311191134
I0803 22:55:52.341609 16480 trainer.py:139] Epoch[504/1000] loss: 0.14977842960092758
I0803 22:56:37.239813 16480 trainer.py:139] Epoch[505/1000] loss: 0.1502496545844608
I0803 22:57:22.188870 16480 trainer.py:139] Epoch[506/1000] loss: 0.14976043032275305
I0803 22:58:06.233674 16480 trainer.py:139] Epoch[507/1000] loss: 0.1497876395781835
I0803 22:58:50.805031 16480 trainer.py:139] Epoch[508/1000] loss: 0.14976665669017367
I0803 22:59:35.463079 16480 trainer.py:139] Epoch[509/1000] loss: 0.1499055051141315
I0803 23:00:20.446041 16480 trainer.py:139] Epoch[510/1000] loss: 0.14973370419608223
I0803 23:01:05.510727 16480 trainer.py:139] Epoch[511/1000] loss: 0.15003566741943358
I0803 23:01:50.332870 16480 trainer.py:139] Epoch[512/1000] loss: 0.15008345464865366
I0803 23:02:33.774764 16480 trainer.py:139] Epoch[513/1000] loss: 0.14974973645475176
I0803 23:03:18.171535 16480 trainer.py:139] Epoch[514/1000] loss: 0.14984518746534983
I0803 23:04:02.849056 16480 trainer.py:139] Epoch[515/1000] loss: 0.150170174241066
I0803 23:04:47.089213 16480 trainer.py:139] Epoch[516/1000] loss: 0.1496907482544581
I0803 23:05:31.159629 16480 trainer.py:139] Epoch[517/1000] loss: 0.15064659357070923
I0803 23:06:15.865754 16480 trainer.py:139] Epoch[518/1000] loss: 0.15052192207839754
I0803 23:07:00.177722 16480 trainer.py:139] Epoch[519/1000] loss: 0.15030128127998776
I0803 23:07:44.620846 16480 trainer.py:139] Epoch[520/1000] loss: 0.1500669570763906
I0803 23:08:29.205934 16480 trainer.py:139] Epoch[521/1000] loss: 0.15131690290239122
I0803 23:09:13.973528 16480 trainer.py:139] Epoch[522/1000] loss: 0.1502231126361423
I0803 23:09:58.391655 16480 trainer.py:139] Epoch[523/1000] loss: 0.14989358478122286
I0803 23:10:42.283453 16480 trainer.py:139] Epoch[524/1000] loss: 0.15081037941906186
I0803 23:11:26.131792 16480 trainer.py:139] Epoch[525/1000] loss: 0.1512245696120792
I0803 23:12:10.575940 16480 trainer.py:139] Epoch[526/1000] loss: 0.1500912085506651
I0803 23:12:55.210591 16480 trainer.py:139] Epoch[527/1000] loss: 0.15041547887855106
I0803 23:13:39.772245 16480 trainer.py:139] Epoch[528/1000] loss: 0.1508540274699529
I0803 23:14:24.605360 16480 trainer.py:139] Epoch[529/1000] loss: 0.15039923548698425
I0803 23:15:09.282413 16480 trainer.py:139] Epoch[530/1000] loss: 0.15040465427769556
I0803 23:15:53.935199 16480 trainer.py:139] Epoch[531/1000] loss: 0.15104652219348483
I0803 23:16:38.550637 16480 trainer.py:139] Epoch[532/1000] loss: 0.15040527178181543
I0803 23:17:23.226426 16480 trainer.py:139] Epoch[533/1000] loss: 0.15062413215637208
I0803 23:18:07.908507 16480 trainer.py:139] Epoch[534/1000] loss: 0.14977772666348352
I0803 23:18:52.775203 16480 trainer.py:139] Epoch[535/1000] loss: 0.14860205696688758
I0803 23:19:37.483117 16480 trainer.py:139] Epoch[536/1000] loss: 0.1489258070786794
I0803 23:20:21.473744 16480 trainer.py:139] Epoch[537/1000] loss: 0.15027709239059026
I0803 23:21:04.832524 16480 trainer.py:139] Epoch[538/1000] loss: 0.1507458683517244
I0803 23:21:49.178884 16480 trainer.py:139] Epoch[539/1000] loss: 0.14982499096128676
I0803 23:22:33.522291 16480 trainer.py:139] Epoch[540/1000] loss: 0.15038700153430304
I0803 23:23:18.687838 16480 trainer.py:139] Epoch[541/1000] loss: 0.1498472301165263
I0803 23:24:03.498092 16480 trainer.py:139] Epoch[542/1000] loss: 0.1505464337931739
I0803 23:24:47.983397 16480 trainer.py:139] Epoch[543/1000] loss: 0.1501273661851883
I0803 23:25:32.135497 16480 trainer.py:139] Epoch[544/1000] loss: 0.15058244427045187
I0803 23:26:15.953231 16480 trainer.py:139] Epoch[545/1000] loss: 0.14937267667717405
I0803 23:26:59.889387 16480 trainer.py:139] Epoch[546/1000] loss: 0.15008940855662029
I0803 23:27:43.633033 16480 trainer.py:139] Epoch[547/1000] loss: 0.14980157792568208
I0803 23:28:28.493234 16480 trainer.py:139] Epoch[548/1000] loss: 0.15012896368900935
I0803 23:29:12.652987 16480 trainer.py:139] Epoch[549/1000] loss: 0.15033311165041394
I0803 23:29:13.222715 16480 trainer.py:145] Test: [{'precision': 0.18777963272120204, 'recall': 0.2621647932047933, 'hit_ratio': 0.8964941569282137, 'ndcg': 0.2943909603519884}]
I0803 23:29:57.667723 16480 trainer.py:139] Epoch[550/1000] loss: 0.1509148261944453
I0803 23:30:42.768197 16480 trainer.py:139] Epoch[551/1000] loss: 0.15006412009398143
I0803 23:31:27.261492 16480 trainer.py:139] Epoch[552/1000] loss: 0.15030657301346462
I0803 23:32:11.824489 16480 trainer.py:139] Epoch[553/1000] loss: 0.1505357680718104
I0803 23:32:56.332467 16480 trainer.py:139] Epoch[554/1000] loss: 0.15000974973042805
I0803 23:33:41.268410 16480 trainer.py:139] Epoch[555/1000] loss: 0.14969887488418154
I0803 23:34:25.948239 16480 trainer.py:139] Epoch[556/1000] loss: 0.1506535800298055
I0803 23:35:10.771162 16480 trainer.py:139] Epoch[557/1000] loss: 0.15009395599365236
I0803 23:35:55.335056 16480 trainer.py:139] Epoch[558/1000] loss: 0.14975058813889822
I0803 23:36:40.201551 16480 trainer.py:139] Epoch[559/1000] loss: 0.1510984198914634
I0803 23:37:25.425848 16480 trainer.py:139] Epoch[560/1000] loss: 0.15008543113867442
I0803 23:38:10.307008 16480 trainer.py:139] Epoch[561/1000] loss: 0.1500724141465293
I0803 23:38:55.408306 16480 trainer.py:139] Epoch[562/1000] loss: 0.15085085895326403
I0803 23:39:40.177076 16480 trainer.py:139] Epoch[563/1000] loss: 0.150475581685702
I0803 23:40:25.000662 16480 trainer.py:139] Epoch[564/1000] loss: 0.15085822562376658
I0803 23:41:09.770351 16480 trainer.py:139] Epoch[565/1000] loss: 0.15076300819714863
I0803 23:41:54.795741 16480 trainer.py:139] Epoch[566/1000] loss: 0.1499865985578961
I0803 23:42:40.100809 16480 trainer.py:139] Epoch[567/1000] loss: 0.14930092381106483
I0803 23:43:25.213837 16480 trainer.py:139] Epoch[568/1000] loss: 0.14966376543045043
I0803 23:44:10.308955 16480 trainer.py:139] Epoch[569/1000] loss: 0.15091274129019844
I0803 23:44:54.678794 16480 trainer.py:139] Epoch[570/1000] loss: 0.14983909103605483
I0803 23:45:39.257701 16480 trainer.py:139] Epoch[571/1000] loss: 0.14947581277953254
I0803 23:46:24.131099 16480 trainer.py:139] Epoch[572/1000] loss: 0.1497251096698973
I0803 23:47:09.031714 16480 trainer.py:139] Epoch[573/1000] loss: 0.14998046156432893
I0803 23:47:53.907949 16480 trainer.py:139] Epoch[574/1000] loss: 0.15015899406539068
I0803 23:48:38.824301 16480 trainer.py:139] Epoch[575/1000] loss: 0.1502837148639891
I0803 23:49:23.591148 16480 trainer.py:139] Epoch[576/1000] loss: 0.1502400557200114
I0803 23:50:08.178520 16480 trainer.py:139] Epoch[577/1000] loss: 0.15088153143723806
I0803 23:50:53.191752 16480 trainer.py:139] Epoch[578/1000] loss: 0.15076448500156403
I0803 23:51:37.772403 16480 trainer.py:139] Epoch[579/1000] loss: 0.14985453873872756
I0803 23:52:22.488944 16480 trainer.py:139] Epoch[580/1000] loss: 0.149576877951622
I0803 23:53:07.092178 16480 trainer.py:139] Epoch[581/1000] loss: 0.14954007354047563
I0803 23:53:51.785490 16480 trainer.py:139] Epoch[582/1000] loss: 0.1494465114010705
I0803 23:54:36.403366 16480 trainer.py:139] Epoch[583/1000] loss: 0.15008327186107637
I0803 23:55:20.990102 16480 trainer.py:139] Epoch[584/1000] loss: 0.15119929909706115
I0803 23:56:05.566255 16480 trainer.py:139] Epoch[585/1000] loss: 0.14982679519388412
I0803 23:56:50.212265 16480 trainer.py:139] Epoch[586/1000] loss: 0.15063014268875122
I0803 23:57:35.084993 16480 trainer.py:139] Epoch[587/1000] loss: 0.14976662119229633
I0803 23:58:19.906491 16480 trainer.py:139] Epoch[588/1000] loss: 0.15016594615247514
I0803 23:59:04.482322 16480 trainer.py:139] Epoch[589/1000] loss: 0.14953905516200594
I0803 23:59:48.933646 16480 trainer.py:139] Epoch[590/1000] loss: 0.14970386491881477
I0804 00:00:34.044673 16480 trainer.py:139] Epoch[591/1000] loss: 0.1490250164270401
I0804 00:01:18.738700 16480 trainer.py:139] Epoch[592/1000] loss: 0.14960772381888496
I0804 00:02:03.212550 16480 trainer.py:139] Epoch[593/1000] loss: 0.15010269244511923
I0804 00:02:47.805018 16480 trainer.py:139] Epoch[594/1000] loss: 0.1504269544945823
I0804 00:03:31.927234 16480 trainer.py:139] Epoch[595/1000] loss: 0.14919806122779847
I0804 00:04:16.874696 16480 trainer.py:139] Epoch[596/1000] loss: 0.15008155326048533
I0804 00:05:01.606894 16480 trainer.py:139] Epoch[597/1000] loss: 0.1507835179567337
I0804 00:05:46.522446 16480 trainer.py:139] Epoch[598/1000] loss: 0.15043318443828158
I0804 00:06:31.507533 16480 trainer.py:139] Epoch[599/1000] loss: 0.15038089050187006
I0804 00:06:32.087136 16480 trainer.py:145] Test: [{'precision': 0.188889816360601, 'recall': 0.26418030085522215, 'hit_ratio': 0.8991652754590985, 'ndcg': 0.29561120061628066}]
I0804 00:07:16.798381 16480 trainer.py:139] Epoch[600/1000] loss: 0.14951716406477822
I0804 00:08:01.548370 16480 trainer.py:139] Epoch[601/1000] loss: 0.14990161803033616
I0804 00:08:46.459409 16480 trainer.py:139] Epoch[602/1000] loss: 0.15015804602040184
I0804 00:09:31.068330 16480 trainer.py:139] Epoch[603/1000] loss: 0.15040312594837613
I0804 00:10:15.781165 16480 trainer.py:139] Epoch[604/1000] loss: 0.15097299443350898
I0804 00:11:00.750540 16480 trainer.py:139] Epoch[605/1000] loss: 0.1497139178382026
I0804 00:11:45.442870 16480 trainer.py:139] Epoch[606/1000] loss: 0.14979928387535943
I0804 00:12:30.251951 16480 trainer.py:139] Epoch[607/1000] loss: 0.1497164050075743
I0804 00:13:15.026883 16480 trainer.py:139] Epoch[608/1000] loss: 0.1494484472937054
I0804 00:13:59.866907 16480 trainer.py:139] Epoch[609/1000] loss: 0.15037250651253595
I0804 00:14:44.643131 16480 trainer.py:139] Epoch[610/1000] loss: 0.15025068170494504
I0804 00:15:29.475253 16480 trainer.py:139] Epoch[611/1000] loss: 0.15015902737776438
I0804 00:16:14.429138 16480 trainer.py:139] Epoch[612/1000] loss: 0.14943562765916188
I0804 00:16:59.284188 16480 trainer.py:139] Epoch[613/1000] loss: 0.15106053690115612
I0804 00:17:44.130992 16480 trainer.py:139] Epoch[614/1000] loss: 0.1497500271929635
I0804 00:18:29.084847 16480 trainer.py:139] Epoch[615/1000] loss: 0.14982119997342427
I0804 00:19:13.644968 16480 trainer.py:139] Epoch[616/1000] loss: 0.1493204606903924
I0804 00:19:58.655223 16480 trainer.py:139] Epoch[617/1000] loss: 0.15055227001508076
I0804 00:20:43.662429 16480 trainer.py:139] Epoch[618/1000] loss: 0.1504757900370492
I0804 00:21:28.439738 16480 trainer.py:139] Epoch[619/1000] loss: 0.15009852621290418
I0804 00:22:13.131090 16480 trainer.py:139] Epoch[620/1000] loss: 0.15019490202267965
I0804 00:22:58.095968 16480 trainer.py:139] Epoch[621/1000] loss: 0.14978344606028662
I0804 00:23:42.773445 16480 trainer.py:139] Epoch[622/1000] loss: 0.15032465808921391
I0804 00:24:27.390306 16480 trainer.py:139] Epoch[623/1000] loss: 0.1493389899863137
I0804 00:25:12.253912 16480 trainer.py:139] Epoch[624/1000] loss: 0.15054052684042188
I0804 00:25:57.081542 16480 trainer.py:139] Epoch[625/1000] loss: 0.1500128745370441
I0804 00:26:42.064357 16480 trainer.py:139] Epoch[626/1000] loss: 0.150889422694842
I0804 00:27:26.287364 16480 trainer.py:139] Epoch[627/1000] loss: 0.14980741805500455
I0804 00:28:10.497370 16480 trainer.py:139] Epoch[628/1000] loss: 0.14976550704903072
I0804 00:28:54.805499 16480 trainer.py:139] Epoch[629/1000] loss: 0.1511021090216107
I0804 00:29:39.553683 16480 trainer.py:139] Epoch[630/1000] loss: 0.15071798271603054
I0804 00:30:24.349637 16480 trainer.py:139] Epoch[631/1000] loss: 0.14931961046324835
I0804 00:31:09.177027 16480 trainer.py:139] Epoch[632/1000] loss: 0.14937854637702305
I0804 00:31:54.247482 16480 trainer.py:139] Epoch[633/1000] loss: 0.1494594779279497
I0804 00:32:39.357089 16480 trainer.py:139] Epoch[634/1000] loss: 0.15047048767407736
I0804 00:33:24.126045 16480 trainer.py:139] Epoch[635/1000] loss: 0.14946673346890343
I0804 00:34:08.143254 16480 trainer.py:139] Epoch[636/1000] loss: 0.15018294036388397
I0804 00:34:51.797898 16480 trainer.py:139] Epoch[637/1000] loss: 0.14961858318911658
I0804 00:35:36.796488 16480 trainer.py:139] Epoch[638/1000] loss: 0.1498600184255176
I0804 00:36:21.825289 16480 trainer.py:139] Epoch[639/1000] loss: 0.14985495077239142
I0804 00:37:06.917529 16480 trainer.py:139] Epoch[640/1000] loss: 0.15008737941582997
I0804 00:37:51.623861 16480 trainer.py:139] Epoch[641/1000] loss: 0.1496479311916563
I0804 00:38:36.572755 16480 trainer.py:139] Epoch[642/1000] loss: 0.15000069227483537
I0804 00:39:21.448064 16480 trainer.py:139] Epoch[643/1000] loss: 0.15049311618010203
I0804 00:40:06.356335 16480 trainer.py:139] Epoch[644/1000] loss: 0.14957318279478285
I0804 00:40:51.259015 16480 trainer.py:139] Epoch[645/1000] loss: 0.14958500272697872
I0804 00:41:36.019005 16480 trainer.py:139] Epoch[646/1000] loss: 0.14974985553158654
I0804 00:42:20.999690 16480 trainer.py:139] Epoch[647/1000] loss: 0.15002127528190612
I0804 00:43:06.207794 16480 trainer.py:139] Epoch[648/1000] loss: 0.15031288219822778
I0804 00:43:51.015462 16480 trainer.py:139] Epoch[649/1000] loss: 0.14926427258385552
I0804 00:43:51.560638 16480 trainer.py:145] Test: [{'precision': 0.18858096828046747, 'recall': 0.26296227203066286, 'hit_ratio': 0.8971619365609349, 'ndcg': 0.2955201542774776}]
I0804 00:44:36.346667 16480 trainer.py:139] Epoch[650/1000] loss: 0.14977619647979737
I0804 00:45:20.647740 16480 trainer.py:139] Epoch[651/1000] loss: 0.1504975300365024
I0804 00:46:05.713809 16480 trainer.py:139] Epoch[652/1000] loss: 0.15043418765068053
I0804 00:46:50.456019 16480 trainer.py:139] Epoch[653/1000] loss: 0.1505333126253552
I0804 00:47:35.216934 16480 trainer.py:139] Epoch[654/1000] loss: 0.15008785651789772
I0804 00:48:20.498864 16480 trainer.py:139] Epoch[655/1000] loss: 0.14971303502718608
I0804 00:49:05.223580 16480 trainer.py:139] Epoch[656/1000] loss: 0.15030968911117978
I0804 00:49:50.079869 16480 trainer.py:139] Epoch[657/1000] loss: 0.15072244690524209
I0804 00:50:34.939190 16480 trainer.py:139] Epoch[658/1000] loss: 0.14965148912535772
I0804 00:51:19.787106 16480 trainer.py:139] Epoch[659/1000] loss: 0.14990759982003107
I0804 00:52:04.414400 16480 trainer.py:139] Epoch[660/1000] loss: 0.1497868400812149
I0804 00:52:49.368215 16480 trainer.py:139] Epoch[661/1000] loss: 0.1498353064722485
I0804 00:53:33.612704 16480 trainer.py:139] Epoch[662/1000] loss: 0.1505893474817276
I0804 00:54:18.952026 16480 trainer.py:139] Epoch[663/1000] loss: 0.14983716825644175
I0804 00:55:03.625274 16480 trainer.py:139] Epoch[664/1000] loss: 0.15098685827520159
I0804 00:55:48.634443 16480 trainer.py:139] Epoch[665/1000] loss: 0.1497683608531952
I0804 00:56:33.316709 16480 trainer.py:139] Epoch[666/1000] loss: 0.1493100619978375
I0804 00:57:18.216160 16480 trainer.py:139] Epoch[667/1000] loss: 0.1509070435497496
I0804 00:58:03.063319 16480 trainer.py:139] Epoch[668/1000] loss: 0.15013348946968713
I0804 00:58:47.924916 16480 trainer.py:139] Epoch[669/1000] loss: 0.14968866990672217
I0804 00:59:32.532325 16480 trainer.py:139] Epoch[670/1000] loss: 0.15058330535888673
I0804 01:00:17.320068 16480 trainer.py:139] Epoch[671/1000] loss: 0.1493221714761522
I0804 01:01:02.029873 16480 trainer.py:139] Epoch[672/1000] loss: 0.14968227177858354
I0804 01:01:46.916947 16480 trainer.py:139] Epoch[673/1000] loss: 0.1498440189494027
I0804 01:02:31.457607 16480 trainer.py:139] Epoch[674/1000] loss: 0.14962893942991892
I0804 01:03:15.984556 16480 trainer.py:139] Epoch[675/1000] loss: 0.14974976089265613
I0804 01:04:00.651737 16480 trainer.py:139] Epoch[676/1000] loss: 0.14969452427493202
I0804 01:04:44.837246 16480 trainer.py:139] Epoch[677/1000] loss: 0.15016671531730227
I0804 01:05:29.306344 16480 trainer.py:139] Epoch[678/1000] loss: 0.15017439398500654
I0804 01:06:13.955720 16480 trainer.py:139] Epoch[679/1000] loss: 0.15033001959323883
I0804 01:06:58.726129 16480 trainer.py:139] Epoch[680/1000] loss: 0.15011176274882423
I0804 01:07:43.650610 16480 trainer.py:139] Epoch[681/1000] loss: 0.14983126196596358
I0804 01:08:28.572752 16480 trainer.py:139] Epoch[682/1000] loss: 0.15037111752563054
I0804 01:09:12.941790 16480 trainer.py:139] Epoch[683/1000] loss: 0.1494866195983357
I0804 01:09:57.949152 16480 trainer.py:139] Epoch[684/1000] loss: 0.14969821963045332
I0804 01:10:42.875639 16480 trainer.py:139] Epoch[685/1000] loss: 0.14960065490669675
I0804 01:11:25.583138 16480 trainer.py:139] Epoch[686/1000] loss: 0.15051320672035218
I0804 01:12:10.473560 16480 trainer.py:139] Epoch[687/1000] loss: 0.15045544816388023
I0804 01:12:55.134996 16480 trainer.py:139] Epoch[688/1000] loss: 0.14967870189083948
I0804 01:13:40.153449 16480 trainer.py:139] Epoch[689/1000] loss: 0.14957507113615673
I0804 01:14:25.258111 16480 trainer.py:139] Epoch[690/1000] loss: 0.14977129413021936
I0804 01:15:10.115179 16480 trainer.py:139] Epoch[691/1000] loss: 0.14898296680715348
I0804 01:15:55.135172 16480 trainer.py:139] Epoch[692/1000] loss: 0.14989611162079705
I0804 01:16:40.096797 16480 trainer.py:139] Epoch[693/1000] loss: 0.14959750380780962
I0804 01:17:24.874649 16480 trainer.py:139] Epoch[694/1000] loss: 0.15033495664596558
I0804 01:18:09.618373 16480 trainer.py:139] Epoch[695/1000] loss: 0.1510732647445467
I0804 01:18:54.540496 16480 trainer.py:139] Epoch[696/1000] loss: 0.15006890217463176
I0804 01:19:39.373465 16480 trainer.py:139] Epoch[697/1000] loss: 0.14926024291250442
I0804 01:20:23.763130 16480 trainer.py:139] Epoch[698/1000] loss: 0.14962669187121921
I0804 01:21:06.974678 16480 trainer.py:139] Epoch[699/1000] loss: 0.1504572695824835
I0804 01:21:07.550751 16480 trainer.py:145] Test: [{'precision': 0.18883138564273785, 'recall': 0.26423246342179796, 'hit_ratio': 0.898330550918197, 'ndcg': 0.2954954835822768}]
I0804 01:21:51.650300 16480 trainer.py:139] Epoch[700/1000] loss: 0.15031246311134763
I0804 01:22:36.796943 16480 trainer.py:139] Epoch[701/1000] loss: 0.14988435566425323
I0804 01:23:21.727388 16480 trainer.py:139] Epoch[702/1000] loss: 0.14992871152030096
I0804 01:24:06.644095 16480 trainer.py:139] Epoch[703/1000] loss: 0.15073038895924887
I0804 01:24:51.511786 16480 trainer.py:139] Epoch[704/1000] loss: 0.1507827479309506
I0804 01:25:36.347086 16480 trainer.py:139] Epoch[705/1000] loss: 0.14964353591203688
I0804 01:26:21.002093 16480 trainer.py:139] Epoch[706/1000] loss: 0.1500626309712728
I0804 01:27:05.179738 16480 trainer.py:139] Epoch[707/1000] loss: 0.14913570556375716
I0804 01:27:49.665504 16480 trainer.py:139] Epoch[708/1000] loss: 0.15042802406681907
I0804 01:28:34.506280 16480 trainer.py:139] Epoch[709/1000] loss: 0.14899597446123758
I0804 01:29:18.772254 16480 trainer.py:139] Epoch[710/1000] loss: 0.1496323084168964
I0804 01:30:03.609105 16480 trainer.py:139] Epoch[711/1000] loss: 0.14951490117443933
I0804 01:30:48.281525 16480 trainer.py:139] Epoch[712/1000] loss: 0.15121783859199947
I0804 01:31:32.874039 16480 trainer.py:139] Epoch[713/1000] loss: 0.14929648319880168
I0804 01:32:17.948939 16480 trainer.py:139] Epoch[714/1000] loss: 0.15004236115349665
I0804 01:33:02.116879 16480 trainer.py:139] Epoch[715/1000] loss: 0.14882934225930108
I0804 01:33:46.125459 16480 trainer.py:139] Epoch[716/1000] loss: 0.15012104206615023
I0804 01:34:31.237149 16480 trainer.py:139] Epoch[717/1000] loss: 0.14997041119469537
I0804 01:35:16.320391 16480 trainer.py:139] Epoch[718/1000] loss: 0.1502906843688753
I0804 01:36:01.038640 16480 trainer.py:139] Epoch[719/1000] loss: 0.1498162579536438
I0804 01:36:45.923420 16480 trainer.py:139] Epoch[720/1000] loss: 0.149972289469507
I0804 01:37:30.582530 16480 trainer.py:139] Epoch[721/1000] loss: 0.15052074035008747
I0804 01:38:15.173441 16480 trainer.py:139] Epoch[722/1000] loss: 0.14880845957332187
I0804 01:38:59.830867 16480 trainer.py:139] Epoch[723/1000] loss: 0.14997761944929758
I0804 01:39:44.831031 16480 trainer.py:139] Epoch[724/1000] loss: 0.14998519440491995
I0804 01:40:29.717775 16480 trainer.py:139] Epoch[725/1000] loss: 0.1501002993186315
I0804 01:41:14.590849 16480 trainer.py:139] Epoch[726/1000] loss: 0.15072157945897843
I0804 01:41:59.524038 16480 trainer.py:139] Epoch[727/1000] loss: 0.14914365079667832
I0804 01:42:44.496719 16480 trainer.py:139] Epoch[728/1000] loss: 0.15020136064953274
I0804 01:43:28.567111 16480 trainer.py:139] Epoch[729/1000] loss: 0.15056332823303012
I0804 01:44:13.315339 16480 trainer.py:139] Epoch[730/1000] loss: 0.1496888275941213
I0804 01:44:58.211664 16480 trainer.py:139] Epoch[731/1000] loss: 0.14937602990203433
I0804 01:45:43.310806 16480 trainer.py:139] Epoch[732/1000] loss: 0.1491164469718933
I0804 01:46:28.237344 16480 trainer.py:139] Epoch[733/1000] loss: 0.14974740584691365
I0804 01:47:13.354610 16480 trainer.py:139] Epoch[734/1000] loss: 0.1495502013630337
I0804 01:47:58.017846 16480 trainer.py:139] Epoch[735/1000] loss: 0.15054066412978703
I0804 01:48:42.817385 16480 trainer.py:139] Epoch[736/1000] loss: 0.15033125188615587
I0804 01:49:27.593126 16480 trainer.py:139] Epoch[737/1000] loss: 0.1498628579907947
I0804 01:50:12.099749 16480 trainer.py:139] Epoch[738/1000] loss: 0.1498153633541531
I0804 01:50:56.991700 16480 trainer.py:139] Epoch[739/1000] loss: 0.1503695210483339
I0804 01:51:41.595623 16480 trainer.py:139] Epoch[740/1000] loss: 0.14982755925920274
I0804 01:52:26.817314 16480 trainer.py:139] Epoch[741/1000] loss: 0.14927880479229821
I0804 01:53:11.791819 16480 trainer.py:139] Epoch[742/1000] loss: 0.15005103905995687
I0804 01:53:56.981360 16480 trainer.py:139] Epoch[743/1000] loss: 0.15040910926130083
I0804 01:54:41.973201 16480 trainer.py:139] Epoch[744/1000] loss: 0.14916198425822788
I0804 01:55:27.006428 16480 trainer.py:139] Epoch[745/1000] loss: 0.14979395740562015
I0804 01:56:12.037438 16480 trainer.py:139] Epoch[746/1000] loss: 0.14953967594438128
I0804 01:56:56.295690 16480 trainer.py:139] Epoch[747/1000] loss: 0.1502663956085841
I0804 01:57:40.459561 16480 trainer.py:139] Epoch[748/1000] loss: 0.14961431953642104
I0804 01:58:25.556534 16480 trainer.py:139] Epoch[749/1000] loss: 0.14966637717352974
I0804 01:58:26.124269 16480 trainer.py:145] Test: [{'precision': 0.18898163606010016, 'recall': 0.26426136345153506, 'hit_ratio': 0.8979966611018364, 'ndcg': 0.296121800004369}]
I0804 01:59:08.564670 16480 trainer.py:139] Epoch[750/1000] loss: 0.15049867967764535
I0804 01:59:53.043344 16480 trainer.py:139] Epoch[751/1000] loss: 0.1492317541440328
I0804 02:00:38.282933 16480 trainer.py:139] Epoch[752/1000] loss: 0.1497401679886712
I0804 02:01:22.951115 16480 trainer.py:139] Epoch[753/1000] loss: 0.1496978998846478
I0804 02:02:07.834245 16480 trainer.py:139] Epoch[754/1000] loss: 0.14954911708831786
I0804 02:02:52.945065 16480 trainer.py:139] Epoch[755/1000] loss: 0.15065678510400984
I0804 02:03:37.726082 16480 trainer.py:139] Epoch[756/1000] loss: 0.1500541306204266
I0804 02:04:22.504072 16480 trainer.py:139] Epoch[757/1000] loss: 0.15088348613844976
I0804 02:05:07.408153 16480 trainer.py:139] Epoch[758/1000] loss: 0.15002805127037896
I0804 02:05:52.106444 16480 trainer.py:139] Epoch[759/1000] loss: 0.14912149714099035
I0804 02:06:36.963790 16480 trainer.py:139] Epoch[760/1000] loss: 0.14975428581237793
I0804 02:07:21.785199 16480 trainer.py:139] Epoch[761/1000] loss: 0.14924785753091177
I0804 02:08:06.458115 16480 trainer.py:139] Epoch[762/1000] loss: 0.1493340191576216
I0804 02:08:51.217459 16480 trainer.py:139] Epoch[763/1000] loss: 0.14922088788615331
I0804 02:09:36.183618 16480 trainer.py:139] Epoch[764/1000] loss: 0.1500931959019767
I0804 02:10:20.937386 16480 trainer.py:139] Epoch[765/1000] loss: 0.14955600327915616
I0804 02:11:05.596254 16480 trainer.py:139] Epoch[766/1000] loss: 0.15039092911614313
I0804 02:11:50.233777 16480 trainer.py:139] Epoch[767/1000] loss: 0.14960331466462878
I0804 02:12:35.295185 16480 trainer.py:139] Epoch[768/1000] loss: 0.1497866157690684
I0804 02:13:19.396771 16480 trainer.py:139] Epoch[769/1000] loss: 0.14952798850006527
I0804 02:14:03.132576 16480 trainer.py:139] Epoch[770/1000] loss: 0.1500810088713964
I0804 02:14:47.904115 16480 trainer.py:139] Epoch[771/1000] loss: 0.1500840661260817
I0804 02:15:32.660524 16480 trainer.py:139] Epoch[772/1000] loss: 0.15006485879421233
I0804 02:16:17.521681 16480 trainer.py:139] Epoch[773/1000] loss: 0.14975561678409577
I0804 02:17:02.374240 16480 trainer.py:139] Epoch[774/1000] loss: 0.14997868670357598
I0804 02:17:47.185036 16480 trainer.py:139] Epoch[775/1000] loss: 0.1502993236647712
I0804 02:18:31.835952 16480 trainer.py:139] Epoch[776/1000] loss: 0.15026521152920194
I0804 02:19:16.890450 16480 trainer.py:139] Epoch[777/1000] loss: 0.1501507980293698
I0804 02:20:02.036265 16480 trainer.py:139] Epoch[778/1000] loss: 0.1494292340013716
I0804 02:20:46.730779 16480 trainer.py:139] Epoch[779/1000] loss: 0.14988500462638008
I0804 02:21:31.622016 16480 trainer.py:139] Epoch[780/1000] loss: 0.15053068783548143
I0804 02:22:16.548340 16480 trainer.py:139] Epoch[781/1000] loss: 0.14970893734031254
I0804 02:23:00.306977 16480 trainer.py:139] Epoch[782/1000] loss: 0.15060663852426742
I0804 02:23:44.915745 16480 trainer.py:139] Epoch[783/1000] loss: 0.14950065851211547
I0804 02:24:30.250128 16480 trainer.py:139] Epoch[784/1000] loss: 0.14994231594933405
I0804 02:25:15.078749 16480 trainer.py:139] Epoch[785/1000] loss: 0.15003755496607887
I0804 02:26:00.298459 16480 trainer.py:139] Epoch[786/1000] loss: 0.1495154586765501
I0804 02:26:45.230736 16480 trainer.py:139] Epoch[787/1000] loss: 0.15013004422187806
I0804 02:27:30.265280 16480 trainer.py:139] Epoch[788/1000] loss: 0.1496497145957417
I0804 02:28:14.830122 16480 trainer.py:139] Epoch[789/1000] loss: 0.14970710270934634
I0804 02:28:59.629992 16480 trainer.py:139] Epoch[790/1000] loss: 0.14966593748993343
I0804 02:29:44.374570 16480 trainer.py:139] Epoch[791/1000] loss: 0.15017373932732475
I0804 02:30:29.320626 16480 trainer.py:139] Epoch[792/1000] loss: 0.15011862880653806
I0804 02:31:14.646674 16480 trainer.py:139] Epoch[793/1000] loss: 0.1499856150812573
I0804 02:31:58.663911 16480 trainer.py:139] Epoch[794/1000] loss: 0.15080851634343465
I0804 02:32:43.431343 16480 trainer.py:139] Epoch[795/1000] loss: 0.14907401853137547
I0804 02:33:27.838754 16480 trainer.py:139] Epoch[796/1000] loss: 0.15063183546066283
I0804 02:34:12.456138 16480 trainer.py:139] Epoch[797/1000] loss: 0.15029182225465776
I0804 02:34:56.878266 16480 trainer.py:139] Epoch[798/1000] loss: 0.14936466501818763
I0804 02:35:40.776935 16480 trainer.py:139] Epoch[799/1000] loss: 0.14975448151429493
I0804 02:35:41.339057 16480 trainer.py:145] Test: [{'precision': 0.18818864774624375, 'recall': 0.26354611677592926, 'hit_ratio': 0.8978297161936561, 'ndcg': 0.29463390407659346}]
I0804 02:36:25.404840 16480 trainer.py:139] Epoch[800/1000] loss: 0.14996434430281322
I0804 02:37:09.721740 16480 trainer.py:139] Epoch[801/1000] loss: 0.14979012509187062
I0804 02:37:54.534132 16480 trainer.py:139] Epoch[802/1000] loss: 0.15048213342825573
I0804 02:38:38.603026 16480 trainer.py:139] Epoch[803/1000] loss: 0.15068977501657274
I0804 02:39:22.553791 16480 trainer.py:139] Epoch[804/1000] loss: 0.14928827828831143
I0804 02:40:06.111417 16480 trainer.py:139] Epoch[805/1000] loss: 0.1494652936855952
I0804 02:40:50.704245 16480 trainer.py:139] Epoch[806/1000] loss: 0.15052178263664245
I0804 02:41:35.226625 16480 trainer.py:139] Epoch[807/1000] loss: 0.15025246567196315
I0804 02:42:19.833323 16480 trainer.py:139] Epoch[808/1000] loss: 0.1504416361782286
I0804 02:43:04.787923 16480 trainer.py:139] Epoch[809/1000] loss: 0.15058730708228218
I0804 02:43:49.769108 16480 trainer.py:139] Epoch[810/1000] loss: 0.14970529092682733
I0804 02:44:34.459867 16480 trainer.py:139] Epoch[811/1000] loss: 0.14954470349682703
I0804 02:45:19.099860 16480 trainer.py:139] Epoch[812/1000] loss: 0.14941774090131124
I0804 02:46:04.222143 16480 trainer.py:139] Epoch[813/1000] loss: 0.1500949744383494
I0804 02:46:49.007668 16480 trainer.py:139] Epoch[814/1000] loss: 0.14988608843750423
I0804 02:47:33.736577 16480 trainer.py:139] Epoch[815/1000] loss: 0.14856915851434072
I0804 02:48:18.793406 16480 trainer.py:139] Epoch[816/1000] loss: 0.14925345016850367
I0804 02:49:04.017549 16480 trainer.py:139] Epoch[817/1000] loss: 0.1498825083176295
I0804 02:49:48.950873 16480 trainer.py:139] Epoch[818/1000] loss: 0.15001787066459657
I0804 02:50:34.018197 16480 trainer.py:139] Epoch[819/1000] loss: 0.14995034628444248
I0804 02:51:18.801841 16480 trainer.py:139] Epoch[820/1000] loss: 0.1500112643175655
I0804 02:52:03.666482 16480 trainer.py:139] Epoch[821/1000] loss: 0.1496534926030371
I0804 02:52:48.414994 16480 trainer.py:139] Epoch[822/1000] loss: 0.1502249140209622
I0804 02:53:30.649551 16480 trainer.py:139] Epoch[823/1000] loss: 0.14966229061285655
I0804 02:54:14.619084 16480 trainer.py:139] Epoch[824/1000] loss: 0.15081970036029815
I0804 02:54:59.505560 16480 trainer.py:139] Epoch[825/1000] loss: 0.14994864596260918
I0804 02:55:44.268802 16480 trainer.py:139] Epoch[826/1000] loss: 0.14986643380588954
I0804 02:56:29.254604 16480 trainer.py:139] Epoch[827/1000] loss: 0.1510533015595542
I0804 02:57:14.144205 16480 trainer.py:139] Epoch[828/1000] loss: 0.14951295259926053
I0804 02:57:58.841485 16480 trainer.py:139] Epoch[829/1000] loss: 0.1502515470981598
I0804 02:58:43.563005 16480 trainer.py:139] Epoch[830/1000] loss: 0.1493543384472529
I0804 02:59:28.615186 16480 trainer.py:139] Epoch[831/1000] loss: 0.14995626449584962
I0804 03:00:13.566488 16480 trainer.py:139] Epoch[832/1000] loss: 0.15035640623834398
I0804 03:00:58.250508 16480 trainer.py:139] Epoch[833/1000] loss: 0.1505377287334866
I0804 03:01:43.357536 16480 trainer.py:139] Epoch[834/1000] loss: 0.14971769743495517
I0804 03:02:28.114048 16480 trainer.py:139] Epoch[835/1000] loss: 0.1504759852753745
I0804 03:03:12.962638 16480 trainer.py:139] Epoch[836/1000] loss: 0.14913969933986665
I0804 03:03:58.017561 16480 trainer.py:139] Epoch[837/1000] loss: 0.1502635517385271
I0804 03:04:43.105998 16480 trainer.py:139] Epoch[838/1000] loss: 0.1506186909808053
I0804 03:05:27.883793 16480 trainer.py:139] Epoch[839/1000] loss: 0.15027890615993075
I0804 03:06:12.971485 16480 trainer.py:139] Epoch[840/1000] loss: 0.15020750410026973
I0804 03:06:57.911171 16480 trainer.py:139] Epoch[841/1000] loss: 0.1492171087529924
I0804 03:07:42.087865 16480 trainer.py:139] Epoch[842/1000] loss: 0.15049331863721213
I0804 03:08:26.640454 16480 trainer.py:139] Epoch[843/1000] loss: 0.14913920025030772
I0804 03:09:06.373201 16480 trainer.py:139] Epoch[844/1000] loss: 0.14934681912263234
I0804 03:09:51.270231 16480 trainer.py:139] Epoch[845/1000] loss: 0.1501950020260281
I0804 03:10:36.083756 16480 trainer.py:139] Epoch[846/1000] loss: 0.15053231146600513
I0804 03:11:21.099368 16480 trainer.py:139] Epoch[847/1000] loss: 0.15013359202278984
I0804 03:12:05.710201 16480 trainer.py:139] Epoch[848/1000] loss: 0.1520868823925654
I0804 03:12:50.476665 16480 trainer.py:139] Epoch[849/1000] loss: 0.1503347584936354
I0804 03:12:51.085627 16480 trainer.py:145] Test: [{'precision': 0.1881218697829716, 'recall': 0.2638299725488327, 'hit_ratio': 0.8979966611018364, 'ndcg': 0.29513734914565065}]
I0804 03:13:35.773816 16480 trainer.py:139] Epoch[850/1000] loss: 0.14978429681724972
I0804 03:14:20.550682 16480 trainer.py:139] Epoch[851/1000] loss: 0.14956979155540467
I0804 03:15:04.119137 16480 trainer.py:139] Epoch[852/1000] loss: 0.149789464407497
I0804 03:15:48.793824 16480 trainer.py:139] Epoch[853/1000] loss: 0.14936211751566994
I0804 03:16:33.843519 16480 trainer.py:139] Epoch[854/1000] loss: 0.15007841342025333
I0804 03:17:18.684336 16480 trainer.py:139] Epoch[855/1000] loss: 0.14894879046413634
I0804 03:18:03.472410 16480 trainer.py:139] Epoch[856/1000] loss: 0.1495610202683343
I0804 03:18:48.030302 16480 trainer.py:139] Epoch[857/1000] loss: 0.15011504848798116
I0804 03:19:32.868343 16480 trainer.py:139] Epoch[858/1000] loss: 0.14968099809355206
I0804 03:20:17.805914 16480 trainer.py:139] Epoch[859/1000] loss: 0.14975887530379825
I0804 03:21:02.558808 16480 trainer.py:139] Epoch[860/1000] loss: 0.14982877446545495
I0804 03:21:47.553738 16480 trainer.py:139] Epoch[861/1000] loss: 0.149709086616834
I0804 03:22:32.227468 16480 trainer.py:139] Epoch[862/1000] loss: 0.14937474992540148
I0804 03:23:16.890480 16480 trainer.py:139] Epoch[863/1000] loss: 0.15038976165983411
I0804 03:24:01.795676 16480 trainer.py:139] Epoch[864/1000] loss: 0.14921325412061479
I0804 03:24:46.631430 16480 trainer.py:139] Epoch[865/1000] loss: 0.15033998476134405
I0804 03:25:31.581479 16480 trainer.py:139] Epoch[866/1000] loss: 0.1497631714741389
I0804 03:26:16.482653 16480 trainer.py:139] Epoch[867/1000] loss: 0.15047068271372052
I0804 03:27:01.152604 16480 trainer.py:139] Epoch[868/1000] loss: 0.15001744879616632
I0804 03:27:45.997743 16480 trainer.py:139] Epoch[869/1000] loss: 0.15030989872084724
I0804 03:28:30.499472 16480 trainer.py:139] Epoch[870/1000] loss: 0.14987912548912896
I0804 03:29:15.436740 16480 trainer.py:139] Epoch[871/1000] loss: 0.1505602812104755
I0804 03:30:00.376354 16480 trainer.py:139] Epoch[872/1000] loss: 0.15085624575614928
I0804 03:30:45.319934 16480 trainer.py:139] Epoch[873/1000] loss: 0.14980322195423973
I0804 03:31:30.335960 16480 trainer.py:139] Epoch[874/1000] loss: 0.1492470904853609
I0804 03:32:15.488388 16480 trainer.py:139] Epoch[875/1000] loss: 0.1513777310318417
I0804 03:33:00.229091 16480 trainer.py:139] Epoch[876/1000] loss: 0.14968266248703002
I0804 03:33:44.282724 16480 trainer.py:139] Epoch[877/1000] loss: 0.149973353544871
I0804 03:34:26.927274 16480 trainer.py:139] Epoch[878/1000] loss: 0.14899958411852518
I0804 03:35:08.645755 16480 trainer.py:139] Epoch[879/1000] loss: 0.14954807758331298
I0804 03:35:52.760722 16480 trainer.py:139] Epoch[880/1000] loss: 0.14999907559818693
I0804 03:36:37.102135 16480 trainer.py:139] Epoch[881/1000] loss: 0.15056623074743483
I0804 03:37:21.855221 16480 trainer.py:139] Epoch[882/1000] loss: 0.15038093321853213
I0804 03:38:06.563663 16480 trainer.py:139] Epoch[883/1000] loss: 0.1492177567217085
I0804 03:38:51.084644 16480 trainer.py:139] Epoch[884/1000] loss: 0.15006213042471145
I0804 03:39:36.153362 16480 trainer.py:139] Epoch[885/1000] loss: 0.14938910838630465
I0804 03:40:20.689051 16480 trainer.py:139] Epoch[886/1000] loss: 0.14988799035549163
I0804 03:41:02.664414 16480 trainer.py:139] Epoch[887/1000] loss: 0.14999263405799865
I0804 03:41:46.365455 16480 trainer.py:139] Epoch[888/1000] loss: 0.1499174733294381
I0804 03:42:31.044761 16480 trainer.py:139] Epoch[889/1000] loss: 0.14923108445273506
I0804 03:43:16.039067 16480 trainer.py:139] Epoch[890/1000] loss: 0.15020039525296952
I0804 03:44:00.110871 16480 trainer.py:139] Epoch[891/1000] loss: 0.1495832688940896
I0804 03:44:44.989348 16480 trainer.py:139] Epoch[892/1000] loss: 0.15030775679482353
I0804 03:45:29.780606 16480 trainer.py:139] Epoch[893/1000] loss: 0.15028553747468523
I0804 03:46:14.469209 16480 trainer.py:139] Epoch[894/1000] loss: 0.1485559473435084
I0804 03:46:59.340264 16480 trainer.py:139] Epoch[895/1000] loss: 0.14957798219389384
I0804 03:47:43.869852 16480 trainer.py:139] Epoch[896/1000] loss: 0.15042294078403048
I0804 03:48:28.470485 16480 trainer.py:139] Epoch[897/1000] loss: 0.14900724358028836
I0804 03:49:13.481639 16480 trainer.py:139] Epoch[898/1000] loss: 0.1507301856411828
I0804 03:49:58.068502 16480 trainer.py:139] Epoch[899/1000] loss: 0.15041619804170397
I0804 03:49:58.638120 16480 trainer.py:145] Test: [{'precision': 0.18904841402337222, 'recall': 0.265180802670728, 'hit_ratio': 0.8991652754590985, 'ndcg': 0.2960183520882406}]
I0804 03:50:42.818947 16480 trainer.py:139] Epoch[900/1000] loss: 0.15037991106510162
I0804 03:51:27.524571 16480 trainer.py:139] Epoch[901/1000] loss: 0.14969636526372698
I0804 03:52:12.383880 16480 trainer.py:139] Epoch[902/1000] loss: 0.14885969479878744
I0804 03:52:56.894718 16480 trainer.py:139] Epoch[903/1000] loss: 0.1493865797917048
I0804 03:53:41.629304 16480 trainer.py:139] Epoch[904/1000] loss: 0.14967019432120854
I0804 03:54:26.341808 16480 trainer.py:139] Epoch[905/1000] loss: 0.15033272365729014
I0804 03:55:11.008183 16480 trainer.py:139] Epoch[906/1000] loss: 0.15008466164271037
I0804 03:55:55.861669 16480 trainer.py:139] Epoch[907/1000] loss: 0.14891655842463175
I0804 03:56:39.959245 16480 trainer.py:139] Epoch[908/1000] loss: 0.14908324903912015
I0804 03:57:23.103865 16480 trainer.py:139] Epoch[909/1000] loss: 0.1494707265165117
I0804 03:58:08.124107 16480 trainer.py:139] Epoch[910/1000] loss: 0.14875407245424058
I0804 03:58:50.130054 16480 trainer.py:139] Epoch[911/1000] loss: 0.1495702189869351
I0804 03:59:32.473426 16480 trainer.py:139] Epoch[912/1000] loss: 0.14943989323245155
I0804 04:00:17.224006 16480 trainer.py:139] Epoch[913/1000] loss: 0.1495092491308848
I0804 04:01:01.327067 16480 trainer.py:139] Epoch[914/1000] loss: 0.14913743654886882
I0804 04:01:46.182950 16480 trainer.py:139] Epoch[915/1000] loss: 0.1490456606282128
I0804 04:02:31.123234 16480 trainer.py:139] Epoch[916/1000] loss: 0.1501802693472968
I0804 04:03:15.692109 16480 trainer.py:139] Epoch[917/1000] loss: 0.14982018556859758
I0804 04:04:00.642869 16480 trainer.py:139] Epoch[918/1000] loss: 0.1504223116238912
I0804 04:04:45.435104 16480 trainer.py:139] Epoch[919/1000] loss: 0.14993437945842744
I0804 04:05:30.307820 16480 trainer.py:139] Epoch[920/1000] loss: 0.1493912645843294
I0804 04:06:15.198621 16480 trainer.py:139] Epoch[921/1000] loss: 0.14917095833354527
I0804 04:07:00.254705 16480 trainer.py:139] Epoch[922/1000] loss: 0.14955400440427993
I0804 04:07:44.949513 16480 trainer.py:139] Epoch[923/1000] loss: 0.15017752726872763
I0804 04:08:29.616216 16480 trainer.py:139] Epoch[924/1000] loss: 0.14941743969917298
I0804 04:09:12.284790 16480 trainer.py:139] Epoch[925/1000] loss: 0.1504340076446533
I0804 04:09:55.822446 16480 trainer.py:139] Epoch[926/1000] loss: 0.14994563659032187
I0804 04:10:40.393886 16480 trainer.py:139] Epoch[927/1000] loss: 0.1489997023675177
I0804 04:11:24.755232 16480 trainer.py:139] Epoch[928/1000] loss: 0.14926501505904727
I0804 04:12:09.475269 16480 trainer.py:139] Epoch[929/1000] loss: 0.1499264904525545
I0804 04:12:54.297648 16480 trainer.py:139] Epoch[930/1000] loss: 0.15034840040736727
I0804 04:13:39.281328 16480 trainer.py:139] Epoch[931/1000] loss: 0.14940444197919633
I0804 04:14:23.992777 16480 trainer.py:139] Epoch[932/1000] loss: 0.15081251654360028
I0804 04:15:07.374104 16480 trainer.py:139] Epoch[933/1000] loss: 0.1493104076385498
I0804 04:15:52.082648 16480 trainer.py:139] Epoch[934/1000] loss: 0.1502815000216166
I0804 04:16:36.849122 16480 trainer.py:139] Epoch[935/1000] loss: 0.149630323515998
I0804 04:17:21.757723 16480 trainer.py:139] Epoch[936/1000] loss: 0.1499427068895764
I0804 04:18:06.809188 16480 trainer.py:139] Epoch[937/1000] loss: 0.15012266278266906
I0804 04:18:51.692217 16480 trainer.py:139] Epoch[938/1000] loss: 0.1494567640622457
I0804 04:19:36.650596 16480 trainer.py:139] Epoch[939/1000] loss: 0.149767654604382
I0804 04:20:21.624278 16480 trainer.py:139] Epoch[940/1000] loss: 0.14967883030573528
I0804 04:21:06.492178 16480 trainer.py:139] Epoch[941/1000] loss: 0.14964719275633495
I0804 04:21:51.457274 16480 trainer.py:139] Epoch[942/1000] loss: 0.14850692325168185
I0804 04:22:36.121485 16480 trainer.py:139] Epoch[943/1000] loss: 0.14957288205623626
I0804 04:23:20.045696 16480 trainer.py:139] Epoch[944/1000] loss: 0.15023495945665571
I0804 04:24:05.055372 16480 trainer.py:139] Epoch[945/1000] loss: 0.14998563057846492
I0804 04:24:49.882547 16480 trainer.py:139] Epoch[946/1000] loss: 0.1492959361606174
I0804 04:25:34.569255 16480 trainer.py:139] Epoch[947/1000] loss: 0.14959243026044633
I0804 04:26:19.455477 16480 trainer.py:139] Epoch[948/1000] loss: 0.14882303456465404
I0804 04:27:03.462478 16480 trainer.py:139] Epoch[949/1000] loss: 0.14943344798352984
I0804 04:27:04.022604 16480 trainer.py:145] Test: [{'precision': 0.1884223706176962, 'recall': 0.2640724297634867, 'hit_ratio': 0.8986644407345576, 'ndcg': 0.29563125961172193}]
I0804 04:27:48.687730 16480 trainer.py:139] Epoch[950/1000] loss: 0.15003941867086623
I0804 04:28:33.355514 16480 trainer.py:139] Epoch[951/1000] loss: 0.14928878605365753
I0804 04:29:17.193954 16480 trainer.py:139] Epoch[952/1000] loss: 0.15018168303701612
I0804 04:30:00.407740 16480 trainer.py:139] Epoch[953/1000] loss: 0.15083080252011616
I0804 04:30:44.717784 16480 trainer.py:139] Epoch[954/1000] loss: 0.14882889449596404
I0804 04:31:29.088095 16480 trainer.py:139] Epoch[955/1000] loss: 0.15055318196614584
I0804 04:32:13.637225 16480 trainer.py:139] Epoch[956/1000] loss: 0.1489968356821272
I0804 04:32:58.223353 16480 trainer.py:139] Epoch[957/1000] loss: 0.14973354756832122
I0804 04:33:43.110185 16480 trainer.py:139] Epoch[958/1000] loss: 0.1490362399816513
I0804 04:34:27.841878 16480 trainer.py:139] Epoch[959/1000] loss: 0.1497753863864475
I0804 04:35:12.465872 16480 trainer.py:139] Epoch[960/1000] loss: 0.1500296785434087
I0804 04:35:57.394568 16480 trainer.py:139] Epoch[961/1000] loss: 0.1504379117488861
I0804 04:36:42.405444 16480 trainer.py:139] Epoch[962/1000] loss: 0.1501564857694838
I0804 04:37:27.100726 16480 trainer.py:139] Epoch[963/1000] loss: 0.14960533996423087
I0804 04:38:12.085638 16480 trainer.py:139] Epoch[964/1000] loss: 0.14913543860117595
I0804 04:38:56.988540 16480 trainer.py:139] Epoch[965/1000] loss: 0.14983776026301915
I0804 04:39:42.178927 16480 trainer.py:139] Epoch[966/1000] loss: 0.15025214632352193
I0804 04:40:26.912332 16480 trainer.py:139] Epoch[967/1000] loss: 0.1484374240371916
I0804 04:41:11.717986 16480 trainer.py:139] Epoch[968/1000] loss: 0.15040996809800466
I0804 04:41:56.563170 16480 trainer.py:139] Epoch[969/1000] loss: 0.14986401862568324
I0804 04:42:41.339948 16480 trainer.py:139] Epoch[970/1000] loss: 0.14951658689313466
I0804 04:43:26.269872 16480 trainer.py:139] Epoch[971/1000] loss: 0.15031069768799676
I0804 04:44:10.796698 16480 trainer.py:139] Epoch[972/1000] loss: 0.1492586534553104
I0804 04:44:55.486124 16480 trainer.py:139] Epoch[973/1000] loss: 0.1493929237789578
I0804 04:45:39.641444 16480 trainer.py:139] Epoch[974/1000] loss: 0.15083557632234362
I0804 04:46:24.688502 16480 trainer.py:139] Epoch[975/1000] loss: 0.14899462792608473
I0804 04:47:09.497809 16480 trainer.py:139] Epoch[976/1000] loss: 0.14889035085837046
I0804 04:47:54.596523 16480 trainer.py:139] Epoch[977/1000] loss: 0.14929610106680127
I0804 04:48:39.779182 16480 trainer.py:139] Epoch[978/1000] loss: 0.14915736880567337
I0804 04:49:24.973002 16480 trainer.py:139] Epoch[979/1000] loss: 0.14991048528088463
I0804 04:50:09.476923 16480 trainer.py:139] Epoch[980/1000] loss: 0.1498734117878808
I0804 04:50:53.751300 16480 trainer.py:139] Epoch[981/1000] loss: 0.15020116680198245
I0804 04:51:37.861227 16480 trainer.py:139] Epoch[982/1000] loss: 0.14961876875824398
I0804 04:52:22.816557 16480 trainer.py:139] Epoch[983/1000] loss: 0.14993216706646814
I0804 04:53:07.817903 16480 trainer.py:139] Epoch[984/1000] loss: 0.14968722568617926
I0804 04:53:52.587062 16480 trainer.py:139] Epoch[985/1000] loss: 0.14979348070091672
I0804 04:54:37.362562 16480 trainer.py:139] Epoch[986/1000] loss: 0.1500855294201109
I0804 04:55:21.921715 16480 trainer.py:139] Epoch[987/1000] loss: 0.1496106465657552
I0804 04:56:06.015526 16480 trainer.py:139] Epoch[988/1000] loss: 0.15042469494872623
I0804 04:56:50.768910 16480 trainer.py:139] Epoch[989/1000] loss: 0.15044173604912228
I0804 04:57:34.661267 16480 trainer.py:139] Epoch[990/1000] loss: 0.1487735785047213
I0804 04:58:19.387847 16480 trainer.py:139] Epoch[991/1000] loss: 0.15033429967032538
I0804 04:59:04.054704 16480 trainer.py:139] Epoch[992/1000] loss: 0.149467457930247
I0804 04:59:48.607820 16480 trainer.py:139] Epoch[993/1000] loss: 0.14956049197249943
I0804 05:00:33.644811 16480 trainer.py:139] Epoch[994/1000] loss: 0.15032502379682328
I0804 05:01:18.231470 16480 trainer.py:139] Epoch[995/1000] loss: 0.1495516888300578
I0804 05:02:03.141185 16480 trainer.py:139] Epoch[996/1000] loss: 0.1496857503387663
I0804 05:02:47.793613 16480 trainer.py:139] Epoch[997/1000] loss: 0.14985743317339156
I0804 05:03:31.552310 16480 trainer.py:139] Epoch[998/1000] loss: 0.14969215889771778
I0804 05:04:15.990677 16480 trainer.py:139] Epoch[999/1000] loss: 0.15024054070313772
I0804 05:04:16.586231 16480 trainer.py:145] Test: [{'precision': 0.1888313856427379, 'recall': 0.26381025436609423, 'hit_ratio': 0.8991652754590985, 'ndcg': 0.2956805395597425}]
