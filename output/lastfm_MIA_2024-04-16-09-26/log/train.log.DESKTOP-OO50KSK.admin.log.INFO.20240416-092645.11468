I0416 09:26:47.406746 27328 trainer.py:121] Test: {'precision': 0.002064343163538874, 'recall': 0.005229869177590357, 'hit_ratio': 0.039142091152815014, 'ndcg': 0.0032998394241306565}
I0416 09:26:50.136614 27328 trainer.py:139] Epoch[0/1000] loss: 0.6906476193858732
I0416 09:26:52.791733 27328 trainer.py:139] Epoch[1/1000] loss: 0.679910998190603
I0416 09:26:55.666115 27328 trainer.py:139] Epoch[2/1000] loss: 0.6429301750275397
I0416 09:26:58.490665 27328 trainer.py:139] Epoch[3/1000] loss: 0.5801548400232869
I0416 09:27:01.152761 27328 trainer.py:139] Epoch[4/1000] loss: 0.5151023345608865
I0416 09:27:03.902560 27328 trainer.py:139] Epoch[5/1000] loss: 0.46367983471962715
I0416 09:27:06.522795 27328 trainer.py:139] Epoch[6/1000] loss: 0.42565257703104326
I0416 09:27:09.454987 27328 trainer.py:139] Epoch[7/1000] loss: 0.39481079001580516
I0416 09:27:12.139006 27328 trainer.py:139] Epoch[8/1000] loss: 0.3742339216893719
I0416 09:27:14.889804 27328 trainer.py:139] Epoch[9/1000] loss: 0.35431201131113116
I0416 09:27:17.514024 27328 trainer.py:139] Epoch[10/1000] loss: 0.33619101201334306
I0416 09:27:20.288743 27328 trainer.py:139] Epoch[11/1000] loss: 0.32634947376866497
I0416 09:27:23.085386 27328 trainer.py:139] Epoch[12/1000] loss: 0.3100856561814585
I0416 09:27:25.726551 27328 trainer.py:139] Epoch[13/1000] loss: 0.3032827954138479
I0416 09:27:28.364724 27328 trainer.py:139] Epoch[14/1000] loss: 0.2919008597250908
I0416 09:27:30.921172 27328 trainer.py:139] Epoch[15/1000] loss: 0.2826372413865982
I0416 09:27:33.552370 27328 trainer.py:139] Epoch[16/1000] loss: 0.27641616905889205
I0416 09:27:36.225428 27328 trainer.py:139] Epoch[17/1000] loss: 0.27010683667275215
I0416 09:27:39.085858 27328 trainer.py:139] Epoch[18/1000] loss: 0.2640908100912648
I0416 09:27:41.781875 27328 trainer.py:139] Epoch[19/1000] loss: 0.2547274275172141
I0416 09:27:44.359253 27328 trainer.py:139] Epoch[20/1000] loss: 0.2536518391101591
I0416 09:27:47.031313 27328 trainer.py:139] Epoch[21/1000] loss: 0.24525893840097612
I0416 09:27:49.695401 27328 trainer.py:139] Epoch[22/1000] loss: 0.24434287749951886
I0416 09:27:52.424271 27328 trainer.py:139] Epoch[23/1000] loss: 0.23625788188749744
I0416 09:27:55.224902 27328 trainer.py:139] Epoch[24/1000] loss: 0.23283418003589876
I0416 09:27:58.396292 27328 trainer.py:139] Epoch[25/1000] loss: 0.2293865805672061
I0416 09:28:01.390276 27328 trainer.py:139] Epoch[26/1000] loss: 0.22758823537057446
I0416 09:28:04.556684 27328 trainer.py:139] Epoch[27/1000] loss: 0.22315317680758814
I0416 09:28:07.679239 27328 trainer.py:139] Epoch[28/1000] loss: 0.21965619200660336
I0416 09:28:10.782854 27328 trainer.py:139] Epoch[29/1000] loss: 0.21426362087649684
I0416 09:28:14.126668 27328 trainer.py:139] Epoch[30/1000] loss: 0.21185958721945364
I0416 09:28:17.394736 27328 trainer.py:139] Epoch[31/1000] loss: 0.2050331792523784
I0416 09:28:20.498352 27328 trainer.py:139] Epoch[32/1000] loss: 0.20707868904836715
I0416 09:28:23.649809 27328 trainer.py:139] Epoch[33/1000] loss: 0.2045706308657123
I0416 09:28:26.710570 27328 trainer.py:139] Epoch[34/1000] loss: 0.20406133753638114
I0416 09:28:29.939766 27328 trainer.py:139] Epoch[35/1000] loss: 0.19938007862337173
I0416 09:28:32.981590 27328 trainer.py:139] Epoch[36/1000] loss: 0.19354154842515145
I0416 09:28:36.087201 27328 trainer.py:139] Epoch[37/1000] loss: 0.19354598416436103
I0416 09:28:39.020388 27328 trainer.py:139] Epoch[38/1000] loss: 0.19054092707172518
I0416 09:28:41.950586 27328 trainer.py:139] Epoch[39/1000] loss: 0.186469990399576
I0416 09:28:45.069153 27328 trainer.py:139] Epoch[40/1000] loss: 0.18632459255956835
I0416 09:28:48.098021 27328 trainer.py:139] Epoch[41/1000] loss: 0.18586653134515208
I0416 09:28:51.202633 27328 trainer.py:139] Epoch[42/1000] loss: 0.1847453482689396
I0416 09:28:54.222531 27328 trainer.py:139] Epoch[43/1000] loss: 0.18363416146847508
I0416 09:28:57.319171 27328 trainer.py:139] Epoch[44/1000] loss: 0.18035581707954407
I0416 09:29:00.388901 27328 trainer.py:139] Epoch[45/1000] loss: 0.18144973679896323
I0416 09:29:03.399828 27328 trainer.py:139] Epoch[46/1000] loss: 0.1780194789171219
I0416 09:29:06.447632 27328 trainer.py:139] Epoch[47/1000] loss: 0.17668043846084225
I0416 09:29:09.470519 27328 trainer.py:139] Epoch[48/1000] loss: 0.17309442883537662
I0416 09:29:12.570150 27328 trainer.py:139] Epoch[49/1000] loss: 0.171651927213515
I0416 09:29:12.777457 27328 trainer.py:145] Test: {'precision': 0.11198391420911537, 'recall': 0.2614617099769285, 'hit_ratio': 0.8262734584450402, 'ndcg': 0.24794914429813636}
I0416 09:29:16.047517 27328 trainer.py:139] Epoch[50/1000] loss: 0.16891181324758836
I0416 09:29:19.141168 27328 trainer.py:139] Epoch[51/1000] loss: 0.16875639750111487
I0416 09:29:22.166048 27328 trainer.py:139] Epoch[52/1000] loss: 0.16834799128194008
I0416 09:29:25.185947 27328 trainer.py:139] Epoch[53/1000] loss: 0.16398799707812647
I0416 09:29:28.231755 27328 trainer.py:139] Epoch[54/1000] loss: 0.16465094397144933
I0416 09:29:31.223746 27328 trainer.py:139] Epoch[55/1000] loss: 0.16175966012862422
I0416 09:29:34.317396 27328 trainer.py:139] Epoch[56/1000] loss: 0.16097035234974277
I0416 09:29:37.474833 27328 trainer.py:139] Epoch[57/1000] loss: 0.16210178838622186
I0416 09:29:40.543568 27328 trainer.py:139] Epoch[58/1000] loss: 0.1601669399007674
I0416 09:29:43.611304 27328 trainer.py:139] Epoch[59/1000] loss: 0.15975666959439555
I0416 09:29:46.661101 27328 trainer.py:139] Epoch[60/1000] loss: 0.15610284814911504
I0416 09:29:49.768705 27328 trainer.py:139] Epoch[61/1000] loss: 0.1586640227225519
I0416 09:29:52.919166 27328 trainer.py:139] Epoch[62/1000] loss: 0.15387403195904148
I0416 09:29:56.113479 27328 trainer.py:139] Epoch[63/1000] loss: 0.1533458170390898
I0416 09:29:59.571909 27328 trainer.py:139] Epoch[64/1000] loss: 0.15385129711320322
I0416 09:30:02.839977 27328 trainer.py:139] Epoch[65/1000] loss: 0.1491107560934559
I0416 09:30:06.111034 27328 trainer.py:139] Epoch[66/1000] loss: 0.15040687159184488
I0416 09:30:09.389067 27328 trainer.py:139] Epoch[67/1000] loss: 0.15038069409708824
I0416 09:30:12.689027 27328 trainer.py:139] Epoch[68/1000] loss: 0.14757663876779617
I0416 09:30:15.760751 27328 trainer.py:139] Epoch[69/1000] loss: 0.14648292910668156
I0416 09:30:18.909218 27328 trainer.py:139] Epoch[70/1000] loss: 0.1454888351501957
I0416 09:30:21.925129 27328 trainer.py:139] Epoch[71/1000] loss: 0.1439914535130224
I0416 09:30:24.864297 27328 trainer.py:139] Epoch[72/1000] loss: 0.1443450152873993
I0416 09:30:27.938013 27328 trainer.py:139] Epoch[73/1000] loss: 0.14259030982371299
I0416 09:30:31.110400 27328 trainer.py:139] Epoch[74/1000] loss: 0.14040560491623416
I0416 09:30:34.219001 27328 trainer.py:139] Epoch[75/1000] loss: 0.14117255398342687
I0416 09:30:37.625604 27328 trainer.py:139] Epoch[76/1000] loss: 0.13899210143473842
I0416 09:30:40.953471 27328 trainer.py:139] Epoch[77/1000] loss: 0.14086972417369967
I0416 09:30:44.569374 27328 trainer.py:139] Epoch[78/1000] loss: 0.13818870869375044
I0416 09:30:48.060694 27328 trainer.py:139] Epoch[79/1000] loss: 0.13812140038897913
I0416 09:30:51.517132 27328 trainer.py:139] Epoch[80/1000] loss: 0.13554065722611644
I0416 09:30:54.914765 27328 trainer.py:139] Epoch[81/1000] loss: 0.13751145308056184
I0416 09:30:58.556581 27328 trainer.py:139] Epoch[82/1000] loss: 0.1361402354894146
I0416 09:31:01.951225 27328 trainer.py:139] Epoch[83/1000] loss: 0.13471900671720505
I0416 09:31:05.371782 27328 trainer.py:139] Epoch[84/1000] loss: 0.13455881995539512
I0416 09:31:08.906955 27328 trainer.py:139] Epoch[85/1000] loss: 0.13265919517124852
I0416 09:31:12.255752 27328 trainer.py:139] Epoch[86/1000] loss: 0.1326892827787707
I0416 09:31:15.607539 27328 trainer.py:139] Epoch[87/1000] loss: 0.13218909886575514
I0416 09:31:19.113809 27328 trainer.py:139] Epoch[88/1000] loss: 0.13241927205554901
I0416 09:31:22.392839 27328 trainer.py:139] Epoch[89/1000] loss: 0.13118335845008974
I0416 09:31:25.728680 27328 trainer.py:139] Epoch[90/1000] loss: 0.130771086821633
I0416 09:31:29.409366 27328 trainer.py:139] Epoch[91/1000] loss: 0.12934249038657836
I0416 09:31:33.182743 27328 trainer.py:139] Epoch[92/1000] loss: 0.12889293196701235
I0416 09:31:36.790672 27328 trainer.py:139] Epoch[93/1000] loss: 0.12952779569933492
I0416 09:31:40.466375 27328 trainer.py:139] Epoch[94/1000] loss: 0.1261577630235303
I0416 09:31:44.145070 27328 trainer.py:139] Epoch[95/1000] loss: 0.1269456804279358
I0416 09:31:47.857648 27328 trainer.py:139] Epoch[96/1000] loss: 0.1256497346105114
I0416 09:31:51.433686 27328 trainer.py:139] Epoch[97/1000] loss: 0.1277700263646341
I0416 09:31:55.297758 27328 trainer.py:139] Epoch[98/1000] loss: 0.12253565293165945
I0416 09:31:59.032265 27328 trainer.py:139] Epoch[99/1000] loss: 0.12370200863768978
I0416 09:31:59.331265 27328 trainer.py:145] Test: {'precision': 0.1218230563002682, 'recall': 0.2866534749222812, 'hit_ratio': 0.8595174262734584, 'ndcg': 0.2699531465829552}
I0416 09:32:03.008961 27328 trainer.py:139] Epoch[100/1000] loss: 0.1240219896839511
I0416 09:32:06.799284 27328 trainer.py:139] Epoch[101/1000] loss: 0.12196128863480783
I0416 09:32:10.461031 27328 trainer.py:139] Epoch[102/1000] loss: 0.12159014829704838
I0416 09:32:14.173611 27328 trainer.py:139] Epoch[103/1000] loss: 0.1200588271021843
I0416 09:32:17.920077 27328 trainer.py:139] Epoch[104/1000] loss: 0.12104334273645954
I0416 09:32:21.597774 27328 trainer.py:139] Epoch[105/1000] loss: 0.12123067220372538
I0416 09:32:25.334273 27328 trainer.py:139] Epoch[106/1000] loss: 0.11804345081890782
I0416 09:32:28.936224 27328 trainer.py:139] Epoch[107/1000] loss: 0.12032953048906019
I0416 09:32:32.660764 27328 trainer.py:139] Epoch[108/1000] loss: 0.12021185313501666
I0416 09:32:36.472013 27328 trainer.py:139] Epoch[109/1000] loss: 0.11960566452433986
I0416 09:32:40.324126 27328 trainer.py:139] Epoch[110/1000] loss: 0.1166789791276378
I0416 09:32:44.237037 27328 trainer.py:139] Epoch[111/1000] loss: 0.11763724059827867
I0416 09:32:47.708423 27328 trainer.py:139] Epoch[112/1000] loss: 0.1158054088873248
I0416 09:32:51.367183 27328 trainer.py:139] Epoch[113/1000] loss: 0.11777355233507772
I0416 09:32:55.033916 27328 trainer.py:139] Epoch[114/1000] loss: 0.11435285354814222
I0416 09:32:58.998652 27328 trainer.py:139] Epoch[115/1000] loss: 0.11494163976561639
I0416 09:33:02.891629 27328 trainer.py:139] Epoch[116/1000] loss: 0.11591437555128528
I0416 09:33:06.580289 27328 trainer.py:139] Epoch[117/1000] loss: 0.1141050385852014
I0416 09:33:10.337719 27328 trainer.py:139] Epoch[118/1000] loss: 0.11514884858362136
I0416 09:33:14.122058 27328 trainer.py:139] Epoch[119/1000] loss: 0.11231673028199904
I0416 09:33:17.982144 27328 trainer.py:139] Epoch[120/1000] loss: 0.11249043816520322
I0416 09:33:21.840238 27328 trainer.py:139] Epoch[121/1000] loss: 0.11092009443429209
I0416 09:33:25.640524 27328 trainer.py:139] Epoch[122/1000] loss: 0.11266780812894145
I0416 09:33:29.342141 27328 trainer.py:139] Epoch[123/1000] loss: 0.11277223330351614
I0416 09:33:33.062694 27328 trainer.py:139] Epoch[124/1000] loss: 0.11240598006594565
I0416 09:33:36.893877 27328 trainer.py:139] Epoch[125/1000] loss: 0.10785380486519106
I0416 09:33:40.570578 27328 trainer.py:139] Epoch[126/1000] loss: 0.1085161920036039
I0416 09:33:44.221363 27328 trainer.py:139] Epoch[127/1000] loss: 0.10972448029825764
I0416 09:33:47.923977 27328 trainer.py:139] Epoch[128/1000] loss: 0.11004845798015594
I0416 09:33:51.761141 27328 trainer.py:139] Epoch[129/1000] loss: 0.10732361313796812
I0416 09:33:55.488670 27328 trainer.py:139] Epoch[130/1000] loss: 0.10908774719122917
I0416 09:33:59.116533 27328 trainer.py:139] Epoch[131/1000] loss: 0.10624677928224686
I0416 09:34:02.742403 27328 trainer.py:139] Epoch[132/1000] loss: 0.10586016745336595
I0416 09:34:06.450996 27328 trainer.py:139] Epoch[133/1000] loss: 0.10544672199795323
I0416 09:34:10.018063 27328 trainer.py:139] Epoch[134/1000] loss: 0.10742874155121465
I0416 09:34:13.587123 27328 trainer.py:139] Epoch[135/1000] loss: 0.10853791837730715
I0416 09:34:17.245883 27328 trainer.py:139] Epoch[136/1000] loss: 0.10600351398029635
I0416 09:34:21.124906 27328 trainer.py:139] Epoch[137/1000] loss: 0.10438905031450334
I0416 09:34:24.852436 27328 trainer.py:139] Epoch[138/1000] loss: 0.10458078091183017
I0416 09:34:28.789265 27328 trainer.py:139] Epoch[139/1000] loss: 0.10352154941328111
I0416 09:34:32.390218 27328 trainer.py:139] Epoch[140/1000] loss: 0.10439566763177995
I0416 09:34:36.022068 27328 trainer.py:139] Epoch[141/1000] loss: 0.10373666930583215
I0416 09:34:39.651926 27328 trainer.py:139] Epoch[142/1000] loss: 0.10213433037842473
I0416 09:34:43.299722 27328 trainer.py:139] Epoch[143/1000] loss: 0.1029362853976988
I0416 09:34:46.930575 27328 trainer.py:139] Epoch[144/1000] loss: 0.10209374394147627
I0416 09:34:50.681028 27328 trainer.py:139] Epoch[145/1000] loss: 0.1015624524124207
I0416 09:34:54.389621 27328 trainer.py:139] Epoch[146/1000] loss: 0.10191287076280962
I0416 09:34:58.031438 27328 trainer.py:139] Epoch[147/1000] loss: 0.09940383463136611
I0416 09:35:01.849664 27328 trainer.py:139] Epoch[148/1000] loss: 0.10125363882510893
I0416 09:35:05.398791 27328 trainer.py:139] Epoch[149/1000] loss: 0.09947912467102851
I0416 09:35:05.696794 27328 trainer.py:145] Test: {'precision': 0.12761394101876689, 'recall': 0.3018067753795559, 'hit_ratio': 0.8718498659517426, 'ndcg': 0.2840807053921875}
I0416 09:35:09.544920 27328 trainer.py:139] Epoch[150/1000] loss: 0.09881043842723293
I0416 09:35:13.162817 27328 trainer.py:139] Epoch[151/1000] loss: 0.09770013031459623
I0416 09:35:17.046824 27328 trainer.py:139] Epoch[152/1000] loss: 0.09767149436858392
I0416 09:35:20.828173 27328 trainer.py:139] Epoch[153/1000] loss: 0.09930137160324282
I0416 09:35:24.680287 27328 trainer.py:139] Epoch[154/1000] loss: 0.09900283957681348
I0416 09:35:28.477583 27328 trainer.py:139] Epoch[155/1000] loss: 0.09819666248175406
I0416 09:35:32.114416 27328 trainer.py:139] Epoch[156/1000] loss: 0.09872424866883986
I0416 09:35:35.748260 27328 trainer.py:139] Epoch[157/1000] loss: 0.09717177167054146
I0416 09:35:39.637249 27328 trainer.py:139] Epoch[158/1000] loss: 0.09525980800390244
I0416 09:35:43.366772 27328 trainer.py:139] Epoch[159/1000] loss: 0.09662196136290027
I0416 09:35:47.128189 27328 trainer.py:139] Epoch[160/1000] loss: 0.09572264239672691
I0416 09:35:50.742099 27328 trainer.py:139] Epoch[161/1000] loss: 0.09607516541596382
I0416 09:35:54.496539 27328 trainer.py:139] Epoch[162/1000] loss: 0.09666233798188548
I0416 09:35:58.200149 27328 trainer.py:139] Epoch[163/1000] loss: 0.0961723233903608
I0416 09:36:01.894789 27328 trainer.py:139] Epoch[164/1000] loss: 0.09485759730300596
I0416 09:36:05.545575 27328 trainer.py:139] Epoch[165/1000] loss: 0.0964890742494214
I0416 09:36:09.261145 27328 trainer.py:139] Epoch[166/1000] loss: 0.09515781436235674
I0416 09:36:13.099305 27328 trainer.py:139] Epoch[167/1000] loss: 0.0969391621408924
I0416 09:36:16.821852 27328 trainer.py:139] Epoch[168/1000] loss: 0.0926452343983035
I0416 09:36:20.308188 27328 trainer.py:139] Epoch[169/1000] loss: 0.09336090616641506
I0416 09:36:23.822431 27328 trainer.py:139] Epoch[170/1000] loss: 0.0957219168063133
I0416 09:36:27.474215 27328 trainer.py:139] Epoch[171/1000] loss: 0.09500496762414132
I0416 09:36:31.120018 27328 trainer.py:139] Epoch[172/1000] loss: 0.09293147969630457
I0416 09:36:34.818644 27328 trainer.py:139] Epoch[173/1000] loss: 0.09379006465596537
I0416 09:36:38.518268 27328 trainer.py:139] Epoch[174/1000] loss: 0.09027326082991015
I0416 09:36:42.214901 27328 trainer.py:139] Epoch[175/1000] loss: 0.09087820759704036
I0416 09:36:45.802898 27328 trainer.py:139] Epoch[176/1000] loss: 0.09251459014992561
I0416 09:36:49.621124 27328 trainer.py:139] Epoch[177/1000] loss: 0.09170371245953345
I0416 09:36:53.259951 27328 trainer.py:139] Epoch[178/1000] loss: 0.09052338114669246
I0416 09:36:56.837981 27328 trainer.py:139] Epoch[179/1000] loss: 0.08885076834309485
I0416 09:37:00.278471 27328 trainer.py:139] Epoch[180/1000] loss: 0.0898208454731972
I0416 09:37:03.804674 27328 trainer.py:139] Epoch[181/1000] loss: 0.08965175887269358
I0416 09:37:07.776387 27328 trainer.py:139] Epoch[182/1000] loss: 0.08890489296567056
I0416 09:37:11.607570 27328 trainer.py:139] Epoch[183/1000] loss: 0.09022864290783482
I0416 09:37:15.240417 27328 trainer.py:139] Epoch[184/1000] loss: 0.09163463115692139
I0416 09:37:18.970937 27328 trainer.py:139] Epoch[185/1000] loss: 0.08995542771393253
I0416 09:37:22.866425 27328 trainer.py:139] Epoch[186/1000] loss: 0.088448089216986
I0416 09:37:26.452428 27328 trainer.py:139] Epoch[187/1000] loss: 0.08856648543188649
I0416 09:37:30.024478 27328 trainer.py:139] Epoch[188/1000] loss: 0.08942476347569496
I0416 09:37:33.669284 27328 trainer.py:139] Epoch[189/1000] loss: 0.08813053369522095
I0416 09:37:37.317082 27328 trainer.py:139] Epoch[190/1000] loss: 0.08880265730042611
I0416 09:37:41.000759 27328 trainer.py:139] Epoch[191/1000] loss: 0.088233562486787
I0416 09:37:44.813004 27328 trainer.py:139] Epoch[192/1000] loss: 0.08774872725048373
I0416 09:37:48.305321 27328 trainer.py:139] Epoch[193/1000] loss: 0.08644442452538398
I0416 09:37:52.121555 27328 trainer.py:139] Epoch[194/1000] loss: 0.08694826451040083
I0416 09:37:55.672674 27328 trainer.py:139] Epoch[195/1000] loss: 0.08522083850637559
I0416 09:37:59.360337 27328 trainer.py:139] Epoch[196/1000] loss: 0.08506899903858861
I0416 09:38:03.122750 27328 trainer.py:139] Epoch[197/1000] loss: 0.08614713530386647
I0416 09:38:06.841310 27328 trainer.py:139] Epoch[198/1000] loss: 0.08518980611716548
I0416 09:38:10.733290 27328 trainer.py:139] Epoch[199/1000] loss: 0.08836071217252363
I0416 09:38:11.081127 27328 trainer.py:145] Test: {'precision': 0.13101876675603225, 'recall': 0.3093173404772523, 'hit_ratio': 0.8788203753351207, 'ndcg': 0.2910161796266125}
I0416 09:38:14.814636 27328 trainer.py:139] Epoch[200/1000] loss: 0.08592746599066642
I0416 09:38:18.619906 27328 trainer.py:139] Epoch[201/1000] loss: 0.08451944829956178
I0416 09:38:22.412220 27328 trainer.py:139] Epoch[202/1000] loss: 0.08413544946139859
I0416 09:38:26.279283 27328 trainer.py:139] Epoch[203/1000] loss: 0.0837901484581732
I0416 09:38:29.877245 27328 trainer.py:139] Epoch[204/1000] loss: 0.08331647298989757
I0416 09:38:33.443316 27328 trainer.py:139] Epoch[205/1000] loss: 0.0849325630453325
I0416 09:38:37.119019 27328 trainer.py:139] Epoch[206/1000] loss: 0.08413767766567969
I0416 09:38:40.820636 27328 trainer.py:139] Epoch[207/1000] loss: 0.08418029955317897
I0416 09:38:44.471422 27328 trainer.py:139] Epoch[208/1000] loss: 0.08409200825037495
I0416 09:38:48.181012 27328 trainer.py:139] Epoch[209/1000] loss: 0.0828831779860681
I0416 09:38:51.886615 27328 trainer.py:139] Epoch[210/1000] loss: 0.08541815343403047
I0416 09:38:55.633082 27328 trainer.py:139] Epoch[211/1000] loss: 0.08187228297033618
I0416 09:38:59.315762 27328 trainer.py:139] Epoch[212/1000] loss: 0.08290716236637484
I0416 09:39:03.018375 27328 trainer.py:139] Epoch[213/1000] loss: 0.08238689937899189
I0416 09:39:06.612351 27328 trainer.py:139] Epoch[214/1000] loss: 0.0819603735881467
I0416 09:39:10.458484 27328 trainer.py:139] Epoch[215/1000] loss: 0.0827214912541451
I0416 09:39:14.020568 27328 trainer.py:139] Epoch[216/1000] loss: 0.08071136979326125
I0416 09:39:17.708231 27328 trainer.py:139] Epoch[217/1000] loss: 0.08240408979115947
I0416 09:39:21.283271 27328 trainer.py:139] Epoch[218/1000] loss: 0.08021703939284047
I0416 09:39:24.906151 27328 trainer.py:139] Epoch[219/1000] loss: 0.0810683379250188
I0416 09:39:28.580857 27328 trainer.py:139] Epoch[220/1000] loss: 0.08295281591915316
I0416 09:39:32.356228 27328 trainer.py:139] Epoch[221/1000] loss: 0.08207648319582786
I0416 09:39:36.084754 27328 trainer.py:139] Epoch[222/1000] loss: 0.07982750020680889
I0416 09:39:39.890024 27328 trainer.py:139] Epoch[223/1000] loss: 0.08037107197507735
I0416 09:39:43.582670 27328 trainer.py:139] Epoch[224/1000] loss: 0.07977493780274544
I0416 09:39:47.282294 27328 trainer.py:139] Epoch[225/1000] loss: 0.08098238682554613
I0416 09:39:51.052680 27328 trainer.py:139] Epoch[226/1000] loss: 0.08262242376804352
I0416 09:39:54.666590 27328 trainer.py:139] Epoch[227/1000] loss: 0.07959162275637349
I0416 09:39:58.175850 27328 trainer.py:139] Epoch[228/1000] loss: 0.07904895250835726
I0416 09:40:01.610360 27328 trainer.py:139] Epoch[229/1000] loss: 0.07799639024080769
I0416 09:40:05.077760 27328 trainer.py:139] Epoch[230/1000] loss: 0.07997965860751367
I0416 09:40:08.669743 27328 trainer.py:139] Epoch[231/1000] loss: 0.07823754967220369
I0416 09:40:12.019538 27328 trainer.py:139] Epoch[232/1000] loss: 0.07877808472802562
I0416 09:40:15.167007 27328 trainer.py:139] Epoch[233/1000] loss: 0.07938560699262927
I0416 09:40:18.247701 27328 trainer.py:139] Epoch[234/1000] loss: 0.0800769156025302
I0416 09:40:21.441018 27328 trainer.py:139] Epoch[235/1000] loss: 0.07869628071784973
I0416 09:40:24.554602 27328 trainer.py:139] Epoch[236/1000] loss: 0.07871573826959057
I0416 09:40:27.524666 27328 trainer.py:139] Epoch[237/1000] loss: 0.07672307928723673
I0416 09:40:30.165830 27328 trainer.py:139] Epoch[238/1000] loss: 0.07748183896464686
I0416 09:40:33.042208 27328 trainer.py:139] Epoch[239/1000] loss: 0.07643991059833957
I0416 09:40:35.684369 27328 trainer.py:139] Epoch[240/1000] loss: 0.07756202547780928
I0416 09:40:38.387326 27328 trainer.py:139] Epoch[241/1000] loss: 0.07629468316032041
I0416 09:40:41.104237 27328 trainer.py:139] Epoch[242/1000] loss: 0.07600499353101177
I0416 09:40:44.064334 27328 trainer.py:139] Epoch[243/1000] loss: 0.077531264674279
I0416 09:40:46.775264 27328 trainer.py:139] Epoch[244/1000] loss: 0.07486296685472611
I0416 09:40:49.410450 27328 trainer.py:139] Epoch[245/1000] loss: 0.0777070457416196
I0416 09:40:52.042643 27328 trainer.py:139] Epoch[246/1000] loss: 0.07517203496348474
I0416 09:40:54.597097 27328 trainer.py:139] Epoch[247/1000] loss: 0.07509545068587026
I0416 09:40:57.305039 27328 trainer.py:139] Epoch[248/1000] loss: 0.07696580598431249
I0416 09:40:59.890389 27328 trainer.py:139] Epoch[249/1000] loss: 0.07746678278330833
I0416 09:41:00.105669 27328 trainer.py:145] Test: {'precision': 0.13308310991957112, 'recall': 0.31464885501748785, 'hit_ratio': 0.885254691689008, 'ndcg': 0.29664333221942524}
I0416 09:41:02.882379 27328 trainer.py:139] Epoch[250/1000] loss: 0.0755797836088365
I0416 09:41:05.477697 27328 trainer.py:139] Epoch[251/1000] loss: 0.0781901928205644
I0416 09:41:08.213545 27328 trainer.py:139] Epoch[252/1000] loss: 0.07580769614827249
I0416 09:41:10.873646 27328 trainer.py:139] Epoch[253/1000] loss: 0.07480467952066852
I0416 09:41:13.483913 27328 trainer.py:139] Epoch[254/1000] loss: 0.07722538277026146
I0416 09:41:16.129064 27328 trainer.py:139] Epoch[255/1000] loss: 0.07647260014087923
I0416 09:41:18.848965 27328 trainer.py:139] Epoch[256/1000] loss: 0.07393441974155364
I0416 09:41:21.623682 27328 trainer.py:139] Epoch[257/1000] loss: 0.07479258194085091
I0416 09:41:24.163186 27328 trainer.py:139] Epoch[258/1000] loss: 0.07570455175253653
I0416 09:41:26.944881 27328 trainer.py:139] Epoch[259/1000] loss: 0.07532418495224368
I0416 09:41:29.741672 27328 trainer.py:139] Epoch[260/1000] loss: 0.07573988480914023
I0416 09:41:32.469547 27328 trainer.py:139] Epoch[261/1000] loss: 0.07423882619027168
I0416 09:41:35.152570 27328 trainer.py:139] Epoch[262/1000] loss: 0.07354317196915226
I0416 09:41:37.800711 27328 trainer.py:139] Epoch[263/1000] loss: 0.07343212262757363
I0416 09:41:40.520611 27328 trainer.py:139] Epoch[264/1000] loss: 0.07280807341298749
I0416 09:41:43.190679 27328 trainer.py:139] Epoch[265/1000] loss: 0.07311682030558586
I0416 09:41:45.910580 27328 trainer.py:139] Epoch[266/1000] loss: 0.07354695674392485
I0416 09:41:48.461048 27328 trainer.py:139] Epoch[267/1000] loss: 0.07367162598717597
I0416 09:41:51.178955 27328 trainer.py:139] Epoch[268/1000] loss: 0.07309891980501913
I0416 09:41:53.851016 27328 trainer.py:139] Epoch[269/1000] loss: 0.07156508944688304
I0416 09:41:56.403476 27328 trainer.py:139] Epoch[270/1000] loss: 0.07331815506181409
I0416 09:41:58.933015 27328 trainer.py:139] Epoch[271/1000] loss: 0.07310436185329192
I0416 09:42:01.540292 27328 trainer.py:139] Epoch[272/1000] loss: 0.07437098218548682
I0416 09:42:04.276139 27328 trainer.py:139] Epoch[273/1000] loss: 0.0732560160179292
I0416 09:42:07.026838 27328 trainer.py:139] Epoch[274/1000] loss: 0.07320434840456132
I0416 09:42:09.794749 27328 trainer.py:139] Epoch[275/1000] loss: 0.0713557663463777
I0416 09:42:12.380100 27328 trainer.py:139] Epoch[276/1000] loss: 0.07194092773622082
I0416 09:42:15.138871 27328 trainer.py:139] Epoch[277/1000] loss: 0.07283192031806515
I0416 09:42:17.756116 27328 trainer.py:139] Epoch[278/1000] loss: 0.07125238040762563
I0416 09:42:20.504919 27328 trainer.py:139] Epoch[279/1000] loss: 0.07199815276169008
I0416 09:42:23.347410 27328 trainer.py:139] Epoch[280/1000] loss: 0.07136495844010383
I0416 09:42:26.029438 27328 trainer.py:139] Epoch[281/1000] loss: 0.07269984531787134
I0416 09:42:28.824088 27328 trainer.py:139] Epoch[282/1000] loss: 0.07166643873337776
I0416 09:42:31.606779 27328 trainer.py:139] Epoch[283/1000] loss: 0.07135570049285889
I0416 09:42:34.188143 27328 trainer.py:139] Epoch[284/1000] loss: 0.07002768809756925
I0416 09:42:36.772497 27328 trainer.py:139] Epoch[285/1000] loss: 0.07084477043920948
I0416 09:42:39.374791 27328 trainer.py:139] Epoch[286/1000] loss: 0.06992021707757827
I0416 09:42:41.965126 27328 trainer.py:139] Epoch[287/1000] loss: 0.06929959440904279
I0416 09:42:44.601306 27328 trainer.py:139] Epoch[288/1000] loss: 0.07053614828375078
I0416 09:42:47.345128 27328 trainer.py:139] Epoch[289/1000] loss: 0.06920390936636156
I0416 09:42:49.961376 27328 trainer.py:139] Epoch[290/1000] loss: 0.07235324935566995
I0416 09:42:52.547723 27328 trainer.py:139] Epoch[291/1000] loss: 0.0705644530394385
I0416 09:42:55.248688 27328 trainer.py:139] Epoch[292/1000] loss: 0.07151999504816148
I0416 09:42:57.879886 27328 trainer.py:139] Epoch[293/1000] loss: 0.06914980529296783
I0416 09:43:00.767225 27328 trainer.py:139] Epoch[294/1000] loss: 0.07037514940865579
I0416 09:43:03.480149 27328 trainer.py:139] Epoch[295/1000] loss: 0.07007074115737792
I0416 09:43:06.271810 27328 trainer.py:139] Epoch[296/1000] loss: 0.06843546934185489
I0416 09:43:08.933904 27328 trainer.py:139] Epoch[297/1000] loss: 0.07031908186693345
I0416 09:43:11.580052 27328 trainer.py:139] Epoch[298/1000] loss: 0.06948113645757398
I0416 09:43:14.286996 27328 trainer.py:139] Epoch[299/1000] loss: 0.06999474835972633
I0416 09:43:14.489318 27328 trainer.py:145] Test: {'precision': 0.13549597855227893, 'recall': 0.3207750332864669, 'hit_ratio': 0.8927613941018767, 'ndcg': 0.3023933319457108}
I0416 09:43:17.164370 27328 trainer.py:139] Epoch[300/1000] loss: 0.07093065977096558
I0416 09:43:19.878290 27328 trainer.py:139] Epoch[301/1000] loss: 0.07008185742362853
I0416 09:43:22.615135 27328 trainer.py:139] Epoch[302/1000] loss: 0.06992058552080585
I0416 09:43:25.357959 27328 trainer.py:139] Epoch[303/1000] loss: 0.06794404238462448
I0416 09:43:28.123706 27328 trainer.py:139] Epoch[304/1000] loss: 0.06793462569194456
I0416 09:43:30.899421 27328 trainer.py:139] Epoch[305/1000] loss: 0.06872702774501616
I0416 09:43:33.510685 27328 trainer.py:139] Epoch[306/1000] loss: 0.06883146938297056
I0416 09:43:36.347195 27328 trainer.py:139] Epoch[307/1000] loss: 0.07012615557159146
I0416 09:43:39.110949 27328 trainer.py:139] Epoch[308/1000] loss: 0.07046636013734725
I0416 09:43:41.736166 27328 trainer.py:139] Epoch[309/1000] loss: 0.06769328708610227
I0416 09:43:44.616531 27328 trainer.py:139] Epoch[310/1000] loss: 0.06768746157327006
I0416 09:43:47.298558 27328 trainer.py:139] Epoch[311/1000] loss: 0.06769779901350698
I0416 09:43:49.948693 27328 trainer.py:139] Epoch[312/1000] loss: 0.06933451035330372
I0416 09:43:52.546004 27328 trainer.py:139] Epoch[313/1000] loss: 0.0685224992132956
I0416 09:43:55.291818 27328 trainer.py:139] Epoch[314/1000] loss: 0.06688413168153455
I0416 09:43:57.877170 27328 trainer.py:139] Epoch[315/1000] loss: 0.06795350954897943
I0416 09:44:00.722649 27328 trainer.py:139] Epoch[316/1000] loss: 0.06619582685732073
I0416 09:44:03.563146 27328 trainer.py:139] Epoch[317/1000] loss: 0.06970098013839414
I0416 09:44:06.246170 27328 trainer.py:139] Epoch[318/1000] loss: 0.0675309424198443
I0416 09:44:08.876372 27328 trainer.py:139] Epoch[319/1000] loss: 0.06609911519673563
I0416 09:44:11.516539 27328 trainer.py:139] Epoch[320/1000] loss: 0.06802022949822488
I0416 09:44:14.114846 27328 trainer.py:139] Epoch[321/1000] loss: 0.06914861380092559
I0416 09:44:16.912487 27328 trainer.py:139] Epoch[322/1000] loss: 0.06535773856505271
I0416 09:44:19.615446 27328 trainer.py:139] Epoch[323/1000] loss: 0.06800441095425237
I0416 09:44:22.304449 27328 trainer.py:139] Epoch[324/1000] loss: 0.06741372892452825
I0416 09:44:24.946610 27328 trainer.py:139] Epoch[325/1000] loss: 0.06627663056696614
I0416 09:44:27.686444 27328 trainer.py:139] Epoch[326/1000] loss: 0.06607240883092727
I0416 09:44:30.621625 27328 trainer.py:139] Epoch[327/1000] loss: 0.06704164668917656
I0416 09:44:33.365446 27328 trainer.py:139] Epoch[328/1000] loss: 0.06715840185361524
I0416 09:44:35.931861 27328 trainer.py:139] Epoch[329/1000] loss: 0.0669403251621031
I0416 09:44:38.748438 27328 trainer.py:139] Epoch[330/1000] loss: 0.06746321195556272
I0416 09:44:41.472325 27328 trainer.py:139] Epoch[331/1000] loss: 0.06717009746259259
I0416 09:44:44.287905 27328 trainer.py:139] Epoch[332/1000] loss: 0.06685954945222024
I0416 09:44:47.163286 27328 trainer.py:139] Epoch[333/1000] loss: 0.06428770552719792
I0416 09:44:50.033684 27328 trainer.py:139] Epoch[334/1000] loss: 0.06582613625834065
I0416 09:44:52.795444 27328 trainer.py:139] Epoch[335/1000] loss: 0.06674658747449998
I0416 09:44:55.590095 27328 trainer.py:139] Epoch[336/1000] loss: 0.06536684665949113
I0416 09:44:58.309996 27328 trainer.py:139] Epoch[337/1000] loss: 0.06676116345390197
I0416 09:45:00.909301 27328 trainer.py:139] Epoch[338/1000] loss: 0.0651614441265983
I0416 09:45:03.537507 27328 trainer.py:139] Epoch[339/1000] loss: 0.06472747929153903
I0416 09:45:06.175681 27328 trainer.py:139] Epoch[340/1000] loss: 0.06677273372488637
I0416 09:45:08.874652 27328 trainer.py:139] Epoch[341/1000] loss: 0.06620982878150479
I0416 09:45:11.552693 27328 trainer.py:139] Epoch[342/1000] loss: 0.06491092736682584
I0416 09:45:14.239704 27328 trainer.py:139] Epoch[343/1000] loss: 0.06484841495271652
I0416 09:45:16.905499 27328 trainer.py:139] Epoch[344/1000] loss: 0.0645951414781232
I0416 09:45:19.591514 27328 trainer.py:139] Epoch[345/1000] loss: 0.06460973127715049
I0416 09:45:22.248624 27328 trainer.py:139] Epoch[346/1000] loss: 0.0643958035976656
I0416 09:45:24.885802 27328 trainer.py:139] Epoch[347/1000] loss: 0.0647448146295163
I0416 09:45:27.505040 27328 trainer.py:139] Epoch[348/1000] loss: 0.06447451213194479
I0416 09:45:30.073447 27328 trainer.py:139] Epoch[349/1000] loss: 0.06345842442204876
I0416 09:45:30.264807 27328 trainer.py:145] Test: {'precision': 0.13683646112600545, 'recall': 0.32327498440335545, 'hit_ratio': 0.8954423592493298, 'ndcg': 0.30486603420313824}
I0416 09:45:33.015604 27328 trainer.py:139] Epoch[350/1000] loss: 0.06314373136528077
I0416 09:45:35.698629 27328 trainer.py:139] Epoch[351/1000] loss: 0.06365776783035647
I0416 09:45:38.420522 27328 trainer.py:139] Epoch[352/1000] loss: 0.06418739018901702
I0416 09:45:41.019827 27328 trainer.py:139] Epoch[353/1000] loss: 0.06426977822857519
I0416 09:45:43.647040 27328 trainer.py:139] Epoch[354/1000] loss: 0.06310033149296237
I0416 09:45:46.260297 27328 trainer.py:139] Epoch[355/1000] loss: 0.06522871698102643
I0416 09:45:49.002123 27328 trainer.py:139] Epoch[356/1000] loss: 0.06543326606192897
I0416 09:45:51.702873 27328 trainer.py:139] Epoch[357/1000] loss: 0.06388746826879439
I0416 09:45:54.352010 27328 trainer.py:139] Epoch[358/1000] loss: 0.06404450908303261
I0416 09:45:56.962278 27328 trainer.py:139] Epoch[359/1000] loss: 0.06044257756683134
I0416 09:45:59.631349 27328 trainer.py:139] Epoch[360/1000] loss: 0.06516745962923573
I0416 09:46:02.406066 27328 trainer.py:139] Epoch[361/1000] loss: 0.0630247633784048
I0416 09:46:05.117993 27328 trainer.py:139] Epoch[362/1000] loss: 0.06365334470906565
I0416 09:46:07.800021 27328 trainer.py:139] Epoch[363/1000] loss: 0.0642761834446461
I0416 09:46:10.504972 27328 trainer.py:139] Epoch[364/1000] loss: 0.06194216733978641
I0416 09:46:13.194973 27328 trainer.py:139] Epoch[365/1000] loss: 0.06304218175430451
I0416 09:46:15.887963 27328 trainer.py:139] Epoch[366/1000] loss: 0.06337116538516936
I0416 09:46:18.529127 27328 trainer.py:139] Epoch[367/1000] loss: 0.06365336513807697
I0416 09:46:21.229094 27328 trainer.py:139] Epoch[368/1000] loss: 0.06322115034826341
I0416 09:46:23.898166 27328 trainer.py:139] Epoch[369/1000] loss: 0.06352690871684782
I0416 09:46:26.502453 27328 trainer.py:139] Epoch[370/1000] loss: 0.06340463062928568
I0416 09:46:29.349926 27328 trainer.py:139] Epoch[371/1000] loss: 0.06347850217453894
I0416 09:46:32.096738 27328 trainer.py:139] Epoch[372/1000] loss: 0.06378784559426769
I0416 09:46:34.769795 27328 trainer.py:139] Epoch[373/1000] loss: 0.062411861434098215
I0416 09:46:37.441856 27328 trainer.py:139] Epoch[374/1000] loss: 0.06397609376618939
I0416 09:46:40.162754 27328 trainer.py:139] Epoch[375/1000] loss: 0.06370111663014658
I0416 09:46:42.650431 27328 trainer.py:139] Epoch[376/1000] loss: 0.06358304163140635
I0416 09:46:45.258705 27328 trainer.py:139] Epoch[377/1000] loss: 0.06372827351573974
I0416 09:46:47.863990 27328 trainer.py:139] Epoch[378/1000] loss: 0.061997430218804266
I0416 09:46:50.570934 27328 trainer.py:139] Epoch[379/1000] loss: 0.06254885742260564
I0416 09:46:53.188178 27328 trainer.py:139] Epoch[380/1000] loss: 0.06294232558819556
I0416 09:46:55.865223 27328 trainer.py:139] Epoch[381/1000] loss: 0.06377337644657781
I0416 09:46:58.431637 27328 trainer.py:139] Epoch[382/1000] loss: 0.0628833401828043
I0416 09:47:01.142567 27328 trainer.py:139] Epoch[383/1000] loss: 0.06399023088236008
I0416 09:47:03.892368 27328 trainer.py:139] Epoch[384/1000] loss: 0.062193976775292426
I0416 09:47:06.508615 27328 trainer.py:139] Epoch[385/1000] loss: 0.06176061844152789
I0416 09:47:09.070046 27328 trainer.py:139] Epoch[386/1000] loss: 0.0627290059722239
I0416 09:47:11.721177 27328 trainer.py:139] Epoch[387/1000] loss: 0.060538656408748316
I0416 09:47:14.571643 27328 trainer.py:139] Epoch[388/1000] loss: 0.06199114337082832
I0416 09:47:17.335396 27328 trainer.py:139] Epoch[389/1000] loss: 0.06089710600433811
I0416 09:47:20.097158 27328 trainer.py:139] Epoch[390/1000] loss: 0.06266588068777515
I0416 09:47:22.900777 27328 trainer.py:139] Epoch[391/1000] loss: 0.0611789918714954
I0416 09:47:25.520015 27328 trainer.py:139] Epoch[392/1000] loss: 0.0625343631592489
I0416 09:47:28.261846 27328 trainer.py:139] Epoch[393/1000] loss: 0.06104758946645644
I0416 09:47:30.793373 27328 trainer.py:139] Epoch[394/1000] loss: 0.06204517414012263
I0416 09:47:33.517260 27328 trainer.py:139] Epoch[395/1000] loss: 0.06069903328053413
I0416 09:47:36.226198 27328 trainer.py:139] Epoch[396/1000] loss: 0.06211031096116189
I0416 09:47:38.854406 27328 trainer.py:139] Epoch[397/1000] loss: 0.06185323264329664
I0416 09:47:41.427797 27328 trainer.py:139] Epoch[398/1000] loss: 0.0624286882098644
I0416 09:47:44.137730 27328 trainer.py:139] Epoch[399/1000] loss: 0.06118654940397509
I0416 09:47:44.321117 27328 trainer.py:145] Test: {'precision': 0.1375871313672923, 'recall': 0.3253489567521267, 'hit_ratio': 0.8932975871313673, 'ndcg': 0.3072938286619472}
I0416 09:47:46.987198 27328 trainer.py:139] Epoch[400/1000] loss: 0.06104709244062824
I0416 09:47:49.644309 27328 trainer.py:139] Epoch[401/1000] loss: 0.06121087542945339
I0416 09:47:52.247600 27328 trainer.py:139] Epoch[402/1000] loss: 0.06004599133326161
I0416 09:47:54.905707 27328 trainer.py:139] Epoch[403/1000] loss: 0.06107862942641781
I0416 09:47:57.583748 27328 trainer.py:139] Epoch[404/1000] loss: 0.061068077601732745
I0416 09:48:00.382385 27328 trainer.py:139] Epoch[405/1000] loss: 0.061760218032906135
I0416 09:48:03.016573 27328 trainer.py:139] Epoch[406/1000] loss: 0.061180545678061825
I0416 09:48:05.724514 27328 trainer.py:139] Epoch[407/1000] loss: 0.061727395341280966
I0416 09:48:08.406541 27328 trainer.py:139] Epoch[408/1000] loss: 0.06027443550767437
I0416 09:48:11.073618 27328 trainer.py:139] Epoch[409/1000] loss: 0.061471265890905936
I0416 09:48:13.571263 27328 trainer.py:139] Epoch[410/1000] loss: 0.06123747796781601
I0416 09:48:16.322061 27328 trainer.py:139] Epoch[411/1000] loss: 0.06148610191960489
I0416 09:48:18.947278 27328 trainer.py:139] Epoch[412/1000] loss: 0.06099623778174
I0416 09:48:21.671167 27328 trainer.py:139] Epoch[413/1000] loss: 0.06120693671607202
I0416 09:48:24.259506 27328 trainer.py:139] Epoch[414/1000] loss: 0.061056282972135854
I0416 09:48:27.099007 27328 trainer.py:139] Epoch[415/1000] loss: 0.060284354633861975
I0416 09:48:29.795984 27328 trainer.py:139] Epoch[416/1000] loss: 0.060343740087363026
I0416 09:48:32.509905 27328 trainer.py:139] Epoch[417/1000] loss: 0.06019832818738876
I0416 09:48:35.426149 27328 trainer.py:139] Epoch[418/1000] loss: 0.06137800505084376
I0416 09:48:38.154023 27328 trainer.py:139] Epoch[419/1000] loss: 0.06173073993094506
I0416 09:48:40.946681 27328 trainer.py:139] Epoch[420/1000] loss: 0.06086882624414659
I0416 09:48:43.616748 27328 trainer.py:139] Epoch[421/1000] loss: 0.06000120685465874
I0416 09:48:46.314723 27328 trainer.py:139] Epoch[422/1000] loss: 0.06056049718491493
I0416 09:48:49.024657 27328 trainer.py:139] Epoch[423/1000] loss: 0.06008108464940902
I0416 09:48:51.768477 27328 trainer.py:139] Epoch[424/1000] loss: 0.05920705776060781
I0416 09:48:54.639872 27328 trainer.py:139] Epoch[425/1000] loss: 0.060428838455869306
I0416 09:48:57.487345 27328 trainer.py:139] Epoch[426/1000] loss: 0.06112377345561981
I0416 09:49:00.306913 27328 trainer.py:139] Epoch[427/1000] loss: 0.05879377297336055
I0416 09:49:03.262027 27328 trainer.py:139] Epoch[428/1000] loss: 0.058306746785679174
I0416 09:49:06.017807 27328 trainer.py:139] Epoch[429/1000] loss: 0.05857916909360116
I0416 09:49:08.836378 27328 trainer.py:139] Epoch[430/1000] loss: 0.05963167283804186
I0416 09:49:11.448639 27328 trainer.py:139] Epoch[431/1000] loss: 0.058204694621024594
I0416 09:49:14.212393 27328 trainer.py:139] Epoch[432/1000] loss: 0.05951720367996923
I0416 09:49:16.863524 27328 trainer.py:139] Epoch[433/1000] loss: 0.0598088487261726
I0416 09:49:19.499705 27328 trainer.py:139] Epoch[434/1000] loss: 0.05821164168657795
I0416 09:49:22.239540 27328 trainer.py:139] Epoch[435/1000] loss: 0.059483281907535365
I0416 09:49:24.894657 27328 trainer.py:139] Epoch[436/1000] loss: 0.05874678612716736
I0416 09:49:27.568711 27328 trainer.py:139] Epoch[437/1000] loss: 0.05859389192154331
I0416 09:49:30.259708 27328 trainer.py:139] Epoch[438/1000] loss: 0.05774206055268165
I0416 09:49:32.995556 27328 trainer.py:139] Epoch[439/1000] loss: 0.05918717107945873
I0416 09:49:35.786220 27328 trainer.py:139] Epoch[440/1000] loss: 0.05970101671353463
I0416 09:49:38.364594 27328 trainer.py:139] Epoch[441/1000] loss: 0.059276625874542424
I0416 09:49:41.102435 27328 trainer.py:139] Epoch[442/1000] loss: 0.05831713902373468
I0416 09:49:43.834296 27328 trainer.py:139] Epoch[443/1000] loss: 0.060029379422626185
I0416 09:49:46.727616 27328 trainer.py:139] Epoch[444/1000] loss: 0.059169343522479455
I0416 09:49:49.550174 27328 trainer.py:139] Epoch[445/1000] loss: 0.05889352014468562
I0416 09:49:52.338844 27328 trainer.py:139] Epoch[446/1000] loss: 0.05857211531650636
I0416 09:49:55.069709 27328 trainer.py:139] Epoch[447/1000] loss: 0.0588832215195702
I0416 09:49:57.894259 27328 trainer.py:139] Epoch[448/1000] loss: 0.058701673943188884
I0416 09:50:00.656020 27328 trainer.py:139] Epoch[449/1000] loss: 0.059087059670878996
I0416 09:50:00.866317 27328 trainer.py:145] Test: {'precision': 0.13828418230563008, 'recall': 0.32736715452099474, 'hit_ratio': 0.8981233243967829, 'ndcg': 0.3086163742708329}
I0416 09:50:03.631067 27328 trainer.py:139] Epoch[450/1000] loss: 0.05728981667949307
I0416 09:50:06.345984 27328 trainer.py:139] Epoch[451/1000] loss: 0.05965732795096213
I0416 09:50:09.259239 27328 trainer.py:139] Epoch[452/1000] loss: 0.05895318823956674
I0416 09:50:11.875487 27328 trainer.py:139] Epoch[453/1000] loss: 0.05847338815369914
I0416 09:50:14.476783 27328 trainer.py:139] Epoch[454/1000] loss: 0.058018702292634595
I0416 09:50:17.244524 27328 trainer.py:139] Epoch[455/1000] loss: 0.05779148049412235
I0416 09:50:19.957449 27328 trainer.py:139] Epoch[456/1000] loss: 0.05996563129367367
I0416 09:50:22.762068 27328 trainer.py:139] Epoch[457/1000] loss: 0.059532893521170464
I0416 09:50:25.342433 27328 trainer.py:139] Epoch[458/1000] loss: 0.058386702571184404
I0416 09:50:28.055358 27328 trainer.py:139] Epoch[459/1000] loss: 0.05848343105566117
I0416 09:50:30.661640 27328 trainer.py:139] Epoch[460/1000] loss: 0.05858274393023983
I0416 09:50:33.385526 27328 trainer.py:139] Epoch[461/1000] loss: 0.058417588352195675
I0416 09:50:36.006758 27328 trainer.py:139] Epoch[462/1000] loss: 0.058081197041657665
I0416 09:50:38.624998 27328 trainer.py:139] Epoch[463/1000] loss: 0.05741049589649323
I0416 09:50:41.307025 27328 trainer.py:139] Epoch[464/1000] loss: 0.058354396252862865
I0416 09:50:43.937227 27328 trainer.py:139] Epoch[465/1000] loss: 0.058322899163730686
I0416 09:50:46.784700 27328 trainer.py:139] Epoch[466/1000] loss: 0.0599279091242821
I0416 09:50:49.504601 27328 trainer.py:139] Epoch[467/1000] loss: 0.0584177796638781
I0416 09:50:52.292275 27328 trainer.py:139] Epoch[468/1000] loss: 0.05840669199824333
I0416 09:50:55.226459 27328 trainer.py:139] Epoch[469/1000] loss: 0.05657994939434913
I0416 09:50:57.871610 27328 trainer.py:139] Epoch[470/1000] loss: 0.05842171897811274
I0416 09:51:00.644335 27328 trainer.py:139] Epoch[471/1000] loss: 0.058495177256484183
I0416 09:51:03.439982 27328 trainer.py:139] Epoch[472/1000] loss: 0.0574860964571276
I0416 09:51:06.141942 27328 trainer.py:139] Epoch[473/1000] loss: 0.0559161574609818
I0416 09:51:08.792078 27328 trainer.py:139] Epoch[474/1000] loss: 0.057811601748389584
I0416 09:51:11.500017 27328 trainer.py:139] Epoch[475/1000] loss: 0.05938006264548148
I0416 09:51:14.185036 27328 trainer.py:139] Epoch[476/1000] loss: 0.057940603504257816
I0416 09:51:16.911912 27328 trainer.py:139] Epoch[477/1000] loss: 0.05760830316332079
I0416 09:51:19.496268 27328 trainer.py:139] Epoch[478/1000] loss: 0.057626750200025494
I0416 09:51:22.276964 27328 trainer.py:139] Epoch[479/1000] loss: 0.05718822993578449
I0416 09:51:25.036731 27328 trainer.py:139] Epoch[480/1000] loss: 0.0581644827560071
I0416 09:51:27.685869 27328 trainer.py:139] Epoch[481/1000] loss: 0.05729524274506877
I0416 09:51:30.328029 27328 trainer.py:139] Epoch[482/1000] loss: 0.05568749349444143
I0416 09:51:33.126667 27328 trainer.py:139] Epoch[483/1000] loss: 0.05694382529585592
I0416 09:51:35.784775 27328 trainer.py:139] Epoch[484/1000] loss: 0.057013782762712045
I0416 09:51:38.412938 27328 trainer.py:139] Epoch[485/1000] loss: 0.05735555759841396
I0416 09:51:41.230512 27328 trainer.py:139] Epoch[486/1000] loss: 0.057980716709167726
I0416 09:51:44.065030 27328 trainer.py:139] Epoch[487/1000] loss: 0.0575674879214456
I0416 09:51:46.898549 27328 trainer.py:139] Epoch[488/1000] loss: 0.05714799067185771
I0416 09:51:49.836722 27328 trainer.py:139] Epoch[489/1000] loss: 0.056574713318578655
I0416 09:51:52.525725 27328 trainer.py:139] Epoch[490/1000] loss: 0.05641306155631619
I0416 09:51:55.207754 27328 trainer.py:139] Epoch[491/1000] loss: 0.057586119179764104
I0416 09:51:57.896757 27328 trainer.py:139] Epoch[492/1000] loss: 0.05635251501394856
I0416 09:52:00.596767 27328 trainer.py:139] Epoch[493/1000] loss: 0.05615765541311233
I0416 09:52:03.167125 27328 trainer.py:139] Epoch[494/1000] loss: 0.05705205351114273
I0416 09:52:05.788356 27328 trainer.py:139] Epoch[495/1000] loss: 0.057159603363083254
I0416 09:52:08.527193 27328 trainer.py:139] Epoch[496/1000] loss: 0.05714412670462362
I0416 09:52:11.157394 27328 trainer.py:139] Epoch[497/1000] loss: 0.05730631719193151
I0416 09:52:14.051711 27328 trainer.py:139] Epoch[498/1000] loss: 0.058458414169088486
I0416 09:52:16.914135 27328 trainer.py:139] Epoch[499/1000] loss: 0.055972365362028924
I0416 09:52:17.119448 27328 trainer.py:145] Test: {'precision': 0.13895442359249338, 'recall': 0.3283518147817944, 'hit_ratio': 0.8975871313672922, 'ndcg': 0.3095405761273314}
I0416 09:52:20.091601 27328 trainer.py:139] Epoch[500/1000] loss: 0.05662971855171265
I0416 09:52:22.844390 27328 trainer.py:139] Epoch[501/1000] loss: 0.05706408920307313
I0416 09:52:25.475588 27328 trainer.py:139] Epoch[502/1000] loss: 0.0568722118773768
I0416 09:52:28.241336 27328 trainer.py:139] Epoch[503/1000] loss: 0.05688783262045153
I0416 09:52:30.913397 27328 trainer.py:139] Epoch[504/1000] loss: 0.057341407263471235
I0416 09:52:33.613364 27328 trainer.py:139] Epoch[505/1000] loss: 0.05810174586311463
I0416 09:52:36.260508 27328 trainer.py:139] Epoch[506/1000] loss: 0.056745626993717685
I0416 09:52:38.851839 27328 trainer.py:139] Epoch[507/1000] loss: 0.057160656298360514
I0416 09:52:41.470080 27328 trainer.py:139] Epoch[508/1000] loss: 0.05694454896353906
I0416 09:52:44.305594 27328 trainer.py:139] Epoch[509/1000] loss: 0.05558227603473971
I0416 09:52:46.976659 27328 trainer.py:139] Epoch[510/1000] loss: 0.055426875069256754
I0416 09:52:49.685595 27328 trainer.py:139] Epoch[511/1000] loss: 0.05680660050242178
I0416 09:52:52.401510 27328 trainer.py:139] Epoch[512/1000] loss: 0.05642829571039446
I0416 09:52:55.077557 27328 trainer.py:139] Epoch[513/1000] loss: 0.056055637136582404
I0416 09:52:57.974864 27328 trainer.py:139] Epoch[514/1000] loss: 0.05733667842803463
I0416 09:53:00.701742 27328 trainer.py:139] Epoch[515/1000] loss: 0.05621726174027689
I0416 09:53:03.490413 27328 trainer.py:139] Epoch[516/1000] loss: 0.05397091433405876
I0416 09:53:06.208297 27328 trainer.py:139] Epoch[517/1000] loss: 0.056195933251611645
I0416 09:53:08.855528 27328 trainer.py:139] Epoch[518/1000] loss: 0.0550678142857167
I0416 09:53:11.455830 27328 trainer.py:139] Epoch[519/1000] loss: 0.0562995430682936
I0416 09:53:14.042176 27328 trainer.py:139] Epoch[520/1000] loss: 0.055959308820386085
I0416 09:53:16.713240 27328 trainer.py:139] Epoch[521/1000] loss: 0.05506294521112596
I0416 09:53:19.414204 27328 trainer.py:139] Epoch[522/1000] loss: 0.055304375747519154
I0416 09:53:22.232775 27328 trainer.py:139] Epoch[523/1000] loss: 0.056530806566438364
I0416 09:53:24.843043 27328 trainer.py:139] Epoch[524/1000] loss: 0.05498960770426258
I0416 09:53:27.488046 27328 trainer.py:139] Epoch[525/1000] loss: 0.054507444222127235
I0416 09:53:30.153457 27328 trainer.py:139] Epoch[526/1000] loss: 0.0552227257961227
I0416 09:53:32.856413 27328 trainer.py:139] Epoch[527/1000] loss: 0.05630262905070858
I0416 09:53:35.594254 27328 trainer.py:139] Epoch[528/1000] loss: 0.055248722434043884
I0416 09:53:38.298208 27328 trainer.py:139] Epoch[529/1000] loss: 0.054949138433702534
I0416 09:53:40.967279 27328 trainer.py:139] Epoch[530/1000] loss: 0.05430524531872042
I0416 09:53:43.694157 27328 trainer.py:139] Epoch[531/1000] loss: 0.05459548460860406
I0416 09:53:46.377182 27328 trainer.py:139] Epoch[532/1000] loss: 0.05520209153333018
I0416 09:53:49.104059 27328 trainer.py:139] Epoch[533/1000] loss: 0.05358691657743146
I0416 09:53:51.776119 27328 trainer.py:139] Epoch[534/1000] loss: 0.05409723964910353
I0416 09:53:54.511966 27328 trainer.py:139] Epoch[535/1000] loss: 0.05604401399050989
I0416 09:53:57.172068 27328 trainer.py:139] Epoch[536/1000] loss: 0.05521391151893523
I0416 09:53:59.828182 27328 trainer.py:139] Epoch[537/1000] loss: 0.05586663020714637
I0416 09:54:02.461373 27328 trainer.py:139] Epoch[538/1000] loss: 0.05642700483722071
I0416 09:54:05.161340 27328 trainer.py:139] Epoch[539/1000] loss: 0.055816206960908825
I0416 09:54:07.879416 27328 trainer.py:139] Epoch[540/1000] loss: 0.05565698865440584
I0416 09:54:10.400980 27328 trainer.py:139] Epoch[541/1000] loss: 0.0563316301953408
I0416 09:54:13.061356 27328 trainer.py:139] Epoch[542/1000] loss: 0.05381025470072223
I0416 09:54:15.695758 27328 trainer.py:139] Epoch[543/1000] loss: 0.05443628817316024
I0416 09:54:18.412669 27328 trainer.py:139] Epoch[544/1000] loss: 0.05529156411367078
I0416 09:54:21.019947 27328 trainer.py:139] Epoch[545/1000] loss: 0.055062755942344666
I0416 09:54:23.802088 27328 trainer.py:139] Epoch[546/1000] loss: 0.05540263604733252
I0416 09:54:26.477139 27328 trainer.py:139] Epoch[547/1000] loss: 0.05485213115330665
I0416 09:54:29.187424 27328 trainer.py:139] Epoch[548/1000] loss: 0.05516358380836825
I0416 09:54:31.796695 27328 trainer.py:139] Epoch[549/1000] loss: 0.057296344589802525
I0416 09:54:32.000015 27328 trainer.py:145] Test: {'precision': 0.13959785522788212, 'recall': 0.32994299467726385, 'hit_ratio': 0.9002680965147453, 'ndcg': 0.31096212012746166}
I0416 09:54:34.768752 27328 trainer.py:139] Epoch[550/1000] loss: 0.05612315285590387
I0416 09:54:37.533504 27328 trainer.py:139] Epoch[551/1000] loss: 0.055310465275279934
I0416 09:54:40.141779 27328 trainer.py:139] Epoch[552/1000] loss: 0.05525049074522911
I0416 09:54:43.037093 27328 trainer.py:139] Epoch[553/1000] loss: 0.0556137919906647
I0416 09:54:45.660317 27328 trainer.py:139] Epoch[554/1000] loss: 0.05523767742899156
I0416 09:54:48.249424 27328 trainer.py:139] Epoch[555/1000] loss: 0.05539488251651487
I0416 09:54:50.974283 27328 trainer.py:139] Epoch[556/1000] loss: 0.054180432471536824
I0416 09:54:53.577574 27328 trainer.py:139] Epoch[557/1000] loss: 0.05456964335133953
I0416 09:54:56.222725 27328 trainer.py:139] Epoch[558/1000] loss: 0.054914298557466074
I0416 09:54:58.905749 27328 trainer.py:139] Epoch[559/1000] loss: 0.055115602910518646
I0416 09:55:01.575816 27328 trainer.py:139] Epoch[560/1000] loss: 0.05467382253658387
I0416 09:55:04.228940 27328 trainer.py:139] Epoch[561/1000] loss: 0.05358900934938462
I0416 09:55:06.759475 27328 trainer.py:139] Epoch[562/1000] loss: 0.0542623792444506
I0416 09:55:09.567082 27328 trainer.py:139] Epoch[563/1000] loss: 0.05540020463447417
I0416 09:55:12.266053 27328 trainer.py:139] Epoch[564/1000] loss: 0.054809277937296896
I0416 09:55:14.933131 27328 trainer.py:139] Epoch[565/1000] loss: 0.05527723724803617
I0416 09:55:17.684924 27328 trainer.py:139] Epoch[566/1000] loss: 0.055305750860321905
I0416 09:55:20.390873 27328 trainer.py:139] Epoch[567/1000] loss: 0.05406974556465303
I0416 09:55:23.064926 27328 trainer.py:139] Epoch[568/1000] loss: 0.05490444456377337
I0416 09:55:25.786822 27328 trainer.py:139] Epoch[569/1000] loss: 0.05543641193259147
I0416 09:55:28.438949 27328 trainer.py:139] Epoch[570/1000] loss: 0.05468819759065105
I0416 09:55:31.181772 27328 trainer.py:139] Epoch[571/1000] loss: 0.05365736446072979
I0416 09:55:33.920609 27328 trainer.py:139] Epoch[572/1000] loss: 0.053653727616033244
I0416 09:55:36.529881 27328 trainer.py:139] Epoch[573/1000] loss: 0.054374254398768945
I0416 09:55:39.542801 27328 trainer.py:139] Epoch[574/1000] loss: 0.053992600210251346
I0416 09:55:42.142105 27328 trainer.py:139] Epoch[575/1000] loss: 0.05467986363557077
I0416 09:55:44.852040 27328 trainer.py:139] Epoch[576/1000] loss: 0.05410851442044781
I0416 09:55:47.572937 27328 trainer.py:139] Epoch[577/1000] loss: 0.0540556441391668
I0416 09:55:50.234034 27328 trainer.py:139] Epoch[578/1000] loss: 0.05404199491585455
I0416 09:55:52.832343 27328 trainer.py:139] Epoch[579/1000] loss: 0.05478739305849998
I0416 09:55:55.528323 27328 trainer.py:139] Epoch[580/1000] loss: 0.054131640061255426
I0416 09:55:58.176946 27328 trainer.py:139] Epoch[581/1000] loss: 0.05311881234088252
I0416 09:56:00.937709 27328 trainer.py:139] Epoch[582/1000] loss: 0.054869670541055744
I0416 09:56:03.736347 27328 trainer.py:139] Epoch[583/1000] loss: 0.05404564882478406
I0416 09:56:06.469204 27328 trainer.py:139] Epoch[584/1000] loss: 0.05492192518807227
I0416 09:56:09.180135 27328 trainer.py:139] Epoch[585/1000] loss: 0.05365498087579204
I0416 09:56:12.001696 27328 trainer.py:139] Epoch[586/1000] loss: 0.05386400379000172
I0416 09:56:14.705873 27328 trainer.py:139] Epoch[587/1000] loss: 0.05408235651350791
I0416 09:56:17.367968 27328 trainer.py:139] Epoch[588/1000] loss: 0.05357919224808293
I0416 09:56:19.926408 27328 trainer.py:139] Epoch[589/1000] loss: 0.054557885974645615
I0416 09:56:22.605446 27328 trainer.py:139] Epoch[590/1000] loss: 0.05401721308308263
I0416 09:56:25.280497 27328 trainer.py:139] Epoch[591/1000] loss: 0.054080624614031084
I0416 09:56:28.025314 27328 trainer.py:139] Epoch[592/1000] loss: 0.053100710554469015
I0416 09:56:30.766791 27328 trainer.py:139] Epoch[593/1000] loss: 0.054267868639961366
I0416 09:56:33.512087 27328 trainer.py:139] Epoch[594/1000] loss: 0.05319905112827978
I0416 09:56:36.231987 27328 trainer.py:139] Epoch[595/1000] loss: 0.05356221357660909
I0416 09:56:38.901057 27328 trainer.py:139] Epoch[596/1000] loss: 0.05479724032263602
I0416 09:56:41.609996 27328 trainer.py:139] Epoch[597/1000] loss: 0.05259850477018664
I0416 09:56:44.449498 27328 trainer.py:139] Epoch[598/1000] loss: 0.053375771689799525
I0416 09:56:47.066740 27328 trainer.py:139] Epoch[599/1000] loss: 0.05395214067351434
I0416 09:56:47.268068 27328 trainer.py:145] Test: {'precision': 0.14050938337801613, 'recall': 0.33188101539071435, 'hit_ratio': 0.8975871313672922, 'ndcg': 0.31364355541996825}
I0416 09:56:49.990957 27328 trainer.py:139] Epoch[600/1000] loss: 0.052632859637660366
I0416 09:56:52.560362 27328 trainer.py:139] Epoch[601/1000] loss: 0.05456341454578984
I0416 09:56:55.280263 27328 trainer.py:139] Epoch[602/1000] loss: 0.05354848960714956
I0416 09:56:57.918437 27328 trainer.py:139] Epoch[603/1000] loss: 0.05375979372089909
I0416 09:57:00.531694 27328 trainer.py:139] Epoch[604/1000] loss: 0.05302893490560593
I0416 09:57:03.093125 27328 trainer.py:139] Epoch[605/1000] loss: 0.05309339624739463
I0416 09:57:05.752229 27328 trainer.py:139] Epoch[606/1000] loss: 0.05386008346273053
I0416 09:57:08.352531 27328 trainer.py:139] Epoch[607/1000] loss: 0.053616383623692296
I0416 09:57:11.094357 27328 trainer.py:139] Epoch[608/1000] loss: 0.05397077697900034
I0416 09:57:13.869075 27328 trainer.py:139] Epoch[609/1000] loss: 0.05373636957618498
I0416 09:57:16.605919 27328 trainer.py:139] Epoch[610/1000] loss: 0.0524005698821237
I0416 09:57:19.404556 27328 trainer.py:139] Epoch[611/1000] loss: 0.05220163805830863
I0416 09:57:22.123461 27328 trainer.py:139] Epoch[612/1000] loss: 0.0534589666753046
I0416 09:57:24.829408 27328 trainer.py:139] Epoch[613/1000] loss: 0.052877514953574824
I0416 09:57:27.442666 27328 trainer.py:139] Epoch[614/1000] loss: 0.05422175134862623
I0416 09:57:29.981204 27328 trainer.py:139] Epoch[615/1000] loss: 0.05387666340797178
I0416 09:57:32.563768 27328 trainer.py:139] Epoch[616/1000] loss: 0.05213494562814312
I0416 09:57:35.175032 27328 trainer.py:139] Epoch[617/1000] loss: 0.05318825367477632
I0416 09:57:37.811212 27328 trainer.py:139] Epoch[618/1000] loss: 0.05385152286579532
I0416 09:57:40.468634 27328 trainer.py:139] Epoch[619/1000] loss: 0.053889307644098036
I0416 09:57:43.189533 27328 trainer.py:139] Epoch[620/1000] loss: 0.05368526207823907
I0416 09:57:45.882524 27328 trainer.py:139] Epoch[621/1000] loss: 0.052662402511604374
I0416 09:57:48.483821 27328 trainer.py:139] Epoch[622/1000] loss: 0.05380682346801604
I0416 09:57:51.130965 27328 trainer.py:139] Epoch[623/1000] loss: 0.05439141332622497
I0416 09:57:53.866855 27328 trainer.py:139] Epoch[624/1000] loss: 0.05349892113477953
I0416 09:57:56.521520 27328 trainer.py:139] Epoch[625/1000] loss: 0.0545308472168061
I0416 09:57:59.252738 27328 trainer.py:139] Epoch[626/1000] loss: 0.053296811157657255
I0416 09:58:02.014499 27328 trainer.py:139] Epoch[627/1000] loss: 0.052626208792771065
I0416 09:58:04.638277 27328 trainer.py:139] Epoch[628/1000] loss: 0.05371007912101284
I0416 09:58:07.253528 27328 trainer.py:139] Epoch[629/1000] loss: 0.05252347598152776
I0416 09:58:09.826919 27328 trainer.py:139] Epoch[630/1000] loss: 0.0518128692863449
I0416 09:58:12.424230 27328 trainer.py:139] Epoch[631/1000] loss: 0.05297635303389642
I0416 09:58:15.155094 27328 trainer.py:139] Epoch[632/1000] loss: 0.05317337089969266
I0416 09:58:17.780311 27328 trainer.py:139] Epoch[633/1000] loss: 0.05201223060008018
I0416 09:58:20.497698 27328 trainer.py:139] Epoch[634/1000] loss: 0.05427110808030251
I0416 09:58:23.083626 27328 trainer.py:139] Epoch[635/1000] loss: 0.05224020106177176
I0416 09:58:25.732869 27328 trainer.py:139] Epoch[636/1000] loss: 0.053229702696684866
I0416 09:58:28.508154 27328 trainer.py:139] Epoch[637/1000] loss: 0.053056528010675987
I0416 09:58:31.311916 27328 trainer.py:139] Epoch[638/1000] loss: 0.053321688526099725
I0416 09:58:34.059723 27328 trainer.py:139] Epoch[639/1000] loss: 0.05256449959931835
I0416 09:58:36.781513 27328 trainer.py:139] Epoch[640/1000] loss: 0.053309151482197545
I0416 09:58:39.577646 27328 trainer.py:139] Epoch[641/1000] loss: 0.0525401109649289
I0416 09:58:42.442063 27328 trainer.py:139] Epoch[642/1000] loss: 0.05189139287798635
I0416 09:58:45.079241 27328 trainer.py:139] Epoch[643/1000] loss: 0.05245273536251437
I0416 09:58:47.871944 27328 trainer.py:139] Epoch[644/1000] loss: 0.052446074303119414
I0416 09:58:50.601766 27328 trainer.py:139] Epoch[645/1000] loss: 0.0524287122872568
I0416 09:58:53.254890 27328 trainer.py:139] Epoch[646/1000] loss: 0.05254550602647566
I0416 09:58:55.966674 27328 trainer.py:139] Epoch[647/1000] loss: 0.05223680539957939
I0416 09:58:58.554019 27328 trainer.py:139] Epoch[648/1000] loss: 0.05278059599861022
I0416 09:59:01.307806 27328 trainer.py:139] Epoch[649/1000] loss: 0.052386063000848214
I0416 09:59:01.515113 27328 trainer.py:145] Test: {'precision': 0.14053619302949066, 'recall': 0.33219007512139526, 'hit_ratio': 0.8986595174262735, 'ndcg': 0.3130951099311358}
I0416 09:59:04.152290 27328 trainer.py:139] Epoch[650/1000] loss: 0.05256386221416535
I0416 09:59:06.850264 27328 trainer.py:139] Epoch[651/1000] loss: 0.05280684607644235
I0416 09:59:09.657872 27328 trainer.py:139] Epoch[652/1000] loss: 0.052251704037189484
I0416 09:59:12.443552 27328 trainer.py:139] Epoch[653/1000] loss: 0.052824143560663346
I0416 09:59:15.057807 27328 trainer.py:139] Epoch[654/1000] loss: 0.05186045914888382
I0416 09:59:17.739834 27328 trainer.py:139] Epoch[655/1000] loss: 0.052185418625031746
I0416 09:59:20.437808 27328 trainer.py:139] Epoch[656/1000] loss: 0.05221598739585569
I0416 09:59:23.120013 27328 trainer.py:139] Epoch[657/1000] loss: 0.052369808958422755
I0416 09:59:25.765165 27328 trainer.py:139] Epoch[658/1000] loss: 0.05105426234583701
I0416 09:59:28.491337 27328 trainer.py:139] Epoch[659/1000] loss: 0.05175726476215547
I0416 09:59:31.014894 27328 trainer.py:139] Epoch[660/1000] loss: 0.05195344816292486
I0416 09:59:33.736515 27328 trainer.py:139] Epoch[661/1000] loss: 0.05367023786229472
I0416 09:59:36.428509 27328 trainer.py:139] Epoch[662/1000] loss: 0.05266145400462612
I0416 09:59:39.175321 27328 trainer.py:139] Epoch[663/1000] loss: 0.05145278897496962
I0416 09:59:42.018807 27328 trainer.py:139] Epoch[664/1000] loss: 0.051591035579481435
I0416 09:59:44.784555 27328 trainer.py:139] Epoch[665/1000] loss: 0.052234627546802644
I0416 09:59:47.403792 27328 trainer.py:139] Epoch[666/1000] loss: 0.05276596522138965
I0416 09:59:50.134657 27328 trainer.py:139] Epoch[667/1000] loss: 0.05202572227966401
I0416 09:59:52.843594 27328 trainer.py:139] Epoch[668/1000] loss: 0.053007048704931815
I0416 09:59:55.400042 27328 trainer.py:139] Epoch[669/1000] loss: 0.0522821429035356
I0416 09:59:58.096023 27328 trainer.py:139] Epoch[670/1000] loss: 0.0518185076934676
I0416 10:00:00.830873 27328 trainer.py:139] Epoch[671/1000] loss: 0.05124768254257018
I0416 10:00:03.542801 27328 trainer.py:139] Epoch[672/1000] loss: 0.05162286878593506
I0416 10:00:06.215174 27328 trainer.py:139] Epoch[673/1000] loss: 0.052566368132829666
I0416 10:00:08.912153 27328 trainer.py:139] Epoch[674/1000] loss: 0.05130784610106099
I0416 10:00:11.485543 27328 trainer.py:139] Epoch[675/1000] loss: 0.0528433809597646
I0416 10:00:14.196474 27328 trainer.py:139] Epoch[676/1000] loss: 0.05254411493097582
I0416 10:00:16.846607 27328 trainer.py:139] Epoch[677/1000] loss: 0.05270533323768647
I0416 10:00:19.622321 27328 trainer.py:139] Epoch[678/1000] loss: 0.05194993797809847
I0416 10:00:22.269466 27328 trainer.py:139] Epoch[679/1000] loss: 0.05218621968261657
I0416 10:00:24.886711 27328 trainer.py:139] Epoch[680/1000] loss: 0.0517372291895651
I0416 10:00:27.646479 27328 trainer.py:139] Epoch[681/1000] loss: 0.05086301988170993
I0416 10:00:30.213889 27328 trainer.py:139] Epoch[682/1000] loss: 0.052470301187807517
I0416 10:00:32.921829 27328 trainer.py:139] Epoch[683/1000] loss: 0.052162872326950875
I0416 10:00:35.565983 27328 trainer.py:139] Epoch[684/1000] loss: 0.05165501119148347
I0416 10:00:38.179241 27328 trainer.py:139] Epoch[685/1000] loss: 0.05113745901373125
I0416 10:00:40.860272 27328 trainer.py:139] Epoch[686/1000] loss: 0.05215354564209138
I0416 10:00:43.527349 27328 trainer.py:139] Epoch[687/1000] loss: 0.05224640979882209
I0416 10:00:46.219344 27328 trainer.py:139] Epoch[688/1000] loss: 0.05212277534507936
I0416 10:00:48.872468 27328 trainer.py:139] Epoch[689/1000] loss: 0.05283534226398314
I0416 10:00:51.489713 27328 trainer.py:139] Epoch[690/1000] loss: 0.05293226999140555
I0416 10:00:54.306289 27328 trainer.py:139] Epoch[691/1000] loss: 0.05274066977923916
I0416 10:00:56.872704 27328 trainer.py:139] Epoch[692/1000] loss: 0.051188059992367224
I0416 10:00:59.811871 27328 trainer.py:139] Epoch[693/1000] loss: 0.0517418097344137
I0416 10:01:02.532769 27328 trainer.py:139] Epoch[694/1000] loss: 0.05209646073560561
I0416 10:01:05.159980 27328 trainer.py:139] Epoch[695/1000] loss: 0.05086506134079349
I0416 10:01:07.764267 27328 trainer.py:139] Epoch[696/1000] loss: 0.05148767812117454
I0416 10:01:10.493137 27328 trainer.py:139] Epoch[697/1000] loss: 0.05062306083498463
I0416 10:01:13.163205 27328 trainer.py:139] Epoch[698/1000] loss: 0.051066667682701544
I0416 10:01:15.867159 27328 trainer.py:139] Epoch[699/1000] loss: 0.05145180657986672
I0416 10:01:16.036592 27328 trainer.py:145] Test: {'precision': 0.14152815013404835, 'recall': 0.33493829874763503, 'hit_ratio': 0.8997319034852547, 'ndcg': 0.3147856450306412}
I0416 10:01:18.700680 27328 trainer.py:139] Epoch[700/1000] loss: 0.05224922587794642
I0416 10:01:21.282044 27328 trainer.py:139] Epoch[701/1000] loss: 0.05147545448234005
I0416 10:01:23.998955 27328 trainer.py:139] Epoch[702/1000] loss: 0.051044237829985156
I0416 10:01:26.875332 27328 trainer.py:139] Epoch[703/1000] loss: 0.051209233821399754
I0416 10:01:29.543407 27328 trainer.py:139] Epoch[704/1000] loss: 0.05114492689890246
I0416 10:01:32.322110 27328 trainer.py:139] Epoch[705/1000] loss: 0.05049867531464946
I0416 10:01:35.066928 27328 trainer.py:139] Epoch[706/1000] loss: 0.05162386295776213
I0416 10:01:37.841646 27328 trainer.py:139] Epoch[707/1000] loss: 0.05015191363711511
I0416 10:01:40.752906 27328 trainer.py:139] Epoch[708/1000] loss: 0.05180231361619888
I0416 10:01:43.461845 27328 trainer.py:139] Epoch[709/1000] loss: 0.05185727318448405
I0416 10:01:46.131911 27328 trainer.py:139] Epoch[710/1000] loss: 0.05062317655932519
I0416 10:01:48.922576 27328 trainer.py:139] Epoch[711/1000] loss: 0.05171539694551499
I0416 10:01:51.769052 27328 trainer.py:139] Epoch[712/1000] loss: 0.05121237243856153
I0416 10:01:54.434137 27328 trainer.py:139] Epoch[713/1000] loss: 0.050972635347035625
I0416 10:01:57.019488 27328 trainer.py:139] Epoch[714/1000] loss: 0.051451789515633735
I0416 10:01:59.849022 27328 trainer.py:139] Epoch[715/1000] loss: 0.05179548107327953
I0416 10:02:02.583873 27328 trainer.py:139] Epoch[716/1000] loss: 0.049858644003829646
I0416 10:02:05.332677 27328 trainer.py:139] Epoch[717/1000] loss: 0.051465191187397126
I0416 10:02:07.973841 27328 trainer.py:139] Epoch[718/1000] loss: 0.051485329025214716
I0416 10:02:10.587066 27328 trainer.py:139] Epoch[719/1000] loss: 0.05132897222234357
I0416 10:02:13.256136 27328 trainer.py:139] Epoch[720/1000] loss: 0.051273100438617894
I0416 10:02:15.913248 27328 trainer.py:139] Epoch[721/1000] loss: 0.05182731956724198
I0416 10:02:18.701919 27328 trainer.py:139] Epoch[722/1000] loss: 0.050632348103869344
I0416 10:02:21.442749 27328 trainer.py:139] Epoch[723/1000] loss: 0.050949394943252686
I0416 10:02:24.168630 27328 trainer.py:139] Epoch[724/1000] loss: 0.051700911694957365
I0416 10:02:27.061950 27328 trainer.py:139] Epoch[725/1000] loss: 0.05136427451525965
I0416 10:02:29.897260 27328 trainer.py:139] Epoch[726/1000] loss: 0.05093188127202372
I0416 10:02:32.755697 27328 trainer.py:139] Epoch[727/1000] loss: 0.05155427489549883
I0416 10:02:35.539385 27328 trainer.py:139] Epoch[728/1000] loss: 0.051484819141126445
I0416 10:02:38.202476 27328 trainer.py:139] Epoch[729/1000] loss: 0.050788248258252296
I0416 10:02:40.899453 27328 trainer.py:139] Epoch[730/1000] loss: 0.05119039226443537
I0416 10:02:43.641281 27328 trainer.py:139] Epoch[731/1000] loss: 0.05173544777977851
I0416 10:02:46.320318 27328 trainer.py:139] Epoch[732/1000] loss: 0.05021714371058249
I0416 10:02:49.044205 27328 trainer.py:139] Epoch[733/1000] loss: 0.05094023974191758
I0416 10:02:51.740186 27328 trainer.py:139] Epoch[734/1000] loss: 0.05112980858933541
I0416 10:02:54.497960 27328 trainer.py:139] Epoch[735/1000] loss: 0.05007697593781256
I0416 10:02:57.410218 27328 trainer.py:139] Epoch[736/1000] loss: 0.051054819096480644
I0416 10:03:00.077296 27328 trainer.py:139] Epoch[737/1000] loss: 0.05100549553190508
I0416 10:03:02.755336 27328 trainer.py:139] Epoch[738/1000] loss: 0.050168340124430194
I0416 10:03:05.395504 27328 trainer.py:139] Epoch[739/1000] loss: 0.050884431528468284
I0416 10:03:08.025705 27328 trainer.py:139] Epoch[740/1000] loss: 0.049588489796846144
I0416 10:03:10.733645 27328 trainer.py:139] Epoch[741/1000] loss: 0.04984437397891475
I0416 10:03:13.502382 27328 trainer.py:139] Epoch[742/1000] loss: 0.05077618468672999
I0416 10:03:16.216303 27328 trainer.py:139] Epoch[743/1000] loss: 0.051618557663694505
I0416 10:03:18.993923 27328 trainer.py:139] Epoch[744/1000] loss: 0.04992920088191186
I0416 10:03:21.765158 27328 trainer.py:139] Epoch[745/1000] loss: 0.050290636477931853
I0416 10:03:24.432235 27328 trainer.py:139] Epoch[746/1000] loss: 0.050634569338252465
I0416 10:03:27.285689 27328 trainer.py:139] Epoch[747/1000] loss: 0.051872874580083356
I0416 10:03:29.974694 27328 trainer.py:139] Epoch[748/1000] loss: 0.050490017379483866
I0416 10:03:32.748414 27328 trainer.py:139] Epoch[749/1000] loss: 0.05113304682797001
I0416 10:03:32.941767 27328 trainer.py:145] Test: {'precision': 0.1410723860589813, 'recall': 0.3339931655370862, 'hit_ratio': 0.9018766756032172, 'ndcg': 0.31395470529985714}
I0416 10:03:35.720472 27328 trainer.py:139] Epoch[750/1000] loss: 0.05057269791441579
I0416 10:03:38.545022 27328 trainer.py:139] Epoch[751/1000] loss: 0.051260351293510004
I0416 10:03:41.158280 27328 trainer.py:139] Epoch[752/1000] loss: 0.05050596642878748
I0416 10:03:43.962898 27328 trainer.py:139] Epoch[753/1000] loss: 0.05096891053741978
I0416 10:03:46.748579 27328 trainer.py:139] Epoch[754/1000] loss: 0.05075851719706289
I0416 10:03:49.524293 27328 trainer.py:139] Epoch[755/1000] loss: 0.051897513049264106
I0416 10:03:52.333894 27328 trainer.py:139] Epoch[756/1000] loss: 0.050673832816462365
I0416 10:03:55.104624 27328 trainer.py:139] Epoch[757/1000] loss: 0.05049297045315466
I0416 10:03:57.989972 27328 trainer.py:139] Epoch[758/1000] loss: 0.05148757068860915
I0416 10:04:00.717847 27328 trainer.py:139] Epoch[759/1000] loss: 0.05096572096790037
I0416 10:04:03.382931 27328 trainer.py:139] Epoch[760/1000] loss: 0.050724268199936036
I0416 10:04:06.101834 27328 trainer.py:139] Epoch[761/1000] loss: 0.05145386029635706
I0416 10:04:08.896484 27328 trainer.py:139] Epoch[762/1000] loss: 0.04984504356980324
I0416 10:04:11.654258 27328 trainer.py:139] Epoch[763/1000] loss: 0.05041170576887746
I0416 10:04:14.501732 27328 trainer.py:139] Epoch[764/1000] loss: 0.05071518774474821
I0416 10:04:17.287413 27328 trainer.py:139] Epoch[765/1000] loss: 0.05101764117998461
I0416 10:04:20.079061 27328 trainer.py:139] Epoch[766/1000] loss: 0.04961114040305538
I0416 10:04:22.666406 27328 trainer.py:139] Epoch[767/1000] loss: 0.05021682213391027
I0416 10:04:25.360393 27328 trainer.py:139] Epoch[768/1000] loss: 0.04946057234079607
I0416 10:04:28.202883 27328 trainer.py:139] Epoch[769/1000] loss: 0.05059300062637175
I0416 10:04:30.905841 27328 trainer.py:139] Epoch[770/1000] loss: 0.05071948961384835
I0416 10:04:33.695508 27328 trainer.py:139] Epoch[771/1000] loss: 0.050395394044537696
I0416 10:04:36.503116 27328 trainer.py:139] Epoch[772/1000] loss: 0.04914614642339368
I0416 10:04:39.182153 27328 trainer.py:139] Epoch[773/1000] loss: 0.04900572545105411
I0416 10:04:42.028631 27328 trainer.py:139] Epoch[774/1000] loss: 0.05033381583709871
I0416 10:04:44.768465 27328 trainer.py:139] Epoch[775/1000] loss: 0.04972161100276055
I0416 10:04:47.556139 27328 trainer.py:139] Epoch[776/1000] loss: 0.049346399283216845
I0416 10:04:50.308931 27328 trainer.py:139] Epoch[777/1000] loss: 0.05015939269815722
I0416 10:04:52.986970 27328 trainer.py:139] Epoch[778/1000] loss: 0.049192548399010015
I0416 10:04:55.684944 27328 trainer.py:139] Epoch[779/1000] loss: 0.050744406037753625
I0416 10:04:58.431755 27328 trainer.py:139] Epoch[780/1000] loss: 0.05023032498936499
I0416 10:05:01.046009 27328 trainer.py:139] Epoch[781/1000] loss: 0.04923897645165844
I0416 10:05:03.745977 27328 trainer.py:139] Epoch[782/1000] loss: 0.051251671967967864
I0416 10:05:06.345281 27328 trainer.py:139] Epoch[783/1000] loss: 0.05072680404109339
I0416 10:05:09.068172 27328 trainer.py:139] Epoch[784/1000] loss: 0.0503761806795674
I0416 10:05:11.871793 27328 trainer.py:139] Epoch[785/1000] loss: 0.04919051655357884
I0416 10:05:14.519934 27328 trainer.py:139] Epoch[786/1000] loss: 0.050042210327040766
I0416 10:05:17.278704 27328 trainer.py:139] Epoch[787/1000] loss: 0.05019424242838737
I0416 10:05:19.960732 27328 trainer.py:139] Epoch[788/1000] loss: 0.049660880358949784
I0416 10:05:22.826146 27328 trainer.py:139] Epoch[789/1000] loss: 0.050163709588589206
I0416 10:05:25.637740 27328 trainer.py:139] Epoch[790/1000] loss: 0.05027298557181512
I0416 10:05:28.529067 27328 trainer.py:139] Epoch[791/1000] loss: 0.05073292853851472
I0416 10:05:31.315745 27328 trainer.py:139] Epoch[792/1000] loss: 0.04991766834451306
I0416 10:05:34.056575 27328 trainer.py:139] Epoch[793/1000] loss: 0.05028503808763719
I0416 10:05:36.756543 27328 trainer.py:139] Epoch[794/1000] loss: 0.050335527908417485
I0416 10:05:39.556177 27328 trainer.py:139] Epoch[795/1000] loss: 0.04874230236295731
I0416 10:05:42.272091 27328 trainer.py:139] Epoch[796/1000] loss: 0.04915674451378084
I0416 10:05:44.799635 27328 trainer.py:139] Epoch[797/1000] loss: 0.049470145495668534
I0416 10:05:47.379007 27328 trainer.py:139] Epoch[798/1000] loss: 0.049773112660454165
I0416 10:05:50.145750 27328 trainer.py:139] Epoch[799/1000] loss: 0.049602533900930036
I0416 10:05:50.325150 27328 trainer.py:145] Test: {'precision': 0.14069705093833784, 'recall': 0.33327841506125694, 'hit_ratio': 0.9024128686327078, 'ndcg': 0.31450083626525105}
I0416 10:05:53.022128 27328 trainer.py:139] Epoch[800/1000] loss: 0.05039557622325036
I0416 10:05:55.771929 27328 trainer.py:139] Epoch[801/1000] loss: 0.05068577982244953
I0416 10:05:58.445983 27328 trainer.py:139] Epoch[802/1000] loss: 0.050224273555701776
I0416 10:06:01.342293 27328 trainer.py:139] Epoch[803/1000] loss: 0.04906830504055946
I0416 10:06:04.095084 27328 trainer.py:139] Epoch[804/1000] loss: 0.05055188099222799
I0416 10:06:06.804022 27328 trainer.py:139] Epoch[805/1000] loss: 0.05140178145900849
I0416 10:06:09.682337 27328 trainer.py:139] Epoch[806/1000] loss: 0.05019937131193376
I0416 10:06:12.464535 27328 trainer.py:139] Epoch[807/1000] loss: 0.050708997153466745
I0416 10:06:15.124636 27328 trainer.py:139] Epoch[808/1000] loss: 0.05026466375397098
I0416 10:06:17.725933 27328 trainer.py:139] Epoch[809/1000] loss: 0.04989687509594425
I0416 10:06:20.353144 27328 trainer.py:139] Epoch[810/1000] loss: 0.04968604000826036
I0416 10:06:23.005271 27328 trainer.py:139] Epoch[811/1000] loss: 0.04951868602825749
I0416 10:06:25.676335 27328 trainer.py:139] Epoch[812/1000] loss: 0.049510752481798974
I0416 10:06:28.547730 27328 trainer.py:139] Epoch[813/1000] loss: 0.05016779863545971
I0416 10:06:31.260654 27328 trainer.py:139] Epoch[814/1000] loss: 0.04835802496921632
I0416 10:06:33.876902 27328 trainer.py:139] Epoch[815/1000] loss: 0.04921159869240176
I0416 10:06:36.558928 27328 trainer.py:139] Epoch[816/1000] loss: 0.05104471214355961
I0416 10:06:39.264878 27328 trainer.py:139] Epoch[817/1000] loss: 0.04885812644516268
I0416 10:06:41.935941 27328 trainer.py:139] Epoch[818/1000] loss: 0.05005059427311344
I0416 10:06:44.741554 27328 trainer.py:139] Epoch[819/1000] loss: 0.049611120094214714
I0416 10:06:47.523248 27328 trainer.py:139] Epoch[820/1000] loss: 0.04905945206842115
I0416 10:06:50.184346 27328 trainer.py:139] Epoch[821/1000] loss: 0.04801354677446427
I0416 10:06:53.005907 27328 trainer.py:139] Epoch[822/1000] loss: 0.05028599248297753
I0416 10:06:55.801554 27328 trainer.py:139] Epoch[823/1000] loss: 0.049958477938367475
I0416 10:06:58.572285 27328 trainer.py:139] Epoch[824/1000] loss: 0.0507371497731055
I0416 10:07:01.400822 27328 trainer.py:139] Epoch[825/1000] loss: 0.04897853635972546
I0416 10:07:04.179526 27328 trainer.py:139] Epoch[826/1000] loss: 0.050154605219441074
I0416 10:07:06.988130 27328 trainer.py:139] Epoch[827/1000] loss: 0.04848437527975728
I0416 10:07:09.756869 27328 trainer.py:139] Epoch[828/1000] loss: 0.04967684442958524
I0416 10:07:12.526039 27328 trainer.py:139] Epoch[829/1000] loss: 0.04979690320549473
I0416 10:07:15.168200 27328 trainer.py:139] Epoch[830/1000] loss: 0.049913773733762004
I0416 10:07:17.974810 27328 trainer.py:139] Epoch[831/1000] loss: 0.05094875395298004
I0416 10:07:20.763481 27328 trainer.py:139] Epoch[832/1000] loss: 0.04904520223217626
I0416 10:07:23.613946 27328 trainer.py:139] Epoch[833/1000] loss: 0.05023595077856895
I0416 10:07:26.206273 27328 trainer.py:139] Epoch[834/1000] loss: 0.04917683332197128
I0416 10:07:28.961057 27328 trainer.py:139] Epoch[835/1000] loss: 0.04968334301825492
I0416 10:07:31.802551 27328 trainer.py:139] Epoch[836/1000] loss: 0.04984697146761802
I0416 10:07:34.594211 27328 trainer.py:139] Epoch[837/1000] loss: 0.04920977474220337
I0416 10:07:37.212452 27328 trainer.py:139] Epoch[838/1000] loss: 0.050156309479667295
I0416 10:07:40.097800 27328 trainer.py:139] Epoch[839/1000] loss: 0.048766623461438764
I0416 10:07:42.774844 27328 trainer.py:139] Epoch[840/1000] loss: 0.04980553542414019
I0416 10:07:45.536605 27328 trainer.py:139] Epoch[841/1000] loss: 0.04919661737738117
I0416 10:07:48.229596 27328 trainer.py:139] Epoch[842/1000] loss: 0.049940797830781626
I0416 10:07:51.003767 27328 trainer.py:139] Epoch[843/1000] loss: 0.0492851370044293
I0416 10:07:53.736625 27328 trainer.py:139] Epoch[844/1000] loss: 0.04959495089227153
I0416 10:07:56.491410 27328 trainer.py:139] Epoch[845/1000] loss: 0.05027397469647469
I0416 10:07:59.365793 27328 trainer.py:139] Epoch[846/1000] loss: 0.049758864266257134
I0416 10:08:02.187354 27328 trainer.py:139] Epoch[847/1000] loss: 0.048677844265776295
I0416 10:08:04.886324 27328 trainer.py:139] Epoch[848/1000] loss: 0.050510736242417364
I0416 10:08:07.664032 27328 trainer.py:139] Epoch[849/1000] loss: 0.048612886138500705
I0416 10:08:07.860376 27328 trainer.py:145] Test: {'precision': 0.13967828418230568, 'recall': 0.33066840197773817, 'hit_ratio': 0.8997319034852547, 'ndcg': 0.31343648127888507}
I0416 10:08:10.666986 27328 trainer.py:139] Epoch[850/1000] loss: 0.04910142755796833
I0416 10:08:13.445690 27328 trainer.py:139] Epoch[851/1000] loss: 0.05020577364390896
I0416 10:08:16.085858 27328 trainer.py:139] Epoch[852/1000] loss: 0.05062959895979974
I0416 10:08:18.755925 27328 trainer.py:139] Epoch[853/1000] loss: 0.05027575418353081
I0416 10:08:21.397089 27328 trainer.py:139] Epoch[854/1000] loss: 0.048909392448202256
I0416 10:08:24.117987 27328 trainer.py:139] Epoch[855/1000] loss: 0.048357903837196285
I0416 10:08:26.816958 27328 trainer.py:139] Epoch[856/1000] loss: 0.04940339213898105
I0416 10:08:29.488022 27328 trainer.py:139] Epoch[857/1000] loss: 0.049053050457469875
I0416 10:08:32.109253 27328 trainer.py:139] Epoch[858/1000] loss: 0.04987022328761316
I0416 10:08:34.640783 27328 trainer.py:139] Epoch[859/1000] loss: 0.048143786047735525
I0416 10:08:37.417494 27328 trainer.py:139] Epoch[860/1000] loss: 0.04955756111491111
I0416 10:08:40.005835 27328 trainer.py:139] Epoch[861/1000] loss: 0.04852941968748646
I0416 10:08:42.873243 27328 trainer.py:139] Epoch[862/1000] loss: 0.05017592553650179
I0416 10:08:45.540321 27328 trainer.py:139] Epoch[863/1000] loss: 0.04923167800711047
I0416 10:08:48.227331 27328 trainer.py:139] Epoch[864/1000] loss: 0.05041297861645298
I0416 10:08:50.920322 27328 trainer.py:139] Epoch[865/1000] loss: 0.04865977168083191
I0416 10:08:53.674110 27328 trainer.py:139] Epoch[866/1000] loss: 0.049839100770411954
I0416 10:08:56.512613 27328 trainer.py:139] Epoch[867/1000] loss: 0.049881935480140874
I0416 10:08:59.245471 27328 trainer.py:139] Epoch[868/1000] loss: 0.04938386981525729
I0416 10:09:01.881652 27328 trainer.py:139] Epoch[869/1000] loss: 0.049007883956355434
I0416 10:09:04.675306 27328 trainer.py:139] Epoch[870/1000] loss: 0.049796355347479546
I0416 10:09:07.334410 27328 trainer.py:139] Epoch[871/1000] loss: 0.04905768748252622
I0416 10:09:10.114110 27328 trainer.py:139] Epoch[872/1000] loss: 0.048281358134362004
I0416 10:09:12.771222 27328 trainer.py:139] Epoch[873/1000] loss: 0.049665942788124084
I0416 10:09:15.422352 27328 trainer.py:139] Epoch[874/1000] loss: 0.04751851325554232
I0416 10:09:18.224976 27328 trainer.py:139] Epoch[875/1000] loss: 0.04931435890255436
I0416 10:09:20.848201 27328 trainer.py:139] Epoch[876/1000] loss: 0.04957487025568562
I0416 10:09:23.604979 27328 trainer.py:139] Epoch[877/1000] loss: 0.049206933066729575
I0416 10:09:26.449462 27328 trainer.py:139] Epoch[878/1000] loss: 0.04945945042756296
I0416 10:09:29.137470 27328 trainer.py:139] Epoch[879/1000] loss: 0.04936619643722811
I0416 10:09:32.016838 27328 trainer.py:139] Epoch[880/1000] loss: 0.049840879656614795
I0416 10:09:34.703847 27328 trainer.py:139] Epoch[881/1000] loss: 0.04955844881553804
I0416 10:09:37.409795 27328 trainer.py:139] Epoch[882/1000] loss: 0.04942822552496387
I0416 10:09:40.165576 27328 trainer.py:139] Epoch[883/1000] loss: 0.04982436724728154
I0416 10:09:42.880495 27328 trainer.py:139] Epoch[884/1000] loss: 0.04916343393345033
I0416 10:09:45.685111 27328 trainer.py:139] Epoch[885/1000] loss: 0.048515421849104665
I0416 10:09:48.443882 27328 trainer.py:139] Epoch[886/1000] loss: 0.04954402040570013
I0416 10:09:51.123916 27328 trainer.py:139] Epoch[887/1000] loss: 0.049080348303241116
I0416 10:09:53.766077 27328 trainer.py:139] Epoch[888/1000] loss: 0.04924440347859936
I0416 10:09:56.540794 27328 trainer.py:139] Epoch[889/1000] loss: 0.04830731679835627
I0416 10:09:59.216842 27328 trainer.py:139] Epoch[890/1000] loss: 0.04834579039485224
I0416 10:10:01.849036 27328 trainer.py:139] Epoch[891/1000] loss: 0.04873651710729445
I0416 10:10:04.441364 27328 trainer.py:139] Epoch[892/1000] loss: 0.04926595692673037
I0416 10:10:07.120400 27328 trainer.py:139] Epoch[893/1000] loss: 0.0507931488175546
I0416 10:10:09.703759 27328 trainer.py:139] Epoch[894/1000] loss: 0.04734581360413182
I0416 10:10:12.387778 27328 trainer.py:139] Epoch[895/1000] loss: 0.050465579354955305
I0416 10:10:15.054856 27328 trainer.py:139] Epoch[896/1000] loss: 0.049176405153928265
I0416 10:10:17.768817 27328 trainer.py:139] Epoch[897/1000] loss: 0.05016320415081516
I0416 10:10:20.496652 27328 trainer.py:139] Epoch[898/1000] loss: 0.04862636039333959
I0416 10:10:23.171703 27328 trainer.py:139] Epoch[899/1000] loss: 0.04841897840942106
I0416 10:10:23.357083 27328 trainer.py:145] Test: {'precision': 0.14016085790884728, 'recall': 0.3314463907450031, 'hit_ratio': 0.900804289544236, 'ndcg': 0.31400137431513175}
I0416 10:10:26.157713 27328 trainer.py:139] Epoch[900/1000] loss: 0.04836264817464736
I0416 10:10:28.886584 27328 trainer.py:139] Epoch[901/1000] loss: 0.04901692595693373
I0416 10:10:31.571601 27328 trainer.py:139] Epoch[902/1000] loss: 0.04919720957836797
I0416 10:10:34.412099 27328 trainer.py:139] Epoch[903/1000] loss: 0.04922527026745581
I0416 10:10:37.027350 27328 trainer.py:139] Epoch[904/1000] loss: 0.04925129202104384
I0416 10:10:39.804061 27328 trainer.py:139] Epoch[905/1000] loss: 0.04904591688706029
I0416 10:10:42.516985 27328 trainer.py:139] Epoch[906/1000] loss: 0.04929181332549741
I0416 10:10:45.213962 27328 trainer.py:139] Epoch[907/1000] loss: 0.04852072678266033
I0416 10:10:47.920906 27328 trainer.py:139] Epoch[908/1000] loss: 0.04878755730967368
I0416 10:10:50.597950 27328 trainer.py:139] Epoch[909/1000] loss: 0.04843915241860574
I0416 10:10:53.446421 27328 trainer.py:139] Epoch[910/1000] loss: 0.04854891136769326
I0416 10:10:56.021805 27328 trainer.py:139] Epoch[911/1000] loss: 0.04912438219593417
I0416 10:10:58.603169 27328 trainer.py:139] Epoch[912/1000] loss: 0.047968048602342606
I0416 10:11:01.269251 27328 trainer.py:139] Epoch[913/1000] loss: 0.049783386049732085
I0416 10:11:03.871544 27328 trainer.py:139] Epoch[914/1000] loss: 0.048641833927362196
I0416 10:11:06.557559 27328 trainer.py:139] Epoch[915/1000] loss: 0.04844101890921593
I0416 10:11:09.189754 27328 trainer.py:139] Epoch[916/1000] loss: 0.048439660620304845
I0416 10:11:11.953507 27328 trainer.py:139] Epoch[917/1000] loss: 0.04918519996346966
I0416 10:11:14.572744 27328 trainer.py:139] Epoch[918/1000] loss: 0.048660583313434355
I0416 10:11:17.373375 27328 trainer.py:139] Epoch[919/1000] loss: 0.04863778321493056
I0416 10:11:20.187959 27328 trainer.py:139] Epoch[920/1000] loss: 0.048815088767197826
I0416 10:11:22.965667 27328 trainer.py:139] Epoch[921/1000] loss: 0.049072538051874406
I0416 10:11:25.721448 27328 trainer.py:139] Epoch[922/1000] loss: 0.04902286635291192
I0416 10:11:28.475234 27328 trainer.py:139] Epoch[923/1000] loss: 0.048212922628848784
I0416 10:11:31.160252 27328 trainer.py:139] Epoch[924/1000] loss: 0.049276323207924445
I0416 10:11:33.971846 27328 trainer.py:139] Epoch[925/1000] loss: 0.04828135969658052
I0416 10:11:36.586100 27328 trainer.py:139] Epoch[926/1000] loss: 0.048505774308596886
I0416 10:11:39.242216 27328 trainer.py:139] Epoch[927/1000] loss: 0.048170398079579874
I0416 10:11:41.905306 27328 trainer.py:139] Epoch[928/1000] loss: 0.049126550795570496
I0416 10:11:44.580356 27328 trainer.py:139] Epoch[929/1000] loss: 0.04893206612717721
I0416 10:11:47.293281 27328 trainer.py:139] Epoch[930/1000] loss: 0.04830248798093488
I0416 10:11:49.969328 27328 trainer.py:139] Epoch[931/1000] loss: 0.04854319569083952
I0416 10:11:52.702186 27328 trainer.py:139] Epoch[932/1000] loss: 0.0485208828843409
I0416 10:11:55.464943 27328 trainer.py:139] Epoch[933/1000] loss: 0.049689357199015155
I0416 10:11:58.172884 27328 trainer.py:139] Epoch[934/1000] loss: 0.04840328003610334
I0416 10:12:01.018365 27328 trainer.py:139] Epoch[935/1000] loss: 0.048658387435059396
I0416 10:12:03.803048 27328 trainer.py:139] Epoch[936/1000] loss: 0.04904958341390856
I0416 10:12:06.489063 27328 trainer.py:139] Epoch[937/1000] loss: 0.04823795970409147
I0416 10:12:09.088786 27328 trainer.py:139] Epoch[938/1000] loss: 0.04886696499682242
I0416 10:12:11.738920 27328 trainer.py:139] Epoch[939/1000] loss: 0.049638166182464166
I0416 10:12:14.300351 27328 trainer.py:139] Epoch[940/1000] loss: 0.049365418933091626
I0416 10:12:16.971415 27328 trainer.py:139] Epoch[941/1000] loss: 0.04828736041822741
I0416 10:12:19.595636 27328 trainer.py:139] Epoch[942/1000] loss: 0.04982902650390902
I0416 10:12:22.310553 27328 trainer.py:139] Epoch[943/1000] loss: 0.04932368138144093
I0416 10:12:25.087265 27328 trainer.py:139] Epoch[944/1000] loss: 0.0491143872420634
I0416 10:12:27.700521 27328 trainer.py:139] Epoch[945/1000] loss: 0.04832849759728678
I0416 10:12:30.312783 27328 trainer.py:139] Epoch[946/1000] loss: 0.048068745842864434
I0416 10:12:33.108430 27328 trainer.py:139] Epoch[947/1000] loss: 0.048749543726444244
I0416 10:12:35.833314 27328 trainer.py:139] Epoch[948/1000] loss: 0.049162598987740856
I0416 10:12:38.574145 27328 trainer.py:139] Epoch[949/1000] loss: 0.048941059578810966
I0416 10:12:38.777465 27328 trainer.py:145] Test: {'precision': 0.14075067024128693, 'recall': 0.33353049966557313, 'hit_ratio': 0.900804289544236, 'ndcg': 0.31430439205437777}
I0416 10:12:41.509326 27328 trainer.py:139] Epoch[950/1000] loss: 0.04910650224454941
I0416 10:12:44.269094 27328 trainer.py:139] Epoch[951/1000] loss: 0.048025483926457745
I0416 10:12:46.963081 27328 trainer.py:139] Epoch[952/1000] loss: 0.04910242172979539
I0416 10:12:49.711884 27328 trainer.py:139] Epoch[953/1000] loss: 0.04820314001652502
I0416 10:12:52.536435 27328 trainer.py:139] Epoch[954/1000] loss: 0.04819585394955451
I0416 10:12:55.213479 27328 trainer.py:139] Epoch[955/1000] loss: 0.048994458731143706
I0416 10:12:57.905990 27328 trainer.py:139] Epoch[956/1000] loss: 0.048851230331966956
I0416 10:13:00.695159 27328 trainer.py:139] Epoch[957/1000] loss: 0.04754717888370637
I0416 10:13:03.513731 27328 trainer.py:139] Epoch[958/1000] loss: 0.04848057584416482
I0416 10:13:06.288447 27328 trainer.py:139] Epoch[959/1000] loss: 0.0484177938872768
I0416 10:13:08.982435 27328 trainer.py:139] Epoch[960/1000] loss: 0.04923658661784664
I0416 10:13:11.636556 27328 trainer.py:139] Epoch[961/1000] loss: 0.04785259031961041
I0416 10:13:14.236856 27328 trainer.py:139] Epoch[962/1000] loss: 0.04894314021352799
I0416 10:13:16.952822 27328 trainer.py:139] Epoch[963/1000] loss: 0.048335253952010986
I0416 10:13:19.671726 27328 trainer.py:139] Epoch[964/1000] loss: 0.04805453650413021
I0416 10:13:22.241131 27328 trainer.py:139] Epoch[965/1000] loss: 0.04849152038654973
I0416 10:13:24.926148 27328 trainer.py:139] Epoch[966/1000] loss: 0.04941011965274811
I0416 10:13:27.737743 27328 trainer.py:139] Epoch[967/1000] loss: 0.048075451004889705
I0416 10:13:30.381897 27328 trainer.py:139] Epoch[968/1000] loss: 0.04789355589497474
I0416 10:13:33.088841 27328 trainer.py:139] Epoch[969/1000] loss: 0.048049622005031954
I0416 10:13:35.796782 27328 trainer.py:139] Epoch[970/1000] loss: 0.048132033237526496
I0416 10:13:38.597413 27328 trainer.py:139] Epoch[971/1000] loss: 0.04828076845695896
I0416 10:13:41.225620 27328 trainer.py:139] Epoch[972/1000] loss: 0.04812247510398588
I0416 10:13:43.921601 27328 trainer.py:139] Epoch[973/1000] loss: 0.04885219530232491
I0416 10:13:46.621568 27328 trainer.py:139] Epoch[974/1000] loss: 0.04793662001048365
I0416 10:13:49.313562 27328 trainer.py:139] Epoch[975/1000] loss: 0.047887760665147536
I0416 10:13:51.879977 27328 trainer.py:139] Epoch[976/1000] loss: 0.04971068148170748
I0416 10:13:54.463334 27328 trainer.py:139] Epoch[977/1000] loss: 0.04693529226126209
I0416 10:13:57.296855 27328 trainer.py:139] Epoch[978/1000] loss: 0.04768769370932733
I0416 10:13:59.864265 27328 trainer.py:139] Epoch[979/1000] loss: 0.04818628800492133
I0416 10:14:02.631010 27328 trainer.py:139] Epoch[980/1000] loss: 0.04849801428856388
I0416 10:14:05.228321 27328 trainer.py:139] Epoch[981/1000] loss: 0.04774922565106423
I0416 10:14:07.942241 27328 trainer.py:139] Epoch[982/1000] loss: 0.047858335077762604
I0416 10:14:10.803670 27328 trainer.py:139] Epoch[983/1000] loss: 0.049062574943227154
I0416 10:14:13.471744 27328 trainer.py:139] Epoch[984/1000] loss: 0.04896877994460444
I0416 10:14:16.154767 27328 trainer.py:139] Epoch[985/1000] loss: 0.047285552467069315
I0416 10:14:18.799329 27328 trainer.py:139] Epoch[986/1000] loss: 0.04900388551815864
I0416 10:14:21.617093 27328 trainer.py:139] Epoch[987/1000] loss: 0.049370817359416716
I0416 10:14:24.221380 27328 trainer.py:139] Epoch[988/1000] loss: 0.048338782643118215
I0416 10:14:26.983141 27328 trainer.py:139] Epoch[989/1000] loss: 0.04844570700680056
I0416 10:14:29.565487 27328 trainer.py:139] Epoch[990/1000] loss: 0.04769737345557059
I0416 10:14:32.498674 27328 trainer.py:139] Epoch[991/1000] loss: 0.048036784654663454
I0416 10:14:35.199639 27328 trainer.py:139] Epoch[992/1000] loss: 0.04787008175926824
I0416 10:14:37.915553 27328 trainer.py:139] Epoch[993/1000] loss: 0.04804756997093078
I0416 10:14:40.653307 27328 trainer.py:139] Epoch[994/1000] loss: 0.04836241816801409
I0416 10:14:43.378360 27328 trainer.py:139] Epoch[995/1000] loss: 0.0486136311965604
I0416 10:14:46.018526 27328 trainer.py:139] Epoch[996/1000] loss: 0.04849878253955995
I0416 10:14:48.683611 27328 trainer.py:139] Epoch[997/1000] loss: 0.04848301771187013
I0416 10:14:51.360655 27328 trainer.py:139] Epoch[998/1000] loss: 0.04878381844009123
I0416 10:14:54.083546 27328 trainer.py:139] Epoch[999/1000] loss: 0.04897661603266193
I0416 10:14:54.276898 27328 trainer.py:145] Test: {'precision': 0.14085790884718502, 'recall': 0.3341302434532999, 'hit_ratio': 0.900804289544236, 'ndcg': 0.31490998065621423}
