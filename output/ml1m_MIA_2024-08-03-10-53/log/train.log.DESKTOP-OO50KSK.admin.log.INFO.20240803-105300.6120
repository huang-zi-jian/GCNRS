I0803 10:53:07.862749  9752 trainer.py:119] Test: [{'precision': 0.05646911519198666, 'recall': 0.0657453663033959, 'hit_ratio': 0.44908180300500833, 'ndcg': 0.07729858763319665}]
I0803 10:53:23.503593  9752 trainer.py:139] Epoch[0/1000] loss: 0.7886945307254791
I0803 10:53:39.379859  9752 trainer.py:139] Epoch[1/1000] loss: 0.535224199295044
I0803 10:53:55.703865  9752 trainer.py:139] Epoch[2/1000] loss: 0.5110504726568857
I0803 10:54:11.119230  9752 trainer.py:139] Epoch[3/1000] loss: 0.5000899930795034
I0803 10:54:27.037872  9752 trainer.py:139] Epoch[4/1000] loss: 0.48283303280671436
I0803 10:54:43.501335  9752 trainer.py:139] Epoch[5/1000] loss: 0.46718259155750275
I0803 10:54:59.834991  9752 trainer.py:139] Epoch[6/1000] loss: 0.4481376111507416
I0803 10:55:15.878350  9752 trainer.py:139] Epoch[7/1000] loss: 0.4425087571144104
I0803 10:55:31.673725  9752 trainer.py:139] Epoch[8/1000] loss: 0.4358748495578766
I0803 10:55:47.520204  9752 trainer.py:139] Epoch[9/1000] loss: 0.43345558146635693
I0803 10:56:03.193665  9752 trainer.py:139] Epoch[10/1000] loss: 0.4303572475910187
I0803 10:56:19.029667  9752 trainer.py:139] Epoch[11/1000] loss: 0.42860473692417145
I0803 10:56:35.165616  9752 trainer.py:139] Epoch[12/1000] loss: 0.42956624428431195
I0803 10:56:50.948422  9752 trainer.py:139] Epoch[13/1000] loss: 0.4223032395044963
I0803 10:57:06.852031  9752 trainer.py:139] Epoch[14/1000] loss: 0.42543021341164905
I0803 10:57:22.262745  9752 trainer.py:139] Epoch[15/1000] loss: 0.42130466798941296
I0803 10:57:38.030273  9752 trainer.py:139] Epoch[16/1000] loss: 0.41727196673552197
I0803 10:57:53.583749  9752 trainer.py:139] Epoch[17/1000] loss: 0.4148690203825633
I0803 10:58:09.277259  9752 trainer.py:139] Epoch[18/1000] loss: 0.414238174756368
I0803 10:58:24.757900  9752 trainer.py:139] Epoch[19/1000] loss: 0.4116765509049098
I0803 10:58:40.352203  9752 trainer.py:139] Epoch[20/1000] loss: 0.41477646430333454
I0803 10:58:55.838367  9752 trainer.py:139] Epoch[21/1000] loss: 0.4092807372411092
I0803 10:59:11.557197  9752 trainer.py:139] Epoch[22/1000] loss: 0.4063718368609746
I0803 10:59:27.199144  9752 trainer.py:139] Epoch[23/1000] loss: 0.4058419813712438
I0803 10:59:42.892041  9752 trainer.py:139] Epoch[24/1000] loss: 0.4033956825733185
I0803 10:59:58.617840  9752 trainer.py:139] Epoch[25/1000] loss: 0.4008120546738307
I0803 11:00:14.336037  9752 trainer.py:139] Epoch[26/1000] loss: 0.39881787200768787
I0803 11:00:30.178182  9752 trainer.py:139] Epoch[27/1000] loss: 0.3946249137322108
I0803 11:00:45.562071  9752 trainer.py:139] Epoch[28/1000] loss: 0.3958075741926829
I0803 11:01:01.252451  9752 trainer.py:139] Epoch[29/1000] loss: 0.3956356296936671
I0803 11:01:16.900208  9752 trainer.py:139] Epoch[30/1000] loss: 0.3895120720068614
I0803 11:01:32.595043  9752 trainer.py:139] Epoch[31/1000] loss: 0.39310048520565033
I0803 11:01:48.398891  9752 trainer.py:139] Epoch[32/1000] loss: 0.38688648740450543
I0803 11:02:03.887375  9752 trainer.py:139] Epoch[33/1000] loss: 0.38302961985270184
I0803 11:02:20.014497  9752 trainer.py:139] Epoch[34/1000] loss: 0.3884879450003306
I0803 11:02:35.537820  9752 trainer.py:139] Epoch[35/1000] loss: 0.3833252191543579
I0803 11:02:51.974195  9752 trainer.py:139] Epoch[36/1000] loss: 0.38169751067956287
I0803 11:03:07.881130  9752 trainer.py:139] Epoch[37/1000] loss: 0.38052338858445484
I0803 11:03:23.636142  9752 trainer.py:139] Epoch[38/1000] loss: 0.37902091940244037
I0803 11:03:39.571971  9752 trainer.py:139] Epoch[39/1000] loss: 0.3784403403600057
I0803 11:03:55.622296  9752 trainer.py:139] Epoch[40/1000] loss: 0.37731248140335083
I0803 11:04:11.256228  9752 trainer.py:139] Epoch[41/1000] loss: 0.37876742084821063
I0803 11:04:26.871388  9752 trainer.py:139] Epoch[42/1000] loss: 0.3770526200532913
I0803 11:04:42.826803  9752 trainer.py:139] Epoch[43/1000] loss: 0.3792088230450948
I0803 11:04:58.587792  9752 trainer.py:139] Epoch[44/1000] loss: 0.37466975549856824
I0803 11:05:14.617194  9752 trainer.py:139] Epoch[45/1000] loss: 0.37311415870984393
I0803 11:05:30.496404  9752 trainer.py:139] Epoch[46/1000] loss: 0.37266819179058075
I0803 11:05:46.242801  9752 trainer.py:139] Epoch[47/1000] loss: 0.3757923096418381
I0803 11:06:01.834117  9752 trainer.py:139] Epoch[48/1000] loss: 0.37366891900698346
I0803 11:06:17.699819  9752 trainer.py:139] Epoch[49/1000] loss: 0.3695761909087499
I0803 11:06:18.274430  9752 trainer.py:145] Test: [{'precision': 0.15128547579298837, 'recall': 0.19164894871437207, 'hit_ratio': 0.8176961602671119, 'ndcg': 0.22702495010670554}]
I0803 11:06:33.877000  9752 trainer.py:139] Epoch[50/1000] loss: 0.36924904584884644
I0803 11:06:49.399995  9752 trainer.py:139] Epoch[51/1000] loss: 0.36802710096041363
I0803 11:07:04.755521  9752 trainer.py:139] Epoch[52/1000] loss: 0.3640148838361104
I0803 11:07:20.269662  9752 trainer.py:139] Epoch[53/1000] loss: 0.37025486429532367
I0803 11:07:35.748524  9752 trainer.py:139] Epoch[54/1000] loss: 0.3640199850002925
I0803 11:07:51.366281  9752 trainer.py:139] Epoch[55/1000] loss: 0.3673332134882609
I0803 11:08:07.101629  9752 trainer.py:139] Epoch[56/1000] loss: 0.3674368013938268
I0803 11:08:22.829901  9752 trainer.py:139] Epoch[57/1000] loss: 0.3667323539654414
I0803 11:08:38.456873  9752 trainer.py:139] Epoch[58/1000] loss: 0.36649265388647717
I0803 11:08:53.938117  9752 trainer.py:139] Epoch[59/1000] loss: 0.36480264365673065
I0803 11:09:09.508269  9752 trainer.py:139] Epoch[60/1000] loss: 0.36421676476796466
I0803 11:09:25.608456  9752 trainer.py:139] Epoch[61/1000] loss: 0.36627403895060223
I0803 11:09:41.347142  9752 trainer.py:139] Epoch[62/1000] loss: 0.36431126793225604
I0803 11:09:56.986585  9752 trainer.py:139] Epoch[63/1000] loss: 0.35886064171791077
I0803 11:10:12.540118  9752 trainer.py:139] Epoch[64/1000] loss: 0.36156411468982697
I0803 11:10:28.322787  9752 trainer.py:139] Epoch[65/1000] loss: 0.3589671750863393
I0803 11:10:43.748566  9752 trainer.py:139] Epoch[66/1000] loss: 0.36039218803246814
I0803 11:10:59.308161  9752 trainer.py:139] Epoch[67/1000] loss: 0.35800662636756897
I0803 11:11:14.997079  9752 trainer.py:139] Epoch[68/1000] loss: 0.3569217175245285
I0803 11:11:30.823408  9752 trainer.py:139] Epoch[69/1000] loss: 0.3585590620835622
I0803 11:11:46.649292  9752 trainer.py:139] Epoch[70/1000] loss: 0.3556956946849823
I0803 11:12:02.425500  9752 trainer.py:139] Epoch[71/1000] loss: 0.35509730875492096
I0803 11:12:18.192636  9752 trainer.py:139] Epoch[72/1000] loss: 0.3542969872554143
I0803 11:12:33.915126  9752 trainer.py:139] Epoch[73/1000] loss: 0.35191407799720764
I0803 11:12:49.434095  9752 trainer.py:139] Epoch[74/1000] loss: 0.3530069390932719
I0803 11:13:04.981294  9752 trainer.py:139] Epoch[75/1000] loss: 0.3512926350037257
I0803 11:13:20.771369  9752 trainer.py:139] Epoch[76/1000] loss: 0.3518589536348979
I0803 11:13:36.232641  9752 trainer.py:139] Epoch[77/1000] loss: 0.35194311539332074
I0803 11:13:51.862178  9752 trainer.py:139] Epoch[78/1000] loss: 0.35062191883722943
I0803 11:14:07.521126  9752 trainer.py:139] Epoch[79/1000] loss: 0.34861934185028076
I0803 11:14:23.068494  9752 trainer.py:139] Epoch[80/1000] loss: 0.3449764649073283
I0803 11:14:38.737335  9752 trainer.py:139] Epoch[81/1000] loss: 0.34834205607573193
I0803 11:14:54.488869  9752 trainer.py:139] Epoch[82/1000] loss: 0.34665557742118835
I0803 11:15:10.190588  9752 trainer.py:139] Epoch[83/1000] loss: 0.3436063677072525
I0803 11:15:25.794966  9752 trainer.py:139] Epoch[84/1000] loss: 0.3449098815520604
I0803 11:15:41.453787  9752 trainer.py:139] Epoch[85/1000] loss: 0.34513193368911743
I0803 11:15:57.060557  9752 trainer.py:139] Epoch[86/1000] loss: 0.3425063838561376
I0803 11:16:12.808941  9752 trainer.py:139] Epoch[87/1000] loss: 0.34235287209351856
I0803 11:16:28.391798  9752 trainer.py:139] Epoch[88/1000] loss: 0.34398966034253436
I0803 11:16:44.059354  9752 trainer.py:139] Epoch[89/1000] loss: 0.34332774579524994
I0803 11:16:59.633692  9752 trainer.py:139] Epoch[90/1000] loss: 0.3423246542612712
I0803 11:17:15.471739  9752 trainer.py:139] Epoch[91/1000] loss: 0.33813053866227466
I0803 11:17:31.377099  9752 trainer.py:139] Epoch[92/1000] loss: 0.33765482902526855
I0803 11:17:47.190865  9752 trainer.py:139] Epoch[93/1000] loss: 0.33864177763462067
I0803 11:18:02.777297  9752 trainer.py:139] Epoch[94/1000] loss: 0.3361492355664571
I0803 11:18:18.360883  9752 trainer.py:139] Epoch[95/1000] loss: 0.33569563428560895
I0803 11:18:33.726848  9752 trainer.py:139] Epoch[96/1000] loss: 0.33429332077503204
I0803 11:18:49.171841  9752 trainer.py:139] Epoch[97/1000] loss: 0.33817922572294873
I0803 11:19:04.986768  9752 trainer.py:139] Epoch[98/1000] loss: 0.3366401841243108
I0803 11:19:21.165917  9752 trainer.py:139] Epoch[99/1000] loss: 0.33616670469443005
I0803 11:19:21.901017  9752 trainer.py:145] Test: [{'precision': 0.15775459098497494, 'recall': 0.20552950631791422, 'hit_ratio': 0.8347245409015025, 'ndcg': 0.2388133539900403}]
I0803 11:19:37.977777  9752 trainer.py:139] Epoch[100/1000] loss: 0.33183058102925617
I0803 11:19:54.170280  9752 trainer.py:139] Epoch[101/1000] loss: 0.33672434588273364
I0803 11:20:09.844537  9752 trainer.py:139] Epoch[102/1000] loss: 0.33247366547584534
I0803 11:20:25.343075  9752 trainer.py:139] Epoch[103/1000] loss: 0.3329309771458308
I0803 11:20:40.989997  9752 trainer.py:139] Epoch[104/1000] loss: 0.332396720846494
I0803 11:20:56.986357  9752 trainer.py:139] Epoch[105/1000] loss: 0.329053670167923
I0803 11:21:12.783157  9752 trainer.py:139] Epoch[106/1000] loss: 0.3325481116771698
I0803 11:21:28.315411  9752 trainer.py:139] Epoch[107/1000] loss: 0.3278483748435974
I0803 11:21:43.985323  9752 trainer.py:139] Epoch[108/1000] loss: 0.3315722346305847
I0803 11:21:59.819202  9752 trainer.py:139] Epoch[109/1000] loss: 0.3280648738145828
I0803 11:22:15.468441  9752 trainer.py:139] Epoch[110/1000] loss: 0.3249833683172862
I0803 11:22:31.116642  9752 trainer.py:139] Epoch[111/1000] loss: 0.3271961510181427
I0803 11:22:46.612005  9752 trainer.py:139] Epoch[112/1000] loss: 0.3264283339182536
I0803 11:23:02.288383  9752 trainer.py:139] Epoch[113/1000] loss: 0.32553764681021374
I0803 11:23:17.914263  9752 trainer.py:139] Epoch[114/1000] loss: 0.32371224959691364
I0803 11:23:33.960355  9752 trainer.py:139] Epoch[115/1000] loss: 0.32469646135965985
I0803 11:23:49.701547  9752 trainer.py:139] Epoch[116/1000] loss: 0.32259133954842883
I0803 11:24:05.413959  9752 trainer.py:139] Epoch[117/1000] loss: 0.3235064794619878
I0803 11:24:21.010984  9752 trainer.py:139] Epoch[118/1000] loss: 0.3233056316773097
I0803 11:24:36.644903  9752 trainer.py:139] Epoch[119/1000] loss: 0.3202919065952301
I0803 11:24:52.172753  9752 trainer.py:139] Epoch[120/1000] loss: 0.32299667596817017
I0803 11:25:07.529756  9752 trainer.py:139] Epoch[121/1000] loss: 0.32032834986845654
I0803 11:25:23.008028  9752 trainer.py:139] Epoch[122/1000] loss: 0.3197149783372879
I0803 11:25:38.456650  9752 trainer.py:139] Epoch[123/1000] loss: 0.32067250708738965
I0803 11:25:54.021313  9752 trainer.py:139] Epoch[124/1000] loss: 0.31779587765534717
I0803 11:26:09.704083  9752 trainer.py:139] Epoch[125/1000] loss: 0.3195182184378306
I0803 11:26:26.054933  9752 trainer.py:139] Epoch[126/1000] loss: 0.3168177902698517
I0803 11:26:41.936234  9752 trainer.py:139] Epoch[127/1000] loss: 0.3171503891547521
I0803 11:26:57.634238  9752 trainer.py:139] Epoch[128/1000] loss: 0.3150050640106201
I0803 11:27:13.267921  9752 trainer.py:139] Epoch[129/1000] loss: 0.3145836144685745
I0803 11:27:29.295953  9752 trainer.py:139] Epoch[130/1000] loss: 0.3129199246565501
I0803 11:27:44.914208  9752 trainer.py:139] Epoch[131/1000] loss: 0.3122468690077464
I0803 11:28:00.692915  9752 trainer.py:139] Epoch[132/1000] loss: 0.31401901443799335
I0803 11:28:16.304315  9752 trainer.py:139] Epoch[133/1000] loss: 0.3128177871306737
I0803 11:28:32.226176  9752 trainer.py:139] Epoch[134/1000] loss: 0.3150992343823115
I0803 11:28:47.768963  9752 trainer.py:139] Epoch[135/1000] loss: 0.31151463091373444
I0803 11:29:03.015253  9752 trainer.py:139] Epoch[136/1000] loss: 0.3110225647687912
I0803 11:29:18.757699  9752 trainer.py:139] Epoch[137/1000] loss: 0.31109101076920825
I0803 11:29:34.714025  9752 trainer.py:139] Epoch[138/1000] loss: 0.3087713122367859
I0803 11:29:50.300670  9752 trainer.py:139] Epoch[139/1000] loss: 0.3085308422644933
I0803 11:30:06.130393  9752 trainer.py:139] Epoch[140/1000] loss: 0.3101235032081604
I0803 11:30:21.899613  9752 trainer.py:139] Epoch[141/1000] loss: 0.30958054463068646
I0803 11:30:37.311100  9752 trainer.py:139] Epoch[142/1000] loss: 0.30792685846487683
I0803 11:30:52.914068  9752 trainer.py:139] Epoch[143/1000] loss: 0.3086887151002884
I0803 11:31:08.496826  9752 trainer.py:139] Epoch[144/1000] loss: 0.30715136229991913
I0803 11:31:24.045942  9752 trainer.py:139] Epoch[145/1000] loss: 0.3068479001522064
I0803 11:31:39.422179  9752 trainer.py:139] Epoch[146/1000] loss: 0.3059387505054474
I0803 11:31:54.831941  9752 trainer.py:139] Epoch[147/1000] loss: 0.304202139377594
I0803 11:32:10.390526  9752 trainer.py:139] Epoch[148/1000] loss: 0.30373746653397876
I0803 11:32:26.134181  9752 trainer.py:139] Epoch[149/1000] loss: 0.30343829095363617
I0803 11:32:26.711251  9752 trainer.py:145] Test: [{'precision': 0.1644824707846411, 'recall': 0.22071747808525338, 'hit_ratio': 0.8606010016694491, 'ndcg': 0.251973667691966}]
I0803 11:32:42.683534  9752 trainer.py:139] Epoch[150/1000] loss: 0.304791659116745
I0803 11:32:58.138901  9752 trainer.py:139] Epoch[151/1000] loss: 0.30321404834588367
I0803 11:33:14.075694  9752 trainer.py:139] Epoch[152/1000] loss: 0.3028017779191335
I0803 11:33:29.754578  9752 trainer.py:139] Epoch[153/1000] loss: 0.30265237390995026
I0803 11:33:45.704831  9752 trainer.py:139] Epoch[154/1000] loss: 0.3002883891264598
I0803 11:34:01.464559  9752 trainer.py:139] Epoch[155/1000] loss: 0.30163675049940747
I0803 11:34:17.027689  9752 trainer.py:139] Epoch[156/1000] loss: 0.3014088571071625
I0803 11:34:32.595034  9752 trainer.py:139] Epoch[157/1000] loss: 0.29873716831207275
I0803 11:34:48.424878  9752 trainer.py:139] Epoch[158/1000] loss: 0.2991606493790944
I0803 11:35:03.877860  9752 trainer.py:139] Epoch[159/1000] loss: 0.2996731946865718
I0803 11:35:19.435550  9752 trainer.py:139] Epoch[160/1000] loss: 0.2968982557455699
I0803 11:35:35.463792  9752 trainer.py:139] Epoch[161/1000] loss: 0.2990103413661321
I0803 11:35:51.256129  9752 trainer.py:139] Epoch[162/1000] loss: 0.29684314131736755
I0803 11:36:06.965402  9752 trainer.py:139] Epoch[163/1000] loss: 0.2971263776222865
I0803 11:36:22.690995  9752 trainer.py:139] Epoch[164/1000] loss: 0.2959105769793193
I0803 11:36:38.435177  9752 trainer.py:139] Epoch[165/1000] loss: 0.2963475187619527
I0803 11:36:53.988986  9752 trainer.py:139] Epoch[166/1000] loss: 0.29547229409217834
I0803 11:37:09.542560  9752 trainer.py:139] Epoch[167/1000] loss: 0.29609353840351105
I0803 11:37:25.205163  9752 trainer.py:139] Epoch[168/1000] loss: 0.2953419089317322
I0803 11:37:40.652046  9752 trainer.py:139] Epoch[169/1000] loss: 0.2932000954945882
I0803 11:37:56.389415  9752 trainer.py:139] Epoch[170/1000] loss: 0.29448264837265015
I0803 11:38:11.907184  9752 trainer.py:139] Epoch[171/1000] loss: 0.28993695477644604
I0803 11:38:27.586275  9752 trainer.py:139] Epoch[172/1000] loss: 0.293549120426178
I0803 11:38:43.348317  9752 trainer.py:139] Epoch[173/1000] loss: 0.28925420840581256
I0803 11:38:59.173238  9752 trainer.py:139] Epoch[174/1000] loss: 0.29148651162783307
I0803 11:39:14.996826  9752 trainer.py:139] Epoch[175/1000] loss: 0.2879292021195094
I0803 11:39:30.832941  9752 trainer.py:139] Epoch[176/1000] loss: 0.28940795361995697
I0803 11:39:46.428876  9752 trainer.py:139] Epoch[177/1000] loss: 0.290431613723437
I0803 11:40:01.984743  9752 trainer.py:139] Epoch[178/1000] loss: 0.2874975899855296
I0803 11:40:17.577912  9752 trainer.py:139] Epoch[179/1000] loss: 0.28774427374204
I0803 11:40:33.158574  9752 trainer.py:139] Epoch[180/1000] loss: 0.28997910022735596
I0803 11:40:49.029321  9752 trainer.py:139] Epoch[181/1000] loss: 0.28634073336919147
I0803 11:41:04.548244  9752 trainer.py:139] Epoch[182/1000] loss: 0.2874123553435008
I0803 11:41:20.178282  9752 trainer.py:139] Epoch[183/1000] loss: 0.28523148596286774
I0803 11:41:36.099995  9752 trainer.py:139] Epoch[184/1000] loss: 0.28676068782806396
I0803 11:41:51.826556  9752 trainer.py:139] Epoch[185/1000] loss: 0.2868746568759282
I0803 11:42:07.704344  9752 trainer.py:139] Epoch[186/1000] loss: 0.2856196810801824
I0803 11:42:23.569455  9752 trainer.py:139] Epoch[187/1000] loss: 0.2838975638151169
I0803 11:42:39.791418  9752 trainer.py:139] Epoch[188/1000] loss: 0.2838559051354726
I0803 11:42:55.348495  9752 trainer.py:139] Epoch[189/1000] loss: 0.2849303086598714
I0803 11:43:10.873422  9752 trainer.py:139] Epoch[190/1000] loss: 0.28262126445770264
I0803 11:43:26.072600  9752 trainer.py:139] Epoch[191/1000] loss: 0.28301586707433063
I0803 11:43:41.575710  9752 trainer.py:139] Epoch[192/1000] loss: 0.28520190715789795
I0803 11:43:57.205415  9752 trainer.py:139] Epoch[193/1000] loss: 0.28224804997444153
I0803 11:44:12.783454  9752 trainer.py:139] Epoch[194/1000] loss: 0.2834984064102173
I0803 11:44:28.100554  9752 trainer.py:139] Epoch[195/1000] loss: 0.2806658347447713
I0803 11:44:43.437190  9752 trainer.py:139] Epoch[196/1000] loss: 0.2805232107639313
I0803 11:44:59.026339  9752 trainer.py:139] Epoch[197/1000] loss: 0.28166430195172626
I0803 11:45:14.302565  9752 trainer.py:139] Epoch[198/1000] loss: 0.28068260351816815
I0803 11:45:29.701864  9752 trainer.py:139] Epoch[199/1000] loss: 0.27982674539089203
I0803 11:45:30.333328  9752 trainer.py:145] Test: [{'precision': 0.17084307178631056, 'recall': 0.23356270403694818, 'hit_ratio': 0.8712854757929883, 'ndcg': 0.2634426286805567}]
I0803 11:45:45.821979  9752 trainer.py:139] Epoch[200/1000] loss: 0.2813219477732976
I0803 11:46:01.412240  9752 trainer.py:139] Epoch[201/1000] loss: 0.28060732285181683
I0803 11:46:16.930077  9752 trainer.py:139] Epoch[202/1000] loss: 0.2782939374446869
I0803 11:46:32.669412  9752 trainer.py:139] Epoch[203/1000] loss: 0.27679552137851715
I0803 11:46:48.106603  9752 trainer.py:139] Epoch[204/1000] loss: 0.2789268245299657
I0803 11:47:03.381967  9752 trainer.py:139] Epoch[205/1000] loss: 0.2794847885767619
I0803 11:47:18.952466  9752 trainer.py:139] Epoch[206/1000] loss: 0.27700262268384296
I0803 11:47:34.424346  9752 trainer.py:139] Epoch[207/1000] loss: 0.2776236931482951
I0803 11:47:49.837994  9752 trainer.py:139] Epoch[208/1000] loss: 0.2770168085892995
I0803 11:48:05.254189  9752 trainer.py:139] Epoch[209/1000] loss: 0.27631475031375885
I0803 11:48:20.626313  9752 trainer.py:139] Epoch[210/1000] loss: 0.27594534556070965
I0803 11:48:36.073203  9752 trainer.py:139] Epoch[211/1000] loss: 0.27531152466932934
I0803 11:48:51.670045  9752 trainer.py:139] Epoch[212/1000] loss: 0.27448752025763196
I0803 11:49:07.043363  9752 trainer.py:139] Epoch[213/1000] loss: 0.2729187607765198
I0803 11:49:22.280964  9752 trainer.py:139] Epoch[214/1000] loss: 0.27290889124075574
I0803 11:49:37.554346  9752 trainer.py:139] Epoch[215/1000] loss: 0.2717321962118149
I0803 11:49:53.116194  9752 trainer.py:139] Epoch[216/1000] loss: 0.27368197838465375
I0803 11:50:08.429821  9752 trainer.py:139] Epoch[217/1000] loss: 0.2723987052838008
I0803 11:50:23.794898  9752 trainer.py:139] Epoch[218/1000] loss: 0.27297259867191315
I0803 11:50:39.317982  9752 trainer.py:139] Epoch[219/1000] loss: 0.27204529941082
I0803 11:50:55.067293  9752 trainer.py:139] Epoch[220/1000] loss: 0.27041533092657727
I0803 11:51:11.118188  9752 trainer.py:139] Epoch[221/1000] loss: 0.27183016141255695
I0803 11:51:26.684906  9752 trainer.py:139] Epoch[222/1000] loss: 0.2710283895333608
I0803 11:51:42.218573  9752 trainer.py:139] Epoch[223/1000] loss: 0.27126118540763855
I0803 11:51:57.682011  9752 trainer.py:139] Epoch[224/1000] loss: 0.2709731012582779
I0803 11:52:13.323003  9752 trainer.py:139] Epoch[225/1000] loss: 0.2693051795164744
I0803 11:52:28.720429  9752 trainer.py:139] Epoch[226/1000] loss: 0.2707367241382599
I0803 11:52:44.185380  9752 trainer.py:139] Epoch[227/1000] loss: 0.2696531613667806
I0803 11:52:59.660113  9752 trainer.py:139] Epoch[228/1000] loss: 0.26864709953467053
I0803 11:53:15.356347  9752 trainer.py:139] Epoch[229/1000] loss: 0.26695463558038074
I0803 11:53:30.832262  9752 trainer.py:139] Epoch[230/1000] loss: 0.26875903209050495
I0803 11:53:46.131223  9752 trainer.py:139] Epoch[231/1000] loss: 0.26808615028858185
I0803 11:54:01.287547  9752 trainer.py:139] Epoch[232/1000] loss: 0.2679893374443054
I0803 11:54:17.029500  9752 trainer.py:139] Epoch[233/1000] loss: 0.2685656100511551
I0803 11:54:32.175926  9752 trainer.py:139] Epoch[234/1000] loss: 0.2661464711030324
I0803 11:54:47.526721  9752 trainer.py:139] Epoch[235/1000] loss: 0.267714982231458
I0803 11:55:03.065086  9752 trainer.py:139] Epoch[236/1000] loss: 0.26718054711818695
I0803 11:55:18.412868  9752 trainer.py:139] Epoch[237/1000] loss: 0.26783429086208344
I0803 11:55:33.846851  9752 trainer.py:139] Epoch[238/1000] loss: 0.2665800054868062
I0803 11:55:49.083923  9752 trainer.py:139] Epoch[239/1000] loss: 0.264944131175677
I0803 11:56:04.788816  9752 trainer.py:139] Epoch[240/1000] loss: 0.265117809176445
I0803 11:56:20.390136  9752 trainer.py:139] Epoch[241/1000] loss: 0.26460202038288116
I0803 11:56:35.770773  9752 trainer.py:139] Epoch[242/1000] loss: 0.26460403203964233
I0803 11:56:51.172688  9752 trainer.py:139] Epoch[243/1000] loss: 0.26479092240333557
I0803 11:57:06.614671  9752 trainer.py:139] Epoch[244/1000] loss: 0.2632894019285838
I0803 11:57:22.356266  9752 trainer.py:139] Epoch[245/1000] loss: 0.2638181100289027
I0803 11:57:37.732325  9752 trainer.py:139] Epoch[246/1000] loss: 0.26570698618888855
I0803 11:57:53.076151  9752 trainer.py:139] Epoch[247/1000] loss: 0.26342420279979706
I0803 11:58:08.544602  9752 trainer.py:139] Epoch[248/1000] loss: 0.2630095034837723
I0803 11:58:24.116654  9752 trainer.py:139] Epoch[249/1000] loss: 0.26152091721693677
I0803 11:58:24.713638  9752 trainer.py:145] Test: [{'precision': 0.1767863105175292, 'recall': 0.24493498513238574, 'hit_ratio': 0.8834724540901503, 'ndcg': 0.274472292299468}]
I0803 11:58:40.197177  9752 trainer.py:139] Epoch[250/1000] loss: 0.26530564328034717
I0803 11:58:55.749569  9752 trainer.py:139] Epoch[251/1000] loss: 0.26060033837954205
I0803 11:59:11.224145  9752 trainer.py:139] Epoch[252/1000] loss: 0.26158685485521954
I0803 11:59:26.672378  9752 trainer.py:139] Epoch[253/1000] loss: 0.2606838544209798
I0803 11:59:42.038870  9752 trainer.py:139] Epoch[254/1000] loss: 0.2614886909723282
I0803 11:59:57.274429  9752 trainer.py:139] Epoch[255/1000] loss: 0.26279211541016895
I0803 12:00:12.496452  9752 trainer.py:139] Epoch[256/1000] loss: 0.26092476149400073
I0803 12:00:27.933448  9752 trainer.py:139] Epoch[257/1000] loss: 0.2605653405189514
I0803 12:00:43.287497  9752 trainer.py:139] Epoch[258/1000] loss: 0.25961491962273914
I0803 12:00:58.649391  9752 trainer.py:139] Epoch[259/1000] loss: 0.26064587632815045
I0803 12:01:13.960892  9752 trainer.py:139] Epoch[260/1000] loss: 0.26057766377925873
I0803 12:01:29.338794  9752 trainer.py:139] Epoch[261/1000] loss: 0.2601071298122406
I0803 12:01:45.095253  9752 trainer.py:139] Epoch[262/1000] loss: 0.25921625395615894
I0803 12:02:00.350055  9752 trainer.py:139] Epoch[263/1000] loss: 0.2575676888227463
I0803 12:02:15.691084  9752 trainer.py:139] Epoch[264/1000] loss: 0.25913487871487934
I0803 12:02:31.046423  9752 trainer.py:139] Epoch[265/1000] loss: 0.2583954135576884
I0803 12:02:46.487375  9752 trainer.py:139] Epoch[266/1000] loss: 0.25866547723611194
I0803 12:03:01.661533  9752 trainer.py:139] Epoch[267/1000] loss: 0.25836388270060223
I0803 12:03:16.982366  9752 trainer.py:139] Epoch[268/1000] loss: 0.25742578009764355
I0803 12:03:32.660106  9752 trainer.py:139] Epoch[269/1000] loss: 0.256864458322525
I0803 12:03:48.123396  9752 trainer.py:139] Epoch[270/1000] loss: 0.2570536136627197
I0803 12:04:03.640446  9752 trainer.py:139] Epoch[271/1000] loss: 0.25738876064618427
I0803 12:04:19.054739  9752 trainer.py:139] Epoch[272/1000] loss: 0.2561311920483907
I0803 12:04:34.626621  9752 trainer.py:139] Epoch[273/1000] loss: 0.255906417965889
I0803 12:04:50.018287  9752 trainer.py:139] Epoch[274/1000] loss: 0.25613609949747723
I0803 12:05:05.372626  9752 trainer.py:139] Epoch[275/1000] loss: 0.2564268658558528
I0803 12:05:20.667898  9752 trainer.py:139] Epoch[276/1000] loss: 0.25730782747268677
I0803 12:05:36.077060  9752 trainer.py:139] Epoch[277/1000] loss: 0.25536294281482697
I0803 12:05:51.307117  9752 trainer.py:139] Epoch[278/1000] loss: 0.25585637986660004
I0803 12:06:06.527548  9752 trainer.py:139] Epoch[279/1000] loss: 0.2549521525700887
I0803 12:06:21.954143  9752 trainer.py:139] Epoch[280/1000] loss: 0.25274019688367844
I0803 12:06:37.432925  9752 trainer.py:139] Epoch[281/1000] loss: 0.2530009249846141
I0803 12:06:52.869852  9752 trainer.py:139] Epoch[282/1000] loss: 0.2560790379842122
I0803 12:07:08.094137  9752 trainer.py:139] Epoch[283/1000] loss: 0.25285224119822186
I0803 12:07:23.786250  9752 trainer.py:139] Epoch[284/1000] loss: 0.2528143872817357
I0803 12:07:39.192018  9752 trainer.py:139] Epoch[285/1000] loss: 0.2539455791314443
I0803 12:07:54.590014  9752 trainer.py:139] Epoch[286/1000] loss: 0.25248513867457706
I0803 12:08:10.312900  9752 trainer.py:139] Epoch[287/1000] loss: 0.25470295548439026
I0803 12:08:25.799118  9752 trainer.py:139] Epoch[288/1000] loss: 0.2535893072684606
I0803 12:08:41.229641  9752 trainer.py:139] Epoch[289/1000] loss: 0.2530236567060153
I0803 12:08:56.696666  9752 trainer.py:139] Epoch[290/1000] loss: 0.2525056799252828
I0803 12:09:12.198410  9752 trainer.py:139] Epoch[291/1000] loss: 0.25253326694170636
I0803 12:09:27.692470  9752 trainer.py:139] Epoch[292/1000] loss: 0.2526582529147466
I0803 12:09:43.122981  9752 trainer.py:139] Epoch[293/1000] loss: 0.2522146900494893
I0803 12:09:58.452958  9752 trainer.py:139] Epoch[294/1000] loss: 0.2517840340733528
I0803 12:10:13.789071  9752 trainer.py:139] Epoch[295/1000] loss: 0.2521739254395167
I0803 12:10:29.406776  9752 trainer.py:139] Epoch[296/1000] loss: 0.2521092966198921
I0803 12:10:44.848240  9752 trainer.py:139] Epoch[297/1000] loss: 0.24987087150414786
I0803 12:11:00.258053  9752 trainer.py:139] Epoch[298/1000] loss: 0.2507937749226888
I0803 12:11:15.772258  9752 trainer.py:139] Epoch[299/1000] loss: 0.2515311762690544
I0803 12:11:16.346180  9752 trainer.py:145] Test: [{'precision': 0.18090984974958269, 'recall': 0.2517044857938206, 'hit_ratio': 0.889482470784641, 'ndcg': 0.2811647700011795}]
I0803 12:11:31.855410  9752 trainer.py:139] Epoch[300/1000] loss: 0.25137898822625476
I0803 12:11:47.310043  9752 trainer.py:139] Epoch[301/1000] loss: 0.25066421180963516
I0803 12:12:02.512051  9752 trainer.py:139] Epoch[302/1000] loss: 0.2513272588451703
I0803 12:12:17.795433  9752 trainer.py:139] Epoch[303/1000] loss: 0.249733733634154
I0803 12:12:33.106634  9752 trainer.py:139] Epoch[304/1000] loss: 0.24993827939033508
I0803 12:12:48.381317  9752 trainer.py:139] Epoch[305/1000] loss: 0.24984686573346457
I0803 12:13:03.735482  9752 trainer.py:139] Epoch[306/1000] loss: 0.2498378430803617
I0803 12:13:19.091782  9752 trainer.py:139] Epoch[307/1000] loss: 0.248573270936807
I0803 12:13:34.351334  9752 trainer.py:139] Epoch[308/1000] loss: 0.24881305048863092
I0803 12:13:49.843702  9752 trainer.py:139] Epoch[309/1000] loss: 0.24965302646160126
I0803 12:14:05.498837  9752 trainer.py:139] Epoch[310/1000] loss: 0.24872428427139917
I0803 12:14:20.858594  9752 trainer.py:139] Epoch[311/1000] loss: 0.24702150374650955
I0803 12:14:36.480191  9752 trainer.py:139] Epoch[312/1000] loss: 0.24885201702515283
I0803 12:14:51.977216  9752 trainer.py:139] Epoch[313/1000] loss: 0.24862933903932571
I0803 12:15:07.329924  9752 trainer.py:139] Epoch[314/1000] loss: 0.24789375563462576
I0803 12:15:22.877879  9752 trainer.py:139] Epoch[315/1000] loss: 0.24843699733416238
I0803 12:15:38.314074  9752 trainer.py:139] Epoch[316/1000] loss: 0.24948208530743918
I0803 12:15:53.794528  9752 trainer.py:139] Epoch[317/1000] loss: 0.2459032560388247
I0803 12:16:09.193713  9752 trainer.py:139] Epoch[318/1000] loss: 0.24673505624135336
I0803 12:16:24.890284  9752 trainer.py:139] Epoch[319/1000] loss: 0.24814719210068384
I0803 12:16:40.194755  9752 trainer.py:139] Epoch[320/1000] loss: 0.24792853991190592
I0803 12:16:55.795673  9752 trainer.py:139] Epoch[321/1000] loss: 0.24651831885178885
I0803 12:17:11.198959  9752 trainer.py:139] Epoch[322/1000] loss: 0.24601495265960693
I0803 12:17:26.702137  9752 trainer.py:139] Epoch[323/1000] loss: 0.24564415464798608
I0803 12:17:42.218221  9752 trainer.py:139] Epoch[324/1000] loss: 0.24662699550390244
I0803 12:17:57.294371  9752 trainer.py:139] Epoch[325/1000] loss: 0.2455436736345291
I0803 12:18:12.519361  9752 trainer.py:139] Epoch[326/1000] loss: 0.24690688649813333
I0803 12:18:27.882355  9752 trainer.py:139] Epoch[327/1000] loss: 0.2459473212560018
I0803 12:18:43.297408  9752 trainer.py:139] Epoch[328/1000] loss: 0.24760620296001434
I0803 12:18:58.619049  9752 trainer.py:139] Epoch[329/1000] loss: 0.2447637990117073
I0803 12:19:13.953901  9752 trainer.py:139] Epoch[330/1000] loss: 0.2455439493060112
I0803 12:19:29.788302  9752 trainer.py:139] Epoch[331/1000] loss: 0.24582943816979727
I0803 12:19:45.001231  9752 trainer.py:139] Epoch[332/1000] loss: 0.24505405376354852
I0803 12:20:00.584827  9752 trainer.py:139] Epoch[333/1000] loss: 0.24646085500717163
I0803 12:20:16.099585  9752 trainer.py:139] Epoch[334/1000] loss: 0.24572968234618506
I0803 12:20:31.400614  9752 trainer.py:139] Epoch[335/1000] loss: 0.24363982925812402
I0803 12:20:46.713888  9752 trainer.py:139] Epoch[336/1000] loss: 0.2455114225546519
I0803 12:21:02.290416  9752 trainer.py:139] Epoch[337/1000] loss: 0.2442832663655281
I0803 12:21:17.557565  9752 trainer.py:139] Epoch[338/1000] loss: 0.24479396641254425
I0803 12:21:33.083281  9752 trainer.py:139] Epoch[339/1000] loss: 0.24300762762626013
I0803 12:21:48.757108  9752 trainer.py:139] Epoch[340/1000] loss: 0.24475950002670288
I0803 12:22:04.226170  9752 trainer.py:139] Epoch[341/1000] loss: 0.24204142888387045
I0803 12:22:19.651620  9752 trainer.py:139] Epoch[342/1000] loss: 0.24337817480166754
I0803 12:22:35.329194  9752 trainer.py:139] Epoch[343/1000] loss: 0.24187541753053665
I0803 12:22:50.852385  9752 trainer.py:139] Epoch[344/1000] loss: 0.2427747497955958
I0803 12:23:06.388492  9752 trainer.py:139] Epoch[345/1000] loss: 0.24347098420063654
I0803 12:23:21.776479  9752 trainer.py:139] Epoch[346/1000] loss: 0.24397158126036325
I0803 12:23:37.164191  9752 trainer.py:139] Epoch[347/1000] loss: 0.24374538411696753
I0803 12:23:52.346975  9752 trainer.py:139] Epoch[348/1000] loss: 0.24254424621661505
I0803 12:24:07.576051  9752 trainer.py:139] Epoch[349/1000] loss: 0.24299498399098715
I0803 12:24:08.128761  9752 trainer.py:145] Test: [{'precision': 0.18432387312186982, 'recall': 0.2572532830620042, 'hit_ratio': 0.8941569282136895, 'ndcg': 0.2865369891145028}]
I0803 12:24:23.335884  9752 trainer.py:139] Epoch[350/1000] loss: 0.24290959785381952
I0803 12:24:38.647432  9752 trainer.py:139] Epoch[351/1000] loss: 0.24165863047043482
I0803 12:24:53.797509  9752 trainer.py:139] Epoch[352/1000] loss: 0.24176222334305444
I0803 12:25:09.164707  9752 trainer.py:139] Epoch[353/1000] loss: 0.24228982627391815
I0803 12:25:24.571688  9752 trainer.py:139] Epoch[354/1000] loss: 0.24048571785291037
I0803 12:25:39.876472  9752 trainer.py:139] Epoch[355/1000] loss: 0.24095230301221213
I0803 12:25:55.154480  9752 trainer.py:139] Epoch[356/1000] loss: 0.24175590525070825
I0803 12:26:10.628820  9752 trainer.py:139] Epoch[357/1000] loss: 0.24014592667420706
I0803 12:26:26.040488  9752 trainer.py:139] Epoch[358/1000] loss: 0.24228443205356598
I0803 12:26:41.417286  9752 trainer.py:139] Epoch[359/1000] loss: 0.24056709557771683
I0803 12:26:56.877599  9752 trainer.py:139] Epoch[360/1000] loss: 0.24107510348161063
I0803 12:27:12.440597  9752 trainer.py:139] Epoch[361/1000] loss: 0.2406440650423368
I0803 12:27:27.943492  9752 trainer.py:139] Epoch[362/1000] loss: 0.2396496832370758
I0803 12:27:43.369592  9752 trainer.py:139] Epoch[363/1000] loss: 0.24132639914751053
I0803 12:27:58.799237  9752 trainer.py:139] Epoch[364/1000] loss: 0.23996074497699738
I0803 12:28:14.427031  9752 trainer.py:139] Epoch[365/1000] loss: 0.24000875651836395
I0803 12:28:29.687976  9752 trainer.py:139] Epoch[366/1000] loss: 0.24089486648639044
I0803 12:28:44.940683  9752 trainer.py:139] Epoch[367/1000] loss: 0.23962057381868362
I0803 12:29:00.242479  9752 trainer.py:139] Epoch[368/1000] loss: 0.2406604861219724
I0803 12:29:15.623914  9752 trainer.py:139] Epoch[369/1000] loss: 0.23904594282309213
I0803 12:29:31.315507  9752 trainer.py:139] Epoch[370/1000] loss: 0.24107959121465683
I0803 12:29:46.795830  9752 trainer.py:139] Epoch[371/1000] loss: 0.24095300088326135
I0803 12:30:02.075497  9752 trainer.py:139] Epoch[372/1000] loss: 0.2399975061416626
I0803 12:30:17.523033  9752 trainer.py:139] Epoch[373/1000] loss: 0.24018499503533045
I0803 12:30:32.742455  9752 trainer.py:139] Epoch[374/1000] loss: 0.2394663393497467
I0803 12:30:48.078338  9752 trainer.py:139] Epoch[375/1000] loss: 0.24006017297506332
I0803 12:31:03.691128  9752 trainer.py:139] Epoch[376/1000] loss: 0.23806019872426987
I0803 12:31:18.912909  9752 trainer.py:139] Epoch[377/1000] loss: 0.24013618876536688
I0803 12:31:34.239320  9752 trainer.py:139] Epoch[378/1000] loss: 0.24035143852233887
I0803 12:31:49.686197  9752 trainer.py:139] Epoch[379/1000] loss: 0.23963820934295654
I0803 12:32:05.417250  9752 trainer.py:139] Epoch[380/1000] loss: 0.23967655251423517
I0803 12:32:20.802735  9752 trainer.py:139] Epoch[381/1000] loss: 0.23733748495578766
I0803 12:32:36.175498  9752 trainer.py:139] Epoch[382/1000] loss: 0.23931684841712317
I0803 12:32:51.492923  9752 trainer.py:139] Epoch[383/1000] loss: 0.2375538448492686
I0803 12:33:07.260715  9752 trainer.py:139] Epoch[384/1000] loss: 0.23760425547758737
I0803 12:33:22.832727  9752 trainer.py:139] Epoch[385/1000] loss: 0.23806744813919067
I0803 12:33:38.643858  9752 trainer.py:139] Epoch[386/1000] loss: 0.23783396681149802
I0803 12:33:53.910602  9752 trainer.py:139] Epoch[387/1000] loss: 0.23774274190266928
I0803 12:34:09.628461  9752 trainer.py:139] Epoch[388/1000] loss: 0.23890183369318643
I0803 12:34:25.399591  9752 trainer.py:139] Epoch[389/1000] loss: 0.23784916599591574
I0803 12:34:40.648221  9752 trainer.py:139] Epoch[390/1000] loss: 0.23681830366452536
I0803 12:34:56.050133  9752 trainer.py:139] Epoch[391/1000] loss: 0.2384502092997233
I0803 12:35:11.404081  9752 trainer.py:139] Epoch[392/1000] loss: 0.23656414449214935
I0803 12:35:27.070444  9752 trainer.py:139] Epoch[393/1000] loss: 0.237261896332105
I0803 12:35:42.627950  9752 trainer.py:139] Epoch[394/1000] loss: 0.2365544786055883
I0803 12:35:57.951769  9752 trainer.py:139] Epoch[395/1000] loss: 0.23601550112167993
I0803 12:36:14.023798  9752 trainer.py:139] Epoch[396/1000] loss: 0.23603902012109756
I0803 12:36:30.601261  9752 trainer.py:139] Epoch[397/1000] loss: 0.23722311357657114
I0803 12:36:47.182244  9752 trainer.py:139] Epoch[398/1000] loss: 0.23707232375939688
I0803 12:37:03.464138  9752 trainer.py:139] Epoch[399/1000] loss: 0.23770990471045175
I0803 12:37:04.055685  9752 trainer.py:145] Test: [{'precision': 0.18645242070116863, 'recall': 0.2603263277186695, 'hit_ratio': 0.8959933222036728, 'ndcg': 0.2906993147982984}]
I0803 12:37:20.257512  9752 trainer.py:139] Epoch[400/1000] loss: 0.23553883284330368
I0803 12:37:36.111578  9752 trainer.py:139] Epoch[401/1000] loss: 0.23550273974736533
I0803 12:37:52.110508  9752 trainer.py:139] Epoch[402/1000] loss: 0.23674753805001578
I0803 12:38:08.424375  9752 trainer.py:139] Epoch[403/1000] loss: 0.23688487460215887
I0803 12:38:24.705940  9752 trainer.py:139] Epoch[404/1000] loss: 0.2357154687245687
I0803 12:38:40.902892  9752 trainer.py:139] Epoch[405/1000] loss: 0.23717866092920303
I0803 12:38:56.696192  9752 trainer.py:139] Epoch[406/1000] loss: 0.23703608910242716
I0803 12:39:12.371659  9752 trainer.py:139] Epoch[407/1000] loss: 0.23470318565766016
I0803 12:39:28.279328  9752 trainer.py:139] Epoch[408/1000] loss: 0.23669605205456415
I0803 12:39:44.612754  9752 trainer.py:139] Epoch[409/1000] loss: 0.23558766643206278
I0803 12:40:00.255949  9752 trainer.py:139] Epoch[410/1000] loss: 0.23622549821933111
I0803 12:40:15.877341  9752 trainer.py:139] Epoch[411/1000] loss: 0.23541622360547385
I0803 12:40:31.711185  9752 trainer.py:139] Epoch[412/1000] loss: 0.2361559917529424
I0803 12:40:47.218773  9752 trainer.py:139] Epoch[413/1000] loss: 0.23513120164473852
I0803 12:41:03.111306  9752 trainer.py:139] Epoch[414/1000] loss: 0.23459525406360626
I0803 12:41:18.904497  9752 trainer.py:139] Epoch[415/1000] loss: 0.23488164444764456
I0803 12:41:35.065250  9752 trainer.py:139] Epoch[416/1000] loss: 0.23621961971124014
I0803 12:41:50.842385  9752 trainer.py:139] Epoch[417/1000] loss: 0.2350980540116628
I0803 12:42:06.790687  9752 trainer.py:139] Epoch[418/1000] loss: 0.23451549311478934
I0803 12:42:22.347157  9752 trainer.py:139] Epoch[419/1000] loss: 0.23551729818185171
I0803 12:42:38.087712  9752 trainer.py:139] Epoch[420/1000] loss: 0.23416808744271597
I0803 12:42:53.449536  9752 trainer.py:139] Epoch[421/1000] loss: 0.23478742937246957
I0803 12:43:09.020554  9752 trainer.py:139] Epoch[422/1000] loss: 0.23424339046080908
I0803 12:43:24.775160  9752 trainer.py:139] Epoch[423/1000] loss: 0.23438537369171777
I0803 12:43:40.422401  9752 trainer.py:139] Epoch[424/1000] loss: 0.23453756173451742
I0803 12:43:56.134809  9752 trainer.py:139] Epoch[425/1000] loss: 0.23390022168556848
I0803 12:44:11.787535  9752 trainer.py:139] Epoch[426/1000] loss: 0.23248722404241562
I0803 12:44:27.558611  9752 trainer.py:139] Epoch[427/1000] loss: 0.23443473875522614
I0803 12:44:43.450041  9752 trainer.py:139] Epoch[428/1000] loss: 0.23564091324806213
I0803 12:44:59.122134  9752 trainer.py:139] Epoch[429/1000] loss: 0.23418415089448294
I0803 12:45:15.033621  9752 trainer.py:139] Epoch[430/1000] loss: 0.23367268840471903
I0803 12:45:31.329760  9752 trainer.py:139] Epoch[431/1000] loss: 0.23384774724642435
I0803 12:45:47.148594  9752 trainer.py:139] Epoch[432/1000] loss: 0.23362757762273154
I0803 12:46:02.944811  9752 trainer.py:139] Epoch[433/1000] loss: 0.2338099479675293
I0803 12:46:18.614460  9752 trainer.py:139] Epoch[434/1000] loss: 0.23406821489334106
I0803 12:46:34.263787  9752 trainer.py:139] Epoch[435/1000] loss: 0.2329238305489222
I0803 12:46:50.181060  9752 trainer.py:139] Epoch[436/1000] loss: 0.23328542212645212
I0803 12:47:05.782341  9752 trainer.py:139] Epoch[437/1000] loss: 0.23186804602543512
I0803 12:47:21.663569  9752 trainer.py:139] Epoch[438/1000] loss: 0.23313949008782706
I0803 12:47:37.775328  9752 trainer.py:139] Epoch[439/1000] loss: 0.23226617276668549
I0803 12:47:53.401221  9752 trainer.py:139] Epoch[440/1000] loss: 0.2323936621348063
I0803 12:48:09.427195  9752 trainer.py:139] Epoch[441/1000] loss: 0.23235550274451575
I0803 12:48:25.419638  9752 trainer.py:139] Epoch[442/1000] loss: 0.2327563539147377
I0803 12:48:41.370615  9752 trainer.py:139] Epoch[443/1000] loss: 0.23075314859549204
I0803 12:48:57.095646  9752 trainer.py:139] Epoch[444/1000] loss: 0.23266969621181488
I0803 12:49:12.835472  9752 trainer.py:139] Epoch[445/1000] loss: 0.23168500264485678
I0803 12:49:28.567271  9752 trainer.py:139] Epoch[446/1000] loss: 0.23163804163535437
I0803 12:49:44.068791  9752 trainer.py:139] Epoch[447/1000] loss: 0.23125605036815008
I0803 12:49:59.796610  9752 trainer.py:139] Epoch[448/1000] loss: 0.23323486497004828
I0803 12:50:15.516725  9752 trainer.py:139] Epoch[449/1000] loss: 0.23335733513037363
I0803 12:50:16.159115  9752 trainer.py:145] Test: [{'precision': 0.18860601001669444, 'recall': 0.2640351920179831, 'hit_ratio': 0.8979966611018364, 'ndcg': 0.2949092131285628}]
I0803 12:50:31.889537  9752 trainer.py:139] Epoch[450/1000] loss: 0.23036741216977438
I0803 12:50:47.714842  9752 trainer.py:139] Epoch[451/1000] loss: 0.23039753238360086
I0803 12:51:03.498921  9752 trainer.py:139] Epoch[452/1000] loss: 0.23165416220823923
I0803 12:51:19.708653  9752 trainer.py:139] Epoch[453/1000] loss: 0.2300246780117353
I0803 12:51:36.054037  9752 trainer.py:139] Epoch[454/1000] loss: 0.2307742809255918
I0803 12:51:51.674189  9752 trainer.py:139] Epoch[455/1000] loss: 0.23141376922527948
I0803 12:52:07.702601  9752 trainer.py:139] Epoch[456/1000] loss: 0.23010970652103424
I0803 12:52:23.554783  9752 trainer.py:139] Epoch[457/1000] loss: 0.23053150872389475
I0803 12:52:39.140523  9752 trainer.py:139] Epoch[458/1000] loss: 0.23019879311323166
I0803 12:52:54.618987  9752 trainer.py:139] Epoch[459/1000] loss: 0.23086053878068924
I0803 12:53:10.171949  9752 trainer.py:139] Epoch[460/1000] loss: 0.23135041942199072
I0803 12:53:26.611583  9752 trainer.py:139] Epoch[461/1000] loss: 0.23176061610380808
I0803 12:53:42.470025  9752 trainer.py:139] Epoch[462/1000] loss: 0.23092462122440338
I0803 12:53:58.526623  9752 trainer.py:139] Epoch[463/1000] loss: 0.23082584887742996
I0803 12:54:14.232906  9752 trainer.py:139] Epoch[464/1000] loss: 0.23094088087479273
I0803 12:54:29.908906  9752 trainer.py:139] Epoch[465/1000] loss: 0.23056870698928833
I0803 12:54:45.944917  9752 trainer.py:139] Epoch[466/1000] loss: 0.23026526967684427
I0803 12:55:01.484599  9752 trainer.py:139] Epoch[467/1000] loss: 0.22925429294506708
I0803 12:55:17.484131  9752 trainer.py:139] Epoch[468/1000] loss: 0.22934506585200629
I0803 12:55:33.302318  9752 trainer.py:139] Epoch[469/1000] loss: 0.23104125758012137
I0803 12:55:48.784450  9752 trainer.py:139] Epoch[470/1000] loss: 0.2298973153034846
I0803 12:56:04.449604  9752 trainer.py:139] Epoch[471/1000] loss: 0.23003250112136206
I0803 12:56:20.474601  9752 trainer.py:139] Epoch[472/1000] loss: 0.23018215845028558
I0803 12:56:36.510970  9752 trainer.py:139] Epoch[473/1000] loss: 0.2310019681851069
I0803 12:56:52.348072  9752 trainer.py:139] Epoch[474/1000] loss: 0.23075479517380396
I0803 12:57:08.341290  9752 trainer.py:139] Epoch[475/1000] loss: 0.2294336979587873
I0803 12:57:24.271025  9752 trainer.py:139] Epoch[476/1000] loss: 0.22936190913120905
I0803 12:57:40.687780  9752 trainer.py:139] Epoch[477/1000] loss: 0.22935816397269568
I0803 12:57:56.895241  9752 trainer.py:139] Epoch[478/1000] loss: 0.22933816661437353
I0803 12:58:12.669952  9752 trainer.py:139] Epoch[479/1000] loss: 0.2287896846731504
I0803 12:58:28.762082  9752 trainer.py:139] Epoch[480/1000] loss: 0.22892500956853232
I0803 12:58:44.319058  9752 trainer.py:139] Epoch[481/1000] loss: 0.22857019305229187
I0803 12:58:59.834127  9752 trainer.py:139] Epoch[482/1000] loss: 0.2304327388604482
I0803 12:59:15.926946  9752 trainer.py:139] Epoch[483/1000] loss: 0.2296815738081932
I0803 12:59:32.094798  9752 trainer.py:139] Epoch[484/1000] loss: 0.22787092129389444
I0803 12:59:47.953260  9752 trainer.py:139] Epoch[485/1000] loss: 0.22916175425052643
I0803 13:00:03.926066  9752 trainer.py:139] Epoch[486/1000] loss: 0.22959116101264954
I0803 13:00:19.612572  9752 trainer.py:139] Epoch[487/1000] loss: 0.22843709339698157
I0803 13:00:35.254294  9752 trainer.py:139] Epoch[488/1000] loss: 0.23066200067599615
I0803 13:00:51.107237  9752 trainer.py:139] Epoch[489/1000] loss: 0.2290121242403984
I0803 13:01:06.606983  9752 trainer.py:139] Epoch[490/1000] loss: 0.22863611578941345
I0803 13:01:22.255573  9752 trainer.py:139] Epoch[491/1000] loss: 0.22842248032490411
I0803 13:01:37.915189  9752 trainer.py:139] Epoch[492/1000] loss: 0.22908730804920197
I0803 13:01:53.809119  9752 trainer.py:139] Epoch[493/1000] loss: 0.22831167032321295
I0803 13:02:09.673567  9752 trainer.py:139] Epoch[494/1000] loss: 0.22818782925605774
I0803 13:02:25.367945  9752 trainer.py:139] Epoch[495/1000] loss: 0.2280563140908877
I0803 13:02:40.972970  9752 trainer.py:139] Epoch[496/1000] loss: 0.2289663627743721
I0803 13:02:56.856915  9752 trainer.py:139] Epoch[497/1000] loss: 0.22780067722002664
I0803 13:03:12.618654  9752 trainer.py:139] Epoch[498/1000] loss: 0.22758806000153223
I0803 13:03:28.553399  9752 trainer.py:139] Epoch[499/1000] loss: 0.22887883335351944
I0803 13:03:29.146006  9752 trainer.py:145] Test: [{'precision': 0.18975792988313858, 'recall': 0.26525470445217275, 'hit_ratio': 0.898330550918197, 'ndcg': 0.2965330844345881}]
I0803 13:03:45.224886  9752 trainer.py:139] Epoch[500/1000] loss: 0.22785483300685883
I0803 13:04:01.008925  9752 trainer.py:139] Epoch[501/1000] loss: 0.22768341253201166
I0803 13:04:16.957723  9752 trainer.py:139] Epoch[502/1000] loss: 0.2268648917476336
I0803 13:04:33.062822  9752 trainer.py:139] Epoch[503/1000] loss: 0.22889050096273422
I0803 13:04:48.933927  9752 trainer.py:139] Epoch[504/1000] loss: 0.22768077005942663
I0803 13:05:04.660641  9752 trainer.py:139] Epoch[505/1000] loss: 0.22719532003005347
I0803 13:05:20.618609  9752 trainer.py:139] Epoch[506/1000] loss: 0.2280601809422175
I0803 13:05:36.483373  9752 trainer.py:139] Epoch[507/1000] loss: 0.22777564575274786
I0803 13:05:52.446036  9752 trainer.py:139] Epoch[508/1000] loss: 0.2271715303262075
I0803 13:06:08.023853  9752 trainer.py:139] Epoch[509/1000] loss: 0.22587033112843832
I0803 13:06:23.851979  9752 trainer.py:139] Epoch[510/1000] loss: 0.2276830996076266
I0803 13:06:39.552629  9752 trainer.py:139] Epoch[511/1000] loss: 0.22686042388280234
I0803 13:06:55.052233  9752 trainer.py:139] Epoch[512/1000] loss: 0.22854871799548468
I0803 13:07:10.649354  9752 trainer.py:139] Epoch[513/1000] loss: 0.22720741977294287
I0803 13:07:26.340872  9752 trainer.py:139] Epoch[514/1000] loss: 0.22678446273008981
I0803 13:07:41.875380  9752 trainer.py:139] Epoch[515/1000] loss: 0.22801716377337775
I0803 13:07:57.709815  9752 trainer.py:139] Epoch[516/1000] loss: 0.22632462034622827
I0803 13:08:13.447177  9752 trainer.py:139] Epoch[517/1000] loss: 0.2263389378786087
I0803 13:08:29.362039  9752 trainer.py:139] Epoch[518/1000] loss: 0.2276855632662773
I0803 13:08:45.361088  9752 trainer.py:139] Epoch[519/1000] loss: 0.2255877430240313
I0803 13:09:01.401447  9752 trainer.py:139] Epoch[520/1000] loss: 0.22662926216920218
I0803 13:09:17.139744  9752 trainer.py:139] Epoch[521/1000] loss: 0.2260385975241661
I0803 13:09:33.080579  9752 trainer.py:139] Epoch[522/1000] loss: 0.22735654066006342
I0803 13:09:48.938262  9752 trainer.py:139] Epoch[523/1000] loss: 0.22806663562854132
I0803 13:10:04.733367  9752 trainer.py:139] Epoch[524/1000] loss: 0.22599810113509497
I0803 13:10:20.438868  9752 trainer.py:139] Epoch[525/1000] loss: 0.2265480955441793
I0803 13:10:36.358423  9752 trainer.py:139] Epoch[526/1000] loss: 0.22628450393676758
I0803 13:10:52.365160  9752 trainer.py:139] Epoch[527/1000] loss: 0.227287491162618
I0803 13:11:07.994616  9752 trainer.py:139] Epoch[528/1000] loss: 0.22606583187977472
I0803 13:11:24.034589  9752 trainer.py:139] Epoch[529/1000] loss: 0.2256979395945867
I0803 13:11:40.000769  9752 trainer.py:139] Epoch[530/1000] loss: 0.22604953994353613
I0803 13:11:55.848311  9752 trainer.py:139] Epoch[531/1000] loss: 0.22536533574263254
I0803 13:12:11.726793  9752 trainer.py:139] Epoch[532/1000] loss: 0.22692082822322845
I0803 13:12:27.520879  9752 trainer.py:139] Epoch[533/1000] loss: 0.22560087591409683
I0803 13:12:43.123665  9752 trainer.py:139] Epoch[534/1000] loss: 0.2272037168343862
I0803 13:12:58.767395  9752 trainer.py:139] Epoch[535/1000] loss: 0.2255037228266398
I0803 13:13:14.107004  9752 trainer.py:139] Epoch[536/1000] loss: 0.2260712335507075
I0803 13:13:29.761289  9752 trainer.py:139] Epoch[537/1000] loss: 0.22612434873978296
I0803 13:13:45.768127  9752 trainer.py:139] Epoch[538/1000] loss: 0.22724312792221704
I0803 13:14:01.272705  9752 trainer.py:139] Epoch[539/1000] loss: 0.22638003279765448
I0803 13:14:17.074119  9752 trainer.py:139] Epoch[540/1000] loss: 0.22681202491124472
I0803 13:14:32.786655  9752 trainer.py:139] Epoch[541/1000] loss: 0.22662603110074997
I0803 13:14:48.545483  9752 trainer.py:139] Epoch[542/1000] loss: 0.2257472351193428
I0803 13:15:04.202128  9752 trainer.py:139] Epoch[543/1000] loss: 0.225117360552152
I0803 13:15:20.163260  9752 trainer.py:139] Epoch[544/1000] loss: 0.2250238135457039
I0803 13:15:35.986436  9752 trainer.py:139] Epoch[545/1000] loss: 0.22630990793307623
I0803 13:15:51.842558  9752 trainer.py:139] Epoch[546/1000] loss: 0.2246196394165357
I0803 13:16:07.990168  9752 trainer.py:139] Epoch[547/1000] loss: 0.2244277223944664
I0803 13:16:23.675784  9752 trainer.py:139] Epoch[548/1000] loss: 0.22586719691753387
I0803 13:16:39.356964  9752 trainer.py:139] Epoch[549/1000] loss: 0.22584972282250723
I0803 13:16:39.986429  9752 trainer.py:145] Test: [{'precision': 0.1914357262103506, 'recall': 0.2683429916113329, 'hit_ratio': 0.9003338898163606, 'ndcg': 0.299500453332973}]
I0803 13:16:55.498226  9752 trainer.py:139] Epoch[550/1000] loss: 0.22558077424764633
I0803 13:17:11.314846  9752 trainer.py:139] Epoch[551/1000] loss: 0.22588530679543814
I0803 13:17:27.087589  9752 trainer.py:139] Epoch[552/1000] loss: 0.22418300062417984
I0803 13:17:42.927222  9752 trainer.py:139] Epoch[553/1000] loss: 0.22463557620843252
I0803 13:17:58.575180  9752 trainer.py:139] Epoch[554/1000] loss: 0.22442352026700974
I0803 13:18:14.274801  9752 trainer.py:139] Epoch[555/1000] loss: 0.2251544619599978
I0803 13:18:29.962411  9752 trainer.py:139] Epoch[556/1000] loss: 0.22498349845409393
I0803 13:18:46.040675  9752 trainer.py:139] Epoch[557/1000] loss: 0.22530319541692734
I0803 13:19:01.465612  9752 trainer.py:139] Epoch[558/1000] loss: 0.22556542108456293
I0803 13:19:17.049263  9752 trainer.py:139] Epoch[559/1000] loss: 0.22591176877419153
I0803 13:19:32.953060  9752 trainer.py:139] Epoch[560/1000] loss: 0.22496703267097473
I0803 13:19:48.585754  9752 trainer.py:139] Epoch[561/1000] loss: 0.22497213383515677
I0803 13:20:04.132585  9752 trainer.py:139] Epoch[562/1000] loss: 0.22318903853495917
I0803 13:20:19.736123  9752 trainer.py:139] Epoch[563/1000] loss: 0.2240952973564466
I0803 13:20:35.487860  9752 trainer.py:139] Epoch[564/1000] loss: 0.22350862373908362
I0803 13:20:51.257303  9752 trainer.py:139] Epoch[565/1000] loss: 0.22441090643405914
I0803 13:21:07.027906  9752 trainer.py:139] Epoch[566/1000] loss: 0.2246826315919558
I0803 13:21:22.779213  9752 trainer.py:139] Epoch[567/1000] loss: 0.22389023999373117
I0803 13:21:38.560821  9752 trainer.py:139] Epoch[568/1000] loss: 0.22500604639450708
I0803 13:21:54.628132  9752 trainer.py:139] Epoch[569/1000] loss: 0.2240639626979828
I0803 13:22:10.338644  9752 trainer.py:139] Epoch[570/1000] loss: 0.22416950017213821
I0803 13:22:26.236371  9752 trainer.py:139] Epoch[571/1000] loss: 0.22472409904003143
I0803 13:22:41.813357  9752 trainer.py:139] Epoch[572/1000] loss: 0.2254277542233467
I0803 13:22:57.274879  9752 trainer.py:139] Epoch[573/1000] loss: 0.22387143969535828
I0803 13:23:13.096150  9752 trainer.py:139] Epoch[574/1000] loss: 0.22417408227920532
I0803 13:23:29.339782  9752 trainer.py:139] Epoch[575/1000] loss: 0.22300096352895102
I0803 13:23:45.205453  9752 trainer.py:139] Epoch[576/1000] loss: 0.22469856838385263
I0803 13:24:01.280287  9752 trainer.py:139] Epoch[577/1000] loss: 0.2244072730342547
I0803 13:24:17.008493  9752 trainer.py:139] Epoch[578/1000] loss: 0.2239421233534813
I0803 13:24:32.685431  9752 trainer.py:139] Epoch[579/1000] loss: 0.22511424124240875
I0803 13:24:48.489751  9752 trainer.py:139] Epoch[580/1000] loss: 0.22461233784755072
I0803 13:25:04.139539  9752 trainer.py:139] Epoch[581/1000] loss: 0.22451521456241608
I0803 13:25:20.093320  9752 trainer.py:139] Epoch[582/1000] loss: 0.2244421218832334
I0803 13:25:36.023938  9752 trainer.py:139] Epoch[583/1000] loss: 0.22176686922709146
I0803 13:25:51.565308  9752 trainer.py:139] Epoch[584/1000] loss: 0.2233043983578682
I0803 13:26:07.388458  9752 trainer.py:139] Epoch[585/1000] loss: 0.2244789575537046
I0803 13:26:23.204796  9752 trainer.py:139] Epoch[586/1000] loss: 0.223104327917099
I0803 13:26:39.060530  9752 trainer.py:139] Epoch[587/1000] loss: 0.22387528667847315
I0803 13:26:54.739472  9752 trainer.py:139] Epoch[588/1000] loss: 0.22239183634519577
I0803 13:27:10.416826  9752 trainer.py:139] Epoch[589/1000] loss: 0.22219977776209512
I0803 13:27:26.740222  9752 trainer.py:139] Epoch[590/1000] loss: 0.22453594704469046
I0803 13:27:42.639721  9752 trainer.py:139] Epoch[591/1000] loss: 0.2231824497381846
I0803 13:27:58.433092  9752 trainer.py:139] Epoch[592/1000] loss: 0.22350030144055685
I0803 13:28:14.260144  9752 trainer.py:139] Epoch[593/1000] loss: 0.22334307680527368
I0803 13:28:29.959815  9752 trainer.py:139] Epoch[594/1000] loss: 0.22290820131699243
I0803 13:28:45.536975  9752 trainer.py:139] Epoch[595/1000] loss: 0.22360555827617645
I0803 13:29:01.198489  9752 trainer.py:139] Epoch[596/1000] loss: 0.22303051253159842
I0803 13:29:16.934279  9752 trainer.py:139] Epoch[597/1000] loss: 0.22325890759627023
I0803 13:29:32.726781  9752 trainer.py:139] Epoch[598/1000] loss: 0.22236236184835434
I0803 13:29:48.859252  9752 trainer.py:139] Epoch[599/1000] loss: 0.2248201643427213
I0803 13:29:49.419378  9752 trainer.py:145] Test: [{'precision': 0.19199499165275455, 'recall': 0.26958016428741993, 'hit_ratio': 0.9021702838063439, 'ndcg': 0.30083275151141886}]
I0803 13:30:05.084053  9752 trainer.py:139] Epoch[600/1000] loss: 0.22281057139237723
I0803 13:30:20.881415  9752 trainer.py:139] Epoch[601/1000] loss: 0.22307262818018594
I0803 13:30:36.521136  9752 trainer.py:139] Epoch[602/1000] loss: 0.221672922372818
I0803 13:30:52.212492  9752 trainer.py:139] Epoch[603/1000] loss: 0.22261876612901688
I0803 13:31:07.887963  9752 trainer.py:139] Epoch[604/1000] loss: 0.22281823555628458
I0803 13:31:23.474467  9752 trainer.py:139] Epoch[605/1000] loss: 0.22237102687358856
I0803 13:31:38.912827  9752 trainer.py:139] Epoch[606/1000] loss: 0.22231738020976385
I0803 13:31:54.950691  9752 trainer.py:139] Epoch[607/1000] loss: 0.22325986375411352
I0803 13:32:10.864025  9752 trainer.py:139] Epoch[608/1000] loss: 0.22246755907932916
I0803 13:32:26.439267  9752 trainer.py:139] Epoch[609/1000] loss: 0.22174225747585297
I0803 13:32:42.045004  9752 trainer.py:139] Epoch[610/1000] loss: 0.22214289009571075
I0803 13:32:58.023555  9752 trainer.py:139] Epoch[611/1000] loss: 0.2209299529592196
I0803 13:33:14.114888  9752 trainer.py:139] Epoch[612/1000] loss: 0.22120046118895212
I0803 13:33:30.064086  9752 trainer.py:139] Epoch[613/1000] loss: 0.22241112838188806
I0803 13:33:45.939901  9752 trainer.py:139] Epoch[614/1000] loss: 0.22217176606257757
I0803 13:34:01.573961  9752 trainer.py:139] Epoch[615/1000] loss: 0.22095303485790888
I0803 13:34:17.514530  9752 trainer.py:139] Epoch[616/1000] loss: 0.22107706467310587
I0803 13:34:33.097157  9752 trainer.py:139] Epoch[617/1000] loss: 0.22265871614217758
I0803 13:34:48.958461  9752 trainer.py:139] Epoch[618/1000] loss: 0.22243675341208777
I0803 13:35:04.804505  9752 trainer.py:139] Epoch[619/1000] loss: 0.22183511654535928
I0803 13:35:20.752107  9752 trainer.py:139] Epoch[620/1000] loss: 0.22005642453829447
I0803 13:35:37.511486  9752 trainer.py:139] Epoch[621/1000] loss: 0.22198359916607538
I0803 13:35:53.440717  9752 trainer.py:139] Epoch[622/1000] loss: 0.22179962197939554
I0803 13:36:09.263559  9752 trainer.py:139] Epoch[623/1000] loss: 0.221679096420606
I0803 13:36:25.060923  9752 trainer.py:139] Epoch[624/1000] loss: 0.22304573406775793
I0803 13:36:40.957266  9752 trainer.py:139] Epoch[625/1000] loss: 0.2212460165222486
I0803 13:36:56.690953  9752 trainer.py:139] Epoch[626/1000] loss: 0.22293958316246668
I0803 13:37:12.329579  9752 trainer.py:139] Epoch[627/1000] loss: 0.22150814284880957
I0803 13:37:27.915277  9752 trainer.py:139] Epoch[628/1000] loss: 0.22191249330838522
I0803 13:37:43.791948  9752 trainer.py:139] Epoch[629/1000] loss: 0.22093900789817175
I0803 13:37:59.215105  9752 trainer.py:139] Epoch[630/1000] loss: 0.22182305653889975
I0803 13:38:15.000932  9752 trainer.py:139] Epoch[631/1000] loss: 0.2204600696762403
I0803 13:38:30.732741  9752 trainer.py:139] Epoch[632/1000] loss: 0.22095263004302979
I0803 13:38:46.415989  9752 trainer.py:139] Epoch[633/1000] loss: 0.21945209801197052
I0803 13:39:02.316549  9752 trainer.py:139] Epoch[634/1000] loss: 0.22024752696355185
I0803 13:39:18.185338  9752 trainer.py:139] Epoch[635/1000] loss: 0.22144602735837302
I0803 13:39:33.793771  9752 trainer.py:139] Epoch[636/1000] loss: 0.22059861570596695
I0803 13:39:49.799436  9752 trainer.py:139] Epoch[637/1000] loss: 0.22103672722975412
I0803 13:40:05.796846  9752 trainer.py:139] Epoch[638/1000] loss: 0.21949018041292825
I0803 13:40:21.725071  9752 trainer.py:139] Epoch[639/1000] loss: 0.22220608095328012
I0803 13:40:37.497928  9752 trainer.py:139] Epoch[640/1000] loss: 0.22041195134321848
I0803 13:40:53.280648  9752 trainer.py:139] Epoch[641/1000] loss: 0.21940669417381287
I0803 13:41:09.055763  9752 trainer.py:139] Epoch[642/1000] loss: 0.21980664879083633
I0803 13:41:25.335106  9752 trainer.py:139] Epoch[643/1000] loss: 0.21991348266601562
I0803 13:41:41.368521  9752 trainer.py:139] Epoch[644/1000] loss: 0.21922174096107483
I0803 13:41:57.099006  9752 trainer.py:139] Epoch[645/1000] loss: 0.21949896464745203
I0803 13:42:12.907439  9752 trainer.py:139] Epoch[646/1000] loss: 0.22075878580411276
I0803 13:42:28.660065  9752 trainer.py:139] Epoch[647/1000] loss: 0.22047052532434464
I0803 13:42:44.360219  9752 trainer.py:139] Epoch[648/1000] loss: 0.2206714948018392
I0803 13:42:59.857170  9752 trainer.py:139] Epoch[649/1000] loss: 0.2196039284269015
I0803 13:43:00.428259  9752 trainer.py:145] Test: [{'precision': 0.19282971619365602, 'recall': 0.27112575873088257, 'hit_ratio': 0.9038397328881469, 'ndcg': 0.3023673842163831}]
I0803 13:43:15.823483  9752 trainer.py:139] Epoch[650/1000] loss: 0.21985199054082236
I0803 13:43:31.719936  9752 trainer.py:139] Epoch[651/1000] loss: 0.2208237200975418
I0803 13:43:47.536131  9752 trainer.py:139] Epoch[652/1000] loss: 0.21919209510087967
I0803 13:44:03.327845  9752 trainer.py:139] Epoch[653/1000] loss: 0.21873290836811066
I0803 13:44:19.296782  9752 trainer.py:139] Epoch[654/1000] loss: 0.22068477670351663
I0803 13:44:34.822202  9752 trainer.py:139] Epoch[655/1000] loss: 0.2197046826283137
I0803 13:44:50.824536  9752 trainer.py:139] Epoch[656/1000] loss: 0.22005225966374078
I0803 13:45:06.803002  9752 trainer.py:139] Epoch[657/1000] loss: 0.22035652647415796
I0803 13:45:22.916054  9752 trainer.py:139] Epoch[658/1000] loss: 0.2196249638994535
I0803 13:45:39.001658  9752 trainer.py:139] Epoch[659/1000] loss: 0.22039265433947244
I0803 13:45:54.612785  9752 trainer.py:139] Epoch[660/1000] loss: 0.22106659412384033
I0803 13:46:10.299230  9752 trainer.py:139] Epoch[661/1000] loss: 0.21928677707910538
I0803 13:46:26.167098  9752 trainer.py:139] Epoch[662/1000] loss: 0.21807234237591425
I0803 13:46:41.946625  9752 trainer.py:139] Epoch[663/1000] loss: 0.2190303628643354
I0803 13:46:57.465256  9752 trainer.py:139] Epoch[664/1000] loss: 0.2196744034687678
I0803 13:47:13.548943  9752 trainer.py:139] Epoch[665/1000] loss: 0.22015959521134695
I0803 13:47:29.577546  9752 trainer.py:139] Epoch[666/1000] loss: 0.2189432978630066
I0803 13:47:45.478844  9752 trainer.py:139] Epoch[667/1000] loss: 0.21981298426787058
I0803 13:48:01.040938  9752 trainer.py:139] Epoch[668/1000] loss: 0.21978271007537842
I0803 13:48:16.695059  9752 trainer.py:139] Epoch[669/1000] loss: 0.21991535276174545
I0803 13:48:32.289414  9752 trainer.py:139] Epoch[670/1000] loss: 0.21871044983466467
I0803 13:48:48.463109  9752 trainer.py:139] Epoch[671/1000] loss: 0.21984040985504785
I0803 13:49:04.223779  9752 trainer.py:139] Epoch[672/1000] loss: 0.21963235239187875
I0803 13:49:20.051436  9752 trainer.py:139] Epoch[673/1000] loss: 0.21943239867687225
I0803 13:49:35.616704  9752 trainer.py:139] Epoch[674/1000] loss: 0.22022093584140143
I0803 13:49:51.104401  9752 trainer.py:139] Epoch[675/1000] loss: 0.2194495921333631
I0803 13:50:07.032981  9752 trainer.py:139] Epoch[676/1000] loss: 0.21923090517520905
I0803 13:50:22.848161  9752 trainer.py:139] Epoch[677/1000] loss: 0.2193350543578466
I0803 13:50:38.797437  9752 trainer.py:139] Epoch[678/1000] loss: 0.2184179201722145
I0803 13:50:54.919573  9752 trainer.py:139] Epoch[679/1000] loss: 0.2201431319117546
I0803 13:51:10.769898  9752 trainer.py:139] Epoch[680/1000] loss: 0.21823961536089578
I0803 13:51:26.834569  9752 trainer.py:139] Epoch[681/1000] loss: 0.21962660551071167
I0803 13:51:42.796183  9752 trainer.py:139] Epoch[682/1000] loss: 0.21897070606549582
I0803 13:51:58.815881  9752 trainer.py:139] Epoch[683/1000] loss: 0.2190239205956459
I0803 13:52:15.108208  9752 trainer.py:139] Epoch[684/1000] loss: 0.2187665527065595
I0803 13:52:30.644713  9752 trainer.py:139] Epoch[685/1000] loss: 0.2210164119799932
I0803 13:52:46.123712  9752 trainer.py:139] Epoch[686/1000] loss: 0.21861965705951056
I0803 13:53:01.755651  9752 trainer.py:139] Epoch[687/1000] loss: 0.2202045147617658
I0803 13:53:17.420041  9752 trainer.py:139] Epoch[688/1000] loss: 0.21841002255678177
I0803 13:53:33.301776  9752 trainer.py:139] Epoch[689/1000] loss: 0.21818631887435913
I0803 13:53:49.175688  9752 trainer.py:139] Epoch[690/1000] loss: 0.21815670281648636
I0803 13:54:04.979460  9752 trainer.py:139] Epoch[691/1000] loss: 0.21844286968310675
I0803 13:54:20.880275  9752 trainer.py:139] Epoch[692/1000] loss: 0.2182698349157969
I0803 13:54:36.664492  9752 trainer.py:139] Epoch[693/1000] loss: 0.21787342677513757
I0803 13:54:52.244453  9752 trainer.py:139] Epoch[694/1000] loss: 0.21904955307642618
I0803 13:55:07.760794  9752 trainer.py:139] Epoch[695/1000] loss: 0.21835328141848245
I0803 13:55:23.491582  9752 trainer.py:139] Epoch[696/1000] loss: 0.2182996744910876
I0803 13:55:39.028511  9752 trainer.py:139] Epoch[697/1000] loss: 0.21861027677853903
I0803 13:55:55.064513  9752 trainer.py:139] Epoch[698/1000] loss: 0.21798676500717798
I0803 13:56:11.070987  9752 trainer.py:139] Epoch[699/1000] loss: 0.21901573240756989
I0803 13:56:11.671977  9752 trainer.py:145] Test: [{'precision': 0.1938063439065108, 'recall': 0.27225564519850787, 'hit_ratio': 0.9041736227045075, 'ndcg': 0.30418559072797885}]
I0803 13:56:27.572282  9752 trainer.py:139] Epoch[700/1000] loss: 0.2184372420112292
I0803 13:56:43.425863  9752 trainer.py:139] Epoch[701/1000] loss: 0.21894973516464233
I0803 13:56:59.031367  9752 trainer.py:139] Epoch[702/1000] loss: 0.2178183744351069
I0803 13:57:15.155560  9752 trainer.py:139] Epoch[703/1000] loss: 0.2167163540919622
I0803 13:57:31.222794  9752 trainer.py:139] Epoch[704/1000] loss: 0.21898389359315237
I0803 13:57:47.270963  9752 trainer.py:139] Epoch[705/1000] loss: 0.21862322837114334
I0803 13:58:02.933085  9752 trainer.py:139] Epoch[706/1000] loss: 0.2180254856745402
I0803 13:58:18.624843  9752 trainer.py:139] Epoch[707/1000] loss: 0.2184253359834353
I0803 13:58:34.293330  9752 trainer.py:139] Epoch[708/1000] loss: 0.2188738907376925
I0803 13:58:50.078506  9752 trainer.py:139] Epoch[709/1000] loss: 0.2181961884101232
I0803 13:59:05.693745  9752 trainer.py:139] Epoch[710/1000] loss: 0.21856041500965753
I0803 13:59:21.820762  9752 trainer.py:139] Epoch[711/1000] loss: 0.2173005094130834
I0803 13:59:37.723033  9752 trainer.py:139] Epoch[712/1000] loss: 0.21678708493709564
I0803 13:59:53.797165  9752 trainer.py:139] Epoch[713/1000] loss: 0.2176153634985288
I0803 14:00:09.461965  9752 trainer.py:139] Epoch[714/1000] loss: 0.21647570778926215
I0803 14:00:25.198016  9752 trainer.py:139] Epoch[715/1000] loss: 0.21739299595355988
I0803 14:00:40.907756  9752 trainer.py:139] Epoch[716/1000] loss: 0.2183922529220581
I0803 14:00:56.555905  9752 trainer.py:139] Epoch[717/1000] loss: 0.21650076657533646
I0803 14:01:12.104704  9752 trainer.py:139] Epoch[718/1000] loss: 0.21783123662074408
I0803 14:01:27.631154  9752 trainer.py:139] Epoch[719/1000] loss: 0.21720117082198462
I0803 14:01:43.583516  9752 trainer.py:139] Epoch[720/1000] loss: 0.2180978829662005
I0803 14:01:59.348430  9752 trainer.py:139] Epoch[721/1000] loss: 0.21733655035495758
I0803 14:02:15.318475  9752 trainer.py:139] Epoch[722/1000] loss: 0.21761634945869446
I0803 14:02:30.990910  9752 trainer.py:139] Epoch[723/1000] loss: 0.2173877159754435
I0803 14:02:46.880612  9752 trainer.py:139] Epoch[724/1000] loss: 0.21714236090580621
I0803 14:03:02.974564  9752 trainer.py:139] Epoch[725/1000] loss: 0.2176462486386299
I0803 14:03:18.756093  9752 trainer.py:139] Epoch[726/1000] loss: 0.21716040869553885
I0803 14:03:34.854532  9752 trainer.py:139] Epoch[727/1000] loss: 0.21795180439949036
I0803 14:03:50.494296  9752 trainer.py:139] Epoch[728/1000] loss: 0.2170224686463674
I0803 14:04:06.103845  9752 trainer.py:139] Epoch[729/1000] loss: 0.2167920395731926
I0803 14:04:21.660146  9752 trainer.py:139] Epoch[730/1000] loss: 0.21818401664495468
I0803 14:04:37.312450  9752 trainer.py:139] Epoch[731/1000] loss: 0.2175008331735929
I0803 14:04:53.101313  9752 trainer.py:139] Epoch[732/1000] loss: 0.21729256709416708
I0803 14:05:08.838071  9752 trainer.py:139] Epoch[733/1000] loss: 0.2173146183292071
I0803 14:05:24.695597  9752 trainer.py:139] Epoch[734/1000] loss: 0.21816353251536688
I0803 14:05:40.723232  9752 trainer.py:139] Epoch[735/1000] loss: 0.21730348467826843
I0803 14:05:56.903558  9752 trainer.py:139] Epoch[736/1000] loss: 0.21820601572593054
I0803 14:06:12.566781  9752 trainer.py:139] Epoch[737/1000] loss: 0.21604833006858826
I0803 14:06:28.538340  9752 trainer.py:139] Epoch[738/1000] loss: 0.21767541517814
I0803 14:06:44.183943  9752 trainer.py:139] Epoch[739/1000] loss: 0.2174025351802508
I0803 14:06:59.933833  9752 trainer.py:139] Epoch[740/1000] loss: 0.2175940548380216
I0803 14:07:15.818681  9752 trainer.py:139] Epoch[741/1000] loss: 0.21712030718723932
I0803 14:07:31.770676  9752 trainer.py:139] Epoch[742/1000] loss: 0.2166804869969686
I0803 14:07:47.507262  9752 trainer.py:139] Epoch[743/1000] loss: 0.21629665791988373
I0803 14:08:03.398427  9752 trainer.py:139] Epoch[744/1000] loss: 0.21708579609791437
I0803 14:08:19.108881  9752 trainer.py:139] Epoch[745/1000] loss: 0.21639551719029745
I0803 14:08:34.932782  9752 trainer.py:139] Epoch[746/1000] loss: 0.2176386366287867
I0803 14:08:50.955047  9752 trainer.py:139] Epoch[747/1000] loss: 0.21687847872575125
I0803 14:09:06.817790  9752 trainer.py:139] Epoch[748/1000] loss: 0.2169595087567965
I0803 14:09:22.871510  9752 trainer.py:139] Epoch[749/1000] loss: 0.21751287082831064
I0803 14:09:23.478480  9752 trainer.py:145] Test: [{'precision': 0.19450751252086815, 'recall': 0.2725252922749018, 'hit_ratio': 0.9043405676126878, 'ndcg': 0.30565789502600177}]
I0803 14:09:39.248801  9752 trainer.py:139] Epoch[750/1000] loss: 0.21694643795490265
I0803 14:09:55.060012  9752 trainer.py:139] Epoch[751/1000] loss: 0.21490358064572015
I0803 14:10:10.785669  9752 trainer.py:139] Epoch[752/1000] loss: 0.21647029121716818
I0803 14:10:26.518476  9752 trainer.py:139] Epoch[753/1000] loss: 0.2158026248216629
I0803 14:10:42.393404  9752 trainer.py:139] Epoch[754/1000] loss: 0.21604032814502716
I0803 14:10:58.269890  9752 trainer.py:139] Epoch[755/1000] loss: 0.21719305962324142
I0803 14:11:14.029255  9752 trainer.py:139] Epoch[756/1000] loss: 0.2157286653916041
I0803 14:11:30.163336  9752 trainer.py:139] Epoch[757/1000] loss: 0.21625732878843942
I0803 14:11:46.136844  9752 trainer.py:139] Epoch[758/1000] loss: 0.21606277177731195
I0803 14:12:01.671489  9752 trainer.py:139] Epoch[759/1000] loss: 0.21615762015183768
I0803 14:12:17.509293  9752 trainer.py:139] Epoch[760/1000] loss: 0.2166170453031858
I0803 14:12:33.131971  9752 trainer.py:139] Epoch[761/1000] loss: 0.21602575232585272
I0803 14:12:48.751060  9752 trainer.py:139] Epoch[762/1000] loss: 0.21727139502763748
I0803 14:13:04.319798  9752 trainer.py:139] Epoch[763/1000] loss: 0.21696161727110544
I0803 14:13:19.759662  9752 trainer.py:139] Epoch[764/1000] loss: 0.21679161240657172
I0803 14:13:35.313911  9752 trainer.py:139] Epoch[765/1000] loss: 0.21598292887210846
I0803 14:13:51.207055  9752 trainer.py:139] Epoch[766/1000] loss: 0.2159205675125122
I0803 14:14:06.976101  9752 trainer.py:139] Epoch[767/1000] loss: 0.2161979302763939
I0803 14:14:22.923341  9752 trainer.py:139] Epoch[768/1000] loss: 0.2161687364180883
I0803 14:14:38.989800  9752 trainer.py:139] Epoch[769/1000] loss: 0.215990220506986
I0803 14:14:54.658650  9752 trainer.py:139] Epoch[770/1000] loss: 0.21689659853776297
I0803 14:15:10.489775  9752 trainer.py:139] Epoch[771/1000] loss: 0.21486867467562357
I0803 14:15:26.772590  9752 trainer.py:139] Epoch[772/1000] loss: 0.2156915565331777
I0803 14:15:42.615325  9752 trainer.py:139] Epoch[773/1000] loss: 0.21644626061121622
I0803 14:15:58.150954  9752 trainer.py:139] Epoch[774/1000] loss: 0.21661546329657236
I0803 14:16:13.972177  9752 trainer.py:139] Epoch[775/1000] loss: 0.21667800347010294
I0803 14:16:29.546482  9752 trainer.py:139] Epoch[776/1000] loss: 0.21562142670154572
I0803 14:16:45.205306  9752 trainer.py:139] Epoch[777/1000] loss: 0.21475481490294138
I0803 14:17:00.564521  9752 trainer.py:139] Epoch[778/1000] loss: 0.21509691576162973
I0803 14:17:16.244846  9752 trainer.py:139] Epoch[779/1000] loss: 0.21545934677124023
I0803 14:17:32.728982  9752 trainer.py:139] Epoch[780/1000] loss: 0.2163181652625402
I0803 14:17:48.524225  9752 trainer.py:139] Epoch[781/1000] loss: 0.21603136758009592
I0803 14:18:04.252744  9752 trainer.py:139] Epoch[782/1000] loss: 0.2158497894803683
I0803 14:18:19.972363  9752 trainer.py:139] Epoch[783/1000] loss: 0.21616853276888529
I0803 14:18:35.617405  9752 trainer.py:139] Epoch[784/1000] loss: 0.21501566221316656
I0803 14:18:51.310896  9752 trainer.py:139] Epoch[785/1000] loss: 0.21666692942380905
I0803 14:19:06.843175  9752 trainer.py:139] Epoch[786/1000] loss: 0.2143683135509491
I0803 14:19:22.390888  9752 trainer.py:139] Epoch[787/1000] loss: 0.21511131276686987
I0803 14:19:38.002408  9752 trainer.py:139] Epoch[788/1000] loss: 0.2149515524506569
I0803 14:19:53.809272  9752 trainer.py:139] Epoch[789/1000] loss: 0.21511395772298178
I0803 14:20:09.668717  9752 trainer.py:139] Epoch[790/1000] loss: 0.21512573957443237
I0803 14:20:25.515004  9752 trainer.py:139] Epoch[791/1000] loss: 0.2134216676155726
I0803 14:20:41.316603  9752 trainer.py:139] Epoch[792/1000] loss: 0.21666825811068216
I0803 14:20:56.869110  9752 trainer.py:139] Epoch[793/1000] loss: 0.21518819282452264
I0803 14:21:12.781584  9752 trainer.py:139] Epoch[794/1000] loss: 0.21539811293284097
I0803 14:21:28.724683  9752 trainer.py:139] Epoch[795/1000] loss: 0.21581772218147913
I0803 14:21:44.544550  9752 trainer.py:139] Epoch[796/1000] loss: 0.21525462220112482
I0803 14:22:00.708905  9752 trainer.py:139] Epoch[797/1000] loss: 0.21460177501042685
I0803 14:22:16.562385  9752 trainer.py:139] Epoch[798/1000] loss: 0.2155231013894081
I0803 14:22:32.281733  9752 trainer.py:139] Epoch[799/1000] loss: 0.2144289861122767
I0803 14:22:32.860340  9752 trainer.py:145] Test: [{'precision': 0.19533388981636063, 'recall': 0.27440637221089, 'hit_ratio': 0.9051752921535893, 'ndcg': 0.30741528419574166}]
I0803 14:22:48.423506  9752 trainer.py:139] Epoch[800/1000] loss: 0.2155011792977651
I0803 14:23:04.292187  9752 trainer.py:139] Epoch[801/1000] loss: 0.21541847536961237
I0803 14:23:20.449894  9752 trainer.py:139] Epoch[802/1000] loss: 0.2150732527176539
I0803 14:23:36.430270  9752 trainer.py:139] Epoch[803/1000] loss: 0.21627517292896906
I0803 14:23:52.088613  9752 trainer.py:139] Epoch[804/1000] loss: 0.21404610325892767
I0803 14:24:07.729350  9752 trainer.py:139] Epoch[805/1000] loss: 0.21414762983719507
I0803 14:24:23.548330  9752 trainer.py:139] Epoch[806/1000] loss: 0.21496260414520899
I0803 14:24:39.071531  9752 trainer.py:139] Epoch[807/1000] loss: 0.2144796351591746
I0803 14:24:54.832823  9752 trainer.py:139] Epoch[808/1000] loss: 0.2150414064526558
I0803 14:25:10.318065  9752 trainer.py:139] Epoch[809/1000] loss: 0.2148227592309316
I0803 14:25:26.265699  9752 trainer.py:139] Epoch[810/1000] loss: 0.21593356877565384
I0803 14:25:41.776769  9752 trainer.py:139] Epoch[811/1000] loss: 0.21565669775009155
I0803 14:25:57.249387  9752 trainer.py:139] Epoch[812/1000] loss: 0.21515938391288122
I0803 14:26:13.256078  9752 trainer.py:139] Epoch[813/1000] loss: 0.21697221199671426
I0803 14:26:29.319634  9752 trainer.py:139] Epoch[814/1000] loss: 0.2145434245467186
I0803 14:26:45.151635  9752 trainer.py:139] Epoch[815/1000] loss: 0.2159455269575119
I0803 14:27:00.806372  9752 trainer.py:139] Epoch[816/1000] loss: 0.2155473828315735
I0803 14:27:16.778908  9752 trainer.py:139] Epoch[817/1000] loss: 0.2147223154703776
I0803 14:27:32.646568  9752 trainer.py:139] Epoch[818/1000] loss: 0.2148850162823995
I0803 14:27:48.677367  9752 trainer.py:139] Epoch[819/1000] loss: 0.21481020003557205
I0803 14:28:04.660510  9752 trainer.py:139] Epoch[820/1000] loss: 0.21483207990725836
I0803 14:28:20.670081  9752 trainer.py:139] Epoch[821/1000] loss: 0.21469786763191223
I0803 14:28:36.425145  9752 trainer.py:139] Epoch[822/1000] loss: 0.21429907033840814
I0803 14:28:51.977155  9752 trainer.py:139] Epoch[823/1000] loss: 0.21385574589172998
I0803 14:29:07.401968  9752 trainer.py:139] Epoch[824/1000] loss: 0.21417159090439478
I0803 14:29:23.500967  9752 trainer.py:139] Epoch[825/1000] loss: 0.21406027177969614
I0803 14:29:39.415830  9752 trainer.py:139] Epoch[826/1000] loss: 0.21462728579839072
I0803 14:29:55.295752  9752 trainer.py:139] Epoch[827/1000] loss: 0.21343268702427545
I0803 14:30:10.965871  9752 trainer.py:139] Epoch[828/1000] loss: 0.21443250526984534
I0803 14:30:26.824372  9752 trainer.py:139] Epoch[829/1000] loss: 0.21472652504841486
I0803 14:30:42.389435  9752 trainer.py:139] Epoch[830/1000] loss: 0.21471036473910013
I0803 14:30:57.978075  9752 trainer.py:139] Epoch[831/1000] loss: 0.21365977078676224
I0803 14:31:13.415345  9752 trainer.py:139] Epoch[832/1000] loss: 0.21421207239230475
I0803 14:31:29.313009  9752 trainer.py:139] Epoch[833/1000] loss: 0.213566392660141
I0803 14:31:44.738445  9752 trainer.py:139] Epoch[834/1000] loss: 0.21401140838861465
I0803 14:32:00.433216  9752 trainer.py:139] Epoch[835/1000] loss: 0.2153449480732282
I0803 14:32:16.642205  9752 trainer.py:139] Epoch[836/1000] loss: 0.2151374320189158
I0803 14:32:32.581491  9752 trainer.py:139] Epoch[837/1000] loss: 0.21361942837635675
I0803 14:32:48.703634  9752 trainer.py:139] Epoch[838/1000] loss: 0.21385111659765244
I0803 14:33:04.730033  9752 trainer.py:139] Epoch[839/1000] loss: 0.2141075705488523
I0803 14:33:21.118631  9752 trainer.py:139] Epoch[840/1000] loss: 0.21327807009220123
I0803 14:33:37.843084  9752 trainer.py:139] Epoch[841/1000] loss: 0.21460994829734167
I0803 14:33:54.134487  9752 trainer.py:139] Epoch[842/1000] loss: 0.21514315406481424
I0803 14:34:10.195399  9752 trainer.py:139] Epoch[843/1000] loss: 0.21502089003721872
I0803 14:34:26.253157  9752 trainer.py:139] Epoch[844/1000] loss: 0.2137752945224444
I0803 14:34:42.357353  9752 trainer.py:139] Epoch[845/1000] loss: 0.21459398667017618
I0803 14:34:58.264272  9752 trainer.py:139] Epoch[846/1000] loss: 0.21324048936367035
I0803 14:35:14.521245  9752 trainer.py:139] Epoch[847/1000] loss: 0.21285113443930945
I0803 14:35:30.989694  9752 trainer.py:139] Epoch[848/1000] loss: 0.21494467556476593
I0803 14:35:47.359397  9752 trainer.py:139] Epoch[849/1000] loss: 0.2136947065591812
I0803 14:35:48.005789  9752 trainer.py:145] Test: [{'precision': 0.1957429048414023, 'recall': 0.275573009815164, 'hit_ratio': 0.9058430717863105, 'ndcg': 0.308273983651316}]
I0803 14:36:03.980995  9752 trainer.py:139] Epoch[850/1000] loss: 0.2129495864113172
I0803 14:36:20.059514  9752 trainer.py:139] Epoch[851/1000] loss: 0.21458791196346283
I0803 14:36:36.039067  9752 trainer.py:139] Epoch[852/1000] loss: 0.21313568949699402
I0803 14:36:52.162148  9752 trainer.py:139] Epoch[853/1000] loss: 0.213487279911836
I0803 14:37:08.350107  9752 trainer.py:139] Epoch[854/1000] loss: 0.21394138783216476
I0803 14:37:24.058664  9752 trainer.py:139] Epoch[855/1000] loss: 0.21402347832918167
I0803 14:37:40.088936  9752 trainer.py:139] Epoch[856/1000] loss: 0.21368034929037094
I0803 14:37:55.944826  9752 trainer.py:139] Epoch[857/1000] loss: 0.21308045834302902
I0803 14:38:12.118246  9752 trainer.py:139] Epoch[858/1000] loss: 0.21310206751028696
I0803 14:38:27.884609  9752 trainer.py:139] Epoch[859/1000] loss: 0.21393502751986185
I0803 14:38:43.710069  9752 trainer.py:139] Epoch[860/1000] loss: 0.21410546948512396
I0803 14:38:59.711942  9752 trainer.py:139] Epoch[861/1000] loss: 0.21474828819433847
I0803 14:39:15.601616  9752 trainer.py:139] Epoch[862/1000] loss: 0.214378260076046
I0803 14:39:32.247365  9752 trainer.py:139] Epoch[863/1000] loss: 0.2131272554397583
I0803 14:39:47.995434  9752 trainer.py:139] Epoch[864/1000] loss: 0.2126468097170194
I0803 14:40:03.475015  9752 trainer.py:139] Epoch[865/1000] loss: 0.21319228410720825
I0803 14:40:19.156078  9752 trainer.py:139] Epoch[866/1000] loss: 0.2130791718761126
I0803 14:40:34.938234  9752 trainer.py:139] Epoch[867/1000] loss: 0.2130814492702484
I0803 14:40:50.639286  9752 trainer.py:139] Epoch[868/1000] loss: 0.21364568173885345
I0803 14:41:06.254664  9752 trainer.py:139] Epoch[869/1000] loss: 0.21494686106840769
I0803 14:41:22.213335  9752 trainer.py:139] Epoch[870/1000] loss: 0.2145202433069547
I0803 14:41:38.230140  9752 trainer.py:139] Epoch[871/1000] loss: 0.21334813783566156
I0803 14:41:53.955453  9752 trainer.py:139] Epoch[872/1000] loss: 0.21272019296884537
I0803 14:42:09.743686  9752 trainer.py:139] Epoch[873/1000] loss: 0.21320625642935434
I0803 14:42:25.845265  9752 trainer.py:139] Epoch[874/1000] loss: 0.21201406667629877
I0803 14:42:41.554757  9752 trainer.py:139] Epoch[875/1000] loss: 0.21333961437145868
I0803 14:42:56.953189  9752 trainer.py:139] Epoch[876/1000] loss: 0.21381830424070358
I0803 14:43:12.463481  9752 trainer.py:139] Epoch[877/1000] loss: 0.21306168287992477
I0803 14:43:27.922845  9752 trainer.py:139] Epoch[878/1000] loss: 0.21303964157899222
I0803 14:43:43.832181  9752 trainer.py:139] Epoch[879/1000] loss: 0.21240372955799103
I0803 14:43:59.579485  9752 trainer.py:139] Epoch[880/1000] loss: 0.21404114117225012
I0803 14:44:15.211380  9752 trainer.py:139] Epoch[881/1000] loss: 0.2133458654085795
I0803 14:44:31.287458  9752 trainer.py:139] Epoch[882/1000] loss: 0.2137497067451477
I0803 14:44:47.231060  9752 trainer.py:139] Epoch[883/1000] loss: 0.21264545619487762
I0803 14:45:02.897361  9752 trainer.py:139] Epoch[884/1000] loss: 0.21355373164017996
I0803 14:45:18.835343  9752 trainer.py:139] Epoch[885/1000] loss: 0.2137188563744227
I0803 14:45:34.724401  9752 trainer.py:139] Epoch[886/1000] loss: 0.21211970349152884
I0803 14:45:50.739210  9752 trainer.py:139] Epoch[887/1000] loss: 0.21382813652356467
I0803 14:46:06.494432  9752 trainer.py:139] Epoch[888/1000] loss: 0.21515132238467535
I0803 14:46:22.223776  9752 trainer.py:139] Epoch[889/1000] loss: 0.2133165250221888
I0803 14:46:37.872235  9752 trainer.py:139] Epoch[890/1000] loss: 0.21315395832061768
I0803 14:46:53.943600  9752 trainer.py:139] Epoch[891/1000] loss: 0.211295818289121
I0803 14:47:09.743273  9752 trainer.py:139] Epoch[892/1000] loss: 0.21262659629185995
I0803 14:47:25.901500  9752 trainer.py:139] Epoch[893/1000] loss: 0.21254719297091165
I0803 14:47:41.693242  9752 trainer.py:139] Epoch[894/1000] loss: 0.2130491410692533
I0803 14:47:57.420899  9752 trainer.py:139] Epoch[895/1000] loss: 0.21351474523544312
I0803 14:48:13.227661  9752 trainer.py:139] Epoch[896/1000] loss: 0.2131700317064921
I0803 14:48:29.236385  9752 trainer.py:139] Epoch[897/1000] loss: 0.21345318853855133
I0803 14:48:44.770514  9752 trainer.py:139] Epoch[898/1000] loss: 0.21146387606859207
I0803 14:49:00.450183  9752 trainer.py:139] Epoch[899/1000] loss: 0.2136561448375384
I0803 14:49:01.042769  9752 trainer.py:145] Test: [{'precision': 0.19688647746243737, 'recall': 0.27650211435356165, 'hit_ratio': 0.9070116861435726, 'ndcg': 0.3096368104037006}]
I0803 14:49:16.801804  9752 trainer.py:139] Epoch[900/1000] loss: 0.2128784308830897
I0803 14:49:32.737086  9752 trainer.py:139] Epoch[901/1000] loss: 0.21299158533414206
I0803 14:49:48.277404  9752 trainer.py:139] Epoch[902/1000] loss: 0.21364137530326843
I0803 14:50:03.784756  9752 trainer.py:139] Epoch[903/1000] loss: 0.2126751790444056
I0803 14:50:19.636481  9752 trainer.py:139] Epoch[904/1000] loss: 0.2121996929248174
I0803 14:50:35.788958  9752 trainer.py:139] Epoch[905/1000] loss: 0.21252975116173425
I0803 14:50:51.769106  9752 trainer.py:139] Epoch[906/1000] loss: 0.2120223119854927
I0803 14:51:07.550402  9752 trainer.py:139] Epoch[907/1000] loss: 0.21177240957816443
I0803 14:51:23.473232  9752 trainer.py:139] Epoch[908/1000] loss: 0.21221483002106348
I0803 14:51:39.339099  9752 trainer.py:139] Epoch[909/1000] loss: 0.21221214532852173
I0803 14:51:55.703512  9752 trainer.py:139] Epoch[910/1000] loss: 0.21164298057556152
I0803 14:52:11.616122  9752 trainer.py:139] Epoch[911/1000] loss: 0.21258021891117096
I0803 14:52:27.486032  9752 trainer.py:139] Epoch[912/1000] loss: 0.21312353014945984
I0803 14:52:43.192017  9752 trainer.py:139] Epoch[913/1000] loss: 0.21264609197775522
I0803 14:52:58.961035  9752 trainer.py:139] Epoch[914/1000] loss: 0.2113846018910408
I0803 14:53:14.892239  9752 trainer.py:139] Epoch[915/1000] loss: 0.21244393289089203
I0803 14:53:31.002626  9752 trainer.py:139] Epoch[916/1000] loss: 0.2121137355764707
I0803 14:53:46.808696  9752 trainer.py:139] Epoch[917/1000] loss: 0.21175345530112585
I0803 14:54:02.782714  9752 trainer.py:139] Epoch[918/1000] loss: 0.21198521554470062
I0803 14:54:18.855127  9752 trainer.py:139] Epoch[919/1000] loss: 0.21255756169557571
I0803 14:54:34.514966  9752 trainer.py:139] Epoch[920/1000] loss: 0.21266508599122366
I0803 14:54:50.022182  9752 trainer.py:139] Epoch[921/1000] loss: 0.2126031145453453
I0803 14:55:05.605528  9752 trainer.py:139] Epoch[922/1000] loss: 0.21163553496201834
I0803 14:55:21.147394  9752 trainer.py:139] Epoch[923/1000] loss: 0.21199101209640503
I0803 14:55:36.934432  9752 trainer.py:139] Epoch[924/1000] loss: 0.21167207757631937
I0803 14:55:52.491640  9752 trainer.py:139] Epoch[925/1000] loss: 0.2125659982363383
I0803 14:56:08.300203  9752 trainer.py:139] Epoch[926/1000] loss: 0.21104270468155542
I0803 14:56:24.115367  9752 trainer.py:139] Epoch[927/1000] loss: 0.21201332410176596
I0803 14:56:39.915473  9752 trainer.py:139] Epoch[928/1000] loss: 0.2134640042980512
I0803 14:56:55.616413  9752 trainer.py:139] Epoch[929/1000] loss: 0.21229667961597443
I0803 14:57:11.786286  9752 trainer.py:139] Epoch[930/1000] loss: 0.21170289317766824
I0803 14:57:28.001770  9752 trainer.py:139] Epoch[931/1000] loss: 0.21243553857008615
I0803 14:57:44.129872  9752 trainer.py:139] Epoch[932/1000] loss: 0.21234301229317984
I0803 14:57:59.965923  9752 trainer.py:139] Epoch[933/1000] loss: 0.21283884098132452
I0803 14:58:15.707436  9752 trainer.py:139] Epoch[934/1000] loss: 0.21073613812526068
I0803 14:58:31.382545  9752 trainer.py:139] Epoch[935/1000] loss: 0.21101133525371552
I0803 14:58:47.075486  9752 trainer.py:139] Epoch[936/1000] loss: 0.21103712419668832
I0803 14:59:02.691258  9752 trainer.py:139] Epoch[937/1000] loss: 0.21201320985953012
I0803 14:59:18.498636  9752 trainer.py:139] Epoch[938/1000] loss: 0.21109217156966528
I0803 14:59:34.260632  9752 trainer.py:139] Epoch[939/1000] loss: 0.21273819853862128
I0803 14:59:50.673637  9752 trainer.py:139] Epoch[940/1000] loss: 0.21167647590239844
I0803 15:00:07.785848  9752 trainer.py:139] Epoch[941/1000] loss: 0.2121805672844251
I0803 15:00:24.711362  9752 trainer.py:139] Epoch[942/1000] loss: 0.21323163559039435
I0803 15:00:40.656513  9752 trainer.py:139] Epoch[943/1000] loss: 0.21088435252507529
I0803 15:00:56.612954  9752 trainer.py:139] Epoch[944/1000] loss: 0.2127943014105161
I0803 15:01:12.564737  9752 trainer.py:139] Epoch[945/1000] loss: 0.21223029990990958
I0803 15:01:28.159724  9752 trainer.py:139] Epoch[946/1000] loss: 0.21174922088781992
I0803 15:01:43.854073  9752 trainer.py:139] Epoch[947/1000] loss: 0.21257450183232626
I0803 15:01:59.712295  9752 trainer.py:139] Epoch[948/1000] loss: 0.2117332617441813
I0803 15:02:16.075402  9752 trainer.py:139] Epoch[949/1000] loss: 0.21164532005786896
I0803 15:02:16.692336  9752 trainer.py:145] Test: [{'precision': 0.1970617696160267, 'recall': 0.27734549250095764, 'hit_ratio': 0.9076794657762938, 'ndcg': 0.3099912172716486}]
I0803 15:02:32.634928  9752 trainer.py:139] Epoch[950/1000] loss: 0.2106951822837194
I0803 15:02:48.614299  9752 trainer.py:139] Epoch[951/1000] loss: 0.21168469885985056
I0803 15:03:04.903787  9752 trainer.py:139] Epoch[952/1000] loss: 0.21100917706886926
I0803 15:03:21.045099  9752 trainer.py:139] Epoch[953/1000] loss: 0.21090763062238693
I0803 15:03:37.078391  9752 trainer.py:139] Epoch[954/1000] loss: 0.2119299148519834
I0803 15:03:53.190590  9752 trainer.py:139] Epoch[955/1000] loss: 0.21126473198334375
I0803 15:04:09.217876  9752 trainer.py:139] Epoch[956/1000] loss: 0.21207924683888754
I0803 15:04:25.363445  9752 trainer.py:139] Epoch[957/1000] loss: 0.21073690553506216
I0803 15:04:41.209021  9752 trainer.py:139] Epoch[958/1000] loss: 0.21224021166563034
I0803 15:04:57.399034  9752 trainer.py:139] Epoch[959/1000] loss: 0.21203638861576715
I0803 15:05:15.808837  9752 trainer.py:139] Epoch[960/1000] loss: 0.21167562156915665
I0803 15:05:33.947337  9752 trainer.py:139] Epoch[961/1000] loss: 0.21031707525253296
I0803 15:05:52.596617  9752 trainer.py:139] Epoch[962/1000] loss: 0.2107917790611585
I0803 15:06:11.373310  9752 trainer.py:139] Epoch[963/1000] loss: 0.21125591546297073
I0803 15:06:29.219779  9752 trainer.py:139] Epoch[964/1000] loss: 0.2117252672712008
I0803 15:06:47.454649  9752 trainer.py:139] Epoch[965/1000] loss: 0.21091332286596298
I0803 15:07:05.553141  9752 trainer.py:139] Epoch[966/1000] loss: 0.21193682650725046
I0803 15:07:23.560824  9752 trainer.py:139] Epoch[967/1000] loss: 0.21073332180579504
I0803 15:07:42.883859  9752 trainer.py:139] Epoch[968/1000] loss: 0.2114675814906756
I0803 15:08:03.672171  9752 trainer.py:139] Epoch[969/1000] loss: 0.2113297482331594
I0803 15:08:22.328425  9752 trainer.py:139] Epoch[970/1000] loss: 0.21065717687209448
I0803 15:08:40.375734  9752 trainer.py:139] Epoch[971/1000] loss: 0.2122522567709287
I0803 15:08:58.212542  9752 trainer.py:139] Epoch[972/1000] loss: 0.21161269148190817
I0803 15:09:15.920167  9752 trainer.py:139] Epoch[973/1000] loss: 0.21157707273960114
I0803 15:09:34.185114  9752 trainer.py:139] Epoch[974/1000] loss: 0.21153447280327478
I0803 15:09:52.094003  9752 trainer.py:139] Epoch[975/1000] loss: 0.21211793025334677
I0803 15:10:10.336354  9752 trainer.py:139] Epoch[976/1000] loss: 0.21050248791774115
I0803 15:10:27.789045  9752 trainer.py:139] Epoch[977/1000] loss: 0.21054830898841223
I0803 15:10:45.524326  9752 trainer.py:139] Epoch[978/1000] loss: 0.2113081564505895
I0803 15:11:03.022275  9752 trainer.py:139] Epoch[979/1000] loss: 0.21062856167554855
I0803 15:11:21.382552  9752 trainer.py:139] Epoch[980/1000] loss: 0.2106288547317187
I0803 15:11:39.784192  9752 trainer.py:139] Epoch[981/1000] loss: 0.21151244640350342
I0803 15:11:57.900455  9752 trainer.py:139] Epoch[982/1000] loss: 0.2109716758131981
I0803 15:12:15.834409  9752 trainer.py:139] Epoch[983/1000] loss: 0.21099333465099335
I0803 15:12:33.589827  9752 trainer.py:139] Epoch[984/1000] loss: 0.21095030506451926
I0803 15:12:51.109848  9752 trainer.py:139] Epoch[985/1000] loss: 0.21183041483163834
I0803 15:13:09.076470  9752 trainer.py:139] Epoch[986/1000] loss: 0.21071435262759527
I0803 15:13:26.815967  9752 trainer.py:139] Epoch[987/1000] loss: 0.21077542006969452
I0803 15:13:44.061792  9752 trainer.py:139] Epoch[988/1000] loss: 0.21106175829966864
I0803 15:14:01.664041  9752 trainer.py:139] Epoch[989/1000] loss: 0.2114333932598432
I0803 15:14:19.236532  9752 trainer.py:139] Epoch[990/1000] loss: 0.21142219503720602
I0803 15:14:37.277012  9752 trainer.py:139] Epoch[991/1000] loss: 0.2113776902357737
I0803 15:14:55.525064  9752 trainer.py:139] Epoch[992/1000] loss: 0.21099417905012766
I0803 15:15:13.737190  9752 trainer.py:139] Epoch[993/1000] loss: 0.2112031082312266
I0803 15:15:31.885118  9752 trainer.py:139] Epoch[994/1000] loss: 0.20995811372995377
I0803 15:15:49.711531  9752 trainer.py:139] Epoch[995/1000] loss: 0.21125040700038275
I0803 15:16:07.577261  9752 trainer.py:139] Epoch[996/1000] loss: 0.21080206086238226
I0803 15:16:25.544179  9752 trainer.py:139] Epoch[997/1000] loss: 0.2106034979224205
I0803 15:16:43.054402  9752 trainer.py:139] Epoch[998/1000] loss: 0.21036103864510855
I0803 15:17:01.239846  9752 trainer.py:139] Epoch[999/1000] loss: 0.21187937508026758
I0803 15:17:01.975003  9752 trainer.py:145] Test: [{'precision': 0.19694490818030055, 'recall': 0.27737649740696607, 'hit_ratio': 0.9073455759599333, 'ndcg': 0.30983781757091905}]
