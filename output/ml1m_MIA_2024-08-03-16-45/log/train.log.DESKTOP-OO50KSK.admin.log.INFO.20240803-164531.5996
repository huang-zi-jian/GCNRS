I0803 16:45:39.127321  3068 trainer.py:119] Test: [{'precision': 0.0004924874791318864, 'recall': 0.0006034177476148269, 'hit_ratio': 0.008848080133555926, 'ndcg': 0.0006119234654540375}]
I0803 16:46:26.497856  3068 trainer.py:139] Epoch[0/1000] loss: 0.6114919273058573
I0803 16:47:13.866358  3068 trainer.py:139] Epoch[1/1000] loss: 0.4147860226366255
I0803 16:47:59.731485  3068 trainer.py:139] Epoch[2/1000] loss: 0.39346352060635886
I0803 16:48:43.945999  3068 trainer.py:139] Epoch[3/1000] loss: 0.38611000431908504
I0803 16:49:28.175178  3068 trainer.py:139] Epoch[4/1000] loss: 0.37770045797030133
I0803 16:50:12.464485  3068 trainer.py:139] Epoch[5/1000] loss: 0.3745487109820048
I0803 16:50:58.208708  3068 trainer.py:139] Epoch[6/1000] loss: 0.36872912340694003
I0803 16:51:44.986681  3068 trainer.py:139] Epoch[7/1000] loss: 0.3608239163292779
I0803 16:52:30.143188  3068 trainer.py:139] Epoch[8/1000] loss: 0.3559100466304355
I0803 16:53:14.921453  3068 trainer.py:139] Epoch[9/1000] loss: 0.3485742447111342
I0803 16:53:59.567373  3068 trainer.py:139] Epoch[10/1000] loss: 0.3423087563779619
I0803 16:54:44.526272  3068 trainer.py:139] Epoch[11/1000] loss: 0.338600554201338
I0803 16:55:29.706891  3068 trainer.py:139] Epoch[12/1000] loss: 0.3344896917872959
I0803 16:56:16.558677  3068 trainer.py:139] Epoch[13/1000] loss: 0.33061111834314133
I0803 16:57:01.870903  3068 trainer.py:139] Epoch[14/1000] loss: 0.3255957958433363
I0803 16:57:46.610753  3068 trainer.py:139] Epoch[15/1000] loss: 0.32225794699456956
I0803 16:58:31.451476  3068 trainer.py:139] Epoch[16/1000] loss: 0.3187061704529656
I0803 16:59:15.072827  3068 trainer.py:139] Epoch[17/1000] loss: 0.3137217337555355
I0803 17:00:00.015753  3068 trainer.py:139] Epoch[18/1000] loss: 0.3133851550685035
I0803 17:00:44.094584  3068 trainer.py:139] Epoch[19/1000] loss: 0.3089821747938792
I0803 17:01:28.953119  3068 trainer.py:139] Epoch[20/1000] loss: 0.3043878702322642
I0803 17:02:13.379104  3068 trainer.py:139] Epoch[21/1000] loss: 0.30112374279234144
I0803 17:02:58.379315  3068 trainer.py:139] Epoch[22/1000] loss: 0.2980012000931634
I0803 17:03:42.425173  3068 trainer.py:139] Epoch[23/1000] loss: 0.2954903362856971
I0803 17:04:26.988191  3068 trainer.py:139] Epoch[24/1000] loss: 0.29198876910739474
I0803 17:05:11.297695  3068 trainer.py:139] Epoch[25/1000] loss: 0.289207200606664
I0803 17:05:55.972855  3068 trainer.py:139] Epoch[26/1000] loss: 0.2868070924282074
I0803 17:06:40.374445  3068 trainer.py:139] Epoch[27/1000] loss: 0.28299706869655183
I0803 17:07:25.057603  3068 trainer.py:139] Epoch[28/1000] loss: 0.28130164755715265
I0803 17:08:10.009341  3068 trainer.py:139] Epoch[29/1000] loss: 0.2777554361025492
I0803 17:08:53.338064  3068 trainer.py:139] Epoch[30/1000] loss: 0.2765628205405341
I0803 17:09:37.811276  3068 trainer.py:139] Epoch[31/1000] loss: 0.2738490108648936
I0803 17:10:21.753535  3068 trainer.py:139] Epoch[32/1000] loss: 0.2708615965313382
I0803 17:11:06.392945  3068 trainer.py:139] Epoch[33/1000] loss: 0.2693743106391695
I0803 17:11:49.769898  3068 trainer.py:139] Epoch[34/1000] loss: 0.2670912860499488
I0803 17:12:34.411989  3068 trainer.py:139] Epoch[35/1000] loss: 0.26610361046261255
I0803 17:13:18.846335  3068 trainer.py:139] Epoch[36/1000] loss: 0.26264650768703884
I0803 17:14:03.359230  3068 trainer.py:139] Epoch[37/1000] loss: 0.26183659149540794
I0803 17:14:47.925599  3068 trainer.py:139] Epoch[38/1000] loss: 0.26097629394796157
I0803 17:15:32.380429  3068 trainer.py:139] Epoch[39/1000] loss: 0.2576089386145274
I0803 17:16:16.760984  3068 trainer.py:139] Epoch[40/1000] loss: 0.2570738303661346
I0803 17:17:01.133298  3068 trainer.py:139] Epoch[41/1000] loss: 0.2565261485841539
I0803 17:17:45.322897  3068 trainer.py:139] Epoch[42/1000] loss: 0.2547948084274928
I0803 17:18:29.625886  3068 trainer.py:139] Epoch[43/1000] loss: 0.2522668644454744
I0803 17:19:14.341380  3068 trainer.py:139] Epoch[44/1000] loss: 0.250858018928104
I0803 17:19:58.690465  3068 trainer.py:139] Epoch[45/1000] loss: 0.2497795006301668
I0803 17:20:43.199246  3068 trainer.py:139] Epoch[46/1000] loss: 0.24964463227325015
I0803 17:21:27.851346  3068 trainer.py:139] Epoch[47/1000] loss: 0.24825831274191537
I0803 17:22:11.942766  3068 trainer.py:139] Epoch[48/1000] loss: 0.24783908320797815
I0803 17:22:55.919670  3068 trainer.py:139] Epoch[49/1000] loss: 0.24643783734904395
I0803 17:22:56.480792  3068 trainer.py:145] Test: [{'precision': 0.18388981636060098, 'recall': 0.254213208842789, 'hit_ratio': 0.8913188647746244, 'ndcg': 0.28542044701730307}]
I0803 17:23:39.731615  3068 trainer.py:139] Epoch[50/1000] loss: 0.2446968514389462
I0803 17:24:24.140392  3068 trainer.py:139] Epoch[51/1000] loss: 0.24299295239978366
I0803 17:25:08.289731  3068 trainer.py:139] Epoch[52/1000] loss: 0.2433634881178538
I0803 17:25:52.223515  3068 trainer.py:139] Epoch[53/1000] loss: 0.24216097520457375
I0803 17:26:36.781406  3068 trainer.py:139] Epoch[54/1000] loss: 0.24024154510762957
I0803 17:27:21.489654  3068 trainer.py:139] Epoch[55/1000] loss: 0.24128618531756932
I0803 17:28:05.955430  3068 trainer.py:139] Epoch[56/1000] loss: 0.2394730696413252
I0803 17:28:49.852361  3068 trainer.py:139] Epoch[57/1000] loss: 0.2387634273370107
I0803 17:29:34.611709  3068 trainer.py:139] Epoch[58/1000] loss: 0.23706748306751252
I0803 17:30:19.341100  3068 trainer.py:139] Epoch[59/1000] loss: 0.2378528396288554
I0803 17:31:04.092514  3068 trainer.py:139] Epoch[60/1000] loss: 0.23684185286362966
I0803 17:31:48.424391  3068 trainer.py:139] Epoch[61/1000] loss: 0.23590525580777064
I0803 17:32:32.876879  3068 trainer.py:139] Epoch[62/1000] loss: 0.23510577506489225
I0803 17:33:17.152124  3068 trainer.py:139] Epoch[63/1000] loss: 0.2362195854054557
I0803 17:34:01.083786  3068 trainer.py:139] Epoch[64/1000] loss: 0.23417262653509777
I0803 17:34:44.504220  3068 trainer.py:139] Epoch[65/1000] loss: 0.233489058415095
I0803 17:35:29.756865  3068 trainer.py:139] Epoch[66/1000] loss: 0.2328500386741426
I0803 17:36:14.080554  3068 trainer.py:139] Epoch[67/1000] loss: 0.23192036224736107
I0803 17:36:58.699456  3068 trainer.py:139] Epoch[68/1000] loss: 0.2315046571360694
I0803 17:37:42.983702  3068 trainer.py:139] Epoch[69/1000] loss: 0.2314281349711948
I0803 17:38:27.014926  3068 trainer.py:139] Epoch[70/1000] loss: 0.23030496027734546
I0803 17:39:10.692533  3068 trainer.py:139] Epoch[71/1000] loss: 0.22900718139277565
I0803 17:39:54.633112  3068 trainer.py:139] Epoch[72/1000] loss: 0.2292699221107695
I0803 17:40:38.174309  3068 trainer.py:139] Epoch[73/1000] loss: 0.22886365506384107
I0803 17:41:22.973435  3068 trainer.py:139] Epoch[74/1000] loss: 0.2293328281905916
I0803 17:42:07.167212  3068 trainer.py:139] Epoch[75/1000] loss: 0.22658156686358982
I0803 17:42:51.025058  3068 trainer.py:139] Epoch[76/1000] loss: 0.22856525222460428
I0803 17:43:35.435734  3068 trainer.py:139] Epoch[77/1000] loss: 0.22708170817957984
I0803 17:44:19.810583  3068 trainer.py:139] Epoch[78/1000] loss: 0.22686260839303335
I0803 17:45:05.912786  3068 trainer.py:139] Epoch[79/1000] loss: 0.22630947728951772
I0803 17:45:52.739749  3068 trainer.py:139] Epoch[80/1000] loss: 0.22518617338604396
I0803 17:46:36.650561  3068 trainer.py:139] Epoch[81/1000] loss: 0.22647231923209296
I0803 17:47:20.728560  3068 trainer.py:139] Epoch[82/1000] loss: 0.22526289721330006
I0803 17:48:05.129706  3068 trainer.py:139] Epoch[83/1000] loss: 0.22557594776153564
I0803 17:48:49.329993  3068 trainer.py:139] Epoch[84/1000] loss: 0.22501688453886243
I0803 17:49:33.586091  3068 trainer.py:139] Epoch[85/1000] loss: 0.2237133546670278
I0803 17:50:17.473887  3068 trainer.py:139] Epoch[86/1000] loss: 0.22459480822086333
I0803 17:51:01.203585  3068 trainer.py:139] Epoch[87/1000] loss: 0.2244212958547804
I0803 17:51:45.082888  3068 trainer.py:139] Epoch[88/1000] loss: 0.22436977015601264
I0803 17:52:29.068660  3068 trainer.py:139] Epoch[89/1000] loss: 0.22297078596221076
I0803 17:53:13.216646  3068 trainer.py:139] Epoch[90/1000] loss: 0.22351829316880967
I0803 17:53:57.539244  3068 trainer.py:139] Epoch[91/1000] loss: 0.22381793677806855
I0803 17:54:41.890848  3068 trainer.py:139] Epoch[92/1000] loss: 0.2232619310087628
I0803 17:55:25.827077  3068 trainer.py:139] Epoch[93/1000] loss: 0.22214404775036706
I0803 17:56:09.916455  3068 trainer.py:139] Epoch[94/1000] loss: 0.22077291031678517
I0803 17:56:53.784946  3068 trainer.py:139] Epoch[95/1000] loss: 0.22204277475674947
I0803 17:57:37.613068  3068 trainer.py:139] Epoch[96/1000] loss: 0.22279405037562053
I0803 17:58:21.625629  3068 trainer.py:139] Epoch[97/1000] loss: 0.22097769651148055
I0803 17:59:04.842713  3068 trainer.py:139] Epoch[98/1000] loss: 0.21937927862008413
I0803 17:59:48.753732  3068 trainer.py:139] Epoch[99/1000] loss: 0.21985529316796196
I0803 17:59:49.363239  3068 trainer.py:145] Test: [{'precision': 0.19419866444073455, 'recall': 0.2726709749417937, 'hit_ratio': 0.9043405676126878, 'ndcg': 0.3048207314591171}]
I0803 18:00:33.857295  3068 trainer.py:139] Epoch[100/1000] loss: 0.22169213387701248
I0803 18:01:18.470533  3068 trainer.py:139] Epoch[101/1000] loss: 0.21991134723027547
I0803 18:02:02.321252  3068 trainer.py:139] Epoch[102/1000] loss: 0.22023377822505102
I0803 18:02:45.944555  3068 trainer.py:139] Epoch[103/1000] loss: 0.2206642531024085
I0803 18:03:30.990539  3068 trainer.py:139] Epoch[104/1000] loss: 0.21923284305466545
I0803 18:04:15.745054  3068 trainer.py:139] Epoch[105/1000] loss: 0.21926455398400624
I0803 18:04:59.489905  3068 trainer.py:139] Epoch[106/1000] loss: 0.21810036632749769
I0803 18:05:42.773428  3068 trainer.py:139] Epoch[107/1000] loss: 0.21877836518817478
I0803 18:06:27.384791  3068 trainer.py:139] Epoch[108/1000] loss: 0.21839616848362817
I0803 18:07:11.914285  3068 trainer.py:139] Epoch[109/1000] loss: 0.21844709780481125
I0803 18:07:56.500979  3068 trainer.py:139] Epoch[110/1000] loss: 0.21730016787846884
I0803 18:08:39.606360  3068 trainer.py:139] Epoch[111/1000] loss: 0.21783415642049578
I0803 18:09:22.976506  3068 trainer.py:139] Epoch[112/1000] loss: 0.21652449111143748
I0803 18:10:07.168647  3068 trainer.py:139] Epoch[113/1000] loss: 0.21697186390558879
I0803 18:10:50.048918  3068 trainer.py:139] Epoch[114/1000] loss: 0.2174384660191006
I0803 18:11:32.838714  3068 trainer.py:139] Epoch[115/1000] loss: 0.21669403062926398
I0803 18:12:17.440166  3068 trainer.py:139] Epoch[116/1000] loss: 0.21608437518278759
I0803 18:13:01.848987  3068 trainer.py:139] Epoch[117/1000] loss: 0.21627709805965423
I0803 18:13:45.756502  3068 trainer.py:139] Epoch[118/1000] loss: 0.21618561764558156
I0803 18:14:29.331223  3068 trainer.py:139] Epoch[119/1000] loss: 0.21641503108872306
I0803 18:15:12.494740  3068 trainer.py:139] Epoch[120/1000] loss: 0.2153940897517734
I0803 18:15:56.538304  3068 trainer.py:139] Epoch[121/1000] loss: 0.2156436116165585
I0803 18:16:39.917223  3068 trainer.py:139] Epoch[122/1000] loss: 0.21592456824249692
I0803 18:17:22.613641  3068 trainer.py:139] Epoch[123/1000] loss: 0.2147366808520423
I0803 18:18:06.405601  3068 trainer.py:139] Epoch[124/1000] loss: 0.21500553713904486
I0803 18:18:50.626186  3068 trainer.py:139] Epoch[125/1000] loss: 0.21566980832152896
I0803 18:19:34.311402  3068 trainer.py:139] Epoch[126/1000] loss: 0.21554721302456326
I0803 18:20:17.832130  3068 trainer.py:139] Epoch[127/1000] loss: 0.21424733817577363
I0803 18:21:01.122651  3068 trainer.py:139] Epoch[128/1000] loss: 0.21489308602280088
I0803 18:21:44.954908  3068 trainer.py:139] Epoch[129/1000] loss: 0.21460633900430467
I0803 18:22:28.372761  3068 trainer.py:139] Epoch[130/1000] loss: 0.21336604860093858
I0803 18:23:12.297821  3068 trainer.py:139] Epoch[131/1000] loss: 0.21307702740033468
I0803 18:23:56.225172  3068 trainer.py:139] Epoch[132/1000] loss: 0.21444114161862268
I0803 18:24:40.486457  3068 trainer.py:139] Epoch[133/1000] loss: 0.21351890822251637
I0803 18:25:25.211548  3068 trainer.py:139] Epoch[134/1000] loss: 0.21404783997270796
I0803 18:26:08.573212  3068 trainer.py:139] Epoch[135/1000] loss: 0.212544680568907
I0803 18:26:51.701609  3068 trainer.py:139] Epoch[136/1000] loss: 0.21311496456464132
I0803 18:27:35.650574  3068 trainer.py:139] Epoch[137/1000] loss: 0.21356133315298292
I0803 18:28:19.563851  3068 trainer.py:139] Epoch[138/1000] loss: 0.2129531846443812
I0803 18:29:02.594220  3068 trainer.py:139] Epoch[139/1000] loss: 0.21218576292196908
I0803 18:29:46.260420  3068 trainer.py:139] Epoch[140/1000] loss: 0.21332157678074307
I0803 18:30:29.868240  3068 trainer.py:139] Epoch[141/1000] loss: 0.2132938042614195
I0803 18:31:13.450493  3068 trainer.py:139] Epoch[142/1000] loss: 0.2114942184421751
I0803 18:31:57.641856  3068 trainer.py:139] Epoch[143/1000] loss: 0.21271009729968177
I0803 18:32:40.476991  3068 trainer.py:139] Epoch[144/1000] loss: 0.21255958358446758
I0803 18:33:24.422309  3068 trainer.py:139] Epoch[145/1000] loss: 0.21152978519598642
I0803 18:34:07.813887  3068 trainer.py:139] Epoch[146/1000] loss: 0.21168335934480031
I0803 18:34:51.233211  3068 trainer.py:139] Epoch[147/1000] loss: 0.21229020926687453
I0803 18:35:33.905581  3068 trainer.py:139] Epoch[148/1000] loss: 0.2116144127315945
I0803 18:36:17.827675  3068 trainer.py:139] Epoch[149/1000] loss: 0.21171443137857648
I0803 18:36:18.420386  3068 trainer.py:145] Test: [{'precision': 0.19798831385642734, 'recall': 0.278481547238837, 'hit_ratio': 0.9078464106844741, 'ndcg': 0.3119736898701878}]
I0803 18:37:02.574615  3068 trainer.py:139] Epoch[150/1000] loss: 0.21039248526096344
I0803 18:37:46.587880  3068 trainer.py:139] Epoch[151/1000] loss: 0.21182789544264474
I0803 18:38:30.348132  3068 trainer.py:139] Epoch[152/1000] loss: 0.21157998753918542
I0803 18:39:14.075294  3068 trainer.py:139] Epoch[153/1000] loss: 0.21111467864778308
I0803 18:39:57.786170  3068 trainer.py:139] Epoch[154/1000] loss: 0.21006090025107066
I0803 18:40:41.462064  3068 trainer.py:139] Epoch[155/1000] loss: 0.21036616020732457
I0803 18:41:25.258574  3068 trainer.py:139] Epoch[156/1000] loss: 0.21009475476211972
I0803 18:42:09.490671  3068 trainer.py:139] Epoch[157/1000] loss: 0.2112810182571411
I0803 18:42:53.597867  3068 trainer.py:139] Epoch[158/1000] loss: 0.2105088377661175
I0803 18:43:37.428877  3068 trainer.py:139] Epoch[159/1000] loss: 0.21047446800602806
I0803 18:44:21.071980  3068 trainer.py:139] Epoch[160/1000] loss: 0.21114760180314382
I0803 18:45:04.705102  3068 trainer.py:139] Epoch[161/1000] loss: 0.21095441109604307
I0803 18:45:48.584227  3068 trainer.py:139] Epoch[162/1000] loss: 0.21037530647383795
I0803 18:46:32.331731  3068 trainer.py:139] Epoch[163/1000] loss: 0.2085378658109241
I0803 18:47:16.378247  3068 trainer.py:139] Epoch[164/1000] loss: 0.20991761419508193
I0803 18:48:00.296602  3068 trainer.py:139] Epoch[165/1000] loss: 0.20972947471671635
I0803 18:48:44.283957  3068 trainer.py:139] Epoch[166/1000] loss: 0.20862024717860753
I0803 18:49:28.147740  3068 trainer.py:139] Epoch[167/1000] loss: 0.20956836177243127
I0803 18:50:12.083464  3068 trainer.py:139] Epoch[168/1000] loss: 0.20908970806333754
I0803 18:50:55.774109  3068 trainer.py:139] Epoch[169/1000] loss: 0.2094145742389891
I0803 18:51:39.435521  3068 trainer.py:139] Epoch[170/1000] loss: 0.20946700096130372
I0803 18:52:23.603550  3068 trainer.py:139] Epoch[171/1000] loss: 0.20916923503081003
I0803 18:53:07.214735  3068 trainer.py:139] Epoch[172/1000] loss: 0.20861156668927935
I0803 18:53:51.564506  3068 trainer.py:139] Epoch[173/1000] loss: 0.20868572890758513
I0803 18:54:35.688757  3068 trainer.py:139] Epoch[174/1000] loss: 0.20885729591051738
I0803 18:55:19.488921  3068 trainer.py:139] Epoch[175/1000] loss: 0.20972910026709238
I0803 18:56:03.430293  3068 trainer.py:139] Epoch[176/1000] loss: 0.20803005443678962
I0803 18:56:47.067099  3068 trainer.py:139] Epoch[177/1000] loss: 0.20769279062747956
I0803 18:57:30.891011  3068 trainer.py:139] Epoch[178/1000] loss: 0.20917795830302768
I0803 18:58:14.953149  3068 trainer.py:139] Epoch[179/1000] loss: 0.20954723272058698
I0803 18:58:58.869437  3068 trainer.py:139] Epoch[180/1000] loss: 0.20884578492906358
I0803 18:59:43.387041  3068 trainer.py:139] Epoch[181/1000] loss: 0.20831765247715844
I0803 19:00:27.754733  3068 trainer.py:139] Epoch[182/1000] loss: 0.20878616763485802
I0803 19:01:12.017728  3068 trainer.py:139] Epoch[183/1000] loss: 0.2080623843934801
I0803 19:01:55.832768  3068 trainer.py:139] Epoch[184/1000] loss: 0.2081034654378891
I0803 19:02:39.306871  3068 trainer.py:139] Epoch[185/1000] loss: 0.2075440994898478
I0803 19:03:22.811921  3068 trainer.py:139] Epoch[186/1000] loss: 0.20876824650499556
I0803 19:04:07.124413  3068 trainer.py:139] Epoch[187/1000] loss: 0.2077549680074056
I0803 19:04:51.125245  3068 trainer.py:139] Epoch[188/1000] loss: 0.20828744656509823
I0803 19:05:35.030317  3068 trainer.py:139] Epoch[189/1000] loss: 0.20914569232198926
I0803 19:06:18.999930  3068 trainer.py:139] Epoch[190/1000] loss: 0.20779192295339372
I0803 19:07:02.815857  3068 trainer.py:139] Epoch[191/1000] loss: 0.2078189723359214
I0803 19:07:46.874222  3068 trainer.py:139] Epoch[192/1000] loss: 0.20655123439100054
I0803 19:08:30.555038  3068 trainer.py:139] Epoch[193/1000] loss: 0.2073290518257353
I0803 19:09:14.315325  3068 trainer.py:139] Epoch[194/1000] loss: 0.20612966305679745
I0803 19:09:58.109093  3068 trainer.py:139] Epoch[195/1000] loss: 0.20584935850567287
I0803 19:10:42.269462  3068 trainer.py:139] Epoch[196/1000] loss: 0.20726037396325006
I0803 19:11:26.163599  3068 trainer.py:139] Epoch[197/1000] loss: 0.20791120105319552
I0803 19:12:10.529839  3068 trainer.py:139] Epoch[198/1000] loss: 0.20614675184090933
I0803 19:12:54.336317  3068 trainer.py:139] Epoch[199/1000] loss: 0.20675160560343
I0803 19:12:54.922886  3068 trainer.py:145] Test: [{'precision': 0.20062604340567614, 'recall': 0.2822936847206746, 'hit_ratio': 0.9081803005008348, 'ndcg': 0.31638064839326685}]
I0803 19:13:38.491961  3068 trainer.py:139] Epoch[200/1000] loss: 0.20630436400572458
I0803 19:14:21.851780  3068 trainer.py:139] Epoch[201/1000] loss: 0.20590093354384104
I0803 19:15:05.512382  3068 trainer.py:139] Epoch[202/1000] loss: 0.20696650445461273
I0803 19:15:49.877151  3068 trainer.py:139] Epoch[203/1000] loss: 0.2067772661977344
I0803 19:16:33.307918  3068 trainer.py:139] Epoch[204/1000] loss: 0.20710795866118537
I0803 19:17:17.118435  3068 trainer.py:139] Epoch[205/1000] loss: 0.20707437727186415
I0803 19:18:00.727659  3068 trainer.py:139] Epoch[206/1000] loss: 0.2063694515493181
I0803 19:18:44.991122  3068 trainer.py:139] Epoch[207/1000] loss: 0.20687400162220002
I0803 19:19:29.080974  3068 trainer.py:139] Epoch[208/1000] loss: 0.2055381997426351
I0803 19:20:12.998620  3068 trainer.py:139] Epoch[209/1000] loss: 0.20663046181201936
I0803 19:20:56.656285  3068 trainer.py:139] Epoch[210/1000] loss: 0.20574877162774405
I0803 19:21:40.316628  3068 trainer.py:139] Epoch[211/1000] loss: 0.20536728812588587
I0803 19:22:23.642096  3068 trainer.py:139] Epoch[212/1000] loss: 0.20602691756354438
I0803 19:23:07.605760  3068 trainer.py:139] Epoch[213/1000] loss: 0.2048245727353626
I0803 19:23:51.713192  3068 trainer.py:139] Epoch[214/1000] loss: 0.20609035975403256
I0803 19:24:35.606277  3068 trainer.py:139] Epoch[215/1000] loss: 0.20542340722348956
I0803 19:25:19.641872  3068 trainer.py:139] Epoch[216/1000] loss: 0.20486278103457556
I0803 19:26:03.340507  3068 trainer.py:139] Epoch[217/1000] loss: 0.2064460355705685
I0803 19:26:46.998421  3068 trainer.py:139] Epoch[218/1000] loss: 0.20505851672755349
I0803 19:27:30.743040  3068 trainer.py:139] Epoch[219/1000] loss: 0.20564913113911948
I0803 19:28:14.411885  3068 trainer.py:139] Epoch[220/1000] loss: 0.20430975589487288
I0803 19:28:58.468206  3068 trainer.py:139] Epoch[221/1000] loss: 0.20439165578948126
I0803 19:29:42.412956  3068 trainer.py:139] Epoch[222/1000] loss: 0.20580778903431363
I0803 19:30:26.649826  3068 trainer.py:139] Epoch[223/1000] loss: 0.2041714268260532
I0803 19:31:10.844757  3068 trainer.py:139] Epoch[224/1000] loss: 0.2046311938100391
I0803 19:31:54.611106  3068 trainer.py:139] Epoch[225/1000] loss: 0.20455842448605432
I0803 19:32:38.319383  3068 trainer.py:139] Epoch[226/1000] loss: 0.20527607487307656
I0803 19:33:22.041672  3068 trainer.py:139] Epoch[227/1000] loss: 0.20516154646873475
I0803 19:34:06.139144  3068 trainer.py:139] Epoch[228/1000] loss: 0.20502959880563948
I0803 19:34:50.182005  3068 trainer.py:139] Epoch[229/1000] loss: 0.20433102256721922
I0803 19:35:34.515669  3068 trainer.py:139] Epoch[230/1000] loss: 0.204234556555748
I0803 19:36:18.713416  3068 trainer.py:139] Epoch[231/1000] loss: 0.20356133931212955
I0803 19:37:02.510262  3068 trainer.py:139] Epoch[232/1000] loss: 0.20404076708687677
I0803 19:37:46.147003  3068 trainer.py:139] Epoch[233/1000] loss: 0.2045666766166687
I0803 19:38:29.940166  3068 trainer.py:139] Epoch[234/1000] loss: 0.2033513222138087
I0803 19:39:13.401053  3068 trainer.py:139] Epoch[235/1000] loss: 0.20325391544236077
I0803 19:39:57.654004  3068 trainer.py:139] Epoch[236/1000] loss: 0.2045623982614941
I0803 19:40:41.794782  3068 trainer.py:139] Epoch[237/1000] loss: 0.2039312109020021
I0803 19:41:25.356314  3068 trainer.py:139] Epoch[238/1000] loss: 0.20522216273678673
I0803 19:42:09.608989  3068 trainer.py:139] Epoch[239/1000] loss: 0.20356127672725255
I0803 19:42:53.325621  3068 trainer.py:139] Epoch[240/1000] loss: 0.20408394826783074
I0803 19:43:37.197083  3068 trainer.py:139] Epoch[241/1000] loss: 0.20315545479456584
I0803 19:44:20.755604  3068 trainer.py:139] Epoch[242/1000] loss: 0.20436212182044983
I0803 19:45:04.595971  3068 trainer.py:139] Epoch[243/1000] loss: 0.20379472970962526
I0803 19:45:48.441569  3068 trainer.py:139] Epoch[244/1000] loss: 0.20331103026866912
I0803 19:46:32.126596  3068 trainer.py:139] Epoch[245/1000] loss: 0.20337807555993398
I0803 19:47:15.731058  3068 trainer.py:139] Epoch[246/1000] loss: 0.20246045834488338
I0803 19:47:59.832412  3068 trainer.py:139] Epoch[247/1000] loss: 0.2036255090104209
I0803 19:48:44.107456  3068 trainer.py:139] Epoch[248/1000] loss: 0.20343547026316325
I0803 19:49:27.844686  3068 trainer.py:139] Epoch[249/1000] loss: 0.20344944695631664
I0803 19:49:28.406805  3068 trainer.py:145] Test: [{'precision': 0.2023372287145242, 'recall': 0.2848080350248867, 'hit_ratio': 0.9136894824707846, 'ndcg': 0.3195318351218605}]
I0803 19:50:11.940193  3068 trainer.py:139] Epoch[250/1000] loss: 0.2032635035779741
I0803 19:50:55.861091  3068 trainer.py:139] Epoch[251/1000] loss: 0.20342073884275225
I0803 19:51:39.816699  3068 trainer.py:139] Epoch[252/1000] loss: 0.20379855963918897
I0803 19:52:23.342336  3068 trainer.py:139] Epoch[253/1000] loss: 0.20201578378677368
I0803 19:53:06.888706  3068 trainer.py:139] Epoch[254/1000] loss: 0.20381665216551886
I0803 19:53:50.739299  3068 trainer.py:139] Epoch[255/1000] loss: 0.20283931334813435
I0803 19:54:34.783439  3068 trainer.py:139] Epoch[256/1000] loss: 0.2024630614121755
I0803 19:55:18.794158  3068 trainer.py:139] Epoch[257/1000] loss: 0.20345299634668562
I0803 19:56:02.379737  3068 trainer.py:139] Epoch[258/1000] loss: 0.2033618242873086
I0803 19:56:46.168861  3068 trainer.py:139] Epoch[259/1000] loss: 0.20224626315964592
I0803 19:57:29.948365  3068 trainer.py:139] Epoch[260/1000] loss: 0.20305264155069988
I0803 19:58:14.026824  3068 trainer.py:139] Epoch[261/1000] loss: 0.20235985259215036
I0803 19:58:58.221469  3068 trainer.py:139] Epoch[262/1000] loss: 0.20232759488953483
I0803 19:59:42.673968  3068 trainer.py:139] Epoch[263/1000] loss: 0.20255092912250094
I0803 20:00:26.760530  3068 trainer.py:139] Epoch[264/1000] loss: 0.2017990936835607
I0803 20:01:11.001024  3068 trainer.py:139] Epoch[265/1000] loss: 0.20359578914112514
I0803 20:01:54.547464  3068 trainer.py:139] Epoch[266/1000] loss: 0.20287207113371955
I0803 20:02:38.580048  3068 trainer.py:139] Epoch[267/1000] loss: 0.20397783206568823
I0803 20:03:22.121772  3068 trainer.py:139] Epoch[268/1000] loss: 0.2024607163005405
I0803 20:04:06.231101  3068 trainer.py:139] Epoch[269/1000] loss: 0.20311469700601364
I0803 20:04:50.358455  3068 trainer.py:139] Epoch[270/1000] loss: 0.20318782607714336
I0803 20:05:34.471892  3068 trainer.py:139] Epoch[271/1000] loss: 0.20218530913194022
I0803 20:06:18.940356  3068 trainer.py:139] Epoch[272/1000] loss: 0.20274055673016442
I0803 20:07:03.105543  3068 trainer.py:139] Epoch[273/1000] loss: 0.20234768986701965
I0803 20:07:46.822791  3068 trainer.py:139] Epoch[274/1000] loss: 0.20259772492779626
I0803 20:08:30.757787  3068 trainer.py:139] Epoch[275/1000] loss: 0.2028400197956297
I0803 20:09:14.831273  3068 trainer.py:139] Epoch[276/1000] loss: 0.2016847687959671
I0803 20:09:58.956621  3068 trainer.py:139] Epoch[277/1000] loss: 0.20117907318804
I0803 20:10:43.273110  3068 trainer.py:139] Epoch[278/1000] loss: 0.20202371888690523
I0803 20:11:27.557954  3068 trainer.py:139] Epoch[279/1000] loss: 0.20237881302833557
I0803 20:12:11.870643  3068 trainer.py:139] Epoch[280/1000] loss: 0.20241126226054298
I0803 20:12:55.723097  3068 trainer.py:139] Epoch[281/1000] loss: 0.2018361304865943
I0803 20:13:39.719644  3068 trainer.py:139] Epoch[282/1000] loss: 0.20269636472066244
I0803 20:14:23.466108  3068 trainer.py:139] Epoch[283/1000] loss: 0.2021514023012585
I0803 20:15:07.022236  3068 trainer.py:139] Epoch[284/1000] loss: 0.2014012289709515
I0803 20:15:50.555322  3068 trainer.py:139] Epoch[285/1000] loss: 0.20214571469359927
I0803 20:16:34.083204  3068 trainer.py:139] Epoch[286/1000] loss: 0.2022518793741862
I0803 20:17:17.662684  3068 trainer.py:139] Epoch[287/1000] loss: 0.20254767994085948
I0803 20:18:01.975827  3068 trainer.py:139] Epoch[288/1000] loss: 0.20095896581808725
I0803 20:18:46.237708  3068 trainer.py:139] Epoch[289/1000] loss: 0.20171143313248951
I0803 20:19:30.576978  3068 trainer.py:139] Epoch[290/1000] loss: 0.20220963444974688
I0803 20:20:14.446382  3068 trainer.py:139] Epoch[291/1000] loss: 0.20210604833232032
I0803 20:20:58.381047  3068 trainer.py:139] Epoch[292/1000] loss: 0.20123225404156578
I0803 20:21:42.462856  3068 trainer.py:139] Epoch[293/1000] loss: 0.2023244031932619
I0803 20:22:25.885021  3068 trainer.py:139] Epoch[294/1000] loss: 0.20096256885263655
I0803 20:23:09.510261  3068 trainer.py:139] Epoch[295/1000] loss: 0.20255048010084364
I0803 20:23:53.705289  3068 trainer.py:139] Epoch[296/1000] loss: 0.20090465293990242
I0803 20:24:38.332992  3068 trainer.py:139] Epoch[297/1000] loss: 0.2007447717587153
I0803 20:25:22.716692  3068 trainer.py:139] Epoch[298/1000] loss: 0.20241661270459493
I0803 20:26:06.315318  3068 trainer.py:139] Epoch[299/1000] loss: 0.20206054720613692
I0803 20:26:06.915860  3068 trainer.py:145] Test: [{'precision': 0.20295492487479133, 'recall': 0.28555171398994045, 'hit_ratio': 0.9143572621035059, 'ndcg': 0.3203614436728094}]
I0803 20:26:51.204952  3068 trainer.py:139] Epoch[300/1000] loss: 0.20127251042260064
I0803 20:27:35.571165  3068 trainer.py:139] Epoch[301/1000] loss: 0.2007073848777347
I0803 20:28:19.773779  3068 trainer.py:139] Epoch[302/1000] loss: 0.2008096096250746
I0803 20:29:03.957249  3068 trainer.py:139] Epoch[303/1000] loss: 0.20108400245507557
I0803 20:29:48.706659  3068 trainer.py:139] Epoch[304/1000] loss: 0.20109359257751042
I0803 20:30:34.021871  3068 trainer.py:139] Epoch[305/1000] loss: 0.20088252186775207
I0803 20:31:18.809386  3068 trainer.py:139] Epoch[306/1000] loss: 0.2011348396539688
I0803 20:32:02.923883  3068 trainer.py:139] Epoch[307/1000] loss: 0.2013458945353826
I0803 20:32:46.924020  3068 trainer.py:139] Epoch[308/1000] loss: 0.2010903803507487
I0803 20:33:31.118983  3068 trainer.py:139] Epoch[309/1000] loss: 0.20050286538071102
I0803 20:34:15.784452  3068 trainer.py:139] Epoch[310/1000] loss: 0.20121011508835687
I0803 20:34:59.949774  3068 trainer.py:139] Epoch[311/1000] loss: 0.20118277827898662
I0803 20:35:44.241050  3068 trainer.py:139] Epoch[312/1000] loss: 0.20049026277330187
I0803 20:36:28.942312  3068 trainer.py:139] Epoch[313/1000] loss: 0.19979168951511384
I0803 20:37:14.146078  3068 trainer.py:139] Epoch[314/1000] loss: 0.20058376716242896
I0803 20:37:58.541338  3068 trainer.py:139] Epoch[315/1000] loss: 0.20126260234249962
I0803 20:38:42.985584  3068 trainer.py:139] Epoch[316/1000] loss: 0.20066387507650588
I0803 20:39:27.140005  3068 trainer.py:139] Epoch[317/1000] loss: 0.2005268919467926
I0803 20:40:11.272527  3068 trainer.py:139] Epoch[318/1000] loss: 0.1999802742401759
I0803 20:40:55.551956  3068 trainer.py:139] Epoch[319/1000] loss: 0.2018591539727317
I0803 20:41:40.073358  3068 trainer.py:139] Epoch[320/1000] loss: 0.20016071061293284
I0803 20:42:24.732427  3068 trainer.py:139] Epoch[321/1000] loss: 0.20075351688596937
I0803 20:43:09.587135  3068 trainer.py:139] Epoch[322/1000] loss: 0.2004929436577691
I0803 20:43:54.132705  3068 trainer.py:139] Epoch[323/1000] loss: 0.20070050173335605
I0803 20:44:38.144282  3068 trainer.py:139] Epoch[324/1000] loss: 0.20059542152616713
I0803 20:45:22.483998  3068 trainer.py:139] Epoch[325/1000] loss: 0.2010456269979477
I0803 20:46:06.910850  3068 trainer.py:139] Epoch[326/1000] loss: 0.20044061693880294
I0803 20:46:51.314842  3068 trainer.py:139] Epoch[327/1000] loss: 0.2000700169801712
I0803 20:47:35.827387  3068 trainer.py:139] Epoch[328/1000] loss: 0.2005403784248564
I0803 20:48:20.659891  3068 trainer.py:139] Epoch[329/1000] loss: 0.2011953545941247
I0803 20:49:05.051753  3068 trainer.py:139] Epoch[330/1000] loss: 0.2004590179522832
I0803 20:49:49.118938  3068 trainer.py:139] Epoch[331/1000] loss: 0.19978768659962548
I0803 20:50:33.738266  3068 trainer.py:139] Epoch[332/1000] loss: 0.19952132489946153
I0803 20:51:17.665751  3068 trainer.py:139] Epoch[333/1000] loss: 0.19981280505657195
I0803 20:52:02.192327  3068 trainer.py:139] Epoch[334/1000] loss: 0.19996412111653222
I0803 20:52:46.461694  3068 trainer.py:139] Epoch[335/1000] loss: 0.20004235923290253
I0803 20:53:30.756436  3068 trainer.py:139] Epoch[336/1000] loss: 0.20036004026730855
I0803 20:54:15.529797  3068 trainer.py:139] Epoch[337/1000] loss: 0.1998034440808826
I0803 20:55:00.420224  3068 trainer.py:139] Epoch[338/1000] loss: 0.19950161861048804
I0803 20:55:44.496521  3068 trainer.py:139] Epoch[339/1000] loss: 0.20093231088585323
I0803 20:56:28.789471  3068 trainer.py:139] Epoch[340/1000] loss: 0.1997667290767034
I0803 20:57:13.152104  3068 trainer.py:139] Epoch[341/1000] loss: 0.20067768699593014
I0803 20:57:57.429434  3068 trainer.py:139] Epoch[342/1000] loss: 0.19976912154091728
I0803 20:58:42.150019  3068 trainer.py:139] Epoch[343/1000] loss: 0.19974953836864895
I0803 20:59:26.470364  3068 trainer.py:139] Epoch[344/1000] loss: 0.19964582370387182
I0803 21:00:13.176955  3068 trainer.py:139] Epoch[345/1000] loss: 0.19970061891608767
I0803 21:01:00.105316  3068 trainer.py:139] Epoch[346/1000] loss: 0.19957232740190295
I0803 21:01:45.361931  3068 trainer.py:139] Epoch[347/1000] loss: 0.20019992199209002
I0803 21:02:29.809983  3068 trainer.py:139] Epoch[348/1000] loss: 0.20036379635334015
I0803 21:03:14.682319  3068 trainer.py:139] Epoch[349/1000] loss: 0.19902614567014906
I0803 21:03:15.247961  3068 trainer.py:145] Test: [{'precision': 0.20398998330550916, 'recall': 0.2873003838202904, 'hit_ratio': 0.915525876460768, 'ndcg': 0.322678748641555}]
I0803 21:04:00.164585  3068 trainer.py:139] Epoch[350/1000] loss: 0.20011661211649576
I0803 21:04:44.695767  3068 trainer.py:139] Epoch[351/1000] loss: 0.19973567141426934
I0803 21:05:29.808951  3068 trainer.py:139] Epoch[352/1000] loss: 0.19918104536003536
I0803 21:06:15.316793  3068 trainer.py:139] Epoch[353/1000] loss: 0.2000421209467782
I0803 21:07:00.473103  3068 trainer.py:139] Epoch[354/1000] loss: 0.20001671466562482
I0803 21:07:45.530323  3068 trainer.py:139] Epoch[355/1000] loss: 0.19888163208961487
I0803 21:08:30.687873  3068 trainer.py:139] Epoch[356/1000] loss: 0.19978271842002868
I0803 21:09:15.412795  3068 trainer.py:139] Epoch[357/1000] loss: 0.19831591248512268
I0803 21:10:00.557170  3068 trainer.py:139] Epoch[358/1000] loss: 0.1995739862653944
I0803 21:10:45.594517  3068 trainer.py:139] Epoch[359/1000] loss: 0.20055332991811964
I0803 21:11:30.796714  3068 trainer.py:139] Epoch[360/1000] loss: 0.19914413922362859
I0803 21:12:16.112823  3068 trainer.py:139] Epoch[361/1000] loss: 0.19962386846542357
I0803 21:13:01.247084  3068 trainer.py:139] Epoch[362/1000] loss: 0.19946221126450434
I0803 21:13:46.545103  3068 trainer.py:139] Epoch[363/1000] loss: 0.20000654015276167
I0803 21:14:31.325840  3068 trainer.py:139] Epoch[364/1000] loss: 0.20053189516067504
I0803 21:15:16.313084  3068 trainer.py:139] Epoch[365/1000] loss: 0.19986864527066547
I0803 21:16:01.438288  3068 trainer.py:139] Epoch[366/1000] loss: 0.19884976400269402
I0803 21:16:46.431654  3068 trainer.py:139] Epoch[367/1000] loss: 0.19898307998975118
I0803 21:17:31.599889  3068 trainer.py:139] Epoch[368/1000] loss: 0.19948399782180787
I0803 21:18:16.670075  3068 trainer.py:139] Epoch[369/1000] loss: 0.19945331480767992
I0803 21:19:01.908660  3068 trainer.py:139] Epoch[370/1000] loss: 0.1981084402402242
I0803 21:19:47.032104  3068 trainer.py:139] Epoch[371/1000] loss: 0.19878239353497823
I0803 21:20:31.861066  3068 trainer.py:139] Epoch[372/1000] loss: 0.19994591176509857
I0803 21:21:16.719628  3068 trainer.py:139] Epoch[373/1000] loss: 0.19976630946000418
I0803 21:22:01.950491  3068 trainer.py:139] Epoch[374/1000] loss: 0.19861258526643116
I0803 21:22:46.800861  3068 trainer.py:139] Epoch[375/1000] loss: 0.19938408381409115
I0803 21:23:31.780245  3068 trainer.py:139] Epoch[376/1000] loss: 0.19930634140968323
I0803 21:24:17.008007  3068 trainer.py:139] Epoch[377/1000] loss: 0.19857528342141045
I0803 21:25:02.066153  3068 trainer.py:139] Epoch[378/1000] loss: 0.19955225023958417
I0803 21:25:46.826543  3068 trainer.py:139] Epoch[379/1000] loss: 0.1987679835822847
I0803 21:26:31.603745  3068 trainer.py:139] Epoch[380/1000] loss: 0.19933157755268946
I0803 21:27:16.682241  3068 trainer.py:139] Epoch[381/1000] loss: 0.19973202341132693
I0803 21:28:01.658024  3068 trainer.py:139] Epoch[382/1000] loss: 0.1976893135574129
I0803 21:28:46.363457  3068 trainer.py:139] Epoch[383/1000] loss: 0.19857612782054476
I0803 21:29:31.171827  3068 trainer.py:139] Epoch[384/1000] loss: 0.1986663704448276
I0803 21:30:16.542095  3068 trainer.py:139] Epoch[385/1000] loss: 0.19870099478297765
I0803 21:31:01.779231  3068 trainer.py:139] Epoch[386/1000] loss: 0.1987881036599477
I0803 21:31:46.813324  3068 trainer.py:139] Epoch[387/1000] loss: 0.1990683126449585
I0803 21:32:31.356764  3068 trainer.py:139] Epoch[388/1000] loss: 0.19868139604727428
I0803 21:33:16.366152  3068 trainer.py:139] Epoch[389/1000] loss: 0.198935955564181
I0803 21:34:01.139078  3068 trainer.py:139] Epoch[390/1000] loss: 0.19934635288185543
I0803 21:34:46.117030  3068 trainer.py:139] Epoch[391/1000] loss: 0.19870129406452178
I0803 21:35:30.806044  3068 trainer.py:139] Epoch[392/1000] loss: 0.1995348358154297
I0803 21:36:15.500762  3068 trainer.py:139] Epoch[393/1000] loss: 0.1990933335489697
I0803 21:37:00.388674  3068 trainer.py:139] Epoch[394/1000] loss: 0.19832138465510474
I0803 21:37:44.912253  3068 trainer.py:139] Epoch[395/1000] loss: 0.19845919417010413
I0803 21:38:29.236957  3068 trainer.py:139] Epoch[396/1000] loss: 0.1986210364765591
I0803 21:39:13.779651  3068 trainer.py:139] Epoch[397/1000] loss: 0.19973165982299382
I0803 21:39:58.268822  3068 trainer.py:139] Epoch[398/1000] loss: 0.1987299691968494
I0803 21:40:43.041061  3068 trainer.py:139] Epoch[399/1000] loss: 0.1985914518435796
I0803 21:40:43.624111  3068 trainer.py:145] Test: [{'precision': 0.2046327212020033, 'recall': 0.28846189111481, 'hit_ratio': 0.9158597662771285, 'ndcg': 0.3234714420288457}]
I0803 21:41:28.507931  3068 trainer.py:139] Epoch[400/1000] loss: 0.19794901781611973
I0803 21:42:13.608607  3068 trainer.py:139] Epoch[401/1000] loss: 0.19821849789884355
I0803 21:42:58.682718  3068 trainer.py:139] Epoch[402/1000] loss: 0.19879580782519446
I0803 21:43:43.537496  3068 trainer.py:139] Epoch[403/1000] loss: 0.19835954937669967
I0803 21:44:28.404340  3068 trainer.py:139] Epoch[404/1000] loss: 0.19841035803159077
I0803 21:45:12.668613  3068 trainer.py:139] Epoch[405/1000] loss: 0.19851984977722167
I0803 21:45:57.508484  3068 trainer.py:139] Epoch[406/1000] loss: 0.19964963455994925
I0803 21:46:42.601303  3068 trainer.py:139] Epoch[407/1000] loss: 0.19866610911157395
I0803 21:47:27.501819  3068 trainer.py:139] Epoch[408/1000] loss: 0.19938427216476864
I0803 21:48:12.545976  3068 trainer.py:139] Epoch[409/1000] loss: 0.1976255679130554
I0803 21:48:57.876362  3068 trainer.py:139] Epoch[410/1000] loss: 0.19838271756966908
I0803 21:49:43.084042  3068 trainer.py:139] Epoch[411/1000] loss: 0.1981397369172838
I0803 21:50:28.170071  3068 trainer.py:139] Epoch[412/1000] loss: 0.19907195038265652
I0803 21:51:12.752514  3068 trainer.py:139] Epoch[413/1000] loss: 0.19872217575709025
I0803 21:51:57.662468  3068 trainer.py:139] Epoch[414/1000] loss: 0.1983562590016259
I0803 21:52:42.643864  3068 trainer.py:139] Epoch[415/1000] loss: 0.19829497906896804
I0803 21:53:27.512317  3068 trainer.py:139] Epoch[416/1000] loss: 0.19871977415349748
I0803 21:54:12.817189  3068 trainer.py:139] Epoch[417/1000] loss: 0.1975419181585312
I0803 21:54:58.130036  3068 trainer.py:139] Epoch[418/1000] loss: 0.19780298358864254
I0803 21:55:42.189169  3068 trainer.py:139] Epoch[419/1000] loss: 0.19864570769998763
I0803 21:56:26.690474  3068 trainer.py:139] Epoch[420/1000] loss: 0.19799685531192357
I0803 21:57:10.561743  3068 trainer.py:139] Epoch[421/1000] loss: 0.19758774333530002
I0803 21:57:53.785663  3068 trainer.py:139] Epoch[422/1000] loss: 0.19814358214537303
I0803 21:58:37.595817  3068 trainer.py:139] Epoch[423/1000] loss: 0.198544073038631
I0803 21:59:21.404145  3068 trainer.py:139] Epoch[424/1000] loss: 0.19815324319733513
I0803 22:00:05.988401  3068 trainer.py:139] Epoch[425/1000] loss: 0.1986296370294359
I0803 22:00:50.603797  3068 trainer.py:139] Epoch[426/1000] loss: 0.1992622752984365
I0803 22:01:35.092288  3068 trainer.py:139] Epoch[427/1000] loss: 0.1974482638306088
I0803 22:02:19.337044  3068 trainer.py:139] Epoch[428/1000] loss: 0.1976855837636524
I0803 22:03:03.271685  3068 trainer.py:139] Epoch[429/1000] loss: 0.1982331399122874
I0803 22:03:47.536438  3068 trainer.py:139] Epoch[430/1000] loss: 0.1970745449595981
I0803 22:04:31.517759  3068 trainer.py:139] Epoch[431/1000] loss: 0.1987862358490626
I0803 22:05:15.311553  3068 trainer.py:139] Epoch[432/1000] loss: 0.19914622883001964
I0803 22:05:59.990251  3068 trainer.py:139] Epoch[433/1000] loss: 0.1980874318546719
I0803 22:06:44.677967  3068 trainer.py:139] Epoch[434/1000] loss: 0.19718235923184288
I0803 22:07:29.068533  3068 trainer.py:139] Epoch[435/1000] loss: 0.19788538071844314
I0803 22:08:13.579211  3068 trainer.py:139] Epoch[436/1000] loss: 0.19851134028699663
I0803 22:08:57.276990  3068 trainer.py:139] Epoch[437/1000] loss: 0.19857520759105682
I0803 22:09:41.398000  3068 trainer.py:139] Epoch[438/1000] loss: 0.19808983471658495
I0803 22:10:25.765221  3068 trainer.py:139] Epoch[439/1000] loss: 0.1977765272723304
I0803 22:11:09.967397  3068 trainer.py:139] Epoch[440/1000] loss: 0.1978591154019038
I0803 22:11:53.990682  3068 trainer.py:139] Epoch[441/1000] loss: 0.19892684565650093
I0803 22:12:38.590219  3068 trainer.py:139] Epoch[442/1000] loss: 0.19784147924847073
I0803 22:13:22.518063  3068 trainer.py:139] Epoch[443/1000] loss: 0.19797406130366854
I0803 22:14:06.243169  3068 trainer.py:139] Epoch[444/1000] loss: 0.19721588591734568
I0803 22:14:50.002933  3068 trainer.py:139] Epoch[445/1000] loss: 0.1975028904941347
I0803 22:15:34.145803  3068 trainer.py:139] Epoch[446/1000] loss: 0.197005937827958
I0803 22:16:18.532446  3068 trainer.py:139] Epoch[447/1000] loss: 0.19740988731384276
I0803 22:17:01.311987  3068 trainer.py:139] Epoch[448/1000] loss: 0.1974047342273924
I0803 22:17:45.041682  3068 trainer.py:139] Epoch[449/1000] loss: 0.19870984461572436
I0803 22:17:45.630711  3068 trainer.py:145] Test: [{'precision': 0.20475792988313857, 'recall': 0.28862052420636813, 'hit_ratio': 0.9153589315525876, 'ndcg': 0.32315998053887884}]
I0803 22:18:30.163412  3068 trainer.py:139] Epoch[450/1000] loss: 0.19679169846905603
I0803 22:19:14.740811  3068 trainer.py:139] Epoch[451/1000] loss: 0.1978710358010398
I0803 22:19:59.316285  3068 trainer.py:139] Epoch[452/1000] loss: 0.19765422191884782
I0803 22:20:42.444448  3068 trainer.py:139] Epoch[453/1000] loss: 0.19773867256111569
I0803 22:21:26.273779  3068 trainer.py:139] Epoch[454/1000] loss: 0.19834741287761265
I0803 22:22:09.821509  3068 trainer.py:139] Epoch[455/1000] loss: 0.19792177153958215
I0803 22:22:52.833096  3068 trainer.py:139] Epoch[456/1000] loss: 0.1979998066690233
I0803 22:23:34.468024  3068 trainer.py:139] Epoch[457/1000] loss: 0.19798220210605197
I0803 22:24:18.692448  3068 trainer.py:139] Epoch[458/1000] loss: 0.196915746000078
I0803 22:25:03.349785  3068 trainer.py:139] Epoch[459/1000] loss: 0.19840911368529002
I0803 22:25:47.914439  3068 trainer.py:139] Epoch[460/1000] loss: 0.19735123587979211
I0803 22:26:32.460847  3068 trainer.py:139] Epoch[461/1000] loss: 0.19761425223615434
I0803 22:27:16.451564  3068 trainer.py:139] Epoch[462/1000] loss: 0.19821329553922018
I0803 22:28:00.884322  3068 trainer.py:139] Epoch[463/1000] loss: 0.19781375176376767
I0803 22:28:44.570265  3068 trainer.py:139] Epoch[464/1000] loss: 0.19709812170929378
I0803 22:29:28.523284  3068 trainer.py:139] Epoch[465/1000] loss: 0.1983033194144567
I0803 22:30:13.304172  3068 trainer.py:139] Epoch[466/1000] loss: 0.19787244843112098
I0803 22:30:57.917364  3068 trainer.py:139] Epoch[467/1000] loss: 0.19780961374441783
I0803 22:31:42.371563  3068 trainer.py:139] Epoch[468/1000] loss: 0.1981056539879905
I0803 22:32:27.349521  3068 trainer.py:139] Epoch[469/1000] loss: 0.19856131189399295
I0803 22:33:11.693012  3068 trainer.py:139] Epoch[470/1000] loss: 0.19747073047690922
I0803 22:33:56.360968  3068 trainer.py:139] Epoch[471/1000] loss: 0.19747456981076134
I0803 22:34:40.274625  3068 trainer.py:139] Epoch[472/1000] loss: 0.19768323832088047
I0803 22:35:24.811022  3068 trainer.py:139] Epoch[473/1000] loss: 0.1972525774108039
I0803 22:36:09.172127  3068 trainer.py:139] Epoch[474/1000] loss: 0.1981724762916565
I0803 22:36:53.599695  3068 trainer.py:139] Epoch[475/1000] loss: 0.19769184033075968
I0803 22:37:38.283885  3068 trainer.py:139] Epoch[476/1000] loss: 0.19698271526230707
I0803 22:38:22.585110  3068 trainer.py:139] Epoch[477/1000] loss: 0.197928071419398
I0803 22:39:07.337604  3068 trainer.py:139] Epoch[478/1000] loss: 0.1971937968995836
I0803 22:39:51.757014  3068 trainer.py:139] Epoch[479/1000] loss: 0.19771460188759699
I0803 22:40:36.179737  3068 trainer.py:139] Epoch[480/1000] loss: 0.19882727053430346
I0803 22:41:20.274023  3068 trainer.py:139] Epoch[481/1000] loss: 0.1978111129336887
I0803 22:42:05.091993  3068 trainer.py:139] Epoch[482/1000] loss: 0.19680088771714105
I0803 22:42:50.296080  3068 trainer.py:139] Epoch[483/1000] loss: 0.19763393137190077
I0803 22:43:34.930680  3068 trainer.py:139] Epoch[484/1000] loss: 0.19824781543678707
I0803 22:44:19.488829  3068 trainer.py:139] Epoch[485/1000] loss: 0.19679387158817715
I0803 22:45:04.161048  3068 trainer.py:139] Epoch[486/1000] loss: 0.1974246476093928
I0803 22:45:48.671034  3068 trainer.py:139] Epoch[487/1000] loss: 0.19752212603886923
I0803 22:46:32.861125  3068 trainer.py:139] Epoch[488/1000] loss: 0.19665265599886575
I0803 22:47:17.008121  3068 trainer.py:139] Epoch[489/1000] loss: 0.19743873728646172
I0803 22:48:01.488361  3068 trainer.py:139] Epoch[490/1000] loss: 0.19795402103000218
I0803 22:48:45.792762  3068 trainer.py:139] Epoch[491/1000] loss: 0.1978592562675476
I0803 22:49:29.722734  3068 trainer.py:139] Epoch[492/1000] loss: 0.19750321606794993
I0803 22:50:13.861466  3068 trainer.py:139] Epoch[493/1000] loss: 0.19746570176548428
I0803 22:50:58.572732  3068 trainer.py:139] Epoch[494/1000] loss: 0.19708718021710714
I0803 22:51:42.360883  3068 trainer.py:139] Epoch[495/1000] loss: 0.19732140368885465
I0803 22:52:26.798691  3068 trainer.py:139] Epoch[496/1000] loss: 0.1971356319056617
I0803 22:53:10.709214  3068 trainer.py:139] Epoch[497/1000] loss: 0.19783971356021032
I0803 22:53:55.380915  3068 trainer.py:139] Epoch[498/1000] loss: 0.19745033608542548
I0803 22:54:39.909924  3068 trainer.py:139] Epoch[499/1000] loss: 0.19656214892864227
I0803 22:54:40.511910  3068 trainer.py:145] Test: [{'precision': 0.20487479131886477, 'recall': 0.2887611043759914, 'hit_ratio': 0.915025041736227, 'ndcg': 0.3238371827182539}]
I0803 22:55:25.268621  3068 trainer.py:139] Epoch[500/1000] loss: 0.19710270676347943
I0803 22:56:10.225753  3068 trainer.py:139] Epoch[501/1000] loss: 0.19765478558010524
I0803 22:56:55.048047  3068 trainer.py:139] Epoch[502/1000] loss: 0.1975683801703983
I0803 22:57:39.850042  3068 trainer.py:139] Epoch[503/1000] loss: 0.19757359743118286
I0803 22:58:23.676804  3068 trainer.py:139] Epoch[504/1000] loss: 0.1959292205174764
I0803 22:59:08.624626  3068 trainer.py:139] Epoch[505/1000] loss: 0.19735045803917778
I0803 22:59:53.370105  3068 trainer.py:139] Epoch[506/1000] loss: 0.1971251701646381
I0803 23:00:38.577135  3068 trainer.py:139] Epoch[507/1000] loss: 0.19753934231069353
I0803 23:01:23.363057  3068 trainer.py:139] Epoch[508/1000] loss: 0.1963789541191525
I0803 23:02:07.978863  3068 trainer.py:139] Epoch[509/1000] loss: 0.1976333973142836
I0803 23:02:51.358610  3068 trainer.py:139] Epoch[510/1000] loss: 0.19728059629599254
I0803 23:03:36.288569  3068 trainer.py:139] Epoch[511/1000] loss: 0.19640376130739848
I0803 23:04:20.706628  3068 trainer.py:139] Epoch[512/1000] loss: 0.19743272370762296
I0803 23:05:04.929173  3068 trainer.py:139] Epoch[513/1000] loss: 0.19662286990218691
I0803 23:05:48.926356  3068 trainer.py:139] Epoch[514/1000] loss: 0.1972396785683102
I0803 23:06:33.625561  3068 trainer.py:139] Epoch[515/1000] loss: 0.19708086801899805
I0803 23:07:18.225150  3068 trainer.py:139] Epoch[516/1000] loss: 0.19747052888075511
I0803 23:08:02.500906  3068 trainer.py:139] Epoch[517/1000] loss: 0.19722465415795645
I0803 23:08:47.135323  3068 trainer.py:139] Epoch[518/1000] loss: 0.19675395766894022
I0803 23:09:31.698767  3068 trainer.py:139] Epoch[519/1000] loss: 0.1971116183201472
I0803 23:10:16.162984  3068 trainer.py:139] Epoch[520/1000] loss: 0.19673530214362675
I0803 23:10:59.816581  3068 trainer.py:139] Epoch[521/1000] loss: 0.19733307037088607
I0803 23:11:43.900275  3068 trainer.py:139] Epoch[522/1000] loss: 0.19767305387390985
I0803 23:12:28.686187  3068 trainer.py:139] Epoch[523/1000] loss: 0.19637467940648398
I0803 23:13:13.326946  3068 trainer.py:139] Epoch[524/1000] loss: 0.19800603118207719
I0803 23:13:58.008116  3068 trainer.py:139] Epoch[525/1000] loss: 0.19762187467681036
I0803 23:14:42.680505  3068 trainer.py:139] Epoch[526/1000] loss: 0.19774227254920534
I0803 23:15:27.480878  3068 trainer.py:139] Epoch[527/1000] loss: 0.19740624964237213
I0803 23:16:11.972170  3068 trainer.py:139] Epoch[528/1000] loss: 0.19649865958425733
I0803 23:16:56.863610  3068 trainer.py:139] Epoch[529/1000] loss: 0.19617403441005282
I0803 23:17:41.179597  3068 trainer.py:139] Epoch[530/1000] loss: 0.19688339703612856
I0803 23:18:26.144008  3068 trainer.py:139] Epoch[531/1000] loss: 0.19763855874538422
I0803 23:19:11.107441  3068 trainer.py:139] Epoch[532/1000] loss: 0.19713073167535994
I0803 23:19:55.784974  3068 trainer.py:139] Epoch[533/1000] loss: 0.19683286163542005
I0803 23:20:39.393356  3068 trainer.py:139] Epoch[534/1000] loss: 0.1974126023054123
I0803 23:21:23.228585  3068 trainer.py:139] Epoch[535/1000] loss: 0.19729317439926994
I0803 23:22:07.431235  3068 trainer.py:139] Epoch[536/1000] loss: 0.19694135977162255
I0803 23:22:52.447552  3068 trainer.py:139] Epoch[537/1000] loss: 0.19699430624643963
I0803 23:23:37.141762  3068 trainer.py:139] Epoch[538/1000] loss: 0.19684498012065887
I0803 23:24:22.200201  3068 trainer.py:139] Epoch[539/1000] loss: 0.19677204509576163
I0803 23:25:06.464728  3068 trainer.py:139] Epoch[540/1000] loss: 0.19717832187811535
I0803 23:25:50.379601  3068 trainer.py:139] Epoch[541/1000] loss: 0.1972398497660955
I0803 23:26:34.158153  3068 trainer.py:139] Epoch[542/1000] loss: 0.1969351789686415
I0803 23:27:18.335379  3068 trainer.py:139] Epoch[543/1000] loss: 0.19688869456450145
I0803 23:28:02.404778  3068 trainer.py:139] Epoch[544/1000] loss: 0.19567445132467481
I0803 23:28:47.153198  3068 trainer.py:139] Epoch[545/1000] loss: 0.19809233533011542
I0803 23:29:31.291971  3068 trainer.py:139] Epoch[546/1000] loss: 0.19722337789005703
I0803 23:30:16.078230  3068 trainer.py:139] Epoch[547/1000] loss: 0.1971100785334905
I0803 23:31:01.193928  3068 trainer.py:139] Epoch[548/1000] loss: 0.19668223222096762
I0803 23:31:45.644925  3068 trainer.py:139] Epoch[549/1000] loss: 0.19656238277753194
I0803 23:31:46.235172  3068 trainer.py:145] Test: [{'precision': 0.20509181969949913, 'recall': 0.289623330065225, 'hit_ratio': 0.9165275459098498, 'ndcg': 0.32417160923678684}]
I0803 23:32:30.688100  3068 trainer.py:139] Epoch[550/1000] loss: 0.19813773115475972
I0803 23:33:15.356646  3068 trainer.py:139] Epoch[551/1000] loss: 0.1967199812332789
I0803 23:34:00.400754  3068 trainer.py:139] Epoch[552/1000] loss: 0.19698074903753068
I0803 23:34:44.993348  3068 trainer.py:139] Epoch[553/1000] loss: 0.19724403295252058
I0803 23:35:29.664108  3068 trainer.py:139] Epoch[554/1000] loss: 0.19727239343855116
I0803 23:36:14.384255  3068 trainer.py:139] Epoch[555/1000] loss: 0.19593310217062632
I0803 23:36:59.319964  3068 trainer.py:139] Epoch[556/1000] loss: 0.19603623807430268
I0803 23:37:44.540493  3068 trainer.py:139] Epoch[557/1000] loss: 0.19625997755262586
I0803 23:38:29.394186  3068 trainer.py:139] Epoch[558/1000] loss: 0.19680356270737118
I0803 23:39:14.269406  3068 trainer.py:139] Epoch[559/1000] loss: 0.19718597855832842
I0803 23:39:59.342726  3068 trainer.py:139] Epoch[560/1000] loss: 0.19623686439461177
I0803 23:40:43.920702  3068 trainer.py:139] Epoch[561/1000] loss: 0.19710144665506152
I0803 23:41:28.733001  3068 trainer.py:139] Epoch[562/1000] loss: 0.1960706564452913
I0803 23:42:14.010950  3068 trainer.py:139] Epoch[563/1000] loss: 0.1961532484822803
I0803 23:42:59.289017  3068 trainer.py:139] Epoch[564/1000] loss: 0.19663772986994849
I0803 23:43:44.281300  3068 trainer.py:139] Epoch[565/1000] loss: 0.19697942508591545
I0803 23:44:29.238139  3068 trainer.py:139] Epoch[566/1000] loss: 0.19663145932886336
I0803 23:45:13.607568  3068 trainer.py:139] Epoch[567/1000] loss: 0.1974155475695928
I0803 23:45:58.384398  3068 trainer.py:139] Epoch[568/1000] loss: 0.1963932900958591
I0803 23:46:43.132508  3068 trainer.py:139] Epoch[569/1000] loss: 0.19629936357339223
I0803 23:47:28.093475  3068 trainer.py:139] Epoch[570/1000] loss: 0.1952040390835868
I0803 23:48:13.031961  3068 trainer.py:139] Epoch[571/1000] loss: 0.1966418280866411
I0803 23:48:57.866659  3068 trainer.py:139] Epoch[572/1000] loss: 0.19650343577067056
I0803 23:49:42.516715  3068 trainer.py:139] Epoch[573/1000] loss: 0.19590671334001752
I0803 23:50:27.385611  3068 trainer.py:139] Epoch[574/1000] loss: 0.19659685989220937
I0803 23:51:12.059097  3068 trainer.py:139] Epoch[575/1000] loss: 0.19571686135398017
I0803 23:51:56.821682  3068 trainer.py:139] Epoch[576/1000] loss: 0.1959793221950531
I0803 23:52:41.391038  3068 trainer.py:139] Epoch[577/1000] loss: 0.19681928045219846
I0803 23:53:26.021770  3068 trainer.py:139] Epoch[578/1000] loss: 0.1964026457733578
I0803 23:54:10.696814  3068 trainer.py:139] Epoch[579/1000] loss: 0.19633069574832918
I0803 23:54:55.474002  3068 trainer.py:139] Epoch[580/1000] loss: 0.19678851505120595
I0803 23:55:39.859547  3068 trainer.py:139] Epoch[581/1000] loss: 0.19625557521979015
I0803 23:56:24.650035  3068 trainer.py:139] Epoch[582/1000] loss: 0.19708898829089272
I0803 23:57:09.116037  3068 trainer.py:139] Epoch[583/1000] loss: 0.1966648370689816
I0803 23:57:54.119870  3068 trainer.py:139] Epoch[584/1000] loss: 0.19684594227208033
I0803 23:58:38.820621  3068 trainer.py:139] Epoch[585/1000] loss: 0.1968148054016961
I0803 23:59:23.411602  3068 trainer.py:139] Epoch[586/1000] loss: 0.19689254257414077
I0804 00:00:08.141076  3068 trainer.py:139] Epoch[587/1000] loss: 0.19611029691166348
I0804 00:00:52.991344  3068 trainer.py:139] Epoch[588/1000] loss: 0.19725382023387486
I0804 00:01:37.588512  3068 trainer.py:139] Epoch[589/1000] loss: 0.1963738113641739
I0804 00:02:22.175392  3068 trainer.py:139] Epoch[590/1000] loss: 0.1970514495505227
I0804 00:03:06.254928  3068 trainer.py:139] Epoch[591/1000] loss: 0.1960557132297092
I0804 00:03:50.984917  3068 trainer.py:139] Epoch[592/1000] loss: 0.19570926407972972
I0804 00:04:35.870149  3068 trainer.py:139] Epoch[593/1000] loss: 0.1953871203131146
I0804 00:05:20.776753  3068 trainer.py:139] Epoch[594/1000] loss: 0.1957329981194602
I0804 00:06:05.772478  3068 trainer.py:139] Epoch[595/1000] loss: 0.19656909392939673
I0804 00:06:50.292148  3068 trainer.py:139] Epoch[596/1000] loss: 0.1961556886964374
I0804 00:07:35.083092  3068 trainer.py:139] Epoch[597/1000] loss: 0.19703738252321878
I0804 00:08:20.069925  3068 trainer.py:139] Epoch[598/1000] loss: 0.195528597301907
I0804 00:09:04.674331  3068 trainer.py:139] Epoch[599/1000] loss: 0.1966092730893029
I0804 00:09:05.252930  3068 trainer.py:145] Test: [{'precision': 0.2053839732888147, 'recall': 0.2891479860146974, 'hit_ratio': 0.9161936560934891, 'ndcg': 0.32474423945388736}]
I0804 00:09:49.956144  3068 trainer.py:139] Epoch[600/1000] loss: 0.1960141932302051
I0804 00:10:34.920857  3068 trainer.py:139] Epoch[601/1000] loss: 0.19684998234113057
I0804 00:11:19.607840  3068 trainer.py:139] Epoch[602/1000] loss: 0.19626953177981907
I0804 00:12:04.392202  3068 trainer.py:139] Epoch[603/1000] loss: 0.19590351111359067
I0804 00:12:49.405261  3068 trainer.py:139] Epoch[604/1000] loss: 0.19587413138813442
I0804 00:13:34.027996  3068 trainer.py:139] Epoch[605/1000] loss: 0.19606378495693208
I0804 00:14:18.867225  3068 trainer.py:139] Epoch[606/1000] loss: 0.19666447619597116
I0804 00:15:03.560893  3068 trainer.py:139] Epoch[607/1000] loss: 0.19529724988672467
I0804 00:15:48.662876  3068 trainer.py:139] Epoch[608/1000] loss: 0.19681842075453865
I0804 00:16:33.587942  3068 trainer.py:139] Epoch[609/1000] loss: 0.19614018632305993
I0804 00:17:18.357086  3068 trainer.py:139] Epoch[610/1000] loss: 0.19734309474627176
I0804 00:18:03.335092  3068 trainer.py:139] Epoch[611/1000] loss: 0.1961524403757519
I0804 00:18:48.015539  3068 trainer.py:139] Epoch[612/1000] loss: 0.1975346592399809
I0804 00:19:32.793413  3068 trainer.py:139] Epoch[613/1000] loss: 0.19575388616985745
I0804 00:20:17.786571  3068 trainer.py:139] Epoch[614/1000] loss: 0.19624078081713783
I0804 00:21:02.649423  3068 trainer.py:139] Epoch[615/1000] loss: 0.19534821603033278
I0804 00:21:47.431636  3068 trainer.py:139] Epoch[616/1000] loss: 0.1968174103895823
I0804 00:22:32.313037  3068 trainer.py:139] Epoch[617/1000] loss: 0.19555698573589325
I0804 00:23:16.996215  3068 trainer.py:139] Epoch[618/1000] loss: 0.19659520910845862
I0804 00:24:01.794594  3068 trainer.py:139] Epoch[619/1000] loss: 0.19620256384213766
I0804 00:24:46.480333  3068 trainer.py:139] Epoch[620/1000] loss: 0.19770411524507733
I0804 00:25:31.162595  3068 trainer.py:139] Epoch[621/1000] loss: 0.19619859761661954
I0804 00:26:16.100190  3068 trainer.py:139] Epoch[622/1000] loss: 0.1962343199385537
I0804 00:27:00.802742  3068 trainer.py:139] Epoch[623/1000] loss: 0.19626668565803104
I0804 00:27:44.770648  3068 trainer.py:139] Epoch[624/1000] loss: 0.19659065776401097
I0804 00:28:29.360487  3068 trainer.py:139] Epoch[625/1000] loss: 0.196219997604688
I0804 00:29:13.728581  3068 trainer.py:139] Epoch[626/1000] loss: 0.19555608325534396
I0804 00:29:58.694346  3068 trainer.py:139] Epoch[627/1000] loss: 0.19681337820159064
I0804 00:30:43.257308  3068 trainer.py:139] Epoch[628/1000] loss: 0.19638809508747523
I0804 00:31:28.319386  3068 trainer.py:139] Epoch[629/1000] loss: 0.19508007804552713
I0804 00:32:13.373035  3068 trainer.py:139] Epoch[630/1000] loss: 0.195566934744517
I0804 00:32:58.457351  3068 trainer.py:139] Epoch[631/1000] loss: 0.19586966858969795
I0804 00:33:43.098371  3068 trainer.py:139] Epoch[632/1000] loss: 0.1960988105667962
I0804 00:34:25.953344  3068 trainer.py:139] Epoch[633/1000] loss: 0.19698650194538964
I0804 00:35:11.018412  3068 trainer.py:139] Epoch[634/1000] loss: 0.19545609368218317
I0804 00:35:55.933812  3068 trainer.py:139] Epoch[635/1000] loss: 0.19654284589820437
I0804 00:36:41.015795  3068 trainer.py:139] Epoch[636/1000] loss: 0.19694262504577636
I0804 00:37:25.928800  3068 trainer.py:139] Epoch[637/1000] loss: 0.19655234416325887
I0804 00:38:10.658596  3068 trainer.py:139] Epoch[638/1000] loss: 0.19634126073784297
I0804 00:38:55.608630  3068 trainer.py:139] Epoch[639/1000] loss: 0.19583643052313063
I0804 00:39:40.568560  3068 trainer.py:139] Epoch[640/1000] loss: 0.19537840240531498
I0804 00:40:25.378102  3068 trainer.py:139] Epoch[641/1000] loss: 0.19610751549402872
I0804 00:41:10.302467  3068 trainer.py:139] Epoch[642/1000] loss: 0.19641754812664455
I0804 00:41:54.959920  3068 trainer.py:139] Epoch[643/1000] loss: 0.1959122477637397
I0804 00:42:40.255020  3068 trainer.py:139] Epoch[644/1000] loss: 0.1970449471473694
I0804 00:43:25.219439  3068 trainer.py:139] Epoch[645/1000] loss: 0.19617431104183197
I0804 00:44:09.890738  3068 trainer.py:139] Epoch[646/1000] loss: 0.19591796550485824
I0804 00:44:54.675339  3068 trainer.py:139] Epoch[647/1000] loss: 0.19579661468664805
I0804 00:45:39.167770  3068 trainer.py:139] Epoch[648/1000] loss: 0.1954230229722129
I0804 00:46:24.206218  3068 trainer.py:139] Epoch[649/1000] loss: 0.1954087632894516
I0804 00:46:24.770330  3068 trainer.py:145] Test: [{'precision': 0.20509181969949916, 'recall': 0.2893088543414856, 'hit_ratio': 0.915525876460768, 'ndcg': 0.32447536576773756}]
I0804 00:47:09.541246  3068 trainer.py:139] Epoch[650/1000] loss: 0.19541378213299646
I0804 00:47:54.398780  3068 trainer.py:139] Epoch[651/1000] loss: 0.19638583593898348
I0804 00:48:39.483492  3068 trainer.py:139] Epoch[652/1000] loss: 0.19657184375656975
I0804 00:49:24.308058  3068 trainer.py:139] Epoch[653/1000] loss: 0.19592262513107725
I0804 00:50:09.148587  3068 trainer.py:139] Epoch[654/1000] loss: 0.19594686693615385
I0804 00:50:53.958822  3068 trainer.py:139] Epoch[655/1000] loss: 0.1971856360965305
I0804 00:51:38.869402  3068 trainer.py:139] Epoch[656/1000] loss: 0.19605049696233537
I0804 00:52:23.389736  3068 trainer.py:139] Epoch[657/1000] loss: 0.19724890185727015
I0804 00:53:07.915713  3068 trainer.py:139] Epoch[658/1000] loss: 0.19584426250722672
I0804 00:53:52.821864  3068 trainer.py:139] Epoch[659/1000] loss: 0.196480064590772
I0804 00:54:37.809305  3068 trainer.py:139] Epoch[660/1000] loss: 0.19698997305499183
I0804 00:55:22.757757  3068 trainer.py:139] Epoch[661/1000] loss: 0.1957977726062139
I0804 00:56:07.735781  3068 trainer.py:139] Epoch[662/1000] loss: 0.19631924112637839
I0804 00:56:52.253716  3068 trainer.py:139] Epoch[663/1000] loss: 0.19647662666108873
I0804 00:57:37.220473  3068 trainer.py:139] Epoch[664/1000] loss: 0.19607763588428498
I0804 00:58:22.141142  3068 trainer.py:139] Epoch[665/1000] loss: 0.19568655636575488
I0804 00:59:06.807599  3068 trainer.py:139] Epoch[666/1000] loss: 0.19529322160614862
I0804 00:59:51.485922  3068 trainer.py:139] Epoch[667/1000] loss: 0.1965307793352339
I0804 01:00:36.344905  3068 trainer.py:139] Epoch[668/1000] loss: 0.1963044579161538
I0804 01:01:21.326330  3068 trainer.py:139] Epoch[669/1000] loss: 0.19621654795275795
I0804 01:02:06.084197  3068 trainer.py:139] Epoch[670/1000] loss: 0.19572942051622602
I0804 01:02:50.674813  3068 trainer.py:139] Epoch[671/1000] loss: 0.19635451647970412
I0804 01:03:35.065080  3068 trainer.py:139] Epoch[672/1000] loss: 0.19599526385466257
I0804 01:04:19.653733  3068 trainer.py:139] Epoch[673/1000] loss: 0.19654669463634492
I0804 01:05:03.717106  3068 trainer.py:139] Epoch[674/1000] loss: 0.19555468029446071
I0804 01:05:48.353780  3068 trainer.py:139] Epoch[675/1000] loss: 0.19632494005892012
I0804 01:06:33.290770  3068 trainer.py:139] Epoch[676/1000] loss: 0.19593593895435332
I0804 01:07:18.070048  3068 trainer.py:139] Epoch[677/1000] loss: 0.196374499268002
I0804 01:08:02.940994  3068 trainer.py:139] Epoch[678/1000] loss: 0.19648087912135653
I0804 01:08:47.314436  3068 trainer.py:139] Epoch[679/1000] loss: 0.1964339448346032
I0804 01:09:32.259900  3068 trainer.py:139] Epoch[680/1000] loss: 0.19636631906032562
I0804 01:10:17.241574  3068 trainer.py:139] Epoch[681/1000] loss: 0.19660216980510287
I0804 01:11:00.910078  3068 trainer.py:139] Epoch[682/1000] loss: 0.19687072270446354
I0804 01:11:44.812562  3068 trainer.py:139] Epoch[683/1000] loss: 0.1950575589471393
I0804 01:12:29.654032  3068 trainer.py:139] Epoch[684/1000] loss: 0.1963618473874198
I0804 01:13:14.400064  3068 trainer.py:139] Epoch[685/1000] loss: 0.19610276175869837
I0804 01:13:59.576243  3068 trainer.py:139] Epoch[686/1000] loss: 0.196329312854343
I0804 01:14:44.540520  3068 trainer.py:139] Epoch[687/1000] loss: 0.19668482879797616
I0804 01:15:29.536288  3068 trainer.py:139] Epoch[688/1000] loss: 0.19675784051418305
I0804 01:16:14.360359  3068 trainer.py:139] Epoch[689/1000] loss: 0.19590744468900892
I0804 01:16:59.290789  3068 trainer.py:139] Epoch[690/1000] loss: 0.19680453485912747
I0804 01:17:43.931536  3068 trainer.py:139] Epoch[691/1000] loss: 0.19634755770365397
I0804 01:18:28.864982  3068 trainer.py:139] Epoch[692/1000] loss: 0.19655352135499318
I0804 01:19:13.821352  3068 trainer.py:139] Epoch[693/1000] loss: 0.19585301770104302
I0804 01:19:58.496416  3068 trainer.py:139] Epoch[694/1000] loss: 0.1958291333913803
I0804 01:20:42.073278  3068 trainer.py:139] Epoch[695/1000] loss: 0.1967202776008182
I0804 01:21:25.566002  3068 trainer.py:139] Epoch[696/1000] loss: 0.19544266323248546
I0804 01:22:10.423215  3068 trainer.py:139] Epoch[697/1000] loss: 0.19650169200367398
I0804 01:22:55.428157  3068 trainer.py:139] Epoch[698/1000] loss: 0.19586635794904497
I0804 01:23:40.496517  3068 trainer.py:139] Epoch[699/1000] loss: 0.19636519683731926
I0804 01:23:41.074165  3068 trainer.py:145] Test: [{'precision': 0.20533388981636053, 'recall': 0.2897499018998857, 'hit_ratio': 0.9156928213689483, 'ndcg': 0.32488937142212965}]
I0804 01:24:25.994859  3068 trainer.py:139] Epoch[700/1000] loss: 0.19626128514607746
I0804 01:25:10.858373  3068 trainer.py:139] Epoch[701/1000] loss: 0.1949593946006563
I0804 01:25:55.404358  3068 trainer.py:139] Epoch[702/1000] loss: 0.19607347475157844
I0804 01:26:39.704349  3068 trainer.py:139] Epoch[703/1000] loss: 0.19705385227998098
I0804 01:27:24.321825  3068 trainer.py:139] Epoch[704/1000] loss: 0.1956258632739385
I0804 01:28:09.007103  3068 trainer.py:139] Epoch[705/1000] loss: 0.19631506158245934
I0804 01:28:53.564223  3068 trainer.py:139] Epoch[706/1000] loss: 0.19577740808327992
I0804 01:29:37.958858  3068 trainer.py:139] Epoch[707/1000] loss: 0.19502532502015432
I0804 01:30:22.747655  3068 trainer.py:139] Epoch[708/1000] loss: 0.1957496127155092
I0804 01:31:07.238328  3068 trainer.py:139] Epoch[709/1000] loss: 0.1959356798066033
I0804 01:31:52.109996  3068 trainer.py:139] Epoch[710/1000] loss: 0.19565404805872175
I0804 01:32:37.206165  3068 trainer.py:139] Epoch[711/1000] loss: 0.19562193969885508
I0804 01:33:20.578151  3068 trainer.py:139] Epoch[712/1000] loss: 0.19556942462921142
I0804 01:34:05.444071  3068 trainer.py:139] Epoch[713/1000] loss: 0.19613235818015204
I0804 01:34:50.533840  3068 trainer.py:139] Epoch[714/1000] loss: 0.1947832585705651
I0804 01:35:35.580299  3068 trainer.py:139] Epoch[715/1000] loss: 0.19544451422161527
I0804 01:36:20.150007  3068 trainer.py:139] Epoch[716/1000] loss: 0.19543896701600816
I0804 01:37:05.072370  3068 trainer.py:139] Epoch[717/1000] loss: 0.19536108725600773
I0804 01:37:49.749596  3068 trainer.py:139] Epoch[718/1000] loss: 0.19604150917794969
I0804 01:38:34.246647  3068 trainer.py:139] Epoch[719/1000] loss: 0.19551747216118706
I0804 01:39:19.298717  3068 trainer.py:139] Epoch[720/1000] loss: 0.19512051906850603
I0804 01:40:04.088779  3068 trainer.py:139] Epoch[721/1000] loss: 0.19523876607418061
I0804 01:40:48.771740  3068 trainer.py:139] Epoch[722/1000] loss: 0.19639217429690892
I0804 01:41:33.880727  3068 trainer.py:139] Epoch[723/1000] loss: 0.19622728678915236
I0804 01:42:18.943675  3068 trainer.py:139] Epoch[724/1000] loss: 0.19611446585920123
I0804 01:43:03.270684  3068 trainer.py:139] Epoch[725/1000] loss: 0.1957905564043257
I0804 01:43:47.850281  3068 trainer.py:139] Epoch[726/1000] loss: 0.19629989167054493
I0804 01:44:32.522639  3068 trainer.py:139] Epoch[727/1000] loss: 0.19502362747987112
I0804 01:45:17.367349  3068 trainer.py:139] Epoch[728/1000] loss: 0.19622556295659807
I0804 01:46:02.403166  3068 trainer.py:139] Epoch[729/1000] loss: 0.1959190077914132
I0804 01:46:47.583849  3068 trainer.py:139] Epoch[730/1000] loss: 0.19609717534648047
I0804 01:47:32.567016  3068 trainer.py:139] Epoch[731/1000] loss: 0.19540896157423654
I0804 01:48:17.203803  3068 trainer.py:139] Epoch[732/1000] loss: 0.19531208283371396
I0804 01:49:02.208425  3068 trainer.py:139] Epoch[733/1000] loss: 0.196831533908844
I0804 01:49:46.720777  3068 trainer.py:139] Epoch[734/1000] loss: 0.19636488841639624
I0804 01:50:31.447877  3068 trainer.py:139] Epoch[735/1000] loss: 0.1955225357082155
I0804 01:51:16.274173  3068 trainer.py:139] Epoch[736/1000] loss: 0.19611677991019355
I0804 01:52:00.959420  3068 trainer.py:139] Epoch[737/1000] loss: 0.19509693119261
I0804 01:52:46.168731  3068 trainer.py:139] Epoch[738/1000] loss: 0.19599915312396154
I0804 01:53:31.052697  3068 trainer.py:139] Epoch[739/1000] loss: 0.19664310720231798
I0804 01:54:16.255128  3068 trainer.py:139] Epoch[740/1000] loss: 0.1959614987505807
I0804 01:55:01.323335  3068 trainer.py:139] Epoch[741/1000] loss: 0.1963763658867942
I0804 01:55:46.413016  3068 trainer.py:139] Epoch[742/1000] loss: 0.1953061177333196
I0804 01:56:31.183037  3068 trainer.py:139] Epoch[743/1000] loss: 0.1954194955031077
I0804 01:57:14.742376  3068 trainer.py:139] Epoch[744/1000] loss: 0.19580735272831387
I0804 01:57:59.783534  3068 trainer.py:139] Epoch[745/1000] loss: 0.19501677950223287
I0804 01:58:43.686118  3068 trainer.py:139] Epoch[746/1000] loss: 0.19572224391831292
I0804 01:59:26.873492  3068 trainer.py:139] Epoch[747/1000] loss: 0.19609893918037413
I0804 02:00:11.918312  3068 trainer.py:139] Epoch[748/1000] loss: 0.1961662648121516
I0804 02:00:56.934015  3068 trainer.py:139] Epoch[749/1000] loss: 0.19595018910037146
I0804 02:00:57.512122  3068 trainer.py:145] Test: [{'precision': 0.20513355592654425, 'recall': 0.290673179184316, 'hit_ratio': 0.9180267111853089, 'ndcg': 0.3285665855556306}]
I0804 02:01:42.184364  3068 trainer.py:139] Epoch[750/1000] loss: 0.1965662337674035
I0804 02:02:27.303361  3068 trainer.py:139] Epoch[751/1000] loss: 0.1967006900575426
I0804 02:03:12.288095  3068 trainer.py:139] Epoch[752/1000] loss: 0.19559111807081433
I0804 02:03:56.862477  3068 trainer.py:139] Epoch[753/1000] loss: 0.19590563244289821
I0804 02:04:41.824049  3068 trainer.py:139] Epoch[754/1000] loss: 0.19669294291072423
I0804 02:05:26.460250  3068 trainer.py:139] Epoch[755/1000] loss: 0.1966245863172743
I0804 02:06:11.499175  3068 trainer.py:139] Epoch[756/1000] loss: 0.19540088435014089
I0804 02:06:56.197177  3068 trainer.py:139] Epoch[757/1000] loss: 0.19515618589189318
I0804 02:07:41.000716  3068 trainer.py:139] Epoch[758/1000] loss: 0.19590871161884732
I0804 02:08:25.640591  3068 trainer.py:139] Epoch[759/1000] loss: 0.19601012421978845
I0804 02:09:10.593486  3068 trainer.py:139] Epoch[760/1000] loss: 0.19608502805233002
I0804 02:09:55.522359  3068 trainer.py:139] Epoch[761/1000] loss: 0.1961221296257443
I0804 02:10:40.128181  3068 trainer.py:139] Epoch[762/1000] loss: 0.1960864601532618
I0804 02:11:24.888067  3068 trainer.py:139] Epoch[763/1000] loss: 0.19566036502520243
I0804 02:12:09.681564  3068 trainer.py:139] Epoch[764/1000] loss: 0.194948341316647
I0804 02:12:54.672928  3068 trainer.py:139] Epoch[765/1000] loss: 0.1954202534755071
I0804 02:13:37.677979  3068 trainer.py:139] Epoch[766/1000] loss: 0.1957712811893887
I0804 02:14:22.612777  3068 trainer.py:139] Epoch[767/1000] loss: 0.1958467384841707
I0804 02:15:07.211370  3068 trainer.py:139] Epoch[768/1000] loss: 0.1952545303768582
I0804 02:15:52.215398  3068 trainer.py:139] Epoch[769/1000] loss: 0.1962083042992486
I0804 02:16:37.038672  3068 trainer.py:139] Epoch[770/1000] loss: 0.19524779789977603
I0804 02:17:21.708769  3068 trainer.py:139] Epoch[771/1000] loss: 0.19635923743247985
I0804 02:18:06.745305  3068 trainer.py:139] Epoch[772/1000] loss: 0.19603039297792646
I0804 02:18:51.627537  3068 trainer.py:139] Epoch[773/1000] loss: 0.1958123576641083
I0804 02:19:36.609828  3068 trainer.py:139] Epoch[774/1000] loss: 0.19612722946537867
I0804 02:20:21.518558  3068 trainer.py:139] Epoch[775/1000] loss: 0.195685632692443
I0804 02:21:06.247720  3068 trainer.py:139] Epoch[776/1000] loss: 0.1957978403568268
I0804 02:21:51.361404  3068 trainer.py:139] Epoch[777/1000] loss: 0.19578744437959458
I0804 02:22:35.147373  3068 trainer.py:139] Epoch[778/1000] loss: 0.19572055326567755
I0804 02:23:19.762416  3068 trainer.py:139] Epoch[779/1000] loss: 0.19597729947831896
I0804 02:24:04.855299  3068 trainer.py:139] Epoch[780/1000] loss: 0.19543267640802595
I0804 02:24:50.044484  3068 trainer.py:139] Epoch[781/1000] loss: 0.1952969898780187
I0804 02:25:34.842672  3068 trainer.py:139] Epoch[782/1000] loss: 0.1955007205406825
I0804 02:26:19.984560  3068 trainer.py:139] Epoch[783/1000] loss: 0.19588079472382863
I0804 02:27:04.934977  3068 trainer.py:139] Epoch[784/1000] loss: 0.19577131542894574
I0804 02:27:49.906207  3068 trainer.py:139] Epoch[785/1000] loss: 0.19481859379344516
I0804 02:28:34.399188  3068 trainer.py:139] Epoch[786/1000] loss: 0.19568117015891606
I0804 02:29:19.157128  3068 trainer.py:139] Epoch[787/1000] loss: 0.1952425832218594
I0804 02:30:03.983045  3068 trainer.py:139] Epoch[788/1000] loss: 0.19659869882795547
I0804 02:30:49.104067  3068 trainer.py:139] Epoch[789/1000] loss: 0.1955620198117362
I0804 02:31:33.386076  3068 trainer.py:139] Epoch[790/1000] loss: 0.1952966754966312
I0804 02:32:18.174396  3068 trainer.py:139] Epoch[791/1000] loss: 0.19545370393329198
I0804 02:33:02.816806  3068 trainer.py:139] Epoch[792/1000] loss: 0.19654997289180756
I0804 02:33:47.377730  3068 trainer.py:139] Epoch[793/1000] loss: 0.19529857767952813
I0804 02:34:32.027729  3068 trainer.py:139] Epoch[794/1000] loss: 0.19531353387567732
I0804 02:35:16.127509  3068 trainer.py:139] Epoch[795/1000] loss: 0.19651558789942
I0804 02:36:00.017443  3068 trainer.py:139] Epoch[796/1000] loss: 0.19594578948285846
I0804 02:36:44.160017  3068 trainer.py:139] Epoch[797/1000] loss: 0.19526783671644
I0804 02:37:28.651906  3068 trainer.py:139] Epoch[798/1000] loss: 0.1963529790772332
I0804 02:38:13.210384  3068 trainer.py:139] Epoch[799/1000] loss: 0.19500693255000645
I0804 02:38:13.778954  3068 trainer.py:145] Test: [{'precision': 0.2054590984974958, 'recall': 0.290435533737931, 'hit_ratio': 0.9143572621035059, 'ndcg': 0.32872914028091127}]
I0804 02:38:57.824761  3068 trainer.py:139] Epoch[800/1000] loss: 0.19530162817902036
I0804 02:39:41.431203  3068 trainer.py:139] Epoch[801/1000] loss: 0.19494963619444106
I0804 02:40:25.517902  3068 trainer.py:139] Epoch[802/1000] loss: 0.19670855250623492
I0804 02:41:10.334607  3068 trainer.py:139] Epoch[803/1000] loss: 0.1954712540573544
I0804 02:41:54.667195  3068 trainer.py:139] Epoch[804/1000] loss: 0.19593746271398332
I0804 02:42:39.408522  3068 trainer.py:139] Epoch[805/1000] loss: 0.19607108155886332
I0804 02:43:24.570919  3068 trainer.py:139] Epoch[806/1000] loss: 0.19534520771768357
I0804 02:44:09.335031  3068 trainer.py:139] Epoch[807/1000] loss: 0.19492726855807835
I0804 02:44:53.988478  3068 trainer.py:139] Epoch[808/1000] loss: 0.19583081026871998
I0804 02:45:38.824637  3068 trainer.py:139] Epoch[809/1000] loss: 0.19494903577698602
I0804 02:46:23.784982  3068 trainer.py:139] Epoch[810/1000] loss: 0.1939913945727878
I0804 02:47:08.570412  3068 trainer.py:139] Epoch[811/1000] loss: 0.1965970042016771
I0804 02:47:53.449781  3068 trainer.py:139] Epoch[812/1000] loss: 0.19466307196352217
I0804 02:48:38.555257  3068 trainer.py:139] Epoch[813/1000] loss: 0.19542486588160196
I0804 02:49:23.761521  3068 trainer.py:139] Epoch[814/1000] loss: 0.19539077043533326
I0804 02:50:08.657147  3068 trainer.py:139] Epoch[815/1000] loss: 0.1958158164554172
I0804 02:50:53.788589  3068 trainer.py:139] Epoch[816/1000] loss: 0.19473953439129724
I0804 02:51:38.450746  3068 trainer.py:139] Epoch[817/1000] loss: 0.19517807788319058
I0804 02:52:23.295250  3068 trainer.py:139] Epoch[818/1000] loss: 0.19566985951529609
I0804 02:53:07.077144  3068 trainer.py:139] Epoch[819/1000] loss: 0.19550536506705815
I0804 02:53:49.684468  3068 trainer.py:139] Epoch[820/1000] loss: 0.1960620406601164
I0804 02:54:34.236351  3068 trainer.py:139] Epoch[821/1000] loss: 0.19534652564260696
I0804 02:55:19.173685  3068 trainer.py:139] Epoch[822/1000] loss: 0.1946700969669554
I0804 02:56:04.081477  3068 trainer.py:139] Epoch[823/1000] loss: 0.19538611405425602
I0804 02:56:48.787377  3068 trainer.py:139] Epoch[824/1000] loss: 0.195710685716735
I0804 02:57:33.500190  3068 trainer.py:139] Epoch[825/1000] loss: 0.1963981737693151
I0804 02:58:18.499101  3068 trainer.py:139] Epoch[826/1000] loss: 0.19698411332236396
I0804 02:59:03.286324  3068 trainer.py:139] Epoch[827/1000] loss: 0.1952322545316484
I0804 02:59:48.322943  3068 trainer.py:139] Epoch[828/1000] loss: 0.19490116556485493
I0804 03:00:33.299190  3068 trainer.py:139] Epoch[829/1000] loss: 0.19542649110158283
I0804 03:01:18.109705  3068 trainer.py:139] Epoch[830/1000] loss: 0.19576678706540002
I0804 03:02:03.107969  3068 trainer.py:139] Epoch[831/1000] loss: 0.19575497104061976
I0804 03:02:47.794030  3068 trainer.py:139] Epoch[832/1000] loss: 0.19569421960247887
I0804 03:03:32.591348  3068 trainer.py:139] Epoch[833/1000] loss: 0.196290708316697
I0804 03:04:17.852082  3068 trainer.py:139] Epoch[834/1000] loss: 0.1957908422417111
I0804 03:05:02.728818  3068 trainer.py:139] Epoch[835/1000] loss: 0.19584250615702736
I0804 03:05:47.595366  3068 trainer.py:139] Epoch[836/1000] loss: 0.19540409465630848
I0804 03:06:32.803581  3068 trainer.py:139] Epoch[837/1000] loss: 0.1957335857550303
I0804 03:07:17.136394  3068 trainer.py:139] Epoch[838/1000] loss: 0.19536326275931465
I0804 03:08:01.676162  3068 trainer.py:139] Epoch[839/1000] loss: 0.19534711718559264
I0804 03:08:41.517833  3068 trainer.py:139] Epoch[840/1000] loss: 0.19599215355184343
I0804 03:09:26.091741  3068 trainer.py:139] Epoch[841/1000] loss: 0.1963700756099489
I0804 03:10:10.862709  3068 trainer.py:139] Epoch[842/1000] loss: 0.1951842423942354
I0804 03:10:55.754947  3068 trainer.py:139] Epoch[843/1000] loss: 0.19572951078414916
I0804 03:11:40.613770  3068 trainer.py:139] Epoch[844/1000] loss: 0.19555021882057189
I0804 03:12:25.272882  3068 trainer.py:139] Epoch[845/1000] loss: 0.19531809369723002
I0804 03:13:10.082733  3068 trainer.py:139] Epoch[846/1000] loss: 0.19590961356957753
I0804 03:13:54.862915  3068 trainer.py:139] Epoch[847/1000] loss: 0.19519952893257142
I0804 03:14:38.595895  3068 trainer.py:139] Epoch[848/1000] loss: 0.19571867916319105
I0804 03:15:23.111500  3068 trainer.py:139] Epoch[849/1000] loss: 0.19573090023464626
I0804 03:15:23.691150  3068 trainer.py:145] Test: [{'precision': 0.20505008347245413, 'recall': 0.291125278917107, 'hit_ratio': 0.91937242070116861, 'ndcg': 0.3305935786531391}]
I0804 03:16:08.513370  3068 trainer.py:139] Epoch[850/1000] loss: 0.19488092025121054
I0804 03:16:53.352644  3068 trainer.py:139] Epoch[851/1000] loss: 0.19476231588257684
I0804 03:17:38.334129  3068 trainer.py:139] Epoch[852/1000] loss: 0.1951617279317644
I0804 03:18:22.946298  3068 trainer.py:139] Epoch[853/1000] loss: 0.19559438824653624
I0804 03:19:07.635329  3068 trainer.py:139] Epoch[854/1000] loss: 0.19508006831010183
I0804 03:19:52.521597  3068 trainer.py:139] Epoch[855/1000] loss: 0.19640470299455853
I0804 03:20:37.449875  3068 trainer.py:139] Epoch[856/1000] loss: 0.19628190086947547
I0804 03:21:22.192604  3068 trainer.py:139] Epoch[857/1000] loss: 0.19676247894763946
I0804 03:22:07.088637  3068 trainer.py:139] Epoch[858/1000] loss: 0.1957325035995907
I0804 03:22:51.634469  3068 trainer.py:139] Epoch[859/1000] loss: 0.19510805156495836
I0804 03:23:36.541534  3068 trainer.py:139] Epoch[860/1000] loss: 0.1956538983186086
I0804 03:24:21.447261  3068 trainer.py:139] Epoch[861/1000] loss: 0.1947819689909617
I0804 03:25:06.260332  3068 trainer.py:139] Epoch[862/1000] loss: 0.1965551355150011
I0804 03:25:51.166898  3068 trainer.py:139] Epoch[863/1000] loss: 0.19581017467710707
I0804 03:26:36.074667  3068 trainer.py:139] Epoch[864/1000] loss: 0.1955286799536811
I0804 03:27:20.716012  3068 trainer.py:139] Epoch[865/1000] loss: 0.19528081993261973
I0804 03:28:05.494969  3068 trainer.py:139] Epoch[866/1000] loss: 0.19541764153374566
I0804 03:28:50.226853  3068 trainer.py:139] Epoch[867/1000] loss: 0.19545924206574758
I0804 03:29:35.134310  3068 trainer.py:139] Epoch[868/1000] loss: 0.19559546775288053
I0804 03:30:20.045214  3068 trainer.py:139] Epoch[869/1000] loss: 0.19503740396764543
I0804 03:31:05.037706  3068 trainer.py:139] Epoch[870/1000] loss: 0.19522923582130008
I0804 03:31:50.212618  3068 trainer.py:139] Epoch[871/1000] loss: 0.19442557712395986
I0804 03:32:35.080778  3068 trainer.py:139] Epoch[872/1000] loss: 0.1954902282026079
I0804 03:33:19.398652  3068 trainer.py:139] Epoch[873/1000] loss: 0.1945711823966768
I0804 03:34:03.288942  3068 trainer.py:139] Epoch[874/1000] loss: 0.1956080056561364
I0804 03:34:45.366518  3068 trainer.py:139] Epoch[875/1000] loss: 0.19539277176062267
I0804 03:35:27.719982  3068 trainer.py:139] Epoch[876/1000] loss: 0.19494492173194886
I0804 03:36:12.172401  3068 trainer.py:139] Epoch[877/1000] loss: 0.19459547652138603
I0804 03:36:56.709733  3068 trainer.py:139] Epoch[878/1000] loss: 0.19467691441377005
I0804 03:37:41.216456  3068 trainer.py:139] Epoch[879/1000] loss: 0.19525411791271632
I0804 03:38:26.155099  3068 trainer.py:139] Epoch[880/1000] loss: 0.1964516952302721
I0804 03:39:10.884844  3068 trainer.py:139] Epoch[881/1000] loss: 0.19534488783942328
I0804 03:39:55.528498  3068 trainer.py:139] Epoch[882/1000] loss: 0.19504063738716973
I0804 03:40:39.121318  3068 trainer.py:139] Epoch[883/1000] loss: 0.1953688931465149
I0804 03:41:21.036478  3068 trainer.py:139] Epoch[884/1000] loss: 0.19563191672166189
I0804 03:42:05.885493  3068 trainer.py:139] Epoch[885/1000] loss: 0.19584258377552033
I0804 03:42:50.525822  3068 trainer.py:139] Epoch[886/1000] loss: 0.1951260683933894
I0804 03:43:35.718720  3068 trainer.py:139] Epoch[887/1000] loss: 0.19462157944838207
I0804 03:44:19.802223  3068 trainer.py:139] Epoch[888/1000] loss: 0.19558044373989106
I0804 03:45:04.610714  3068 trainer.py:139] Epoch[889/1000] loss: 0.19559582630793254
I0804 03:45:49.314607  3068 trainer.py:139] Epoch[890/1000] loss: 0.19595626009835138
I0804 03:46:34.160883  3068 trainer.py:139] Epoch[891/1000] loss: 0.19535333467854393
I0804 03:47:18.763514  3068 trainer.py:139] Epoch[892/1000] loss: 0.19516474028428396
I0804 03:48:03.516489  3068 trainer.py:139] Epoch[893/1000] loss: 0.1947083044052124
I0804 03:48:48.172970  3068 trainer.py:139] Epoch[894/1000] loss: 0.19547350611951617
I0804 03:49:33.012517  3068 trainer.py:139] Epoch[895/1000] loss: 0.19563946591483222
I0804 03:50:17.235599  3068 trainer.py:139] Epoch[896/1000] loss: 0.19567476484510635
I0804 03:51:01.883658  3068 trainer.py:139] Epoch[897/1000] loss: 0.1958943396144443
I0804 03:51:46.582560  3068 trainer.py:139] Epoch[898/1000] loss: 0.19506593889660306
I0804 03:52:31.245040  3068 trainer.py:139] Epoch[899/1000] loss: 0.19552605284584892
I0804 03:52:31.807159  3068 trainer.py:145] Test: [{'precision': 0.20561769616026718, 'recall': 0.2905041716868664, 'hit_ratio': 0.9168614357262104, 'ndcg': 0.3280843859628045}]
I0804 03:53:16.322962  3068 trainer.py:139] Epoch[900/1000] loss: 0.19508955836296082
I0804 03:54:01.243780  3068 trainer.py:139] Epoch[901/1000] loss: 0.19512345718012916
I0804 03:54:45.972542  3068 trainer.py:139] Epoch[902/1000] loss: 0.19520773066414726
I0804 03:55:30.611091  3068 trainer.py:139] Epoch[903/1000] loss: 0.19566158910592396
I0804 03:56:15.519646  3068 trainer.py:139] Epoch[904/1000] loss: 0.1947395290931066
I0804 03:56:58.414107  3068 trainer.py:139] Epoch[905/1000] loss: 0.19537693017058902
I0804 03:57:42.869516  3068 trainer.py:139] Epoch[906/1000] loss: 0.1957219319873386
I0804 03:58:26.683821  3068 trainer.py:139] Epoch[907/1000] loss: 0.19501163158151838
I0804 03:59:08.535197  3068 trainer.py:139] Epoch[908/1000] loss: 0.19520052664809756
I0804 03:59:52.040864  3068 trainer.py:139] Epoch[909/1000] loss: 0.1954139365752538
I0804 04:00:36.593667  3068 trainer.py:139] Epoch[910/1000] loss: 0.19559401366445753
I0804 04:01:20.967502  3068 trainer.py:139] Epoch[911/1000] loss: 0.19472335477670033
I0804 04:02:05.921000  3068 trainer.py:139] Epoch[912/1000] loss: 0.19518283704916636
I0804 04:02:50.626552  3068 trainer.py:139] Epoch[913/1000] loss: 0.19603765116797553
I0804 04:03:35.359160  3068 trainer.py:139] Epoch[914/1000] loss: 0.19474456542068058
I0804 04:04:20.353017  3068 trainer.py:139] Epoch[915/1000] loss: 0.19572340859307183
I0804 04:05:05.088702  3068 trainer.py:139] Epoch[916/1000] loss: 0.19514332678582932
I0804 04:05:50.009226  3068 trainer.py:139] Epoch[917/1000] loss: 0.19580532524320815
I0804 04:06:34.836971  3068 trainer.py:139] Epoch[918/1000] loss: 0.19592295640044743
I0804 04:07:19.838717  3068 trainer.py:139] Epoch[919/1000] loss: 0.1945590156316757
I0804 04:08:04.539104  3068 trainer.py:139] Epoch[920/1000] loss: 0.19495148539543153
I0804 04:08:48.312388  3068 trainer.py:139] Epoch[921/1000] loss: 0.1956661093235016
I0804 04:09:31.069842  3068 trainer.py:139] Epoch[922/1000] loss: 0.1951759397983551
I0804 04:10:15.257147  3068 trainer.py:139] Epoch[923/1000] loss: 0.19534294168154398
I0804 04:10:59.844324  3068 trainer.py:139] Epoch[924/1000] loss: 0.19567743162314097
I0804 04:11:44.182198  3068 trainer.py:139] Epoch[925/1000] loss: 0.19562567214171092
I0804 04:12:29.141991  3068 trainer.py:139] Epoch[926/1000] loss: 0.1945873005522622
I0804 04:13:14.026133  3068 trainer.py:139] Epoch[927/1000] loss: 0.19450150940153335
I0804 04:13:58.885062  3068 trainer.py:139] Epoch[928/1000] loss: 0.19444322433736588
I0804 04:14:42.473294  3068 trainer.py:139] Epoch[929/1000] loss: 0.19503152628739676
I0804 04:15:26.940840  3068 trainer.py:139] Epoch[930/1000] loss: 0.1960431804921892
I0804 04:16:11.663638  3068 trainer.py:139] Epoch[931/1000] loss: 0.19588773316807218
I0804 04:16:56.539497  3068 trainer.py:139] Epoch[932/1000] loss: 0.19494733134905498
I0804 04:17:41.405556  3068 trainer.py:139] Epoch[933/1000] loss: 0.1950624356004927
I0804 04:18:26.503567  3068 trainer.py:139] Epoch[934/1000] loss: 0.1952573671605852
I0804 04:19:11.505775  3068 trainer.py:139] Epoch[935/1000] loss: 0.1948671861489614
I0804 04:19:56.466995  3068 trainer.py:139] Epoch[936/1000] loss: 0.19419756253560383
I0804 04:20:41.262586  3068 trainer.py:139] Epoch[937/1000] loss: 0.1936676420105828
I0804 04:21:26.192452  3068 trainer.py:139] Epoch[938/1000] loss: 0.19480380045043097
I0804 04:22:11.045539  3068 trainer.py:139] Epoch[939/1000] loss: 0.19487314932876162
I0804 04:22:55.419209  3068 trainer.py:139] Epoch[940/1000] loss: 0.19512700961695778
I0804 04:23:39.578092  3068 trainer.py:139] Epoch[941/1000] loss: 0.1959976808892356
I0804 04:24:24.797899  3068 trainer.py:139] Epoch[942/1000] loss: 0.19572049491935306
I0804 04:25:09.577177  3068 trainer.py:139] Epoch[943/1000] loss: 0.19562953193982444
I0804 04:25:54.105371  3068 trainer.py:139] Epoch[944/1000] loss: 0.19557503190305497
I0804 04:26:38.967718  3068 trainer.py:139] Epoch[945/1000] loss: 0.19523183425267537
I0804 04:27:23.120705  3068 trainer.py:139] Epoch[946/1000] loss: 0.19579583942890166
I0804 04:28:07.594178  3068 trainer.py:139] Epoch[947/1000] loss: 0.19526122589906056
I0804 04:28:52.196383  3068 trainer.py:139] Epoch[948/1000] loss: 0.19531690418720246
I0804 04:29:35.188560  3068 trainer.py:139] Epoch[949/1000] loss: 0.19542007784048715
I0804 04:29:35.750679  3068 trainer.py:145] Test: [{'precision': 0.20490818030050073, 'recall': 0.2899204615632006, 'hit_ratio': 0.9190283806343906, 'ndcg': 0.3268365167043371}]
I0804 04:30:19.804223  3068 trainer.py:139] Epoch[950/1000] loss: 0.19509796619415284
I0804 04:31:04.321607  3068 trainer.py:139] Epoch[951/1000] loss: 0.19496850079960293
I0804 04:31:48.644417  3068 trainer.py:139] Epoch[952/1000] loss: 0.194413843287362
I0804 04:32:33.026643  3068 trainer.py:139] Epoch[953/1000] loss: 0.194878331290351
I0804 04:33:17.887138  3068 trainer.py:139] Epoch[954/1000] loss: 0.1947582799858517
I0804 04:34:02.790425  3068 trainer.py:139] Epoch[955/1000] loss: 0.1956593041949802
I0804 04:34:47.491627  3068 trainer.py:139] Epoch[956/1000] loss: 0.19590992384486727
I0804 04:35:32.108456  3068 trainer.py:139] Epoch[957/1000] loss: 0.19487939529948764
I0804 04:36:17.088980  3068 trainer.py:139] Epoch[958/1000] loss: 0.19627444545427958
I0804 04:37:02.122983  3068 trainer.py:139] Epoch[959/1000] loss: 0.19529156446456908
I0804 04:37:46.835180  3068 trainer.py:139] Epoch[960/1000] loss: 0.1959697402185864
I0804 04:38:31.737805  3068 trainer.py:139] Epoch[961/1000] loss: 0.19531490557723574
I0804 04:39:16.817870  3068 trainer.py:139] Epoch[962/1000] loss: 0.194711409078704
I0804 04:40:01.612917  3068 trainer.py:139] Epoch[963/1000] loss: 0.194739349020852
I0804 04:40:46.709724  3068 trainer.py:139] Epoch[964/1000] loss: 0.19556512024667527
I0804 04:41:31.466074  3068 trainer.py:139] Epoch[965/1000] loss: 0.1947776237461302
I0804 04:42:16.217888  3068 trainer.py:139] Epoch[966/1000] loss: 0.19568955229388343
I0804 04:43:01.045607  3068 trainer.py:139] Epoch[967/1000] loss: 0.19402167909675175
I0804 04:43:45.354062  3068 trainer.py:139] Epoch[968/1000] loss: 0.194946677353647
I0804 04:44:30.366658  3068 trainer.py:139] Epoch[969/1000] loss: 0.19585925393634374
I0804 04:45:14.406470  3068 trainer.py:139] Epoch[970/1000] loss: 0.1955559801393085
I0804 04:45:59.345122  3068 trainer.py:139] Epoch[971/1000] loss: 0.1951105968819724
I0804 04:46:44.455035  3068 trainer.py:139] Epoch[972/1000] loss: 0.1955243616633945
I0804 04:47:29.246496  3068 trainer.py:139] Epoch[973/1000] loss: 0.19485854314433204
I0804 04:48:14.385594  3068 trainer.py:139] Epoch[974/1000] loss: 0.19425962845484415
I0804 04:48:59.624654  3068 trainer.py:139] Epoch[975/1000] loss: 0.19494161201847923
I0804 04:49:44.642459  3068 trainer.py:139] Epoch[976/1000] loss: 0.19522053851021662
I0804 04:50:28.547886  3068 trainer.py:139] Epoch[977/1000] loss: 0.19537047114637163
I0804 04:51:13.108764  3068 trainer.py:139] Epoch[978/1000] loss: 0.19503460109233856
I0804 04:51:57.431437  3068 trainer.py:139] Epoch[979/1000] loss: 0.19467694024244944
I0804 04:52:42.379755  3068 trainer.py:139] Epoch[980/1000] loss: 0.195279393725925
I0804 04:53:27.276405  3068 trainer.py:139] Epoch[981/1000] loss: 0.1951192075676388
I0804 04:54:12.251681  3068 trainer.py:139] Epoch[982/1000] loss: 0.19551029748386806
I0804 04:54:57.060029  3068 trainer.py:139] Epoch[983/1000] loss: 0.19473486728138395
I0804 04:55:40.992853  3068 trainer.py:139] Epoch[984/1000] loss: 0.19463749706745148
I0804 04:56:25.571986  3068 trainer.py:139] Epoch[985/1000] loss: 0.19500551574760014
I0804 04:57:10.394548  3068 trainer.py:139] Epoch[986/1000] loss: 0.19485457552803886
I0804 04:57:54.074815  3068 trainer.py:139] Epoch[987/1000] loss: 0.19440014686849383
I0804 04:58:39.027515  3068 trainer.py:139] Epoch[988/1000] loss: 0.19423316379388172
I0804 04:59:23.486087  3068 trainer.py:139] Epoch[989/1000] loss: 0.1948039761516783
I0804 05:00:08.312930  3068 trainer.py:139] Epoch[990/1000] loss: 0.1945377841922972
I0804 05:00:52.974299  3068 trainer.py:139] Epoch[991/1000] loss: 0.19540473534001243
I0804 05:01:37.978035  3068 trainer.py:139] Epoch[992/1000] loss: 0.19599183022975922
I0804 05:02:22.820634  3068 trainer.py:139] Epoch[993/1000] loss: 0.19536096433798472
I0804 05:03:06.412502  3068 trainer.py:139] Epoch[994/1000] loss: 0.19504727668232388
I0804 05:03:51.035070  3068 trainer.py:139] Epoch[995/1000] loss: 0.1960990872648027
I0804 05:04:37.273802  3068 trainer.py:139] Epoch[996/1000] loss: 0.19483985556496514
I0804 05:05:27.924146  3068 trainer.py:139] Epoch[997/1000] loss: 0.19545201149251726
I0804 05:06:18.600962  3068 trainer.py:139] Epoch[998/1000] loss: 0.19453810142146216
I0804 05:07:09.216220  3068 trainer.py:139] Epoch[999/1000] loss: 0.19524854554070367
I0804 05:07:09.900583  3068 trainer.py:145] Test: [{'precision': 0.2048998330550918, 'recall': 0.2909112703487082, 'hit_ratio': 0.9168614357262104, 'ndcg': 0.3294847861295599}]
