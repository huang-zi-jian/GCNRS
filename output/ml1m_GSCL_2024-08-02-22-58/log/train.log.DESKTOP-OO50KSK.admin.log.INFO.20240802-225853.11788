I0802 22:59:01.261738 16048 trainer.py:119] Test: [{'precision': 0.0847829716193657, 'recall': 0.10294058656594784, 'hit_ratio': 0.617195325542571, 'ndcg': 0.12040285770206294}]
I0802 22:59:18.543145 16048 trainer.py:139] Epoch[0/1000] loss: 0.573231115937233
I0802 22:59:35.605163 16048 trainer.py:139] Epoch[1/1000] loss: 0.4882057625800371
I0802 22:59:53.179508 16048 trainer.py:139] Epoch[2/1000] loss: 0.46660033240914345
I0802 23:00:10.362714 16048 trainer.py:139] Epoch[3/1000] loss: 0.46181933395564556
I0802 23:00:27.671283 16048 trainer.py:139] Epoch[4/1000] loss: 0.46070814691483974
I0802 23:00:44.752477 16048 trainer.py:139] Epoch[5/1000] loss: 0.4552195928990841
I0802 23:01:02.342733 16048 trainer.py:139] Epoch[6/1000] loss: 0.44955991953611374
I0802 23:01:20.189156 16048 trainer.py:139] Epoch[7/1000] loss: 0.44264110922813416
I0802 23:01:37.919494 16048 trainer.py:139] Epoch[8/1000] loss: 0.4342353269457817
I0802 23:01:55.613819 16048 trainer.py:139] Epoch[9/1000] loss: 0.42584662325680256
I0802 23:02:13.566006 16048 trainer.py:139] Epoch[10/1000] loss: 0.4189956374466419
I0802 23:02:31.367807 16048 trainer.py:139] Epoch[11/1000] loss: 0.41190686635673046
I0802 23:02:49.373649 16048 trainer.py:139] Epoch[12/1000] loss: 0.4067651703953743
I0802 23:03:07.328694 16048 trainer.py:139] Epoch[13/1000] loss: 0.40284578315913677
I0802 23:03:25.356763 16048 trainer.py:139] Epoch[14/1000] loss: 0.39922259747982025
I0802 23:03:43.535677 16048 trainer.py:139] Epoch[15/1000] loss: 0.39691296592354774
I0802 23:04:01.293480 16048 trainer.py:139] Epoch[16/1000] loss: 0.3955466039478779
I0802 23:04:18.583855 16048 trainer.py:139] Epoch[17/1000] loss: 0.3940130863338709
I0802 23:04:36.098738 16048 trainer.py:139] Epoch[18/1000] loss: 0.3929063845425844
I0802 23:04:53.391792 16048 trainer.py:139] Epoch[19/1000] loss: 0.3899533115327358
I0802 23:05:10.525859 16048 trainer.py:139] Epoch[20/1000] loss: 0.3887382410466671
I0802 23:05:27.687191 16048 trainer.py:139] Epoch[21/1000] loss: 0.38767238333821297
I0802 23:05:45.016766 16048 trainer.py:139] Epoch[22/1000] loss: 0.385485639795661
I0802 23:06:02.358366 16048 trainer.py:139] Epoch[23/1000] loss: 0.38415526412427425
I0802 23:06:19.564850 16048 trainer.py:139] Epoch[24/1000] loss: 0.383054967969656
I0802 23:06:37.111255 16048 trainer.py:139] Epoch[25/1000] loss: 0.38318467512726784
I0802 23:06:54.431167 16048 trainer.py:139] Epoch[26/1000] loss: 0.3805042579770088
I0802 23:07:11.690485 16048 trainer.py:139] Epoch[27/1000] loss: 0.3801905531436205
I0802 23:07:28.773455 16048 trainer.py:139] Epoch[28/1000] loss: 0.37869833037257195
I0802 23:07:46.059689 16048 trainer.py:139] Epoch[29/1000] loss: 0.376861272379756
I0802 23:08:03.528307 16048 trainer.py:139] Epoch[30/1000] loss: 0.3767881244421005
I0802 23:08:20.994291 16048 trainer.py:139] Epoch[31/1000] loss: 0.3744015470147133
I0802 23:08:38.587662 16048 trainer.py:139] Epoch[32/1000] loss: 0.3717953022569418
I0802 23:08:56.048599 16048 trainer.py:139] Epoch[33/1000] loss: 0.3719664141535759
I0802 23:09:13.658418 16048 trainer.py:139] Epoch[34/1000] loss: 0.3698482047766447
I0802 23:09:31.160317 16048 trainer.py:139] Epoch[35/1000] loss: 0.36823136918246746
I0802 23:09:48.389494 16048 trainer.py:139] Epoch[36/1000] loss: 0.36575164645910263
I0802 23:10:05.917902 16048 trainer.py:139] Epoch[37/1000] loss: 0.36670345813035965
I0802 23:10:23.249083 16048 trainer.py:139] Epoch[38/1000] loss: 0.36544437892735004
I0802 23:10:40.747662 16048 trainer.py:139] Epoch[39/1000] loss: 0.3628515638411045
I0802 23:10:57.861731 16048 trainer.py:139] Epoch[40/1000] loss: 0.36242685094475746
I0802 23:11:15.209178 16048 trainer.py:139] Epoch[41/1000] loss: 0.35899860598146915
I0802 23:11:32.421345 16048 trainer.py:139] Epoch[42/1000] loss: 0.3584063332527876
I0802 23:11:49.509238 16048 trainer.py:139] Epoch[43/1000] loss: 0.35528285428881645
I0802 23:12:06.818927 16048 trainer.py:139] Epoch[44/1000] loss: 0.3534181844443083
I0802 23:12:24.006431 16048 trainer.py:139] Epoch[45/1000] loss: 0.35108099319040775
I0802 23:12:41.166691 16048 trainer.py:139] Epoch[46/1000] loss: 0.3515170235186815
I0802 23:12:58.688756 16048 trainer.py:139] Epoch[47/1000] loss: 0.3511660676449537
I0802 23:13:15.800245 16048 trainer.py:139] Epoch[48/1000] loss: 0.3493243958801031
I0802 23:13:32.945829 16048 trainer.py:139] Epoch[49/1000] loss: 0.34790244698524475
I0802 23:13:33.541431 16048 trainer.py:145] Test: [{'precision': 0.15843906510851422, 'recall': 0.2075875614731531, 'hit_ratio': 0.843906510851419, 'ndcg': 0.24258383635915653}]
I0802 23:13:50.998330 16048 trainer.py:139] Epoch[50/1000] loss: 0.3451380282640457
I0802 23:14:08.479017 16048 trainer.py:139] Epoch[51/1000] loss: 0.34309807047247887
I0802 23:14:25.897436 16048 trainer.py:139] Epoch[52/1000] loss: 0.34193013422191143
I0802 23:14:43.223171 16048 trainer.py:139] Epoch[53/1000] loss: 0.3420681320130825
I0802 23:15:00.675000 16048 trainer.py:139] Epoch[54/1000] loss: 0.34009309858083725
I0802 23:15:17.867726 16048 trainer.py:139] Epoch[55/1000] loss: 0.3392875865101814
I0802 23:15:35.519944 16048 trainer.py:139] Epoch[56/1000] loss: 0.3383043557405472
I0802 23:15:52.835975 16048 trainer.py:139] Epoch[57/1000] loss: 0.3364206776022911
I0802 23:16:10.213766 16048 trainer.py:139] Epoch[58/1000] loss: 0.3361683785915375
I0802 23:16:27.392318 16048 trainer.py:139] Epoch[59/1000] loss: 0.3331306967884302
I0802 23:16:44.745654 16048 trainer.py:139] Epoch[60/1000] loss: 0.33337385952472687
I0802 23:17:02.170065 16048 trainer.py:139] Epoch[61/1000] loss: 0.33349207416176796
I0802 23:17:19.283731 16048 trainer.py:139] Epoch[62/1000] loss: 0.32963224686682224
I0802 23:17:36.406794 16048 trainer.py:139] Epoch[63/1000] loss: 0.3289940170943737
I0802 23:17:53.659824 16048 trainer.py:139] Epoch[64/1000] loss: 0.32801347225904465
I0802 23:18:10.947299 16048 trainer.py:139] Epoch[65/1000] loss: 0.3269651532173157
I0802 23:18:28.038024 16048 trainer.py:139] Epoch[66/1000] loss: 0.3245385531336069
I0802 23:18:45.414620 16048 trainer.py:139] Epoch[67/1000] loss: 0.3250771053135395
I0802 23:19:02.965378 16048 trainer.py:139] Epoch[68/1000] loss: 0.3227086290717125
I0802 23:19:20.604944 16048 trainer.py:139] Epoch[69/1000] loss: 0.3218914996832609
I0802 23:19:38.071018 16048 trainer.py:139] Epoch[70/1000] loss: 0.320003030821681
I0802 23:19:55.642977 16048 trainer.py:139] Epoch[71/1000] loss: 0.3188095949590206
I0802 23:20:13.198940 16048 trainer.py:139] Epoch[72/1000] loss: 0.3191179633140564
I0802 23:20:30.705101 16048 trainer.py:139] Epoch[73/1000] loss: 0.31766126304864883
I0802 23:20:48.028249 16048 trainer.py:139] Epoch[74/1000] loss: 0.31597742065787315
I0802 23:21:05.447656 16048 trainer.py:139] Epoch[75/1000] loss: 0.3152810037136078
I0802 23:21:22.916907 16048 trainer.py:139] Epoch[76/1000] loss: 0.3142900876700878
I0802 23:21:40.470289 16048 trainer.py:139] Epoch[77/1000] loss: 0.3139692209661007
I0802 23:21:58.029096 16048 trainer.py:139] Epoch[78/1000] loss: 0.31300737895071507
I0802 23:22:15.700472 16048 trainer.py:139] Epoch[79/1000] loss: 0.31001054868102074
I0802 23:22:33.057115 16048 trainer.py:139] Epoch[80/1000] loss: 0.3091758508235216
I0802 23:22:50.476924 16048 trainer.py:139] Epoch[81/1000] loss: 0.31049536913633347
I0802 23:23:08.028069 16048 trainer.py:139] Epoch[82/1000] loss: 0.30814930237829685
I0802 23:23:25.896169 16048 trainer.py:139] Epoch[83/1000] loss: 0.306964049115777
I0802 23:23:43.883960 16048 trainer.py:139] Epoch[84/1000] loss: 0.3061019144952297
I0802 23:24:01.826541 16048 trainer.py:139] Epoch[85/1000] loss: 0.30710402876138687
I0802 23:24:19.973560 16048 trainer.py:139] Epoch[86/1000] loss: 0.30538249760866165
I0802 23:24:37.974560 16048 trainer.py:139] Epoch[87/1000] loss: 0.3045699670910835
I0802 23:24:55.761971 16048 trainer.py:139] Epoch[88/1000] loss: 0.3046263065189123
I0802 23:25:13.571663 16048 trainer.py:139] Epoch[89/1000] loss: 0.30252790451049805
I0802 23:25:31.355125 16048 trainer.py:139] Epoch[90/1000] loss: 0.3012521266937256
I0802 23:25:49.070548 16048 trainer.py:139] Epoch[91/1000] loss: 0.3001489005982876
I0802 23:26:06.601609 16048 trainer.py:139] Epoch[92/1000] loss: 0.30102463625371456
I0802 23:26:23.962519 16048 trainer.py:139] Epoch[93/1000] loss: 0.2978316508233547
I0802 23:26:41.474901 16048 trainer.py:139] Epoch[94/1000] loss: 0.2977918181568384
I0802 23:26:59.130832 16048 trainer.py:139] Epoch[95/1000] loss: 0.2965810690075159
I0802 23:27:16.870535 16048 trainer.py:139] Epoch[96/1000] loss: 0.29586051404476166
I0802 23:27:35.105569 16048 trainer.py:139] Epoch[97/1000] loss: 0.2950646970421076
I0802 23:27:52.941491 16048 trainer.py:139] Epoch[98/1000] loss: 0.2932478319853544
I0802 23:28:10.877016 16048 trainer.py:139] Epoch[99/1000] loss: 0.29406349547207355
I0802 23:28:11.635035 16048 trainer.py:145] Test: [{'precision': 0.1702170283806344, 'recall': 0.23075056633897092, 'hit_ratio': 0.8691151919866444, 'ndcg': 0.26273380837460525}]
I0802 23:28:29.254187 16048 trainer.py:139] Epoch[100/1000] loss: 0.29195928759872913
I0802 23:28:46.889846 16048 trainer.py:139] Epoch[101/1000] loss: 0.2918270342051983
I0802 23:29:04.508082 16048 trainer.py:139] Epoch[102/1000] loss: 0.29110013507306576
I0802 23:29:22.299450 16048 trainer.py:139] Epoch[103/1000] loss: 0.2891882974654436
I0802 23:29:40.062192 16048 trainer.py:139] Epoch[104/1000] loss: 0.28951476141810417
I0802 23:29:57.792032 16048 trainer.py:139] Epoch[105/1000] loss: 0.2885821480304003
I0802 23:30:15.726522 16048 trainer.py:139] Epoch[106/1000] loss: 0.2866865135729313
I0802 23:30:33.773406 16048 trainer.py:139] Epoch[107/1000] loss: 0.2871234603226185
I0802 23:30:51.835123 16048 trainer.py:139] Epoch[108/1000] loss: 0.28459560312330723
I0802 23:31:09.493847 16048 trainer.py:139] Epoch[109/1000] loss: 0.28411509841680527
I0802 23:31:27.181267 16048 trainer.py:139] Epoch[110/1000] loss: 0.2838712874799967
I0802 23:31:45.004496 16048 trainer.py:139] Epoch[111/1000] loss: 0.28176142275333405
I0802 23:32:02.629925 16048 trainer.py:139] Epoch[112/1000] loss: 0.2820747196674347
I0802 23:32:20.512296 16048 trainer.py:139] Epoch[113/1000] loss: 0.2808992974460125
I0802 23:32:38.464417 16048 trainer.py:139] Epoch[114/1000] loss: 0.28156340308487415
I0802 23:32:56.337852 16048 trainer.py:139] Epoch[115/1000] loss: 0.27980837225914
I0802 23:33:14.380262 16048 trainer.py:139] Epoch[116/1000] loss: 0.2799946703016758
I0802 23:33:32.206581 16048 trainer.py:139] Epoch[117/1000] loss: 0.2791198845952749
I0802 23:33:50.270571 16048 trainer.py:139] Epoch[118/1000] loss: 0.27879901230335236
I0802 23:34:08.274738 16048 trainer.py:139] Epoch[119/1000] loss: 0.27785521373152733
I0802 23:34:25.975178 16048 trainer.py:139] Epoch[120/1000] loss: 0.2768214363604784
I0802 23:34:43.604593 16048 trainer.py:139] Epoch[121/1000] loss: 0.27567089535295963
I0802 23:35:01.351994 16048 trainer.py:139] Epoch[122/1000] loss: 0.2750166989862919
I0802 23:35:18.916067 16048 trainer.py:139] Epoch[123/1000] loss: 0.2743706535547972
I0802 23:35:36.749839 16048 trainer.py:139] Epoch[124/1000] loss: 0.2734115235507488
I0802 23:35:54.723466 16048 trainer.py:139] Epoch[125/1000] loss: 0.2737904042005539
I0802 23:36:12.314373 16048 trainer.py:139] Epoch[126/1000] loss: 0.2737209089100361
I0802 23:36:30.027352 16048 trainer.py:139] Epoch[127/1000] loss: 0.2705635577440262
I0802 23:36:47.967856 16048 trainer.py:139] Epoch[128/1000] loss: 0.27034133672714233
I0802 23:37:05.459421 16048 trainer.py:139] Epoch[129/1000] loss: 0.27183448150753975
I0802 23:37:23.130248 16048 trainer.py:139] Epoch[130/1000] loss: 0.2706058472394943
I0802 23:37:40.973319 16048 trainer.py:139] Epoch[131/1000] loss: 0.2690644171088934
I0802 23:37:58.469712 16048 trainer.py:139] Epoch[132/1000] loss: 0.2689969688653946
I0802 23:38:16.205310 16048 trainer.py:139] Epoch[133/1000] loss: 0.26786603033542633
I0802 23:38:33.909477 16048 trainer.py:139] Epoch[134/1000] loss: 0.2660508584231138
I0802 23:38:51.683030 16048 trainer.py:139] Epoch[135/1000] loss: 0.26614011637866497
I0802 23:39:09.576295 16048 trainer.py:139] Epoch[136/1000] loss: 0.2652956619858742
I0802 23:39:27.552070 16048 trainer.py:139] Epoch[137/1000] loss: 0.2650961074978113
I0802 23:39:45.584706 16048 trainer.py:139] Epoch[138/1000] loss: 0.2651831917464733
I0802 23:40:03.452362 16048 trainer.py:139] Epoch[139/1000] loss: 0.2634177431464195
I0802 23:40:21.009708 16048 trainer.py:139] Epoch[140/1000] loss: 0.2639825325459242
I0802 23:40:38.868556 16048 trainer.py:139] Epoch[141/1000] loss: 0.2640404272824526
I0802 23:40:56.617511 16048 trainer.py:139] Epoch[142/1000] loss: 0.2623176835477352
I0802 23:41:14.188980 16048 trainer.py:139] Epoch[143/1000] loss: 0.26107470132410526
I0802 23:41:31.926825 16048 trainer.py:139] Epoch[144/1000] loss: 0.2606310322880745
I0802 23:41:49.482521 16048 trainer.py:139] Epoch[145/1000] loss: 0.2604091204702854
I0802 23:42:07.145501 16048 trainer.py:139] Epoch[146/1000] loss: 0.2611447609961033
I0802 23:42:25.166316 16048 trainer.py:139] Epoch[147/1000] loss: 0.26014608331024647
I0802 23:42:43.288238 16048 trainer.py:139] Epoch[148/1000] loss: 0.2608146797865629
I0802 23:43:01.153774 16048 trainer.py:139] Epoch[149/1000] loss: 0.25933605059981346
I0802 23:43:01.780677 16048 trainer.py:145] Test: [{'precision': 0.18068447412353922, 'recall': 0.24907412469782614, 'hit_ratio': 0.884474123539232, 'ndcg': 0.2794979170647144}]
I0802 23:43:19.515269 16048 trainer.py:139] Epoch[150/1000] loss: 0.25835253298282623
I0802 23:43:37.150492 16048 trainer.py:139] Epoch[151/1000] loss: 0.25908219814300537
I0802 23:43:55.011969 16048 trainer.py:139] Epoch[152/1000] loss: 0.25833035819232464
I0802 23:44:12.802556 16048 trainer.py:139] Epoch[153/1000] loss: 0.2583696264773607
I0802 23:44:30.597030 16048 trainer.py:139] Epoch[154/1000] loss: 0.2558722645044327
I0802 23:44:48.340723 16048 trainer.py:139] Epoch[155/1000] loss: 0.25593130104243755
I0802 23:45:05.876891 16048 trainer.py:139] Epoch[156/1000] loss: 0.25485883094370365
I0802 23:45:23.653577 16048 trainer.py:139] Epoch[157/1000] loss: 0.25575225334614515
I0802 23:45:41.625675 16048 trainer.py:139] Epoch[158/1000] loss: 0.25415748078376055
I0802 23:45:59.482019 16048 trainer.py:139] Epoch[159/1000] loss: 0.2540318835526705
I0802 23:46:17.239604 16048 trainer.py:139] Epoch[160/1000] loss: 0.2541541736572981
I0802 23:46:34.843085 16048 trainer.py:139] Epoch[161/1000] loss: 0.2545864172279835
I0802 23:46:52.384552 16048 trainer.py:139] Epoch[162/1000] loss: 0.2527770856395364
I0802 23:47:09.877493 16048 trainer.py:139] Epoch[163/1000] loss: 0.2536251861602068
I0802 23:47:27.424999 16048 trainer.py:139] Epoch[164/1000] loss: 0.2526742806658149
I0802 23:47:45.169361 16048 trainer.py:139] Epoch[165/1000] loss: 0.2518168203532696
I0802 23:48:02.925141 16048 trainer.py:139] Epoch[166/1000] loss: 0.2528331745415926
I0802 23:48:20.755707 16048 trainer.py:139] Epoch[167/1000] loss: 0.25193701032549143
I0802 23:48:38.356508 16048 trainer.py:139] Epoch[168/1000] loss: 0.25262913946062326
I0802 23:48:56.084305 16048 trainer.py:139] Epoch[169/1000] loss: 0.2513044523075223
I0802 23:49:14.018525 16048 trainer.py:139] Epoch[170/1000] loss: 0.25094269402325153
I0802 23:49:31.575239 16048 trainer.py:139] Epoch[171/1000] loss: 0.2502637133002281
I0802 23:49:49.493698 16048 trainer.py:139] Epoch[172/1000] loss: 0.24974748864769936
I0802 23:50:06.944881 16048 trainer.py:139] Epoch[173/1000] loss: 0.24930364359170198
I0802 23:50:24.731616 16048 trainer.py:139] Epoch[174/1000] loss: 0.2491540163755417
I0802 23:50:42.399775 16048 trainer.py:139] Epoch[175/1000] loss: 0.24756327364593744
I0802 23:51:00.352791 16048 trainer.py:139] Epoch[176/1000] loss: 0.2492670863866806
I0802 23:51:18.082535 16048 trainer.py:139] Epoch[177/1000] loss: 0.24853348173201084
I0802 23:51:36.028736 16048 trainer.py:139] Epoch[178/1000] loss: 0.2483847476541996
I0802 23:51:53.925173 16048 trainer.py:139] Epoch[179/1000] loss: 0.24629839044064283
I0802 23:52:11.693249 16048 trainer.py:139] Epoch[180/1000] loss: 0.24701065104454756
I0802 23:52:29.192541 16048 trainer.py:139] Epoch[181/1000] loss: 0.24849743489176035
I0802 23:52:46.986850 16048 trainer.py:139] Epoch[182/1000] loss: 0.24677601736038923
I0802 23:53:04.567210 16048 trainer.py:139] Epoch[183/1000] loss: 0.24746036622673273
I0802 23:53:22.628057 16048 trainer.py:139] Epoch[184/1000] loss: 0.24525563418865204
I0802 23:53:40.506268 16048 trainer.py:139] Epoch[185/1000] loss: 0.24501040112227201
I0802 23:53:58.545234 16048 trainer.py:139] Epoch[186/1000] loss: 0.24541143886744976
I0802 23:54:16.277788 16048 trainer.py:139] Epoch[187/1000] loss: 0.24415380600839853
I0802 23:54:33.732768 16048 trainer.py:139] Epoch[188/1000] loss: 0.2445294577628374
I0802 23:54:51.057936 16048 trainer.py:139] Epoch[189/1000] loss: 0.2447521211579442
I0802 23:55:08.614686 16048 trainer.py:139] Epoch[190/1000] loss: 0.24418378248810768
I0802 23:55:25.937667 16048 trainer.py:139] Epoch[191/1000] loss: 0.24324070662260056
I0802 23:55:43.522098 16048 trainer.py:139] Epoch[192/1000] loss: 0.24354970548301935
I0802 23:56:00.720797 16048 trainer.py:139] Epoch[193/1000] loss: 0.2428730372339487
I0802 23:56:18.160055 16048 trainer.py:139] Epoch[194/1000] loss: 0.2429383285343647
I0802 23:56:35.469347 16048 trainer.py:139] Epoch[195/1000] loss: 0.2434243680909276
I0802 23:56:53.071310 16048 trainer.py:139] Epoch[196/1000] loss: 0.24226872250437737
I0802 23:57:10.318231 16048 trainer.py:139] Epoch[197/1000] loss: 0.24232808779925108
I0802 23:57:27.817458 16048 trainer.py:139] Epoch[198/1000] loss: 0.24166950676590204
I0802 23:57:45.268462 16048 trainer.py:139] Epoch[199/1000] loss: 0.24129715654999018
I0802 23:57:45.880414 16048 trainer.py:145] Test: [{'precision': 0.18666944908180297, 'recall': 0.2593238325339208, 'hit_ratio': 0.894991652754591, 'ndcg': 0.29017119834604244}]
I0802 23:58:03.036716 16048 trainer.py:139] Epoch[200/1000] loss: 0.24230672605335712
I0802 23:58:20.236707 16048 trainer.py:139] Epoch[201/1000] loss: 0.24030774738639593
I0802 23:58:37.584993 16048 trainer.py:139] Epoch[202/1000] loss: 0.24219598527997732
I0802 23:58:54.999027 16048 trainer.py:139] Epoch[203/1000] loss: 0.24073572643101215
I0802 23:59:12.457370 16048 trainer.py:139] Epoch[204/1000] loss: 0.24046790692955256
I0802 23:59:29.743965 16048 trainer.py:139] Epoch[205/1000] loss: 0.24040797259658575
I0802 23:59:46.839021 16048 trainer.py:139] Epoch[206/1000] loss: 0.24053909350186586
I0803 00:00:04.013841 16048 trainer.py:139] Epoch[207/1000] loss: 0.23989206831902266
I0803 00:00:21.293236 16048 trainer.py:139] Epoch[208/1000] loss: 0.23933983128517866
I0803 00:00:38.425007 16048 trainer.py:139] Epoch[209/1000] loss: 0.240160109475255
I0803 00:00:55.597442 16048 trainer.py:139] Epoch[210/1000] loss: 0.23978443536907434
I0803 00:01:12.906601 16048 trainer.py:139] Epoch[211/1000] loss: 0.23949236329644918
I0803 00:01:30.157197 16048 trainer.py:139] Epoch[212/1000] loss: 0.2391099389642477
I0803 00:01:47.706856 16048 trainer.py:139] Epoch[213/1000] loss: 0.23970361333340406
I0803 00:02:05.030479 16048 trainer.py:139] Epoch[214/1000] loss: 0.23934790212661028
I0803 00:02:22.829256 16048 trainer.py:139] Epoch[215/1000] loss: 0.23757097218185663
I0803 00:02:40.045074 16048 trainer.py:139] Epoch[216/1000] loss: 0.2381647415459156
I0803 00:02:57.454228 16048 trainer.py:139] Epoch[217/1000] loss: 0.23738162592053413
I0803 00:03:14.670405 16048 trainer.py:139] Epoch[218/1000] loss: 0.2371767582371831
I0803 00:03:31.997364 16048 trainer.py:139] Epoch[219/1000] loss: 0.2374232280999422
I0803 00:03:49.481214 16048 trainer.py:139] Epoch[220/1000] loss: 0.23701495770365
I0803 00:04:06.760247 16048 trainer.py:139] Epoch[221/1000] loss: 0.23686086852103472
I0803 00:04:24.156854 16048 trainer.py:139] Epoch[222/1000] loss: 0.23570190463215113
I0803 00:04:41.561329 16048 trainer.py:139] Epoch[223/1000] loss: 0.23565048724412918
I0803 00:04:58.907446 16048 trainer.py:139] Epoch[224/1000] loss: 0.23719155509024858
I0803 00:05:16.149255 16048 trainer.py:139] Epoch[225/1000] loss: 0.2364353323355317
I0803 00:05:33.360807 16048 trainer.py:139] Epoch[226/1000] loss: 0.23560192808508873
I0803 00:05:50.699265 16048 trainer.py:139] Epoch[227/1000] loss: 0.2346868421882391
I0803 00:06:08.057975 16048 trainer.py:139] Epoch[228/1000] loss: 0.23514071013778448
I0803 00:06:25.126417 16048 trainer.py:139] Epoch[229/1000] loss: 0.23631959781050682
I0803 00:06:42.555870 16048 trainer.py:139] Epoch[230/1000] loss: 0.2349746972322464
I0803 00:06:59.968108 16048 trainer.py:139] Epoch[231/1000] loss: 0.23550925310701132
I0803 00:07:17.428758 16048 trainer.py:139] Epoch[232/1000] loss: 0.234695284627378
I0803 00:07:34.769071 16048 trainer.py:139] Epoch[233/1000] loss: 0.23496899753808975
I0803 00:07:52.124125 16048 trainer.py:139] Epoch[234/1000] loss: 0.2349285865202546
I0803 00:08:09.339380 16048 trainer.py:139] Epoch[235/1000] loss: 0.23530523478984833
I0803 00:08:26.505407 16048 trainer.py:139] Epoch[236/1000] loss: 0.23397680930793285
I0803 00:08:43.971370 16048 trainer.py:139] Epoch[237/1000] loss: 0.23368920478969812
I0803 00:09:01.090374 16048 trainer.py:139] Epoch[238/1000] loss: 0.23360173776745796
I0803 00:09:18.588362 16048 trainer.py:139] Epoch[239/1000] loss: 0.23422083258628845
I0803 00:09:36.148394 16048 trainer.py:139] Epoch[240/1000] loss: 0.23213867750018835
I0803 00:09:53.566892 16048 trainer.py:139] Epoch[241/1000] loss: 0.2337191253900528
I0803 00:10:11.117573 16048 trainer.py:139] Epoch[242/1000] loss: 0.23440839629620314
I0803 00:10:28.180171 16048 trainer.py:139] Epoch[243/1000] loss: 0.23245415557175875
I0803 00:10:45.655086 16048 trainer.py:139] Epoch[244/1000] loss: 0.23255587741732597
I0803 00:11:02.957858 16048 trainer.py:139] Epoch[245/1000] loss: 0.23269997723400593
I0803 00:11:19.915381 16048 trainer.py:139] Epoch[246/1000] loss: 0.23256990872323513
I0803 00:11:37.152607 16048 trainer.py:139] Epoch[247/1000] loss: 0.23236910346895456
I0803 00:11:54.279243 16048 trainer.py:139] Epoch[248/1000] loss: 0.23282356280833483
I0803 00:12:11.648442 16048 trainer.py:139] Epoch[249/1000] loss: 0.23253401182591915
I0803 00:12:12.257954 16048 trainer.py:145] Test: [{'precision': 0.19047579298831385, 'recall': 0.2644114009532501, 'hit_ratio': 0.898330550918197, 'ndcg': 0.29673185356238013}]
I0803 00:12:29.477116 16048 trainer.py:139] Epoch[250/1000] loss: 0.23189663887023926
I0803 00:12:46.648451 16048 trainer.py:139] Epoch[251/1000] loss: 0.232215846888721
I0803 00:13:04.087547 16048 trainer.py:139] Epoch[252/1000] loss: 0.23155805468559265
I0803 00:13:21.620619 16048 trainer.py:139] Epoch[253/1000] loss: 0.2317945510149002
I0803 00:13:38.856836 16048 trainer.py:139] Epoch[254/1000] loss: 0.23156169801950455
I0803 00:13:56.260034 16048 trainer.py:139] Epoch[255/1000] loss: 0.23209586832672358
I0803 00:14:13.676481 16048 trainer.py:139] Epoch[256/1000] loss: 0.2301303194835782
I0803 00:14:31.074613 16048 trainer.py:139] Epoch[257/1000] loss: 0.229876471683383
I0803 00:14:48.485818 16048 trainer.py:139] Epoch[258/1000] loss: 0.2301361169666052
I0803 00:15:05.942805 16048 trainer.py:139] Epoch[259/1000] loss: 0.22969487216323614
I0803 00:15:23.473170 16048 trainer.py:139] Epoch[260/1000] loss: 0.22994250152260065
I0803 00:15:40.621182 16048 trainer.py:139] Epoch[261/1000] loss: 0.2300055120140314
I0803 00:15:58.160804 16048 trainer.py:139] Epoch[262/1000] loss: 0.2305562812834978
I0803 00:16:15.604944 16048 trainer.py:139] Epoch[263/1000] loss: 0.23046690877526999
I0803 00:16:33.075639 16048 trainer.py:139] Epoch[264/1000] loss: 0.2296511624008417
I0803 00:16:50.391216 16048 trainer.py:139] Epoch[265/1000] loss: 0.2287430064752698
I0803 00:17:07.644890 16048 trainer.py:139] Epoch[266/1000] loss: 0.2297443738207221
I0803 00:17:24.936818 16048 trainer.py:139] Epoch[267/1000] loss: 0.22784358821809292
I0803 00:17:42.299296 16048 trainer.py:139] Epoch[268/1000] loss: 0.22817950136959553
I0803 00:17:59.731711 16048 trainer.py:139] Epoch[269/1000] loss: 0.22976867109537125
I0803 00:18:16.845294 16048 trainer.py:139] Epoch[270/1000] loss: 0.2282977644354105
I0803 00:18:34.286642 16048 trainer.py:139] Epoch[271/1000] loss: 0.22946340218186378
I0803 00:18:51.707555 16048 trainer.py:139] Epoch[272/1000] loss: 0.22819799557328224
I0803 00:19:09.050634 16048 trainer.py:139] Epoch[273/1000] loss: 0.22768161538988352
I0803 00:19:26.236439 16048 trainer.py:139] Epoch[274/1000] loss: 0.22888039890676737
I0803 00:19:43.658135 16048 trainer.py:139] Epoch[275/1000] loss: 0.2278057299554348
I0803 00:20:01.127110 16048 trainer.py:139] Epoch[276/1000] loss: 0.22741686180233955
I0803 00:20:18.351034 16048 trainer.py:139] Epoch[277/1000] loss: 0.22729345131665468
I0803 00:20:35.635063 16048 trainer.py:139] Epoch[278/1000] loss: 0.2266503619030118
I0803 00:20:53.132459 16048 trainer.py:139] Epoch[279/1000] loss: 0.2275342270731926
I0803 00:21:10.352435 16048 trainer.py:139] Epoch[280/1000] loss: 0.2279263511300087
I0803 00:21:27.586750 16048 trainer.py:139] Epoch[281/1000] loss: 0.22694393806159496
I0803 00:21:45.128104 16048 trainer.py:139] Epoch[282/1000] loss: 0.22730300202965736
I0803 00:22:02.491845 16048 trainer.py:139] Epoch[283/1000] loss: 0.22681934293359518
I0803 00:22:19.804980 16048 trainer.py:139] Epoch[284/1000] loss: 0.2279750071465969
I0803 00:22:37.385475 16048 trainer.py:139] Epoch[285/1000] loss: 0.2263829130679369
I0803 00:22:54.529818 16048 trainer.py:139] Epoch[286/1000] loss: 0.22683672234416008
I0803 00:23:12.406615 16048 trainer.py:139] Epoch[287/1000] loss: 0.2263529859483242
I0803 00:23:29.523501 16048 trainer.py:139] Epoch[288/1000] loss: 0.22655271459370852
I0803 00:23:46.895668 16048 trainer.py:139] Epoch[289/1000] loss: 0.2268244968727231
I0803 00:24:04.454336 16048 trainer.py:139] Epoch[290/1000] loss: 0.2273050146177411
I0803 00:24:21.432656 16048 trainer.py:139] Epoch[291/1000] loss: 0.22690323740243912
I0803 00:24:38.812425 16048 trainer.py:139] Epoch[292/1000] loss: 0.22557499632239342
I0803 00:24:56.139252 16048 trainer.py:139] Epoch[293/1000] loss: 0.22577757015824318
I0803 00:25:13.594494 16048 trainer.py:139] Epoch[294/1000] loss: 0.22593453340232372
I0803 00:25:30.912118 16048 trainer.py:139] Epoch[295/1000] loss: 0.2261192835867405
I0803 00:25:48.048269 16048 trainer.py:139] Epoch[296/1000] loss: 0.22506382316350937
I0803 00:26:05.490222 16048 trainer.py:139] Epoch[297/1000] loss: 0.22519514989107847
I0803 00:26:23.008445 16048 trainer.py:139] Epoch[298/1000] loss: 0.22665531560778618
I0803 00:26:40.294466 16048 trainer.py:139] Epoch[299/1000] loss: 0.22580266371369362
I0803 00:26:40.987150 16048 trainer.py:145] Test: [{'precision': 0.19211185308848072, 'recall': 0.2681129071241683, 'hit_ratio': 0.9001669449081803, 'ndcg': 0.300767774911091}]
I0803 00:26:58.503721 16048 trainer.py:139] Epoch[300/1000] loss: 0.22613811772316694
I0803 00:27:16.018807 16048 trainer.py:139] Epoch[301/1000] loss: 0.22458806354552507
I0803 00:27:33.390785 16048 trainer.py:139] Epoch[302/1000] loss: 0.22522033751010895
I0803 00:27:50.899166 16048 trainer.py:139] Epoch[303/1000] loss: 0.2256305254995823
I0803 00:28:08.142477 16048 trainer.py:139] Epoch[304/1000] loss: 0.22383406199514866
I0803 00:28:25.352137 16048 trainer.py:139] Epoch[305/1000] loss: 0.22465676628053188
I0803 00:28:42.888021 16048 trainer.py:139] Epoch[306/1000] loss: 0.22462011687457561
I0803 00:28:59.891271 16048 trainer.py:139] Epoch[307/1000] loss: 0.22500804346054792
I0803 00:29:17.024181 16048 trainer.py:139] Epoch[308/1000] loss: 0.22507454082369804
I0803 00:29:34.268461 16048 trainer.py:139] Epoch[309/1000] loss: 0.22433328535407782
I0803 00:29:51.441992 16048 trainer.py:139] Epoch[310/1000] loss: 0.22356733120977879
I0803 00:30:08.492292 16048 trainer.py:139] Epoch[311/1000] loss: 0.2246970608830452
I0803 00:30:25.993520 16048 trainer.py:139] Epoch[312/1000] loss: 0.2238310230895877
I0803 00:30:43.327414 16048 trainer.py:139] Epoch[313/1000] loss: 0.22472745645791292
I0803 00:31:00.532415 16048 trainer.py:139] Epoch[314/1000] loss: 0.22295814752578735
I0803 00:31:17.759878 16048 trainer.py:139] Epoch[315/1000] loss: 0.22290840838104486
I0803 00:31:35.274659 16048 trainer.py:139] Epoch[316/1000] loss: 0.22379716578871012
I0803 00:31:52.679873 16048 trainer.py:139] Epoch[317/1000] loss: 0.2237701090052724
I0803 00:32:10.262703 16048 trainer.py:139] Epoch[318/1000] loss: 0.22275227960199118
I0803 00:32:27.355784 16048 trainer.py:139] Epoch[319/1000] loss: 0.2239263979718089
I0803 00:32:44.625898 16048 trainer.py:139] Epoch[320/1000] loss: 0.22385604307055473
I0803 00:33:02.164537 16048 trainer.py:139] Epoch[321/1000] loss: 0.22443910874426365
I0803 00:33:19.475736 16048 trainer.py:139] Epoch[322/1000] loss: 0.22318267915397882
I0803 00:33:36.815659 16048 trainer.py:139] Epoch[323/1000] loss: 0.22229003813117743
I0803 00:33:54.134996 16048 trainer.py:139] Epoch[324/1000] loss: 0.22206273302435875
I0803 00:34:11.776975 16048 trainer.py:139] Epoch[325/1000] loss: 0.2222826685756445
I0803 00:34:29.006025 16048 trainer.py:139] Epoch[326/1000] loss: 0.22279102634638548
I0803 00:34:46.167987 16048 trainer.py:139] Epoch[327/1000] loss: 0.22268608678132296
I0803 00:35:03.448920 16048 trainer.py:139] Epoch[328/1000] loss: 0.2227530162781477
I0803 00:35:20.706912 16048 trainer.py:139] Epoch[329/1000] loss: 0.22215169295668602
I0803 00:35:37.896512 16048 trainer.py:139] Epoch[330/1000] loss: 0.2220444455742836
I0803 00:35:55.176516 16048 trainer.py:139] Epoch[331/1000] loss: 0.22151186596602201
I0803 00:36:12.202530 16048 trainer.py:139] Epoch[332/1000] loss: 0.22355300188064575
I0803 00:36:29.365092 16048 trainer.py:139] Epoch[333/1000] loss: 0.2213128749281168
I0803 00:36:46.981563 16048 trainer.py:139] Epoch[334/1000] loss: 0.2221696488559246
I0803 00:37:04.198237 16048 trainer.py:139] Epoch[335/1000] loss: 0.22218266502022743
I0803 00:37:21.490908 16048 trainer.py:139] Epoch[336/1000] loss: 0.2218696866184473
I0803 00:37:38.679570 16048 trainer.py:139] Epoch[337/1000] loss: 0.22228932846337557
I0803 00:37:56.209943 16048 trainer.py:139] Epoch[338/1000] loss: 0.2206305181607604
I0803 00:38:13.729221 16048 trainer.py:139] Epoch[339/1000] loss: 0.22244089655578136
I0803 00:38:31.114942 16048 trainer.py:139] Epoch[340/1000] loss: 0.2213645027950406
I0803 00:38:48.426898 16048 trainer.py:139] Epoch[341/1000] loss: 0.22245226614177227
I0803 00:39:05.849268 16048 trainer.py:139] Epoch[342/1000] loss: 0.221690583974123
I0803 00:39:23.131977 16048 trainer.py:139] Epoch[343/1000] loss: 0.22204724792391062
I0803 00:39:40.730326 16048 trainer.py:139] Epoch[344/1000] loss: 0.22120688762515783
I0803 00:39:58.034317 16048 trainer.py:139] Epoch[345/1000] loss: 0.22034824267029762
I0803 00:40:15.600493 16048 trainer.py:139] Epoch[346/1000] loss: 0.22156395763158798
I0803 00:40:33.101237 16048 trainer.py:139] Epoch[347/1000] loss: 0.22158535290509462
I0803 00:40:50.389204 16048 trainer.py:139] Epoch[348/1000] loss: 0.2208858858793974
I0803 00:41:07.721452 16048 trainer.py:139] Epoch[349/1000] loss: 0.22122445795685053
I0803 00:41:08.325002 16048 trainer.py:145] Test: [{'precision': 0.19399833055091822, 'recall': 0.2714175033800372, 'hit_ratio': 0.9026711185308848, 'ndcg': 0.30399685964578954}]
I0803 00:41:25.574203 16048 trainer.py:139] Epoch[350/1000] loss: 0.21955102402716875
I0803 00:41:43.052688 16048 trainer.py:139] Epoch[351/1000] loss: 0.22027691267430782
I0803 00:42:00.265153 16048 trainer.py:139] Epoch[352/1000] loss: 0.22011625580489635
I0803 00:42:17.509967 16048 trainer.py:139] Epoch[353/1000] loss: 0.22186297550797462
I0803 00:42:34.742794 16048 trainer.py:139] Epoch[354/1000] loss: 0.22139038424938917
I0803 00:42:52.406463 16048 trainer.py:139] Epoch[355/1000] loss: 0.22094369120895863
I0803 00:43:09.763636 16048 trainer.py:139] Epoch[356/1000] loss: 0.22053007036447525
I0803 00:43:27.141805 16048 trainer.py:139] Epoch[357/1000] loss: 0.21993516758084297
I0803 00:43:44.518896 16048 trainer.py:139] Epoch[358/1000] loss: 0.21952415723353624
I0803 00:44:01.826790 16048 trainer.py:139] Epoch[359/1000] loss: 0.2203529579564929
I0803 00:44:19.049187 16048 trainer.py:139] Epoch[360/1000] loss: 0.2199514713138342
I0803 00:44:36.517709 16048 trainer.py:139] Epoch[361/1000] loss: 0.21899596229195595
I0803 00:44:53.844855 16048 trainer.py:139] Epoch[362/1000] loss: 0.21971253585070372
I0803 00:45:11.231721 16048 trainer.py:139] Epoch[363/1000] loss: 0.21832044329494238
I0803 00:45:28.534921 16048 trainer.py:139] Epoch[364/1000] loss: 0.22044106479734182
I0803 00:45:46.020098 16048 trainer.py:139] Epoch[365/1000] loss: 0.21988143399357796
I0803 00:46:03.550927 16048 trainer.py:139] Epoch[366/1000] loss: 0.2203586446121335
I0803 00:46:20.861546 16048 trainer.py:139] Epoch[367/1000] loss: 0.21887828409671783
I0803 00:46:38.159835 16048 trainer.py:139] Epoch[368/1000] loss: 0.21837877668440342
I0803 00:46:55.522114 16048 trainer.py:139] Epoch[369/1000] loss: 0.21860950160771608
I0803 00:47:12.705556 16048 trainer.py:139] Epoch[370/1000] loss: 0.21896332036703825
I0803 00:47:30.152193 16048 trainer.py:139] Epoch[371/1000] loss: 0.21813140623271465
I0803 00:47:47.435155 16048 trainer.py:139] Epoch[372/1000] loss: 0.21934250090271235
I0803 00:48:04.709516 16048 trainer.py:139] Epoch[373/1000] loss: 0.2197033418342471
I0803 00:48:21.881194 16048 trainer.py:139] Epoch[374/1000] loss: 0.2197347516193986
I0803 00:48:39.258985 16048 trainer.py:139] Epoch[375/1000] loss: 0.21889659482985735
I0803 00:48:56.529835 16048 trainer.py:139] Epoch[376/1000] loss: 0.21921498328447342
I0803 00:49:13.663803 16048 trainer.py:139] Epoch[377/1000] loss: 0.21795236226171255
I0803 00:49:30.689796 16048 trainer.py:139] Epoch[378/1000] loss: 0.21982416789978743
I0803 00:49:48.152900 16048 trainer.py:139] Epoch[379/1000] loss: 0.2195332646369934
I0803 00:50:05.459076 16048 trainer.py:139] Epoch[380/1000] loss: 0.21893287729471922
I0803 00:50:22.690589 16048 trainer.py:139] Epoch[381/1000] loss: 0.21744421403855085
I0803 00:50:40.210523 16048 trainer.py:139] Epoch[382/1000] loss: 0.21815347578376532
I0803 00:50:57.374316 16048 trainer.py:139] Epoch[383/1000] loss: 0.21770666539669037
I0803 00:51:14.659147 16048 trainer.py:139] Epoch[384/1000] loss: 0.21866543777287006
I0803 00:51:32.002027 16048 trainer.py:139] Epoch[385/1000] loss: 0.2185365492478013
I0803 00:51:49.321719 16048 trainer.py:139] Epoch[386/1000] loss: 0.21941257268190384
I0803 00:52:06.689218 16048 trainer.py:139] Epoch[387/1000] loss: 0.21813295036554337
I0803 00:52:24.183540 16048 trainer.py:139] Epoch[388/1000] loss: 0.21792390756309032
I0803 00:52:41.564997 16048 trainer.py:139] Epoch[389/1000] loss: 0.21802318561822176
I0803 00:52:58.862335 16048 trainer.py:139] Epoch[390/1000] loss: 0.2180878659710288
I0803 00:53:16.242112 16048 trainer.py:139] Epoch[391/1000] loss: 0.2174261948093772
I0803 00:53:33.387420 16048 trainer.py:139] Epoch[392/1000] loss: 0.21780698373913765
I0803 00:53:50.596060 16048 trainer.py:139] Epoch[393/1000] loss: 0.2176405880600214
I0803 00:54:07.802402 16048 trainer.py:139] Epoch[394/1000] loss: 0.21767644118517637
I0803 00:54:25.180169 16048 trainer.py:139] Epoch[395/1000] loss: 0.21687398292124271
I0803 00:54:42.284068 16048 trainer.py:139] Epoch[396/1000] loss: 0.21680795773863792
I0803 00:54:59.610018 16048 trainer.py:139] Epoch[397/1000] loss: 0.21668340545147657
I0803 00:55:17.156459 16048 trainer.py:139] Epoch[398/1000] loss: 0.21874170005321503
I0803 00:55:34.414146 16048 trainer.py:139] Epoch[399/1000] loss: 0.21700491569936275
I0803 00:55:35.024668 16048 trainer.py:145] Test: [{'precision': 0.19646076794657757, 'recall': 0.27515916325706935, 'hit_ratio': 0.9053422370617696, 'ndcg': 0.3077422469990303}]
I0803 00:55:52.372548 16048 trainer.py:139] Epoch[400/1000] loss: 0.2167743155732751
I0803 00:56:09.856266 16048 trainer.py:139] Epoch[401/1000] loss: 0.2178968396037817
I0803 00:56:27.461668 16048 trainer.py:139] Epoch[402/1000] loss: 0.21688142884522676
I0803 00:56:44.550949 16048 trainer.py:139] Epoch[403/1000] loss: 0.21707873698323965
I0803 00:57:01.814357 16048 trainer.py:139] Epoch[404/1000] loss: 0.21675830706954002
I0803 00:57:19.331858 16048 trainer.py:139] Epoch[405/1000] loss: 0.21787599474191666
I0803 00:57:37.002387 16048 trainer.py:139] Epoch[406/1000] loss: 0.21685074362903833
I0803 00:57:54.225136 16048 trainer.py:139] Epoch[407/1000] loss: 0.2167497482150793
I0803 00:58:11.669155 16048 trainer.py:139] Epoch[408/1000] loss: 0.2166632181033492
I0803 00:58:29.009396 16048 trainer.py:139] Epoch[409/1000] loss: 0.2174422787502408
I0803 00:58:46.573745 16048 trainer.py:139] Epoch[410/1000] loss: 0.21697447448968887
I0803 00:59:04.012927 16048 trainer.py:139] Epoch[411/1000] loss: 0.21704610902816057
I0803 00:59:21.290864 16048 trainer.py:139] Epoch[412/1000] loss: 0.21586498711258173
I0803 00:59:38.535939 16048 trainer.py:139] Epoch[413/1000] loss: 0.2166323270648718
I0803 00:59:55.576899 16048 trainer.py:139] Epoch[414/1000] loss: 0.216046211309731
I0803 01:00:12.894620 16048 trainer.py:139] Epoch[415/1000] loss: 0.21550697833299637
I0803 01:00:30.007973 16048 trainer.py:139] Epoch[416/1000] loss: 0.21657420601695776
I0803 01:00:47.060639 16048 trainer.py:139] Epoch[417/1000] loss: 0.2164956657215953
I0803 01:01:04.455937 16048 trainer.py:139] Epoch[418/1000] loss: 0.2167030917480588
I0803 01:01:21.536676 16048 trainer.py:139] Epoch[419/1000] loss: 0.21702751331031322
I0803 01:01:39.000176 16048 trainer.py:139] Epoch[420/1000] loss: 0.21626632940024137
I0803 01:01:56.530318 16048 trainer.py:139] Epoch[421/1000] loss: 0.21731077134609222
I0803 01:02:13.842743 16048 trainer.py:139] Epoch[422/1000] loss: 0.2167533403262496
I0803 01:02:31.252603 16048 trainer.py:139] Epoch[423/1000] loss: 0.21607604809105396
I0803 01:02:48.506637 16048 trainer.py:139] Epoch[424/1000] loss: 0.21620976645499468
I0803 01:03:05.656112 16048 trainer.py:139] Epoch[425/1000] loss: 0.21654225699603558
I0803 01:03:23.051664 16048 trainer.py:139] Epoch[426/1000] loss: 0.21565101575106382
I0803 01:03:40.683745 16048 trainer.py:139] Epoch[427/1000] loss: 0.2165991859510541
I0803 01:03:57.981430 16048 trainer.py:139] Epoch[428/1000] loss: 0.21581200789660215
I0803 01:04:15.053814 16048 trainer.py:139] Epoch[429/1000] loss: 0.21460195910185575
I0803 01:04:32.380123 16048 trainer.py:139] Epoch[430/1000] loss: 0.21520402375608683
I0803 01:04:49.795570 16048 trainer.py:139] Epoch[431/1000] loss: 0.21512988582253456
I0803 01:05:07.084074 16048 trainer.py:139] Epoch[432/1000] loss: 0.21442148834466934
I0803 01:05:24.328332 16048 trainer.py:139] Epoch[433/1000] loss: 0.2151279430836439
I0803 01:05:41.718654 16048 trainer.py:139] Epoch[434/1000] loss: 0.21551657747477293
I0803 01:05:58.885238 16048 trainer.py:139] Epoch[435/1000] loss: 0.21489133220165968
I0803 01:06:16.134068 16048 trainer.py:139] Epoch[436/1000] loss: 0.21398747619241476
I0803 01:06:33.267621 16048 trainer.py:139] Epoch[437/1000] loss: 0.21529659442603588
I0803 01:06:50.473870 16048 trainer.py:139] Epoch[438/1000] loss: 0.21625777706503868
I0803 01:07:07.765456 16048 trainer.py:139] Epoch[439/1000] loss: 0.21508802566677332
I0803 01:07:25.107282 16048 trainer.py:139] Epoch[440/1000] loss: 0.2152536790817976
I0803 01:07:42.397741 16048 trainer.py:139] Epoch[441/1000] loss: 0.21479617897421122
I0803 01:07:59.830501 16048 trainer.py:139] Epoch[442/1000] loss: 0.21410384308546782
I0803 01:08:17.135668 16048 trainer.py:139] Epoch[443/1000] loss: 0.21509610768407583
I0803 01:08:34.353695 16048 trainer.py:139] Epoch[444/1000] loss: 0.21314705349504948
I0803 01:08:51.862424 16048 trainer.py:139] Epoch[445/1000] loss: 0.21496377605944872
I0803 01:09:09.466420 16048 trainer.py:139] Epoch[446/1000] loss: 0.21398655883967876
I0803 01:09:26.929186 16048 trainer.py:139] Epoch[447/1000] loss: 0.2147485325112939
I0803 01:09:44.160047 16048 trainer.py:139] Epoch[448/1000] loss: 0.21421031933277845
I0803 01:10:01.689918 16048 trainer.py:139] Epoch[449/1000] loss: 0.21430688444525003
I0803 01:10:02.236637 16048 trainer.py:145] Test: [{'precision': 0.19749582637729543, 'recall': 0.27711324574033547, 'hit_ratio': 0.9061769616026711, 'ndcg': 0.30959412145987736}]
I0803 01:10:19.555832 16048 trainer.py:139] Epoch[450/1000] loss: 0.21508114971220493
I0803 01:10:36.883732 16048 trainer.py:139] Epoch[451/1000] loss: 0.21465301793068647
I0803 01:10:54.196090 16048 trainer.py:139] Epoch[452/1000] loss: 0.21478561777621508
I0803 01:11:11.370608 16048 trainer.py:139] Epoch[453/1000] loss: 0.21487727761268616
I0803 01:11:28.628549 16048 trainer.py:139] Epoch[454/1000] loss: 0.2140508694574237
I0803 01:11:45.762136 16048 trainer.py:139] Epoch[455/1000] loss: 0.21297865826636553
I0803 01:12:03.249309 16048 trainer.py:139] Epoch[456/1000] loss: 0.21499889064580202
I0803 01:12:20.657889 16048 trainer.py:139] Epoch[457/1000] loss: 0.21369278710335493
I0803 01:12:38.017186 16048 trainer.py:139] Epoch[458/1000] loss: 0.21412110328674316
I0803 01:12:55.467945 16048 trainer.py:139] Epoch[459/1000] loss: 0.21422186121344566
I0803 01:13:12.805336 16048 trainer.py:139] Epoch[460/1000] loss: 0.21356855425983667
I0803 01:13:30.041628 16048 trainer.py:139] Epoch[461/1000] loss: 0.21312032639980316
I0803 01:13:47.262121 16048 trainer.py:139] Epoch[462/1000] loss: 0.21325255930423737
I0803 01:14:04.981732 16048 trainer.py:139] Epoch[463/1000] loss: 0.21504528261721134
I0803 01:14:22.294371 16048 trainer.py:139] Epoch[464/1000] loss: 0.21404280606657267
I0803 01:14:39.568525 16048 trainer.py:139] Epoch[465/1000] loss: 0.21278284583240747
I0803 01:14:57.109447 16048 trainer.py:139] Epoch[466/1000] loss: 0.2135453950613737
I0803 01:15:14.303570 16048 trainer.py:139] Epoch[467/1000] loss: 0.2138137249276042
I0803 01:15:31.718525 16048 trainer.py:139] Epoch[468/1000] loss: 0.2137073501944542
I0803 01:15:48.919296 16048 trainer.py:139] Epoch[469/1000] loss: 0.21339146979153156
I0803 01:16:06.291505 16048 trainer.py:139] Epoch[470/1000] loss: 0.21291909459978342
I0803 01:16:23.872177 16048 trainer.py:139] Epoch[471/1000] loss: 0.21414706576615572
I0803 01:16:41.276215 16048 trainer.py:139] Epoch[472/1000] loss: 0.21388908941298723
I0803 01:16:58.820653 16048 trainer.py:139] Epoch[473/1000] loss: 0.21441273484379053
I0803 01:17:16.101522 16048 trainer.py:139] Epoch[474/1000] loss: 0.2132637221366167
I0803 01:17:33.286487 16048 trainer.py:139] Epoch[475/1000] loss: 0.21287380065768957
I0803 01:17:50.867621 16048 trainer.py:139] Epoch[476/1000] loss: 0.21252378169447184
I0803 01:18:08.075022 16048 trainer.py:139] Epoch[477/1000] loss: 0.21366294380277395
I0803 01:18:25.495436 16048 trainer.py:139] Epoch[478/1000] loss: 0.21244035381823778
I0803 01:18:42.666146 16048 trainer.py:139] Epoch[479/1000] loss: 0.21402710396796465
I0803 01:19:00.100415 16048 trainer.py:139] Epoch[480/1000] loss: 0.2126156771555543
I0803 01:19:17.484313 16048 trainer.py:139] Epoch[481/1000] loss: 0.21388285607099533
I0803 01:19:35.005519 16048 trainer.py:139] Epoch[482/1000] loss: 0.21430132631212473
I0803 01:19:52.355243 16048 trainer.py:139] Epoch[483/1000] loss: 0.21255701128393412
I0803 01:20:09.765116 16048 trainer.py:139] Epoch[484/1000] loss: 0.2128291977569461
I0803 01:20:27.228287 16048 trainer.py:139] Epoch[485/1000] loss: 0.2139018876478076
I0803 01:20:44.534059 16048 trainer.py:139] Epoch[486/1000] loss: 0.21334373019635677
I0803 01:21:01.797089 16048 trainer.py:139] Epoch[487/1000] loss: 0.21276600565761328
I0803 01:21:19.240198 16048 trainer.py:139] Epoch[488/1000] loss: 0.21261444315314293
I0803 01:21:36.607717 16048 trainer.py:139] Epoch[489/1000] loss: 0.21221883594989777
I0803 01:21:53.978112 16048 trainer.py:139] Epoch[490/1000] loss: 0.21297718957066536
I0803 01:22:11.220865 16048 trainer.py:139] Epoch[491/1000] loss: 0.21205943264067173
I0803 01:22:28.589678 16048 trainer.py:139] Epoch[492/1000] loss: 0.21339114382863045
I0803 01:22:45.804598 16048 trainer.py:139] Epoch[493/1000] loss: 0.21318741980940104
I0803 01:23:03.100650 16048 trainer.py:139] Epoch[494/1000] loss: 0.2116480264812708
I0803 01:23:20.313454 16048 trainer.py:139] Epoch[495/1000] loss: 0.21284216456115246
I0803 01:23:37.706772 16048 trainer.py:139] Epoch[496/1000] loss: 0.21221504360437393
I0803 01:23:55.087092 16048 trainer.py:139] Epoch[497/1000] loss: 0.21188900340348482
I0803 01:24:12.548428 16048 trainer.py:139] Epoch[498/1000] loss: 0.21217412315309048
I0803 01:24:29.768437 16048 trainer.py:139] Epoch[499/1000] loss: 0.21057644113898277
I0803 01:24:30.380991 16048 trainer.py:145] Test: [{'precision': 0.19792988313856422, 'recall': 0.2775227278086653, 'hit_ratio': 0.906677796327212, 'ndcg': 0.3110770248811037}]
I0803 01:24:47.678188 16048 trainer.py:139] Epoch[500/1000] loss: 0.21100281830877066
I0803 01:25:04.848385 16048 trainer.py:139] Epoch[501/1000] loss: 0.21200527902692556
I0803 01:25:22.139007 16048 trainer.py:139] Epoch[502/1000] loss: 0.2118088584393263
I0803 01:25:39.569542 16048 trainer.py:139] Epoch[503/1000] loss: 0.21159325167536736
I0803 01:25:56.668935 16048 trainer.py:139] Epoch[504/1000] loss: 0.21125022694468498
I0803 01:26:14.143767 16048 trainer.py:139] Epoch[505/1000] loss: 0.21223230473697186
I0803 01:26:31.633981 16048 trainer.py:139] Epoch[506/1000] loss: 0.21257351618260145
I0803 01:26:49.033958 16048 trainer.py:139] Epoch[507/1000] loss: 0.21161868702620268
I0803 01:27:06.345528 16048 trainer.py:139] Epoch[508/1000] loss: 0.21150810830295086
I0803 01:27:23.913316 16048 trainer.py:139] Epoch[509/1000] loss: 0.21278879884630442
I0803 01:27:41.339988 16048 trainer.py:139] Epoch[510/1000] loss: 0.21120745316147804
I0803 01:27:58.676992 16048 trainer.py:139] Epoch[511/1000] loss: 0.21178861148655415
I0803 01:28:16.028914 16048 trainer.py:139] Epoch[512/1000] loss: 0.21221697609871626
I0803 01:28:33.407862 16048 trainer.py:139] Epoch[513/1000] loss: 0.21162171103060246
I0803 01:28:50.925135 16048 trainer.py:139] Epoch[514/1000] loss: 0.21172985527664423
I0803 01:29:08.126378 16048 trainer.py:139] Epoch[515/1000] loss: 0.21192263532429934
I0803 01:29:25.159401 16048 trainer.py:139] Epoch[516/1000] loss: 0.2109106071293354
I0803 01:29:42.291277 16048 trainer.py:139] Epoch[517/1000] loss: 0.21089052874594927
I0803 01:29:59.783179 16048 trainer.py:139] Epoch[518/1000] loss: 0.21144309733062983
I0803 01:30:17.023917 16048 trainer.py:139] Epoch[519/1000] loss: 0.21194340474903584
I0803 01:30:34.282660 16048 trainer.py:139] Epoch[520/1000] loss: 0.2122577279806137
I0803 01:30:51.883136 16048 trainer.py:139] Epoch[521/1000] loss: 0.21142213325947523
I0803 01:31:09.068557 16048 trainer.py:139] Epoch[522/1000] loss: 0.21165298856794834
I0803 01:31:26.156022 16048 trainer.py:139] Epoch[523/1000] loss: 0.21081210300326347
I0803 01:31:43.552550 16048 trainer.py:139] Epoch[524/1000] loss: 0.21166970487684011
I0803 01:32:00.971980 16048 trainer.py:139] Epoch[525/1000] loss: 0.2106822533532977
I0803 01:32:18.457840 16048 trainer.py:139] Epoch[526/1000] loss: 0.20975210051983595
I0803 01:32:35.845951 16048 trainer.py:139] Epoch[527/1000] loss: 0.21071269176900387
I0803 01:32:53.008973 16048 trainer.py:139] Epoch[528/1000] loss: 0.21218309458345175
I0803 01:33:10.394788 16048 trainer.py:139] Epoch[529/1000] loss: 0.2108730049803853
I0803 01:33:27.697899 16048 trainer.py:139] Epoch[530/1000] loss: 0.21114322822540998
I0803 01:33:45.058739 16048 trainer.py:139] Epoch[531/1000] loss: 0.21033261343836784
I0803 01:34:02.376497 16048 trainer.py:139] Epoch[532/1000] loss: 0.2107838997617364
I0803 01:34:19.468436 16048 trainer.py:139] Epoch[533/1000] loss: 0.21090029552578926
I0803 01:34:36.679696 16048 trainer.py:139] Epoch[534/1000] loss: 0.21038151439279318
I0803 01:34:54.091465 16048 trainer.py:139] Epoch[535/1000] loss: 0.21107029169797897
I0803 01:35:11.569480 16048 trainer.py:139] Epoch[536/1000] loss: 0.21068035904318094
I0803 01:35:28.884984 16048 trainer.py:139] Epoch[537/1000] loss: 0.21083794813603163
I0803 01:35:46.183344 16048 trainer.py:139] Epoch[538/1000] loss: 0.21065283566713333
I0803 01:36:03.634988 16048 trainer.py:139] Epoch[539/1000] loss: 0.2106572724878788
I0803 01:36:21.152739 16048 trainer.py:139] Epoch[540/1000] loss: 0.21118874847888947
I0803 01:36:38.145354 16048 trainer.py:139] Epoch[541/1000] loss: 0.210717280395329
I0803 01:36:55.759978 16048 trainer.py:139] Epoch[542/1000] loss: 0.21032487228512764
I0803 01:37:13.413659 16048 trainer.py:139] Epoch[543/1000] loss: 0.21077060792595148
I0803 01:37:30.827853 16048 trainer.py:139] Epoch[544/1000] loss: 0.20990042109042406
I0803 01:37:48.210240 16048 trainer.py:139] Epoch[545/1000] loss: 0.2098481860011816
I0803 01:38:05.628854 16048 trainer.py:139] Epoch[546/1000] loss: 0.21000689547508955
I0803 01:38:22.911365 16048 trainer.py:139] Epoch[547/1000] loss: 0.2100354852154851
I0803 01:38:40.238688 16048 trainer.py:139] Epoch[548/1000] loss: 0.21042859740555286
I0803 01:38:57.767408 16048 trainer.py:139] Epoch[549/1000] loss: 0.21018329355865717
I0803 01:38:58.324124 16048 trainer.py:145] Test: [{'precision': 0.19948247078464101, 'recall': 0.27979379850100977, 'hit_ratio': 0.9075125208681135, 'ndcg': 0.31365574388916295}]
I0803 01:39:15.808831 16048 trainer.py:139] Epoch[550/1000] loss: 0.21088217105716467
I0803 01:39:33.500291 16048 trainer.py:139] Epoch[551/1000] loss: 0.20959203876554966
I0803 01:39:50.863802 16048 trainer.py:139] Epoch[552/1000] loss: 0.21029257867485285
I0803 01:40:07.987179 16048 trainer.py:139] Epoch[553/1000] loss: 0.21026642434298992
I0803 01:40:25.210940 16048 trainer.py:139] Epoch[554/1000] loss: 0.21046236529946327
I0803 01:40:42.569976 16048 trainer.py:139] Epoch[555/1000] loss: 0.2098108734935522
I0803 01:40:59.838975 16048 trainer.py:139] Epoch[556/1000] loss: 0.20950365718454123
I0803 01:41:17.130043 16048 trainer.py:139] Epoch[557/1000] loss: 0.20996423158794641
I0803 01:41:34.628279 16048 trainer.py:139] Epoch[558/1000] loss: 0.20999593753367662
I0803 01:41:51.815711 16048 trainer.py:139] Epoch[559/1000] loss: 0.2102853273972869
I0803 01:42:08.853454 16048 trainer.py:139] Epoch[560/1000] loss: 0.20897801499813795
I0803 01:42:26.391427 16048 trainer.py:139] Epoch[561/1000] loss: 0.21002119313925505
I0803 01:42:43.651938 16048 trainer.py:139] Epoch[562/1000] loss: 0.21069167368113995
I0803 01:43:01.368163 16048 trainer.py:139] Epoch[563/1000] loss: 0.21028092131018639
I0803 01:43:18.595950 16048 trainer.py:139] Epoch[564/1000] loss: 0.20869199838489294
I0803 01:43:35.690296 16048 trainer.py:139] Epoch[565/1000] loss: 0.2088274173438549
I0803 01:43:53.279174 16048 trainer.py:139] Epoch[566/1000] loss: 0.2097062235698104
I0803 01:44:10.763194 16048 trainer.py:139] Epoch[567/1000] loss: 0.20922637544572353
I0803 01:44:28.252185 16048 trainer.py:139] Epoch[568/1000] loss: 0.20926523860543966
I0803 01:44:45.595542 16048 trainer.py:139] Epoch[569/1000] loss: 0.20907273795455694
I0803 01:45:03.185442 16048 trainer.py:139] Epoch[570/1000] loss: 0.20937841292470694
I0803 01:45:20.451412 16048 trainer.py:139] Epoch[571/1000] loss: 0.20979866292327642
I0803 01:45:37.796878 16048 trainer.py:139] Epoch[572/1000] loss: 0.20929784420877695
I0803 01:45:55.106180 16048 trainer.py:139] Epoch[573/1000] loss: 0.20972705725580454
I0803 01:46:12.343152 16048 trainer.py:139] Epoch[574/1000] loss: 0.20988675020635128
I0803 01:46:29.760510 16048 trainer.py:139] Epoch[575/1000] loss: 0.20989065803587437
I0803 01:46:47.211888 16048 trainer.py:139] Epoch[576/1000] loss: 0.20894037559628487
I0803 01:47:04.629181 16048 trainer.py:139] Epoch[577/1000] loss: 0.20895110350102186
I0803 01:47:22.121502 16048 trainer.py:139] Epoch[578/1000] loss: 0.20955704618245363
I0803 01:47:39.454751 16048 trainer.py:139] Epoch[579/1000] loss: 0.20943350158631802
I0803 01:47:56.491384 16048 trainer.py:139] Epoch[580/1000] loss: 0.20948993135243654
I0803 01:48:13.714926 16048 trainer.py:139] Epoch[581/1000] loss: 0.21076803095638752
I0803 01:48:30.916289 16048 trainer.py:139] Epoch[582/1000] loss: 0.20928087644279003
I0803 01:48:48.366712 16048 trainer.py:139] Epoch[583/1000] loss: 0.20790875609964132
I0803 01:49:05.686795 16048 trainer.py:139] Epoch[584/1000] loss: 0.2097273049876094
I0803 01:49:22.622552 16048 trainer.py:139] Epoch[585/1000] loss: 0.20881812367588282
I0803 01:49:39.754320 16048 trainer.py:139] Epoch[586/1000] loss: 0.20990561600774527
I0803 01:49:57.254440 16048 trainer.py:139] Epoch[587/1000] loss: 0.209960063919425
I0803 01:50:14.666336 16048 trainer.py:139] Epoch[588/1000] loss: 0.20866858214139938
I0803 01:50:31.930178 16048 trainer.py:139] Epoch[589/1000] loss: 0.20825675502419472
I0803 01:50:49.342374 16048 trainer.py:139] Epoch[590/1000] loss: 0.20872389804571867
I0803 01:51:06.759326 16048 trainer.py:139] Epoch[591/1000] loss: 0.20920761302113533
I0803 01:51:24.005082 16048 trainer.py:139] Epoch[592/1000] loss: 0.20960058737546206
I0803 01:51:41.331071 16048 trainer.py:139] Epoch[593/1000] loss: 0.20840869937092066
I0803 01:51:58.923884 16048 trainer.py:139] Epoch[594/1000] loss: 0.20853491313755512
I0803 01:52:16.449025 16048 trainer.py:139] Epoch[595/1000] loss: 0.20874672755599022
I0803 01:52:33.924980 16048 trainer.py:139] Epoch[596/1000] loss: 0.20935064274817705
I0803 01:52:51.230620 16048 trainer.py:139] Epoch[597/1000] loss: 0.20856458507478237
I0803 01:53:08.663168 16048 trainer.py:139] Epoch[598/1000] loss: 0.2086500646546483
I0803 01:53:25.764878 16048 trainer.py:139] Epoch[599/1000] loss: 0.20827078353613615
I0803 01:53:26.375401 16048 trainer.py:145] Test: [{'precision': 0.20016694490818027, 'recall': 0.2809575539053316, 'hit_ratio': 0.9095158597662771, 'ndcg': 0.31508301515397835}]
I0803 01:53:43.508684 16048 trainer.py:139] Epoch[600/1000] loss: 0.20855877920985222
I0803 01:54:00.794565 16048 trainer.py:139] Epoch[601/1000] loss: 0.20909840520471334
I0803 01:54:17.991003 16048 trainer.py:139] Epoch[602/1000] loss: 0.20881085470318794
I0803 01:54:35.187839 16048 trainer.py:139] Epoch[603/1000] loss: 0.20771189406514168
I0803 01:54:52.356339 16048 trainer.py:139] Epoch[604/1000] loss: 0.20861961971968412
I0803 01:55:09.964815 16048 trainer.py:139] Epoch[605/1000] loss: 0.2090238006785512
I0803 01:55:27.428883 16048 trainer.py:139] Epoch[606/1000] loss: 0.20963809452950954
I0803 01:55:44.758271 16048 trainer.py:139] Epoch[607/1000] loss: 0.2082227123901248
I0803 01:56:02.112138 16048 trainer.py:139] Epoch[608/1000] loss: 0.20888663083314896
I0803 01:56:19.401599 16048 trainer.py:139] Epoch[609/1000] loss: 0.20783853996545076
I0803 01:56:36.747823 16048 trainer.py:139] Epoch[610/1000] loss: 0.20803710911422968
I0803 01:56:54.153934 16048 trainer.py:139] Epoch[611/1000] loss: 0.20822257548570633
I0803 01:57:11.718387 16048 trainer.py:139] Epoch[612/1000] loss: 0.209177085198462
I0803 01:57:29.353069 16048 trainer.py:139] Epoch[613/1000] loss: 0.20873372163623571
I0803 01:57:47.008738 16048 trainer.py:139] Epoch[614/1000] loss: 0.20821609254926443
I0803 01:58:04.526756 16048 trainer.py:139] Epoch[615/1000] loss: 0.20757116097956896
I0803 01:58:21.891187 16048 trainer.py:139] Epoch[616/1000] loss: 0.2076167594641447
I0803 01:58:39.274317 16048 trainer.py:139] Epoch[617/1000] loss: 0.20788826700299978
I0803 01:58:56.489534 16048 trainer.py:139] Epoch[618/1000] loss: 0.20720449928194284
I0803 01:59:14.100957 16048 trainer.py:139] Epoch[619/1000] loss: 0.2084758672863245
I0803 01:59:31.285060 16048 trainer.py:139] Epoch[620/1000] loss: 0.20826508849859238
I0803 01:59:48.874857 16048 trainer.py:139] Epoch[621/1000] loss: 0.20771444495767355
I0803 02:00:06.274191 16048 trainer.py:139] Epoch[622/1000] loss: 0.20803084317594767
I0803 02:00:23.367357 16048 trainer.py:139] Epoch[623/1000] loss: 0.2068662978708744
I0803 02:00:40.635369 16048 trainer.py:139] Epoch[624/1000] loss: 0.2076989095658064
I0803 02:00:58.030968 16048 trainer.py:139] Epoch[625/1000] loss: 0.20781637262552977
I0803 02:01:15.704095 16048 trainer.py:139] Epoch[626/1000] loss: 0.20704463310539722
I0803 02:01:33.183300 16048 trainer.py:139] Epoch[627/1000] loss: 0.20848616492003202
I0803 02:01:50.415838 16048 trainer.py:139] Epoch[628/1000] loss: 0.2081185569986701
I0803 02:02:07.883281 16048 trainer.py:139] Epoch[629/1000] loss: 0.20735605992376804
I0803 02:02:25.273387 16048 trainer.py:139] Epoch[630/1000] loss: 0.20714445319026709
I0803 02:02:42.849184 16048 trainer.py:139] Epoch[631/1000] loss: 0.20696592051535845
I0803 02:03:00.186800 16048 trainer.py:139] Epoch[632/1000] loss: 0.20696617290377617
I0803 02:03:17.579707 16048 trainer.py:139] Epoch[633/1000] loss: 0.20713509898632765
I0803 02:03:35.115873 16048 trainer.py:139] Epoch[634/1000] loss: 0.20774508826434612
I0803 02:03:52.387693 16048 trainer.py:139] Epoch[635/1000] loss: 0.20608341600745916
I0803 02:04:09.656131 16048 trainer.py:139] Epoch[636/1000] loss: 0.2067803842946887
I0803 02:04:27.127487 16048 trainer.py:139] Epoch[637/1000] loss: 0.2076772516593337
I0803 02:04:44.449108 16048 trainer.py:139] Epoch[638/1000] loss: 0.20668895915150642
I0803 02:05:01.761972 16048 trainer.py:139] Epoch[639/1000] loss: 0.20807397086173296
I0803 02:05:19.019827 16048 trainer.py:139] Epoch[640/1000] loss: 0.20841228030622005
I0803 02:05:36.303371 16048 trainer.py:139] Epoch[641/1000] loss: 0.2070315182209015
I0803 02:05:53.581154 16048 trainer.py:139] Epoch[642/1000] loss: 0.20751467812806368
I0803 02:06:10.887713 16048 trainer.py:139] Epoch[643/1000] loss: 0.208083251491189
I0803 02:06:28.331934 16048 trainer.py:139] Epoch[644/1000] loss: 0.20790483057498932
I0803 02:06:45.721571 16048 trainer.py:139] Epoch[645/1000] loss: 0.20803310070186853
I0803 02:07:02.874346 16048 trainer.py:139] Epoch[646/1000] loss: 0.20740011055022478
I0803 02:07:19.970213 16048 trainer.py:139] Epoch[647/1000] loss: 0.20710909366607666
I0803 02:07:37.538684 16048 trainer.py:139] Epoch[648/1000] loss: 0.20722295809537172
I0803 02:07:55.130654 16048 trainer.py:139] Epoch[649/1000] loss: 0.20712781138718128
I0803 02:07:55.740602 16048 trainer.py:145] Test: [{'precision': 0.2009181969949916, 'recall': 0.2825666766440949, 'hit_ratio': 0.9093489148580969, 'ndcg': 0.31601583514459475}]
I0803 02:08:13.530241 16048 trainer.py:139] Epoch[650/1000] loss: 0.20652895141392946
I0803 02:08:30.885742 16048 trainer.py:139] Epoch[651/1000] loss: 0.2082810467109084
I0803 02:08:48.276317 16048 trainer.py:139] Epoch[652/1000] loss: 0.2066616639494896
I0803 02:09:05.615707 16048 trainer.py:139] Epoch[653/1000] loss: 0.2072473419830203
I0803 02:09:23.110317 16048 trainer.py:139] Epoch[654/1000] loss: 0.20542676094919443
I0803 02:09:40.485719 16048 trainer.py:139] Epoch[655/1000] loss: 0.20682884939014912
I0803 02:09:58.038333 16048 trainer.py:139] Epoch[656/1000] loss: 0.20769903156906366
I0803 02:10:15.331403 16048 trainer.py:139] Epoch[657/1000] loss: 0.2074739532545209
I0803 02:10:32.780951 16048 trainer.py:139] Epoch[658/1000] loss: 0.2080731140449643
I0803 02:10:50.197397 16048 trainer.py:139] Epoch[659/1000] loss: 0.20626944117248058
I0803 02:11:07.740713 16048 trainer.py:139] Epoch[660/1000] loss: 0.20713617093861103
I0803 02:11:24.771615 16048 trainer.py:139] Epoch[661/1000] loss: 0.20720479730516672
I0803 02:11:41.976806 16048 trainer.py:139] Epoch[662/1000] loss: 0.2075006803497672
I0803 02:11:59.131746 16048 trainer.py:139] Epoch[663/1000] loss: 0.20722264051437378
I0803 02:12:16.416732 16048 trainer.py:139] Epoch[664/1000] loss: 0.2066396353766322
I0803 02:12:33.676817 16048 trainer.py:139] Epoch[665/1000] loss: 0.20685628522187471
I0803 02:12:51.102875 16048 trainer.py:139] Epoch[666/1000] loss: 0.2061994317919016
I0803 02:13:08.531460 16048 trainer.py:139] Epoch[667/1000] loss: 0.20673021208494902
I0803 02:13:25.802535 16048 trainer.py:139] Epoch[668/1000] loss: 0.20720034558326006
I0803 02:13:43.319410 16048 trainer.py:139] Epoch[669/1000] loss: 0.20664694905281067
I0803 02:14:00.823358 16048 trainer.py:139] Epoch[670/1000] loss: 0.20610599964857101
I0803 02:14:18.273681 16048 trainer.py:139] Epoch[671/1000] loss: 0.20652305521070957
I0803 02:14:35.598942 16048 trainer.py:139] Epoch[672/1000] loss: 0.2072084778919816
I0803 02:14:53.053670 16048 trainer.py:139] Epoch[673/1000] loss: 0.20667683705687523
I0803 02:15:10.548308 16048 trainer.py:139] Epoch[674/1000] loss: 0.20651082880795002
I0803 02:15:27.907791 16048 trainer.py:139] Epoch[675/1000] loss: 0.2065760362893343
I0803 02:15:45.226787 16048 trainer.py:139] Epoch[676/1000] loss: 0.20648244209587574
I0803 02:16:02.578815 16048 trainer.py:139] Epoch[677/1000] loss: 0.2062907749786973
I0803 02:16:19.681187 16048 trainer.py:139] Epoch[678/1000] loss: 0.20645495038479567
I0803 02:16:37.170990 16048 trainer.py:139] Epoch[679/1000] loss: 0.206261252053082
I0803 02:16:54.408744 16048 trainer.py:139] Epoch[680/1000] loss: 0.20717621594667435
I0803 02:17:11.796146 16048 trainer.py:139] Epoch[681/1000] loss: 0.20729600731283426
I0803 02:17:28.849081 16048 trainer.py:139] Epoch[682/1000] loss: 0.20563846174627542
I0803 02:17:46.185559 16048 trainer.py:139] Epoch[683/1000] loss: 0.20595589093863964
I0803 02:18:03.580938 16048 trainer.py:139] Epoch[684/1000] loss: 0.20637910068035126
I0803 02:18:20.915692 16048 trainer.py:139] Epoch[685/1000] loss: 0.20585094951093197
I0803 02:18:38.336535 16048 trainer.py:139] Epoch[686/1000] loss: 0.20583659503608942
I0803 02:18:55.762454 16048 trainer.py:139] Epoch[687/1000] loss: 0.20564349927008152
I0803 02:19:13.393402 16048 trainer.py:139] Epoch[688/1000] loss: 0.2068498032167554
I0803 02:19:30.708279 16048 trainer.py:139] Epoch[689/1000] loss: 0.20671206153929234
I0803 02:19:47.862304 16048 trainer.py:139] Epoch[690/1000] loss: 0.20774191990494728
I0803 02:20:05.346254 16048 trainer.py:139] Epoch[691/1000] loss: 0.20561281312257051
I0803 02:20:22.794764 16048 trainer.py:139] Epoch[692/1000] loss: 0.2057195845991373
I0803 02:20:40.034301 16048 trainer.py:139] Epoch[693/1000] loss: 0.20653388928622007
I0803 02:20:57.338567 16048 trainer.py:139] Epoch[694/1000] loss: 0.20533295720815659
I0803 02:21:14.661164 16048 trainer.py:139] Epoch[695/1000] loss: 0.20496018137782812
I0803 02:21:31.888777 16048 trainer.py:139] Epoch[696/1000] loss: 0.20517326146364212
I0803 02:21:49.172265 16048 trainer.py:139] Epoch[697/1000] loss: 0.20589387603104115
I0803 02:22:06.364241 16048 trainer.py:139] Epoch[698/1000] loss: 0.20647700875997543
I0803 02:22:23.754912 16048 trainer.py:139] Epoch[699/1000] loss: 0.2054523015394807
I0803 02:22:24.414805 16048 trainer.py:145] Test: [{'precision': 0.2014023372287145, 'recall': 0.28227358786683415, 'hit_ratio': 0.9078464106844741, 'ndcg': 0.3173042904656304}]
I0803 02:22:41.712488 16048 trainer.py:139] Epoch[700/1000] loss: 0.20513375476002693
I0803 02:22:59.224772 16048 trainer.py:139] Epoch[701/1000] loss: 0.2059037545695901
I0803 02:23:16.634381 16048 trainer.py:139] Epoch[702/1000] loss: 0.20585759170353413
I0803 02:23:33.652341 16048 trainer.py:139] Epoch[703/1000] loss: 0.20528143178671598
I0803 02:23:50.872960 16048 trainer.py:139] Epoch[704/1000] loss: 0.20613879524171352
I0803 02:24:08.170756 16048 trainer.py:139] Epoch[705/1000] loss: 0.20566821284592152
I0803 02:24:26.021411 16048 trainer.py:139] Epoch[706/1000] loss: 0.2059821030125022
I0803 02:24:43.280649 16048 trainer.py:139] Epoch[707/1000] loss: 0.2058738498017192
I0803 02:25:01.017299 16048 trainer.py:139] Epoch[708/1000] loss: 0.2062231069430709
I0803 02:25:18.439015 16048 trainer.py:139] Epoch[709/1000] loss: 0.20636119600385427
I0803 02:25:35.978990 16048 trainer.py:139] Epoch[710/1000] loss: 0.20656501594930887
I0803 02:25:53.192451 16048 trainer.py:139] Epoch[711/1000] loss: 0.20517393946647644
I0803 02:26:10.698650 16048 trainer.py:139] Epoch[712/1000] loss: 0.20532951038330793
I0803 02:26:28.070593 16048 trainer.py:139] Epoch[713/1000] loss: 0.20528084971010685
I0803 02:26:45.465991 16048 trainer.py:139] Epoch[714/1000] loss: 0.2063399739563465
I0803 02:27:02.632111 16048 trainer.py:139] Epoch[715/1000] loss: 0.20658535044640303
I0803 02:27:19.730683 16048 trainer.py:139] Epoch[716/1000] loss: 0.2060185708105564
I0803 02:27:37.414385 16048 trainer.py:139] Epoch[717/1000] loss: 0.20487702917307615
I0803 02:27:54.742645 16048 trainer.py:139] Epoch[718/1000] loss: 0.20491699781268835
I0803 02:28:11.937046 16048 trainer.py:139] Epoch[719/1000] loss: 0.20588702987879515
I0803 02:28:29.283422 16048 trainer.py:139] Epoch[720/1000] loss: 0.20647906139492989
I0803 02:28:46.630629 16048 trainer.py:139] Epoch[721/1000] loss: 0.2054819678887725
