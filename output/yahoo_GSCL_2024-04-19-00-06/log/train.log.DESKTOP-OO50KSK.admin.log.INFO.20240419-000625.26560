I0419 00:06:31.313606 30816 trainer.py:121] Test: [{'precision': 0.005098615190935795, 'recall': 0.056888742348247166, 'hit_ratio': 0.09861519093579521, 'ndcg': 0.025179586117753974}]
I0419 00:06:42.907949 30816 trainer.py:139] Epoch[0/1000] loss: 1.1156928952663177
I0419 00:06:52.017572 30816 trainer.py:139] Epoch[1/1000] loss: 1.0037051333535103
I0419 00:07:03.534663 30816 trainer.py:139] Epoch[2/1000] loss: 0.9738726519769237
I0419 00:07:12.423165 30816 trainer.py:139] Epoch[3/1000] loss: 0.9288670247600924
I0419 00:07:23.843858 30816 trainer.py:139] Epoch[4/1000] loss: 0.9058741831010387
I0419 00:07:34.446897 30816 trainer.py:139] Epoch[5/1000] loss: 0.8761493034901158
I0419 00:07:44.097864 30816 trainer.py:139] Epoch[6/1000] loss: 0.8593964230629706
I0419 00:07:53.854791 30816 trainer.py:139] Epoch[7/1000] loss: 0.8399389309267844
I0419 00:08:04.424365 30816 trainer.py:139] Epoch[8/1000] loss: 0.8245277520148985
I0419 00:08:13.917795 30816 trainer.py:139] Epoch[9/1000] loss: 0.8121295686691038
I0419 00:08:24.545519 30816 trainer.py:139] Epoch[10/1000] loss: 0.802933624675197
I0419 00:08:33.704439 30816 trainer.py:139] Epoch[11/1000] loss: 0.7934188515909256
I0419 00:08:44.959995 30816 trainer.py:139] Epoch[12/1000] loss: 0.7877534666369038
I0419 00:08:53.884524 30816 trainer.py:139] Epoch[13/1000] loss: 0.7772465550130413
I0419 00:09:05.027624 30816 trainer.py:139] Epoch[14/1000] loss: 0.7686791602642306
I0419 00:09:13.650642 30816 trainer.py:139] Epoch[15/1000] loss: 0.7623468772057564
I0419 00:09:24.679672 30816 trainer.py:139] Epoch[16/1000] loss: 0.7577827957368666
I0419 00:09:33.529214 30816 trainer.py:139] Epoch[17/1000] loss: 0.7510985059122885
I0419 00:09:44.849536 30816 trainer.py:139] Epoch[18/1000] loss: 0.7443474771515015
I0419 00:09:53.851500 30816 trainer.py:139] Epoch[19/1000] loss: 0.7391622566407726
I0419 00:10:04.806187 30816 trainer.py:139] Epoch[20/1000] loss: 0.7384443379217579
I0419 00:10:13.905686 30816 trainer.py:139] Epoch[21/1000] loss: 0.7337783565444331
I0419 00:10:23.555044 30816 trainer.py:139] Epoch[22/1000] loss: 0.7316827716365937
I0419 00:10:33.849341 30816 trainer.py:139] Epoch[23/1000] loss: 0.724812077899133
I0419 00:10:43.402087 30816 trainer.py:139] Epoch[24/1000] loss: 0.726309189873357
I0419 00:10:53.692739 30816 trainer.py:139] Epoch[25/1000] loss: 0.7206489136142116
I0419 00:11:02.882357 30816 trainer.py:139] Epoch[26/1000] loss: 0.7203660818838304
I0419 00:11:13.860297 30816 trainer.py:139] Epoch[27/1000] loss: 0.714726395183994
I0419 00:11:22.602627 30816 trainer.py:139] Epoch[28/1000] loss: 0.7153893170818206
I0419 00:11:33.710079 30816 trainer.py:139] Epoch[29/1000] loss: 0.7086259059367641
I0419 00:11:42.475750 30816 trainer.py:139] Epoch[30/1000] loss: 0.7109362646456687
I0419 00:11:53.934602 30816 trainer.py:139] Epoch[31/1000] loss: 0.70902663180905
I0419 00:12:02.874251 30816 trainer.py:139] Epoch[32/1000] loss: 0.7043976658774961
I0419 00:12:13.748265 30816 trainer.py:139] Epoch[33/1000] loss: 0.7016262152502614
I0419 00:12:22.756947 30816 trainer.py:139] Epoch[34/1000] loss: 0.6970411789032721
I0419 00:12:33.977508 30816 trainer.py:139] Epoch[35/1000] loss: 0.6970597659387896
I0419 00:12:42.706536 30816 trainer.py:139] Epoch[36/1000] loss: 0.7005282352047582
I0419 00:12:53.980227 30816 trainer.py:139] Epoch[37/1000] loss: 0.6934428099663027
I0419 00:13:01.989014 30816 trainer.py:139] Epoch[38/1000] loss: 0.6921013141832044
I0419 00:13:11.749926 30816 trainer.py:139] Epoch[39/1000] loss: 0.6935458154447617
I0419 00:13:21.014061 30816 trainer.py:139] Epoch[40/1000] loss: 0.6898703171360877
I0419 00:13:29.029824 30816 trainer.py:139] Epoch[41/1000] loss: 0.6909716956077083
I0419 00:13:40.136993 30816 trainer.py:139] Epoch[42/1000] loss: 0.685248262459232
I0419 00:13:48.895699 30816 trainer.py:139] Epoch[43/1000] loss: 0.6832512694020425
I0419 00:14:00.007849 30816 trainer.py:139] Epoch[44/1000] loss: 0.6824862255204108
I0419 00:14:08.796479 30816 trainer.py:139] Epoch[45/1000] loss: 0.6820279369431157
I0419 00:14:19.956631 30816 trainer.py:139] Epoch[46/1000] loss: 0.6803246765367447
I0419 00:14:29.145455 30816 trainer.py:139] Epoch[47/1000] loss: 0.6800741985920937
I0419 00:14:40.564700 30816 trainer.py:139] Epoch[48/1000] loss: 0.6785741842562153
I0419 00:14:50.784617 30816 trainer.py:139] Epoch[49/1000] loss: 0.677087176230646
I0419 00:14:51.603473 30816 trainer.py:145] Test: [{'precision': 0.011435165757448601, 'recall': 0.14229912275443118, 'hit_ratio': 0.21821233738984475, 'ndcg': 0.06705362949739668}]
I0419 00:15:01.370988 30816 trainer.py:139] Epoch[50/1000] loss: 0.6777487195307209
I0419 00:15:11.709818 30816 trainer.py:139] Epoch[51/1000] loss: 0.6798965344505925
I0419 00:15:21.514112 30816 trainer.py:139] Epoch[52/1000] loss: 0.6749211713191001
I0419 00:15:30.847050 30816 trainer.py:139] Epoch[53/1000] loss: 0.6757100724404858
I0419 00:15:41.398438 30816 trainer.py:139] Epoch[54/1000] loss: 0.6727216532153468
I0419 00:15:50.127422 30816 trainer.py:139] Epoch[55/1000] loss: 0.6671645400985595
I0419 00:16:01.243869 30816 trainer.py:139] Epoch[56/1000] loss: 0.6723877201157231
I0419 00:16:09.977064 30816 trainer.py:139] Epoch[57/1000] loss: 0.6708663269396751
I0419 00:16:21.106279 30816 trainer.py:139] Epoch[58/1000] loss: 0.6651705734191402
I0419 00:16:30.158442 30816 trainer.py:139] Epoch[59/1000] loss: 0.6674402231170286
I0419 00:16:41.279441 30816 trainer.py:139] Epoch[60/1000] loss: 0.6645933476186567
I0419 00:16:50.284268 30816 trainer.py:139] Epoch[61/1000] loss: 0.6665682119707907
I0419 00:17:01.492142 30816 trainer.py:139] Epoch[62/1000] loss: 0.6592311503425721
I0419 00:17:10.408851 30816 trainer.py:139] Epoch[63/1000] loss: 0.6626803855742177
I0419 00:17:21.443907 30816 trainer.py:139] Epoch[64/1000] loss: 0.6641575617174948
I0419 00:17:30.501889 30816 trainer.py:139] Epoch[65/1000] loss: 0.658610366044506
I0419 00:17:41.626413 30816 trainer.py:139] Epoch[66/1000] loss: 0.6649705431153697
I0419 00:17:50.634155 30816 trainer.py:139] Epoch[67/1000] loss: 0.6611938063175448
I0419 00:18:01.623805 30816 trainer.py:139] Epoch[68/1000] loss: 0.6559887124646094
I0419 00:18:10.664834 30816 trainer.py:139] Epoch[69/1000] loss: 0.6547928404423499
I0419 00:18:20.935267 30816 trainer.py:139] Epoch[70/1000] loss: 0.654101635179212
I0419 00:18:31.038934 30816 trainer.py:139] Epoch[71/1000] loss: 0.6569236565020776
I0419 00:18:39.998733 30816 trainer.py:139] Epoch[72/1000] loss: 0.6519857837307838
I0419 00:18:50.936473 30816 trainer.py:139] Epoch[73/1000] loss: 0.6512788197686595
I0419 00:18:59.972440 30816 trainer.py:139] Epoch[74/1000] loss: 0.6517517922386047
I0419 00:19:10.999913 30816 trainer.py:139] Epoch[75/1000] loss: 0.6545273709681726
I0419 00:19:19.419484 30816 trainer.py:139] Epoch[76/1000] loss: 0.6485170510507399
I0419 00:19:27.559284 30816 trainer.py:139] Epoch[77/1000] loss: 0.6472408338900535
I0419 00:19:38.096382 30816 trainer.py:139] Epoch[78/1000] loss: 0.6497027585583348
I0419 00:19:46.521321 30816 trainer.py:139] Epoch[79/1000] loss: 0.6460760418445833
I0419 00:19:54.482742 30816 trainer.py:139] Epoch[80/1000] loss: 0.646485315215203
I0419 00:20:04.728725 30816 trainer.py:139] Epoch[81/1000] loss: 0.6465946887770007
I0419 00:20:12.897901 30816 trainer.py:139] Epoch[82/1000] loss: 0.6499329507350922
I0419 00:20:21.427851 30816 trainer.py:139] Epoch[83/1000] loss: 0.6482837229005752
I0419 00:20:31.904255 30816 trainer.py:139] Epoch[84/1000] loss: 0.6430112767604089
I0419 00:20:40.105904 30816 trainer.py:139] Epoch[85/1000] loss: 0.6428243075647662
I0419 00:20:48.549252 30816 trainer.py:139] Epoch[86/1000] loss: 0.6432727623370386
I0419 00:20:57.930070 30816 trainer.py:139] Epoch[87/1000] loss: 0.6392364780749044
I0419 00:21:07.116369 30816 trainer.py:139] Epoch[88/1000] loss: 0.6472916958793518
I0419 00:21:15.343274 30816 trainer.py:139] Epoch[89/1000] loss: 0.6417182405148784
I0419 00:21:24.936462 30816 trainer.py:139] Epoch[90/1000] loss: 0.641417863868898
I0419 00:21:34.319125 30816 trainer.py:139] Epoch[91/1000] loss: 0.644122927419601
I0419 00:21:43.043190 30816 trainer.py:139] Epoch[92/1000] loss: 0.6348573642392312
I0419 00:21:54.757271 30816 trainer.py:139] Epoch[93/1000] loss: 0.6417092219475777
I0419 00:22:03.842448 30816 trainer.py:139] Epoch[94/1000] loss: 0.6381647827163819
I0419 00:22:15.268751 30816 trainer.py:139] Epoch[95/1000] loss: 0.6353805843860872
I0419 00:22:24.252067 30816 trainer.py:139] Epoch[96/1000] loss: 0.6369772361170861
I0419 00:22:35.887088 30816 trainer.py:139] Epoch[97/1000] loss: 0.6375089653076664
I0419 00:22:45.341671 30816 trainer.py:139] Epoch[98/1000] loss: 0.6322095903658098
I0419 00:22:56.808822 30816 trainer.py:139] Epoch[99/1000] loss: 0.6345763648709943
I0419 00:22:57.640603 30816 trainer.py:145] Test: [{'precision': 0.011749895090222414, 'recall': 0.14799172711468137, 'hit_ratio': 0.22408728493495594, 'ndcg': 0.06980284280057976}]
I0419 00:23:07.032290 30816 trainer.py:139] Epoch[100/1000] loss: 0.6357490478023406
I0419 00:23:18.752679 30816 trainer.py:139] Epoch[101/1000] loss: 0.6332584206135042
I0419 00:23:29.742243 30816 trainer.py:139] Epoch[102/1000] loss: 0.6327706046642796
I0419 00:23:39.467273 30816 trainer.py:139] Epoch[103/1000] loss: 0.6332530658091268
I0419 00:23:49.632647 30816 trainer.py:139] Epoch[104/1000] loss: 0.6332671353893895
I0419 00:23:59.967838 30816 trainer.py:139] Epoch[105/1000] loss: 0.630186777922415
I0419 00:24:10.585710 30816 trainer.py:139] Epoch[106/1000] loss: 0.6295770127927104
I0419 00:24:19.750147 30816 trainer.py:139] Epoch[107/1000] loss: 0.6303612320653854
I0419 00:24:29.084506 30816 trainer.py:139] Epoch[108/1000] loss: 0.6320661546722535
I0419 00:24:39.984699 30816 trainer.py:139] Epoch[109/1000] loss: 0.6321840555437149
I0419 00:24:48.891084 30816 trainer.py:139] Epoch[110/1000] loss: 0.6292636279136904
I0419 00:24:59.956395 30816 trainer.py:139] Epoch[111/1000] loss: 0.6282323896884918
I0419 00:25:10.475042 30816 trainer.py:139] Epoch[112/1000] loss: 0.628368918934176
I0419 00:25:20.467329 30816 trainer.py:139] Epoch[113/1000] loss: 0.623550679414503
I0419 00:25:31.368136 30816 trainer.py:139] Epoch[114/1000] loss: 0.628507367064876
I0419 00:25:40.902848 30816 trainer.py:139] Epoch[115/1000] loss: 0.6260199575654922
I0419 00:25:49.705958 30816 trainer.py:139] Epoch[116/1000] loss: 0.6247208964440131
I0419 00:26:00.869561 30816 trainer.py:139] Epoch[117/1000] loss: 0.6264390657024999
I0419 00:26:09.823012 30816 trainer.py:139] Epoch[118/1000] loss: 0.6236360832568137
I0419 00:26:20.863361 30816 trainer.py:139] Epoch[119/1000] loss: 0.6238946568581366
I0419 00:26:29.882378 30816 trainer.py:139] Epoch[120/1000] loss: 0.6220854511184077
I0419 00:26:40.599508 30816 trainer.py:139] Epoch[121/1000] loss: 0.6236782535429923
I0419 00:26:50.191603 30816 trainer.py:139] Epoch[122/1000] loss: 0.6220886332373465
I0419 00:26:59.859047 30816 trainer.py:139] Epoch[123/1000] loss: 0.6219100010010504
I0419 00:27:10.192385 30816 trainer.py:139] Epoch[124/1000] loss: 0.6229070655761226
I0419 00:27:19.260727 30816 trainer.py:139] Epoch[125/1000] loss: 0.6233524237909625
I0419 00:27:30.469903 30816 trainer.py:139] Epoch[126/1000] loss: 0.6180466721134801
I0419 00:27:39.409981 30816 trainer.py:139] Epoch[127/1000] loss: 0.6192475172781176
I0419 00:27:50.516838 30816 trainer.py:139] Epoch[128/1000] loss: 0.6189895358777815
I0419 00:27:59.358681 30816 trainer.py:139] Epoch[129/1000] loss: 0.6176720290414749
I0419 00:28:10.532376 30816 trainer.py:139] Epoch[130/1000] loss: 0.6199638949286553
I0419 00:28:19.511817 30816 trainer.py:139] Epoch[131/1000] loss: 0.6198115992930627
I0419 00:28:30.259555 30816 trainer.py:139] Epoch[132/1000] loss: 0.6190406555129636
I0419 00:28:39.604022 30816 trainer.py:139] Epoch[133/1000] loss: 0.6167823614612702
I0419 00:28:49.339221 30816 trainer.py:139] Epoch[134/1000] loss: 0.6197003231894586
I0419 00:28:59.780622 30816 trainer.py:139] Epoch[135/1000] loss: 0.6168910043854867
I0419 00:29:09.288830 30816 trainer.py:139] Epoch[136/1000] loss: 0.620610184246494
I0419 00:29:19.846648 30816 trainer.py:139] Epoch[137/1000] loss: 0.6144068721802004
I0419 00:29:28.936268 30816 trainer.py:139] Epoch[138/1000] loss: 0.6194819048527749
I0419 00:29:40.157902 30816 trainer.py:139] Epoch[139/1000] loss: 0.6159588271571744
I0419 00:29:49.030532 30816 trainer.py:139] Epoch[140/1000] loss: 0.6154744538568682
I0419 00:30:00.220943 30816 trainer.py:139] Epoch[141/1000] loss: 0.6167930854905036
I0419 00:30:09.210027 30816 trainer.py:139] Epoch[142/1000] loss: 0.6163704568339933
I0419 00:30:20.455904 30816 trainer.py:139] Epoch[143/1000] loss: 0.6125142064786726
I0419 00:30:29.380475 30816 trainer.py:139] Epoch[144/1000] loss: 0.6178406130883002
I0419 00:30:40.497644 30816 trainer.py:139] Epoch[145/1000] loss: 0.6152789140901258
I0419 00:30:49.602733 30816 trainer.py:139] Epoch[146/1000] loss: 0.6141545753325185
I0419 00:31:00.675171 30816 trainer.py:139] Epoch[147/1000] loss: 0.6131675051104638
I0419 00:31:09.741028 30816 trainer.py:139] Epoch[148/1000] loss: 0.6175935460675147
I0419 00:31:19.989075 30816 trainer.py:139] Epoch[149/1000] loss: 0.6149528084262725
I0419 00:31:20.806950 30816 trainer.py:145] Test: [{'precision': 0.011980696600923211, 'recall': 0.15186339747816877, 'hit_ratio': 0.22996223248006714, 'ndcg': 0.07168284067816104}]
I0419 00:31:29.809316 30816 trainer.py:139] Epoch[150/1000] loss: 0.6109741003282608
I0419 00:31:37.960202 30816 trainer.py:139] Epoch[151/1000] loss: 0.6125160253817036
I0419 00:31:47.550361 30816 trainer.py:139] Epoch[152/1000] loss: 0.6133040208970347
I0419 00:31:56.686910 30816 trainer.py:139] Epoch[153/1000] loss: 0.6076506587766832
I0419 00:32:05.160929 30816 trainer.py:139] Epoch[154/1000] loss: 0.6073452570746022
I0419 00:32:13.545102 30816 trainer.py:139] Epoch[155/1000] loss: 0.6081939166592013
I0419 00:32:23.914136 30816 trainer.py:139] Epoch[156/1000] loss: 0.6093218499614347
I0419 00:32:32.185843 30816 trainer.py:139] Epoch[157/1000] loss: 0.6099473785969519
I0419 00:32:40.518729 30816 trainer.py:139] Epoch[158/1000] loss: 0.6075977875340369
I0419 00:32:49.267624 30816 trainer.py:139] Epoch[159/1000] loss: 0.6064502125786196
I0419 00:32:59.239472 30816 trainer.py:139] Epoch[160/1000] loss: 0.6106265533354974
I0419 00:33:07.322927 30816 trainer.py:139] Epoch[161/1000] loss: 0.6113652558095993
I0419 00:33:17.484283 30816 trainer.py:139] Epoch[162/1000] loss: 0.6075339634572307
I0419 00:33:25.986603 30816 trainer.py:139] Epoch[163/1000] loss: 0.6086178470042444
I0419 00:33:34.346976 30816 trainer.py:139] Epoch[164/1000] loss: 0.6071780708528334
I0419 00:33:42.594239 30816 trainer.py:139] Epoch[165/1000] loss: 0.6115340407817594
I0419 00:33:53.107053 30816 trainer.py:139] Epoch[166/1000] loss: 0.6088291339335903
I0419 00:34:01.790342 30816 trainer.py:139] Epoch[167/1000] loss: 0.6054861189857605
I0419 00:34:13.333327 30816 trainer.py:139] Epoch[168/1000] loss: 0.6095680623285232
I0419 00:34:22.396100 30816 trainer.py:139] Epoch[169/1000] loss: 0.6041748043029539
I0419 00:34:33.903030 30816 trainer.py:139] Epoch[170/1000] loss: 0.6054831608649223
I0419 00:34:42.948113 30816 trainer.py:139] Epoch[171/1000] loss: 0.6078656248507961
I0419 00:34:53.129624 30816 trainer.py:139] Epoch[172/1000] loss: 0.6054234283585702
I0419 00:35:03.204789 30816 trainer.py:139] Epoch[173/1000] loss: 0.6070234227565027
I0419 00:35:12.044321 30816 trainer.py:139] Epoch[174/1000] loss: 0.6063274914218534
I0419 00:35:23.065811 30816 trainer.py:139] Epoch[175/1000] loss: 0.6054309173937766
I0419 00:35:31.912951 30816 trainer.py:139] Epoch[176/1000] loss: 0.6023394590423953
I0419 00:35:43.188919 30816 trainer.py:139] Epoch[177/1000] loss: 0.605035706873863
I0419 00:35:51.782794 30816 trainer.py:139] Epoch[178/1000] loss: 0.6017725179272313
I0419 00:36:00.020816 30816 trainer.py:139] Epoch[179/1000] loss: 0.6058808949685865
I0419 00:36:08.366238 30816 trainer.py:139] Epoch[180/1000] loss: 0.6015443657675097
I0419 00:36:18.735913 30816 trainer.py:139] Epoch[181/1000] loss: 0.6021353563954753
I0419 00:36:26.971669 30816 trainer.py:139] Epoch[182/1000] loss: 0.6050988156949321
I0419 00:36:35.613294 30816 trainer.py:139] Epoch[183/1000] loss: 0.6028559736667141
I0419 00:36:43.932516 30816 trainer.py:139] Epoch[184/1000] loss: 0.6021744349310475
I0419 00:36:53.695724 30816 trainer.py:139] Epoch[185/1000] loss: 0.6016439622448336
I0419 00:37:02.668192 30816 trainer.py:139] Epoch[186/1000] loss: 0.6003317429173377
I0419 00:37:11.302429 30816 trainer.py:139] Epoch[187/1000] loss: 0.6038850613178746
I0419 00:37:19.796188 30816 trainer.py:139] Epoch[188/1000] loss: 0.6050909671091265
I0419 00:37:28.335951 30816 trainer.py:139] Epoch[189/1000] loss: 0.5993831090388759
I0419 00:37:38.511243 30816 trainer.py:139] Epoch[190/1000] loss: 0.599442167628196
I0419 00:37:46.739392 30816 trainer.py:139] Epoch[191/1000] loss: 0.5985378363440114
I0419 00:37:55.021449 30816 trainer.py:139] Epoch[192/1000] loss: 0.6003380417823792
I0419 00:38:04.109336 30816 trainer.py:139] Epoch[193/1000] loss: 0.6023845095788279
I0419 00:38:13.888340 30816 trainer.py:139] Epoch[194/1000] loss: 0.6003136288735175
I0419 00:38:22.201667 30816 trainer.py:139] Epoch[195/1000] loss: 0.6021217915319628
I0419 00:38:30.262224 30816 trainer.py:139] Epoch[196/1000] loss: 0.5983057329731603
I0419 00:38:39.059269 30816 trainer.py:139] Epoch[197/1000] loss: 0.6023670136928558
I0419 00:38:48.989168 30816 trainer.py:139] Epoch[198/1000] loss: 0.6039082542542489
I0419 00:38:57.321753 30816 trainer.py:139] Epoch[199/1000] loss: 0.5994403727592961
I0419 00:38:58.071798 30816 trainer.py:145] Test: [{'precision': 0.012190516156105752, 'recall': 0.15399123420525018, 'hit_ratio': 0.23206042803189258, 'ndcg': 0.07280031015527647}]
I0419 00:39:06.585189 30816 trainer.py:139] Epoch[200/1000] loss: 0.5969863591655609
I0419 00:39:17.079049 30816 trainer.py:139] Epoch[201/1000] loss: 0.6011368228543189
I0419 00:39:25.458445 30816 trainer.py:139] Epoch[202/1000] loss: 0.5997009546526016
I0419 00:39:33.914510 30816 trainer.py:139] Epoch[203/1000] loss: 0.5995582438284351
I0419 00:39:42.623745 30816 trainer.py:139] Epoch[204/1000] loss: 0.5978299292825884
I0419 00:39:51.515442 30816 trainer.py:139] Epoch[205/1000] loss: 0.5985897212259231
I0419 00:40:01.357022 30816 trainer.py:139] Epoch[206/1000] loss: 0.5970447611424231
I0419 00:40:09.906553 30816 trainer.py:139] Epoch[207/1000] loss: 0.599383234016357
I0419 00:40:18.435365 30816 trainer.py:139] Epoch[208/1000] loss: 0.5955247206072654
I0419 00:40:26.777200 30816 trainer.py:139] Epoch[209/1000] loss: 0.5998679216830961
I0419 00:40:37.164716 30816 trainer.py:139] Epoch[210/1000] loss: 0.598253728881959
I0419 00:40:45.439306 30816 trainer.py:139] Epoch[211/1000] loss: 0.5974524463376691
I0419 00:40:53.595340 30816 trainer.py:139] Epoch[212/1000] loss: 0.5979299814470352
I0419 00:41:02.105430 30816 trainer.py:139] Epoch[213/1000] loss: 0.5971332942285845
I0419 00:41:12.611657 30816 trainer.py:139] Epoch[214/1000] loss: 0.6020572829631067
I0419 00:41:20.690454 30816 trainer.py:139] Epoch[215/1000] loss: 0.5980327667728547
I0419 00:41:29.188005 30816 trainer.py:139] Epoch[216/1000] loss: 0.5986768834052547
I0419 00:41:38.443310 30816 trainer.py:139] Epoch[217/1000] loss: 0.5964950236581987
I0419 00:41:47.902191 30816 trainer.py:139] Epoch[218/1000] loss: 0.5994557469121872
I0419 00:41:56.253253 30816 trainer.py:139] Epoch[219/1000] loss: 0.5986311964450344
I0419 00:42:04.616437 30816 trainer.py:139] Epoch[220/1000] loss: 0.5924932437558328
I0419 00:42:15.370060 30816 trainer.py:139] Epoch[221/1000] loss: 0.5963689309935416
I0419 00:42:23.736366 30816 trainer.py:139] Epoch[222/1000] loss: 0.596807453901537
I0419 00:42:32.133220 30816 trainer.py:139] Epoch[223/1000] loss: 0.5995035594509494
I0419 00:42:40.456770 30816 trainer.py:139] Epoch[224/1000] loss: 0.5939955057636384
I0419 00:42:50.792260 30816 trainer.py:139] Epoch[225/1000] loss: 0.5954113794911292
I0419 00:42:58.974428 30816 trainer.py:139] Epoch[226/1000] loss: 0.5925954993694059
I0419 00:43:07.388267 30816 trainer.py:139] Epoch[227/1000] loss: 0.5956336702069929
I0419 00:43:15.825992 30816 trainer.py:139] Epoch[228/1000] loss: 0.5974933053216627
I0419 00:43:26.225534 30816 trainer.py:139] Epoch[229/1000] loss: 0.593017287792698
I0419 00:43:34.800981 30816 trainer.py:139] Epoch[230/1000] loss: 0.5966599237534308
I0419 00:43:43.106806 30816 trainer.py:139] Epoch[231/1000] loss: 0.5936597143450091
I0419 00:43:51.455901 30816 trainer.py:139] Epoch[232/1000] loss: 0.5938787085394706
I0419 00:44:00.782483 30816 trainer.py:139] Epoch[233/1000] loss: 0.5960380367694362
I0419 00:44:10.689113 30816 trainer.py:139] Epoch[234/1000] loss: 0.5940018632719594
I0419 00:44:19.244918 30816 trainer.py:139] Epoch[235/1000] loss: 0.5940904309672694
I0419 00:44:27.476452 30816 trainer.py:139] Epoch[236/1000] loss: 0.5974676320629735
I0419 00:44:36.308927 30816 trainer.py:139] Epoch[237/1000] loss: 0.5905014997528445
I0419 00:44:46.314094 30816 trainer.py:139] Epoch[238/1000] loss: 0.5928612755190942
I0419 00:44:54.554731 30816 trainer.py:139] Epoch[239/1000] loss: 0.5923185925329885
I0419 00:45:03.029448 30816 trainer.py:139] Epoch[240/1000] loss: 0.5950949124751552
I0419 00:45:11.305313 30816 trainer.py:139] Epoch[241/1000] loss: 0.597502822837522
I0419 00:45:21.868812 30816 trainer.py:139] Epoch[242/1000] loss: 0.5937777738417348
I0419 00:45:30.320884 30816 trainer.py:139] Epoch[243/1000] loss: 0.5921425963601759
I0419 00:45:38.675644 30816 trainer.py:139] Epoch[244/1000] loss: 0.5956406506799883
I0419 00:45:47.232165 30816 trainer.py:139] Epoch[245/1000] loss: 0.5954189473582853
I0419 00:45:57.575311 30816 trainer.py:139] Epoch[246/1000] loss: 0.5914222453871081
I0419 00:46:05.946081 30816 trainer.py:139] Epoch[247/1000] loss: 0.5946359490194628
I0419 00:46:14.207221 30816 trainer.py:139] Epoch[248/1000] loss: 0.594400498174852
I0419 00:46:22.683270 30816 trainer.py:139] Epoch[249/1000] loss: 0.5920708169860225
I0419 00:46:23.423793 30816 trainer.py:145] Test: [{'precision': 0.012316407889215283, 'recall': 0.15463651259916475, 'hit_ratio': 0.23373898447335292, 'ndcg': 0.07379691553907944}]
I0419 00:46:32.137803 30816 trainer.py:139] Epoch[250/1000] loss: 0.5937748589823323
I0419 00:46:42.091698 30816 trainer.py:139] Epoch[251/1000] loss: 0.5935497639640686
I0419 00:46:50.483612 30816 trainer.py:139] Epoch[252/1000] loss: 0.5911110879913453
I0419 00:46:58.715765 30816 trainer.py:139] Epoch[253/1000] loss: 0.5895035766786144
I0419 00:47:07.221646 30816 trainer.py:139] Epoch[254/1000] loss: 0.593552783612282
I0419 00:47:17.644057 30816 trainer.py:139] Epoch[255/1000] loss: 0.5930831018955477
I0419 00:47:25.777940 30816 trainer.py:139] Epoch[256/1000] loss: 0.5891710663995435
I0419 00:47:33.906589 30816 trainer.py:139] Epoch[257/1000] loss: 0.5907971176408953
I0419 00:47:43.173819 30816 trainer.py:139] Epoch[258/1000] loss: 0.5918828777728542
I0419 00:47:52.538830 30816 trainer.py:139] Epoch[259/1000] loss: 0.5910189161377568
I0419 00:48:00.750977 30816 trainer.py:139] Epoch[260/1000] loss: 0.5903616163038439
I0419 00:48:08.953822 30816 trainer.py:139] Epoch[261/1000] loss: 0.5906461640711753
I0419 00:48:18.173259 30816 trainer.py:139] Epoch[262/1000] loss: 0.5910617190022622
I0419 00:48:27.715574 30816 trainer.py:139] Epoch[263/1000] loss: 0.5924617004009985
I0419 00:48:36.198611 30816 trainer.py:139] Epoch[264/1000] loss: 0.5928752537696592
I0419 00:48:44.788395 30816 trainer.py:139] Epoch[265/1000] loss: 0.5926063531829465
I0419 00:48:53.445311 30816 trainer.py:139] Epoch[266/1000] loss: 0.5932589769363403
I0419 00:49:03.448856 30816 trainer.py:139] Epoch[267/1000] loss: 0.594655611822682
I0419 00:49:11.635071 30816 trainer.py:139] Epoch[268/1000] loss: 0.5943339053661593
I0419 00:49:19.741259 30816 trainer.py:139] Epoch[269/1000] loss: 0.5927494860464527
I0419 00:49:29.947979 30816 trainer.py:139] Epoch[270/1000] loss: 0.589676458028055
I0419 00:49:38.206943 30816 trainer.py:139] Epoch[271/1000] loss: 0.5910646655867177
I0419 00:49:46.633500 30816 trainer.py:139] Epoch[272/1000] loss: 0.5924881177563821
I0419 00:49:55.059092 30816 trainer.py:139] Epoch[273/1000] loss: 0.5913665275419911
I0419 00:50:04.034230 30816 trainer.py:139] Epoch[274/1000] loss: 0.5907726951183812
I0419 00:50:14.135018 30816 trainer.py:139] Epoch[275/1000] loss: 0.5891333289684788
I0419 00:50:22.372238 30816 trainer.py:139] Epoch[276/1000] loss: 0.591519397112631
I0419 00:50:30.616489 30816 trainer.py:139] Epoch[277/1000] loss: 0.5901477875248078
I0419 00:50:39.747857 30816 trainer.py:139] Epoch[278/1000] loss: 0.5899295441565975
I0419 00:50:49.543104 30816 trainer.py:139] Epoch[279/1000] loss: 0.5895163291885007
I0419 00:50:57.782411 30816 trainer.py:139] Epoch[280/1000] loss: 0.5903790477783449
I0419 00:51:06.128146 30816 trainer.py:139] Epoch[281/1000] loss: 0.588108935663777
I0419 00:51:16.078755 30816 trainer.py:139] Epoch[282/1000] loss: 0.5922137143150452
I0419 00:51:24.939087 30816 trainer.py:139] Epoch[283/1000] loss: 0.5901232957839966
I0419 00:51:33.269714 30816 trainer.py:139] Epoch[284/1000] loss: 0.5900410961720252
I0419 00:51:41.719228 30816 trainer.py:139] Epoch[285/1000] loss: 0.5907267245554155
I0419 00:51:50.110367 30816 trainer.py:139] Epoch[286/1000] loss: 0.5929693858469686
I0419 00:52:00.582565 30816 trainer.py:139] Epoch[287/1000] loss: 0.589050006481909
I0419 00:52:08.860377 30816 trainer.py:139] Epoch[288/1000] loss: 0.5891493299315053
I0419 00:52:17.081807 30816 trainer.py:139] Epoch[289/1000] loss: 0.5876876106185298
I0419 00:52:25.485893 30816 trainer.py:139] Epoch[290/1000] loss: 0.5888633843391172
I0419 00:52:35.799625 30816 trainer.py:139] Epoch[291/1000] loss: 0.5902369887598099
I0419 00:52:44.113663 30816 trainer.py:139] Epoch[292/1000] loss: 0.5884098506742909
I0419 00:52:52.257122 30816 trainer.py:139] Epoch[293/1000] loss: 0.5900196413840016
I0419 00:53:02.214753 30816 trainer.py:139] Epoch[294/1000] loss: 0.5867650239698349
I0419 00:53:10.606186 30816 trainer.py:139] Epoch[295/1000] loss: 0.5906498730182648
I0419 00:53:18.992838 30816 trainer.py:139] Epoch[296/1000] loss: 0.5899751878553822
I0419 00:53:27.170960 30816 trainer.py:139] Epoch[297/1000] loss: 0.5888079001057532
I0419 00:53:37.392493 30816 trainer.py:139] Epoch[298/1000] loss: 0.5914052830588433
I0419 00:53:45.928688 30816 trainer.py:139] Epoch[299/1000] loss: 0.5898747482607442
I0419 00:53:46.643856 30816 trainer.py:145] Test: [{'precision': 0.012253462022660517, 'recall': 0.1554613032791799, 'hit_ratio': 0.23248006714225766, 'ndcg': 0.0739330035850236}]
I0419 00:53:55.079384 30816 trainer.py:139] Epoch[300/1000] loss: 0.5880425562781673
I0419 00:54:03.497416 30816 trainer.py:139] Epoch[301/1000] loss: 0.5909339670212038
I0419 00:54:13.191132 30816 trainer.py:139] Epoch[302/1000] loss: 0.5886361473991025
I0419 00:54:22.150642 30816 trainer.py:139] Epoch[303/1000] loss: 0.5881135444487294
I0419 00:54:30.292839 30816 trainer.py:139] Epoch[304/1000] loss: 0.5899129923312895
I0419 00:54:38.559324 30816 trainer.py:139] Epoch[305/1000] loss: 0.5876538138235768
I0419 00:54:47.028592 30816 trainer.py:139] Epoch[306/1000] loss: 0.5876273195589742
I0419 00:54:57.062156 30816 trainer.py:139] Epoch[307/1000] loss: 0.5907884951560728
I0419 00:55:05.552836 30816 trainer.py:139] Epoch[308/1000] loss: 0.5876030200912107
I0419 00:55:13.866541 30816 trainer.py:139] Epoch[309/1000] loss: 0.5871507294716374
I0419 00:55:23.024966 30816 trainer.py:139] Epoch[310/1000] loss: 0.5899405325612714
I0419 00:55:32.660612 30816 trainer.py:139] Epoch[311/1000] loss: 0.5891277434364441
I0419 00:55:41.174891 30816 trainer.py:139] Epoch[312/1000] loss: 0.5894342603222016
I0419 00:55:49.452565 30816 trainer.py:139] Epoch[313/1000] loss: 0.5893687798130897
I0419 00:55:57.665403 30816 trainer.py:139] Epoch[314/1000] loss: 0.5864131892881086
I0419 00:56:08.129899 30816 trainer.py:139] Epoch[315/1000] loss: 0.5875023401552631
I0419 00:56:16.476682 30816 trainer.py:139] Epoch[316/1000] loss: 0.5892299942431911
I0419 00:56:24.119600 30816 trainer.py:139] Epoch[317/1000] loss: 0.5863624609285786
I0419 00:56:31.748704 30816 trainer.py:139] Epoch[318/1000] loss: 0.5897911450555248
I0419 00:56:39.313408 30816 trainer.py:139] Epoch[319/1000] loss: 0.584157096762811
I0419 00:56:46.941119 30816 trainer.py:139] Epoch[320/1000] loss: 0.5873676826876979
I0419 00:56:54.451242 30816 trainer.py:139] Epoch[321/1000] loss: 0.5876010262197063
I0419 00:57:01.981506 30816 trainer.py:139] Epoch[322/1000] loss: 0.585697760505061
I0419 00:57:09.628427 30816 trainer.py:139] Epoch[323/1000] loss: 0.5892677239833339
I0419 00:57:17.141194 30816 trainer.py:139] Epoch[324/1000] loss: 0.5845650386425757
I0419 00:57:24.828441 30816 trainer.py:139] Epoch[325/1000] loss: 0.5852449199845714
I0419 00:57:31.942631 30816 trainer.py:139] Epoch[326/1000] loss: 0.5853796533999904
I0419 00:57:38.926347 30816 trainer.py:139] Epoch[327/1000] loss: 0.5890498161315918
I0419 00:57:45.864730 30816 trainer.py:139] Epoch[328/1000] loss: 0.5893434218821987
I0419 00:57:52.815914 30816 trainer.py:139] Epoch[329/1000] loss: 0.5842670432982906
I0419 00:57:59.642076 30816 trainer.py:139] Epoch[330/1000] loss: 0.5855691182997919
I0419 00:58:06.524536 30816 trainer.py:139] Epoch[331/1000] loss: 0.5862535219038686
I0419 00:58:13.364163 30816 trainer.py:139] Epoch[332/1000] loss: 0.5853965205530967
I0419 00:58:20.250088 30816 trainer.py:139] Epoch[333/1000] loss: 0.5860300064086914
I0419 00:58:27.193794 30816 trainer.py:139] Epoch[334/1000] loss: 0.5839224265467736
I0419 00:58:34.399860 30816 trainer.py:139] Epoch[335/1000] loss: 0.5865957506241337
I0419 00:58:41.318522 30816 trainer.py:139] Epoch[336/1000] loss: 0.5835723348202244
I0419 00:58:48.336160 30816 trainer.py:139] Epoch[337/1000] loss: 0.5862604389267583
I0419 00:58:55.111901 30816 trainer.py:139] Epoch[338/1000] loss: 0.585168614502876
I0419 00:59:02.013645 30816 trainer.py:139] Epoch[339/1000] loss: 0.587961140178865
I0419 00:59:08.901875 30816 trainer.py:139] Epoch[340/1000] loss: 0.5881449724397352
I0419 00:59:15.935394 30816 trainer.py:139] Epoch[341/1000] loss: 0.5845749608932003
I0419 00:59:22.956837 30816 trainer.py:139] Epoch[342/1000] loss: 0.5869248701680091
I0419 00:59:29.900776 30816 trainer.py:139] Epoch[343/1000] loss: 0.5869092912443222
I0419 00:59:37.013033 30816 trainer.py:139] Epoch[344/1000] loss: 0.5868566151588194
I0419 00:59:44.008964 30816 trainer.py:139] Epoch[345/1000] loss: 0.5865495031879794
I0419 00:59:50.953316 30816 trainer.py:139] Epoch[346/1000] loss: 0.5879183536575686
I0419 00:59:57.916656 30816 trainer.py:139] Epoch[347/1000] loss: 0.5854367344610153
I0419 01:00:04.991917 30816 trainer.py:139] Epoch[348/1000] loss: 0.5850625691875335
I0419 01:00:11.952566 30816 trainer.py:139] Epoch[349/1000] loss: 0.587484662571261
I0419 01:00:12.488342 30816 trainer.py:145] Test: [{'precision': 0.01227444397817877, 'recall': 0.15456474098941575, 'hit_ratio': 0.2312211498111624, 'ndcg': 0.07369578658721986}]
I0419 01:00:19.379842 30816 trainer.py:139] Epoch[350/1000] loss: 0.5864480320484408
I0419 01:00:26.258768 30816 trainer.py:139] Epoch[351/1000] loss: 0.5837880796001803
I0419 01:00:33.281475 30816 trainer.py:139] Epoch[352/1000] loss: 0.5840697788423107
I0419 01:00:40.050721 30816 trainer.py:139] Epoch[353/1000] loss: 0.5878594469639563
I0419 01:00:46.951293 30816 trainer.py:139] Epoch[354/1000] loss: 0.5859973920929816
I0419 01:00:53.886235 30816 trainer.py:139] Epoch[355/1000] loss: 0.5833256446546123
I0419 01:01:00.901842 30816 trainer.py:139] Epoch[356/1000] loss: 0.5876221426071659
I0419 01:01:07.722002 30816 trainer.py:139] Epoch[357/1000] loss: 0.585302492303233
I0419 01:01:14.675126 30816 trainer.py:139] Epoch[358/1000] loss: 0.583613193804218
I0419 01:01:21.488345 30816 trainer.py:139] Epoch[359/1000] loss: 0.5837324223210735
I0419 01:01:28.452410 30816 trainer.py:139] Epoch[360/1000] loss: 0.5854050670900652
I0419 01:01:35.585415 30816 trainer.py:139] Epoch[361/1000] loss: 0.5834395520148739
I0419 01:01:42.460732 30816 trainer.py:139] Epoch[362/1000] loss: 0.5830602299782538
I0419 01:01:49.291608 30816 trainer.py:139] Epoch[363/1000] loss: 0.5824232149508691
I0419 01:01:56.078647 30816 trainer.py:139] Epoch[364/1000] loss: 0.5835350771104136
I0419 01:02:02.933724 30816 trainer.py:139] Epoch[365/1000] loss: 0.5883108290933794
I0419 01:02:09.862343 30816 trainer.py:139] Epoch[366/1000] loss: 0.585996889298962
I0419 01:02:16.820240 30816 trainer.py:139] Epoch[367/1000] loss: 0.5857735785745806
I0419 01:02:23.676891 30816 trainer.py:139] Epoch[368/1000] loss: 0.5841831853312831
I0419 01:02:30.876771 30816 trainer.py:139] Epoch[369/1000] loss: 0.5829550018233638
I0419 01:02:37.780425 30816 trainer.py:139] Epoch[370/1000] loss: 0.5823913043545138
I0419 01:02:44.724376 30816 trainer.py:139] Epoch[371/1000] loss: 0.5840401043814998
I0419 01:02:51.442278 30816 trainer.py:139] Epoch[372/1000] loss: 0.5842369256481048
I0419 01:02:58.313226 30816 trainer.py:139] Epoch[373/1000] loss: 0.5885912006901156
I0419 01:03:05.222344 30816 trainer.py:139] Epoch[374/1000] loss: 0.5862644564720892
I0419 01:03:12.156347 30816 trainer.py:139] Epoch[375/1000] loss: 0.5856853627389477
I0419 01:03:19.066956 30816 trainer.py:139] Epoch[376/1000] loss: 0.584832348169819
I0419 01:03:26.095466 30816 trainer.py:139] Epoch[377/1000] loss: 0.585046919122819
I0419 01:03:32.878550 30816 trainer.py:139] Epoch[378/1000] loss: 0.5831002458449333
I0419 01:03:39.898987 30816 trainer.py:139] Epoch[379/1000] loss: 0.5811630727783326
I0419 01:03:46.633173 30816 trainer.py:139] Epoch[380/1000] loss: 0.5829758422989999
I0419 01:03:53.654590 30816 trainer.py:139] Epoch[381/1000] loss: 0.5819542225330107
I0419 01:04:00.585495 30816 trainer.py:139] Epoch[382/1000] loss: 0.5880871549729378
I0419 01:04:07.684091 30816 trainer.py:139] Epoch[383/1000] loss: 0.582003911656718
I0419 01:04:14.599908 30816 trainer.py:139] Epoch[384/1000] loss: 0.5836445381564479
I0419 01:04:21.625437 30816 trainer.py:139] Epoch[385/1000] loss: 0.586779119506959
I0419 01:04:28.641411 30816 trainer.py:139] Epoch[386/1000] loss: 0.5862295723730518
I0419 01:04:35.477577 30816 trainer.py:139] Epoch[387/1000] loss: 0.586315159836123
I0419 01:04:42.509279 30816 trainer.py:139] Epoch[388/1000] loss: 0.5840281276933609
I0419 01:04:49.429945 30816 trainer.py:139] Epoch[389/1000] loss: 0.5871131545112979
I0419 01:04:56.241827 30816 trainer.py:139] Epoch[390/1000] loss: 0.5840105664345526
I0419 01:05:03.181995 30816 trainer.py:139] Epoch[391/1000] loss: 0.5849673565356962
I0419 01:05:10.184181 30816 trainer.py:139] Epoch[392/1000] loss: 0.5875379116304459
I0419 01:05:17.135551 30816 trainer.py:139] Epoch[393/1000] loss: 0.5857038219128886
I0419 01:05:23.923341 30816 trainer.py:139] Epoch[394/1000] loss: 0.5803955802994389
I0419 01:05:30.861089 30816 trainer.py:139] Epoch[395/1000] loss: 0.5812722646421001
I0419 01:05:37.723158 30816 trainer.py:139] Epoch[396/1000] loss: 0.5838375062711777
I0419 01:05:44.489451 30816 trainer.py:139] Epoch[397/1000] loss: 0.5811575189713509
I0419 01:05:51.491306 30816 trainer.py:139] Epoch[398/1000] loss: 0.5839517501092726
I0419 01:05:58.293464 30816 trainer.py:139] Epoch[399/1000] loss: 0.5849878518812118
I0419 01:05:58.835217 30816 trainer.py:145] Test: [{'precision': 0.012337389844733534, 'recall': 0.15430130088124214, 'hit_ratio': 0.23289970625262274, 'ndcg': 0.07346460359573147}]
I0419 01:06:05.706112 30816 trainer.py:139] Epoch[400/1000] loss: 0.5846525536429498
I0419 01:06:12.685431 30816 trainer.py:139] Epoch[401/1000] loss: 0.5842970244346126
I0419 01:06:19.763770 30816 trainer.py:139] Epoch[402/1000] loss: 0.5856821008266941
I0419 01:06:26.610916 30816 trainer.py:139] Epoch[403/1000] loss: 0.5861236626102079
I0419 01:06:33.453910 30816 trainer.py:139] Epoch[404/1000] loss: 0.5843574029784049
I0419 01:06:40.453497 30816 trainer.py:139] Epoch[405/1000] loss: 0.5813281228465419
I0419 01:06:47.350640 30816 trainer.py:139] Epoch[406/1000] loss: 0.5819844170924156
I0419 01:06:54.368258 30816 trainer.py:139] Epoch[407/1000] loss: 0.5837746675937406
I0419 01:07:01.264804 30816 trainer.py:139] Epoch[408/1000] loss: 0.5869570461011702
I0419 01:07:08.238349 30816 trainer.py:139] Epoch[409/1000] loss: 0.5836349821859791
I0419 01:07:15.182136 30816 trainer.py:139] Epoch[410/1000] loss: 0.5847819437903743
I0419 01:07:21.997149 30816 trainer.py:139] Epoch[411/1000] loss: 0.5825864672660828
I0419 01:07:28.922909 30816 trainer.py:139] Epoch[412/1000] loss: 0.5853063541073953
I0419 01:07:35.839732 30816 trainer.py:139] Epoch[413/1000] loss: 0.5833591934173338
I0419 01:07:42.855540 30816 trainer.py:139] Epoch[414/1000] loss: 0.5834798543683944
I0419 01:07:49.731935 30816 trainer.py:139] Epoch[415/1000] loss: 0.5812561906153156
I0419 01:07:56.604878 30816 trainer.py:139] Epoch[416/1000] loss: 0.5844166288452763
I0419 01:08:03.737933 30816 trainer.py:139] Epoch[417/1000] loss: 0.5840429471385095
I0419 01:08:10.544089 30816 trainer.py:139] Epoch[418/1000] loss: 0.5831759100960147
I0419 01:08:17.407458 30816 trainer.py:139] Epoch[419/1000] loss: 0.5821407273892434
I0419 01:08:24.282371 30816 trainer.py:139] Epoch[420/1000] loss: 0.5821600085304629
I0419 01:08:31.389638 30816 trainer.py:139] Epoch[421/1000] loss: 0.5814228000179413
I0419 01:08:38.358850 30816 trainer.py:139] Epoch[422/1000] loss: 0.5840305176473433
I0419 01:08:45.405750 30816 trainer.py:139] Epoch[423/1000] loss: 0.5799061011883521
I0419 01:08:52.152097 30816 trainer.py:139] Epoch[424/1000] loss: 0.5823804274682076
I0419 01:08:59.028629 30816 trainer.py:139] Epoch[425/1000] loss: 0.5789029684758955
I0419 01:09:05.893097 30816 trainer.py:139] Epoch[426/1000] loss: 0.5850360008978075
I0419 01:09:12.681286 30816 trainer.py:139] Epoch[427/1000] loss: 0.5846079482186225
I0419 01:09:19.609491 30816 trainer.py:139] Epoch[428/1000] loss: 0.579704483670573
I0419 01:09:26.510346 30816 trainer.py:139] Epoch[429/1000] loss: 0.5818068288987682
I0419 01:09:33.248161 30816 trainer.py:139] Epoch[430/1000] loss: 0.5843679385800515
I0419 01:09:40.255187 30816 trainer.py:139] Epoch[431/1000] loss: 0.5829723044749229
I0419 01:09:47.016245 30816 trainer.py:139] Epoch[432/1000] loss: 0.5825639934309067
I0419 01:09:53.989575 30816 trainer.py:139] Epoch[433/1000] loss: 0.5810854454194346
I0419 01:10:00.832117 30816 trainer.py:139] Epoch[434/1000] loss: 0.5814492587120302
I0419 01:10:07.739118 30816 trainer.py:139] Epoch[435/1000] loss: 0.5834190066783659
I0419 01:10:14.659472 30816 trainer.py:139] Epoch[436/1000] loss: 0.5819338608172632
I0419 01:10:21.606803 30816 trainer.py:139] Epoch[437/1000] loss: 0.5814604816898223
I0419 01:10:28.572436 30816 trainer.py:139] Epoch[438/1000] loss: 0.5846991817797383
I0419 01:10:35.655633 30816 trainer.py:139] Epoch[439/1000] loss: 0.5831847988790081
I0419 01:10:42.549225 30816 trainer.py:139] Epoch[440/1000] loss: 0.5827336628590861
I0419 01:10:49.447607 30816 trainer.py:139] Epoch[441/1000] loss: 0.5819824405254856
I0419 01:10:56.373936 30816 trainer.py:139] Epoch[442/1000] loss: 0.5816009035033565
I0419 01:11:03.390900 30816 trainer.py:139] Epoch[443/1000] loss: 0.5817773322905263
I0419 01:11:10.308521 30816 trainer.py:139] Epoch[444/1000] loss: 0.5839018917852833
I0419 01:11:17.156291 30816 trainer.py:139] Epoch[445/1000] loss: 0.5830078519159748
I0419 01:11:24.174360 30816 trainer.py:139] Epoch[446/1000] loss: 0.5815536475950672
I0419 01:11:31.206762 30816 trainer.py:139] Epoch[447/1000] loss: 0.5778703997212071
I0419 01:11:38.179811 30816 trainer.py:139] Epoch[448/1000] loss: 0.5809905817431789
I0419 01:11:45.010198 30816 trainer.py:139] Epoch[449/1000] loss: 0.5803981779083129
I0419 01:11:45.542964 30816 trainer.py:145] Test: [{'precision': 0.012358371800251788, 'recall': 0.15432627939971627, 'hit_ratio': 0.23373898447335292, 'ndcg': 0.07265150546022436}]
I0419 01:11:52.425112 30816 trainer.py:139] Epoch[450/1000] loss: 0.5816555465421369
I0419 01:11:59.161728 30816 trainer.py:139] Epoch[451/1000] loss: 0.5819187952626136
I0419 01:12:06.140907 30816 trainer.py:139] Epoch[452/1000] loss: 0.5822033286094666
I0419 01:12:12.937609 30816 trainer.py:139] Epoch[453/1000] loss: 0.5805624934934801
I0419 01:12:19.769914 30816 trainer.py:139] Epoch[454/1000] loss: 0.5822076038006814
I0419 01:12:26.420262 30816 trainer.py:139] Epoch[455/1000] loss: 0.5811168907150146
I0419 01:12:33.318717 30816 trainer.py:139] Epoch[456/1000] loss: 0.5828703574595913
I0419 01:12:40.371717 30816 trainer.py:139] Epoch[457/1000] loss: 0.5808392311296156
I0419 01:12:47.262951 30816 trainer.py:139] Epoch[458/1000] loss: 0.5814047301969221
I0419 01:12:54.165333 30816 trainer.py:139] Epoch[459/1000] loss: 0.5792433436839811
I0419 01:13:01.016993 30816 trainer.py:139] Epoch[460/1000] loss: 0.5808227225657432
I0419 01:13:07.839244 30816 trainer.py:139] Epoch[461/1000] loss: 0.5808332812401557
I0419 01:13:14.749133 30816 trainer.py:139] Epoch[462/1000] loss: 0.5790954462943538
I0419 01:13:21.758710 30816 trainer.py:139] Epoch[463/1000] loss: 0.5816573750588202
I0419 01:13:28.553779 30816 trainer.py:139] Epoch[464/1000] loss: 0.5812243463531617
I0419 01:13:35.305588 30816 trainer.py:139] Epoch[465/1000] loss: 0.5788899035223068
I0419 01:13:42.069575 30816 trainer.py:139] Epoch[466/1000] loss: 0.5817182669716496
I0419 01:13:49.051254 30816 trainer.py:139] Epoch[467/1000] loss: 0.5811274397757745
I0419 01:13:55.931286 30816 trainer.py:139] Epoch[468/1000] loss: 0.5802223980426788
I0419 01:14:02.809211 30816 trainer.py:139] Epoch[469/1000] loss: 0.5840639058620699
I0419 01:14:09.774621 30816 trainer.py:139] Epoch[470/1000] loss: 0.5833276116078899
I0419 01:14:16.611911 30816 trainer.py:139] Epoch[471/1000] loss: 0.580126348041719
I0419 01:14:23.608441 30816 trainer.py:139] Epoch[472/1000] loss: 0.5800967053059609
I0419 01:14:30.632155 30816 trainer.py:139] Epoch[473/1000] loss: 0.5789840096427549
I0419 01:14:37.411929 30816 trainer.py:139] Epoch[474/1000] loss: 0.5795283192588437
I0419 01:14:44.201003 30816 trainer.py:139] Epoch[475/1000] loss: 0.5814733082248319
I0419 01:14:50.980274 30816 trainer.py:139] Epoch[476/1000] loss: 0.5786369298734972
I0419 01:14:57.918190 30816 trainer.py:139] Epoch[477/1000] loss: 0.5787704452391593
I0419 01:15:04.892858 30816 trainer.py:139] Epoch[478/1000] loss: 0.5783667881642619
I0419 01:15:11.754051 30816 trainer.py:139] Epoch[479/1000] loss: 0.581210615173463
I0419 01:15:18.734078 30816 trainer.py:139] Epoch[480/1000] loss: 0.5808505069824957
I0419 01:15:25.590975 30816 trainer.py:139] Epoch[481/1000] loss: 0.5813249618776383
I0419 01:15:32.503184 30816 trainer.py:139] Epoch[482/1000] loss: 0.5804996461637558
I0419 01:15:39.464856 30816 trainer.py:139] Epoch[483/1000] loss: 0.5810809750710765
I0419 01:15:46.460972 30816 trainer.py:139] Epoch[484/1000] loss: 0.5842538995127524
I0419 01:15:53.585331 30816 trainer.py:139] Epoch[485/1000] loss: 0.5827736902621484
I0419 01:16:00.492229 30816 trainer.py:139] Epoch[486/1000] loss: 0.5811501914455045
I0419 01:16:07.415458 30816 trainer.py:139] Epoch[487/1000] loss: 0.5825307186572782
I0419 01:16:14.297698 30816 trainer.py:139] Epoch[488/1000] loss: 0.5789153037532684
I0419 01:16:21.256423 30816 trainer.py:139] Epoch[489/1000] loss: 0.5842799486652497
I0419 01:16:28.142365 30816 trainer.py:139] Epoch[490/1000] loss: 0.5798566302945537
I0419 01:16:35.082033 30816 trainer.py:139] Epoch[491/1000] loss: 0.5786605448492111
I0419 01:16:42.031661 30816 trainer.py:139] Epoch[492/1000] loss: 0.5813854721284681
I0419 01:16:49.198284 30816 trainer.py:139] Epoch[493/1000] loss: 0.5809569416507598
I0419 01:16:56.185820 30816 trainer.py:139] Epoch[494/1000] loss: 0.5827557992550635
I0419 01:17:03.224619 30816 trainer.py:139] Epoch[495/1000] loss: 0.5820129965582201
I0419 01:17:10.075211 30816 trainer.py:139] Epoch[496/1000] loss: 0.5780218349349114
I0419 01:17:16.895406 30816 trainer.py:139] Epoch[497/1000] loss: 0.584389530843304
I0419 01:17:23.972837 30816 trainer.py:139] Epoch[498/1000] loss: 0.5841947813187877
I0419 01:17:31.117436 30816 trainer.py:139] Epoch[499/1000] loss: 0.5808806582804649
I0419 01:17:31.648253 30816 trainer.py:145] Test: [{'precision': 0.012484263533361312, 'recall': 0.15660631856603321, 'hit_ratio': 0.23667645824590852, 'ndcg': 0.07329609752799317}]
I0419 01:17:38.671200 30816 trainer.py:139] Epoch[500/1000] loss: 0.5782607793807983
I0419 01:17:45.488947 30816 trainer.py:139] Epoch[501/1000] loss: 0.5813769294369605
I0419 01:17:52.338088 30816 trainer.py:139] Epoch[502/1000] loss: 0.5794154174866215
I0419 01:17:59.438605 30816 trainer.py:139] Epoch[503/1000] loss: 0.5787927489126882
I0419 01:18:06.279222 30816 trainer.py:139] Epoch[504/1000] loss: 0.5838329388249305
I0419 01:18:13.399838 30816 trainer.py:139] Epoch[505/1000] loss: 0.5795515506498276
I0419 01:18:20.505925 30816 trainer.py:139] Epoch[506/1000] loss: 0.5786566840064141
I0419 01:18:27.363464 30816 trainer.py:139] Epoch[507/1000] loss: 0.5800344626749715
I0419 01:18:34.276167 30816 trainer.py:139] Epoch[508/1000] loss: 0.5819318092638447
I0419 01:18:41.118207 30816 trainer.py:139] Epoch[509/1000] loss: 0.5823109649842785
I0419 01:18:47.962996 30816 trainer.py:139] Epoch[510/1000] loss: 0.5800140586591536
I0419 01:18:54.934557 30816 trainer.py:139] Epoch[511/1000] loss: 0.5795637859452155
I0419 01:19:01.886766 30816 trainer.py:139] Epoch[512/1000] loss: 0.5809501255712202
I0419 01:19:08.833414 30816 trainer.py:139] Epoch[513/1000] loss: 0.5783258493869535
I0419 01:19:15.667070 30816 trainer.py:139] Epoch[514/1000] loss: 0.5788956294136662
I0419 01:19:22.817286 30816 trainer.py:139] Epoch[515/1000] loss: 0.579336533623357
I0419 01:19:29.833659 30816 trainer.py:139] Epoch[516/1000] loss: 0.580399509399168
I0419 01:19:36.807580 30816 trainer.py:139] Epoch[517/1000] loss: 0.5822199410007846
I0419 01:19:43.611489 30816 trainer.py:139] Epoch[518/1000] loss: 0.5816491563473979
I0419 01:19:50.512368 30816 trainer.py:139] Epoch[519/1000] loss: 0.5803109916948503
I0419 01:19:57.301407 30816 trainer.py:139] Epoch[520/1000] loss: 0.5778193310383828
I0419 01:20:04.388974 30816 trainer.py:139] Epoch[521/1000] loss: 0.5820987695647825
I0419 01:20:11.547650 30816 trainer.py:139] Epoch[522/1000] loss: 0.5781081924515385
I0419 01:20:18.614222 30816 trainer.py:139] Epoch[523/1000] loss: 0.5793668666193562
I0419 01:20:25.484854 30816 trainer.py:139] Epoch[524/1000] loss: 0.5798465648005086
I0419 01:20:32.532658 30816 trainer.py:139] Epoch[525/1000] loss: 0.578740527552943
I0419 01:20:39.449937 30816 trainer.py:139] Epoch[526/1000] loss: 0.579862835907167
I0419 01:20:46.335793 30816 trainer.py:139] Epoch[527/1000] loss: 0.58087755210938
I0419 01:20:53.094973 30816 trainer.py:139] Epoch[528/1000] loss: 0.5799150063145545
I0419 01:21:00.012806 30816 trainer.py:139] Epoch[529/1000] loss: 0.5772630437727897
I0419 01:21:06.931393 30816 trainer.py:139] Epoch[530/1000] loss: 0.5781010985374451
I0419 01:21:13.986149 30816 trainer.py:139] Epoch[531/1000] loss: 0.5792954977481596
I0419 01:21:20.889147 30816 trainer.py:139] Epoch[532/1000] loss: 0.582813790728969
I0419 01:21:27.949483 30816 trainer.py:139] Epoch[533/1000] loss: 0.5802413004059945
I0419 01:21:34.886257 30816 trainer.py:139] Epoch[534/1000] loss: 0.5806114375591278
I0419 01:21:41.838647 30816 trainer.py:139] Epoch[535/1000] loss: 0.5802931151082439
I0419 01:21:48.724289 30816 trainer.py:139] Epoch[536/1000] loss: 0.580835412586889
I0419 01:21:55.806435 30816 trainer.py:139] Epoch[537/1000] loss: 0.5813467339161904
I0419 01:22:02.796994 30816 trainer.py:139] Epoch[538/1000] loss: 0.5784779863972818
I0419 01:22:09.760122 30816 trainer.py:139] Epoch[539/1000] loss: 0.5783822853719035
I0419 01:22:16.596007 30816 trainer.py:139] Epoch[540/1000] loss: 0.5796342280603224
I0419 01:22:23.570147 30816 trainer.py:139] Epoch[541/1000] loss: 0.5785173369992164
I0419 01:22:30.676310 30816 trainer.py:139] Epoch[542/1000] loss: 0.5784420717147088
I0419 01:22:37.699764 30816 trainer.py:139] Epoch[543/1000] loss: 0.5827420325048508
I0419 01:22:44.581068 30816 trainer.py:139] Epoch[544/1000] loss: 0.5808861024918095
I0419 01:22:51.436505 30816 trainer.py:139] Epoch[545/1000] loss: 0.5814633984719554
I0419 01:22:58.220417 30816 trainer.py:139] Epoch[546/1000] loss: 0.5795399287054616
I0419 01:23:04.979771 30816 trainer.py:139] Epoch[547/1000] loss: 0.5783456525494975
I0419 01:23:11.870660 30816 trainer.py:139] Epoch[548/1000] loss: 0.5788461402539284
I0419 01:23:19.024122 30816 trainer.py:139] Epoch[549/1000] loss: 0.5808123936576228
I0419 01:23:19.561879 30816 trainer.py:145] Test: [{'precision': 0.01242131766680655, 'recall': 0.1555427332494055, 'hit_ratio': 0.23583718002517834, 'ndcg': 0.07319912544030427}]
I0419 01:23:26.369507 30816 trainer.py:139] Epoch[550/1000] loss: 0.5788737198998851
I0419 01:23:33.294347 30816 trainer.py:139] Epoch[551/1000] loss: 0.5817389891993615
I0419 01:23:40.285936 30816 trainer.py:139] Epoch[552/1000] loss: 0.5798576291530363
I0419 01:23:47.457449 30816 trainer.py:139] Epoch[553/1000] loss: 0.5769149363040924
I0419 01:23:54.404176 30816 trainer.py:139] Epoch[554/1000] loss: 0.5816856834196276
I0419 01:24:01.359832 30816 trainer.py:139] Epoch[555/1000] loss: 0.5796841056116165
I0419 01:24:08.592256 30816 trainer.py:139] Epoch[556/1000] loss: 0.5814826411585654
I0419 01:24:15.645732 30816 trainer.py:139] Epoch[557/1000] loss: 0.5775191149403972
I0419 01:24:22.373179 30816 trainer.py:139] Epoch[558/1000] loss: 0.5776745523175886
I0419 01:24:29.283035 30816 trainer.py:139] Epoch[559/1000] loss: 0.5816228485876515
I0419 01:24:36.276272 30816 trainer.py:139] Epoch[560/1000] loss: 0.5800446569919586
I0419 01:24:43.017225 30816 trainer.py:139] Epoch[561/1000] loss: 0.5771219268921883
I0419 01:24:50.000809 30816 trainer.py:139] Epoch[562/1000] loss: 0.5780788813867876
I0419 01:24:56.920998 30816 trainer.py:139] Epoch[563/1000] loss: 0.5796401529542862
I0419 01:25:03.793525 30816 trainer.py:139] Epoch[564/1000] loss: 0.5793730895365438
I0419 01:25:10.839894 30816 trainer.py:139] Epoch[565/1000] loss: 0.5763509138937919
I0419 01:25:17.877308 30816 trainer.py:139] Epoch[566/1000] loss: 0.578368765692557
I0419 01:25:24.778178 30816 trainer.py:139] Epoch[567/1000] loss: 0.5794695740745913
I0419 01:25:31.553694 30816 trainer.py:139] Epoch[568/1000] loss: 0.5754465172367711
I0419 01:25:38.508493 30816 trainer.py:139] Epoch[569/1000] loss: 0.5820716917514801
I0419 01:25:45.515966 30816 trainer.py:139] Epoch[570/1000] loss: 0.5789690700269514
I0419 01:25:52.477570 30816 trainer.py:139] Epoch[571/1000] loss: 0.579839700652707
I0419 01:25:59.355459 30816 trainer.py:139] Epoch[572/1000] loss: 0.5793804064873727
I0419 01:26:06.345945 30816 trainer.py:139] Epoch[573/1000] loss: 0.5793603975926677
I0419 01:26:13.187042 30816 trainer.py:139] Epoch[574/1000] loss: 0.5787459304255824
I0419 01:26:20.027558 30816 trainer.py:139] Epoch[575/1000] loss: 0.578586911001513
I0419 01:26:26.790869 30816 trainer.py:139] Epoch[576/1000] loss: 0.5797463309380316
I0419 01:26:33.838471 30816 trainer.py:139] Epoch[577/1000] loss: 0.5761153121148387
I0419 01:26:40.794847 30816 trainer.py:139] Epoch[578/1000] loss: 0.5799245767055019
I0419 01:26:47.742535 30816 trainer.py:139] Epoch[579/1000] loss: 0.5792373697603902
I0419 01:26:54.510061 30816 trainer.py:139] Epoch[580/1000] loss: 0.5791083920386529
I0419 01:27:01.338375 30816 trainer.py:139] Epoch[581/1000] loss: 0.5789119168635337
I0419 01:27:08.277876 30816 trainer.py:139] Epoch[582/1000] loss: 0.5807911340267428
I0419 01:27:15.251152 30816 trainer.py:139] Epoch[583/1000] loss: 0.5802606430745894
I0419 01:27:22.213773 30816 trainer.py:139] Epoch[584/1000] loss: 0.579237756229216
I0419 01:27:29.144692 30816 trainer.py:139] Epoch[585/1000] loss: 0.580217944998895
I0419 01:27:36.054732 30816 trainer.py:139] Epoch[586/1000] loss: 0.5781688392162323
I0419 01:27:43.040892 30816 trainer.py:139] Epoch[587/1000] loss: 0.5795409525594404
I0419 01:27:49.909230 30816 trainer.py:139] Epoch[588/1000] loss: 0.5759826283301076
I0419 01:27:56.760619 30816 trainer.py:139] Epoch[589/1000] loss: 0.5792564970831717
I0419 01:28:03.595711 30816 trainer.py:139] Epoch[590/1000] loss: 0.5763177092998258
I0419 01:28:10.584340 30816 trainer.py:139] Epoch[591/1000] loss: 0.5754283483951322
I0419 01:28:17.468225 30816 trainer.py:139] Epoch[592/1000] loss: 0.5804330504709675
I0419 01:28:24.233712 30816 trainer.py:139] Epoch[593/1000] loss: 0.5779410475684751
I0419 01:28:31.138693 30816 trainer.py:139] Epoch[594/1000] loss: 0.575410093030622
I0419 01:28:38.051018 30816 trainer.py:139] Epoch[595/1000] loss: 0.5804317160960166
I0419 01:28:44.928941 30816 trainer.py:139] Epoch[596/1000] loss: 0.5821627215031655
I0419 01:28:51.787450 30816 trainer.py:139] Epoch[597/1000] loss: 0.5759177650174787
I0419 01:28:58.724826 30816 trainer.py:139] Epoch[598/1000] loss: 0.5783135506414598
I0419 01:29:05.707456 30816 trainer.py:139] Epoch[599/1000] loss: 0.5818798167090262
I0419 01:29:06.263595 30816 trainer.py:145] Test: [{'precision': 0.012379353755770041, 'recall': 0.154445177147653, 'hit_ratio': 0.23583718002517834, 'ndcg': 0.07298757008081232}]
I0419 01:29:12.985717 30816 trainer.py:139] Epoch[600/1000] loss: 0.5808645794468541
I0419 01:29:19.946658 30816 trainer.py:139] Epoch[601/1000] loss: 0.5783939102003651
I0419 01:29:26.887394 30816 trainer.py:139] Epoch[602/1000] loss: 0.5758197172995536
I0419 01:29:33.720900 30816 trainer.py:139] Epoch[603/1000] loss: 0.5780037843411968
I0419 01:29:40.642983 30816 trainer.py:139] Epoch[604/1000] loss: 0.5756033832027067
I0419 01:29:47.390953 30816 trainer.py:139] Epoch[605/1000] loss: 0.5770474758840376
I0419 01:29:54.460411 30816 trainer.py:139] Epoch[606/1000] loss: 0.5761894727906873
I0419 01:30:01.365336 30816 trainer.py:139] Epoch[607/1000] loss: 0.5811043458600198
I0419 01:30:08.424437 30816 trainer.py:139] Epoch[608/1000] loss: 0.5817668399503154
I0419 01:30:15.327291 30816 trainer.py:139] Epoch[609/1000] loss: 0.5748350004996022
I0419 01:30:22.286945 30816 trainer.py:139] Epoch[610/1000] loss: 0.5785072830415541
I0419 01:30:29.098128 30816 trainer.py:139] Epoch[611/1000] loss: 0.5811981885663925
I0419 01:30:36.120011 30816 trainer.py:139] Epoch[612/1000] loss: 0.579672186605392
I0419 01:30:42.927131 30816 trainer.py:139] Epoch[613/1000] loss: 0.5771146185936467
I0419 01:30:49.857695 30816 trainer.py:139] Epoch[614/1000] loss: 0.5793069014626164
I0419 01:30:56.714881 30816 trainer.py:139] Epoch[615/1000] loss: 0.5791741128890745
I0419 01:31:03.633239 30816 trainer.py:139] Epoch[616/1000] loss: 0.5805180390034953
I0419 01:31:10.620010 30816 trainer.py:139] Epoch[617/1000] loss: 0.5775781254614553
I0419 01:31:17.656484 30816 trainer.py:139] Epoch[618/1000] loss: 0.578275183516164
I0419 01:31:24.578171 30816 trainer.py:139] Epoch[619/1000] loss: 0.5789378208498801
I0419 01:31:31.551726 30816 trainer.py:139] Epoch[620/1000] loss: 0.5762041422628588
I0419 01:31:38.396298 30816 trainer.py:139] Epoch[621/1000] loss: 0.5796531198486206
I0419 01:31:45.338724 30816 trainer.py:139] Epoch[622/1000] loss: 0.5771605901179775
I0419 01:31:52.185255 30816 trainer.py:139] Epoch[623/1000] loss: 0.5785832818477384
I0419 01:31:59.163994 30816 trainer.py:139] Epoch[624/1000] loss: 0.578186656198194
I0419 01:32:05.992248 30816 trainer.py:139] Epoch[625/1000] loss: 0.5767858672526575
I0419 01:32:12.961675 30816 trainer.py:139] Epoch[626/1000] loss: 0.5817115124194853
I0419 01:32:19.681599 30816 trainer.py:139] Epoch[627/1000] loss: 0.576501339673996
I0419 01:32:26.533344 30816 trainer.py:139] Epoch[628/1000] loss: 0.5791692762605606
I0419 01:32:33.471604 30816 trainer.py:139] Epoch[629/1000] loss: 0.5788544099177083
I0419 01:32:40.349865 30816 trainer.py:139] Epoch[630/1000] loss: 0.5789680182933807
I0419 01:32:47.324005 30816 trainer.py:139] Epoch[631/1000] loss: 0.5758803111891593
I0419 01:32:54.244850 30816 trainer.py:139] Epoch[632/1000] loss: 0.5785000497295011
I0419 01:33:01.044496 30816 trainer.py:139] Epoch[633/1000] loss: 0.5795936536404395
I0419 01:33:08.095108 30816 trainer.py:139] Epoch[634/1000] loss: 0.5790449534693072
I0419 01:33:14.954177 30816 trainer.py:139] Epoch[635/1000] loss: 0.5756242794375266
I0419 01:33:21.816238 30816 trainer.py:139] Epoch[636/1000] loss: 0.57894814783527
I0419 01:33:28.792097 30816 trainer.py:139] Epoch[637/1000] loss: 0.5787473878552837
I0419 01:33:35.586266 30816 trainer.py:139] Epoch[638/1000] loss: 0.5767019679469447
I0419 01:33:42.604711 30816 trainer.py:139] Epoch[639/1000] loss: 0.5797774041852644
I0419 01:33:49.438937 30816 trainer.py:139] Epoch[640/1000] loss: 0.5799935911932299
I0419 01:33:56.733108 30816 trainer.py:139] Epoch[641/1000] loss: 0.5848276903552394
I0419 01:34:03.575178 30816 trainer.py:139] Epoch[642/1000] loss: 0.5769294058122942
I0419 01:34:10.427896 30816 trainer.py:139] Epoch[643/1000] loss: 0.5804131050263682
I0419 01:34:17.458690 30816 trainer.py:139] Epoch[644/1000] loss: 0.5806145418074823
I0419 01:34:24.274588 30816 trainer.py:139] Epoch[645/1000] loss: 0.5788280329396648
I0419 01:34:31.329496 30816 trainer.py:139] Epoch[646/1000] loss: 0.579030538758924
I0419 01:34:38.169256 30816 trainer.py:139] Epoch[647/1000] loss: 0.5751624847612073
I0419 01:34:45.133954 30816 trainer.py:139] Epoch[648/1000] loss: 0.5794125016658537
I0419 01:34:51.883181 30816 trainer.py:139] Epoch[649/1000] loss: 0.5773248710939961
I0419 01:34:52.411414 30816 trainer.py:145] Test: [{'precision': 0.012358371800251788, 'recall': 0.15465799412505243, 'hit_ratio': 0.234158623583718, 'ndcg': 0.07321148738465419}]
I0419 01:34:59.410947 30816 trainer.py:139] Epoch[650/1000] loss: 0.5769928193861439
I0419 01:35:06.433418 30816 trainer.py:139] Epoch[651/1000] loss: 0.578819808460051
I0419 01:35:13.429861 30816 trainer.py:139] Epoch[652/1000] loss: 0.5771919373543032
I0419 01:35:20.218081 30816 trainer.py:139] Epoch[653/1000] loss: 0.5809370269698482
I0419 01:35:27.174826 30816 trainer.py:139] Epoch[654/1000] loss: 0.5786907845927823
I0419 01:35:34.091504 30816 trainer.py:139] Epoch[655/1000] loss: 0.5803904119999178
I0419 01:35:41.151909 30816 trainer.py:139] Epoch[656/1000] loss: 0.5787611622964183
I0419 01:35:48.235681 30816 trainer.py:139] Epoch[657/1000] loss: 0.5770160363566491
I0419 01:35:55.207360 30816 trainer.py:139] Epoch[658/1000] loss: 0.5785924792289734
I0419 01:36:02.272023 30816 trainer.py:139] Epoch[659/1000] loss: 0.5779781110825077
I0419 01:36:09.291979 30816 trainer.py:139] Epoch[660/1000] loss: 0.5757479186980955
I0419 01:36:16.098563 30816 trainer.py:139] Epoch[661/1000] loss: 0.5785136943863284
I0419 01:36:22.999819 30816 trainer.py:139] Epoch[662/1000] loss: 0.5789558464480985
I0419 01:36:29.809150 30816 trainer.py:139] Epoch[663/1000] loss: 0.5801645613485767
I0419 01:36:36.734434 30816 trainer.py:139] Epoch[664/1000] loss: 0.5781464028743005
I0419 01:36:43.626978 30816 trainer.py:139] Epoch[665/1000] loss: 0.5770860737369906
I0419 01:36:50.687779 30816 trainer.py:139] Epoch[666/1000] loss: 0.5752388306202427
I0419 01:36:57.860556 30816 trainer.py:139] Epoch[667/1000] loss: 0.5792593494538338
I0419 01:37:04.890139 30816 trainer.py:139] Epoch[668/1000] loss: 0.578494046964953
I0419 01:37:11.965989 30816 trainer.py:139] Epoch[669/1000] loss: 0.5776549029734827
I0419 01:37:18.756916 30816 trainer.py:139] Epoch[670/1000] loss: 0.5774795114994049
I0419 01:37:25.796923 30816 trainer.py:139] Epoch[671/1000] loss: 0.578071508676775
I0419 01:37:32.523589 30816 trainer.py:139] Epoch[672/1000] loss: 0.5782386141438638
I0419 01:37:39.578882 30816 trainer.py:139] Epoch[673/1000] loss: 0.5764165982123344
I0419 01:37:46.365566 30816 trainer.py:139] Epoch[674/1000] loss: 0.5803174751420175
I0419 01:37:53.132956 30816 trainer.py:139] Epoch[675/1000] loss: 0.5773795535487514
I0419 01:37:59.776894 30816 trainer.py:139] Epoch[676/1000] loss: 0.5771646855338928
I0419 01:38:06.646845 30816 trainer.py:139] Epoch[677/1000] loss: 0.5786656372008785
I0419 01:38:13.529580 30816 trainer.py:139] Epoch[678/1000] loss: 0.5791410015475366
I0419 01:38:20.512620 30816 trainer.py:139] Epoch[679/1000] loss: 0.5760823574758345
I0419 01:38:27.430281 30816 trainer.py:139] Epoch[680/1000] loss: 0.5779396035978871
I0419 01:38:34.488696 30816 trainer.py:139] Epoch[681/1000] loss: 0.5761726056375811
I0419 01:38:41.446792 30816 trainer.py:139] Epoch[682/1000] loss: 0.5806544269284895
I0419 01:38:48.388878 30816 trainer.py:139] Epoch[683/1000] loss: 0.5767404965816005
I0419 01:38:55.359808 30816 trainer.py:139] Epoch[684/1000] loss: 0.577985615499558
I0419 01:39:02.094109 30816 trainer.py:139] Epoch[685/1000] loss: 0.5773872310115445
I0419 01:39:08.870767 30816 trainer.py:139] Epoch[686/1000] loss: 0.5805068044893203
I0419 01:39:15.771432 30816 trainer.py:139] Epoch[687/1000] loss: 0.5793662830706565
I0419 01:39:22.575207 30816 trainer.py:139] Epoch[688/1000] loss: 0.5778387150456828
I0419 01:39:29.647458 30816 trainer.py:139] Epoch[689/1000] loss: 0.5777985713174266
I0419 01:39:36.568549 30816 trainer.py:139] Epoch[690/1000] loss: 0.5783555651864698
I0419 01:39:43.453257 30816 trainer.py:139] Epoch[691/1000] loss: 0.5759652151215461
I0419 01:39:50.528718 30816 trainer.py:139] Epoch[692/1000] loss: 0.5750224080777937
I0419 01:39:57.631858 30816 trainer.py:139] Epoch[693/1000] loss: 0.5793062352365063
I0419 01:40:04.705157 30816 trainer.py:139] Epoch[694/1000] loss: 0.5778567444893622
I0419 01:40:11.529581 30816 trainer.py:139] Epoch[695/1000] loss: 0.5776966194952687
I0419 01:40:18.458705 30816 trainer.py:139] Epoch[696/1000] loss: 0.5777405836889821
I0419 01:40:25.380387 30816 trainer.py:139] Epoch[697/1000] loss: 0.5775133342512192
I0419 01:40:32.169605 30816 trainer.py:139] Epoch[698/1000] loss: 0.5788676796420928
I0419 01:40:39.241431 30816 trainer.py:139] Epoch[699/1000] loss: 0.5769695418496286
I0419 01:40:39.782191 30816 trainer.py:145] Test: [{'precision': 0.012463281577843061, 'recall': 0.15553973582718864, 'hit_ratio': 0.23793537557700378, 'ndcg': 0.0729888202076792}]
I0419 01:40:46.792793 30816 trainer.py:139] Epoch[700/1000] loss: 0.5782296407607294
I0419 01:40:53.714539 30816 trainer.py:139] Epoch[701/1000] loss: 0.5797356780498258
I0419 01:41:00.777751 30816 trainer.py:139] Epoch[702/1000] loss: 0.5766899508814658
I0419 01:41:07.872957 30816 trainer.py:139] Epoch[703/1000] loss: 0.5761971464080196
I0419 01:41:14.793751 30816 trainer.py:139] Epoch[704/1000] loss: 0.5779773381448561
I0419 01:41:21.516324 30816 trainer.py:139] Epoch[705/1000] loss: 0.5808901892554376
I0419 01:41:28.557214 30816 trainer.py:139] Epoch[706/1000] loss: 0.5761015165236688
I0419 01:41:35.392772 30816 trainer.py:139] Epoch[707/1000] loss: 0.5756040369310687
I0419 01:41:42.383813 30816 trainer.py:139] Epoch[708/1000] loss: 0.579048365354538
I0419 01:41:49.153552 30816 trainer.py:139] Epoch[709/1000] loss: 0.5833265041151354
I0419 01:41:56.111219 30816 trainer.py:139] Epoch[710/1000] loss: 0.5767462724639524
I0419 01:42:03.043911 30816 trainer.py:139] Epoch[711/1000] loss: 0.5795420302498725
I0419 01:42:10.157088 30816 trainer.py:139] Epoch[712/1000] loss: 0.5803064021372026
I0419 01:42:17.137885 30816 trainer.py:139] Epoch[713/1000] loss: 0.5785989319124529
I0419 01:42:24.040387 30816 trainer.py:139] Epoch[714/1000] loss: 0.5765457239843184
I0419 01:42:31.040436 30816 trainer.py:139] Epoch[715/1000] loss: 0.5769449395518149
I0419 01:42:37.987266 30816 trainer.py:139] Epoch[716/1000] loss: 0.5763028302500325
I0419 01:42:44.930916 30816 trainer.py:139] Epoch[717/1000] loss: 0.5736643883489794
I0419 01:42:51.882855 30816 trainer.py:139] Epoch[718/1000] loss: 0.5770089472493818
I0419 01:42:58.786271 30816 trainer.py:139] Epoch[719/1000] loss: 0.577244944149448
I0419 01:43:05.605785 30816 trainer.py:139] Epoch[720/1000] loss: 0.5812838721659875
I0419 01:43:12.559708 30816 trainer.py:139] Epoch[721/1000] loss: 0.5787098628859366
I0419 01:43:19.321445 30816 trainer.py:139] Epoch[722/1000] loss: 0.5745118885271011
I0419 01:43:26.214371 30816 trainer.py:139] Epoch[723/1000] loss: 0.5770561733553486
I0419 01:43:33.159768 30816 trainer.py:139] Epoch[724/1000] loss: 0.5780811165609667
I0419 01:43:40.387458 30816 trainer.py:139] Epoch[725/1000] loss: 0.5799703944113946
I0419 01:43:47.478774 30816 trainer.py:139] Epoch[726/1000] loss: 0.5791396469839157
I0419 01:43:54.373864 30816 trainer.py:139] Epoch[727/1000] loss: 0.5750046660823207
I0419 01:44:01.331577 30816 trainer.py:139] Epoch[728/1000] loss: 0.5774799316160141
I0419 01:44:08.443715 30816 trainer.py:139] Epoch[729/1000] loss: 0.5769919945347693
I0419 01:44:15.246891 30816 trainer.py:139] Epoch[730/1000] loss: 0.57676732059448
I0419 01:44:22.327764 30816 trainer.py:139] Epoch[731/1000] loss: 0.5791977836239722
I0419 01:44:29.297431 30816 trainer.py:139] Epoch[732/1000] loss: 0.5807917579527824
I0419 01:44:36.092076 30816 trainer.py:139] Epoch[733/1000] loss: 0.5748967249547282
I0419 01:44:42.966948 30816 trainer.py:139] Epoch[734/1000] loss: 0.578019441135468
I0419 01:44:49.753825 30816 trainer.py:139] Epoch[735/1000] loss: 0.5775635155939287
I0419 01:44:56.675588 30816 trainer.py:139] Epoch[736/1000] loss: 0.5769234193909553
I0419 01:45:03.384869 30816 trainer.py:139] Epoch[737/1000] loss: 0.5762259969788213
I0419 01:45:10.272699 30816 trainer.py:139] Epoch[738/1000] loss: 0.5762365066236065
I0419 01:45:17.192091 30816 trainer.py:139] Epoch[739/1000] loss: 0.5751075004377673
I0419 01:45:24.125859 30816 trainer.py:139] Epoch[740/1000] loss: 0.5797720426513303
I0419 01:45:31.145289 30816 trainer.py:139] Epoch[741/1000] loss: 0.578610518286305
I0419 01:45:38.067198 30816 trainer.py:139] Epoch[742/1000] loss: 0.5772834948955043
I0419 01:45:45.215228 30816 trainer.py:139] Epoch[743/1000] loss: 0.5783160165432961
I0419 01:45:52.202928 30816 trainer.py:139] Epoch[744/1000] loss: 0.577951455308545
I0419 01:45:59.067004 30816 trainer.py:139] Epoch[745/1000] loss: 0.5759298551467157
I0419 01:46:06.420736 30816 trainer.py:139] Epoch[746/1000] loss: 0.5796060292951523
I0419 01:46:13.136021 30816 trainer.py:139] Epoch[747/1000] loss: 0.5778182773820816
I0419 01:46:19.944254 30816 trainer.py:139] Epoch[748/1000] loss: 0.5794763978450529
I0419 01:46:26.657757 30816 trainer.py:139] Epoch[749/1000] loss: 0.5768407381349995
I0419 01:46:27.218880 30816 trainer.py:145] Test: [{'precision': 0.012589173310952584, 'recall': 0.15815914979784054, 'hit_ratio': 0.2404532102391943, 'ndcg': 0.07352844064315861}]
I0419 01:46:34.058404 30816 trainer.py:139] Epoch[750/1000] loss: 0.5766383957478308
I0419 01:46:40.955321 30816 trainer.py:139] Epoch[751/1000] loss: 0.5770878455331249
I0419 01:46:47.764266 30816 trainer.py:139] Epoch[752/1000] loss: 0.5764767133420513
I0419 01:46:54.813306 30816 trainer.py:139] Epoch[753/1000] loss: 0.5797604649297653
I0419 01:47:01.806750 30816 trainer.py:139] Epoch[754/1000] loss: 0.5765423582446191
I0419 01:47:08.709329 30816 trainer.py:139] Epoch[755/1000] loss: 0.5777864648449805
I0419 01:47:15.645265 30816 trainer.py:139] Epoch[756/1000] loss: 0.5772468813004032
I0419 01:47:22.470634 30816 trainer.py:139] Epoch[757/1000] loss: 0.5784834267631653
I0419 01:47:29.526095 30816 trainer.py:139] Epoch[758/1000] loss: 0.5804580065511888
I0419 01:47:36.346899 30816 trainer.py:139] Epoch[759/1000] loss: 0.5751901317027307
I0419 01:47:43.374332 30816 trainer.py:139] Epoch[760/1000] loss: 0.575385311918874
I0419 01:47:50.492417 30816 trainer.py:139] Epoch[761/1000] loss: 0.5778771936893463
I0419 01:47:57.596919 30816 trainer.py:139] Epoch[762/1000] loss: 0.5752327509464756
I0419 01:48:04.509016 30816 trainer.py:139] Epoch[763/1000] loss: 0.5749087997021214
I0419 01:48:11.387789 30816 trainer.py:139] Epoch[764/1000] loss: 0.5760058972143358
I0419 01:48:18.142464 30816 trainer.py:139] Epoch[765/1000] loss: 0.5777019810292029
I0419 01:48:25.110632 30816 trainer.py:139] Epoch[766/1000] loss: 0.5783692319546977
I0419 01:48:32.147157 30816 trainer.py:139] Epoch[767/1000] loss: 0.5758781673446778
I0419 01:48:39.149770 30816 trainer.py:139] Epoch[768/1000] loss: 0.5778800979737313
I0419 01:48:46.023692 30816 trainer.py:139] Epoch[769/1000] loss: 0.5795921539106677
I0419 01:48:52.881263 30816 trainer.py:139] Epoch[770/1000] loss: 0.5754159775472456
I0419 01:48:59.818262 30816 trainer.py:139] Epoch[771/1000] loss: 0.5796524574679713
I0419 01:49:06.715205 30816 trainer.py:139] Epoch[772/1000] loss: 0.5788066877472785
I0419 01:49:13.518376 30816 trainer.py:139] Epoch[773/1000] loss: 0.5771357878561942
I0419 01:49:20.483663 30816 trainer.py:139] Epoch[774/1000] loss: 0.582813601340017
I0419 01:49:27.474661 30816 trainer.py:139] Epoch[775/1000] loss: 0.5815808196221629
I0419 01:49:34.307206 30816 trainer.py:139] Epoch[776/1000] loss: 0.576495264807055
I0419 01:49:41.195091 30816 trainer.py:139] Epoch[777/1000] loss: 0.5782657573300023
I0419 01:49:48.156123 30816 trainer.py:139] Epoch[778/1000] loss: 0.5802776659688642
I0419 01:49:55.086350 30816 trainer.py:139] Epoch[779/1000] loss: 0.5750307661871756
I0419 01:50:02.026495 30816 trainer.py:139] Epoch[780/1000] loss: 0.5769739275978457
I0419 01:50:09.004645 30816 trainer.py:139] Epoch[781/1000] loss: 0.5802723005894692
I0419 01:50:15.952890 30816 trainer.py:139] Epoch[782/1000] loss: 0.5771470935113968
I0419 01:50:23.042129 30816 trainer.py:139] Epoch[783/1000] loss: 0.5782765986457947
I0419 01:50:29.872498 30816 trainer.py:139] Epoch[784/1000] loss: 0.5767319510059972
I0419 01:50:36.804825 30816 trainer.py:139] Epoch[785/1000] loss: 0.5777286531463746
I0419 01:50:43.607062 30816 trainer.py:139] Epoch[786/1000] loss: 0.5733175008527694
I0419 01:50:50.482248 30816 trainer.py:139] Epoch[787/1000] loss: 0.5754940240613876
I0419 01:50:57.382641 30816 trainer.py:139] Epoch[788/1000] loss: 0.5751939848546059
I0419 01:51:04.545811 30816 trainer.py:139] Epoch[789/1000] loss: 0.5744295687444748
I0419 01:51:11.401261 30816 trainer.py:139] Epoch[790/1000] loss: 0.5775085149272796
I0419 01:51:18.353955 30816 trainer.py:139] Epoch[791/1000] loss: 0.5753580351029673
I0419 01:51:25.563425 30816 trainer.py:139] Epoch[792/1000] loss: 0.5748243197318046
I0419 01:51:32.421287 30816 trainer.py:139] Epoch[793/1000] loss: 0.5779945802304053
I0419 01:51:39.178600 30816 trainer.py:139] Epoch[794/1000] loss: 0.5769595407670544
I0419 01:51:46.295857 30816 trainer.py:139] Epoch[795/1000] loss: 0.5780979116116801
I0419 01:51:53.242207 30816 trainer.py:139] Epoch[796/1000] loss: 0.575082084824962
I0419 01:52:00.097302 30816 trainer.py:139] Epoch[797/1000] loss: 0.5799866587884964
I0419 01:52:07.044883 30816 trainer.py:139] Epoch[798/1000] loss: 0.5782589335595408
I0419 01:52:13.848125 30816 trainer.py:139] Epoch[799/1000] loss: 0.5767138648417688
I0419 01:52:14.401721 30816 trainer.py:145] Test: [{'precision': 0.012316407889215281, 'recall': 0.15476640089523014, 'hit_ratio': 0.23625681913554344, 'ndcg': 0.07296592044422304}]
I0419 01:52:21.312449 30816 trainer.py:139] Epoch[800/1000] loss: 0.5768259225353118
I0419 01:52:28.269087 30816 trainer.py:139] Epoch[801/1000] loss: 0.577290145620223
I0419 01:52:35.142205 30816 trainer.py:139] Epoch[802/1000] loss: 0.5754694900205058
I0419 01:52:41.956274 30816 trainer.py:139] Epoch[803/1000] loss: 0.578989403863107
I0419 01:52:48.835978 30816 trainer.py:139] Epoch[804/1000] loss: 0.5789411356372218
I0419 01:52:55.934855 30816 trainer.py:139] Epoch[805/1000] loss: 0.5755961979589155
I0419 01:53:03.042026 30816 trainer.py:139] Epoch[806/1000] loss: 0.5766472220420837
I0419 01:53:09.972782 30816 trainer.py:139] Epoch[807/1000] loss: 0.5733680561665566
I0419 01:53:16.845819 30816 trainer.py:139] Epoch[808/1000] loss: 0.5803375820959767
I0419 01:53:23.692876 30816 trainer.py:139] Epoch[809/1000] loss: 0.5739646505924964
I0419 01:53:30.519986 30816 trainer.py:139] Epoch[810/1000] loss: 0.5755886820054823
I0419 01:53:37.408340 30816 trainer.py:139] Epoch[811/1000] loss: 0.5818296940095963
I0419 01:53:44.300127 30816 trainer.py:139] Epoch[812/1000] loss: 0.5786826360610223
I0419 01:53:51.192434 30816 trainer.py:139] Epoch[813/1000] loss: 0.5745035832928073
I0419 01:53:58.279713 30816 trainer.py:139] Epoch[814/1000] loss: 0.5772224395505844
I0419 01:54:05.142762 30816 trainer.py:139] Epoch[815/1000] loss: 0.5777303614924031
I0419 01:54:12.053670 30816 trainer.py:139] Epoch[816/1000] loss: 0.5747836462913021
I0419 01:54:18.779192 30816 trainer.py:139] Epoch[817/1000] loss: 0.5751267585062212
I0419 01:54:25.697521 30816 trainer.py:139] Epoch[818/1000] loss: 0.5783412504580713
I0419 01:54:32.460251 30816 trainer.py:139] Epoch[819/1000] loss: 0.5760135727543985
I0419 01:54:39.499546 30816 trainer.py:139] Epoch[820/1000] loss: 0.5736828869388949
I0419 01:54:46.355000 30816 trainer.py:139] Epoch[821/1000] loss: 0.576476962335648
I0419 01:54:53.361710 30816 trainer.py:139] Epoch[822/1000] loss: 0.5793201721483662
I0419 01:55:00.331426 30816 trainer.py:139] Epoch[823/1000] loss: 0.5764167106920673
I0419 01:55:07.251252 30816 trainer.py:139] Epoch[824/1000] loss: 0.5783830006276408
I0419 01:55:14.090451 30816 trainer.py:139] Epoch[825/1000] loss: 0.5739758456906965
I0419 01:55:20.918647 30816 trainer.py:139] Epoch[826/1000] loss: 0.5776972982191271
I0419 01:55:27.956050 30816 trainer.py:139] Epoch[827/1000] loss: 0.5747441812869041
I0419 01:55:34.854897 30816 trainer.py:139] Epoch[828/1000] loss: 0.5754011629089233
I0419 01:55:41.690975 30816 trainer.py:139] Epoch[829/1000] loss: 0.5775326048174212
I0419 01:55:48.571948 30816 trainer.py:139] Epoch[830/1000] loss: 0.5767190908232043
I0419 01:55:55.537307 30816 trainer.py:139] Epoch[831/1000] loss: 0.5767218143709244
I0419 01:56:02.348814 30816 trainer.py:139] Epoch[832/1000] loss: 0.5767584154682774
I0419 01:56:09.265685 30816 trainer.py:139] Epoch[833/1000] loss: 0.5787081247375857
I0419 01:56:16.028262 30816 trainer.py:139] Epoch[834/1000] loss: 0.5780047620496442
I0419 01:56:22.966957 30816 trainer.py:139] Epoch[835/1000] loss: 0.5749808040357405
I0419 01:56:29.926559 30816 trainer.py:139] Epoch[836/1000] loss: 0.5773715338399333
I0419 01:56:37.283606 30816 trainer.py:139] Epoch[837/1000] loss: 0.5794506620976233
I0419 01:56:44.332223 30816 trainer.py:139] Epoch[838/1000] loss: 0.5774312951872426
I0419 01:56:51.192241 30816 trainer.py:139] Epoch[839/1000] loss: 0.5785636969151036
I0419 01:56:58.213831 30816 trainer.py:139] Epoch[840/1000] loss: 0.5773649677153556
I0419 01:57:05.095000 30816 trainer.py:139] Epoch[841/1000] loss: 0.578160185006357
I0419 01:57:12.176025 30816 trainer.py:139] Epoch[842/1000] loss: 0.5755055527533254
I0419 01:57:19.045075 30816 trainer.py:139] Epoch[843/1000] loss: 0.5779976037240797
I0419 01:57:25.968493 30816 trainer.py:139] Epoch[844/1000] loss: 0.5755812900681649
I0419 01:57:33.063230 30816 trainer.py:139] Epoch[845/1000] loss: 0.5754103977834025
I0419 01:57:39.990263 30816 trainer.py:139] Epoch[846/1000] loss: 0.5767382325664643
I0419 01:57:46.956362 30816 trainer.py:139] Epoch[847/1000] loss: 0.5757017250983946
I0419 01:57:53.987220 30816 trainer.py:139] Epoch[848/1000] loss: 0.574773891318229
I0419 01:58:01.141205 30816 trainer.py:139] Epoch[849/1000] loss: 0.5773360460035263
I0419 01:58:01.681937 30816 trainer.py:145] Test: [{'precision': 0.012358371800251788, 'recall': 0.15532891713126712, 'hit_ratio': 0.23499790180444818, 'ndcg': 0.07271550950863362}]
I0419 01:58:08.724837 30816 trainer.py:139] Epoch[850/1000] loss: 0.5782157596080534
I0419 01:58:15.759395 30816 trainer.py:139] Epoch[851/1000] loss: 0.5766491332361775
I0419 01:58:22.767901 30816 trainer.py:139] Epoch[852/1000] loss: 0.5777475170550808
I0419 01:58:29.610982 30816 trainer.py:139] Epoch[853/1000] loss: 0.576695688309208
I0419 01:58:36.556373 30816 trainer.py:139] Epoch[854/1000] loss: 0.5749576034084443
I0419 01:58:43.424802 30816 trainer.py:139] Epoch[855/1000] loss: 0.5795869596542851
I0419 01:58:50.367428 30816 trainer.py:139] Epoch[856/1000] loss: 0.5789501734318272
I0419 01:58:57.258853 30816 trainer.py:139] Epoch[857/1000] loss: 0.5744412099161456
I0419 01:59:04.270232 30816 trainer.py:139] Epoch[858/1000] loss: 0.5755098587082278
I0419 01:59:11.293638 30816 trainer.py:139] Epoch[859/1000] loss: 0.5824065900618031
I0419 01:59:18.296092 30816 trainer.py:139] Epoch[860/1000] loss: 0.5748706354248908
I0419 01:59:25.099265 30816 trainer.py:139] Epoch[861/1000] loss: 0.5750128050004283
I0419 01:59:32.026751 30816 trainer.py:139] Epoch[862/1000] loss: 0.5755698382854462
I0419 01:59:38.725791 30816 trainer.py:139] Epoch[863/1000] loss: 0.5758633363631463
I0419 01:59:45.695389 30816 trainer.py:139] Epoch[864/1000] loss: 0.5750048381666983
I0419 01:59:52.442153 30816 trainer.py:139] Epoch[865/1000] loss: 0.5767643009462664
I0419 01:59:59.407748 30816 trainer.py:139] Epoch[866/1000] loss: 0.5770536180465452
I0419 02:00:06.201219 30816 trainer.py:139] Epoch[867/1000] loss: 0.5772098495114234
I0419 02:00:13.028893 30816 trainer.py:139] Epoch[868/1000] loss: 0.5765170503047204
I0419 02:00:19.754782 30816 trainer.py:139] Epoch[869/1000] loss: 0.5792866089651661
I0419 02:00:26.857001 30816 trainer.py:139] Epoch[870/1000] loss: 0.5790137215968101
I0419 02:00:33.754559 30816 trainer.py:139] Epoch[871/1000] loss: 0.5773570104952781
I0419 02:00:40.744120 30816 trainer.py:139] Epoch[872/1000] loss: 0.5749507113810508
I0419 02:00:47.735872 30816 trainer.py:139] Epoch[873/1000] loss: 0.5743450349377047
I0419 02:00:54.730721 30816 trainer.py:139] Epoch[874/1000] loss: 0.5759541723997362
I0419 02:01:02.103738 30816 trainer.py:139] Epoch[875/1000] loss: 0.578403664212073
I0419 02:01:09.137956 30816 trainer.py:139] Epoch[876/1000] loss: 0.57878184414679
I0419 02:01:16.152447 30816 trainer.py:139] Epoch[877/1000] loss: 0.5771997580605168
I0419 02:01:22.942104 30816 trainer.py:139] Epoch[878/1000] loss: 0.5763411050842654
I0419 02:01:29.787290 30816 trainer.py:139] Epoch[879/1000] loss: 0.579588835277865
I0419 02:01:36.764540 30816 trainer.py:139] Epoch[880/1000] loss: 0.5767801788545424
I0419 02:01:43.613611 30816 trainer.py:139] Epoch[881/1000] loss: 0.5742441146604477
I0419 02:01:50.317015 30816 trainer.py:139] Epoch[882/1000] loss: 0.5764915885463837
I0419 02:01:57.264187 30816 trainer.py:139] Epoch[883/1000] loss: 0.5749012049167387
I0419 02:02:04.315390 30816 trainer.py:139] Epoch[884/1000] loss: 0.5761831373937668
I0419 02:02:11.444103 30816 trainer.py:139] Epoch[885/1000] loss: 0.5722734168652566
I0419 02:02:18.352771 30816 trainer.py:139] Epoch[886/1000] loss: 0.5731446550738427
I0419 02:02:25.334094 30816 trainer.py:139] Epoch[887/1000] loss: 0.5757710510684598
I0419 02:02:32.407649 30816 trainer.py:139] Epoch[888/1000] loss: 0.5780808166150124
I0419 02:02:39.405730 30816 trainer.py:139] Epoch[889/1000] loss: 0.5742830836003826
I0419 02:02:46.414810 30816 trainer.py:139] Epoch[890/1000] loss: 0.5773791776549432
I0419 02:02:53.235760 30816 trainer.py:139] Epoch[891/1000] loss: 0.5784762424807395
I0419 02:03:01.908484 30816 trainer.py:139] Epoch[892/1000] loss: 0.5790548382266876
I0419 02:03:08.921590 30816 trainer.py:139] Epoch[893/1000] loss: 0.5777421516756858
I0419 02:03:15.824890 30816 trainer.py:139] Epoch[894/1000] loss: 0.5761357507398052
I0419 02:03:22.607935 30816 trainer.py:139] Epoch[895/1000] loss: 0.5765431398345578
I0419 02:03:29.571345 30816 trainer.py:139] Epoch[896/1000] loss: 0.5740602122199151
I0419 02:03:36.396487 30816 trainer.py:139] Epoch[897/1000] loss: 0.578647933660015
I0419 02:03:43.271498 30816 trainer.py:139] Epoch[898/1000] loss: 0.5754422353159997
I0419 02:03:50.285394 30816 trainer.py:139] Epoch[899/1000] loss: 0.576511429202172
I0419 02:03:50.825587 30816 trainer.py:145] Test: [{'precision': 0.012400335711288298, 'recall': 0.15752502847551103, 'hit_ratio': 0.23667645824590852, 'ndcg': 0.0738205897973868}]
I0419 02:03:57.863815 30816 trainer.py:139] Epoch[900/1000] loss: 0.5780185105339173
I0419 02:04:04.718817 30816 trainer.py:139] Epoch[901/1000] loss: 0.57561658851562
I0419 02:04:11.670729 30816 trainer.py:139] Epoch[902/1000] loss: 0.5744597825311846
I0419 02:04:18.558803 30816 trainer.py:139] Epoch[903/1000] loss: 0.5780281097658219
I0419 02:04:25.398483 30816 trainer.py:139] Epoch[904/1000] loss: 0.5751966180339936
I0419 02:04:32.285563 30816 trainer.py:139] Epoch[905/1000] loss: 0.5758867234952988
I0419 02:04:39.341946 30816 trainer.py:139] Epoch[906/1000] loss: 0.5755202164573054
I0419 02:04:46.170998 30816 trainer.py:139] Epoch[907/1000] loss: 0.5765567623799847
I0419 02:04:53.115192 30816 trainer.py:139] Epoch[908/1000] loss: 0.5781464144106834
I0419 02:04:59.934706 30816 trainer.py:139] Epoch[909/1000] loss: 0.576050914102985
I0419 02:05:06.926413 30816 trainer.py:139] Epoch[910/1000] loss: 0.5759441266136784
I0419 02:05:13.730665 30816 trainer.py:139] Epoch[911/1000] loss: 0.5781439129383333
I0419 02:05:20.663402 30816 trainer.py:139] Epoch[912/1000] loss: 0.5805957788421262
I0419 02:05:27.639719 30816 trainer.py:139] Epoch[913/1000] loss: 0.5769420727606742
I0419 02:05:34.626844 30816 trainer.py:139] Epoch[914/1000] loss: 0.576745597585555
I0419 02:05:41.504764 30816 trainer.py:139] Epoch[915/1000] loss: 0.5770457377356868
I0419 02:05:48.311889 30816 trainer.py:139] Epoch[916/1000] loss: 0.5769535716502897
I0419 02:05:55.139661 30816 trainer.py:139] Epoch[917/1000] loss: 0.5749657884720834
I0419 02:06:02.089880 30816 trainer.py:139] Epoch[918/1000] loss: 0.5750692679036048
I0419 02:06:08.763536 30816 trainer.py:139] Epoch[919/1000] loss: 0.5751692085496841
I0419 02:06:15.742669 30816 trainer.py:139] Epoch[920/1000] loss: 0.5765045487111614
I0419 02:06:22.689139 30816 trainer.py:139] Epoch[921/1000] loss: 0.5748576983328788
I0419 02:06:29.751466 30816 trainer.py:139] Epoch[922/1000] loss: 0.5754873906412432
I0419 02:06:36.784482 30816 trainer.py:139] Epoch[923/1000] loss: 0.5754544052385515
I0419 02:06:43.666565 30816 trainer.py:139] Epoch[924/1000] loss: 0.5751651765838746
I0419 02:06:50.310285 30816 trainer.py:139] Epoch[925/1000] loss: 0.57447957127325
I0419 02:06:56.680833 30816 trainer.py:139] Epoch[926/1000] loss: 0.5743565597841817
I0419 02:07:03.173849 30816 trainer.py:139] Epoch[927/1000] loss: 0.5794371645296773
I0419 02:07:09.605868 30816 trainer.py:139] Epoch[928/1000] loss: 0.5776007608059914
I0419 02:07:16.080961 30816 trainer.py:139] Epoch[929/1000] loss: 0.577576942020847
I0419 02:07:22.621946 30816 trainer.py:139] Epoch[930/1000] loss: 0.5750822607548006
I0419 02:07:29.148134 30816 trainer.py:139] Epoch[931/1000] loss: 0.5756525320391501
I0419 02:07:35.538391 30816 trainer.py:139] Epoch[932/1000] loss: 0.5757478888957731
I0419 02:07:41.956052 30816 trainer.py:139] Epoch[933/1000] loss: 0.5764951282931913
I0419 02:07:48.533046 30816 trainer.py:139] Epoch[934/1000] loss: 0.5744151309613259
I0419 02:07:55.044543 30816 trainer.py:139] Epoch[935/1000] loss: 0.5751986513214726
I0419 02:08:01.404258 30816 trainer.py:139] Epoch[936/1000] loss: 0.5752768603063398
I0419 02:08:07.810488 30816 trainer.py:139] Epoch[937/1000] loss: 0.5767162384525422
I0419 02:08:14.111981 30816 trainer.py:139] Epoch[938/1000] loss: 0.5790162970942836
I0419 02:08:20.781472 30816 trainer.py:139] Epoch[939/1000] loss: 0.5775723976473655
I0419 02:08:27.148255 30816 trainer.py:139] Epoch[940/1000] loss: 0.5758230705415049
I0419 02:08:33.551292 30816 trainer.py:139] Epoch[941/1000] loss: 0.5731916879453967
I0419 02:08:40.071986 30816 trainer.py:139] Epoch[942/1000] loss: 0.5767660102536601
I0419 02:08:46.331158 30816 trainer.py:139] Epoch[943/1000] loss: 0.5780391462387577
I0419 02:08:52.718770 30816 trainer.py:139] Epoch[944/1000] loss: 0.5769860398384833
I0419 02:08:59.216111 30816 trainer.py:139] Epoch[945/1000] loss: 0.5738068492181839
I0419 02:09:05.577328 30816 trainer.py:139] Epoch[946/1000] loss: 0.5727324255051152
I0419 02:09:12.014850 30816 trainer.py:139] Epoch[947/1000] loss: 0.5761753147648226
I0419 02:09:18.397452 30816 trainer.py:139] Epoch[948/1000] loss: 0.5773563913760646
I0419 02:09:24.730778 30816 trainer.py:139] Epoch[949/1000] loss: 0.5789139299623428
I0419 02:09:25.175917 30816 trainer.py:145] Test: [{'precision': 0.012442299622324807, 'recall': 0.15759846531982497, 'hit_ratio': 0.23667645824590852, 'ndcg': 0.073835065051562}]
I0419 02:09:31.587904 30816 trainer.py:139] Epoch[950/1000] loss: 0.5774270392233326
I0419 02:09:37.993092 30816 trainer.py:139] Epoch[951/1000] loss: 0.5775905184207424
I0419 02:09:44.375443 30816 trainer.py:139] Epoch[952/1000] loss: 0.5789854843770305
I0419 02:09:50.673716 30816 trainer.py:139] Epoch[953/1000] loss: 0.5772995227767576
I0419 02:09:57.155850 30816 trainer.py:139] Epoch[954/1000] loss: 0.5744985332412105
I0419 02:10:03.651842 30816 trainer.py:139] Epoch[955/1000] loss: 0.5767644855283922
I0419 02:10:10.060925 30816 trainer.py:139] Epoch[956/1000] loss: 0.5772350065169796
I0419 02:10:16.468802 30816 trainer.py:139] Epoch[957/1000] loss: 0.573282664821994
I0419 02:10:22.834657 30816 trainer.py:139] Epoch[958/1000] loss: 0.5727951122868445
I0419 02:10:29.275988 30816 trainer.py:139] Epoch[959/1000] loss: 0.5755566147065931
I0419 02:10:35.719805 30816 trainer.py:139] Epoch[960/1000] loss: 0.5773306988900707
I0419 02:10:42.048972 30816 trainer.py:139] Epoch[961/1000] loss: 0.5772014846724849
I0419 02:10:48.341181 30816 trainer.py:139] Epoch[962/1000] loss: 0.5764563314376339
I0419 02:10:54.817739 30816 trainer.py:139] Epoch[963/1000] loss: 0.5771679940723604
I0419 02:11:01.173433 30816 trainer.py:139] Epoch[964/1000] loss: 0.5768308822185763
I0419 02:11:07.503760 30816 trainer.py:139] Epoch[965/1000] loss: 0.5736623675592484
I0419 02:11:13.938706 30816 trainer.py:139] Epoch[966/1000] loss: 0.5792352422591178
I0419 02:11:20.298768 30816 trainer.py:139] Epoch[967/1000] loss: 0.5743059410202888
I0419 02:11:26.717885 30816 trainer.py:139] Epoch[968/1000] loss: 0.5755750488850379
I0419 02:11:33.203247 30816 trainer.py:139] Epoch[969/1000] loss: 0.5758188376503606
I0419 02:11:39.624588 30816 trainer.py:139] Epoch[970/1000] loss: 0.574413021725993
I0419 02:11:46.007352 30816 trainer.py:139] Epoch[971/1000] loss: 0.5775036888737832
I0419 02:11:52.454419 30816 trainer.py:139] Epoch[972/1000] loss: 0.5768095456784771
I0419 02:11:58.790775 30816 trainer.py:139] Epoch[973/1000] loss: 0.5742570834775125
I0419 02:12:05.173357 30816 trainer.py:139] Epoch[974/1000] loss: 0.5756336854350182
I0419 02:12:11.551941 30816 trainer.py:139] Epoch[975/1000] loss: 0.577586349941069
I0419 02:12:17.851745 30816 trainer.py:139] Epoch[976/1000] loss: 0.575932603689932
I0419 02:12:24.633908 30816 trainer.py:139] Epoch[977/1000] loss: 0.5739107006980527
I0419 02:12:30.979991 30816 trainer.py:139] Epoch[978/1000] loss: 0.5749188277029222
I0419 02:12:37.487831 30816 trainer.py:139] Epoch[979/1000] loss: 0.5769622998852884
I0419 02:12:43.797613 30816 trainer.py:139] Epoch[980/1000] loss: 0.5761856244456384
I0419 02:12:50.119862 30816 trainer.py:139] Epoch[981/1000] loss: 0.5759741615864539
I0419 02:12:56.576016 30816 trainer.py:139] Epoch[982/1000] loss: 0.5745642262120401
I0419 02:13:02.961184 30816 trainer.py:139] Epoch[983/1000] loss: 0.5802641933964144
I0419 02:13:09.486568 30816 trainer.py:139] Epoch[984/1000] loss: 0.5778561590179321
I0419 02:13:15.841487 30816 trainer.py:139] Epoch[985/1000] loss: 0.5753084228884789
I0419 02:13:22.346795 30816 trainer.py:139] Epoch[986/1000] loss: 0.5782053749407491
I0419 02:13:28.788448 30816 trainer.py:139] Epoch[987/1000] loss: 0.5789225428335129
I0419 02:13:35.093947 30816 trainer.py:139] Epoch[988/1000] loss: 0.5740161047827813
I0419 02:13:41.491474 30816 trainer.py:139] Epoch[989/1000] loss: 0.5761876144716817
I0419 02:13:47.939277 30816 trainer.py:139] Epoch[990/1000] loss: 0.5731844536719783
I0419 02:13:54.389946 30816 trainer.py:139] Epoch[991/1000] loss: 0.5774922841979612
I0419 02:14:00.769742 30816 trainer.py:139] Epoch[992/1000] loss: 0.5796795275903517
I0419 02:14:07.256990 30816 trainer.py:139] Epoch[993/1000] loss: 0.5731111063111213
I0419 02:14:13.706959 30816 trainer.py:139] Epoch[994/1000] loss: 0.5739063851294979
I0419 02:14:20.202591 30816 trainer.py:139] Epoch[995/1000] loss: 0.5769205747112152
I0419 02:14:26.512868 30816 trainer.py:139] Epoch[996/1000] loss: 0.5757063944493571
I0419 02:14:33.100674 30816 trainer.py:139] Epoch[997/1000] loss: 0.575673577285582
I0419 02:14:39.518287 30816 trainer.py:139] Epoch[998/1000] loss: 0.5726926153705966
I0419 02:14:45.857688 30816 trainer.py:139] Epoch[999/1000] loss: 0.577021187351596
I0419 02:14:46.312723 30816 trainer.py:145] Test: [{'precision': 0.012274443978178772, 'recall': 0.1552554802869532, 'hit_ratio': 0.234158623583718, 'ndcg': 0.07294276412038503}]
