I0414 23:16:41.589611 18880 trainer.py:121] Test: {'precision': 0.060777479892761443, 'recall': 0.13512174463641108, 'hit_ratio': 0.5823056300268097, 'ndcg': 0.11923307655600227}
I0414 23:16:45.880257 18880 trainer.py:139] Epoch[0/1500] loss: 0.5862436140737226
I0414 23:16:50.550633 18880 trainer.py:139] Epoch[1/1500] loss: 0.5220741283509039
I0414 23:16:54.967858 18880 trainer.py:139] Epoch[2/1500] loss: 0.5005904743748326
I0414 23:17:01.237880 18880 trainer.py:139] Epoch[3/1500] loss: 0.4788068917489821
I0414 23:17:05.530519 18880 trainer.py:139] Epoch[4/1500] loss: 0.4716325440714436
I0414 23:17:09.712528 18880 trainer.py:139] Epoch[5/1500] loss: 0.45585695485914907
I0414 23:17:14.371940 18880 trainer.py:139] Epoch[6/1500] loss: 0.4321195742776317
I0414 23:17:19.892473 18880 trainer.py:139] Epoch[7/1500] loss: 0.4196266435807751
I0414 23:17:25.627286 18880 trainer.py:139] Epoch[8/1500] loss: 0.3982560221225985
I0414 23:17:30.076403 18880 trainer.py:139] Epoch[9/1500] loss: 0.38292735430502123
I0414 23:17:34.652095 18880 trainer.py:139] Epoch[10/1500] loss: 0.36449557542800903
I0414 23:17:39.189914 18880 trainer.py:139] Epoch[11/1500] loss: 0.34882807347082323
I0414 23:17:45.833690 18880 trainer.py:139] Epoch[12/1500] loss: 0.3406530311030726
I0414 23:17:50.344597 18880 trainer.py:139] Epoch[13/1500] loss: 0.32741455781844353
I0414 23:17:55.414636 18880 trainer.py:139] Epoch[14/1500] loss: 0.3162198335893692
I0414 23:18:00.971048 18880 trainer.py:139] Epoch[15/1500] loss: 0.3147674347123792
I0414 23:18:06.468656 18880 trainer.py:139] Epoch[16/1500] loss: 0.3020489388896573
I0414 23:18:10.928735 18880 trainer.py:139] Epoch[17/1500] loss: 0.2989559740789475
I0414 23:18:15.708744 18880 trainer.py:139] Epoch[18/1500] loss: 0.29166606837703335
I0414 23:18:20.746889 18880 trainer.py:139] Epoch[19/1500] loss: 0.2871507060143255
I0414 23:18:27.295978 18880 trainer.py:139] Epoch[20/1500] loss: 0.27843177318573
I0414 23:18:32.256385 18880 trainer.py:139] Epoch[21/1500] loss: 0.27895197560710294
I0414 23:18:37.098187 18880 trainer.py:139] Epoch[22/1500] loss: 0.27011282213272586
I0414 23:18:41.725706 18880 trainer.py:139] Epoch[23/1500] loss: 0.26234851248802676
I0414 23:18:48.312669 18880 trainer.py:139] Epoch[24/1500] loss: 0.2625349462032318
I0414 23:18:52.976068 18880 trainer.py:139] Epoch[25/1500] loss: 0.2548048726973995
I0414 23:18:57.632492 18880 trainer.py:139] Epoch[26/1500] loss: 0.2537506511134486
I0414 23:19:02.452367 18880 trainer.py:139] Epoch[27/1500] loss: 0.2504667207118004
I0414 23:19:08.224494 18880 trainer.py:139] Epoch[28/1500] loss: 0.2505647924638564
I0414 23:19:13.748938 18880 trainer.py:139] Epoch[29/1500] loss: 0.2449391181430509
I0414 23:19:18.505196 18880 trainer.py:139] Epoch[30/1500] loss: 0.24027446633385074
I0414 23:19:23.506465 18880 trainer.py:139] Epoch[31/1500] loss: 0.2380682619348649
I0414 23:19:28.645273 18880 trainer.py:139] Epoch[32/1500] loss: 0.23278350935828301
I0414 23:19:34.642210 18880 trainer.py:139] Epoch[33/1500] loss: 0.23285289589435823
I0414 23:19:39.271722 18880 trainer.py:139] Epoch[34/1500] loss: 0.23303262937453487
I0414 23:19:44.040769 18880 trainer.py:139] Epoch[35/1500] loss: 0.22762833103056876
I0414 23:19:49.221437 18880 trainer.py:139] Epoch[36/1500] loss: 0.22749829724911722
I0414 23:19:55.478505 18880 trainer.py:139] Epoch[37/1500] loss: 0.2263881093071353
I0414 23:20:00.286421 18880 trainer.py:139] Epoch[38/1500] loss: 0.22083436048799945
I0414 23:20:05.044502 18880 trainer.py:139] Epoch[39/1500] loss: 0.2213034192400594
I0414 23:20:09.667038 18880 trainer.py:139] Epoch[40/1500] loss: 0.22059735896125918
I0414 23:20:16.256992 18880 trainer.py:139] Epoch[41/1500] loss: 0.21697703628770768
I0414 23:20:21.269223 18880 trainer.py:139] Epoch[42/1500] loss: 0.21653477030415688
I0414 23:20:26.159863 18880 trainer.py:139] Epoch[43/1500] loss: 0.21146844711995894
I0414 23:20:30.945852 18880 trainer.py:139] Epoch[44/1500] loss: 0.21122156948812545
I0414 23:20:36.873557 18880 trainer.py:139] Epoch[45/1500] loss: 0.2109621628638237
I0414 23:20:42.074158 18880 trainer.py:139] Epoch[46/1500] loss: 0.2118307851975964
I0414 23:20:46.894032 18880 trainer.py:139] Epoch[47/1500] loss: 0.20474222254368565
I0414 23:20:51.696965 18880 trainer.py:139] Epoch[48/1500] loss: 0.20359942365077235
I0414 23:20:56.248738 18880 trainer.py:139] Epoch[49/1500] loss: 0.20760846186068752
I0414 23:20:56.492865 18880 trainer.py:145] Test: {'precision': 0.11750670241286873, 'recall': 0.27579516336928434, 'hit_ratio': 0.8423592493297587, 'ndcg': 0.2579005370955854}
I0414 23:21:02.714561 18880 trainer.py:139] Epoch[50/1500] loss: 0.20395894300553105
I0414 23:21:07.665995 18880 trainer.py:139] Epoch[51/1500] loss: 0.20245857104178397
I0414 23:21:12.363281 18880 trainer.py:139] Epoch[52/1500] loss: 0.20043644789726503
I0414 23:21:16.835319 18880 trainer.py:139] Epoch[53/1500] loss: 0.20140102217274328
I0414 23:21:21.368154 18880 trainer.py:139] Epoch[54/1500] loss: 0.19898199890890428
I0414 23:21:27.777711 18880 trainer.py:139] Epoch[55/1500] loss: 0.19854321595161192
I0414 23:21:32.366788 18880 trainer.py:139] Epoch[56/1500] loss: 0.19612573856307614
I0414 23:21:37.089988 18880 trainer.py:139] Epoch[57/1500] loss: 0.19491008212489466
I0414 23:21:42.157036 18880 trainer.py:139] Epoch[58/1500] loss: 0.19252924669173457
I0414 23:21:46.815452 18880 trainer.py:139] Epoch[59/1500] loss: 0.19422845446294354
I0414 23:21:53.257899 18880 trainer.py:139] Epoch[60/1500] loss: 0.19284973173372208
I0414 23:21:57.931684 18880 trainer.py:139] Epoch[61/1500] loss: 0.18996637819274778
I0414 23:22:02.766509 18880 trainer.py:139] Epoch[62/1500] loss: 0.1918647337344385
I0414 23:22:07.385058 18880 trainer.py:139] Epoch[63/1500] loss: 0.189761642967501
I0414 23:22:11.966731 18880 trainer.py:139] Epoch[64/1500] loss: 0.18905538705087477
I0414 23:22:18.352381 18880 trainer.py:139] Epoch[65/1500] loss: 0.18782861146234697
I0414 23:22:23.111460 18880 trainer.py:139] Epoch[66/1500] loss: 0.1838057214213956
I0414 23:22:27.633748 18880 trainer.py:139] Epoch[67/1500] loss: 0.18551024602305505
I0414 23:22:32.408773 18880 trainer.py:139] Epoch[68/1500] loss: 0.18407376735441147
I0414 23:22:37.175256 18880 trainer.py:139] Epoch[69/1500] loss: 0.18431466577514524
I0414 23:22:43.393453 18880 trainer.py:139] Epoch[70/1500] loss: 0.1860536495524068
I0414 23:22:48.223296 18880 trainer.py:139] Epoch[71/1500] loss: 0.1834697146569529
I0414 23:22:52.737610 18880 trainer.py:139] Epoch[72/1500] loss: 0.18149872028058575
I0414 23:22:57.292374 18880 trainer.py:139] Epoch[73/1500] loss: 0.18184827941079293
I0414 23:23:02.325535 18880 trainer.py:139] Epoch[74/1500] loss: 0.17926367011762434
I0414 23:23:08.438085 18880 trainer.py:139] Epoch[75/1500] loss: 0.1787424034649326
I0414 23:23:13.104450 18880 trainer.py:139] Epoch[76/1500] loss: 0.1775474303191708
I0414 23:23:17.742933 18880 trainer.py:139] Epoch[77/1500] loss: 0.17713952256787208
I0414 23:23:22.489056 18880 trainer.py:139] Epoch[78/1500] loss: 0.17825667992714914
I0414 23:23:28.886651 18880 trainer.py:139] Epoch[79/1500] loss: 0.17536015231763163
I0414 23:23:33.892327 18880 trainer.py:139] Epoch[80/1500] loss: 0.17856103374112037
I0414 23:23:38.750076 18880 trainer.py:139] Epoch[81/1500] loss: 0.17446746028238727
I0414 23:23:43.285901 18880 trainer.py:139] Epoch[82/1500] loss: 0.1743453553607387
I0414 23:23:48.340990 18880 trainer.py:139] Epoch[83/1500] loss: 0.17636896766001178
I0414 23:23:54.428623 18880 trainer.py:139] Epoch[84/1500] loss: 0.17513544328751102
I0414 23:23:59.189696 18880 trainer.py:139] Epoch[85/1500] loss: 0.1708489521857231
I0414 23:24:03.834158 18880 trainer.py:139] Epoch[86/1500] loss: 0.1754268681810748
I0414 23:24:08.384935 18880 trainer.py:139] Epoch[87/1500] loss: 0.1724225926783777
I0414 23:24:14.746652 18880 trainer.py:139] Epoch[88/1500] loss: 0.17145862598573008
I0414 23:24:19.582473 18880 trainer.py:139] Epoch[89/1500] loss: 0.16963616013526917
I0414 23:24:24.337567 18880 trainer.py:139] Epoch[90/1500] loss: 0.1711244261072528
I0414 23:24:28.915251 18880 trainer.py:139] Epoch[91/1500] loss: 0.1685784939796694
I0414 23:24:33.844761 18880 trainer.py:139] Epoch[92/1500] loss: 0.1705129603224416
I0414 23:24:40.390862 18880 trainer.py:139] Epoch[93/1500] loss: 0.16643303440463159
I0414 23:24:45.218710 18880 trainer.py:139] Epoch[94/1500] loss: 0.16803038120269775
I0414 23:24:50.021642 18880 trainer.py:139] Epoch[95/1500] loss: 0.17061435647549167
I0414 23:24:54.829557 18880 trainer.py:139] Epoch[96/1500] loss: 0.16562334904747625
I0414 23:24:59.555746 18880 trainer.py:139] Epoch[97/1500] loss: 0.16582977339144675
I0414 23:25:06.063974 18880 trainer.py:139] Epoch[98/1500] loss: 0.16723245718786794
I0414 23:25:10.699466 18880 trainer.py:139] Epoch[99/1500] loss: 0.16857345690650324
I0414 23:25:10.940659 18880 trainer.py:145] Test: {'precision': 0.12619302949061667, 'recall': 0.2979073553967105, 'hit_ratio': 0.8632707774798928, 'ndcg': 0.27896021471577864}
I0414 23:25:15.588111 18880 trainer.py:139] Epoch[100/1500] loss: 0.1638575215493479
I0414 23:25:20.241544 18880 trainer.py:139] Epoch[101/1500] loss: 0.16308150464488613
I0414 23:25:24.929860 18880 trainer.py:139] Epoch[102/1500] loss: 0.16185099222967703
I0414 23:25:31.365330 18880 trainer.py:139] Epoch[103/1500] loss: 0.16343047013205866
I0414 23:25:36.011785 18880 trainer.py:139] Epoch[104/1500] loss: 0.16292931524015242
I0414 23:25:40.726014 18880 trainer.py:139] Epoch[105/1500] loss: 0.1614797778667942
I0414 23:25:45.400377 18880 trainer.py:139] Epoch[106/1500] loss: 0.16218108515585622
I0414 23:25:50.384702 18880 trainer.py:139] Epoch[107/1500] loss: 0.16329683699915487
I0414 23:25:56.282414 18880 trainer.py:139] Epoch[108/1500] loss: 0.16183260275471595
I0414 23:26:01.054450 18880 trainer.py:139] Epoch[109/1500] loss: 0.16063471138477325
I0414 23:26:05.755722 18880 trainer.py:139] Epoch[110/1500] loss: 0.16165053315701022
I0414 23:26:10.556661 18880 trainer.py:139] Epoch[111/1500] loss: 0.1608356713287292
I0414 23:26:15.565902 18880 trainer.py:139] Epoch[112/1500] loss: 0.15771440152199037
I0414 23:26:21.634601 18880 trainer.py:139] Epoch[113/1500] loss: 0.15829844820883968
I0414 23:26:26.436961 18880 trainer.py:139] Epoch[114/1500] loss: 0.15788457903169817
I0414 23:26:31.027604 18880 trainer.py:139] Epoch[115/1500] loss: 0.15635776039092772
I0414 23:26:35.779946 18880 trainer.py:139] Epoch[116/1500] loss: 0.15571857123605667
I0414 23:26:41.449490 18880 trainer.py:139] Epoch[117/1500] loss: 0.15667785752204158
I0414 23:26:46.924176 18880 trainer.py:139] Epoch[118/1500] loss: 0.15665663298099272
I0414 23:26:51.624451 18880 trainer.py:139] Epoch[119/1500] loss: 0.15712864024023857
I0414 23:26:55.984285 18880 trainer.py:139] Epoch[120/1500] loss: 0.15675162259609468
I0414 23:27:00.629209 18880 trainer.py:139] Epoch[121/1500] loss: 0.1539597141165887
I0414 23:27:06.909203 18880 trainer.py:139] Epoch[122/1500] loss: 0.15501121311418473
I0414 23:27:11.948342 18880 trainer.py:139] Epoch[123/1500] loss: 0.1560306856709142
I0414 23:27:16.398454 18880 trainer.py:139] Epoch[124/1500] loss: 0.15499625523244182
I0414 23:27:21.140591 18880 trainer.py:139] Epoch[125/1500] loss: 0.15514328402857627
I0414 23:27:25.884720 18880 trainer.py:139] Epoch[126/1500] loss: 0.15247527678166667
I0414 23:27:32.360501 18880 trainer.py:139] Epoch[127/1500] loss: 0.15301017943889864
I0414 23:27:36.994001 18880 trainer.py:139] Epoch[128/1500] loss: 0.15283969813777554
I0414 23:27:41.655491 18880 trainer.py:139] Epoch[129/1500] loss: 0.15232725585660628
I0414 23:27:46.433507 18880 trainer.py:139] Epoch[130/1500] loss: 0.1534290030117958
I0414 23:27:51.064016 18880 trainer.py:139] Epoch[131/1500] loss: 0.15120223020353624
I0414 23:27:57.831377 18880 trainer.py:139] Epoch[132/1500] loss: 0.15408391000763064
I0414 23:28:02.376173 18880 trainer.py:139] Epoch[133/1500] loss: 0.15149818024327677
I0414 23:28:06.875121 18880 trainer.py:139] Epoch[134/1500] loss: 0.15154135804022512
I0414 23:28:11.507629 18880 trainer.py:139] Epoch[135/1500] loss: 0.15250620534343104
I0414 23:28:16.267700 18880 trainer.py:139] Epoch[136/1500] loss: 0.15226492574138026
I0414 23:28:22.545698 18880 trainer.py:139] Epoch[137/1500] loss: 0.1504614160906884
I0414 23:28:27.292816 18880 trainer.py:139] Epoch[138/1500] loss: 0.14796163862751377
I0414 23:28:32.004056 18880 trainer.py:139] Epoch[139/1500] loss: 0.14614739773734922
I0414 23:28:36.554831 18880 trainer.py:139] Epoch[140/1500] loss: 0.14970948667295517
I0414 23:28:41.235498 18880 trainer.py:139] Epoch[141/1500] loss: 0.15094471506534085
I0414 23:28:47.863325 18880 trainer.py:139] Epoch[142/1500] loss: 0.1485489481879819
I0414 23:28:52.524731 18880 trainer.py:139] Epoch[143/1500] loss: 0.1481388682319272
I0414 23:28:57.052583 18880 trainer.py:139] Epoch[144/1500] loss: 0.14865882790857746
I0414 23:29:01.777776 18880 trainer.py:139] Epoch[145/1500] loss: 0.14749963389288995
I0414 23:29:07.141831 18880 trainer.py:139] Epoch[146/1500] loss: 0.14733442375736852
I0414 23:29:12.902623 18880 trainer.py:139] Epoch[147/1500] loss: 0.14598252215693075
I0414 23:29:17.631802 18880 trainer.py:139] Epoch[148/1500] loss: 0.14661034989741542
I0414 23:29:22.230417 18880 trainer.py:139] Epoch[149/1500] loss: 0.1464152369768389
I0414 23:29:22.473605 18880 trainer.py:145] Test: {'precision': 0.12906166219839152, 'recall': 0.3045121109243489, 'hit_ratio': 0.8729222520107238, 'ndcg': 0.28637219980212525}
I0414 23:29:27.277532 18880 trainer.py:139] Epoch[150/1500] loss: 0.1459247109390074
I0414 23:29:32.464129 18880 trainer.py:139] Epoch[151/1500] loss: 0.14740280134062614
I0414 23:29:38.402767 18880 trainer.py:139] Epoch[152/1500] loss: 0.14687514785797365
I0414 23:29:43.262510 18880 trainer.py:139] Epoch[153/1500] loss: 0.14509100226625318
I0414 23:29:47.968765 18880 trainer.py:139] Epoch[154/1500] loss: 0.14628898616760008
I0414 23:29:52.524524 18880 trainer.py:139] Epoch[155/1500] loss: 0.14567099896169478
I0414 23:29:58.976937 18880 trainer.py:139] Epoch[156/1500] loss: 0.143778653875474
I0414 23:30:03.745984 18880 trainer.py:139] Epoch[157/1500] loss: 0.1429414080996667
I0414 23:30:08.467189 18880 trainer.py:139] Epoch[158/1500] loss: 0.14309150701568973
I0414 23:30:13.152514 18880 trainer.py:139] Epoch[159/1500] loss: 0.14495349891724124
I0414 23:30:17.793987 18880 trainer.py:139] Epoch[160/1500] loss: 0.14284472215560176
I0414 23:30:24.203545 18880 trainer.py:139] Epoch[161/1500] loss: 0.14496227666254966
I0414 23:30:29.076244 18880 trainer.py:139] Epoch[162/1500] loss: 0.14283893569823233
I0414 23:30:33.955919 18880 trainer.py:139] Epoch[163/1500] loss: 0.1428251886560071
I0414 23:30:38.682107 18880 trainer.py:139] Epoch[164/1500] loss: 0.1421648182215229
I0414 23:30:44.662103 18880 trainer.py:139] Epoch[165/1500] loss: 0.1415292380317565
I0414 23:30:49.994266 18880 trainer.py:139] Epoch[166/1500] loss: 0.1437448219906899
I0414 23:30:54.903839 18880 trainer.py:139] Epoch[167/1500] loss: 0.14237500679108403
I0414 23:30:59.672884 18880 trainer.py:139] Epoch[168/1500] loss: 0.14287409522841055
I0414 23:31:05.391755 18880 trainer.py:139] Epoch[169/1500] loss: 0.14162150217640784
I0414 23:31:11.221251 18880 trainer.py:139] Epoch[170/1500] loss: 0.14151168927069632
I0414 23:31:16.049100 18880 trainer.py:139] Epoch[171/1500] loss: 0.14011669351208594
I0414 23:31:20.806186 18880 trainer.py:139] Epoch[172/1500] loss: 0.1403286995426301
I0414 23:31:27.314414 18880 trainer.py:139] Epoch[173/1500] loss: 0.13996602835193758
I0414 23:31:32.272763 18880 trainer.py:139] Epoch[174/1500] loss: 0.1412238084500836
I0414 23:31:37.081589 18880 trainer.py:139] Epoch[175/1500] loss: 0.14071899075661937
I0414 23:31:41.917917 18880 trainer.py:139] Epoch[176/1500] loss: 0.14098471883804567
I0414 23:31:47.873991 18880 trainer.py:139] Epoch[177/1500] loss: 0.14009715953180868
I0414 23:31:53.463291 18880 trainer.py:139] Epoch[178/1500] loss: 0.13789042686262437
I0414 23:31:58.342967 18880 trainer.py:139] Epoch[179/1500] loss: 0.13926505898275682
I0414 23:32:02.982447 18880 trainer.py:139] Epoch[180/1500] loss: 0.1371267404287092
I0414 23:32:07.976739 18880 trainer.py:139] Epoch[181/1500] loss: 0.1401438674619121
I0414 23:32:14.229821 18880 trainer.py:139] Epoch[182/1500] loss: 0.13784309452579868
I0414 23:32:19.300855 18880 trainer.py:139] Epoch[183/1500] loss: 0.13846949944573064
I0414 23:32:24.323053 18880 trainer.py:139] Epoch[184/1500] loss: 0.1391222236617919
I0414 23:32:29.123994 18880 trainer.py:139] Epoch[185/1500] loss: 0.13975791729265644
I0414 23:32:35.918262 18880 trainer.py:139] Epoch[186/1500] loss: 0.13739729384260793
I0414 23:32:40.730164 18880 trainer.py:139] Epoch[187/1500] loss: 0.13958169327628228
I0414 23:32:45.466320 18880 trainer.py:139] Epoch[188/1500] loss: 0.1364625375117025
I0414 23:32:50.484534 18880 trainer.py:139] Epoch[189/1500] loss: 0.13715267710147366
I0414 23:32:56.699225 18880 trainer.py:139] Epoch[190/1500] loss: 0.1374703727422222
I0414 23:33:01.285880 18880 trainer.py:139] Epoch[191/1500] loss: 0.13681927731921595
I0414 23:33:05.939313 18880 trainer.py:139] Epoch[192/1500] loss: 0.13900245918381599
I0414 23:33:10.654537 18880 trainer.py:139] Epoch[193/1500] loss: 0.13734401257768755
I0414 23:33:15.594013 18880 trainer.py:139] Epoch[194/1500] loss: 0.13575950793681607
I0414 23:33:21.848091 18880 trainer.py:139] Epoch[195/1500] loss: 0.13382358536604913
I0414 23:33:26.695872 18880 trainer.py:139] Epoch[196/1500] loss: 0.13901383694141142
I0414 23:33:31.205785 18880 trainer.py:139] Epoch[197/1500] loss: 0.13585808825108311
I0414 23:33:35.862207 18880 trainer.py:139] Epoch[198/1500] loss: 0.13615525297580228
I0414 23:33:40.653181 18880 trainer.py:139] Epoch[199/1500] loss: 0.13590261532414344
I0414 23:33:41.004009 18880 trainer.py:145] Test: {'precision': 0.13201072386058987, 'recall': 0.3120521349456061, 'hit_ratio': 0.8831099195710456, 'ndcg': 0.29362797338475194}
I0414 23:33:47.100611 18880 trainer.py:139] Epoch[200/1500] loss: 0.13804418858020537
I0414 23:33:51.692250 18880 trainer.py:139] Epoch[201/1500] loss: 0.1373318289556811
I0414 23:33:56.347676 18880 trainer.py:139] Epoch[202/1500] loss: 0.1351287523584981
I0414 23:34:01.181505 18880 trainer.py:139] Epoch[203/1500] loss: 0.13658539710506315
I0414 23:34:05.936605 18880 trainer.py:139] Epoch[204/1500] loss: 0.13501658506931796
I0414 23:34:12.015269 18880 trainer.py:139] Epoch[205/1500] loss: 0.13468708386344294
I0414 23:34:16.637808 18880 trainer.py:139] Epoch[206/1500] loss: 0.13401228958560574
I0414 23:34:21.312169 18880 trainer.py:139] Epoch[207/1500] loss: 0.13495656126929867
I0414 23:34:25.827064 18880 trainer.py:139] Epoch[208/1500] loss: 0.13401825437622686
I0414 23:34:31.663999 18880 trainer.py:139] Epoch[209/1500] loss: 0.13456142189041262
I0414 23:34:36.811215 18880 trainer.py:139] Epoch[210/1500] loss: 0.13154021362143178
I0414 23:34:41.550361 18880 trainer.py:139] Epoch[211/1500] loss: 0.134048271323404
I0414 23:34:46.029375 18880 trainer.py:139] Epoch[212/1500] loss: 0.1330238924391808
I0414 23:34:50.683805 18880 trainer.py:139] Epoch[213/1500] loss: 0.13460554687246198
I0414 23:34:56.817259 18880 trainer.py:139] Epoch[214/1500] loss: 0.13254811903161387
I0414 23:35:01.773714 18880 trainer.py:139] Epoch[215/1500] loss: 0.13322743989767566
I0414 23:35:06.562693 18880 trainer.py:139] Epoch[216/1500] loss: 0.13410830425639306
I0414 23:35:11.191208 18880 trainer.py:139] Epoch[217/1500] loss: 0.13378852461614915
I0414 23:35:15.810755 18880 trainer.py:139] Epoch[218/1500] loss: 0.13148692418490687
I0414 23:35:22.277620 18880 trainer.py:139] Epoch[219/1500] loss: 0.13349987254027398
I0414 23:35:26.915107 18880 trainer.py:139] Epoch[220/1500] loss: 0.13199023301562957
I0414 23:35:31.407080 18880 trainer.py:139] Epoch[221/1500] loss: 0.132735576841139
I0414 23:35:36.129282 18880 trainer.py:139] Epoch[222/1500] loss: 0.13218542837327527
I0414 23:35:40.959123 18880 trainer.py:139] Epoch[223/1500] loss: 0.12968268269492733
I0414 23:35:47.131474 18880 trainer.py:139] Epoch[224/1500] loss: 0.13139844229144435
I0414 23:35:51.730089 18880 trainer.py:139] Epoch[225/1500] loss: 0.12993767617210264
I0414 23:35:56.401462 18880 trainer.py:139] Epoch[226/1500] loss: 0.1314119939361849
I0414 23:36:01.212367 18880 trainer.py:139] Epoch[227/1500] loss: 0.12880735483861738
I0414 23:36:05.939553 18880 trainer.py:139] Epoch[228/1500] loss: 0.13094282991463138
I0414 23:36:12.255423 18880 trainer.py:139] Epoch[229/1500] loss: 0.1315541123190234
I0414 23:36:16.998555 18880 trainer.py:139] Epoch[230/1500] loss: 0.13087298865279845
I0414 23:36:21.541357 18880 trainer.py:139] Epoch[231/1500] loss: 0.128657286686282
I0414 23:36:26.587478 18880 trainer.py:139] Epoch[232/1500] loss: 0.13042976683185947
I0414 23:36:32.596376 18880 trainer.py:139] Epoch[233/1500] loss: 0.1308720342574581
I0414 23:36:37.181037 18880 trainer.py:139] Epoch[234/1500] loss: 0.13077303839306678
I0414 23:36:41.911212 18880 trainer.py:139] Epoch[235/1500] loss: 0.1280332423986927
I0414 23:36:46.657336 18880 trainer.py:139] Epoch[236/1500] loss: 0.12926511778946845
I0414 23:36:51.546977 18880 trainer.py:139] Epoch[237/1500] loss: 0.1306379629719642
I0414 23:36:57.523982 18880 trainer.py:139] Epoch[238/1500] loss: 0.1270086416794408
I0414 23:37:02.215286 18880 trainer.py:139] Epoch[239/1500] loss: 0.13056786166083428
I0414 23:37:06.758089 18880 trainer.py:139] Epoch[240/1500] loss: 0.12803347336669121
I0414 23:37:11.390592 18880 trainer.py:139] Epoch[241/1500] loss: 0.12978958458669723
I0414 23:37:16.402825 18880 trainer.py:139] Epoch[242/1500] loss: 0.1274941537168718
I0414 23:37:22.373848 18880 trainer.py:139] Epoch[243/1500] loss: 0.12959583247861556
I0414 23:37:26.871801 18880 trainer.py:139] Epoch[244/1500] loss: 0.1296624668663548
I0414 23:37:31.497327 18880 trainer.py:139] Epoch[245/1500] loss: 0.13006535677179212
I0414 23:37:36.442782 18880 trainer.py:139] Epoch[246/1500] loss: 0.12833985157551303
I0414 23:37:41.996206 18880 trainer.py:139] Epoch[247/1500] loss: 0.1286830842014282
I0414 23:37:47.338340 18880 trainer.py:139] Epoch[248/1500] loss: 0.12788072588943666
I0414 23:37:51.868185 18880 trainer.py:139] Epoch[249/1500] loss: 0.12890372112874063
I0414 23:37:52.143265 18880 trainer.py:145] Test: {'precision': 0.13461126005361934, 'recall': 0.31767569837511506, 'hit_ratio': 0.8884718498659517, 'ndcg': 0.2976681457226884}
I0414 23:37:56.975102 18880 trainer.py:139] Epoch[250/1500] loss: 0.1282139490208318
I0414 23:38:01.465080 18880 trainer.py:139] Epoch[251/1500] loss: 0.12826818756518826
I0414 23:38:07.570656 18880 trainer.py:139] Epoch[252/1500] loss: 0.12714069096311445
I0414 23:38:12.552986 18880 trainer.py:139] Epoch[253/1500] loss: 0.12865318045500787
I0414 23:38:17.185995 18880 trainer.py:139] Epoch[254/1500] loss: 0.12662611733521184
I0414 23:38:22.102546 18880 trainer.py:139] Epoch[255/1500] loss: 0.12702606378063078
I0414 23:38:26.630398 18880 trainer.py:139] Epoch[256/1500] loss: 0.12678272229048512
I0414 23:38:33.080820 18880 trainer.py:139] Epoch[257/1500] loss: 0.12740451169590797
I0414 23:38:37.770132 18880 trainer.py:139] Epoch[258/1500] loss: 0.1271776331047858
I0414 23:38:42.321904 18880 trainer.py:139] Epoch[259/1500] loss: 0.12563953356396768
I0414 23:38:47.095934 18880 trainer.py:139] Epoch[260/1500] loss: 0.1287053061589118
I0414 23:38:51.668636 18880 trainer.py:139] Epoch[261/1500] loss: 0.12801951722752664
I0414 23:38:57.566904 18880 trainer.py:139] Epoch[262/1500] loss: 0.12754062827556364
I0414 23:39:02.763973 18880 trainer.py:139] Epoch[263/1500] loss: 0.1257932868696028
I0414 23:39:07.490161 18880 trainer.py:139] Epoch[264/1500] loss: 0.1273701029919809
I0414 23:39:12.181468 18880 trainer.py:139] Epoch[265/1500] loss: 0.12436899831218104
I0414 23:39:16.801012 18880 trainer.py:139] Epoch[266/1500] loss: 0.12708523004285752
I0414 23:39:23.066053 18880 trainer.py:139] Epoch[267/1500] loss: 0.12635027905625681
I0414 23:39:27.951709 18880 trainer.py:139] Epoch[268/1500] loss: 0.12653698796226132
I0414 23:39:32.781551 18880 trainer.py:139] Epoch[269/1500] loss: 0.12753633577977458
I0414 23:39:37.393533 18880 trainer.py:139] Epoch[270/1500] loss: 0.12590088695287704
I0414 23:39:41.904442 18880 trainer.py:139] Epoch[271/1500] loss: 0.1257439546527401
I0414 23:39:47.941246 18880 trainer.py:139] Epoch[272/1500] loss: 0.12593015980335973
I0414 23:39:52.711288 18880 trainer.py:139] Epoch[273/1500] loss: 0.12648178252481646
I0414 23:39:57.407578 18880 trainer.py:139] Epoch[274/1500] loss: 0.12599831723397778
I0414 23:40:02.038087 18880 trainer.py:139] Epoch[275/1500] loss: 0.12652689146418725
I0414 23:40:06.592850 18880 trainer.py:139] Epoch[276/1500] loss: 0.12523986279003083
I0414 23:40:12.901743 18880 trainer.py:139] Epoch[277/1500] loss: 0.12512713093911448
I0414 23:40:17.495376 18880 trainer.py:139] Epoch[278/1500] loss: 0.12399895825693684
I0414 23:40:22.300301 18880 trainer.py:139] Epoch[279/1500] loss: 0.12348917294894496
I0414 23:40:26.956723 18880 trainer.py:139] Epoch[280/1500] loss: 0.12478045422223306
I0414 23:40:31.702845 18880 trainer.py:139] Epoch[281/1500] loss: 0.1253393650535614
I0414 23:40:38.056589 18880 trainer.py:139] Epoch[282/1500] loss: 0.12361654711346473
I0414 23:40:42.744905 18880 trainer.py:139] Epoch[283/1500] loss: 0.12384495547702236
I0414 23:40:47.245847 18880 trainer.py:139] Epoch[284/1500] loss: 0.12468769954096887
I0414 23:40:51.856423 18880 trainer.py:139] Epoch[285/1500] loss: 0.12240177561198512
I0414 23:40:56.935433 18880 trainer.py:139] Epoch[286/1500] loss: 0.12529019771083708
I0414 23:41:03.057949 18880 trainer.py:139] Epoch[287/1500] loss: 0.12372078938830283
I0414 23:41:07.630653 18880 trainer.py:139] Epoch[288/1500] loss: 0.12101737962615106
I0414 23:41:12.221295 18880 trainer.py:139] Epoch[289/1500] loss: 0.12364318990899671
I0414 23:41:17.082033 18880 trainer.py:139] Epoch[290/1500] loss: 0.12507896245487274
I0414 23:41:23.346078 18880 trainer.py:139] Epoch[291/1500] loss: 0.12412941455841064
I0414 23:41:28.167946 18880 trainer.py:139] Epoch[292/1500] loss: 0.124313201154432
I0414 23:41:32.946958 18880 trainer.py:139] Epoch[293/1500] loss: 0.12455979133805921
I0414 23:41:37.455874 18880 trainer.py:139] Epoch[294/1500] loss: 0.12317723444392605
I0414 23:41:42.016617 18880 trainer.py:139] Epoch[295/1500] loss: 0.12351716453990629
I0414 23:41:48.376340 18880 trainer.py:139] Epoch[296/1500] loss: 0.1225768991055027
I0414 23:41:53.090569 18880 trainer.py:139] Epoch[297/1500] loss: 0.12282414662261162
I0414 23:41:57.712109 18880 trainer.py:139] Epoch[298/1500] loss: 0.12296179682016373
I0414 23:42:02.410391 18880 trainer.py:139] Epoch[299/1500] loss: 0.12282015936028573
I0414 23:42:02.664540 18880 trainer.py:145] Test: {'precision': 0.13493297587131373, 'recall': 0.3179773553121606, 'hit_ratio': 0.8857908847184987, 'ndcg': 0.2997263978898766}
I0414 23:42:07.637903 18880 trainer.py:139] Epoch[300/1500] loss: 0.12121017781957504
I0414 23:42:13.530190 18880 trainer.py:139] Epoch[301/1500] loss: 0.1223707833597737
I0414 23:42:18.231463 18880 trainer.py:139] Epoch[302/1500] loss: 0.12262487459567285
I0414 23:42:22.895858 18880 trainer.py:139] Epoch[303/1500] loss: 0.12270489647503822
I0414 23:42:27.543310 18880 trainer.py:139] Epoch[304/1500] loss: 0.12129205609521558
I0414 23:42:32.652724 18880 trainer.py:139] Epoch[305/1500] loss: 0.12178995916920324
I0414 23:42:38.327738 18880 trainer.py:139] Epoch[306/1500] loss: 0.12270430667746451
I0414 23:42:43.024027 18880 trainer.py:139] Epoch[307/1500] loss: 0.12287427484989166
I0414 23:42:47.730283 18880 trainer.py:139] Epoch[308/1500] loss: 0.12155015550313457
I0414 23:42:52.559128 18880 trainer.py:139] Epoch[309/1500] loss: 0.12385031148310631
I0414 23:42:58.016870 18880 trainer.py:139] Epoch[310/1500] loss: 0.12226097069440349
I0414 23:43:03.670955 18880 trainer.py:139] Epoch[311/1500] loss: 0.12305381966214027
I0414 23:43:08.513754 18880 trainer.py:139] Epoch[312/1500] loss: 0.12224686482260304
I0414 23:43:12.989780 18880 trainer.py:139] Epoch[313/1500] loss: 0.1210556119199722
I0414 23:43:17.609326 18880 trainer.py:139] Epoch[314/1500] loss: 0.12273590819489572
I0414 23:43:22.241830 18880 trainer.py:139] Epoch[315/1500] loss: 0.12344386548765245
I0414 23:43:28.662348 18880 trainer.py:139] Epoch[316/1500] loss: 0.12349323039093325
I0414 23:43:33.438373 18880 trainer.py:139] Epoch[317/1500] loss: 0.1204949886568131
I0414 23:43:38.127684 18880 trainer.py:139] Epoch[318/1500] loss: 0.12189267792047993
I0414 23:43:42.615669 18880 trainer.py:139] Epoch[319/1500] loss: 0.12153331454723112
I0414 23:43:47.708632 18880 trainer.py:139] Epoch[320/1500] loss: 0.12190401842517237
I0414 23:43:53.761382 18880 trainer.py:139] Epoch[321/1500] loss: 0.12006422060151253
I0414 23:43:58.380928 18880 trainer.py:139] Epoch[322/1500] loss: 0.12099313759996046
I0414 23:44:03.092110 18880 trainer.py:139] Epoch[323/1500] loss: 0.12177284975205699
I0414 23:44:08.002682 18880 trainer.py:139] Epoch[324/1500] loss: 0.11988314625716978
I0414 23:44:13.031861 18880 trainer.py:139] Epoch[325/1500] loss: 0.1211505118877657
I0414 23:44:18.967999 18880 trainer.py:139] Epoch[326/1500] loss: 0.12215683392940029
I0414 23:44:23.644355 18880 trainer.py:139] Epoch[327/1500] loss: 0.11930590579586645
I0414 23:44:28.317720 18880 trainer.py:139] Epoch[328/1500] loss: 0.12035925590222882
I0414 23:44:32.944242 18880 trainer.py:139] Epoch[329/1500] loss: 0.12132791045211977
I0414 23:44:38.192685 18880 trainer.py:139] Epoch[330/1500] loss: 0.12245939503754338
I0414 23:44:43.898597 18880 trainer.py:139] Epoch[331/1500] loss: 0.11867322364161091
I0414 23:44:48.510167 18880 trainer.py:139] Epoch[332/1500] loss: 0.12219799382071342
I0414 23:44:53.142671 18880 trainer.py:139] Epoch[333/1500] loss: 0.11950609736865567
I0414 23:44:58.011384 18880 trainer.py:139] Epoch[334/1500] loss: 0.12013210981122908
I0414 23:45:03.719288 18880 trainer.py:139] Epoch[335/1500] loss: 0.11862258565041327
I0414 23:45:09.013575 18880 trainer.py:139] Epoch[336/1500] loss: 0.11862652051833368
I0414 23:45:13.736774 18880 trainer.py:139] Epoch[337/1500] loss: 0.12029902516834197
I0414 23:45:18.335391 18880 trainer.py:139] Epoch[338/1500] loss: 0.11927833384083163
I0414 23:45:22.932012 18880 trainer.py:139] Epoch[339/1500] loss: 0.12055713779503299
I0414 23:45:28.949973 18880 trainer.py:139] Epoch[340/1500] loss: 0.11990706959078389
I0414 23:45:33.851574 18880 trainer.py:139] Epoch[341/1500] loss: 0.12104435120859454
I0414 23:45:38.437233 18880 trainer.py:139] Epoch[342/1500] loss: 0.1200399802577111
I0414 23:45:42.991428 18880 trainer.py:139] Epoch[343/1500] loss: 0.12011438055384543
I0414 23:45:47.453501 18880 trainer.py:139] Epoch[344/1500] loss: 0.11914454568778315
I0414 23:45:53.565056 18880 trainer.py:139] Epoch[345/1500] loss: 0.12146798160768324
I0414 23:45:58.317157 18880 trainer.py:139] Epoch[346/1500] loss: 0.11956719501364615
I0414 23:46:03.292512 18880 trainer.py:139] Epoch[347/1500] loss: 0.11973652459921376
I0414 23:46:07.750599 18880 trainer.py:139] Epoch[348/1500] loss: 0.11783772706985474
I0414 23:46:12.425958 18880 trainer.py:139] Epoch[349/1500] loss: 0.12006265694095243
I0414 23:46:12.693064 18880 trainer.py:145] Test: {'precision': 0.13646112600536203, 'recall': 0.3228579483562926, 'hit_ratio': 0.8911528150134048, 'ndcg': 0.3033130574891672}
I0414 23:46:19.056775 18880 trainer.py:139] Epoch[350/1500] loss: 0.11818324462060005
I0414 23:46:23.949407 18880 trainer.py:139] Epoch[351/1500] loss: 0.1181795070728948
I0414 23:46:28.352651 18880 trainer.py:139] Epoch[352/1500] loss: 0.11820985256664214
I0414 23:46:32.906418 18880 trainer.py:139] Epoch[353/1500] loss: 0.11792489790147351
I0414 23:46:38.053200 18880 trainer.py:139] Epoch[354/1500] loss: 0.11768707777223279
I0414 23:46:43.831866 18880 trainer.py:139] Epoch[355/1500] loss: 0.11956311762332916
I0414 23:46:48.403574 18880 trainer.py:139] Epoch[356/1500] loss: 0.1202119620096299
I0414 23:46:53.109289 18880 trainer.py:139] Epoch[357/1500] loss: 0.11770328062195931
I0414 23:46:57.614218 18880 trainer.py:139] Epoch[358/1500] loss: 0.11805839620290264
I0414 23:47:03.167086 18880 trainer.py:139] Epoch[359/1500] loss: 0.11911099668472044
I0414 23:47:08.529145 18880 trainer.py:139] Epoch[360/1500] loss: 0.11875571791202791
I0414 23:47:13.199521 18880 trainer.py:139] Epoch[361/1500] loss: 0.11822878737603465
I0414 23:47:18.005443 18880 trainer.py:139] Epoch[362/1500] loss: 0.11930656601344386
I0414 23:47:22.507382 18880 trainer.py:139] Epoch[363/1500] loss: 0.1199682104972101
I0414 23:47:28.526247 18880 trainer.py:139] Epoch[364/1500] loss: 0.11730836596219771
I0414 23:47:33.399877 18880 trainer.py:139] Epoch[365/1500] loss: 0.11748962897446848
I0414 23:47:37.870427 18880 trainer.py:139] Epoch[366/1500] loss: 0.11887305350072923
I0414 23:47:42.446120 18880 trainer.py:139] Epoch[367/1500] loss: 0.1174653398413812
I0414 23:47:47.197225 18880 trainer.py:139] Epoch[368/1500] loss: 0.11852689640175912
I0414 23:47:53.512099 18880 trainer.py:139] Epoch[369/1500] loss: 0.11732870484552076
I0414 23:47:58.451575 18880 trainer.py:139] Epoch[370/1500] loss: 0.11662880499516765
I0414 23:48:03.287396 18880 trainer.py:139] Epoch[371/1500] loss: 0.1184607270744539
I0414 23:48:08.085346 18880 trainer.py:139] Epoch[372/1500] loss: 0.11795527920607597
I0414 23:48:12.749743 18880 trainer.py:139] Epoch[373/1500] loss: 0.12054763710306536
I0414 23:48:19.155268 18880 trainer.py:139] Epoch[374/1500] loss: 0.11865358294979218
I0414 23:48:23.805710 18880 trainer.py:139] Epoch[375/1500] loss: 0.11852382844494234
I0414 23:48:28.490038 18880 trainer.py:139] Epoch[376/1500] loss: 0.11753520441632118
I0414 23:48:33.083671 18880 trainer.py:139] Epoch[377/1500] loss: 0.117491303192031
I0414 23:48:38.277297 18880 trainer.py:139] Epoch[378/1500] loss: 0.1180171630074901
I0414 23:48:44.100290 18880 trainer.py:139] Epoch[379/1500] loss: 0.11989527051487277
I0414 23:48:48.804551 18880 trainer.py:139] Epoch[380/1500] loss: 0.11693122069681844
I0414 23:48:53.689210 18880 trainer.py:139] Epoch[381/1500] loss: 0.11849920812153047
I0414 23:48:58.181184 18880 trainer.py:139] Epoch[382/1500] loss: 0.11898771024519397
I0414 23:49:02.881459 18880 trainer.py:139] Epoch[383/1500] loss: 0.11697462801971743
I0414 23:49:09.131455 18880 trainer.py:139] Epoch[384/1500] loss: 0.11724621057510376
I0414 23:49:13.906480 18880 trainer.py:139] Epoch[385/1500] loss: 0.11754650790845195
I0414 23:49:18.672537 18880 trainer.py:139] Epoch[386/1500] loss: 0.11855021551732094
I0414 23:49:23.123644 18880 trainer.py:139] Epoch[387/1500] loss: 0.11740389225944396
I0414 23:49:28.229564 18880 trainer.py:139] Epoch[388/1500] loss: 0.11752819798646434
I0414 23:49:33.849740 18880 trainer.py:139] Epoch[389/1500] loss: 0.11656490617221402
I0414 23:49:38.524102 18880 trainer.py:139] Epoch[390/1500] loss: 0.11544261656461223
I0414 23:49:43.232351 18880 trainer.py:139] Epoch[391/1500] loss: 0.11718024553791169
I0414 23:49:47.698869 18880 trainer.py:139] Epoch[392/1500] loss: 0.11775198074117783
I0414 23:49:52.916416 18880 trainer.py:139] Epoch[393/1500] loss: 0.11600743642737789
I0414 23:49:58.820663 18880 trainer.py:139] Epoch[394/1500] loss: 0.11699309824935851
I0414 23:50:03.633561 18880 trainer.py:139] Epoch[395/1500] loss: 0.1174174405394062
I0414 23:50:08.283008 18880 trainer.py:139] Epoch[396/1500] loss: 0.11532907596518917
I0414 23:50:12.871656 18880 trainer.py:139] Epoch[397/1500] loss: 0.11506015927560868
I0414 23:50:18.599495 18880 trainer.py:139] Epoch[398/1500] loss: 0.11591655448559791
I0414 23:50:23.751260 18880 trainer.py:139] Epoch[399/1500] loss: 0.11833405110143846
I0414 23:50:24.013384 18880 trainer.py:145] Test: {'precision': 0.13678284182305636, 'recall': 0.3221307280044074, 'hit_ratio': 0.892225201072386, 'ndcg': 0.3038485001766669}
I0414 23:50:28.700701 18880 trainer.py:139] Epoch[400/1500] loss: 0.1177796017258398
I0414 23:50:33.464764 18880 trainer.py:139] Epoch[401/1500] loss: 0.11650630999957362
I0414 23:50:38.237798 18880 trainer.py:139] Epoch[402/1500] loss: 0.11636715190064523
I0414 23:50:44.564631 18880 trainer.py:139] Epoch[403/1500] loss: 0.11445404541107916
I0414 23:50:49.024162 18880 trainer.py:139] Epoch[404/1500] loss: 0.11531811135430489
I0414 23:50:53.860980 18880 trainer.py:139] Epoch[405/1500] loss: 0.1182406979703134
I0414 23:50:58.667899 18880 trainer.py:139] Epoch[406/1500] loss: 0.11640561684485405
I0414 23:51:03.366184 18880 trainer.py:139] Epoch[407/1500] loss: 0.11664629415158302
I0414 23:51:09.734875 18880 trainer.py:139] Epoch[408/1500] loss: 0.11461438911576424
I0414 23:51:14.322457 18880 trainer.py:139] Epoch[409/1500] loss: 0.11530531894776129
I0414 23:51:19.073071 18880 trainer.py:139] Epoch[410/1500] loss: 0.11609816767515675
I0414 23:51:23.921292 18880 trainer.py:139] Epoch[411/1500] loss: 0.11521949354679353
I0414 23:51:28.666416 18880 trainer.py:139] Epoch[412/1500] loss: 0.11614676492829476
I0414 23:51:35.079412 18880 trainer.py:139] Epoch[413/1500] loss: 0.11524077697146323
I0414 23:51:39.773710 18880 trainer.py:139] Epoch[414/1500] loss: 0.11471009566899269
I0414 23:51:44.391262 18880 trainer.py:139] Epoch[415/1500] loss: 0.11531018249450191
I0414 23:51:49.002834 18880 trainer.py:139] Epoch[416/1500] loss: 0.11480600555096904
I0414 23:51:53.582513 18880 trainer.py:139] Epoch[417/1500] loss: 0.1166947046595235
I0414 23:52:00.043897 18880 trainer.py:139] Epoch[418/1500] loss: 0.11404568461641189
I0414 23:52:04.687267 18880 trainer.py:139] Epoch[419/1500] loss: 0.11539011833167845
I0414 23:52:09.293364 18880 trainer.py:139] Epoch[420/1500] loss: 0.11617077358307377
I0414 23:52:14.034504 18880 trainer.py:139] Epoch[421/1500] loss: 0.11414827694815974
I0414 23:52:18.633072 18880 trainer.py:139] Epoch[422/1500] loss: 0.11547153683439378
I0414 23:52:24.867215 18880 trainer.py:139] Epoch[423/1500] loss: 0.11472297459840775
I0414 23:52:29.484769 18880 trainer.py:139] Epoch[424/1500] loss: 0.11406400943956067
I0414 23:52:34.127237 18880 trainer.py:139] Epoch[425/1500] loss: 0.1144084382441736
I0414 23:52:38.710903 18880 trainer.py:139] Epoch[426/1500] loss: 0.11482256386549242
I0414 23:52:43.472971 18880 trainer.py:139] Epoch[427/1500] loss: 0.11435086448346415
I0414 23:52:49.584726 18880 trainer.py:139] Epoch[428/1500] loss: 0.11395606158241149
I0414 23:52:54.717552 18880 trainer.py:139] Epoch[429/1500] loss: 0.11442012748410625
I0414 23:52:59.390829 18880 trainer.py:139] Epoch[430/1500] loss: 0.11540963789147715
I0414 23:53:04.102572 18880 trainer.py:139] Epoch[431/1500] loss: 0.11605350769335224
I0414 23:53:08.742514 18880 trainer.py:139] Epoch[432/1500] loss: 0.11704088795569635
I0414 23:53:14.926826 18880 trainer.py:139] Epoch[433/1500] loss: 0.11452374126641982
I0414 23:53:19.704840 18880 trainer.py:139] Epoch[434/1500] loss: 0.11253227317525495
I0414 23:53:24.656276 18880 trainer.py:139] Epoch[435/1500] loss: 0.11535816279149824
I0414 23:53:29.493095 18880 trainer.py:139] Epoch[436/1500] loss: 0.11404480737063193
I0414 23:53:34.630854 18880 trainer.py:139] Epoch[437/1500] loss: 0.11519096455266399
I0414 23:53:40.249566 18880 trainer.py:139] Epoch[438/1500] loss: 0.11635163306228576
I0414 23:53:44.774865 18880 trainer.py:139] Epoch[439/1500] loss: 0.11540964125625548
I0414 23:53:49.381453 18880 trainer.py:139] Epoch[440/1500] loss: 0.11373796650478916
I0414 23:53:53.974089 18880 trainer.py:139] Epoch[441/1500] loss: 0.11428598434694352
I0414 23:53:59.962510 18880 trainer.py:139] Epoch[442/1500] loss: 0.11419401726415081
I0414 23:54:04.809293 18880 trainer.py:139] Epoch[443/1500] loss: 0.11333983800103588
I0414 23:54:09.402926 18880 trainer.py:139] Epoch[444/1500] loss: 0.11466519390383074
I0414 23:54:14.174963 18880 trainer.py:139] Epoch[445/1500] loss: 0.11444405754727702
I0414 23:54:18.804474 18880 trainer.py:139] Epoch[446/1500] loss: 0.11389392446125707
I0414 23:54:25.195096 18880 trainer.py:139] Epoch[447/1500] loss: 0.1143980045472422
I0414 23:54:29.705442 18880 trainer.py:139] Epoch[448/1500] loss: 0.11380461290959389
I0414 23:54:34.282131 18880 trainer.py:139] Epoch[449/1500] loss: 0.11347745695421772
I0414 23:54:34.555217 18880 trainer.py:145] Test: {'precision': 0.1368096514745309, 'recall': 0.3235667830128484, 'hit_ratio': 0.892225201072386, 'ndcg': 0.3037057127687605}
I0414 23:54:39.172769 18880 trainer.py:139] Epoch[450/1500] loss: 0.11231476597247585
I0414 23:54:43.682682 18880 trainer.py:139] Epoch[451/1500] loss: 0.11432833032261941
I0414 23:54:50.245727 18880 trainer.py:139] Epoch[452/1500] loss: 0.11363948833557867
I0414 23:54:54.757632 18880 trainer.py:139] Epoch[453/1500] loss: 0.11403732722805392
I0414 23:54:59.390134 18880 trainer.py:139] Epoch[454/1500] loss: 0.11336390289568132
I0414 23:55:04.009680 18880 trainer.py:139] Epoch[455/1500] loss: 0.11526848231592486
I0414 23:55:09.124570 18880 trainer.py:139] Epoch[456/1500] loss: 0.11249497292503234
I0414 23:55:14.818938 18880 trainer.py:139] Epoch[457/1500] loss: 0.11238780088963048
I0414 23:55:19.541138 18880 trainer.py:139] Epoch[458/1500] loss: 0.11293174230283307
I0414 23:55:24.196073 18880 trainer.py:139] Epoch[459/1500] loss: 0.11417674561662058
I0414 23:55:28.808641 18880 trainer.py:139] Epoch[460/1500] loss: 0.11280420759031849
I0414 23:55:33.973364 18880 trainer.py:139] Epoch[461/1500] loss: 0.11328391899024287
I0414 23:55:39.654359 18880 trainer.py:139] Epoch[462/1500] loss: 0.11568688793528464
I0414 23:55:44.162722 18880 trainer.py:139] Epoch[463/1500] loss: 0.11350311170662603
I0414 23:55:48.859518 18880 trainer.py:139] Epoch[464/1500] loss: 0.11351776916173197
I0414 23:55:53.499993 18880 trainer.py:139] Epoch[465/1500] loss: 0.11309355857872194
I0414 23:55:58.755413 18880 trainer.py:139] Epoch[466/1500] loss: 0.11434742904478504
I0414 23:56:04.474278 18880 trainer.py:139] Epoch[467/1500] loss: 0.11247631402746323
I0414 23:56:09.263258 18880 trainer.py:139] Epoch[468/1500] loss: 0.11257869245544556
I0414 23:56:14.008383 18880 trainer.py:139] Epoch[469/1500] loss: 0.11223995637509131
I0414 23:56:18.673776 18880 trainer.py:139] Epoch[470/1500] loss: 0.11374027281999588
I0414 23:56:24.619884 18880 trainer.py:139] Epoch[471/1500] loss: 0.11503935605287552
I0414 23:56:29.481996 18880 trainer.py:139] Epoch[472/1500] loss: 0.1130449082101545
I0414 23:56:33.903205 18880 trainer.py:139] Epoch[473/1500] loss: 0.11346222364133404
I0414 23:56:38.666188 18880 trainer.py:139] Epoch[474/1500] loss: 0.11484177242363652
I0414 23:56:43.325109 18880 trainer.py:139] Epoch[475/1500] loss: 0.11315082061675287
I0414 23:56:49.513406 18880 trainer.py:139] Epoch[476/1500] loss: 0.11245875613343331
I0414 23:56:54.261520 18880 trainer.py:139] Epoch[477/1500] loss: 0.11332518511241482
I0414 23:56:58.853160 18880 trainer.py:139] Epoch[478/1500] loss: 0.11237297735867961
I0414 23:57:03.745793 18880 trainer.py:139] Epoch[479/1500] loss: 0.11286720681575037
I0414 23:57:08.616497 18880 trainer.py:139] Epoch[480/1500] loss: 0.11253412548572786
I0414 23:57:14.622405 18880 trainer.py:139] Epoch[481/1500] loss: 0.1141483786125337
I0414 23:57:19.243944 18880 trainer.py:139] Epoch[482/1500] loss: 0.11229838502983894
I0414 23:57:24.065813 18880 trainer.py:139] Epoch[483/1500] loss: 0.11370961103708513
I0414 23:57:28.587686 18880 trainer.py:139] Epoch[484/1500] loss: 0.11412690315515764
I0414 23:57:34.018960 18880 trainer.py:139] Epoch[485/1500] loss: 0.11410225759590825
I0414 23:57:39.682015 18880 trainer.py:139] Epoch[486/1500] loss: 0.11218341199621078
I0414 23:57:44.362357 18880 trainer.py:139] Epoch[487/1500] loss: 0.11302734911441803
I0414 23:57:48.967949 18880 trainer.py:139] Epoch[488/1500] loss: 0.11193935621169306
I0414 23:57:53.583508 18880 trainer.py:139] Epoch[489/1500] loss: 0.11422762947697793
I0414 23:57:59.623303 18880 trainer.py:139] Epoch[490/1500] loss: 0.11277885879239728
I0414 23:58:04.423244 18880 trainer.py:139] Epoch[491/1500] loss: 0.11182109963509344
I0414 23:58:09.089634 18880 trainer.py:139] Epoch[492/1500] loss: 0.11247430020763029
I0414 23:58:13.775955 18880 trainer.py:139] Epoch[493/1500] loss: 0.11142825599639647
I0414 23:58:18.328724 18880 trainer.py:139] Epoch[494/1500] loss: 0.11322149994873232
I0414 23:58:24.210050 18880 trainer.py:139] Epoch[495/1500] loss: 0.11433538241732505
I0414 23:58:29.232249 18880 trainer.py:139] Epoch[496/1500] loss: 0.11218177599291648
I0414 23:58:33.848805 18880 trainer.py:139] Epoch[497/1500] loss: 0.11315622397007481
I0414 23:58:38.468349 18880 trainer.py:139] Epoch[498/1500] loss: 0.11290977005997012
I0414 23:58:43.140719 18880 trainer.py:139] Epoch[499/1500] loss: 0.11285562428735918
I0414 23:58:43.387891 18880 trainer.py:145] Test: {'precision': 0.13723860589812337, 'recall': 0.32381649234432724, 'hit_ratio': 0.8895442359249329, 'ndcg': 0.30493316124322767}
I0414 23:58:49.161578 18880 trainer.py:139] Epoch[500/1500] loss: 0.11245897700709681
I0414 23:58:54.325303 18880 trainer.py:139] Epoch[501/1500] loss: 0.11174139019943052
I0414 23:58:58.943850 18880 trainer.py:139] Epoch[502/1500] loss: 0.11195839941501617
I0414 23:59:03.471703 18880 trainer.py:139] Epoch[503/1500] loss: 0.11367431571406703
I0414 23:59:08.273638 18880 trainer.py:139] Epoch[504/1500] loss: 0.11060204669352501
I0414 23:59:14.287473 18880 trainer.py:139] Epoch[505/1500] loss: 0.11315609202269584
I0414 23:59:19.110336 18880 trainer.py:139] Epoch[506/1500] loss: 0.11275193311514393
I0414 23:59:23.855462 18880 trainer.py:139] Epoch[507/1500] loss: 0.11272272515681482
I0414 23:59:28.597597 18880 trainer.py:139] Epoch[508/1500] loss: 0.11200150006240414
I0414 23:59:33.381592 18880 trainer.py:139] Epoch[509/1500] loss: 0.11280913218375176
I0414 23:59:39.793143 18880 trainer.py:139] Epoch[510/1500] loss: 0.11279969686462034
I0414 23:59:44.520329 18880 trainer.py:139] Epoch[511/1500] loss: 0.1115958274852845
I0414 23:59:49.255488 18880 trainer.py:139] Epoch[512/1500] loss: 0.11225638250189443
I0414 23:59:53.800283 18880 trainer.py:139] Epoch[513/1500] loss: 0.11214153180199285
I0414 23:59:58.339100 18880 trainer.py:139] Epoch[514/1500] loss: 0.11127155514494065
I0415 00:00:04.396835 18880 trainer.py:139] Epoch[515/1500] loss: 0.11159986401757886
I0415 00:00:09.554579 18880 trainer.py:139] Epoch[516/1500] loss: 0.1111974028810378
I0415 00:00:14.107348 18880 trainer.py:139] Epoch[517/1500] loss: 0.11191595057325979
I0415 00:00:18.747825 18880 trainer.py:139] Epoch[518/1500] loss: 0.11129034623023003
I0415 00:00:23.585639 18880 trainer.py:139] Epoch[519/1500] loss: 0.11170911380360203
I0415 00:00:29.057335 18880 trainer.py:139] Epoch[520/1500] loss: 0.11252507519337439
I0415 00:00:34.564418 18880 trainer.py:139] Epoch[521/1500] loss: 0.11095807557144473
I0415 00:00:39.229811 18880 trainer.py:139] Epoch[522/1500] loss: 0.11088003146071587
I0415 00:00:44.040177 18880 trainer.py:139] Epoch[523/1500] loss: 0.11282702271015413
I0415 00:00:48.707561 18880 trainer.py:139] Epoch[524/1500] loss: 0.1118943789793599
I0415 00:00:54.342710 18880 trainer.py:139] Epoch[525/1500] loss: 0.11174719708581124
I0415 00:00:59.531353 18880 trainer.py:139] Epoch[526/1500] loss: 0.11160173603603916
I0415 00:01:04.224652 18880 trainer.py:139] Epoch[527/1500] loss: 0.11064749042834005
I0415 00:01:08.942867 18880 trainer.py:139] Epoch[528/1500] loss: 0.11199347867119697
I0415 00:01:13.710916 18880 trainer.py:139] Epoch[529/1500] loss: 0.11208794842804631
I0415 00:01:19.504936 18880 trainer.py:139] Epoch[530/1500] loss: 0.1105119513888513
I0415 00:01:24.470834 18880 trainer.py:139] Epoch[531/1500] loss: 0.11255216502374218
I0415 00:01:29.150181 18880 trainer.py:139] Epoch[532/1500] loss: 0.11004962267414216
I0415 00:01:33.719892 18880 trainer.py:139] Epoch[533/1500] loss: 0.11062105360531038
I0415 00:01:38.375319 18880 trainer.py:139] Epoch[534/1500] loss: 0.1114202144165193
I0415 00:01:44.515779 18880 trainer.py:139] Epoch[535/1500] loss: 0.111886725791039
I0415 00:01:49.301765 18880 trainer.py:139] Epoch[536/1500] loss: 0.11186449325853778
I0415 00:01:54.001043 18880 trainer.py:139] Epoch[537/1500] loss: 0.11046415230920238
I0415 00:01:58.574744 18880 trainer.py:139] Epoch[538/1500] loss: 0.11004055699994487
I0415 00:02:03.141466 18880 trainer.py:139] Epoch[539/1500] loss: 0.11191146075725555
I0415 00:02:08.808506 18880 trainer.py:139] Epoch[540/1500] loss: 0.11183608563676957
I0415 00:02:14.029042 18880 trainer.py:139] Epoch[541/1500] loss: 0.11100179966418974
I0415 00:02:18.636627 18880 trainer.py:139] Epoch[542/1500] loss: 0.11217776421577699
I0415 00:02:23.424610 18880 trainer.py:139] Epoch[543/1500] loss: 0.11138488832981355
I0415 00:02:27.997312 18880 trainer.py:139] Epoch[544/1500] loss: 0.11137817800045013
I0415 00:02:33.928470 18880 trainer.py:139] Epoch[545/1500] loss: 0.1111474662057815
I0415 00:02:38.868411 18880 trainer.py:139] Epoch[546/1500] loss: 0.11056420182989489
I0415 00:02:43.478986 18880 trainer.py:139] Epoch[547/1500] loss: 0.1100179341531569
I0415 00:02:48.258969 18880 trainer.py:139] Epoch[548/1500] loss: 0.11077565411406179
I0415 00:02:52.900441 18880 trainer.py:139] Epoch[549/1500] loss: 0.1109395315570216
I0415 00:02:53.163561 18880 trainer.py:145] Test: {'precision': 0.13798927613941023, 'recall': 0.3238544541634749, 'hit_ratio': 0.8890080428954423, 'ndcg': 0.3096149014857712}
I0415 00:02:59.298040 18880 trainer.py:139] Epoch[550/1500] loss: 0.10898045859029216
I0415 00:03:04.387014 18880 trainer.py:139] Epoch[551/1500] loss: 0.10901482211005303
I0415 00:03:09.176990 18880 trainer.py:139] Epoch[552/1500] loss: 0.1111917793750763
I0415 00:03:13.900188 18880 trainer.py:139] Epoch[553/1500] loss: 0.1113812055799269
I0415 00:03:18.394154 18880 trainer.py:139] Epoch[554/1500] loss: 0.11120044992816064
I0415 00:03:24.817664 18880 trainer.py:139] Epoch[555/1500] loss: 0.11011344362651149
I0415 00:03:29.488039 18880 trainer.py:139] Epoch[556/1500] loss: 0.11007059293408547
I0415 00:03:34.021872 18880 trainer.py:139] Epoch[557/1500] loss: 0.11152151154894982
I0415 00:03:38.641418 18880 trainer.py:139] Epoch[558/1500] loss: 0.11057084438300901
I0415 00:03:43.223092 18880 trainer.py:139] Epoch[559/1500] loss: 0.110372542613937
I0415 00:03:49.402418 18880 trainer.py:139] Epoch[560/1500] loss: 0.1113481939800324
I0415 00:03:54.101696 18880 trainer.py:139] Epoch[561/1500] loss: 0.10928669355569347
I0415 00:03:58.645496 18880 trainer.py:139] Epoch[562/1500] loss: 0.11089737545098027
I0415 00:04:03.273015 18880 trainer.py:139] Epoch[563/1500] loss: 0.11173322003695273
I0415 00:04:07.866648 18880 trainer.py:139] Epoch[564/1500] loss: 0.11076505602367463
I0415 00:04:14.180525 18880 trainer.py:139] Epoch[565/1500] loss: 0.11138383227009926
I0415 00:04:18.828974 18880 trainer.py:139] Epoch[566/1500] loss: 0.10975490173985882
I0415 00:04:23.560147 18880 trainer.py:139] Epoch[567/1500] loss: 0.11186189637068779
I0415 00:04:28.092982 18880 trainer.py:139] Epoch[568/1500] loss: 0.10926884052253538
I0415 00:04:32.991596 18880 trainer.py:139] Epoch[569/1500] loss: 0.11247423916093764
I0415 00:04:39.076239 18880 trainer.py:139] Epoch[570/1500] loss: 0.1112234441022719
I0415 00:04:43.786481 18880 trainer.py:139] Epoch[571/1500] loss: 0.10957867435870632
I0415 00:04:48.608350 18880 trainer.py:139] Epoch[572/1500] loss: 0.10970512104611244
I0415 00:04:53.161118 18880 trainer.py:139] Epoch[573/1500] loss: 0.11057192399617165
I0415 00:04:57.975015 18880 trainer.py:139] Epoch[574/1500] loss: 0.10973964463318547
I0415 00:05:04.270951 18880 trainer.py:139] Epoch[575/1500] loss: 0.10970984855967184
I0415 00:05:08.869995 18880 trainer.py:139] Epoch[576/1500] loss: 0.11019031342960173
I0415 00:05:13.645021 18880 trainer.py:139] Epoch[577/1500] loss: 0.10930634986969733
I0415 00:05:18.218720 18880 trainer.py:139] Epoch[578/1500] loss: 0.10964348143146883
I0415 00:05:22.753550 18880 trainer.py:139] Epoch[579/1500] loss: 0.1087082477827226
I0415 00:05:29.079387 18880 trainer.py:139] Epoch[580/1500] loss: 0.1103412946385722
I0415 00:05:33.752752 18880 trainer.py:139] Epoch[581/1500] loss: 0.11057058024790979
I0415 00:05:38.450037 18880 trainer.py:139] Epoch[582/1500] loss: 0.10875247539051118
I0415 00:05:43.153303 18880 trainer.py:139] Epoch[583/1500] loss: 0.1100392781438366
I0415 00:05:48.222345 18880 trainer.py:139] Epoch[584/1500] loss: 0.11260824434218868
I0415 00:05:54.373766 18880 trainer.py:139] Epoch[585/1500] loss: 0.10899220334906731
I0415 00:05:59.022215 18880 trainer.py:139] Epoch[586/1500] loss: 0.11210448126639089
I0415 00:06:03.759367 18880 trainer.py:139] Epoch[587/1500] loss: 0.10949117762427177
I0415 00:06:08.549342 18880 trainer.py:139] Epoch[588/1500] loss: 0.10925818114511428
I0415 00:06:13.169885 18880 trainer.py:139] Epoch[589/1500] loss: 0.10866638489307896
I0415 00:06:19.573938 18880 trainer.py:139] Epoch[590/1500] loss: 0.10995915195634288
I0415 00:06:24.315076 18880 trainer.py:139] Epoch[591/1500] loss: 0.10971156820174187
I0415 00:06:28.883793 18880 trainer.py:139] Epoch[592/1500] loss: 0.10843291109608065
I0415 00:06:33.604998 18880 trainer.py:139] Epoch[593/1500] loss: 0.10919942634720955
I0415 00:06:38.612246 18880 trainer.py:139] Epoch[594/1500] loss: 0.11059044565885298
I0415 00:06:44.588254 18880 trainer.py:139] Epoch[595/1500] loss: 0.11039594464725064
I0415 00:06:49.316436 18880 trainer.py:139] Epoch[596/1500] loss: 0.10937638821140412
I0415 00:06:53.924021 18880 trainer.py:139] Epoch[597/1500] loss: 0.11002960320441954
I0415 00:06:58.549548 18880 trainer.py:139] Epoch[598/1500] loss: 0.10970215066786736
I0415 00:07:03.102318 18880 trainer.py:139] Epoch[599/1500] loss: 0.10964103571830257
I0415 00:07:03.414273 18880 trainer.py:145] Test: {'precision': 0.1379356568364612, 'recall': 0.32344977714115086, 'hit_ratio': 0.8884718498659517, 'ndcg': 0.3090780941766177}
I0415 00:07:09.752070 18880 trainer.py:139] Epoch[600/1500] loss: 0.10838226949976336
I0415 00:07:14.300307 18880 trainer.py:139] Epoch[601/1500] loss: 0.10976623791840769
I0415 00:07:18.894935 18880 trainer.py:139] Epoch[602/1500] loss: 0.10803348498959695
I0415 00:07:23.481590 18880 trainer.py:139] Epoch[603/1500] loss: 0.11096201909165229
I0415 00:07:28.938370 18880 trainer.py:139] Epoch[604/1500] loss: 0.10968432743703166
I0415 00:07:34.427006 18880 trainer.py:139] Epoch[605/1500] loss: 0.10789968361777644
I0415 00:07:39.088845 18880 trainer.py:139] Epoch[606/1500] loss: 0.1088309783128
I0415 00:07:43.778157 18880 trainer.py:139] Epoch[607/1500] loss: 0.1093452452651916
I0415 00:07:48.596038 18880 trainer.py:139] Epoch[608/1500] loss: 0.11036205556123488
I0415 00:07:54.083680 18880 trainer.py:139] Epoch[609/1500] loss: 0.11064837296162883
I0415 00:07:59.513517 18880 trainer.py:139] Epoch[610/1500] loss: 0.10887691114218004
I0415 00:08:04.107149 18880 trainer.py:139] Epoch[611/1500] loss: 0.10849158081316179
I0415 00:08:08.972870 18880 trainer.py:139] Epoch[612/1500] loss: 0.10906773613345239
I0415 00:08:13.490731 18880 trainer.py:139] Epoch[613/1500] loss: 0.11055633617985633
I0415 00:08:19.600292 18880 trainer.py:139] Epoch[614/1500] loss: 0.10941340798331846
I0415 00:08:24.509867 18880 trainer.py:139] Epoch[615/1500] loss: 0.10985899380137844
I0415 00:08:28.966955 18880 trainer.py:139] Epoch[616/1500] loss: 0.11083570050616418
I0415 00:08:33.376206 18880 trainer.py:139] Epoch[617/1500] loss: 0.10955183688671358
I0415 00:08:37.710704 18880 trainer.py:139] Epoch[618/1500] loss: 0.10835077589558016
I0415 00:08:43.399673 18880 trainer.py:139] Epoch[619/1500] loss: 0.10999193859677162
I0415 00:08:48.539477 18880 trainer.py:139] Epoch[620/1500] loss: 0.10860607436587734
I0415 00:08:53.271646 18880 trainer.py:139] Epoch[621/1500] loss: 0.10905290899738189
I0415 00:08:57.896176 18880 trainer.py:139] Epoch[622/1500] loss: 0.10861058364952764
I0415 00:09:02.470872 18880 trainer.py:139] Epoch[623/1500] loss: 0.1084150285009415
I0415 00:09:08.464820 18880 trainer.py:139] Epoch[624/1500] loss: 0.11114358132885348
I0415 00:09:13.348482 18880 trainer.py:139] Epoch[625/1500] loss: 0.10948681687155078
I0415 00:09:17.874341 18880 trainer.py:139] Epoch[626/1500] loss: 0.11149495119048704
I0415 00:09:22.541726 18880 trainer.py:139] Epoch[627/1500] loss: 0.10831555195393101
I0415 00:09:27.188182 18880 trainer.py:139] Epoch[628/1500] loss: 0.10870970449139995
I0415 00:09:33.329635 18880 trainer.py:139] Epoch[629/1500] loss: 0.10928564134144014
I0415 00:09:38.025924 18880 trainer.py:139] Epoch[630/1500] loss: 0.10862454579722497
I0415 00:09:42.543811 18880 trainer.py:139] Epoch[631/1500] loss: 0.11050542516093101
I0415 00:09:47.235115 18880 trainer.py:139] Epoch[632/1500] loss: 0.10809162259101868
I0415 00:09:51.924430 18880 trainer.py:139] Epoch[633/1500] loss: 0.10681827270215558
I0415 00:09:57.904423 18880 trainer.py:139] Epoch[634/1500] loss: 0.10967900483838973
I0415 00:10:02.831938 18880 trainer.py:139] Epoch[635/1500] loss: 0.11016655905592826
I0415 00:10:07.405638 18880 trainer.py:139] Epoch[636/1500] loss: 0.10974407003771874
I0415 00:10:12.173686 18880 trainer.py:139] Epoch[637/1500] loss: 0.10815687693895833
I0415 00:10:16.916818 18880 trainer.py:139] Epoch[638/1500] loss: 0.10874444510667555
I0415 00:10:23.189832 18880 trainer.py:139] Epoch[639/1500] loss: 0.10905575079302635
I0415 00:10:27.765525 18880 trainer.py:139] Epoch[640/1500] loss: 0.10897528380155563
I0415 00:10:32.241551 18880 trainer.py:139] Epoch[641/1500] loss: 0.10983983090808315
I0415 00:10:37.040496 18880 trainer.py:139] Epoch[642/1500] loss: 0.10859721250111057
I0415 00:10:41.563366 18880 trainer.py:139] Epoch[643/1500] loss: 0.10994247058706899
I0415 00:10:47.708806 18880 trainer.py:139] Epoch[644/1500] loss: 0.10852778078086915
I0415 00:10:52.339770 18880 trainer.py:139] Epoch[645/1500] loss: 0.1095450424378918
I0415 00:10:56.934400 18880 trainer.py:139] Epoch[646/1500] loss: 0.10898926349416856
I0415 00:11:01.755272 18880 trainer.py:139] Epoch[647/1500] loss: 0.10872776373740166
I0415 00:11:06.648903 18880 trainer.py:139] Epoch[648/1500] loss: 0.10885169477232041
I0415 00:11:12.667765 18880 trainer.py:139] Epoch[649/1500] loss: 0.10776786770551436
I0415 00:11:12.923907 18880 trainer.py:145] Test: {'precision': 0.13726541554959792, 'recall': 0.32345215552990364, 'hit_ratio': 0.885254691689008, 'ndcg': 0.3047471713610549}
I0415 00:11:17.444783 18880 trainer.py:139] Epoch[650/1500] loss: 0.10978489753700071
I0415 00:11:22.315490 18880 trainer.py:139] Epoch[651/1500] loss: 0.10801964229153048
I0415 00:11:26.846331 18880 trainer.py:139] Epoch[652/1500] loss: 0.10784197382388576
I0415 00:11:32.112716 18880 trainer.py:139] Epoch[653/1500] loss: 0.10954222996388713
I0415 00:11:37.759822 18880 trainer.py:139] Epoch[654/1500] loss: 0.10801217584840712
I0415 00:11:42.262756 18880 trainer.py:139] Epoch[655/1500] loss: 0.10998115472255214
I0415 00:11:46.862368 18880 trainer.py:139] Epoch[656/1500] loss: 0.1077982007015136
I0415 00:11:51.766960 18880 trainer.py:139] Epoch[657/1500] loss: 0.10797891044808973
I0415 00:11:57.165900 18880 trainer.py:139] Epoch[658/1500] loss: 0.10832404345273972
I0415 00:12:02.524971 18880 trainer.py:139] Epoch[659/1500] loss: 0.1077195730420851
I0415 00:12:06.985050 18880 trainer.py:139] Epoch[660/1500] loss: 0.1085412819539347
I0415 00:12:11.949442 18880 trainer.py:139] Epoch[661/1500] loss: 0.10724200885142049
I0415 00:12:16.490252 18880 trainer.py:139] Epoch[662/1500] loss: 0.10799075062236478
I0415 00:12:21.376904 18880 trainer.py:139] Epoch[663/1500] loss: 0.10908411587438276
I0415 00:12:27.456564 18880 trainer.py:139] Epoch[664/1500] loss: 0.10899667081332975
I0415 00:12:32.202687 18880 trainer.py:139] Epoch[665/1500] loss: 0.10817909913678322
I0415 00:12:36.773395 18880 trainer.py:139] Epoch[666/1500] loss: 0.10754887471275945
I0415 00:12:41.574334 18880 trainer.py:139] Epoch[667/1500] loss: 0.10855753311226445
I0415 00:12:46.815801 18880 trainer.py:139] Epoch[668/1500] loss: 0.106683001643227
I0415 00:12:52.514735 18880 trainer.py:139] Epoch[669/1500] loss: 0.10872555091496437
I0415 00:12:57.018667 18880 trainer.py:139] Epoch[670/1500] loss: 0.10743042249833384
I0415 00:13:01.774756 18880 trainer.py:139] Epoch[671/1500] loss: 0.10796594980262941
I0415 00:13:06.382342 18880 trainer.py:139] Epoch[672/1500] loss: 0.10810532276668856
I0415 00:13:11.717495 18880 trainer.py:139] Epoch[673/1500] loss: 0.10812757476683586
I0415 00:13:17.342674 18880 trainer.py:139] Epoch[674/1500] loss: 0.10754524339591304
I0415 00:13:21.819697 18880 trainer.py:139] Epoch[675/1500] loss: 0.10872570401237856
I0415 00:13:26.452200 18880 trainer.py:139] Epoch[676/1500] loss: 0.10808606710164778
I0415 00:13:31.080717 18880 trainer.py:139] Epoch[677/1500] loss: 0.10721951771167017
I0415 00:13:36.014211 18880 trainer.py:139] Epoch[678/1500] loss: 0.10660534928883275
I0415 00:13:42.328087 18880 trainer.py:139] Epoch[679/1500] loss: 0.1081917624800436
I0415 00:13:47.084245 18880 trainer.py:139] Epoch[680/1500] loss: 0.10732925779396488
I0415 00:13:51.980865 18880 trainer.py:139] Epoch[681/1500] loss: 0.10794380499470618
I0415 00:13:56.705060 18880 trainer.py:139] Epoch[682/1500] loss: 0.10766146307991396
I0415 00:14:01.290719 18880 trainer.py:139] Epoch[683/1500] loss: 0.10726041659232109
I0415 00:14:07.482007 18880 trainer.py:139] Epoch[684/1500] loss: 0.10755893636134363
I0415 00:14:12.152382 18880 trainer.py:139] Epoch[685/1500] loss: 0.10970371096364913
I0415 00:14:16.894517 18880 trainer.py:139] Epoch[686/1500] loss: 0.10799218449861772
I0415 00:14:21.484164 18880 trainer.py:139] Epoch[687/1500] loss: 0.10891158710564336
I0415 00:14:26.221315 18880 trainer.py:139] Epoch[688/1500] loss: 0.10804826021194458
I0415 00:14:32.491340 18880 trainer.py:139] Epoch[689/1500] loss: 0.10980360426249043
I0415 00:14:37.256399 18880 trainer.py:139] Epoch[690/1500] loss: 0.10633275778062883
I0415 00:14:42.014480 18880 trainer.py:139] Epoch[691/1500] loss: 0.10754937630507254
I0415 00:14:46.521404 18880 trainer.py:139] Epoch[692/1500] loss: 0.1067160637147965
I0415 00:14:51.116033 18880 trainer.py:139] Epoch[693/1500] loss: 0.10755954971236567
I0415 00:14:56.322616 18880 trainer.py:139] Epoch[694/1500] loss: 0.10842101660466963
I0415 00:15:02.016566 18880 trainer.py:139] Epoch[695/1500] loss: 0.10716530752758827
I0415 00:15:06.757705 18880 trainer.py:139] Epoch[696/1500] loss: 0.10697993395789977
I0415 00:15:11.458977 18880 trainer.py:139] Epoch[697/1500] loss: 0.10863891652514858
I0415 00:15:16.145299 18880 trainer.py:139] Epoch[698/1500] loss: 0.10770866202731286
I0415 00:15:20.931288 18880 trainer.py:139] Epoch[699/1500] loss: 0.1071780230249128
I0415 00:15:21.266168 18880 trainer.py:145] Test: {'precision': 0.13801608579088478, 'recall': 0.323610901520285, 'hit_ratio': 0.8906166219839142, 'ndcg': 0.3119357294723269}
I0415 00:15:27.272074 18880 trainer.py:139] Epoch[700/1500] loss: 0.10889865986762508
I0415 00:15:32.031154 18880 trainer.py:139] Epoch[701/1500] loss: 0.10812945784099641
I0415 00:15:36.492230 18880 trainer.py:139] Epoch[702/1500] loss: 0.1073008585841425
I0415 00:15:41.172574 18880 trainer.py:139] Epoch[703/1500] loss: 0.108813164935958
I0415 00:15:45.771190 18880 trainer.py:139] Epoch[704/1500] loss: 0.10684321147780265
I0415 00:15:52.116430 18880 trainer.py:139] Epoch[705/1500] loss: 0.10806185896358182
I0415 00:15:56.635313 18880 trainer.py:139] Epoch[706/1500] loss: 0.10768823205463347
I0415 00:16:01.297716 18880 trainer.py:139] Epoch[707/1500] loss: 0.10773666587568098
I0415 00:16:05.859454 18880 trainer.py:139] Epoch[708/1500] loss: 0.10797101763948318
I0415 00:16:10.562720 18880 trainer.py:139] Epoch[709/1500] loss: 0.10577265677913543
I0415 00:16:16.399194 18880 trainer.py:139] Epoch[710/1500] loss: 0.10817173940520133
I0415 00:16:21.370564 18880 trainer.py:139] Epoch[711/1500] loss: 0.10707010689281649
I0415 00:16:25.996088 18880 trainer.py:139] Epoch[712/1500] loss: 0.10741406534948657
I0415 00:16:30.389391 18880 trainer.py:139] Epoch[713/1500] loss: 0.10823945797258808
I0415 00:16:34.971064 18880 trainer.py:139] Epoch[714/1500] loss: 0.10711691600661125
I0415 00:16:40.091934 18880 trainer.py:139] Epoch[715/1500] loss: 0.10813537840881655
I0415 00:16:46.107834 18880 trainer.py:139] Epoch[716/1500] loss: 0.10782998992550757
I0415 00:16:50.811100 18880 trainer.py:139] Epoch[717/1500] loss: 0.10680819999787115
I0415 00:16:55.497423 18880 trainer.py:139] Epoch[718/1500] loss: 0.10699648746559696
I0415 00:16:59.975442 18880 trainer.py:139] Epoch[719/1500] loss: 0.10744294331919763
I0415 00:17:05.068404 18880 trainer.py:139] Epoch[720/1500] loss: 0.1086561078986814
I0415 00:17:10.985098 18880 trainer.py:139] Epoch[721/1500] loss: 0.1077088059917573
I0415 00:17:15.440192 18880 trainer.py:139] Epoch[722/1500] loss: 0.10764605575992216
I0415 00:17:19.948112 18880 trainer.py:139] Epoch[723/1500] loss: 0.10600778652775672
I0415 00:17:24.480948 18880 trainer.py:139] Epoch[724/1500] loss: 0.10783139952728825
I0415 00:17:29.064617 18880 trainer.py:139] Epoch[725/1500] loss: 0.10748358166986896
I0415 00:17:35.378491 18880 trainer.py:139] Epoch[726/1500] loss: 0.10588213080360044
I0415 00:17:39.810664 18880 trainer.py:139] Epoch[727/1500] loss: 0.1062715440507858
I0415 00:17:44.439179 18880 trainer.py:139] Epoch[728/1500] loss: 0.10756373693866114
I0415 00:17:49.083642 18880 trainer.py:139] Epoch[729/1500] loss: 0.10675478077703907
I0415 00:17:53.820793 18880 trainer.py:139] Epoch[730/1500] loss: 0.10622728856340531
I0415 00:18:00.017065 18880 trainer.py:139] Epoch[731/1500] loss: 0.10773811729684953
I0415 00:18:04.855876 18880 trainer.py:139] Epoch[732/1500] loss: 0.10849158970579025
I0415 00:18:09.465456 18880 trainer.py:139] Epoch[733/1500] loss: 0.1050519974481675
I0415 00:18:14.204601 18880 trainer.py:139] Epoch[734/1500] loss: 0.10684274785941647
I0415 00:18:18.907867 18880 trainer.py:139] Epoch[735/1500] loss: 0.10720858530652139
I0415 00:18:24.075579 18880 trainer.py:139] Epoch[736/1500] loss: 0.10800679100136604
I0415 00:18:29.820361 18880 trainer.py:139] Epoch[737/1500] loss: 0.10618557756946932
I0415 00:18:34.435919 18880 trainer.py:139] Epoch[738/1500] loss: 0.10827540341884859
I0415 00:18:39.120249 18880 trainer.py:139] Epoch[739/1500] loss: 0.10590934104496433
I0415 00:18:43.765707 18880 trainer.py:139] Epoch[740/1500] loss: 0.10621253232802114
I0415 00:18:48.533759 18880 trainer.py:139] Epoch[741/1500] loss: 0.10702282478732447
I0415 00:18:54.779860 18880 trainer.py:139] Epoch[742/1500] loss: 0.10696933082034511
I0415 00:18:59.517013 18880 trainer.py:139] Epoch[743/1500] loss: 0.10733580877704005
I0415 00:19:04.116626 18880 trainer.py:139] Epoch[744/1500] loss: 0.10825138298734542
I0415 00:19:08.570724 18880 trainer.py:139] Epoch[745/1500] loss: 0.10626069720714323
I0415 00:19:13.336780 18880 trainer.py:139] Epoch[746/1500] loss: 0.10641967336977681
I0415 00:19:19.165427 18880 trainer.py:139] Epoch[747/1500] loss: 0.10613504484776527
I0415 00:19:24.149752 18880 trainer.py:139] Epoch[748/1500] loss: 0.10723315443723433
I0415 00:19:28.634747 18880 trainer.py:139] Epoch[749/1500] loss: 0.10711174866845531
I0415 00:19:28.917724 18880 trainer.py:145] Test: {'precision': 0.13729222520107245, 'recall': 0.32399658109680207, 'hit_ratio': 0.8890080428954423, 'ndcg': 0.31220413384692453}
I0415 00:19:33.567212 18880 trainer.py:139] Epoch[750/1500] loss: 0.10426161774704533
I0415 00:19:38.240739 18880 trainer.py:139] Epoch[751/1500] loss: 0.1057885120953283
I0415 00:19:43.863918 18880 trainer.py:139] Epoch[752/1500] loss: 0.10745123869949771
I0415 00:19:48.917015 18880 trainer.py:139] Epoch[753/1500] loss: 0.10691441763793269
I0415 00:19:53.701009 18880 trainer.py:139] Epoch[754/1500] loss: 0.10617086171142516
I0415 00:19:58.511915 18880 trainer.py:139] Epoch[755/1500] loss: 0.1054664213330515
I0415 00:20:03.364680 18880 trainer.py:139] Epoch[756/1500] loss: 0.10578694699272033
I0415 00:20:08.563231 18880 trainer.py:139] Epoch[757/1500] loss: 0.10727412902539776
I0415 00:20:14.181515 18880 trainer.py:139] Epoch[758/1500] loss: 0.10592447173210882
I0415 00:20:18.734285 18880 trainer.py:139] Epoch[759/1500] loss: 0.10644863113280266
I0415 00:20:23.366788 18880 trainer.py:139] Epoch[760/1500] loss: 0.10689054573735883
I0415 00:20:28.002718 18880 trainer.py:139] Epoch[761/1500] loss: 0.10565041390157515
I0415 00:20:32.739870 18880 trainer.py:139] Epoch[762/1500] loss: 0.10826217815760643
I0415 00:20:38.754748 18880 trainer.py:139] Epoch[763/1500] loss: 0.1072447867162766
I0415 00:20:43.394227 18880 trainer.py:139] Epoch[764/1500] loss: 0.10678891453050798
I0415 00:20:48.178222 18880 trainer.py:139] Epoch[765/1500] loss: 0.10668032880752318
I0415 00:20:52.571524 18880 trainer.py:139] Epoch[766/1500] loss: 0.10561522649180505
I0415 00:20:57.075909 18880 trainer.py:139] Epoch[767/1500] loss: 0.10532399435197154
I0415 00:21:03.243276 18880 trainer.py:139] Epoch[768/1500] loss: 0.10733636612853696
I0415 00:21:07.969465 18880 trainer.py:139] Epoch[769/1500] loss: 0.10782553327660407
I0415 00:21:12.798310 18880 trainer.py:139] Epoch[770/1500] loss: 0.10809463262557983
I0415 00:21:17.357059 18880 trainer.py:139] Epoch[771/1500] loss: 0.10617307645659294
I0415 00:21:22.027435 18880 trainer.py:139] Epoch[772/1500] loss: 0.10549136251211166
I0415 00:21:27.685507 18880 trainer.py:139] Epoch[773/1500] loss: 0.1087419522866126
I0415 00:21:32.906041 18880 trainer.py:139] Epoch[774/1500] loss: 0.10730348166919523
I0415 00:21:37.432897 18880 trainer.py:139] Epoch[775/1500] loss: 0.10767161004966305
I0415 00:21:42.148123 18880 trainer.py:139] Epoch[776/1500] loss: 0.10578150206035183
I0415 00:21:46.701889 18880 trainer.py:139] Epoch[777/1500] loss: 0.1065582390273771
I0415 00:21:52.009133 18880 trainer.py:139] Epoch[778/1500] loss: 0.1052885125240972
I0415 00:21:57.624349 18880 trainer.py:139] Epoch[779/1500] loss: 0.10590640167074819
I0415 00:22:02.227947 18880 trainer.py:139] Epoch[780/1500] loss: 0.10807924861869504
I0415 00:22:06.929579 18880 trainer.py:139] Epoch[781/1500] loss: 0.1066814735531807
I0415 00:22:11.797294 18880 trainer.py:139] Epoch[782/1500] loss: 0.10660472944859535
I0415 00:22:16.393917 18880 trainer.py:139] Epoch[783/1500] loss: 0.10568582747251756
I0415 00:22:22.753641 18880 trainer.py:139] Epoch[784/1500] loss: 0.10733071161854651
I0415 00:22:27.408068 18880 trainer.py:139] Epoch[785/1500] loss: 0.10565870471539036
I0415 00:22:32.066487 18880 trainer.py:139] Epoch[786/1500] loss: 0.1064160944473359
I0415 00:22:36.622243 18880 trainer.py:139] Epoch[787/1500] loss: 0.1066386733324297
I0415 00:22:41.252752 18880 trainer.py:139] Epoch[788/1500] loss: 0.10551263319869195
I0415 00:22:46.549510 18880 trainer.py:139] Epoch[789/1500] loss: 0.10809853552810607
I0415 00:22:52.341133 18880 trainer.py:139] Epoch[790/1500] loss: 0.10816090097350459
I0415 00:22:56.929782 18880 trainer.py:139] Epoch[791/1500] loss: 0.10760587574012818
I0415 00:23:01.608131 18880 trainer.py:139] Epoch[792/1500] loss: 0.10561000627856101
I0415 00:23:06.270966 18880 trainer.py:139] Epoch[793/1500] loss: 0.1053736666517873
I0415 00:23:11.111772 18880 trainer.py:139] Epoch[794/1500] loss: 0.10657948135368285
I0415 00:23:17.312028 18880 trainer.py:139] Epoch[795/1500] loss: 0.10691831068646523
I0415 00:23:21.996357 18880 trainer.py:139] Epoch[796/1500] loss: 0.10615715456585731
I0415 00:23:26.670720 18880 trainer.py:139] Epoch[797/1500] loss: 0.10582896177807162
I0415 00:23:31.509532 18880 trainer.py:139] Epoch[798/1500] loss: 0.10651649678907087
I0415 00:23:36.163522 18880 trainer.py:139] Epoch[799/1500] loss: 0.10549962809008936
I0415 00:23:36.423651 18880 trainer.py:145] Test: {'precision': 0.13782841823056305, 'recall': 0.32391219483525135, 'hit_ratio': 0.8916890080428954, 'ndcg': 0.31272835979100856}
I0415 00:23:42.026905 18880 trainer.py:139] Epoch[800/1500] loss: 0.10773010287554033
I0415 00:23:47.070034 18880 trainer.py:139] Epoch[801/1500] loss: 0.10785909501775619
I0415 00:23:51.842069 18880 trainer.py:139] Epoch[802/1500] loss: 0.10790417367412199
I0415 00:23:56.460619 18880 trainer.py:139] Epoch[803/1500] loss: 0.10642204385611319
I0415 00:24:00.994451 18880 trainer.py:139] Epoch[804/1500] loss: 0.10522409432357357
I0415 00:24:07.097037 18880 trainer.py:139] Epoch[805/1500] loss: 0.1065401348375505
I0415 00:24:12.088338 18880 trainer.py:139] Epoch[806/1500] loss: 0.1064743846654892
I0415 00:24:16.696919 18880 trainer.py:139] Epoch[807/1500] loss: 0.10506237370352592
I0415 00:24:21.318465 18880 trainer.py:139] Epoch[808/1500] loss: 0.10610289631351348
I0415 00:24:26.176215 18880 trainer.py:139] Epoch[809/1500] loss: 0.10515027228863008
I0415 00:24:31.812361 18880 trainer.py:139] Epoch[810/1500] loss: 0.10598416962931233
I0415 00:24:37.131001 18880 trainer.py:139] Epoch[811/1500] loss: 0.10642122837804979
I0415 00:24:41.788844 18880 trainer.py:139] Epoch[812/1500] loss: 0.10481617719896379
I0415 00:24:46.426329 18880 trainer.py:139] Epoch[813/1500] loss: 0.10583670869950325
I0415 00:24:51.254179 18880 trainer.py:139] Epoch[814/1500] loss: 0.10481314817743917
I0415 00:24:55.885684 18880 trainer.py:139] Epoch[815/1500] loss: 0.10637831063039842
I0415 00:25:02.121821 18880 trainer.py:139] Epoch[816/1500] loss: 0.10693983613483367
I0415 00:25:07.068324 18880 trainer.py:139] Epoch[817/1500] loss: 0.10570693568837258
I0415 00:25:11.771591 18880 trainer.py:139] Epoch[818/1500] loss: 0.10515551557463984
I0415 00:25:16.335757 18880 trainer.py:139] Epoch[819/1500] loss: 0.10615737640088604
I0415 00:25:21.073904 18880 trainer.py:139] Epoch[820/1500] loss: 0.10718173990326543
I0415 00:25:27.139059 18880 trainer.py:139] Epoch[821/1500] loss: 0.10662452395885222
I0415 00:25:31.952954 18880 trainer.py:139] Epoch[822/1500] loss: 0.10642608759864684
I0415 00:25:36.610373 18880 trainer.py:139] Epoch[823/1500] loss: 0.1060184754671589
I0415 00:25:41.181082 18880 trainer.py:139] Epoch[824/1500] loss: 0.10595255825788744
I0415 00:25:46.102617 18880 trainer.py:139] Epoch[825/1500] loss: 0.1062288339580259
I0415 00:25:51.491590 18880 trainer.py:139] Epoch[826/1500] loss: 0.10511275549088755
I0415 00:25:56.952320 18880 trainer.py:139] Epoch[827/1500] loss: 0.10683441090006981
I0415 00:26:01.627679 18880 trainer.py:139] Epoch[828/1500] loss: 0.10686190017769413
I0415 00:26:06.446545 18880 trainer.py:139] Epoch[829/1500] loss: 0.10598719913151956
I0415 00:26:10.930543 18880 trainer.py:139] Epoch[830/1500] loss: 0.10653396984261851
I0415 00:26:16.345430 18880 trainer.py:139] Epoch[831/1500] loss: 0.10454492775663253
I0415 00:26:21.683571 18880 trainer.py:139] Epoch[832/1500] loss: 0.1068656355623276
I0415 00:26:26.545739 18880 trainer.py:139] Epoch[833/1500] loss: 0.10620313017599044
I0415 00:26:31.261961 18880 trainer.py:139] Epoch[834/1500] loss: 0.10670113659674121
I0415 00:26:35.673639 18880 trainer.py:139] Epoch[835/1500] loss: 0.10561617247519954
I0415 00:26:40.562287 18880 trainer.py:139] Epoch[836/1500] loss: 0.10655464977025986
I0415 00:26:46.687794 18880 trainer.py:139] Epoch[837/1500] loss: 0.1066263051282975
I0415 00:26:51.408999 18880 trainer.py:139] Epoch[838/1500] loss: 0.10502853965567004
I0415 00:26:56.031535 18880 trainer.py:139] Epoch[839/1500] loss: 0.10477315946932762
I0415 00:27:00.572344 18880 trainer.py:139] Epoch[840/1500] loss: 0.10516288347782628
I0415 00:27:05.292552 18880 trainer.py:139] Epoch[841/1500] loss: 0.10466257554869499
I0415 00:27:11.563776 18880 trainer.py:139] Epoch[842/1500] loss: 0.10398939924855385
I0415 00:27:16.150432 18880 trainer.py:139] Epoch[843/1500] loss: 0.10427611681722826
I0415 00:27:20.709182 18880 trainer.py:139] Epoch[844/1500] loss: 0.10605724684653743
I0415 00:27:25.446333 18880 trainer.py:139] Epoch[845/1500] loss: 0.10689280518601017
I0415 00:27:30.051378 18880 trainer.py:139] Epoch[846/1500] loss: 0.10518438056592018
I0415 00:27:36.141007 18880 trainer.py:139] Epoch[847/1500] loss: 0.10360435252228091
I0415 00:27:41.172174 18880 trainer.py:139] Epoch[848/1500] loss: 0.10640518727802462
I0415 00:27:45.850524 18880 trainer.py:139] Epoch[849/1500] loss: 0.10568261627228029
I0415 00:27:46.086733 18880 trainer.py:145] Test: {'precision': 0.13718498659517434, 'recall': 0.32472803016605273, 'hit_ratio': 0.892225201072386, 'ndcg': 0.3090174756225275}
I0415 00:27:50.754118 18880 trainer.py:139] Epoch[850/1500] loss: 0.10528969644538817
I0415 00:27:55.323831 18880 trainer.py:139] Epoch[851/1500] loss: 0.10496383352625754
I0415 00:28:00.546698 18880 trainer.py:139] Epoch[852/1500] loss: 0.10580453300668348
I0415 00:28:06.600444 18880 trainer.py:139] Epoch[853/1500] loss: 0.10683737334705168
I0415 00:28:11.249890 18880 trainer.py:139] Epoch[854/1500] loss: 0.10502366841800752
I0415 00:28:15.906314 18880 trainer.py:139] Epoch[855/1500] loss: 0.10723758368722854
I0415 00:28:20.670375 18880 trainer.py:139] Epoch[856/1500] loss: 0.10457971067197862
I0415 00:28:25.628787 18880 trainer.py:139] Epoch[857/1500] loss: 0.10480142096357961
I0415 00:28:31.603224 18880 trainer.py:139] Epoch[858/1500] loss: 0.10649194880839317
I0415 00:28:36.370277 18880 trainer.py:139] Epoch[859/1500] loss: 0.10613191416186671
I0415 00:28:41.188158 18880 trainer.py:139] Epoch[860/1500] loss: 0.10629418083736973
I0415 00:28:45.715015 18880 trainer.py:139] Epoch[861/1500] loss: 0.10598192868694183
I0415 00:28:50.522932 18880 trainer.py:139] Epoch[862/1500] loss: 0.10627926621706255
I0415 00:28:56.896608 18880 trainer.py:139] Epoch[863/1500] loss: 0.10695736350551728
I0415 00:29:01.505190 18880 trainer.py:139] Epoch[864/1500] loss: 0.1065125929251794
I0415 00:29:05.771918 18880 trainer.py:139] Epoch[865/1500] loss: 0.10635162577513725
I0415 00:29:10.293788 18880 trainer.py:139] Epoch[866/1500] loss: 0.10434479218336844
I0415 00:29:14.908351 18880 trainer.py:139] Epoch[867/1500] loss: 0.1048968905402768
I0415 00:29:20.635691 18880 trainer.py:139] Epoch[868/1500] loss: 0.10455967101358599
I0415 00:29:25.878152 18880 trainer.py:139] Epoch[869/1500] loss: 0.10385746556905008
I0415 00:29:30.737893 18880 trainer.py:139] Epoch[870/1500] loss: 0.10430288987775002
I0415 00:29:35.444150 18880 trainer.py:139] Epoch[871/1500] loss: 0.10715114012841255
I0415 00:29:40.264024 18880 trainer.py:139] Epoch[872/1500] loss: 0.10580611613488966
I0415 00:29:45.589209 18880 trainer.py:139] Epoch[873/1500] loss: 0.10505574725327953
I0415 00:29:51.209407 18880 trainer.py:139] Epoch[874/1500] loss: 0.10558222138112591
I0415 00:29:55.876793 18880 trainer.py:139] Epoch[875/1500] loss: 0.10581743597022948
I0415 00:30:00.491356 18880 trainer.py:139] Epoch[876/1500] loss: 0.10607846081256866
I0415 00:30:05.073027 18880 trainer.py:139] Epoch[877/1500] loss: 0.10543058235799113
I0415 00:30:09.867987 18880 trainer.py:139] Epoch[878/1500] loss: 0.105618886168926
I0415 00:30:15.884858 18880 trainer.py:139] Epoch[879/1500] loss: 0.10550671359223704
I0415 00:30:20.630979 18880 trainer.py:139] Epoch[880/1500] loss: 0.1049478383314225
I0415 00:30:25.190726 18880 trainer.py:139] Epoch[881/1500] loss: 0.10429349661834779
I0415 00:30:29.864091 18880 trainer.py:139] Epoch[882/1500] loss: 0.10488003660594264
I0415 00:30:34.454174 18880 trainer.py:139] Epoch[883/1500] loss: 0.105771278421725
I0415 00:30:40.253774 18880 trainer.py:139] Epoch[884/1500] loss: 0.10572354687798408
I0415 00:30:45.142418 18880 trainer.py:139] Epoch[885/1500] loss: 0.1044517058518625
I0415 00:30:49.876020 18880 trainer.py:139] Epoch[886/1500] loss: 0.10655759515300874
I0415 00:30:54.658024 18880 trainer.py:139] Epoch[887/1500] loss: 0.10575881936857777
I0415 00:30:59.245097 18880 trainer.py:139] Epoch[888/1500] loss: 0.10515858257009138
I0415 00:31:04.064973 18880 trainer.py:139] Epoch[889/1500] loss: 0.10490359101564653
I0415 00:31:10.506422 18880 trainer.py:139] Epoch[890/1500] loss: 0.10549075516962236
I0415 00:31:14.886770 18880 trainer.py:139] Epoch[891/1500] loss: 0.10546789366391397
I0415 00:31:19.732426 18880 trainer.py:139] Epoch[892/1500] loss: 0.1071715566419786
I0415 00:31:24.432702 18880 trainer.py:139] Epoch[893/1500] loss: 0.10494536570002956
I0415 00:31:29.132977 18880 trainer.py:139] Epoch[894/1500] loss: 0.10438897100187117
I0415 00:31:34.971446 18880 trainer.py:139] Epoch[895/1500] loss: 0.10654297975763198
I0415 00:31:40.335502 18880 trainer.py:139] Epoch[896/1500] loss: 0.10554187889060666
I0415 00:31:45.159363 18880 trainer.py:139] Epoch[897/1500] loss: 0.10414943195158435
I0415 00:31:49.783315 18880 trainer.py:139] Epoch[898/1500] loss: 0.10451245331956495
I0415 00:31:54.566314 18880 trainer.py:139] Epoch[899/1500] loss: 0.10453273836643465
I0415 00:31:54.842390 18880 trainer.py:145] Test: {'precision': 0.13739946380697057, 'recall': 0.3240231705335792, 'hit_ratio': 0.8906166219839142, 'ndcg': 0.3113045144719115}
I0415 00:32:00.144654 18880 trainer.py:139] Epoch[900/1500] loss: 0.10482500084946232
I0415 00:32:05.732451 18880 trainer.py:139] Epoch[901/1500] loss: 0.10568000784804744
I0415 00:32:10.479569 18880 trainer.py:139] Epoch[902/1500] loss: 0.10652540191527336
I0415 00:32:15.239973 18880 trainer.py:139] Epoch[903/1500] loss: 0.10743740681679018
I0415 00:32:20.031943 18880 trainer.py:139] Epoch[904/1500] loss: 0.10647136958376054
I0415 00:32:24.539862 18880 trainer.py:139] Epoch[905/1500] loss: 0.10476951565473311
I0415 00:32:30.881644 18880 trainer.py:139] Epoch[906/1500] loss: 0.10499014825590196
I0415 00:32:35.822118 18880 trainer.py:139] Epoch[907/1500] loss: 0.10532542438276353
I0415 00:32:40.424720 18880 trainer.py:139] Epoch[908/1500] loss: 0.10562740458596137
I0415 00:32:45.036292 18880 trainer.py:139] Epoch[909/1500] loss: 0.10396397666585061
I0415 00:32:49.615972 18880 trainer.py:139] Epoch[910/1500] loss: 0.10546028758248975
I0415 00:32:55.973703 18880 trainer.py:139] Epoch[911/1500] loss: 0.10493309363242119
I0415 00:33:00.755705 18880 trainer.py:139] Epoch[912/1500] loss: 0.10540904513289852
I0415 00:33:05.301496 18880 trainer.py:139] Epoch[913/1500] loss: 0.10492174231236981
I0415 00:33:09.815395 18880 trainer.py:139] Epoch[914/1500] loss: 0.10612348635350505
I0415 00:33:14.345241 18880 trainer.py:139] Epoch[915/1500] loss: 0.10465059333270596
I0415 00:33:20.133879 18880 trainer.py:139] Epoch[916/1500] loss: 0.10373927172153227
I0415 00:33:25.367367 18880 trainer.py:139] Epoch[917/1500] loss: 0.1030435961100363
I0415 00:33:30.016813 18880 trainer.py:139] Epoch[918/1500] loss: 0.10446039491122769
I0415 00:33:34.693168 18880 trainer.py:139] Epoch[919/1500] loss: 0.10447075145859872
I0415 00:33:39.197101 18880 trainer.py:139] Epoch[920/1500] loss: 0.10575802431952569
I0415 00:33:43.849538 18880 trainer.py:139] Epoch[921/1500] loss: 0.10515826147410177
I0415 00:33:50.039829 18880 trainer.py:139] Epoch[922/1500] loss: 0.10373287768133226
I0415 00:33:54.888607 18880 trainer.py:139] Epoch[923/1500] loss: 0.10471247977787448
I0415 00:33:59.531076 18880 trainer.py:139] Epoch[924/1500] loss: 0.10511450854039961
I0415 00:34:04.010092 18880 trainer.py:139] Epoch[925/1500] loss: 0.10721751230378304
I0415 00:34:08.496083 18880 trainer.py:139] Epoch[926/1500] loss: 0.1055826578409441
I0415 00:34:14.616609 18880 trainer.py:139] Epoch[927/1500] loss: 0.10399571926363053
I0415 00:34:19.327849 18880 trainer.py:139] Epoch[928/1500] loss: 0.10470131279960755
I0415 00:34:23.974809 18880 trainer.py:139] Epoch[929/1500] loss: 0.10543492844989223
I0415 00:34:28.691956 18880 trainer.py:139] Epoch[930/1500] loss: 0.10584602456900381
I0415 00:34:33.524835 18880 trainer.py:139] Epoch[931/1500] loss: 0.10646158817314333
I0415 00:34:39.750451 18880 trainer.py:139] Epoch[932/1500] loss: 0.1060423661143549
I0415 00:34:44.389930 18880 trainer.py:139] Epoch[933/1500] loss: 0.1045188632222914
I0415 00:34:49.013463 18880 trainer.py:139] Epoch[934/1500] loss: 0.10389512536987182
I0415 00:34:53.659918 18880 trainer.py:139] Epoch[935/1500] loss: 0.10574271433776425
I0415 00:34:58.355211 18880 trainer.py:139] Epoch[936/1500] loss: 0.10593298317924622
I0415 00:35:04.909284 18880 trainer.py:139] Epoch[937/1500] loss: 0.10591416998255637
I0415 00:35:09.594611 18880 trainer.py:139] Epoch[938/1500] loss: 0.10659080575550756
I0415 00:35:14.234090 18880 trainer.py:139] Epoch[939/1500] loss: 0.1050948757798441
I0415 00:35:18.785863 18880 trainer.py:139] Epoch[940/1500] loss: 0.1047686271129116
I0415 00:35:23.507067 18880 trainer.py:139] Epoch[941/1500] loss: 0.10625499775332789
I0415 00:35:29.352059 18880 trainer.py:139] Epoch[942/1500] loss: 0.1051626157376074
I0415 00:35:34.509804 18880 trainer.py:139] Epoch[943/1500] loss: 0.10454122818285419
I0415 00:35:39.340643 18880 trainer.py:139] Epoch[944/1500] loss: 0.10552249488330656
I0415 00:35:43.898396 18880 trainer.py:139] Epoch[945/1500] loss: 0.10541240846918475
I0415 00:35:48.573754 18880 trainer.py:139] Epoch[946/1500] loss: 0.10591828799055468
I0415 00:35:53.398613 18880 trainer.py:139] Epoch[947/1500] loss: 0.10750133496138357
I0415 00:35:59.773721 18880 trainer.py:139] Epoch[948/1500] loss: 0.10508009094384409
I0415 00:36:04.298584 18880 trainer.py:139] Epoch[949/1500] loss: 0.10421558517602182
I0415 00:36:04.534794 18880 trainer.py:145] Test: {'precision': 0.13753351206434325, 'recall': 0.3230684339491311, 'hit_ratio': 0.892225201072386, 'ndcg': 0.3090074436058551}
I0415 00:36:09.263973 18880 trainer.py:139] Epoch[950/1500] loss: 0.10453571283048199
I0415 00:36:13.942322 18880 trainer.py:139] Epoch[951/1500] loss: 0.10458216671982119
I0415 00:36:18.676484 18880 trainer.py:139] Epoch[952/1500] loss: 0.10465159243152987
I0415 00:36:24.738632 18880 trainer.py:139] Epoch[953/1500] loss: 0.10415595000790011
I0415 00:36:29.383095 18880 trainer.py:139] Epoch[954/1500] loss: 0.10546153567491039
I0415 00:36:33.999652 18880 trainer.py:139] Epoch[955/1500] loss: 0.10448273727970739
I0415 00:36:38.373940 18880 trainer.py:139] Epoch[956/1500] loss: 0.10407356461209635
I0415 00:36:42.976052 18880 trainer.py:139] Epoch[957/1500] loss: 0.10258391403382824
I0415 00:36:48.857376 18880 trainer.py:139] Epoch[958/1500] loss: 0.10481084883213043
I0415 00:36:53.935388 18880 trainer.py:139] Epoch[959/1500] loss: 0.10547121349842317
I0415 00:36:58.499120 18880 trainer.py:139] Epoch[960/1500] loss: 0.10492090280017545
I0415 00:37:03.232678 18880 trainer.py:139] Epoch[961/1500] loss: 0.10467480147077192
I0415 00:37:07.790430 18880 trainer.py:139] Epoch[962/1500] loss: 0.1058997824307411
I0415 00:37:13.281065 18880 trainer.py:139] Epoch[963/1500] loss: 0.10598964099922488
I0415 00:37:18.763720 18880 trainer.py:139] Epoch[964/1500] loss: 0.10459828424838281
I0415 00:37:23.366322 18880 trainer.py:139] Epoch[965/1500] loss: 0.1049521894704911
I0415 00:37:27.891184 18880 trainer.py:139] Epoch[966/1500] loss: 0.10405647682566796
I0415 00:37:32.493786 18880 trainer.py:139] Epoch[967/1500] loss: 0.10442736192095664
I0415 00:37:37.027620 18880 trainer.py:139] Epoch[968/1500] loss: 0.10413554647276478
I0415 00:37:43.295650 18880 trainer.py:139] Epoch[969/1500] loss: 0.1038767798773704
I0415 00:37:47.851599 18880 trainer.py:139] Epoch[970/1500] loss: 0.10469301477555305
I0415 00:37:52.548883 18880 trainer.py:139] Epoch[971/1500] loss: 0.10531180832655199
I0415 00:37:56.972086 18880 trainer.py:139] Epoch[972/1500] loss: 0.10369929815492322
I0415 00:38:01.660403 18880 trainer.py:139] Epoch[973/1500] loss: 0.10458190114267411
I0415 00:38:07.472957 18880 trainer.py:139] Epoch[974/1500] loss: 0.1053619759698068
I0415 00:38:12.540005 18880 trainer.py:139] Epoch[975/1500] loss: 0.1059350554020174
I0415 00:38:17.078821 18880 trainer.py:139] Epoch[976/1500] loss: 0.10474945604801178
I0415 00:38:21.787070 18880 trainer.py:139] Epoch[977/1500] loss: 0.10472012864005181
I0415 00:38:26.395653 18880 trainer.py:139] Epoch[978/1500] loss: 0.10409538159447332
I0415 00:38:31.456722 18880 trainer.py:139] Epoch[979/1500] loss: 0.10427650568946716
I0415 00:38:37.203495 18880 trainer.py:139] Epoch[980/1500] loss: 0.10521637504139254
I0415 00:38:41.997459 18880 trainer.py:139] Epoch[981/1500] loss: 0.10435232592205848
I0415 00:38:46.542255 18880 trainer.py:139] Epoch[982/1500] loss: 0.10441318995529605
I0415 00:38:51.290369 18880 trainer.py:139] Epoch[983/1500] loss: 0.10676882175668594
I0415 00:38:56.035495 18880 trainer.py:139] Epoch[984/1500] loss: 0.10406767721137693
I0415 00:39:02.280603 18880 trainer.py:139] Epoch[985/1500] loss: 0.10541525819609242
I0415 00:39:06.960945 18880 trainer.py:139] Epoch[986/1500] loss: 0.10578922759140691
I0415 00:39:11.525674 18880 trainer.py:139] Epoch[987/1500] loss: 0.10507070273160934
I0415 00:39:16.241897 18880 trainer.py:139] Epoch[988/1500] loss: 0.10560728225015825
I0415 00:39:21.006955 18880 trainer.py:139] Epoch[989/1500] loss: 0.10472373279833025
I0415 00:39:27.169339 18880 trainer.py:139] Epoch[990/1500] loss: 0.10427705174492251
I0415 00:39:32.121771 18880 trainer.py:139] Epoch[991/1500] loss: 0.10470804668241931
I0415 00:39:36.734340 18880 trainer.py:139] Epoch[992/1500] loss: 0.10474114889098753
I0415 00:39:41.383785 18880 trainer.py:139] Epoch[993/1500] loss: 0.1036271135653219
I0415 00:39:46.283395 18880 trainer.py:139] Epoch[994/1500] loss: 0.10407342329140633
I0415 00:39:52.575346 18880 trainer.py:139] Epoch[995/1500] loss: 0.10327292906661187
I0415 00:39:57.220805 18880 trainer.py:139] Epoch[996/1500] loss: 0.10514898429955205
I0415 00:40:01.835367 18880 trainer.py:139] Epoch[997/1500] loss: 0.10543892292245742
I0415 00:40:06.709062 18880 trainer.py:139] Epoch[998/1500] loss: 0.10553780895087027
I0415 00:40:11.365484 18880 trainer.py:139] Epoch[999/1500] loss: 0.10319099647383537
I0415 00:40:11.626611 18880 trainer.py:145] Test: {'precision': 0.1373458445040215, 'recall': 0.32374786885822627, 'hit_ratio': 0.8916890080428954, 'ndcg': 0.30946466610242995}
I0415 00:40:16.477384 18880 trainer.py:139] Epoch[1000/1500] loss: 0.1049768653127455
I0415 00:40:22.436447 18880 trainer.py:139] Epoch[1001/1500] loss: 0.10609184421839253
I0415 00:40:27.152671 18880 trainer.py:139] Epoch[1002/1500] loss: 0.10495963740733362
I0415 00:40:31.808095 18880 trainer.py:139] Epoch[1003/1500] loss: 0.10471333491225396
I0415 00:40:36.392688 18880 trainer.py:139] Epoch[1004/1500] loss: 0.10555820311269452
I0415 00:40:41.121868 18880 trainer.py:139] Epoch[1005/1500] loss: 0.10368114950195435
I0415 00:40:47.271739 18880 trainer.py:139] Epoch[1006/1500] loss: 0.10343041751653917
I0415 00:40:51.998924 18880 trainer.py:139] Epoch[1007/1500] loss: 0.10484539621299313
I0415 00:40:56.904513 18880 trainer.py:139] Epoch[1008/1500] loss: 0.10385002195835114
I0415 00:41:01.562928 18880 trainer.py:139] Epoch[1009/1500] loss: 0.10522914822063138
I0415 00:41:06.155565 18880 trainer.py:139] Epoch[1010/1500] loss: 0.10389479706364294
I0415 00:41:12.173432 18880 trainer.py:139] Epoch[1011/1500] loss: 0.10419752280558309
I0415 00:41:16.983341 18880 trainer.py:139] Epoch[1012/1500] loss: 0.10522224129207673
I0415 00:41:21.565014 18880 trainer.py:139] Epoch[1013/1500] loss: 0.10451437076253275
I0415 00:41:26.192531 18880 trainer.py:139] Epoch[1014/1500] loss: 0.10635806716257526
I0415 00:41:30.856928 18880 trainer.py:139] Epoch[1015/1500] loss: 0.1056471755427699
I0415 00:41:35.716670 18880 trainer.py:139] Epoch[1016/1500] loss: 0.10461247327827639
I0415 00:41:41.943836 18880 trainer.py:139] Epoch[1017/1500] loss: 0.10328561091615308
I0415 00:41:46.712882 18880 trainer.py:139] Epoch[1018/1500] loss: 0.10459757836595658
I0415 00:41:51.366315 18880 trainer.py:139] Epoch[1019/1500] loss: 0.10436685791900081
I0415 00:41:56.066595 18880 trainer.py:139] Epoch[1020/1500] loss: 0.10303480923175812
I0415 00:42:00.733981 18880 trainer.py:139] Epoch[1021/1500] loss: 0.10307498516574982
I0415 00:42:05.996376 18880 trainer.py:139] Epoch[1022/1500] loss: 0.10433613460871481
I0415 00:42:11.635512 18880 trainer.py:139] Epoch[1023/1500] loss: 0.10460133105516434
I0415 00:42:16.167446 18880 trainer.py:139] Epoch[1024/1500] loss: 0.1041722824015925
I0415 00:42:20.955428 18880 trainer.py:139] Epoch[1025/1500] loss: 0.10392395455029703
I0415 00:42:25.600811 18880 trainer.py:139] Epoch[1026/1500] loss: 0.10424307902013102
I0415 00:42:30.183482 18880 trainer.py:139] Epoch[1027/1500] loss: 0.10481274296199122
I0415 00:42:36.401677 18880 trainer.py:139] Epoch[1028/1500] loss: 0.10373194347466191
I0415 00:42:41.378028 18880 trainer.py:139] Epoch[1029/1500] loss: 0.10447003668354403
I0415 00:42:46.001561 18880 trainer.py:139] Epoch[1030/1500] loss: 0.10463196351643532
I0415 00:42:50.782002 18880 trainer.py:139] Epoch[1031/1500] loss: 0.10444399257821421
I0415 00:42:55.401548 18880 trainer.py:139] Epoch[1032/1500] loss: 0.10431319763583521
I0415 00:43:01.815092 18880 trainer.py:139] Epoch[1033/1500] loss: 0.10352546745730985
I0415 00:43:06.207398 18880 trainer.py:139] Epoch[1034/1500] loss: 0.10257522737787615
I0415 00:43:10.926610 18880 trainer.py:139] Epoch[1035/1500] loss: 0.10590236369640596
I0415 00:43:15.355794 18880 trainer.py:139] Epoch[1036/1500] loss: 0.10441316880526082
I0415 00:43:20.481645 18880 trainer.py:139] Epoch[1037/1500] loss: 0.10525489430273732
I0415 00:43:26.107823 18880 trainer.py:139] Epoch[1038/1500] loss: 0.10411907299872368
I0415 00:43:30.647635 18880 trainer.py:139] Epoch[1039/1500] loss: 0.10459465509460818
I0415 00:43:35.150571 18880 trainer.py:139] Epoch[1040/1500] loss: 0.10485486950605147
I0415 00:43:39.821944 18880 trainer.py:139] Epoch[1041/1500] loss: 0.10422419780685056
I0415 00:43:44.585009 18880 trainer.py:139] Epoch[1042/1500] loss: 0.10346401843332476
I0415 00:43:50.924799 18880 trainer.py:139] Epoch[1043/1500] loss: 0.10524899873041338
I0415 00:43:55.656970 18880 trainer.py:139] Epoch[1044/1500] loss: 0.10445119921238191
I0415 00:44:00.172861 18880 trainer.py:139] Epoch[1045/1500] loss: 0.10515391442083544
I0415 00:44:04.716660 18880 trainer.py:139] Epoch[1046/1500] loss: 0.10546176496051973
I0415 00:44:09.567432 18880 trainer.py:139] Epoch[1047/1500] loss: 0.10380241899721084
I0415 00:44:15.852406 18880 trainer.py:139] Epoch[1048/1500] loss: 0.10401051972181566
I0415 00:44:20.648362 18880 trainer.py:139] Epoch[1049/1500] loss: 0.10587097175659672
I0415 00:44:20.908492 18880 trainer.py:145] Test: {'precision': 0.13833780160857914, 'recall': 0.3269655709199946, 'hit_ratio': 0.8916890080428954, 'ndcg': 0.3054877737370326}
I0415 00:44:25.495147 18880 trainer.py:139] Epoch[1050/1500] loss: 0.10446264474622664
I0415 00:44:30.146587 18880 trainer.py:139] Epoch[1051/1500] loss: 0.10383732328491826
I0415 00:44:34.670453 18880 trainer.py:139] Epoch[1052/1500] loss: 0.10470074583445826
I0415 00:44:40.448649 18880 trainer.py:139] Epoch[1053/1500] loss: 0.10348406650366322
I0415 00:44:45.647255 18880 trainer.py:139] Epoch[1054/1500] loss: 0.10310250785081618
I0415 00:44:50.341550 18880 trainer.py:139] Epoch[1055/1500] loss: 0.10557069725567295
I0415 00:44:55.104617 18880 trainer.py:139] Epoch[1056/1500] loss: 0.10362691720647196
I0415 00:44:59.770008 18880 trainer.py:139] Epoch[1057/1500] loss: 0.10276602016341302
I0415 00:45:04.993536 18880 trainer.py:139] Epoch[1058/1500] loss: 0.10436035716725935
I0415 00:45:10.924691 18880 trainer.py:139] Epoch[1059/1500] loss: 0.1035097484146395
I0415 00:45:15.485433 18880 trainer.py:139] Epoch[1060/1500] loss: 0.10429599809069787
I0415 00:45:20.039199 18880 trainer.py:139] Epoch[1061/1500] loss: 0.10524683830238157
I0415 00:45:24.990615 18880 trainer.py:139] Epoch[1062/1500] loss: 0.10658118945937003
I0415 00:45:29.527438 18880 trainer.py:139] Epoch[1063/1500] loss: 0.10399354946228766
I0415 00:45:35.740623 18880 trainer.py:139] Epoch[1064/1500] loss: 0.1031644320295703
I0415 00:45:40.562492 18880 trainer.py:139] Epoch[1065/1500] loss: 0.10417645160228975
I0415 00:45:45.169507 18880 trainer.py:139] Epoch[1066/1500] loss: 0.10361594418364187
I0415 00:45:49.916626 18880 trainer.py:139] Epoch[1067/1500] loss: 0.10334636511341218
I0415 00:45:54.651785 18880 trainer.py:139] Epoch[1068/1500] loss: 0.10288585025456644
I0415 00:46:00.594332 18880 trainer.py:139] Epoch[1069/1500] loss: 0.10416206741525282
I0415 00:46:05.465037 18880 trainer.py:139] Epoch[1070/1500] loss: 0.10334755215914018
I0415 00:46:10.008837 18880 trainer.py:139] Epoch[1071/1500] loss: 0.10388085750802871
I0415 00:46:14.598482 18880 trainer.py:139] Epoch[1072/1500] loss: 0.10390960136728902
I0415 00:46:19.282811 18880 trainer.py:139] Epoch[1073/1500] loss: 0.10378738132215315
I0415 00:46:24.356838 18880 trainer.py:139] Epoch[1074/1500] loss: 0.10303997584889012
I0415 00:46:30.401613 18880 trainer.py:139] Epoch[1075/1500] loss: 0.10340819628007951
I0415 00:46:34.962287 18880 trainer.py:139] Epoch[1076/1500] loss: 0.10393987091318253
I0415 00:46:39.492163 18880 trainer.py:139] Epoch[1077/1500] loss: 0.10451676071651521
I0415 00:46:43.988122 18880 trainer.py:139] Epoch[1078/1500] loss: 0.10336725437833418
I0415 00:46:48.734242 18880 trainer.py:139] Epoch[1079/1500] loss: 0.10573314442749947
I0415 00:46:54.878687 18880 trainer.py:139] Epoch[1080/1500] loss: 0.10298855073990361
I0415 00:46:59.584943 18880 trainer.py:139] Epoch[1081/1500] loss: 0.10425818495212062
I0415 00:47:04.168608 18880 trainer.py:139] Epoch[1082/1500] loss: 0.10384064480181664
I0415 00:47:08.824035 18880 trainer.py:139] Epoch[1083/1500] loss: 0.10421420537656353
I0415 00:47:13.489427 18880 trainer.py:139] Epoch[1084/1500] loss: 0.10518211967522098
I0415 00:47:19.555137 18880 trainer.py:139] Epoch[1085/1500] loss: 0.10499835783435453
I0415 00:47:24.738793 18880 trainer.py:139] Epoch[1086/1500] loss: 0.10474715381860733
I0415 00:47:29.199869 18880 trainer.py:139] Epoch[1087/1500] loss: 0.10466193335671578
I0415 00:47:33.755628 18880 trainer.py:139] Epoch[1088/1500] loss: 0.10517423503821896
I0415 00:47:38.475837 18880 trainer.py:139] Epoch[1089/1500] loss: 0.10355446631869962
I0415 00:47:44.572440 18880 trainer.py:139] Epoch[1090/1500] loss: 0.1035995045977254
I0415 00:47:49.040493 18880 trainer.py:139] Epoch[1091/1500] loss: 0.1038496847594938
I0415 00:47:53.656052 18880 trainer.py:139] Epoch[1092/1500] loss: 0.102691650390625
I0415 00:47:58.360314 18880 trainer.py:139] Epoch[1093/1500] loss: 0.10413891053007494
I0415 00:48:02.939994 18880 trainer.py:139] Epoch[1094/1500] loss: 0.10496474994767097
I0415 00:48:08.534280 18880 trainer.py:139] Epoch[1095/1500] loss: 0.10677530328112264
I0415 00:48:13.943183 18880 trainer.py:139] Epoch[1096/1500] loss: 0.10347456028384547
I0415 00:48:18.562731 18880 trainer.py:139] Epoch[1097/1500] loss: 0.10397899511360353
I0415 00:48:23.191244 18880 trainer.py:139] Epoch[1098/1500] loss: 0.10416299705543826
I0415 00:48:27.927401 18880 trainer.py:139] Epoch[1099/1500] loss: 0.10456546972836217
I0415 00:48:28.196501 18880 trainer.py:145] Test: {'precision': 0.13865951742627355, 'recall': 0.3229551805848921, 'hit_ratio': 0.8954423592493298, 'ndcg': 0.3082695609162354}
I0415 00:48:32.821032 18880 trainer.py:139] Epoch[1100/1500] loss: 0.10340933838198262
I0415 00:48:38.847866 18880 trainer.py:139] Epoch[1101/1500] loss: 0.10334222427298946
I0415 00:48:43.714587 18880 trainer.py:139] Epoch[1102/1500] loss: 0.10379886651231397
I0415 00:48:48.360044 18880 trainer.py:139] Epoch[1103/1500] loss: 0.10273053449007773
I0415 00:48:53.232743 18880 trainer.py:139] Epoch[1104/1500] loss: 0.10291840328324225
I0415 00:48:57.780530 18880 trainer.py:139] Epoch[1105/1500] loss: 0.10405983775854111
I0415 00:49:02.930304 18880 trainer.py:139] Epoch[1106/1500] loss: 0.10283698333847907
I0415 00:49:08.734883 18880 trainer.py:139] Epoch[1107/1500] loss: 0.10391339154974107
I0415 00:49:13.429178 18880 trainer.py:139] Epoch[1108/1500] loss: 0.10440306221285174
I0415 00:49:18.227128 18880 trainer.py:139] Epoch[1109/1500] loss: 0.10383946280325612
I0415 00:49:22.823713 18880 trainer.py:139] Epoch[1110/1500] loss: 0.1028132513165474
I0415 00:49:27.560863 18880 trainer.py:139] Epoch[1111/1500] loss: 0.10439311280365914
I0415 00:49:33.953940 18880 trainer.py:139] Epoch[1112/1500] loss: 0.10366996714184361
I0415 00:49:38.756872 18880 trainer.py:139] Epoch[1113/1500] loss: 0.1039023968961931
I0415 00:49:43.379409 18880 trainer.py:139] Epoch[1114/1500] loss: 0.10490164713513467
I0415 00:49:48.071711 18880 trainer.py:139] Epoch[1115/1500] loss: 0.10365531425322255
I0415 00:49:52.953379 18880 trainer.py:139] Epoch[1116/1500] loss: 0.10421352376860957
I0415 00:49:58.967695 18880 trainer.py:139] Epoch[1117/1500] loss: 0.10551944999925551
I0415 00:50:03.872287 18880 trainer.py:139] Epoch[1118/1500] loss: 0.10454039323714472
I0415 00:50:08.420075 18880 trainer.py:139] Epoch[1119/1500] loss: 0.1033277292886088
I0415 00:50:13.306725 18880 trainer.py:139] Epoch[1120/1500] loss: 0.1042492411309673
I0415 00:50:17.866472 18880 trainer.py:139] Epoch[1121/1500] loss: 0.10409426641079687
I0415 00:50:22.403294 18880 trainer.py:139] Epoch[1122/1500] loss: 0.10426923608587634
I0415 00:50:28.818895 18880 trainer.py:139] Epoch[1123/1500] loss: 0.10394692348857079
I0415 00:50:33.560034 18880 trainer.py:139] Epoch[1124/1500] loss: 0.10399257343622946
I0415 00:50:38.273247 18880 trainer.py:139] Epoch[1125/1500] loss: 0.10290656599306292
I0415 00:50:43.054702 18880 trainer.py:139] Epoch[1126/1500] loss: 0.10429461997362875
I0415 00:50:47.519766 18880 trainer.py:139] Epoch[1127/1500] loss: 0.10489142205445998
I0415 00:50:53.885469 18880 trainer.py:139] Epoch[1128/1500] loss: 0.103280944208945
I0415 00:50:58.642005 18880 trainer.py:139] Epoch[1129/1500] loss: 0.10367824954371299
I0415 00:51:03.360221 18880 trainer.py:139] Epoch[1130/1500] loss: 0.10380870728723464
I0415 00:51:07.852193 18880 trainer.py:139] Epoch[1131/1500] loss: 0.10337939089344393
I0415 00:51:12.408948 18880 trainer.py:139] Epoch[1132/1500] loss: 0.10258968751276692
I0415 00:51:18.799569 18880 trainer.py:139] Epoch[1133/1500] loss: 0.10453873031562375
I0415 00:51:23.436059 18880 trainer.py:139] Epoch[1134/1500] loss: 0.10378907524770306
I0415 00:51:27.932017 18880 trainer.py:139] Epoch[1135/1500] loss: 0.10303643177593907
I0415 00:51:32.799732 18880 trainer.py:139] Epoch[1136/1500] loss: 0.10490794551949348
I0415 00:51:37.401338 18880 trainer.py:139] Epoch[1137/1500] loss: 0.10411282388433334
I0415 00:51:42.739480 18880 trainer.py:139] Epoch[1138/1500] loss: 0.10473037439007912
I0415 00:51:48.402959 18880 trainer.py:139] Epoch[1139/1500] loss: 0.10416142354088445
I0415 00:51:53.000577 18880 trainer.py:139] Epoch[1140/1500] loss: 0.10309048621885238
I0415 00:51:57.529425 18880 trainer.py:139] Epoch[1141/1500] loss: 0.10376641202357507
I0415 00:52:02.080662 18880 trainer.py:139] Epoch[1142/1500] loss: 0.10324805350072923
I0415 00:52:06.797882 18880 trainer.py:139] Epoch[1143/1500] loss: 0.10494508233762556
I0415 00:52:12.882525 18880 trainer.py:139] Epoch[1144/1500] loss: 0.10370796654493578
I0415 00:52:17.507054 18880 trainer.py:139] Epoch[1145/1500] loss: 0.10413018325644155
I0415 00:52:22.140554 18880 trainer.py:139] Epoch[1146/1500] loss: 0.10335875807269927
I0415 00:52:26.846810 18880 trainer.py:139] Epoch[1147/1500] loss: 0.10467311691853308
I0415 00:52:31.434461 18880 trainer.py:139] Epoch[1148/1500] loss: 0.1036298565806881
I0415 00:52:37.376584 18880 trainer.py:139] Epoch[1149/1500] loss: 0.10386413864551051
I0415 00:52:37.678574 18880 trainer.py:145] Test: {'precision': 0.13820375335120652, 'recall': 0.3235975086173005, 'hit_ratio': 0.8949061662198391, 'ndcg': 0.30991607650641695}
I0415 00:52:42.583165 18880 trainer.py:139] Epoch[1150/1500] loss: 0.10306565103030974
I0415 00:52:47.239587 18880 trainer.py:139] Epoch[1151/1500] loss: 0.1040232727123845
I0415 00:52:52.022586 18880 trainer.py:139] Epoch[1152/1500] loss: 0.1048884043289769
I0415 00:52:56.827511 18880 trainer.py:139] Epoch[1153/1500] loss: 0.1045514660016183
I0415 00:53:01.575627 18880 trainer.py:139] Epoch[1154/1500] loss: 0.10417825872859647
I0415 00:53:07.835686 18880 trainer.py:139] Epoch[1155/1500] loss: 0.1043384555847414
I0415 00:53:12.696423 18880 trainer.py:139] Epoch[1156/1500] loss: 0.10367402650656239
I0415 00:53:17.488392 18880 trainer.py:139] Epoch[1157/1500] loss: 0.10259582462810701
I0415 00:53:22.028205 18880 trainer.py:139] Epoch[1158/1500] loss: 0.10358557705917666
I0415 00:53:26.755392 18880 trainer.py:139] Epoch[1159/1500] loss: 0.10441530207472463
I0415 00:53:32.235059 18880 trainer.py:139] Epoch[1160/1500] loss: 0.10383858988361974
I0415 00:53:37.617054 18880 trainer.py:139] Epoch[1161/1500] loss: 0.10342957127478815
I0415 00:53:42.088095 18880 trainer.py:139] Epoch[1162/1500] loss: 0.10322102519773668
I0415 00:53:46.684718 18880 trainer.py:139] Epoch[1163/1500] loss: 0.10327949567187217
I0415 00:53:51.531503 18880 trainer.py:139] Epoch[1164/1500] loss: 0.10438670242025007
I0415 00:53:56.117162 18880 trainer.py:139] Epoch[1165/1500] loss: 0.1031298870521207
I0415 00:54:02.477367 18880 trainer.py:139] Epoch[1166/1500] loss: 0.10363006760035792
I0415 00:54:07.101896 18880 trainer.py:139] Epoch[1167/1500] loss: 0.1038653903430508
I0415 00:54:11.806158 18880 trainer.py:139] Epoch[1168/1500] loss: 0.10341757920480543
I0415 00:54:16.448564 18880 trainer.py:139] Epoch[1169/1500] loss: 0.1024736057846777
I0415 00:54:21.140336 18880 trainer.py:139] Epoch[1170/1500] loss: 0.10471514083685414
I0415 00:54:27.431763 18880 trainer.py:139] Epoch[1171/1500] loss: 0.10243261605501175
I0415 00:54:32.145993 18880 trainer.py:139] Epoch[1172/1500] loss: 0.1040368705026565
I0415 00:54:36.840288 18880 trainer.py:139] Epoch[1173/1500] loss: 0.1036324582753643
I0415 00:54:41.444885 18880 trainer.py:139] Epoch[1174/1500] loss: 0.10407951978906509
I0415 00:54:45.814266 18880 trainer.py:139] Epoch[1175/1500] loss: 0.10384863927479714
I0415 00:54:50.722847 18880 trainer.py:139] Epoch[1176/1500] loss: 0.10518073530927781
I0415 00:54:56.822439 18880 trainer.py:139] Epoch[1177/1500] loss: 0.10347847880855683
I0415 00:55:01.384178 18880 trainer.py:139] Epoch[1178/1500] loss: 0.10370815617422904
I0415 00:55:06.121254 18880 trainer.py:139] Epoch[1179/1500] loss: 0.10265351423332768
I0415 00:55:10.816053 18880 trainer.py:139] Epoch[1180/1500] loss: 0.10417874301633527
I0415 00:55:15.391745 18880 trainer.py:139] Epoch[1181/1500] loss: 0.10298265348519048
I0415 00:55:20.803578 18880 trainer.py:139] Epoch[1182/1500] loss: 0.10257979890992565
I0415 00:55:26.401849 18880 trainer.py:139] Epoch[1183/1500] loss: 0.10321882463270618
I0415 00:55:31.183852 18880 trainer.py:139] Epoch[1184/1500] loss: 0.10380421026099113
I0415 00:55:35.920008 18880 trainer.py:139] Epoch[1185/1500] loss: 0.1029241303763082
I0415 00:55:40.602343 18880 trainer.py:139] Epoch[1186/1500] loss: 0.10366490339079211
I0415 00:55:45.365410 18880 trainer.py:139] Epoch[1187/1500] loss: 0.10311548171504852
I0415 00:55:51.786095 18880 trainer.py:139] Epoch[1188/1500] loss: 0.10304840029247346
I0415 00:55:56.490357 18880 trainer.py:139] Epoch[1189/1500] loss: 0.10494146399920987
I0415 00:56:01.212484 18880 trainer.py:139] Epoch[1190/1500] loss: 0.10358212744036029
I0415 00:56:05.677054 18880 trainer.py:139] Epoch[1191/1500] loss: 0.10331480589605146
I0415 00:56:10.308999 18880 trainer.py:139] Epoch[1192/1500] loss: 0.10340313204834538
I0415 00:56:16.168396 18880 trainer.py:139] Epoch[1193/1500] loss: 0.10332126867386603
I0415 00:56:21.134213 18880 trainer.py:139] Epoch[1194/1500] loss: 0.10385732064324041
I0415 00:56:25.829930 18880 trainer.py:139] Epoch[1195/1500] loss: 0.10468429855761989
I0415 00:56:30.550137 18880 trainer.py:139] Epoch[1196/1500] loss: 0.10458463814950758
I0415 00:56:35.258387 18880 trainer.py:139] Epoch[1197/1500] loss: 0.1028732102244131
I0415 00:56:41.280243 18880 trainer.py:139] Epoch[1198/1500] loss: 0.10414396226406097
I0415 00:56:46.262575 18880 trainer.py:139] Epoch[1199/1500] loss: 0.10368293667993238
I0415 00:56:46.496790 18880 trainer.py:145] Test: {'precision': 0.13815013404825746, 'recall': 0.32365359492003565, 'hit_ratio': 0.8943699731903485, 'ndcg': 0.3077160605732956}
I0415 00:56:51.146236 18880 trainer.py:139] Epoch[1200/1500] loss: 0.10302955416902419
I0415 00:56:55.836544 18880 trainer.py:139] Epoch[1201/1500] loss: 0.10397324398640663
I0415 00:57:00.628515 18880 trainer.py:139] Epoch[1202/1500] loss: 0.10351195570922667
I0415 00:57:05.847059 18880 trainer.py:139] Epoch[1203/1500] loss: 0.10557644189365449
I0415 00:57:11.727383 18880 trainer.py:139] Epoch[1204/1500] loss: 0.10345347201631915
I0415 00:57:16.251250 18880 trainer.py:139] Epoch[1205/1500] loss: 0.10260784770211866
I0415 00:57:20.903684 18880 trainer.py:139] Epoch[1206/1500] loss: 0.10425084540920873
I0415 00:57:25.503296 18880 trainer.py:139] Epoch[1207/1500] loss: 0.10310070408928779
I0415 00:57:30.424833 18880 trainer.py:139] Epoch[1208/1500] loss: 0.10361771525875214
I0415 00:57:36.245765 18880 trainer.py:139] Epoch[1209/1500] loss: 0.10342550205607567
I0415 00:57:41.446367 18880 trainer.py:139] Epoch[1210/1500] loss: 0.10464626670845094
I0415 00:57:46.216838 18880 trainer.py:139] Epoch[1211/1500] loss: 0.10404829104100505
I0415 00:57:50.960968 18880 trainer.py:139] Epoch[1212/1500] loss: 0.10377493116163439
I0415 00:57:55.300450 18880 trainer.py:139] Epoch[1213/1500] loss: 0.10367681831121445
I0415 00:58:00.143249 18880 trainer.py:139] Epoch[1214/1500] loss: 0.10359120032479686
I0415 00:58:06.539382 18880 trainer.py:139] Epoch[1215/1500] loss: 0.10468044059891854
I0415 00:58:11.084179 18880 trainer.py:139] Epoch[1216/1500] loss: 0.10140709699161592
I0415 00:58:15.769505 18880 trainer.py:139] Epoch[1217/1500] loss: 0.1016758805321109
I0415 00:58:20.267893 18880 trainer.py:139] Epoch[1218/1500] loss: 0.10332789608547764
I0415 00:58:24.868504 18880 trainer.py:139] Epoch[1219/1500] loss: 0.10261601065435717
I0415 00:58:30.588366 18880 trainer.py:139] Epoch[1220/1500] loss: 0.10315255676546405
I0415 00:58:35.949433 18880 trainer.py:139] Epoch[1221/1500] loss: 0.102369241176113
I0415 00:58:40.577947 18880 trainer.py:139] Epoch[1222/1500] loss: 0.10232445429409703
I0415 00:58:45.315080 18880 trainer.py:139] Epoch[1223/1500] loss: 0.10181251600865394
I0415 00:58:50.090540 18880 trainer.py:139] Epoch[1224/1500] loss: 0.1045711110195806
I0415 00:58:54.832675 18880 trainer.py:139] Epoch[1225/1500] loss: 0.10347037882574144
I0415 00:59:00.989081 18880 trainer.py:139] Epoch[1226/1500] loss: 0.10208006227208723
I0415 00:59:05.672412 18880 trainer.py:139] Epoch[1227/1500] loss: 0.10238069103610131
I0415 00:59:10.273023 18880 trainer.py:139] Epoch[1228/1500] loss: 0.10320274435704754
I0415 00:59:14.912501 18880 trainer.py:139] Epoch[1229/1500] loss: 0.10454715379784184
I0415 00:59:19.949652 18880 trainer.py:139] Epoch[1230/1500] loss: 0.10194854702680342
I0415 00:59:25.933631 18880 trainer.py:139] Epoch[1231/1500] loss: 0.10230041439494779
I0415 00:59:30.556166 18880 trainer.py:139] Epoch[1232/1500] loss: 0.10340786941589848
I0415 00:59:35.311259 18880 trainer.py:139] Epoch[1233/1500] loss: 0.10411421546051579
I0415 00:59:39.793263 18880 trainer.py:139] Epoch[1234/1500] loss: 0.10304793330930895
I0415 00:59:44.398856 18880 trainer.py:139] Epoch[1235/1500] loss: 0.1036270510765814
I0415 00:59:50.611074 18880 trainer.py:139] Epoch[1236/1500] loss: 0.10327665171315593
I0415 00:59:55.229622 18880 trainer.py:139] Epoch[1237/1500] loss: 0.10384982944496217
I0415 00:59:59.916942 18880 trainer.py:139] Epoch[1238/1500] loss: 0.10237859405817525
I0415 01:00:04.803593 18880 trainer.py:139] Epoch[1239/1500] loss: 0.10195413303952064
I0415 01:00:09.438089 18880 trainer.py:139] Epoch[1240/1500] loss: 0.1044752225279808
I0415 01:00:14.647662 18880 trainer.py:139] Epoch[1241/1500] loss: 0.10426364454530901
I0415 01:00:20.519019 18880 trainer.py:139] Epoch[1242/1500] loss: 0.10265289944025778
I0415 01:00:25.026939 18880 trainer.py:139] Epoch[1243/1500] loss: 0.10424531972216021
I0415 01:00:29.844821 18880 trainer.py:139] Epoch[1244/1500] loss: 0.10263725490339341
I0415 01:00:34.414533 18880 trainer.py:139] Epoch[1245/1500] loss: 0.10259177367533406
I0415 01:00:39.305172 18880 trainer.py:139] Epoch[1246/1500] loss: 0.10356131244090296
I0415 01:00:45.654930 18880 trainer.py:139] Epoch[1247/1500] loss: 0.10229994188393315
I0415 01:00:50.352215 18880 trainer.py:139] Epoch[1248/1500] loss: 0.10371351338201953
I0415 01:00:55.042524 18880 trainer.py:139] Epoch[1249/1500] loss: 0.10270671714698115
I0415 01:00:55.294679 18880 trainer.py:145] Test: {'precision': 0.13788203753351214, 'recall': 0.3232215539896507, 'hit_ratio': 0.8949061662198391, 'ndcg': 0.30701446120896764}
I0415 01:00:59.837482 18880 trainer.py:139] Epoch[1250/1500] loss: 0.10283090005959233
I0415 01:01:04.459021 18880 trainer.py:139] Epoch[1251/1500] loss: 0.10341782267055204
I0415 01:01:10.192840 18880 trainer.py:139] Epoch[1252/1500] loss: 0.10207445222523905
I0415 01:01:15.222015 18880 trainer.py:139] Epoch[1253/1500] loss: 0.10345675940475156
I0415 01:01:19.738904 18880 trainer.py:139] Epoch[1254/1500] loss: 0.1032259788724684
I0415 01:01:24.372403 18880 trainer.py:139] Epoch[1255/1500] loss: 0.10448563819931399
I0415 01:01:29.039788 18880 trainer.py:139] Epoch[1256/1500] loss: 0.10286043199800676
I0415 01:01:33.708171 18880 trainer.py:139] Epoch[1257/1500] loss: 0.10439053946925748
I0415 01:01:39.996135 18880 trainer.py:139] Epoch[1258/1500] loss: 0.10414326671631105
I0415 01:01:44.847855 18880 trainer.py:139] Epoch[1259/1500] loss: 0.10309555982389758
I0415 01:01:49.528705 18880 trainer.py:139] Epoch[1260/1500] loss: 0.10354118529827364
I0415 01:01:54.285790 18880 trainer.py:139] Epoch[1261/1500] loss: 0.10302325241988705
I0415 01:01:58.924270 18880 trainer.py:139] Epoch[1262/1500] loss: 0.10269896349599285
I0415 01:02:04.641155 18880 trainer.py:139] Epoch[1263/1500] loss: 0.1033626556877167
I0415 01:02:09.919777 18880 trainer.py:139] Epoch[1264/1500] loss: 0.10301503322778209
I0415 01:02:14.552784 18880 trainer.py:139] Epoch[1265/1500] loss: 0.10462333766683456
I0415 01:02:18.924159 18880 trainer.py:139] Epoch[1266/1500] loss: 0.10254355231600423
I0415 01:02:23.908486 18880 trainer.py:139] Epoch[1267/1500] loss: 0.10384761181569868
I0415 01:02:29.433006 18880 trainer.py:139] Epoch[1268/1500] loss: 0.10280237755467815
I0415 01:02:34.821974 18880 trainer.py:139] Epoch[1269/1500] loss: 0.1033486618149665
I0415 01:02:39.441521 18880 trainer.py:139] Epoch[1270/1500] loss: 0.10349504313161297
I0415 01:02:44.321197 18880 trainer.py:139] Epoch[1271/1500] loss: 0.10404724195118874
I0415 01:02:48.815374 18880 trainer.py:139] Epoch[1272/1500] loss: 0.10435268451129237
I0415 01:02:53.731927 18880 trainer.py:139] Epoch[1273/1500] loss: 0.10279169342210216
I0415 01:02:59.486674 18880 trainer.py:139] Epoch[1274/1500] loss: 0.10341283366564781
I0415 01:03:03.849081 18880 trainer.py:139] Epoch[1275/1500] loss: 0.1028810540033925
I0415 01:03:08.754668 18880 trainer.py:139] Epoch[1276/1500] loss: 0.10330541576108625
I0415 01:03:13.486839 18880 trainer.py:139] Epoch[1277/1500] loss: 0.10283164463696941
I0415 01:03:18.158209 18880 trainer.py:139] Epoch[1278/1500] loss: 0.1045206900565855
I0415 01:03:24.368854 18880 trainer.py:139] Epoch[1279/1500] loss: 0.10241484041175535
I0415 01:03:28.847869 18880 trainer.py:139] Epoch[1280/1500] loss: 0.10301926876268079
I0415 01:03:33.709605 18880 trainer.py:139] Epoch[1281/1500] loss: 0.10265647860304002
I0415 01:03:38.229485 18880 trainer.py:139] Epoch[1282/1500] loss: 0.10324323033132861
I0415 01:03:42.958664 18880 trainer.py:139] Epoch[1283/1500] loss: 0.1034288723622599
I0415 01:03:47.603126 18880 trainer.py:139] Epoch[1284/1500] loss: 0.10360701814774544
I0415 01:03:53.836273 18880 trainer.py:139] Epoch[1285/1500] loss: 0.10336790113679824
I0415 01:03:58.578408 18880 trainer.py:139] Epoch[1286/1500] loss: 0.1031145004014815
I0415 01:04:03.262738 18880 trainer.py:139] Epoch[1287/1500] loss: 0.10241244853504243
I0415 01:04:07.705874 18880 trainer.py:139] Epoch[1288/1500] loss: 0.10212985402153384
I0415 01:04:12.234722 18880 trainer.py:139] Epoch[1289/1500] loss: 0.1025415017239509
I0415 01:04:18.343288 18880 trainer.py:139] Epoch[1290/1500] loss: 0.10347219556570053
I0415 01:04:23.339573 18880 trainer.py:139] Epoch[1291/1500] loss: 0.10255802086284084
I0415 01:04:27.969085 18880 trainer.py:139] Epoch[1292/1500] loss: 0.10269919854979362
I0415 01:04:32.403251 18880 trainer.py:139] Epoch[1293/1500] loss: 0.10312605312755031
I0415 01:04:36.991899 18880 trainer.py:139] Epoch[1294/1500] loss: 0.10427302458593922
I0415 01:04:41.774899 18880 trainer.py:139] Epoch[1295/1500] loss: 0.10238056605862032
I0415 01:04:47.843605 18880 trainer.py:139] Epoch[1296/1500] loss: 0.10325508781017796
I0415 01:04:52.404347 18880 trainer.py:139] Epoch[1297/1500] loss: 0.10348834289658454
I0415 01:04:57.211266 18880 trainer.py:139] Epoch[1298/1500] loss: 0.10236375947152415
I0415 01:05:01.888617 18880 trainer.py:139] Epoch[1299/1500] loss: 0.10385624679826921
I0415 01:05:02.167685 18880 trainer.py:145] Test: {'precision': 0.13857908847184996, 'recall': 0.3227889273861993, 'hit_ratio': 0.8949061662198391, 'ndcg': 0.3085599295204508}
I0415 01:05:06.819123 18880 trainer.py:139] Epoch[1300/1500] loss: 0.10366539849388984
I0415 01:05:12.834394 18880 trainer.py:139] Epoch[1301/1500] loss: 0.1034390073149435
I0415 01:05:17.800779 18880 trainer.py:139] Epoch[1302/1500] loss: 0.10355925535963427
I0415 01:05:22.442250 18880 trainer.py:139] Epoch[1303/1500] loss: 0.10313129521185352
I0415 01:05:27.259137 18880 trainer.py:139] Epoch[1304/1500] loss: 0.10238815555649419
I0415 01:05:31.966388 18880 trainer.py:139] Epoch[1305/1500] loss: 0.10244795103226939
I0415 01:05:36.678625 18880 trainer.py:139] Epoch[1306/1500] loss: 0.10395071823750773
I0415 01:05:42.867969 18880 trainer.py:139] Epoch[1307/1500] loss: 0.10355923420959903
I0415 01:05:47.598145 18880 trainer.py:139] Epoch[1308/1500] loss: 0.1039263098951309
I0415 01:05:52.149917 18880 trainer.py:139] Epoch[1309/1500] loss: 0.10266725262326579
I0415 01:05:56.830259 18880 trainer.py:139] Epoch[1310/1500] loss: 0.10287831002666105
I0415 01:06:01.304292 18880 trainer.py:139] Epoch[1311/1500] loss: 0.10260956542145822
I0415 01:06:06.282640 18880 trainer.py:139] Epoch[1312/1500] loss: 0.1021164458605551
I0415 01:06:12.382834 18880 trainer.py:139] Epoch[1313/1500] loss: 0.10328597767699149
I0415 01:06:16.810022 18880 trainer.py:139] Epoch[1314/1500] loss: 0.1022575968696225
I0415 01:06:21.539201 18880 trainer.py:139] Epoch[1315/1500] loss: 0.10461936578635246
I0415 01:06:26.201602 18880 trainer.py:139] Epoch[1316/1500] loss: 0.10278444665093575
I0415 01:06:30.953706 18880 trainer.py:139] Epoch[1317/1500] loss: 0.10252958103533714
I0415 01:06:36.457505 18880 trainer.py:139] Epoch[1318/1500] loss: 0.10245963931083679
I0415 01:06:41.779699 18880 trainer.py:139] Epoch[1319/1500] loss: 0.10349082802572558
I0415 01:06:46.264652 18880 trainer.py:139] Epoch[1320/1500] loss: 0.10265459336580769
I0415 01:06:51.081048 18880 trainer.py:139] Epoch[1321/1500] loss: 0.10361424040409827
I0415 01:06:55.577949 18880 trainer.py:139] Epoch[1322/1500] loss: 0.10439079735548265
I0415 01:07:00.217934 18880 trainer.py:139] Epoch[1323/1500] loss: 0.10228544834160036
I0415 01:07:06.422156 18880 trainer.py:139] Epoch[1324/1500] loss: 0.10273473565616915
I0415 01:07:11.223604 18880 trainer.py:139] Epoch[1325/1500] loss: 0.10203809555499785
I0415 01:07:15.771388 18880 trainer.py:139] Epoch[1326/1500] loss: 0.10316379752851301
I0415 01:07:20.628141 18880 trainer.py:139] Epoch[1327/1500] loss: 0.10271176912130849
I0415 01:07:25.215794 18880 trainer.py:139] Epoch[1328/1500] loss: 0.10425915881510704
I0415 01:07:30.279853 18880 trainer.py:139] Epoch[1329/1500] loss: 0.10346281143926805
I0415 01:07:36.210439 18880 trainer.py:139] Epoch[1330/1500] loss: 0.1035628340417339
I0415 01:07:40.896761 18880 trainer.py:139] Epoch[1331/1500] loss: 0.1028935301207727
I0415 01:07:45.603451 18880 trainer.py:139] Epoch[1332/1500] loss: 0.10329885636606524
I0415 01:07:50.373492 18880 trainer.py:139] Epoch[1333/1500] loss: 0.10219930448839741
I0415 01:07:55.354748 18880 trainer.py:139] Epoch[1334/1500] loss: 0.103399662240859
I0415 01:08:01.400034 18880 trainer.py:139] Epoch[1335/1500] loss: 0.10287514689468569
I0415 01:08:06.163100 18880 trainer.py:139] Epoch[1336/1500] loss: 0.10316108792058883
I0415 01:08:10.848425 18880 trainer.py:139] Epoch[1337/1500] loss: 0.10277953407456798
I0415 01:08:15.591558 18880 trainer.py:139] Epoch[1338/1500] loss: 0.10211796337558378
I0415 01:08:20.109442 18880 trainer.py:139] Epoch[1339/1500] loss: 0.1023077895083735
I0415 01:08:26.300730 18880 trainer.py:139] Epoch[1340/1500] loss: 0.10376956602258067
I0415 01:08:30.931238 18880 trainer.py:139] Epoch[1341/1500] loss: 0.10182405191083108
I0415 01:08:35.736590 18880 trainer.py:139] Epoch[1342/1500] loss: 0.10340341997723426
I0415 01:08:40.466766 18880 trainer.py:139] Epoch[1343/1500] loss: 0.10332441738536281
I0415 01:08:45.204915 18880 trainer.py:139] Epoch[1344/1500] loss: 0.10277345127636386
I0415 01:08:50.690567 18880 trainer.py:139] Epoch[1345/1500] loss: 0.10228962691560868
I0415 01:08:56.201128 18880 trainer.py:139] Epoch[1346/1500] loss: 0.10323656422476615
I0415 01:09:00.950240 18880 trainer.py:139] Epoch[1347/1500] loss: 0.10328205362443
I0415 01:09:05.704336 18880 trainer.py:139] Epoch[1348/1500] loss: 0.10306591083926539
I0415 01:09:10.431520 18880 trainer.py:139] Epoch[1349/1500] loss: 0.10240736002883603
I0415 01:09:10.670721 18880 trainer.py:145] Test: {'precision': 0.1379356568364612, 'recall': 0.3234352855261231, 'hit_ratio': 0.8970509383378016, 'ndcg': 0.30807306398259415}
I0415 01:09:15.386945 18880 trainer.py:139] Epoch[1350/1500] loss: 0.10351743765415684
I0415 01:09:21.227406 18880 trainer.py:139] Epoch[1351/1500] loss: 0.10342530089039956
I0415 01:09:26.473852 18880 trainer.py:139] Epoch[1352/1500] loss: 0.10289739985619822
I0415 01:09:31.232931 18880 trainer.py:139] Epoch[1353/1500] loss: 0.10380757407795999
I0415 01:09:35.984038 18880 trainer.py:139] Epoch[1354/1500] loss: 0.10264066029940883
I0415 01:09:40.768032 18880 trainer.py:139] Epoch[1355/1500] loss: 0.10291108248695251
I0415 01:09:45.865979 18880 trainer.py:139] Epoch[1356/1500] loss: 0.10282015007349753
I0415 01:09:51.667569 18880 trainer.py:139] Epoch[1357/1500] loss: 0.10340102593744954
I0415 01:09:56.483458 18880 trainer.py:139] Epoch[1358/1500] loss: 0.10445511773709328
I0415 01:10:01.275427 18880 trainer.py:139] Epoch[1359/1500] loss: 0.10341234577278938
I0415 01:10:06.110252 18880 trainer.py:139] Epoch[1360/1500] loss: 0.10216569155454636
I0415 01:10:10.731791 18880 trainer.py:139] Epoch[1361/1500] loss: 0.10401647441810177
I0415 01:10:17.012778 18880 trainer.py:139] Epoch[1362/1500] loss: 0.10352677539471657
I0415 01:10:21.723023 18880 trainer.py:139] Epoch[1363/1500] loss: 0.10434810624968621
I0415 01:10:26.447217 18880 trainer.py:139] Epoch[1364/1500] loss: 0.10193583609596375
I0415 01:10:30.945604 18880 trainer.py:139] Epoch[1365/1500] loss: 0.1031655361575465
I0415 01:10:35.516312 18880 trainer.py:139] Epoch[1366/1500] loss: 0.10295368779090143
I0415 01:10:41.460427 18880 trainer.py:139] Epoch[1367/1500] loss: 0.10237855320015261
I0415 01:10:46.226483 18880 trainer.py:139] Epoch[1368/1500] loss: 0.10301189268788984
I0415 01:10:50.983569 18880 trainer.py:139] Epoch[1369/1500] loss: 0.10429784198922495
I0415 01:10:55.993806 18880 trainer.py:139] Epoch[1370/1500] loss: 0.10300203244532308
I0415 01:11:00.738932 18880 trainer.py:139] Epoch[1371/1500] loss: 0.10230144305575278
I0415 01:11:05.307649 18880 trainer.py:139] Epoch[1372/1500] loss: 0.10214295045983407
I0415 01:11:11.536811 18880 trainer.py:139] Epoch[1373/1500] loss: 0.1033673579654386
I0415 01:11:16.044172 18880 trainer.py:139] Epoch[1374/1500] loss: 0.10284107635098119
I0415 01:11:20.744448 18880 trainer.py:139] Epoch[1375/1500] loss: 0.10312040029994902
I0415 01:11:25.304636 18880 trainer.py:139] Epoch[1376/1500] loss: 0.1042563624439701
I0415 01:11:29.959065 18880 trainer.py:139] Epoch[1377/1500] loss: 0.10367609248045952
I0415 01:11:35.841339 18880 trainer.py:139] Epoch[1378/1500] loss: 0.10311449919977496
I0415 01:11:41.079321 18880 trainer.py:139] Epoch[1379/1500] loss: 0.10295175136097016
I0415 01:11:45.855343 18880 trainer.py:139] Epoch[1380/1500] loss: 0.10415833323232589
I0415 01:11:50.751961 18880 trainer.py:139] Epoch[1381/1500] loss: 0.10176804445443614
I0415 01:11:55.601681 18880 trainer.py:139] Epoch[1382/1500] loss: 0.10307613567959878
I0415 01:12:00.210318 18880 trainer.py:139] Epoch[1383/1500] loss: 0.10245344451358242
I0415 01:12:06.390612 18880 trainer.py:139] Epoch[1384/1500] loss: 0.10285974726561577
I0415 01:12:11.066475 18880 trainer.py:139] Epoch[1385/1500] loss: 0.10329414663776275
I0415 01:12:15.624228 18880 trainer.py:139] Epoch[1386/1500] loss: 0.10209922708811299
I0415 01:12:20.098260 18880 trainer.py:139] Epoch[1387/1500] loss: 0.10272098572984818
I0415 01:12:24.751693 18880 trainer.py:139] Epoch[1388/1500] loss: 0.1020165073775476
I0415 01:12:29.760937 18880 trainer.py:139] Epoch[1389/1500] loss: 0.10240704349933132
I0415 01:12:35.849566 18880 trainer.py:139] Epoch[1390/1500] loss: 0.10222642267903974
I0415 01:12:40.491039 18880 trainer.py:139] Epoch[1391/1500] loss: 0.1048452825315537
I0415 01:12:45.220218 18880 trainer.py:139] Epoch[1392/1500] loss: 0.10392378222557806
I0415 01:12:49.802888 18880 trainer.py:139] Epoch[1393/1500] loss: 0.10166437515328007
I0415 01:12:54.401501 18880 trainer.py:139] Epoch[1394/1500] loss: 0.10163121766621067
I0415 01:13:00.553919 18880 trainer.py:139] Epoch[1395/1500] loss: 0.10357159063700706
I0415 01:13:05.195391 18880 trainer.py:139] Epoch[1396/1500] loss: 0.10348113578173422
I0415 01:13:09.838860 18880 trainer.py:139] Epoch[1397/1500] loss: 0.102939379311377
I0415 01:13:14.272533 18880 trainer.py:139] Epoch[1398/1500] loss: 0.10162221111597554
I0415 01:13:18.967826 18880 trainer.py:139] Epoch[1399/1500] loss: 0.1023827759969619
I0415 01:13:19.166162 18880 trainer.py:145] Test: {'precision': 0.13801608579088478, 'recall': 0.3239533486366795, 'hit_ratio': 0.8943699731903485, 'ndcg': 0.3097427888325317}
I0415 01:13:23.843514 18880 trainer.py:139] Epoch[1400/1500] loss: 0.10049791345673223
I0415 01:13:30.003907 18880 trainer.py:139] Epoch[1401/1500] loss: 0.10252717858360659
I0415 01:13:34.722122 18880 trainer.py:139] Epoch[1402/1500] loss: 0.10215684290855162
I0415 01:13:39.287847 18880 trainer.py:139] Epoch[1403/1500] loss: 0.10339014160056267
I0415 01:13:43.958221 18880 trainer.py:139] Epoch[1404/1500] loss: 0.10287177610781885
I0415 01:13:48.617634 18880 trainer.py:139] Epoch[1405/1500] loss: 0.10272400393601387
I0415 01:13:54.092319 18880 trainer.py:139] Epoch[1406/1500] loss: 0.10187180484494855
I0415 01:13:59.464348 18880 trainer.py:139] Epoch[1407/1500] loss: 0.10291435641627159
I0415 01:14:04.184556 18880 trainer.py:139] Epoch[1408/1500] loss: 0.10313834562417
I0415 01:14:09.075197 18880 trainer.py:139] Epoch[1409/1500] loss: 0.10370925405333119
I0415 01:14:13.906033 18880 trainer.py:139] Epoch[1410/1500] loss: 0.10488185286521912
I0415 01:14:18.741857 18880 trainer.py:139] Epoch[1411/1500] loss: 0.1019753806533352
I0415 01:14:24.744774 18880 trainer.py:139] Epoch[1412/1500] loss: 0.1017893040853162
I0415 01:14:29.565646 18880 trainer.py:139] Epoch[1413/1500] loss: 0.10283016485552635
I0415 01:14:34.142335 18880 trainer.py:139] Epoch[1414/1500] loss: 0.10320643551888005
I0415 01:14:38.873507 18880 trainer.py:139] Epoch[1415/1500] loss: 0.10313050809406465
I0415 01:14:43.666473 18880 trainer.py:139] Epoch[1416/1500] loss: 0.1021398373188511
I0415 01:14:49.398267 18880 trainer.py:139] Epoch[1417/1500] loss: 0.10329616406271534
I0415 01:14:54.504184 18880 trainer.py:139] Epoch[1418/1500] loss: 0.10213877741367586
I0415 01:14:59.280206 18880 trainer.py:139] Epoch[1419/1500] loss: 0.1021532615826976
I0415 01:15:03.960549 18880 trainer.py:139] Epoch[1420/1500] loss: 0.10306235811402721
I0415 01:15:08.795373 18880 trainer.py:139] Epoch[1421/1500] loss: 0.10272124481777992
I0415 01:15:13.686013 18880 trainer.py:139] Epoch[1422/1500] loss: 0.10187683879367766
I0415 01:15:19.586274 18880 trainer.py:139] Epoch[1423/1500] loss: 0.10307328186688884
I0415 01:15:24.339373 18880 trainer.py:139] Epoch[1424/1500] loss: 0.10298775448914498
I0415 01:15:29.075527 18880 trainer.py:139] Epoch[1425/1500] loss: 0.10244245827198029
I0415 01:15:33.875471 18880 trainer.py:139] Epoch[1426/1500] loss: 0.10210740494151269
I0415 01:15:38.313623 18880 trainer.py:139] Epoch[1427/1500] loss: 0.10154180156607781
I0415 01:15:43.646781 18880 trainer.py:139] Epoch[1428/1500] loss: 0.10183853944463114
I0415 01:15:49.454352 18880 trainer.py:139] Epoch[1429/1500] loss: 0.10304163180051311
I0415 01:15:54.153633 18880 trainer.py:139] Epoch[1430/1500] loss: 0.10355509264815238
I0415 01:15:58.810494 18880 trainer.py:139] Epoch[1431/1500] loss: 0.1024108067635567
I0415 01:16:03.620403 18880 trainer.py:139] Epoch[1432/1500] loss: 0.10187276284540853
I0415 01:16:08.467189 18880 trainer.py:139] Epoch[1433/1500] loss: 0.101642603114728
I0415 01:16:14.817943 18880 trainer.py:139] Epoch[1434/1500] loss: 0.10260795032785784
I0415 01:16:19.336826 18880 trainer.py:139] Epoch[1435/1500] loss: 0.10400660960905013
I0415 01:16:24.149724 18880 trainer.py:139] Epoch[1436/1500] loss: 0.1030779252609899
I0415 01:16:28.901828 18880 trainer.py:139] Epoch[1437/1500] loss: 0.1023434886047917
I0415 01:16:33.465558 18880 trainer.py:139] Epoch[1438/1500] loss: 0.10356079570708736
I0415 01:16:38.722972 18880 trainer.py:139] Epoch[1439/1500] loss: 0.10225210723377043
I0415 01:16:44.250479 18880 trainer.py:139] Epoch[1440/1500] loss: 0.10260101768278307
I0415 01:16:49.029490 18880 trainer.py:139] Epoch[1441/1500] loss: 0.10127023799765494
I0415 01:16:53.583256 18880 trainer.py:139] Epoch[1442/1500] loss: 0.10213380042583711
I0415 01:16:58.254629 18880 trainer.py:139] Epoch[1443/1500] loss: 0.1022928167254694
I0415 01:17:03.492107 18880 trainer.py:139] Epoch[1444/1500] loss: 0.1032386107310172
I0415 01:17:09.068452 18880 trainer.py:139] Epoch[1445/1500] loss: 0.10312884877766332
I0415 01:17:13.921218 18880 trainer.py:139] Epoch[1446/1500] loss: 0.10216332996083845
I0415 01:17:18.490929 18880 trainer.py:139] Epoch[1447/1500] loss: 0.10346458491779142
I0415 01:17:23.038715 18880 trainer.py:139] Epoch[1448/1500] loss: 0.10213639034378913
I0415 01:17:27.726036 18880 trainer.py:139] Epoch[1449/1500] loss: 0.10255633775264986
I0415 01:17:28.074868 18880 trainer.py:145] Test: {'precision': 0.13833780160857917, 'recall': 0.32213715128026766, 'hit_ratio': 0.8911528150134048, 'ndcg': 0.30825203020644854}
I0415 01:17:34.090742 18880 trainer.py:139] Epoch[1450/1500] loss: 0.10316300127775438
I0415 01:17:38.702314 18880 trainer.py:139] Epoch[1451/1500] loss: 0.10258690099562368
I0415 01:17:43.271030 18880 trainer.py:139] Epoch[1452/1500] loss: 0.10131580142244216
I0415 01:17:47.852702 18880 trainer.py:139] Epoch[1453/1500] loss: 0.10236495589056323
I0415 01:17:52.423411 18880 trainer.py:139] Epoch[1454/1500] loss: 0.10158796512311505
I0415 01:17:57.341957 18880 trainer.py:139] Epoch[1455/1500] loss: 0.10239859093581477
I0415 01:18:03.566133 18880 trainer.py:139] Epoch[1456/1500] loss: 0.1025144743823236
I0415 01:18:08.239499 18880 trainer.py:139] Epoch[1457/1500] loss: 0.10272703512061027
I0415 01:18:12.920840 18880 trainer.py:139] Epoch[1458/1500] loss: 0.10311546417013291
I0415 01:18:17.584238 18880 trainer.py:139] Epoch[1459/1500] loss: 0.10276915926125742
I0415 01:18:22.848627 18880 trainer.py:139] Epoch[1460/1500] loss: 0.10369835529596574
I0415 01:18:28.422979 18880 trainer.py:139] Epoch[1461/1500] loss: 0.10250300168991089
I0415 01:18:33.100292 18880 trainer.py:139] Epoch[1462/1500] loss: 0.10238347947597504
I0415 01:18:37.739770 18880 trainer.py:139] Epoch[1463/1500] loss: 0.10529463738203049
I0415 01:18:42.220779 18880 trainer.py:139] Epoch[1464/1500] loss: 0.10316442530001363
I0415 01:18:47.040655 18880 trainer.py:139] Epoch[1465/1500] loss: 0.1027420413109564
I0415 01:18:53.150218 18880 trainer.py:139] Epoch[1466/1500] loss: 0.10316722912173118
I0415 01:18:57.972084 18880 trainer.py:139] Epoch[1467/1500] loss: 0.10233316762793448
I0415 01:19:02.672360 18880 trainer.py:139] Epoch[1468/1500] loss: 0.1007017750413187
I0415 01:19:07.362669 18880 trainer.py:139] Epoch[1469/1500] loss: 0.10266391908930193
I0415 01:19:12.108791 18880 trainer.py:139] Epoch[1470/1500] loss: 0.1020162163242217
I0415 01:19:16.477178 18880 trainer.py:139] Epoch[1471/1500] loss: 0.10101779454177426
I0415 01:19:22.679429 18880 trainer.py:139] Epoch[1472/1500] loss: 0.10197526601053053
I0415 01:19:27.396647 18880 trainer.py:139] Epoch[1473/1500] loss: 0.10248511933511303
I0415 01:19:32.145760 18880 trainer.py:139] Epoch[1474/1500] loss: 0.10262655971511718
I0415 01:19:36.687566 18880 trainer.py:139] Epoch[1475/1500] loss: 0.10317880395920045
I0415 01:19:41.261268 18880 trainer.py:139] Epoch[1476/1500] loss: 0.10175806932872342
I0415 01:19:47.014020 18880 trainer.py:139] Epoch[1477/1500] loss: 0.10189967963003344
I0415 01:19:51.115298 18880 trainer.py:139] Epoch[1478/1500] loss: 0.10451102521150343
I0415 01:19:55.474715 18880 trainer.py:139] Epoch[1479/1500] loss: 0.1016972898956268
I0415 01:19:59.680644 18880 trainer.py:139] Epoch[1480/1500] loss: 0.10242987279930423
I0415 01:20:03.878600 18880 trainer.py:139] Epoch[1481/1500] loss: 0.10213160827275246
I0415 01:20:08.161273 18880 trainer.py:139] Epoch[1482/1500] loss: 0.10154289944517997
I0415 01:20:12.438962 18880 trainer.py:139] Epoch[1483/1500] loss: 0.10309064244070361
I0415 01:20:16.818312 18880 trainer.py:139] Epoch[1484/1500] loss: 0.10247649396619489
I0415 01:20:20.741187 18880 trainer.py:139] Epoch[1485/1500] loss: 0.10299757459471302
I0415 01:20:25.654752 18880 trainer.py:139] Epoch[1486/1500] loss: 0.10352805425082484
I0415 01:20:30.884255 18880 trainer.py:139] Epoch[1487/1500] loss: 0.1023548680447763
I0415 01:20:34.961615 18880 trainer.py:139] Epoch[1488/1500] loss: 0.10234384166617547
I0415 01:20:39.104753 18880 trainer.py:139] Epoch[1489/1500] loss: 0.10196271562768568
I0415 01:20:43.196067 18880 trainer.py:139] Epoch[1490/1500] loss: 0.10301903154580824
I0415 01:20:47.366117 18880 trainer.py:139] Epoch[1491/1500] loss: 0.10253160230575069
I0415 01:20:51.477363 18880 trainer.py:139] Epoch[1492/1500] loss: 0.10243745124147784
I0415 01:20:55.753058 18880 trainer.py:139] Epoch[1493/1500] loss: 0.10177747352469352
I0415 01:20:59.858325 18880 trainer.py:139] Epoch[1494/1500] loss: 0.10114139294432055
I0415 01:21:04.937335 18880 trainer.py:139] Epoch[1495/1500] loss: 0.10310256553273048
I0415 01:21:09.610699 18880 trainer.py:139] Epoch[1496/1500] loss: 0.10209730652070814
I0415 01:21:13.934235 18880 trainer.py:139] Epoch[1497/1500] loss: 0.10251793770059463
I0415 01:21:18.192987 18880 trainer.py:139] Epoch[1498/1500] loss: 0.10199414145561957
I0415 01:21:22.291277 18880 trainer.py:139] Epoch[1499/1500] loss: 0.10266095592129615
I0415 01:21:22.555393 18880 trainer.py:145] Test: {'precision': 0.13882037533512073, 'recall': 0.32373254516252476, 'hit_ratio': 0.8943699731903485, 'ndcg': 0.31197184917206392}
