I0802 23:01:41.936291 14512 trainer.py:119] Test: [{'precision': 0.09414858096828055, 'recall': 0.09783424820462186, 'hit_ratio': 0.6235392320534223, 'ndcg': 0.12113414689146151}]
I0802 23:01:58.218018 14512 trainer.py:139] Epoch[0/1000] loss: 0.5757851600646973
I0802 23:02:14.364915 14512 trainer.py:139] Epoch[1/1000] loss: 0.5593909472227097
I0802 23:02:30.689454 14512 trainer.py:139] Epoch[2/1000] loss: 0.5412513315677643
I0802 23:02:47.237691 14512 trainer.py:139] Epoch[3/1000] loss: 0.531390905380249
I0802 23:03:03.773344 14512 trainer.py:139] Epoch[4/1000] loss: 0.5252964645624161
I0802 23:03:20.078598 14512 trainer.py:139] Epoch[5/1000] loss: 0.5129336565732956
I0802 23:03:36.501681 14512 trainer.py:139] Epoch[6/1000] loss: 0.50387242436409
I0802 23:03:52.962835 14512 trainer.py:139] Epoch[7/1000] loss: 0.5095677226781845
I0802 23:04:09.046549 14512 trainer.py:139] Epoch[8/1000] loss: 0.5017136558890343
I0802 23:04:24.675895 14512 trainer.py:139] Epoch[9/1000] loss: 0.5005642622709274
I0802 23:04:40.407066 14512 trainer.py:139] Epoch[10/1000] loss: 0.4981696456670761
I0802 23:04:56.284278 14512 trainer.py:139] Epoch[11/1000] loss: 0.49541984498500824
I0802 23:05:12.047911 14512 trainer.py:139] Epoch[12/1000] loss: 0.48926112055778503
I0802 23:05:27.532708 14512 trainer.py:139] Epoch[13/1000] loss: 0.4928322061896324
I0802 23:05:43.083130 14512 trainer.py:139] Epoch[14/1000] loss: 0.49105074256658554
I0802 23:05:58.974650 14512 trainer.py:139] Epoch[15/1000] loss: 0.4871121793985367
I0802 23:06:14.842425 14512 trainer.py:139] Epoch[16/1000] loss: 0.48735079169273376
I0802 23:06:30.714712 14512 trainer.py:139] Epoch[17/1000] loss: 0.479779452085495
I0802 23:06:46.309884 14512 trainer.py:139] Epoch[18/1000] loss: 0.47958336770534515
I0802 23:07:02.177766 14512 trainer.py:139] Epoch[19/1000] loss: 0.4740602895617485
I0802 23:07:17.861390 14512 trainer.py:139] Epoch[20/1000] loss: 0.47140344232320786
I0802 23:07:33.501276 14512 trainer.py:139] Epoch[21/1000] loss: 0.4677024781703949
I0802 23:07:49.291160 14512 trainer.py:139] Epoch[22/1000] loss: 0.4649496302008629
I0802 23:08:05.097197 14512 trainer.py:139] Epoch[23/1000] loss: 0.461743101477623
I0802 23:08:20.893086 14512 trainer.py:139] Epoch[24/1000] loss: 0.45986785739660263
I0802 23:08:36.717727 14512 trainer.py:139] Epoch[25/1000] loss: 0.4554717391729355
I0802 23:08:52.590422 14512 trainer.py:139] Epoch[26/1000] loss: 0.45165688544511795
I0802 23:09:08.317997 14512 trainer.py:139] Epoch[27/1000] loss: 0.449691466987133
I0802 23:09:24.228992 14512 trainer.py:139] Epoch[28/1000] loss: 0.44476519525051117
I0802 23:09:39.963780 14512 trainer.py:139] Epoch[29/1000] loss: 0.4458440914750099
I0802 23:09:55.817346 14512 trainer.py:139] Epoch[30/1000] loss: 0.43983108550310135
I0802 23:10:11.633186 14512 trainer.py:139] Epoch[31/1000] loss: 0.4338938072323799
I0802 23:10:27.163307 14512 trainer.py:139] Epoch[32/1000] loss: 0.43492137640714645
I0802 23:10:42.983465 14512 trainer.py:139] Epoch[33/1000] loss: 0.4266868457198143
I0802 23:10:58.660593 14512 trainer.py:139] Epoch[34/1000] loss: 0.4288647621870041
I0802 23:11:14.077386 14512 trainer.py:139] Epoch[35/1000] loss: 0.4261561408638954
I0802 23:11:29.766463 14512 trainer.py:139] Epoch[36/1000] loss: 0.42328929156064987
I0802 23:11:45.405606 14512 trainer.py:139] Epoch[37/1000] loss: 0.4230371117591858
I0802 23:12:01.279478 14512 trainer.py:139] Epoch[38/1000] loss: 0.419433057308197
I0802 23:12:16.837708 14512 trainer.py:139] Epoch[39/1000] loss: 0.4160649850964546
I0802 23:12:32.594176 14512 trainer.py:139] Epoch[40/1000] loss: 0.4148051589727402
I0802 23:12:48.608098 14512 trainer.py:139] Epoch[41/1000] loss: 0.41674714535474777
I0802 23:13:04.361145 14512 trainer.py:139] Epoch[42/1000] loss: 0.41317153722047806
I0802 23:13:19.958965 14512 trainer.py:139] Epoch[43/1000] loss: 0.4118371605873108
I0802 23:13:35.591689 14512 trainer.py:139] Epoch[44/1000] loss: 0.41376180946826935
I0802 23:13:51.249490 14512 trainer.py:139] Epoch[45/1000] loss: 0.4110315591096878
I0802 23:14:07.393078 14512 trainer.py:139] Epoch[46/1000] loss: 0.40784505009651184
I0802 23:14:22.964758 14512 trainer.py:139] Epoch[47/1000] loss: 0.40740498900413513
I0802 23:14:38.809988 14512 trainer.py:139] Epoch[48/1000] loss: 0.4102443903684616
I0802 23:14:54.618511 14512 trainer.py:139] Epoch[49/1000] loss: 0.40524886548519135
I0802 23:14:55.172141 14512 trainer.py:145] Test: [{'precision': 0.14866444073455765, 'recall': 0.18960670689239925, 'hit_ratio': 0.8138564273789649, 'ndcg': 0.22302949670577313}]
I0802 23:15:10.879594 14512 trainer.py:139] Epoch[50/1000] loss: 0.4055173322558403
I0802 23:15:26.694706 14512 trainer.py:139] Epoch[51/1000] loss: 0.4094550535082817
I0802 23:15:42.454544 14512 trainer.py:139] Epoch[52/1000] loss: 0.4028780162334442
I0802 23:15:58.494649 14512 trainer.py:139] Epoch[53/1000] loss: 0.4025453180074692
I0802 23:16:14.282619 14512 trainer.py:139] Epoch[54/1000] loss: 0.40487154573202133
I0802 23:16:29.978353 14512 trainer.py:139] Epoch[55/1000] loss: 0.4034477025270462
I0802 23:16:45.898335 14512 trainer.py:139] Epoch[56/1000] loss: 0.4004311040043831
I0802 23:17:01.685071 14512 trainer.py:139] Epoch[57/1000] loss: 0.40191107988357544
I0802 23:17:17.209543 14512 trainer.py:139] Epoch[58/1000] loss: 0.4083433225750923
I0802 23:17:32.778406 14512 trainer.py:139] Epoch[59/1000] loss: 0.40210144966840744
I0802 23:17:48.432824 14512 trainer.py:139] Epoch[60/1000] loss: 0.402674600481987
I0802 23:18:04.076781 14512 trainer.py:139] Epoch[61/1000] loss: 0.3999384343624115
I0802 23:18:19.806275 14512 trainer.py:139] Epoch[62/1000] loss: 0.4033341407775879
I0802 23:18:35.441163 14512 trainer.py:139] Epoch[63/1000] loss: 0.4006303921341896
I0802 23:18:51.118952 14512 trainer.py:139] Epoch[64/1000] loss: 0.40160829573869705
I0802 23:19:06.757274 14512 trainer.py:139] Epoch[65/1000] loss: 0.39863528311252594
I0802 23:19:22.479866 14512 trainer.py:139] Epoch[66/1000] loss: 0.3991159647703171
I0802 23:19:38.168691 14512 trainer.py:139] Epoch[67/1000] loss: 0.3988829180598259
I0802 23:19:54.097538 14512 trainer.py:139] Epoch[68/1000] loss: 0.40071582049131393
I0802 23:20:09.899724 14512 trainer.py:139] Epoch[69/1000] loss: 0.39642979949712753
I0802 23:20:25.554853 14512 trainer.py:139] Epoch[70/1000] loss: 0.3989905044436455
I0802 23:20:41.752734 14512 trainer.py:139] Epoch[71/1000] loss: 0.39861781895160675
I0802 23:20:57.506102 14512 trainer.py:139] Epoch[72/1000] loss: 0.3981582745909691
I0802 23:21:13.360286 14512 trainer.py:139] Epoch[73/1000] loss: 0.39598075300455093
I0802 23:21:29.156123 14512 trainer.py:139] Epoch[74/1000] loss: 0.3967406079173088
I0802 23:21:44.909144 14512 trainer.py:139] Epoch[75/1000] loss: 0.39511100947856903
I0802 23:22:00.842735 14512 trainer.py:139] Epoch[76/1000] loss: 0.3968767523765564
I0802 23:22:16.511356 14512 trainer.py:139] Epoch[77/1000] loss: 0.39370977133512497
I0802 23:22:32.366745 14512 trainer.py:139] Epoch[78/1000] loss: 0.39539680629968643
I0802 23:22:47.987087 14512 trainer.py:139] Epoch[79/1000] loss: 0.39615748077630997
I0802 23:23:03.674807 14512 trainer.py:139] Epoch[80/1000] loss: 0.3932974711060524
I0802 23:23:20.215889 14512 trainer.py:139] Epoch[81/1000] loss: 0.39515188336372375
I0802 23:23:36.762979 14512 trainer.py:139] Epoch[82/1000] loss: 0.3926885053515434
I0802 23:23:53.033957 14512 trainer.py:139] Epoch[83/1000] loss: 0.3887312710285187
I0802 23:24:09.275398 14512 trainer.py:139] Epoch[84/1000] loss: 0.39179007709026337
I0802 23:24:25.837400 14512 trainer.py:139] Epoch[85/1000] loss: 0.39150813966989517
I0802 23:24:42.172409 14512 trainer.py:139] Epoch[86/1000] loss: 0.38898753374814987
I0802 23:24:58.343033 14512 trainer.py:139] Epoch[87/1000] loss: 0.3891773372888565
I0802 23:25:14.585994 14512 trainer.py:139] Epoch[88/1000] loss: 0.39272768050432205
I0802 23:25:30.714718 14512 trainer.py:139] Epoch[89/1000] loss: 0.39105091243982315
I0802 23:25:46.782853 14512 trainer.py:139] Epoch[90/1000] loss: 0.39129340648651123
I0802 23:26:02.723123 14512 trainer.py:139] Epoch[91/1000] loss: 0.39166081696748734
I0802 23:26:18.595702 14512 trainer.py:139] Epoch[92/1000] loss: 0.3875097781419754
I0802 23:26:34.860175 14512 trainer.py:139] Epoch[93/1000] loss: 0.38842329382896423
I0802 23:26:50.826562 14512 trainer.py:139] Epoch[94/1000] loss: 0.38792457431554794
I0802 23:27:06.739274 14512 trainer.py:139] Epoch[95/1000] loss: 0.3870750442147255
I0802 23:27:22.983607 14512 trainer.py:139] Epoch[96/1000] loss: 0.3868394047021866
I0802 23:27:39.453125 14512 trainer.py:139] Epoch[97/1000] loss: 0.3865669295191765
I0802 23:27:55.563390 14512 trainer.py:139] Epoch[98/1000] loss: 0.3898271545767784
I0802 23:28:11.734701 14512 trainer.py:139] Epoch[99/1000] loss: 0.38806307315826416
I0802 23:28:12.314305 14512 trainer.py:145] Test: [{'precision': 0.14951585976627715, 'recall': 0.19077182984710103, 'hit_ratio': 0.8178631051752921, 'ndcg': 0.2242667870744563}]
I0802 23:28:28.287869 14512 trainer.py:139] Epoch[100/1000] loss: 0.3866584151983261
I0802 23:28:44.359158 14512 trainer.py:139] Epoch[101/1000] loss: 0.3858604282140732
I0802 23:29:00.407582 14512 trainer.py:139] Epoch[102/1000] loss: 0.38563135266304016
I0802 23:29:16.473027 14512 trainer.py:139] Epoch[103/1000] loss: 0.38769012689590454
I0802 23:29:32.555709 14512 trainer.py:139] Epoch[104/1000] loss: 0.38482489436864853
I0802 23:29:48.689537 14512 trainer.py:139] Epoch[105/1000] loss: 0.38015060126781464
I0802 23:30:04.775791 14512 trainer.py:139] Epoch[106/1000] loss: 0.3819001689553261
I0802 23:30:20.972730 14512 trainer.py:139] Epoch[107/1000] loss: 0.3829185292124748
I0802 23:30:37.240093 14512 trainer.py:139] Epoch[108/1000] loss: 0.3847518041729927
I0802 23:30:53.495600 14512 trainer.py:139] Epoch[109/1000] loss: 0.38061946630477905
I0802 23:31:09.637367 14512 trainer.py:139] Epoch[110/1000] loss: 0.3773076608777046
I0802 23:31:25.661246 14512 trainer.py:139] Epoch[111/1000] loss: 0.38042082637548447
I0802 23:31:41.756162 14512 trainer.py:139] Epoch[112/1000] loss: 0.37897152453660965
I0802 23:31:57.816310 14512 trainer.py:139] Epoch[113/1000] loss: 0.37714584171772003
I0802 23:32:13.783519 14512 trainer.py:139] Epoch[114/1000] loss: 0.3783416077494621
I0802 23:32:30.138800 14512 trainer.py:139] Epoch[115/1000] loss: 0.37599843740463257
I0802 23:32:46.344509 14512 trainer.py:139] Epoch[116/1000] loss: 0.3765721097588539
I0802 23:33:02.504680 14512 trainer.py:139] Epoch[117/1000] loss: 0.3775806725025177
I0802 23:33:18.789767 14512 trainer.py:139] Epoch[118/1000] loss: 0.374480739235878
I0802 23:33:35.108661 14512 trainer.py:139] Epoch[119/1000] loss: 0.3767395690083504
I0802 23:33:51.420300 14512 trainer.py:139] Epoch[120/1000] loss: 0.3783615753054619
I0802 23:34:07.580529 14512 trainer.py:139] Epoch[121/1000] loss: 0.37604380398988724
I0802 23:34:23.479456 14512 trainer.py:139] Epoch[122/1000] loss: 0.3759857937693596
I0802 23:34:39.517050 14512 trainer.py:139] Epoch[123/1000] loss: 0.37550200521945953
I0802 23:34:55.465368 14512 trainer.py:139] Epoch[124/1000] loss: 0.3699296712875366
I0802 23:35:11.387928 14512 trainer.py:139] Epoch[125/1000] loss: 0.372853584587574
I0802 23:35:27.575078 14512 trainer.py:139] Epoch[126/1000] loss: 0.3686338886618614
I0802 23:35:43.801833 14512 trainer.py:139] Epoch[127/1000] loss: 0.37295205891132355
I0802 23:35:59.654720 14512 trainer.py:139] Epoch[128/1000] loss: 0.3727685958147049
I0802 23:36:15.692862 14512 trainer.py:139] Epoch[129/1000] loss: 0.37050577253103256
I0802 23:36:32.166320 14512 trainer.py:139] Epoch[130/1000] loss: 0.3722638413310051
I0802 23:36:48.400938 14512 trainer.py:139] Epoch[131/1000] loss: 0.3701291009783745
I0802 23:37:04.376515 14512 trainer.py:139] Epoch[132/1000] loss: 0.36996497213840485
I0802 23:37:20.575195 14512 trainer.py:139] Epoch[133/1000] loss: 0.36815983802080154
I0802 23:37:36.738560 14512 trainer.py:139] Epoch[134/1000] loss: 0.36756494641304016
I0802 23:37:52.672835 14512 trainer.py:139] Epoch[135/1000] loss: 0.3681357800960541
I0802 23:38:08.489653 14512 trainer.py:139] Epoch[136/1000] loss: 0.3664366528391838
I0802 23:38:24.423291 14512 trainer.py:139] Epoch[137/1000] loss: 0.36491356790065765
I0802 23:38:40.541208 14512 trainer.py:139] Epoch[138/1000] loss: 0.3649047464132309
I0802 23:38:56.700065 14512 trainer.py:139] Epoch[139/1000] loss: 0.36292025446891785
I0802 23:39:12.810184 14512 trainer.py:139] Epoch[140/1000] loss: 0.363079771399498
I0802 23:39:29.135954 14512 trainer.py:139] Epoch[141/1000] loss: 0.3630734607577324
I0802 23:39:45.728225 14512 trainer.py:139] Epoch[142/1000] loss: 0.36251816153526306
I0802 23:40:01.936626 14512 trainer.py:139] Epoch[143/1000] loss: 0.3603450059890747
I0802 23:40:17.756413 14512 trainer.py:139] Epoch[144/1000] loss: 0.3618220090866089
I0802 23:40:33.811633 14512 trainer.py:139] Epoch[145/1000] loss: 0.3617028221487999
I0802 23:40:49.864012 14512 trainer.py:139] Epoch[146/1000] loss: 0.36193470656871796
I0802 23:41:05.690239 14512 trainer.py:139] Epoch[147/1000] loss: 0.3612244054675102
I0802 23:41:21.670557 14512 trainer.py:139] Epoch[148/1000] loss: 0.35997290909290314
I0802 23:41:37.469677 14512 trainer.py:139] Epoch[149/1000] loss: 0.3615301698446274
I0802 23:41:38.021378 14512 trainer.py:145] Test: [{'precision': 0.15256260434056768, 'recall': 0.19699729769759233, 'hit_ratio': 0.8282136894824708, 'ndcg': 0.22962090221567721}]
I0802 23:41:53.919939 14512 trainer.py:139] Epoch[150/1000] loss: 0.3592153862118721
I0802 23:42:10.078712 14512 trainer.py:139] Epoch[151/1000] loss: 0.35594767332077026
I0802 23:42:26.278168 14512 trainer.py:139] Epoch[152/1000] loss: 0.3562108352780342
I0802 23:42:42.556130 14512 trainer.py:139] Epoch[153/1000] loss: 0.3553578108549118
I0802 23:42:58.744194 14512 trainer.py:139] Epoch[154/1000] loss: 0.35220566391944885
I0802 23:43:14.714542 14512 trainer.py:139] Epoch[155/1000] loss: 0.3527809679508209
I0802 23:43:30.886486 14512 trainer.py:139] Epoch[156/1000] loss: 0.35448019206523895
I0802 23:43:47.064928 14512 trainer.py:139] Epoch[157/1000] loss: 0.3551926985383034
I0802 23:44:03.191462 14512 trainer.py:139] Epoch[158/1000] loss: 0.3511325642466545
I0802 23:44:19.215121 14512 trainer.py:139] Epoch[159/1000] loss: 0.35109200328588486
I0802 23:44:35.275163 14512 trainer.py:139] Epoch[160/1000] loss: 0.3527301326394081
I0802 23:44:51.206817 14512 trainer.py:139] Epoch[161/1000] loss: 0.3484461084008217
I0802 23:45:07.323139 14512 trainer.py:139] Epoch[162/1000] loss: 0.34997453540563583
I0802 23:45:23.578826 14512 trainer.py:139] Epoch[163/1000] loss: 0.34867997467517853
I0802 23:45:39.977978 14512 trainer.py:139] Epoch[164/1000] loss: 0.3505605012178421
I0802 23:45:56.116458 14512 trainer.py:139] Epoch[165/1000] loss: 0.3495256155729294
I0802 23:46:12.356155 14512 trainer.py:139] Epoch[166/1000] loss: 0.3487621247768402
I0802 23:46:28.425237 14512 trainer.py:139] Epoch[167/1000] loss: 0.3463699743151665
I0802 23:46:44.290503 14512 trainer.py:139] Epoch[168/1000] loss: 0.34388160705566406
I0802 23:47:00.364216 14512 trainer.py:139] Epoch[169/1000] loss: 0.34662801027297974
I0802 23:47:16.127577 14512 trainer.py:139] Epoch[170/1000] loss: 0.3467639833688736
I0802 23:47:32.130130 14512 trainer.py:139] Epoch[171/1000] loss: 0.34612078964710236
I0802 23:47:48.340068 14512 trainer.py:139] Epoch[172/1000] loss: 0.3449301943182945
I0802 23:48:04.467089 14512 trainer.py:139] Epoch[173/1000] loss: 0.3451719135046005
I0802 23:48:20.459697 14512 trainer.py:139] Epoch[174/1000] loss: 0.341517336666584
I0802 23:48:36.478667 14512 trainer.py:139] Epoch[175/1000] loss: 0.34186672419309616
I0802 23:48:52.836891 14512 trainer.py:139] Epoch[176/1000] loss: 0.3441634327173233
I0802 23:49:08.940103 14512 trainer.py:139] Epoch[177/1000] loss: 0.34068217873573303
I0802 23:49:25.096565 14512 trainer.py:139] Epoch[178/1000] loss: 0.34325362741947174
I0802 23:49:41.107099 14512 trainer.py:139] Epoch[179/1000] loss: 0.3422970101237297
I0802 23:49:57.050904 14512 trainer.py:139] Epoch[180/1000] loss: 0.34084396809339523
I0802 23:50:12.879547 14512 trainer.py:139] Epoch[181/1000] loss: 0.34137095510959625
I0802 23:50:28.685573 14512 trainer.py:139] Epoch[182/1000] loss: 0.33839040249586105
I0802 23:50:44.876636 14512 trainer.py:139] Epoch[183/1000] loss: 0.340516060590744
I0802 23:51:00.963747 14512 trainer.py:139] Epoch[184/1000] loss: 0.335501953959465
I0802 23:51:16.958203 14512 trainer.py:139] Epoch[185/1000] loss: 0.33782657980918884
I0802 23:51:33.272337 14512 trainer.py:139] Epoch[186/1000] loss: 0.33786967396736145
I0802 23:51:49.523625 14512 trainer.py:139] Epoch[187/1000] loss: 0.3350636288523674
I0802 23:52:05.611896 14512 trainer.py:139] Epoch[188/1000] loss: 0.33469895273447037
I0802 23:52:21.423929 14512 trainer.py:139] Epoch[189/1000] loss: 0.33542434871196747
I0802 23:52:37.434448 14512 trainer.py:139] Epoch[190/1000] loss: 0.3321392387151718
I0802 23:52:53.417432 14512 trainer.py:139] Epoch[191/1000] loss: 0.3336375579237938
I0802 23:53:09.395969 14512 trainer.py:139] Epoch[192/1000] loss: 0.3332233428955078
I0802 23:53:25.915723 14512 trainer.py:139] Epoch[193/1000] loss: 0.33102940022945404
I0802 23:53:42.152861 14512 trainer.py:139] Epoch[194/1000] loss: 0.33028995990753174
I0802 23:53:58.630947 14512 trainer.py:139] Epoch[195/1000] loss: 0.3283678814768791
I0802 23:54:14.914232 14512 trainer.py:139] Epoch[196/1000] loss: 0.3307143822312355
I0802 23:54:30.908500 14512 trainer.py:139] Epoch[197/1000] loss: 0.32896340638399124
I0802 23:54:46.514514 14512 trainer.py:139] Epoch[198/1000] loss: 0.3315300792455673
I0802 23:55:02.243469 14512 trainer.py:139] Epoch[199/1000] loss: 0.32963865250349045
I0802 23:55:02.798658 14512 trainer.py:145] Test: [{'precision': 0.1572621035058431, 'recall': 0.20702253541963878, 'hit_ratio': 0.8414023372287145, 'ndcg': 0.2380051168170021}]
I0802 23:55:18.429834 14512 trainer.py:139] Epoch[200/1000] loss: 0.3293677419424057
I0802 23:55:34.111416 14512 trainer.py:139] Epoch[201/1000] loss: 0.3278742730617523
I0802 23:55:50.107645 14512 trainer.py:139] Epoch[202/1000] loss: 0.3248443529009819
I0802 23:56:06.090667 14512 trainer.py:139] Epoch[203/1000] loss: 0.3263355642557144
I0802 23:56:21.909726 14512 trainer.py:139] Epoch[204/1000] loss: 0.32768215984106064
I0802 23:56:37.683175 14512 trainer.py:139] Epoch[205/1000] loss: 0.32690369337797165
I0802 23:56:53.386257 14512 trainer.py:139] Epoch[206/1000] loss: 0.3252720236778259
I0802 23:57:09.076780 14512 trainer.py:139] Epoch[207/1000] loss: 0.32545311748981476
I0802 23:57:24.831001 14512 trainer.py:139] Epoch[208/1000] loss: 0.3242757245898247
I0802 23:57:40.548407 14512 trainer.py:139] Epoch[209/1000] loss: 0.32378047704696655
I0802 23:57:56.363470 14512 trainer.py:139] Epoch[210/1000] loss: 0.3221961036324501
I0802 23:58:12.065425 14512 trainer.py:139] Epoch[211/1000] loss: 0.32415589690208435
I0802 23:58:27.613896 14512 trainer.py:139] Epoch[212/1000] loss: 0.32376042753458023
I0802 23:58:43.335110 14512 trainer.py:139] Epoch[213/1000] loss: 0.3214852064847946
I0802 23:58:59.084671 14512 trainer.py:139] Epoch[214/1000] loss: 0.32177168130874634
I0802 23:59:14.697045 14512 trainer.py:139] Epoch[215/1000] loss: 0.32000281661748886
I0802 23:59:30.490093 14512 trainer.py:139] Epoch[216/1000] loss: 0.31907106935977936
I0802 23:59:46.100984 14512 trainer.py:139] Epoch[217/1000] loss: 0.3210609704256058
I0803 00:00:01.902173 14512 trainer.py:139] Epoch[218/1000] loss: 0.31896206736564636
I0803 00:00:17.221505 14512 trainer.py:139] Epoch[219/1000] loss: 0.32054007053375244
I0803 00:00:32.783091 14512 trainer.py:139] Epoch[220/1000] loss: 0.3180030882358551
I0803 00:00:48.634779 14512 trainer.py:139] Epoch[221/1000] loss: 0.3186759278178215
I0803 00:01:04.398952 14512 trainer.py:139] Epoch[222/1000] loss: 0.31753817945718765
I0803 00:01:20.116543 14512 trainer.py:139] Epoch[223/1000] loss: 0.3172127604484558
I0803 00:01:35.732123 14512 trainer.py:139] Epoch[224/1000] loss: 0.31378273665905
I0803 00:01:51.663460 14512 trainer.py:139] Epoch[225/1000] loss: 0.31487587839365005
I0803 00:02:07.459205 14512 trainer.py:139] Epoch[226/1000] loss: 0.31599118560552597
I0803 00:02:23.192603 14512 trainer.py:139] Epoch[227/1000] loss: 0.3152891770005226
I0803 00:02:39.087691 14512 trainer.py:139] Epoch[228/1000] loss: 0.31331299990415573
I0803 00:02:54.827260 14512 trainer.py:139] Epoch[229/1000] loss: 0.3123859316110611
I0803 00:03:10.574727 14512 trainer.py:139] Epoch[230/1000] loss: 0.31127670407295227
I0803 00:03:26.323858 14512 trainer.py:139] Epoch[231/1000] loss: 0.3125300481915474
I0803 00:03:42.018622 14512 trainer.py:139] Epoch[232/1000] loss: 0.31298720836639404
I0803 00:03:57.698324 14512 trainer.py:139] Epoch[233/1000] loss: 0.3128955215215683
I0803 00:04:13.543100 14512 trainer.py:139] Epoch[234/1000] loss: 0.3110186383128166
I0803 00:04:29.195851 14512 trainer.py:139] Epoch[235/1000] loss: 0.31375645846128464
I0803 00:04:44.955916 14512 trainer.py:139] Epoch[236/1000] loss: 0.3102327957749367
I0803 00:05:00.771548 14512 trainer.py:139] Epoch[237/1000] loss: 0.3110785484313965
I0803 00:05:16.425966 14512 trainer.py:139] Epoch[238/1000] loss: 0.31049033999443054
I0803 00:05:31.939980 14512 trainer.py:139] Epoch[239/1000] loss: 0.3110186532139778
I0803 00:05:47.693989 14512 trainer.py:139] Epoch[240/1000] loss: 0.3090454339981079
I0803 00:06:03.639848 14512 trainer.py:139] Epoch[241/1000] loss: 0.3100668489933014
I0803 00:06:19.158443 14512 trainer.py:139] Epoch[242/1000] loss: 0.30818991363048553
I0803 00:06:34.803311 14512 trainer.py:139] Epoch[243/1000] loss: 0.30865170806646347
I0803 00:06:50.600667 14512 trainer.py:139] Epoch[244/1000] loss: 0.306995190680027
I0803 00:07:06.380913 14512 trainer.py:139] Epoch[245/1000] loss: 0.30650904029607773
I0803 00:07:22.070972 14512 trainer.py:139] Epoch[246/1000] loss: 0.307637982070446
I0803 00:07:37.801355 14512 trainer.py:139] Epoch[247/1000] loss: 0.3066956177353859
I0803 00:07:53.710393 14512 trainer.py:139] Epoch[248/1000] loss: 0.306342676281929
I0803 00:08:09.438049 14512 trainer.py:139] Epoch[249/1000] loss: 0.3044966086745262
I0803 00:08:10.036664 14512 trainer.py:145] Test: [{'precision': 0.16258764607679468, 'recall': 0.21801191756245222, 'hit_ratio': 0.8559265442404007, 'ndcg': 0.247981151264035}]
I0803 00:08:26.093783 14512 trainer.py:139] Epoch[250/1000] loss: 0.30581291764974594
I0803 00:08:42.172816 14512 trainer.py:139] Epoch[251/1000] loss: 0.30560702085494995
I0803 00:08:57.882831 14512 trainer.py:139] Epoch[252/1000] loss: 0.30495547503232956
I0803 00:09:14.006963 14512 trainer.py:139] Epoch[253/1000] loss: 0.304053857922554
I0803 00:09:29.794591 14512 trainer.py:139] Epoch[254/1000] loss: 0.3031099662184715
I0803 00:09:45.439460 14512 trainer.py:139] Epoch[255/1000] loss: 0.3035668432712555
I0803 00:10:01.063310 14512 trainer.py:139] Epoch[256/1000] loss: 0.3049771189689636
I0803 00:10:16.896311 14512 trainer.py:139] Epoch[257/1000] loss: 0.3012680187821388
I0803 00:10:32.716321 14512 trainer.py:139] Epoch[258/1000] loss: 0.30367204546928406
I0803 00:10:48.498260 14512 trainer.py:139] Epoch[259/1000] loss: 0.30098801106214523
I0803 00:11:04.111138 14512 trainer.py:139] Epoch[260/1000] loss: 0.30199985951185226
I0803 00:11:19.805748 14512 trainer.py:139] Epoch[261/1000] loss: 0.30023108422756195
I0803 00:11:35.413743 14512 trainer.py:139] Epoch[262/1000] loss: 0.3011006936430931
I0803 00:11:50.950101 14512 trainer.py:139] Epoch[263/1000] loss: 0.2986888885498047
I0803 00:12:06.443135 14512 trainer.py:139] Epoch[264/1000] loss: 0.2996321991086006
I0803 00:12:22.182961 14512 trainer.py:139] Epoch[265/1000] loss: 0.2996414974331856
I0803 00:12:37.899068 14512 trainer.py:139] Epoch[266/1000] loss: 0.29851023107767105
I0803 00:12:53.500697 14512 trainer.py:139] Epoch[267/1000] loss: 0.2973790615797043
I0803 00:13:09.330869 14512 trainer.py:139] Epoch[268/1000] loss: 0.29703524708747864
I0803 00:13:24.998698 14512 trainer.py:139] Epoch[269/1000] loss: 0.2981176972389221
I0803 00:13:40.702800 14512 trainer.py:139] Epoch[270/1000] loss: 0.2979573532938957
I0803 00:13:56.523155 14512 trainer.py:139] Epoch[271/1000] loss: 0.2970031797885895
I0803 00:14:12.393630 14512 trainer.py:139] Epoch[272/1000] loss: 0.2969565689563751
I0803 00:14:28.366980 14512 trainer.py:139] Epoch[273/1000] loss: 0.2957511469721794
I0803 00:14:43.987292 14512 trainer.py:139] Epoch[274/1000] loss: 0.2956538125872612
I0803 00:14:59.666248 14512 trainer.py:139] Epoch[275/1000] loss: 0.2954001873731613
I0803 00:15:15.502300 14512 trainer.py:139] Epoch[276/1000] loss: 0.29507237672805786
I0803 00:15:31.415246 14512 trainer.py:139] Epoch[277/1000] loss: 0.2937968745827675
I0803 00:15:47.342682 14512 trainer.py:139] Epoch[278/1000] loss: 0.2946564704179764
I0803 00:16:03.068042 14512 trainer.py:139] Epoch[279/1000] loss: 0.2951936051249504
I0803 00:16:18.933007 14512 trainer.py:139] Epoch[280/1000] loss: 0.29383584856987
I0803 00:16:34.723260 14512 trainer.py:139] Epoch[281/1000] loss: 0.2949155867099762
I0803 00:16:50.559652 14512 trainer.py:139] Epoch[282/1000] loss: 0.2939330115914345
I0803 00:17:06.079540 14512 trainer.py:139] Epoch[283/1000] loss: 0.29208722710609436
I0803 00:17:21.522538 14512 trainer.py:139] Epoch[284/1000] loss: 0.2922729104757309
I0803 00:17:37.200772 14512 trainer.py:139] Epoch[285/1000] loss: 0.2930201441049576
I0803 00:17:52.684771 14512 trainer.py:139] Epoch[286/1000] loss: 0.2904580682516098
I0803 00:18:08.175852 14512 trainer.py:139] Epoch[287/1000] loss: 0.2919795587658882
I0803 00:18:23.789391 14512 trainer.py:139] Epoch[288/1000] loss: 0.2909366562962532
I0803 00:18:39.406112 14512 trainer.py:139] Epoch[289/1000] loss: 0.2902911305427551
I0803 00:18:55.041656 14512 trainer.py:139] Epoch[290/1000] loss: 0.28993333131074905
I0803 00:19:10.892068 14512 trainer.py:139] Epoch[291/1000] loss: 0.2891778200864792
I0803 00:19:26.642082 14512 trainer.py:139] Epoch[292/1000] loss: 0.28897834569215775
I0803 00:19:42.483508 14512 trainer.py:139] Epoch[293/1000] loss: 0.2884065732359886
I0803 00:19:58.287901 14512 trainer.py:139] Epoch[294/1000] loss: 0.2879432290792465
I0803 00:20:14.132454 14512 trainer.py:139] Epoch[295/1000] loss: 0.2889881432056427
I0803 00:20:30.353352 14512 trainer.py:139] Epoch[296/1000] loss: 0.2869216129183769
I0803 00:20:46.141814 14512 trainer.py:139] Epoch[297/1000] loss: 0.2908558025956154
I0803 00:21:01.977957 14512 trainer.py:139] Epoch[298/1000] loss: 0.2876121625304222
I0803 00:21:17.601651 14512 trainer.py:139] Epoch[299/1000] loss: 0.28741859644651413
I0803 00:21:18.259018 14512 trainer.py:145] Test: [{'precision': 0.1669866444073456, 'recall': 0.22785423234514993, 'hit_ratio': 0.8667779632721202, 'ndcg': 0.25642277385512685}]
I0803 00:21:33.929912 14512 trainer.py:139] Epoch[300/1000] loss: 0.28679124265909195
I0803 00:21:49.836589 14512 trainer.py:139] Epoch[301/1000] loss: 0.28646858036518097
I0803 00:22:05.625727 14512 trainer.py:139] Epoch[302/1000] loss: 0.2855985686182976
I0803 00:22:21.240290 14512 trainer.py:139] Epoch[303/1000] loss: 0.2867032364010811
I0803 00:22:37.275842 14512 trainer.py:139] Epoch[304/1000] loss: 0.28581585735082626
I0803 00:22:52.870822 14512 trainer.py:139] Epoch[305/1000] loss: 0.2851094454526901
I0803 00:23:08.593591 14512 trainer.py:139] Epoch[306/1000] loss: 0.28531935065984726
I0803 00:23:24.322438 14512 trainer.py:139] Epoch[307/1000] loss: 0.28398261219263077
I0803 00:23:40.001274 14512 trainer.py:139] Epoch[308/1000] loss: 0.28302379697561264
I0803 00:23:55.664374 14512 trainer.py:139] Epoch[309/1000] loss: 0.28529199957847595
I0803 00:24:11.318976 14512 trainer.py:139] Epoch[310/1000] loss: 0.28361207991838455
I0803 00:24:27.056156 14512 trainer.py:139] Epoch[311/1000] loss: 0.28493545949459076
I0803 00:24:42.601982 14512 trainer.py:139] Epoch[312/1000] loss: 0.2839386388659477
I0803 00:24:58.354991 14512 trainer.py:139] Epoch[313/1000] loss: 0.283591628074646
I0803 00:25:14.279835 14512 trainer.py:139] Epoch[314/1000] loss: 0.2837317883968353
I0803 00:25:29.820205 14512 trainer.py:139] Epoch[315/1000] loss: 0.2817334532737732
I0803 00:25:45.405405 14512 trainer.py:139] Epoch[316/1000] loss: 0.28220707178115845
I0803 00:26:01.341759 14512 trainer.py:139] Epoch[317/1000] loss: 0.28155113011598587
I0803 00:26:16.954267 14512 trainer.py:139] Epoch[318/1000] loss: 0.28057145327329636
I0803 00:26:32.775048 14512 trainer.py:139] Epoch[319/1000] loss: 0.2807679548859596
I0803 00:26:48.587226 14512 trainer.py:139] Epoch[320/1000] loss: 0.28054021298885345
I0803 00:27:04.648336 14512 trainer.py:139] Epoch[321/1000] loss: 0.28102004528045654
I0803 00:27:20.637157 14512 trainer.py:139] Epoch[322/1000] loss: 0.2801108732819557
I0803 00:27:36.375542 14512 trainer.py:139] Epoch[323/1000] loss: 0.28046074509620667
I0803 00:27:52.050660 14512 trainer.py:139] Epoch[324/1000] loss: 0.2791641056537628
I0803 00:28:07.887778 14512 trainer.py:139] Epoch[325/1000] loss: 0.2787383571267128
I0803 00:28:23.695580 14512 trainer.py:139] Epoch[326/1000] loss: 0.2779483497142792
I0803 00:28:39.341130 14512 trainer.py:139] Epoch[327/1000] loss: 0.27924395352602005
I0803 00:28:54.877089 14512 trainer.py:139] Epoch[328/1000] loss: 0.2779349982738495
I0803 00:29:10.450997 14512 trainer.py:139] Epoch[329/1000] loss: 0.27907848358154297
I0803 00:29:26.054449 14512 trainer.py:139] Epoch[330/1000] loss: 0.2771812379360199
I0803 00:29:41.762937 14512 trainer.py:139] Epoch[331/1000] loss: 0.27701912075281143
I0803 00:29:57.513578 14512 trainer.py:139] Epoch[332/1000] loss: 0.27605414390563965
I0803 00:30:13.171556 14512 trainer.py:139] Epoch[333/1000] loss: 0.27703696489334106
I0803 00:30:28.830204 14512 trainer.py:139] Epoch[334/1000] loss: 0.2756596803665161
I0803 00:30:44.509070 14512 trainer.py:139] Epoch[335/1000] loss: 0.2769149914383888
I0803 00:31:00.549358 14512 trainer.py:139] Epoch[336/1000] loss: 0.2750399634242058
I0803 00:31:16.350053 14512 trainer.py:139] Epoch[337/1000] loss: 0.2758592739701271
I0803 00:31:32.061667 14512 trainer.py:139] Epoch[338/1000] loss: 0.27503475546836853
I0803 00:31:47.735036 14512 trainer.py:139] Epoch[339/1000] loss: 0.2752293720841408
I0803 00:32:03.759293 14512 trainer.py:139] Epoch[340/1000] loss: 0.27569837868213654
I0803 00:32:19.441610 14512 trainer.py:139] Epoch[341/1000] loss: 0.27434447407722473
I0803 00:32:35.214983 14512 trainer.py:139] Epoch[342/1000] loss: 0.2746092528104782
I0803 00:32:50.917837 14512 trainer.py:139] Epoch[343/1000] loss: 0.2738014683127403
I0803 00:33:06.682625 14512 trainer.py:139] Epoch[344/1000] loss: 0.27318019419908524
I0803 00:33:22.392697 14512 trainer.py:139] Epoch[345/1000] loss: 0.27293604612350464
I0803 00:33:38.285995 14512 trainer.py:139] Epoch[346/1000] loss: 0.2745200842618942
I0803 00:33:53.978940 14512 trainer.py:139] Epoch[347/1000] loss: 0.27256637811660767
I0803 00:34:09.761596 14512 trainer.py:139] Epoch[348/1000] loss: 0.2730541229248047
I0803 00:34:25.282161 14512 trainer.py:139] Epoch[349/1000] loss: 0.27106526494026184
I0803 00:34:25.843284 14512 trainer.py:145] Test: [{'precision': 0.17215358931552585, 'recall': 0.23482815404628068, 'hit_ratio': 0.8724540901502504, 'ndcg': 0.2646252069115336}]
I0803 00:34:41.310461 14512 trainer.py:139] Epoch[350/1000] loss: 0.2728841081261635
I0803 00:34:56.988224 14512 trainer.py:139] Epoch[351/1000] loss: 0.2728562578558922
I0803 00:35:12.931093 14512 trainer.py:139] Epoch[352/1000] loss: 0.27229736745357513
I0803 00:35:28.571718 14512 trainer.py:139] Epoch[353/1000] loss: 0.27226053923368454
I0803 00:35:44.267867 14512 trainer.py:139] Epoch[354/1000] loss: 0.27189669758081436
I0803 00:36:00.026611 14512 trainer.py:139] Epoch[355/1000] loss: 0.27152269333601
I0803 00:36:15.984116 14512 trainer.py:139] Epoch[356/1000] loss: 0.2693820670247078
I0803 00:36:31.716334 14512 trainer.py:139] Epoch[357/1000] loss: 0.2702382802963257
I0803 00:36:47.269157 14512 trainer.py:139] Epoch[358/1000] loss: 0.2696145102381706
I0803 00:37:02.981173 14512 trainer.py:139] Epoch[359/1000] loss: 0.2693001702427864
I0803 00:37:18.827086 14512 trainer.py:139] Epoch[360/1000] loss: 0.2718195170164108
I0803 00:37:34.362729 14512 trainer.py:139] Epoch[361/1000] loss: 0.2690490111708641
I0803 00:37:50.198709 14512 trainer.py:139] Epoch[362/1000] loss: 0.26841971278190613
I0803 00:38:05.979019 14512 trainer.py:139] Epoch[363/1000] loss: 0.2700297012925148
I0803 00:38:21.695743 14512 trainer.py:139] Epoch[364/1000] loss: 0.26796403527259827
I0803 00:38:37.403436 14512 trainer.py:139] Epoch[365/1000] loss: 0.2688693255186081
I0803 00:38:53.113066 14512 trainer.py:139] Epoch[366/1000] loss: 0.26803337037563324
I0803 00:39:09.071167 14512 trainer.py:139] Epoch[367/1000] loss: 0.2677839994430542
I0803 00:39:24.915624 14512 trainer.py:139] Epoch[368/1000] loss: 0.2668656185269356
I0803 00:39:40.768199 14512 trainer.py:139] Epoch[369/1000] loss: 0.2678338512778282
I0803 00:39:56.357774 14512 trainer.py:139] Epoch[370/1000] loss: 0.26752083003520966
I0803 00:40:12.451868 14512 trainer.py:139] Epoch[371/1000] loss: 0.2661471962928772
I0803 00:40:28.252406 14512 trainer.py:139] Epoch[372/1000] loss: 0.266108438372612
I0803 00:40:44.053499 14512 trainer.py:139] Epoch[373/1000] loss: 0.26679061353206635
I0803 00:40:59.738088 14512 trainer.py:139] Epoch[374/1000] loss: 0.26591644436120987
I0803 00:41:15.407757 14512 trainer.py:139] Epoch[375/1000] loss: 0.2650776356458664
I0803 00:41:30.977094 14512 trainer.py:139] Epoch[376/1000] loss: 0.26548102498054504
I0803 00:41:46.600575 14512 trainer.py:139] Epoch[377/1000] loss: 0.26448874920606613
I0803 00:42:02.572601 14512 trainer.py:139] Epoch[378/1000] loss: 0.2647025063633919
I0803 00:42:18.202175 14512 trainer.py:139] Epoch[379/1000] loss: 0.2653943747282028
I0803 00:42:33.833297 14512 trainer.py:139] Epoch[380/1000] loss: 0.26460419595241547
I0803 00:42:49.537317 14512 trainer.py:139] Epoch[381/1000] loss: 0.2651607170701027
I0803 00:43:05.329106 14512 trainer.py:139] Epoch[382/1000] loss: 0.264736644923687
I0803 00:43:20.961596 14512 trainer.py:139] Epoch[383/1000] loss: 0.26295820623636246
I0803 00:43:36.629439 14512 trainer.py:139] Epoch[384/1000] loss: 0.2637595757842064
I0803 00:43:52.392255 14512 trainer.py:139] Epoch[385/1000] loss: 0.26367654651403427
I0803 00:44:08.240958 14512 trainer.py:139] Epoch[386/1000] loss: 0.2632657140493393
I0803 00:44:24.009135 14512 trainer.py:139] Epoch[387/1000] loss: 0.2627365291118622
I0803 00:44:39.751586 14512 trainer.py:139] Epoch[388/1000] loss: 0.26172399520874023
I0803 00:44:55.326997 14512 trainer.py:139] Epoch[389/1000] loss: 0.26197075098752975
I0803 00:45:11.378232 14512 trainer.py:139] Epoch[390/1000] loss: 0.26203703135252
I0803 00:45:27.270560 14512 trainer.py:139] Epoch[391/1000] loss: 0.26175013929605484
I0803 00:45:43.001562 14512 trainer.py:139] Epoch[392/1000] loss: 0.2616366520524025
I0803 00:45:58.807892 14512 trainer.py:139] Epoch[393/1000] loss: 0.2614746317267418
I0803 00:46:14.790992 14512 trainer.py:139] Epoch[394/1000] loss: 0.2618909031152725
I0803 00:46:30.303063 14512 trainer.py:139] Epoch[395/1000] loss: 0.2613772228360176
I0803 00:46:45.915908 14512 trainer.py:139] Epoch[396/1000] loss: 0.2612239718437195
I0803 00:47:01.606622 14512 trainer.py:139] Epoch[397/1000] loss: 0.2600949555635452
I0803 00:47:17.323991 14512 trainer.py:139] Epoch[398/1000] loss: 0.2589721158146858
I0803 00:47:32.954011 14512 trainer.py:139] Epoch[399/1000] loss: 0.26011206209659576
I0803 00:47:33.532660 14512 trainer.py:145] Test: [{'precision': 0.17660267111853087, 'recall': 0.2429760337562566, 'hit_ratio': 0.8781302170283807, 'ndcg': 0.27250621673065656}]
I0803 00:47:49.113661 14512 trainer.py:139] Epoch[400/1000] loss: 0.2599427402019501
I0803 00:48:04.744399 14512 trainer.py:139] Epoch[401/1000] loss: 0.2604577764868736
I0803 00:48:20.545131 14512 trainer.py:139] Epoch[402/1000] loss: 0.25815457850694656
I0803 00:48:36.495580 14512 trainer.py:139] Epoch[403/1000] loss: 0.25978079438209534
I0803 00:48:52.139125 14512 trainer.py:139] Epoch[404/1000] loss: 0.2592134103178978
I0803 00:49:07.869238 14512 trainer.py:139] Epoch[405/1000] loss: 0.2597874104976654
I0803 00:49:23.494793 14512 trainer.py:139] Epoch[406/1000] loss: 0.258795402944088
I0803 00:49:39.301004 14512 trainer.py:139] Epoch[407/1000] loss: 0.25832120329141617
I0803 00:49:55.079541 14512 trainer.py:139] Epoch[408/1000] loss: 0.2586919218301773
I0803 00:50:11.013896 14512 trainer.py:139] Epoch[409/1000] loss: 0.25797028839588165
I0803 00:50:26.668521 14512 trainer.py:139] Epoch[410/1000] loss: 0.2578471601009369
I0803 00:50:42.302767 14512 trainer.py:139] Epoch[411/1000] loss: 0.25733397901058197
I0803 00:50:58.037641 14512 trainer.py:139] Epoch[412/1000] loss: 0.25711654871702194
I0803 00:51:13.738166 14512 trainer.py:139] Epoch[413/1000] loss: 0.25717297941446304
I0803 00:51:29.482664 14512 trainer.py:139] Epoch[414/1000] loss: 0.25740840286016464
I0803 00:51:45.281452 14512 trainer.py:139] Epoch[415/1000] loss: 0.2565990760922432
I0803 00:52:00.951269 14512 trainer.py:139] Epoch[416/1000] loss: 0.25602923333644867
I0803 00:52:16.907713 14512 trainer.py:139] Epoch[417/1000] loss: 0.25571631640195847
I0803 00:52:32.723412 14512 trainer.py:139] Epoch[418/1000] loss: 0.25658417493104935
I0803 00:52:48.298457 14512 trainer.py:139] Epoch[419/1000] loss: 0.2562919482588768
I0803 00:53:03.909330 14512 trainer.py:139] Epoch[420/1000] loss: 0.2553760036826134
I0803 00:53:19.627079 14512 trainer.py:139] Epoch[421/1000] loss: 0.25556527078151703
I0803 00:53:35.104519 14512 trainer.py:139] Epoch[422/1000] loss: 0.25483260303735733
I0803 00:53:50.533269 14512 trainer.py:139] Epoch[423/1000] loss: 0.25471560657024384
I0803 00:54:06.106406 14512 trainer.py:139] Epoch[424/1000] loss: 0.2549206018447876
I0803 00:54:21.588931 14512 trainer.py:139] Epoch[425/1000] loss: 0.25497695058584213
I0803 00:54:37.270994 14512 trainer.py:139] Epoch[426/1000] loss: 0.2550978660583496
I0803 00:54:52.959073 14512 trainer.py:139] Epoch[427/1000] loss: 0.2545645236968994
I0803 00:55:08.631529 14512 trainer.py:139] Epoch[428/1000] loss: 0.25500451773405075
I0803 00:55:24.246877 14512 trainer.py:139] Epoch[429/1000] loss: 0.2535765618085861
I0803 00:55:39.872127 14512 trainer.py:139] Epoch[430/1000] loss: 0.25410448759794235
I0803 00:55:55.820726 14512 trainer.py:139] Epoch[431/1000] loss: 0.25283246487379074
I0803 00:56:11.666405 14512 trainer.py:139] Epoch[432/1000] loss: 0.25361379235982895
I0803 00:56:27.632098 14512 trainer.py:139] Epoch[433/1000] loss: 0.25400541722774506
I0803 00:56:43.194957 14512 trainer.py:139] Epoch[434/1000] loss: 0.25258178263902664
I0803 00:56:58.920298 14512 trainer.py:139] Epoch[435/1000] loss: 0.2518804520368576
I0803 00:57:14.744204 14512 trainer.py:139] Epoch[436/1000] loss: 0.2516491711139679
I0803 00:57:30.589227 14512 trainer.py:139] Epoch[437/1000] loss: 0.2528768479824066
I0803 00:57:46.238295 14512 trainer.py:139] Epoch[438/1000] loss: 0.2517082318663597
I0803 00:58:02.081789 14512 trainer.py:139] Epoch[439/1000] loss: 0.25144750624895096
I0803 00:58:17.787463 14512 trainer.py:139] Epoch[440/1000] loss: 0.25165505707263947
I0803 00:58:33.547434 14512 trainer.py:139] Epoch[441/1000] loss: 0.25198984518647194
I0803 00:58:49.496209 14512 trainer.py:139] Epoch[442/1000] loss: 0.2517153210937977
I0803 00:59:05.097861 14512 trainer.py:139] Epoch[443/1000] loss: 0.2527882754802704
I0803 00:59:20.695315 14512 trainer.py:139] Epoch[444/1000] loss: 0.2511400431394577
I0803 00:59:36.538495 14512 trainer.py:139] Epoch[445/1000] loss: 0.25077493861317635
I0803 00:59:52.198361 14512 trainer.py:139] Epoch[446/1000] loss: 0.25142325460910797
I0803 01:00:07.801395 14512 trainer.py:139] Epoch[447/1000] loss: 0.2500920630991459
I0803 01:00:23.283889 14512 trainer.py:139] Epoch[448/1000] loss: 0.2507922649383545
I0803 01:00:39.043538 14512 trainer.py:139] Epoch[449/1000] loss: 0.2500704824924469
I0803 01:00:39.777083 14512 trainer.py:145] Test: [{'precision': 0.18149415692821366, 'recall': 0.24933955051212478, 'hit_ratio': 0.8853088480801335, 'ndcg': 0.28064399732254475}]
I0803 01:00:55.741601 14512 trainer.py:139] Epoch[450/1000] loss: 0.249396201223135
I0803 01:01:11.437581 14512 trainer.py:139] Epoch[451/1000] loss: 0.2505786456167698
I0803 01:01:27.052635 14512 trainer.py:139] Epoch[452/1000] loss: 0.24918614327907562
I0803 01:01:42.817214 14512 trainer.py:139] Epoch[453/1000] loss: 0.24905342608690262
I0803 01:01:58.990304 14512 trainer.py:139] Epoch[454/1000] loss: 0.2507867366075516
I0803 01:02:14.555915 14512 trainer.py:139] Epoch[455/1000] loss: 0.2492840513586998
I0803 01:02:30.235407 14512 trainer.py:139] Epoch[456/1000] loss: 0.2501401752233505
I0803 01:02:45.895260 14512 trainer.py:139] Epoch[457/1000] loss: 0.24934428185224533
I0803 01:03:01.606256 14512 trainer.py:139] Epoch[458/1000] loss: 0.2496715597808361
I0803 01:03:17.397321 14512 trainer.py:139] Epoch[459/1000] loss: 0.2484258934855461
I0803 01:03:33.441679 14512 trainer.py:139] Epoch[460/1000] loss: 0.24864870682358742
I0803 01:03:49.221647 14512 trainer.py:139] Epoch[461/1000] loss: 0.2490875981748104
I0803 01:04:04.974452 14512 trainer.py:139] Epoch[462/1000] loss: 0.24851007759571075
I0803 01:04:20.765566 14512 trainer.py:139] Epoch[463/1000] loss: 0.2476973794400692
I0803 01:04:36.318309 14512 trainer.py:139] Epoch[464/1000] loss: 0.24790750816464424
I0803 01:04:52.060642 14512 trainer.py:139] Epoch[465/1000] loss: 0.2476734183728695
I0803 01:05:07.622272 14512 trainer.py:139] Epoch[466/1000] loss: 0.2485114149749279
I0803 01:05:23.178644 14512 trainer.py:139] Epoch[467/1000] loss: 0.24853989109396935
I0803 01:05:38.834580 14512 trainer.py:139] Epoch[468/1000] loss: 0.24590196460485458
I0803 01:05:54.556374 14512 trainer.py:139] Epoch[469/1000] loss: 0.2458767481148243
I0803 01:06:10.114066 14512 trainer.py:139] Epoch[470/1000] loss: 0.2469305656850338
I0803 01:06:25.721334 14512 trainer.py:139] Epoch[471/1000] loss: 0.24655285477638245
I0803 01:06:41.295847 14512 trainer.py:139] Epoch[472/1000] loss: 0.24688266962766647
I0803 01:06:56.995548 14512 trainer.py:139] Epoch[473/1000] loss: 0.24616852775216103
I0803 01:07:12.603157 14512 trainer.py:139] Epoch[474/1000] loss: 0.24586955830454826
I0803 01:07:28.316313 14512 trainer.py:139] Epoch[475/1000] loss: 0.2461097128689289
I0803 01:07:43.893149 14512 trainer.py:139] Epoch[476/1000] loss: 0.24532606452703476
I0803 01:07:59.651102 14512 trainer.py:139] Epoch[477/1000] loss: 0.24511563777923584
I0803 01:08:15.319625 14512 trainer.py:139] Epoch[478/1000] loss: 0.24596024304628372
I0803 01:08:30.861644 14512 trainer.py:139] Epoch[479/1000] loss: 0.24526147916913033
I0803 01:08:46.790091 14512 trainer.py:139] Epoch[480/1000] loss: 0.24491702392697334
I0803 01:09:02.686594 14512 trainer.py:139] Epoch[481/1000] loss: 0.24571706727147102
I0803 01:09:18.222868 14512 trainer.py:139] Epoch[482/1000] loss: 0.24505019932985306
I0803 01:09:34.043608 14512 trainer.py:139] Epoch[483/1000] loss: 0.24353059381246567
I0803 01:09:49.815076 14512 trainer.py:139] Epoch[484/1000] loss: 0.24516266211867332
I0803 01:10:05.516450 14512 trainer.py:139] Epoch[485/1000] loss: 0.24638795480132103
I0803 01:10:21.391801 14512 trainer.py:139] Epoch[486/1000] loss: 0.24418222159147263
I0803 01:10:37.058723 14512 trainer.py:139] Epoch[487/1000] loss: 0.2444084994494915
I0803 01:10:53.138084 14512 trainer.py:139] Epoch[488/1000] loss: 0.24375533312559128
I0803 01:11:08.905944 14512 trainer.py:139] Epoch[489/1000] loss: 0.24290132150053978
I0803 01:11:24.545433 14512 trainer.py:139] Epoch[490/1000] loss: 0.2451377846300602
I0803 01:11:40.185922 14512 trainer.py:139] Epoch[491/1000] loss: 0.2442575953900814
I0803 01:11:55.851090 14512 trainer.py:139] Epoch[492/1000] loss: 0.24265605583786964
I0803 01:12:11.444920 14512 trainer.py:139] Epoch[493/1000] loss: 0.24307436496019363
I0803 01:12:27.170227 14512 trainer.py:139] Epoch[494/1000] loss: 0.2432926781475544
I0803 01:12:42.915241 14512 trainer.py:139] Epoch[495/1000] loss: 0.24279706180095673
I0803 01:12:58.897445 14512 trainer.py:139] Epoch[496/1000] loss: 0.2440958432853222
I0803 01:13:14.563658 14512 trainer.py:139] Epoch[497/1000] loss: 0.24475353211164474
I0803 01:13:30.175183 14512 trainer.py:139] Epoch[498/1000] loss: 0.2432761713862419
I0803 01:13:45.657346 14512 trainer.py:139] Epoch[499/1000] loss: 0.24342158064246178
I0803 01:13:46.271858 14512 trainer.py:145] Test: [{'precision': 0.18389816360601005, 'recall': 0.25426856132075415, 'hit_ratio': 0.8903171953255425, 'ndcg': 0.28517134118161686}]
I0803 01:14:02.199436 14512 trainer.py:139] Epoch[500/1000] loss: 0.24334309995174408
I0803 01:14:18.071104 14512 trainer.py:139] Epoch[501/1000] loss: 0.24263515323400497
I0803 01:14:33.850813 14512 trainer.py:139] Epoch[502/1000] loss: 0.2412838414311409
I0803 01:14:49.693778 14512 trainer.py:139] Epoch[503/1000] loss: 0.242593165487051
I0803 01:15:05.285305 14512 trainer.py:139] Epoch[504/1000] loss: 0.24457988515496254
I0803 01:15:21.068449 14512 trainer.py:139] Epoch[505/1000] loss: 0.2425875924527645
I0803 01:15:36.819905 14512 trainer.py:139] Epoch[506/1000] loss: 0.24150091782212257
I0803 01:15:52.529009 14512 trainer.py:139] Epoch[507/1000] loss: 0.24170583114027977
I0803 01:16:08.533146 14512 trainer.py:139] Epoch[508/1000] loss: 0.24143773689866066
I0803 01:16:24.302840 14512 trainer.py:139] Epoch[509/1000] loss: 0.2430475391447544
I0803 01:16:39.958495 14512 trainer.py:139] Epoch[510/1000] loss: 0.2410118393599987
I0803 01:16:55.765118 14512 trainer.py:139] Epoch[511/1000] loss: 0.24128435924649239
I0803 01:17:11.347088 14512 trainer.py:139] Epoch[512/1000] loss: 0.24194477871060371
I0803 01:17:26.987630 14512 trainer.py:139] Epoch[513/1000] loss: 0.24166222661733627
I0803 01:17:42.542910 14512 trainer.py:139] Epoch[514/1000] loss: 0.24101663380861282
I0803 01:17:58.075801 14512 trainer.py:139] Epoch[515/1000] loss: 0.24103722721338272
I0803 01:18:14.064429 14512 trainer.py:139] Epoch[516/1000] loss: 0.24010761082172394
I0803 01:18:29.693114 14512 trainer.py:139] Epoch[517/1000] loss: 0.24154997989535332
I0803 01:18:45.287594 14512 trainer.py:139] Epoch[518/1000] loss: 0.23969122767448425
I0803 01:19:01.127552 14512 trainer.py:139] Epoch[519/1000] loss: 0.23959901183843613
I0803 01:19:16.787065 14512 trainer.py:139] Epoch[520/1000] loss: 0.24113226309418678
I0803 01:19:32.625730 14512 trainer.py:139] Epoch[521/1000] loss: 0.23928216099739075
I0803 01:19:48.351427 14512 trainer.py:139] Epoch[522/1000] loss: 0.24059850350022316
I0803 01:20:04.211831 14512 trainer.py:139] Epoch[523/1000] loss: 0.2402530051767826
I0803 01:20:19.981825 14512 trainer.py:139] Epoch[524/1000] loss: 0.24046561866998672
I0803 01:20:35.858557 14512 trainer.py:139] Epoch[525/1000] loss: 0.24125102534890175
I0803 01:20:51.637109 14512 trainer.py:139] Epoch[526/1000] loss: 0.23962080851197243
I0803 01:21:07.394308 14512 trainer.py:139] Epoch[527/1000] loss: 0.23988180607557297
I0803 01:21:23.085787 14512 trainer.py:139] Epoch[528/1000] loss: 0.2400933988392353
I0803 01:21:38.947058 14512 trainer.py:139] Epoch[529/1000] loss: 0.23819443210959435
I0803 01:21:54.714375 14512 trainer.py:139] Epoch[530/1000] loss: 0.2394743114709854
I0803 01:22:10.525595 14512 trainer.py:139] Epoch[531/1000] loss: 0.23932313546538353
I0803 01:22:26.282101 14512 trainer.py:139] Epoch[532/1000] loss: 0.23909522593021393
I0803 01:22:42.041275 14512 trainer.py:139] Epoch[533/1000] loss: 0.24027379974722862
I0803 01:22:57.706320 14512 trainer.py:139] Epoch[534/1000] loss: 0.2393781840801239
I0803 01:23:13.560009 14512 trainer.py:139] Epoch[535/1000] loss: 0.23701148852705956
I0803 01:23:29.056630 14512 trainer.py:139] Epoch[536/1000] loss: 0.23866168782114983
I0803 01:23:44.645289 14512 trainer.py:139] Epoch[537/1000] loss: 0.23908977955579758
I0803 01:24:00.466649 14512 trainer.py:139] Epoch[538/1000] loss: 0.23857219517230988
I0803 01:24:15.886018 14512 trainer.py:139] Epoch[539/1000] loss: 0.2377324290573597
I0803 01:24:31.374213 14512 trainer.py:139] Epoch[540/1000] loss: 0.23788263276219368
I0803 01:24:47.088240 14512 trainer.py:139] Epoch[541/1000] loss: 0.2390327975153923
I0803 01:25:02.743876 14512 trainer.py:139] Epoch[542/1000] loss: 0.23912166059017181
I0803 01:25:18.509249 14512 trainer.py:139] Epoch[543/1000] loss: 0.23658885061740875
I0803 01:25:34.214612 14512 trainer.py:139] Epoch[544/1000] loss: 0.23781199380755424
I0803 01:25:49.902460 14512 trainer.py:139] Epoch[545/1000] loss: 0.2375783696770668
I0803 01:26:05.728121 14512 trainer.py:139] Epoch[546/1000] loss: 0.237029530107975
I0803 01:26:21.396996 14512 trainer.py:139] Epoch[547/1000] loss: 0.2381085604429245
I0803 01:26:37.341151 14512 trainer.py:139] Epoch[548/1000] loss: 0.23743898048996925
I0803 01:26:53.191253 14512 trainer.py:139] Epoch[549/1000] loss: 0.23667237907648087
I0803 01:26:53.896035 14512 trainer.py:145] Test: [{'precision': 0.18637729549248747, 'recall': 0.25804166849569266, 'hit_ratio': 0.8941569282136895, 'ndcg': 0.28917757396296806}]
I0803 01:27:09.821602 14512 trainer.py:139] Epoch[550/1000] loss: 0.23741120472550392
I0803 01:27:25.564965 14512 trainer.py:139] Epoch[551/1000] loss: 0.23726488649845123
I0803 01:27:41.160590 14512 trainer.py:139] Epoch[552/1000] loss: 0.23724843189120293
I0803 01:27:56.795169 14512 trainer.py:139] Epoch[553/1000] loss: 0.23668809235095978
I0803 01:28:12.400160 14512 trainer.py:139] Epoch[554/1000] loss: 0.23801058158278465
I0803 01:28:28.163580 14512 trainer.py:139] Epoch[555/1000] loss: 0.23766247555613518
I0803 01:28:44.067815 14512 trainer.py:139] Epoch[556/1000] loss: 0.23607968166470528
I0803 01:28:59.785260 14512 trainer.py:139] Epoch[557/1000] loss: 0.23623521998524666
I0803 01:29:15.309497 14512 trainer.py:139] Epoch[558/1000] loss: 0.23689286783337593
I0803 01:29:30.835023 14512 trainer.py:139] Epoch[559/1000] loss: 0.23667661100625992
I0803 01:29:46.635026 14512 trainer.py:139] Epoch[560/1000] loss: 0.23600711300969124
I0803 01:30:02.255588 14512 trainer.py:139] Epoch[561/1000] loss: 0.2359057441353798
I0803 01:30:17.995258 14512 trainer.py:139] Epoch[562/1000] loss: 0.237070020288229
I0803 01:30:33.702966 14512 trainer.py:139] Epoch[563/1000] loss: 0.23679465800523758
I0803 01:30:49.445402 14512 trainer.py:139] Epoch[564/1000] loss: 0.23702717944979668
I0803 01:31:05.083633 14512 trainer.py:139] Epoch[565/1000] loss: 0.2357099987566471
I0803 01:31:21.001380 14512 trainer.py:139] Epoch[566/1000] loss: 0.23612823709845543
I0803 01:31:36.694602 14512 trainer.py:139] Epoch[567/1000] loss: 0.2346879430115223
I0803 01:31:52.520593 14512 trainer.py:139] Epoch[568/1000] loss: 0.23440278694033623
I0803 01:32:08.288186 14512 trainer.py:139] Epoch[569/1000] loss: 0.23587464168667793
I0803 01:32:24.068018 14512 trainer.py:139] Epoch[570/1000] loss: 0.23539160564541817
I0803 01:32:39.955038 14512 trainer.py:139] Epoch[571/1000] loss: 0.23532655462622643
I0803 01:32:55.576103 14512 trainer.py:139] Epoch[572/1000] loss: 0.2358265295624733
I0803 01:33:11.304271 14512 trainer.py:139] Epoch[573/1000] loss: 0.234316136687994
I0803 01:33:26.980728 14512 trainer.py:139] Epoch[574/1000] loss: 0.23519990220665932
I0803 01:33:42.796768 14512 trainer.py:139] Epoch[575/1000] loss: 0.23476408049464226
I0803 01:33:58.599244 14512 trainer.py:139] Epoch[576/1000] loss: 0.23559020832180977
I0803 01:34:14.233942 14512 trainer.py:139] Epoch[577/1000] loss: 0.23364122584462166
I0803 01:34:30.054490 14512 trainer.py:139] Epoch[578/1000] loss: 0.23412737250328064
I0803 01:34:45.938158 14512 trainer.py:139] Epoch[579/1000] loss: 0.23410295322537422
I0803 01:35:01.602870 14512 trainer.py:139] Epoch[580/1000] loss: 0.23500240221619606
I0803 01:35:17.149396 14512 trainer.py:139] Epoch[581/1000] loss: 0.23461581021547318
I0803 01:35:32.810094 14512 trainer.py:139] Epoch[582/1000] loss: 0.23381558060646057
I0803 01:35:48.490806 14512 trainer.py:139] Epoch[583/1000] loss: 0.23382804542779922
I0803 01:36:04.020295 14512 trainer.py:139] Epoch[584/1000] loss: 0.2343713864684105
I0803 01:36:19.627648 14512 trainer.py:139] Epoch[585/1000] loss: 0.23332373797893524
I0803 01:36:35.384844 14512 trainer.py:139] Epoch[586/1000] loss: 0.23366045579314232
I0803 01:36:51.024458 14512 trainer.py:139] Epoch[587/1000] loss: 0.23440079391002655
I0803 01:37:06.717019 14512 trainer.py:139] Epoch[588/1000] loss: 0.23300353437662125
I0803 01:37:22.512092 14512 trainer.py:139] Epoch[589/1000] loss: 0.23380329459905624
I0803 01:37:38.373415 14512 trainer.py:139] Epoch[590/1000] loss: 0.23418134450912476
I0803 01:37:54.018302 14512 trainer.py:139] Epoch[591/1000] loss: 0.23371722921729088
I0803 01:38:09.813058 14512 trainer.py:139] Epoch[592/1000] loss: 0.2340850904583931
I0803 01:38:25.613101 14512 trainer.py:139] Epoch[593/1000] loss: 0.23423926904797554
I0803 01:38:41.428783 14512 trainer.py:139] Epoch[594/1000] loss: 0.23293587937951088
I0803 01:38:57.258112 14512 trainer.py:139] Epoch[595/1000] loss: 0.23404605314135551
I0803 01:39:13.116146 14512 trainer.py:139] Epoch[596/1000] loss: 0.23362478241324425
I0803 01:39:29.061387 14512 trainer.py:139] Epoch[597/1000] loss: 0.23359738662838936
I0803 01:39:44.906766 14512 trainer.py:139] Epoch[598/1000] loss: 0.233773123472929
I0803 01:40:00.394909 14512 trainer.py:139] Epoch[599/1000] loss: 0.23358473926782608
I0803 01:40:00.947061 14512 trainer.py:145] Test: [{'precision': 0.18788814691151925, 'recall': 0.261495985945519, 'hit_ratio': 0.896661101836394, 'ndcg': 0.2929921379633639}]
I0803 01:40:16.543854 14512 trainer.py:139] Epoch[600/1000] loss: 0.23384245485067368
I0803 01:40:32.252952 14512 trainer.py:139] Epoch[601/1000] loss: 0.23287684470415115
I0803 01:40:47.873522 14512 trainer.py:139] Epoch[602/1000] loss: 0.23165465891361237
I0803 01:41:03.742614 14512 trainer.py:139] Epoch[603/1000] loss: 0.23238936066627502
I0803 01:41:19.482350 14512 trainer.py:139] Epoch[604/1000] loss: 0.2337016873061657
I0803 01:41:35.163120 14512 trainer.py:139] Epoch[605/1000] loss: 0.23238519951701164
I0803 01:41:50.972923 14512 trainer.py:139] Epoch[606/1000] loss: 0.23296191170811653
I0803 01:42:06.468210 14512 trainer.py:139] Epoch[607/1000] loss: 0.23203711956739426
I0803 01:42:22.174252 14512 trainer.py:139] Epoch[608/1000] loss: 0.2329886145889759
I0803 01:42:37.842431 14512 trainer.py:139] Epoch[609/1000] loss: 0.232888575643301
I0803 01:42:53.774787 14512 trainer.py:139] Epoch[610/1000] loss: 0.23224152252078056
I0803 01:43:09.625287 14512 trainer.py:139] Epoch[611/1000] loss: 0.23318526521325111
I0803 01:43:25.126059 14512 trainer.py:139] Epoch[612/1000] loss: 0.23233572766184807
I0803 01:43:40.935107 14512 trainer.py:139] Epoch[613/1000] loss: 0.23078348487615585
I0803 01:43:56.731366 14512 trainer.py:139] Epoch[614/1000] loss: 0.2311306707561016
I0803 01:44:12.779387 14512 trainer.py:139] Epoch[615/1000] loss: 0.23290346190333366
I0803 01:44:28.723608 14512 trainer.py:139] Epoch[616/1000] loss: 0.2316586598753929
I0803 01:44:44.431852 14512 trainer.py:139] Epoch[617/1000] loss: 0.23187145218253136
I0803 01:45:00.203828 14512 trainer.py:139] Epoch[618/1000] loss: 0.23199844360351562
I0803 01:45:16.070667 14512 trainer.py:139] Epoch[619/1000] loss: 0.2327023260295391
I0803 01:45:31.796891 14512 trainer.py:139] Epoch[620/1000] loss: 0.23164502158761024
I0803 01:45:47.783247 14512 trainer.py:139] Epoch[621/1000] loss: 0.23181071877479553
I0803 01:46:03.451374 14512 trainer.py:139] Epoch[622/1000] loss: 0.2310006394982338
I0803 01:46:19.247092 14512 trainer.py:139] Epoch[623/1000] loss: 0.23197108879685402
I0803 01:46:34.955998 14512 trainer.py:139] Epoch[624/1000] loss: 0.231437548995018
I0803 01:46:50.613890 14512 trainer.py:139] Epoch[625/1000] loss: 0.2315649874508381
I0803 01:47:06.234056 14512 trainer.py:139] Epoch[626/1000] loss: 0.23259954527020454
I0803 01:47:21.856797 14512 trainer.py:139] Epoch[627/1000] loss: 0.23121397197246552
I0803 01:47:37.465240 14512 trainer.py:139] Epoch[628/1000] loss: 0.23074304312467575
I0803 01:47:53.099020 14512 trainer.py:139] Epoch[629/1000] loss: 0.23155146092176437
I0803 01:48:08.624141 14512 trainer.py:139] Epoch[630/1000] loss: 0.23100287839770317
I0803 01:48:24.252133 14512 trainer.py:139] Epoch[631/1000] loss: 0.23006963357329369
I0803 01:48:40.066257 14512 trainer.py:139] Epoch[632/1000] loss: 0.2297111302614212
I0803 01:48:55.962687 14512 trainer.py:139] Epoch[633/1000] loss: 0.22974541783332825
I0803 01:49:11.464992 14512 trainer.py:139] Epoch[634/1000] loss: 0.23037270456552505
I0803 01:49:27.070620 14512 trainer.py:139] Epoch[635/1000] loss: 0.23086892068386078
I0803 01:49:42.818753 14512 trainer.py:139] Epoch[636/1000] loss: 0.23034580424427986
I0803 01:49:58.740087 14512 trainer.py:139] Epoch[637/1000] loss: 0.2295604571700096
I0803 01:50:14.456039 14512 trainer.py:139] Epoch[638/1000] loss: 0.23069188371300697
I0803 01:50:30.140616 14512 trainer.py:139] Epoch[639/1000] loss: 0.23081092908978462
I0803 01:50:46.055232 14512 trainer.py:139] Epoch[640/1000] loss: 0.23099657148122787
I0803 01:51:01.887728 14512 trainer.py:139] Epoch[641/1000] loss: 0.22971076890826225
I0803 01:51:17.467861 14512 trainer.py:139] Epoch[642/1000] loss: 0.22966095805168152
I0803 01:51:33.136889 14512 trainer.py:139] Epoch[643/1000] loss: 0.23052199557423592
I0803 01:51:48.922502 14512 trainer.py:139] Epoch[644/1000] loss: 0.22996247559785843
I0803 01:52:04.691612 14512 trainer.py:139] Epoch[645/1000] loss: 0.2299746796488762
I0803 01:52:20.549719 14512 trainer.py:139] Epoch[646/1000] loss: 0.23132183775305748
I0803 01:52:36.363709 14512 trainer.py:139] Epoch[647/1000] loss: 0.22846126928925514
I0803 01:52:51.994122 14512 trainer.py:139] Epoch[648/1000] loss: 0.22923115640878677
I0803 01:53:08.020318 14512 trainer.py:139] Epoch[649/1000] loss: 0.22990242019295692
I0803 01:53:08.648220 14512 trainer.py:145] Test: [{'precision': 0.18978297161936564, 'recall': 0.2643517123923176, 'hit_ratio': 0.8994991652754591, 'ndcg': 0.2957516682131512}]
I0803 01:53:24.399906 14512 trainer.py:139] Epoch[650/1000] loss: 0.2295706570148468
I0803 01:53:40.150153 14512 trainer.py:139] Epoch[651/1000] loss: 0.22835884615778923
I0803 01:53:55.723383 14512 trainer.py:139] Epoch[652/1000] loss: 0.22888172790408134
I0803 01:54:11.611253 14512 trainer.py:139] Epoch[653/1000] loss: 0.22916842624545097
I0803 01:54:27.179412 14512 trainer.py:139] Epoch[654/1000] loss: 0.2288886271417141
I0803 01:54:42.749593 14512 trainer.py:139] Epoch[655/1000] loss: 0.2291579581797123
I0803 01:54:58.924888 14512 trainer.py:139] Epoch[656/1000] loss: 0.22960291430354118
I0803 01:55:14.624576 14512 trainer.py:139] Epoch[657/1000] loss: 0.22930261492729187
I0803 01:55:30.418635 14512 trainer.py:139] Epoch[658/1000] loss: 0.22929191961884499
I0803 01:55:46.084452 14512 trainer.py:139] Epoch[659/1000] loss: 0.22913344949483871
I0803 01:56:01.945089 14512 trainer.py:139] Epoch[660/1000] loss: 0.22825193405151367
I0803 01:56:17.695164 14512 trainer.py:139] Epoch[661/1000] loss: 0.22835351154208183
I0803 01:56:33.423209 14512 trainer.py:139] Epoch[662/1000] loss: 0.2290136218070984
I0803 01:56:49.273368 14512 trainer.py:139] Epoch[663/1000] loss: 0.22949670627713203
I0803 01:57:05.081315 14512 trainer.py:139] Epoch[664/1000] loss: 0.2287938930094242
I0803 01:57:20.627817 14512 trainer.py:139] Epoch[665/1000] loss: 0.2283821478486061
I0803 01:57:36.643110 14512 trainer.py:139] Epoch[666/1000] loss: 0.2288747876882553
I0803 01:57:52.499447 14512 trainer.py:139] Epoch[667/1000] loss: 0.22872251272201538
I0803 01:58:08.206779 14512 trainer.py:139] Epoch[668/1000] loss: 0.2281741462647915
I0803 01:58:23.926465 14512 trainer.py:139] Epoch[669/1000] loss: 0.22880977019667625
I0803 01:58:39.759695 14512 trainer.py:139] Epoch[670/1000] loss: 0.2277490682899952
I0803 01:58:55.610923 14512 trainer.py:139] Epoch[671/1000] loss: 0.22905127704143524
I0803 01:59:11.224481 14512 trainer.py:139] Epoch[672/1000] loss: 0.22719526663422585
I0803 01:59:26.812023 14512 trainer.py:139] Epoch[673/1000] loss: 0.22742830961942673
I0803 01:59:42.473297 14512 trainer.py:139] Epoch[674/1000] loss: 0.22754238918423653
I0803 01:59:58.215661 14512 trainer.py:139] Epoch[675/1000] loss: 0.22769594565033913
I0803 02:00:13.928123 14512 trainer.py:139] Epoch[676/1000] loss: 0.2270464412868023
I0803 02:00:29.509202 14512 trainer.py:139] Epoch[677/1000] loss: 0.22698066011071205
I0803 02:00:45.276655 14512 trainer.py:139] Epoch[678/1000] loss: 0.22758051380515099
I0803 02:01:01.100429 14512 trainer.py:139] Epoch[679/1000] loss: 0.22678961977362633
I0803 02:01:16.844827 14512 trainer.py:139] Epoch[680/1000] loss: 0.22763697430491447
I0803 02:01:32.619609 14512 trainer.py:139] Epoch[681/1000] loss: 0.22678935900330544
I0803 02:01:48.493119 14512 trainer.py:139] Epoch[682/1000] loss: 0.2279796600341797
I0803 02:02:04.345342 14512 trainer.py:139] Epoch[683/1000] loss: 0.22740674018859863
I0803 02:02:19.924905 14512 trainer.py:139] Epoch[684/1000] loss: 0.22756431624293327
I0803 02:02:35.920497 14512 trainer.py:139] Epoch[685/1000] loss: 0.22802689671516418
I0803 02:02:51.685146 14512 trainer.py:139] Epoch[686/1000] loss: 0.2271326370537281
I0803 02:03:07.440739 14512 trainer.py:139] Epoch[687/1000] loss: 0.22782068327069283
I0803 02:03:23.184669 14512 trainer.py:139] Epoch[688/1000] loss: 0.2269144132733345
I0803 02:03:38.956766 14512 trainer.py:139] Epoch[689/1000] loss: 0.22765667364001274
I0803 02:03:54.938262 14512 trainer.py:139] Epoch[690/1000] loss: 0.22751253470778465
I0803 02:04:10.939931 14512 trainer.py:139] Epoch[691/1000] loss: 0.22656943649053574
I0803 02:04:26.773114 14512 trainer.py:139] Epoch[692/1000] loss: 0.22734994441270828
I0803 02:04:42.589207 14512 trainer.py:139] Epoch[693/1000] loss: 0.227921761572361
I0803 02:04:58.353630 14512 trainer.py:139] Epoch[694/1000] loss: 0.22663814201951027
I0803 02:05:13.820626 14512 trainer.py:139] Epoch[695/1000] loss: 0.22691354900598526
I0803 02:05:29.496884 14512 trainer.py:139] Epoch[696/1000] loss: 0.22751786559820175
I0803 02:05:45.155792 14512 trainer.py:139] Epoch[697/1000] loss: 0.22640477493405342
I0803 02:06:00.936340 14512 trainer.py:139] Epoch[698/1000] loss: 0.22657861560583115
I0803 02:06:16.597668 14512 trainer.py:139] Epoch[699/1000] loss: 0.2272988185286522
I0803 02:06:17.188235 14512 trainer.py:145] Test: [{'precision': 0.19088480801335558, 'recall': 0.2665822674858581, 'hit_ratio': 0.9018363939899833, 'ndcg': 0.29819148769370124}]
I0803 02:06:32.868129 14512 trainer.py:139] Epoch[700/1000] loss: 0.22687876597046852
I0803 02:06:48.734354 14512 trainer.py:139] Epoch[701/1000] loss: 0.22625967860221863
I0803 02:07:04.448169 14512 trainer.py:139] Epoch[702/1000] loss: 0.22750891745090485
I0803 02:07:20.133224 14512 trainer.py:139] Epoch[703/1000] loss: 0.22701112180948257
I0803 02:07:35.987300 14512 trainer.py:139] Epoch[704/1000] loss: 0.22712606191635132
I0803 02:07:51.946036 14512 trainer.py:139] Epoch[705/1000] loss: 0.22791482880711555
I0803 02:08:08.070205 14512 trainer.py:139] Epoch[706/1000] loss: 0.22659020870923996
I0803 02:08:23.792142 14512 trainer.py:139] Epoch[707/1000] loss: 0.226042740046978
I0803 02:08:39.757281 14512 trainer.py:139] Epoch[708/1000] loss: 0.22714295238256454
I0803 02:08:55.575321 14512 trainer.py:139] Epoch[709/1000] loss: 0.2264048494398594
I0803 02:09:11.257339 14512 trainer.py:139] Epoch[710/1000] loss: 0.2248925194144249
I0803 02:09:27.343029 14512 trainer.py:139] Epoch[711/1000] loss: 0.22540538012981415
I0803 02:09:43.122666 14512 trainer.py:139] Epoch[712/1000] loss: 0.22552259638905525
I0803 02:09:59.094361 14512 trainer.py:139] Epoch[713/1000] loss: 0.22623876482248306
I0803 02:10:14.774633 14512 trainer.py:139] Epoch[714/1000] loss: 0.22696547210216522
I0803 02:10:30.386775 14512 trainer.py:139] Epoch[715/1000] loss: 0.22528305277228355
I0803 02:10:46.287007 14512 trainer.py:139] Epoch[716/1000] loss: 0.2259073480963707
I0803 02:11:01.905433 14512 trainer.py:139] Epoch[717/1000] loss: 0.22527945414185524
I0803 02:11:17.652170 14512 trainer.py:139] Epoch[718/1000] loss: 0.22586986795067787
I0803 02:11:33.220768 14512 trainer.py:139] Epoch[719/1000] loss: 0.22625107318162918
I0803 02:11:48.779578 14512 trainer.py:139] Epoch[720/1000] loss: 0.22492947801947594
I0803 02:12:04.580583 14512 trainer.py:139] Epoch[721/1000] loss: 0.22488878294825554
I0803 02:12:20.298110 14512 trainer.py:139] Epoch[722/1000] loss: 0.22632885351777077
I0803 02:12:35.752515 14512 trainer.py:139] Epoch[723/1000] loss: 0.22495012357831
I0803 02:12:51.498550 14512 trainer.py:139] Epoch[724/1000] loss: 0.22597508877515793
I0803 02:13:07.181420 14512 trainer.py:139] Epoch[725/1000] loss: 0.22515378519892693
I0803 02:13:22.902510 14512 trainer.py:139] Epoch[726/1000] loss: 0.22573191672563553
I0803 02:13:38.786355 14512 trainer.py:139] Epoch[727/1000] loss: 0.22575437650084496
I0803 02:13:54.622646 14512 trainer.py:139] Epoch[728/1000] loss: 0.22433969378471375
I0803 02:14:10.307543 14512 trainer.py:139] Epoch[729/1000] loss: 0.22453542426228523
I0803 02:14:26.074573 14512 trainer.py:139] Epoch[730/1000] loss: 0.22551459074020386
I0803 02:14:41.852276 14512 trainer.py:139] Epoch[731/1000] loss: 0.22470275685191154
I0803 02:14:57.585848 14512 trainer.py:139] Epoch[732/1000] loss: 0.2250426486134529
I0803 02:15:13.264874 14512 trainer.py:139] Epoch[733/1000] loss: 0.22480572015047073
I0803 02:15:28.932367 14512 trainer.py:139] Epoch[734/1000] loss: 0.22538334503769875
I0803 02:15:44.473335 14512 trainer.py:139] Epoch[735/1000] loss: 0.22574374079704285
I0803 02:15:59.975690 14512 trainer.py:139] Epoch[736/1000] loss: 0.2247142232954502
I0803 02:16:15.539383 14512 trainer.py:139] Epoch[737/1000] loss: 0.22457905486226082
I0803 02:16:31.458210 14512 trainer.py:139] Epoch[738/1000] loss: 0.225024726241827
I0803 02:16:47.113709 14512 trainer.py:139] Epoch[739/1000] loss: 0.22459442913532257
I0803 02:17:02.744292 14512 trainer.py:139] Epoch[740/1000] loss: 0.22460804507136345
I0803 02:17:18.490792 14512 trainer.py:139] Epoch[741/1000] loss: 0.22394601628184319
I0803 02:17:34.340617 14512 trainer.py:139] Epoch[742/1000] loss: 0.22563011944293976
I0803 02:17:49.805244 14512 trainer.py:139] Epoch[743/1000] loss: 0.22540521621704102
I0803 02:18:05.399032 14512 trainer.py:139] Epoch[744/1000] loss: 0.22493796423077583
I0803 02:18:20.820012 14512 trainer.py:139] Epoch[745/1000] loss: 0.22502658516168594
I0803 02:18:36.414803 14512 trainer.py:139] Epoch[746/1000] loss: 0.22368606179952621
I0803 02:18:52.215617 14512 trainer.py:139] Epoch[747/1000] loss: 0.22406404837965965
I0803 02:19:08.150121 14512 trainer.py:139] Epoch[748/1000] loss: 0.22412969172000885
I0803 02:19:23.939489 14512 trainer.py:139] Epoch[749/1000] loss: 0.2248741313815117
I0803 02:19:24.525055 14512 trainer.py:145] Test: [{'precision': 0.19181969949916527, 'recall': 0.26868611733481773, 'hit_ratio': 0.9031719532554258, 'ndcg': 0.3001176219945339}]
I0803 02:19:40.468914 14512 trainer.py:139] Epoch[750/1000] loss: 0.2253497913479805
I0803 02:19:56.655210 14512 trainer.py:139] Epoch[751/1000] loss: 0.22510065510869026
I0803 02:20:12.339792 14512 trainer.py:139] Epoch[752/1000] loss: 0.2237105518579483
I0803 02:20:28.137392 14512 trainer.py:139] Epoch[753/1000] loss: 0.222760122269392
I0803 02:20:43.859390 14512 trainer.py:139] Epoch[754/1000] loss: 0.22325773537158966
I0803 02:20:59.496473 14512 trainer.py:139] Epoch[755/1000] loss: 0.2239507921040058
I0803 02:21:15.397810 14512 trainer.py:139] Epoch[756/1000] loss: 0.22481492906808853
I0803 02:21:31.272838 14512 trainer.py:139] Epoch[757/1000] loss: 0.22412266582250595
I0803 02:21:46.756687 14512 trainer.py:139] Epoch[758/1000] loss: 0.22354063391685486
I0803 02:22:02.268876 14512 trainer.py:139] Epoch[759/1000] loss: 0.22377311810851097
I0803 02:22:17.978472 14512 trainer.py:139] Epoch[760/1000] loss: 0.22297247499227524
I0803 02:22:33.642259 14512 trainer.py:139] Epoch[761/1000] loss: 0.22388944402337074
I0803 02:22:49.192985 14512 trainer.py:139] Epoch[762/1000] loss: 0.22406228259205818
I0803 02:23:04.869054 14512 trainer.py:139] Epoch[763/1000] loss: 0.22252845391631126
I0803 02:23:20.529769 14512 trainer.py:139] Epoch[764/1000] loss: 0.22424711659550667
I0803 02:23:36.244797 14512 trainer.py:139] Epoch[765/1000] loss: 0.2232937179505825
I0803 02:23:52.200621 14512 trainer.py:139] Epoch[766/1000] loss: 0.22342585772275925
I0803 02:24:08.035209 14512 trainer.py:139] Epoch[767/1000] loss: 0.22462091594934464
I0803 02:24:23.808622 14512 trainer.py:139] Epoch[768/1000] loss: 0.22367146983742714
I0803 02:24:39.424982 14512 trainer.py:139] Epoch[769/1000] loss: 0.22442259266972542
I0803 02:24:55.193506 14512 trainer.py:139] Epoch[770/1000] loss: 0.22294580936431885
I0803 02:25:11.191775 14512 trainer.py:139] Epoch[771/1000] loss: 0.22386235371232033
I0803 02:25:27.144479 14512 trainer.py:139] Epoch[772/1000] loss: 0.22295700386166573
I0803 02:25:43.027388 14512 trainer.py:139] Epoch[773/1000] loss: 0.22394659370183945
I0803 02:25:58.847680 14512 trainer.py:139] Epoch[774/1000] loss: 0.2231702320277691
I0803 02:26:15.034171 14512 trainer.py:139] Epoch[775/1000] loss: 0.223102156072855
I0803 02:26:30.654146 14512 trainer.py:139] Epoch[776/1000] loss: 0.22248118743300438
I0803 02:26:46.327731 14512 trainer.py:139] Epoch[777/1000] loss: 0.22345135360956192
I0803 02:27:02.173643 14512 trainer.py:139] Epoch[778/1000] loss: 0.22344836220145226
I0803 02:27:17.886715 14512 trainer.py:139] Epoch[779/1000] loss: 0.22310595586895943
I0803 02:27:33.511034 14512 trainer.py:139] Epoch[780/1000] loss: 0.22251705452799797
I0803 02:27:48.996058 14512 trainer.py:139] Epoch[781/1000] loss: 0.22302092984318733
I0803 02:28:04.609057 14512 trainer.py:139] Epoch[782/1000] loss: 0.22372512891888618
I0803 02:28:20.051078 14512 trainer.py:139] Epoch[783/1000] loss: 0.22250418737530708
I0803 02:28:35.710974 14512 trainer.py:139] Epoch[784/1000] loss: 0.22247447445988655
I0803 02:28:51.597705 14512 trainer.py:139] Epoch[785/1000] loss: 0.22239118069410324
