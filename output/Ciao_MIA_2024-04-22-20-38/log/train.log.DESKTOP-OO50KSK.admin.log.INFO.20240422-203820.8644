I0422 20:38:29.279668 32300 trainer.py:118] Test: [{'precision': 0.0074615165336374, 'recall': 0.03100125386163198, 'hit_ratio': 0.09449828962371722, 'ndcg': 0.024359300746050607}]
I0422 20:38:33.000664 32300 trainer.py:136] Epoch[0/1000] loss: 0.6970090170701345
I0422 20:38:37.000483 32300 trainer.py:136] Epoch[1/1000] loss: 0.6860108375549316
I0422 20:38:40.749266 32300 trainer.py:136] Epoch[2/1000] loss: 0.6788207391897837
I0422 20:38:44.421264 32300 trainer.py:136] Epoch[3/1000] loss: 0.6708178619543711
I0422 20:38:48.316491 32300 trainer.py:136] Epoch[4/1000] loss: 0.6650501588980356
I0422 20:38:51.951032 32300 trainer.py:136] Epoch[5/1000] loss: 0.6597862839698792
I0422 20:38:55.697620 32300 trainer.py:136] Epoch[6/1000] loss: 0.6554054915904999
I0422 20:38:59.427903 32300 trainer.py:136] Epoch[7/1000] loss: 0.6510237753391266
I0422 20:39:03.105853 32300 trainer.py:136] Epoch[8/1000] loss: 0.6456818183263143
I0422 20:39:06.787855 32300 trainer.py:136] Epoch[9/1000] loss: 0.6421921054522196
I0422 20:39:10.558575 32300 trainer.py:136] Epoch[10/1000] loss: 0.6358242134253184
I0422 20:39:14.512586 32300 trainer.py:136] Epoch[11/1000] loss: 0.6306262115637461
I0422 20:39:18.148264 32300 trainer.py:136] Epoch[12/1000] loss: 0.6258111993471781
I0422 20:39:21.988249 32300 trainer.py:136] Epoch[13/1000] loss: 0.6199228862921397
I0422 20:39:25.944499 32300 trainer.py:136] Epoch[14/1000] loss: 0.6150012016296387
I0422 20:39:29.658344 32300 trainer.py:136] Epoch[15/1000] loss: 0.6090460121631622
I0422 20:39:33.378480 32300 trainer.py:136] Epoch[16/1000] loss: 0.6019589900970459
I0422 20:39:37.001266 32300 trainer.py:136] Epoch[17/1000] loss: 0.5949619710445404
I0422 20:39:40.694734 32300 trainer.py:136] Epoch[18/1000] loss: 0.5876661737759908
I0422 20:39:44.422592 32300 trainer.py:136] Epoch[19/1000] loss: 0.5804410676161448
I0422 20:39:48.089936 32300 trainer.py:136] Epoch[20/1000] loss: 0.5735657115777334
I0422 20:39:51.731104 32300 trainer.py:136] Epoch[21/1000] loss: 0.5647890269756317
I0422 20:39:55.516701 32300 trainer.py:136] Epoch[22/1000] loss: 0.5567502578099569
I0422 20:39:59.170293 32300 trainer.py:136] Epoch[23/1000] loss: 0.5493474801381429
I0422 20:40:02.829963 32300 trainer.py:136] Epoch[24/1000] loss: 0.540346364180247
I0422 20:40:06.738597 32300 trainer.py:136] Epoch[25/1000] loss: 0.5305917660395304
I0422 20:40:10.499082 32300 trainer.py:136] Epoch[26/1000] loss: 0.5229916870594025
I0422 20:40:14.203086 32300 trainer.py:136] Epoch[27/1000] loss: 0.5147472321987152
I0422 20:40:17.971213 32300 trainer.py:136] Epoch[28/1000] loss: 0.5041544685761133
I0422 20:40:21.847137 32300 trainer.py:136] Epoch[29/1000] loss: 0.4955941090981166
I0422 20:40:25.741386 32300 trainer.py:136] Epoch[30/1000] loss: 0.4883456875880559
I0422 20:40:29.494184 32300 trainer.py:136] Epoch[31/1000] loss: 0.47832933564980823
I0422 20:40:33.283772 32300 trainer.py:136] Epoch[32/1000] loss: 0.4678606192270915
I0422 20:40:37.468270 32300 trainer.py:136] Epoch[33/1000] loss: 0.46218497554461163
I0422 20:40:41.355724 32300 trainer.py:136] Epoch[34/1000] loss: 0.45335015654563904
I0422 20:40:45.221063 32300 trainer.py:136] Epoch[35/1000] loss: 0.44221708675225574
I0422 20:40:49.007795 32300 trainer.py:136] Epoch[36/1000] loss: 0.43453406790892285
I0422 20:40:52.778281 32300 trainer.py:136] Epoch[37/1000] loss: 0.4265757103761037
I0422 20:40:56.713950 32300 trainer.py:136] Epoch[38/1000] loss: 0.4178133209546407
I0422 20:41:00.489905 32300 trainer.py:136] Epoch[39/1000] loss: 0.4110667059818904
I0422 20:41:04.250689 32300 trainer.py:136] Epoch[40/1000] loss: 0.4034043252468109
I0422 20:41:07.973043 32300 trainer.py:136] Epoch[41/1000] loss: 0.3964552978674571
I0422 20:41:11.807472 32300 trainer.py:136] Epoch[42/1000] loss: 0.38831158479054767
I0422 20:41:15.800425 32300 trainer.py:136] Epoch[43/1000] loss: 0.38268668949604034
I0422 20:41:19.743478 32300 trainer.py:136] Epoch[44/1000] loss: 0.37468724449475604
I0422 20:41:23.602159 32300 trainer.py:136] Epoch[45/1000] loss: 0.36622561514377594
I0422 20:41:27.713798 32300 trainer.py:136] Epoch[46/1000] loss: 0.36220132807890576
I0422 20:41:31.857894 32300 trainer.py:136] Epoch[47/1000] loss: 0.3547135541836421
I0422 20:41:35.965611 32300 trainer.py:136] Epoch[48/1000] loss: 0.3489268769820531
I0422 20:41:39.932704 32300 trainer.py:136] Epoch[49/1000] loss: 0.34170936048030853
I0422 20:41:41.395983 32300 trainer.py:142] Test: [{'precision': 0.014210376282782206, 'recall': 0.06657029537558375, 'hit_ratio': 0.19170467502850627, 'ndcg': 0.04415399081209364}]
I0422 20:41:45.380017 32300 trainer.py:136] Epoch[50/1000] loss: 0.33636608719825745
I0422 20:41:49.637967 32300 trainer.py:136] Epoch[51/1000] loss: 0.3308194875717163
I0422 20:41:53.638315 32300 trainer.py:136] Epoch[52/1000] loss: 0.32315077384312946
I0422 20:41:57.625583 32300 trainer.py:136] Epoch[53/1000] loss: 0.32000863055388135
I0422 20:42:01.537554 32300 trainer.py:136] Epoch[54/1000] loss: 0.31308217346668243
I0422 20:42:05.706403 32300 trainer.py:136] Epoch[55/1000] loss: 0.3096047341823578
I0422 20:42:10.120503 32300 trainer.py:136] Epoch[56/1000] loss: 0.3043568233648936
I0422 20:42:14.395579 32300 trainer.py:136] Epoch[57/1000] loss: 0.2983863304058711
I0422 20:42:18.690839 32300 trainer.py:136] Epoch[58/1000] loss: 0.2949189841747284
I0422 20:42:23.199747 32300 trainer.py:136] Epoch[59/1000] loss: 0.2909252295891444
I0422 20:42:27.247398 32300 trainer.py:136] Epoch[60/1000] loss: 0.28494526942571
I0422 20:42:31.389858 32300 trainer.py:136] Epoch[61/1000] loss: 0.28186118106047314
I0422 20:42:35.650029 32300 trainer.py:136] Epoch[62/1000] loss: 0.28130730986595154
I0422 20:42:39.933547 32300 trainer.py:136] Epoch[63/1000] loss: 0.27301036318143207
I0422 20:42:44.045348 32300 trainer.py:136] Epoch[64/1000] loss: 0.2691769649585088
I0422 20:42:48.491314 32300 trainer.py:136] Epoch[65/1000] loss: 0.2644300311803818
I0422 20:42:52.629348 32300 trainer.py:136] Epoch[66/1000] loss: 0.26284126937389374
I0422 20:42:56.741967 32300 trainer.py:136] Epoch[67/1000] loss: 0.2597786883513133
I0422 20:43:00.889482 32300 trainer.py:136] Epoch[68/1000] loss: 0.2552355428536733
I0422 20:43:04.954827 32300 trainer.py:136] Epoch[69/1000] loss: 0.25156473616758984
I0422 20:43:09.052098 32300 trainer.py:136] Epoch[70/1000] loss: 0.2466238265236219
I0422 20:43:13.187200 32300 trainer.py:136] Epoch[71/1000] loss: 0.24425654113292694
I0422 20:43:17.351574 32300 trainer.py:136] Epoch[72/1000] loss: 0.24061490843693414
I0422 20:43:21.580683 32300 trainer.py:136] Epoch[73/1000] loss: 0.2393131231268247
I0422 20:43:25.728059 32300 trainer.py:136] Epoch[74/1000] loss: 0.23647775501012802
I0422 20:43:29.756866 32300 trainer.py:136] Epoch[75/1000] loss: 0.2319327617685
I0422 20:43:33.816235 32300 trainer.py:136] Epoch[76/1000] loss: 0.2279530589779218
I0422 20:43:38.386595 32300 trainer.py:136] Epoch[77/1000] loss: 0.22782067209482193
I0422 20:43:42.619683 32300 trainer.py:136] Epoch[78/1000] loss: 0.22244497140248617
I0422 20:43:46.750151 32300 trainer.py:136] Epoch[79/1000] loss: 0.22231579820315042
I0422 20:43:50.933394 32300 trainer.py:136] Epoch[80/1000] loss: 0.2209664856394132
I0422 20:43:55.127243 32300 trainer.py:136] Epoch[81/1000] loss: 0.21823624769846597
I0422 20:43:59.317653 32300 trainer.py:136] Epoch[82/1000] loss: 0.21602539221445718
I0422 20:44:03.530183 32300 trainer.py:136] Epoch[83/1000] loss: 0.21231605609258017
I0422 20:44:07.838372 32300 trainer.py:136] Epoch[84/1000] loss: 0.21183422952890396
I0422 20:44:12.097394 32300 trainer.py:136] Epoch[85/1000] loss: 0.20816966146230698
I0422 20:44:16.149694 32300 trainer.py:136] Epoch[86/1000] loss: 0.20702806611855826
I0422 20:44:20.278106 32300 trainer.py:136] Epoch[87/1000] loss: 0.20295237998167673
I0422 20:44:24.561117 32300 trainer.py:136] Epoch[88/1000] loss: 0.20300191889206567
I0422 20:44:28.870005 32300 trainer.py:136] Epoch[89/1000] loss: 0.19992122054100037
I0422 20:44:35.359429 32300 trainer.py:136] Epoch[90/1000] loss: 0.1985910733540853
I0422 20:44:39.702160 32300 trainer.py:136] Epoch[91/1000] loss: 0.1963022177418073
I0422 20:44:43.969262 32300 trainer.py:136] Epoch[92/1000] loss: 0.19415689756472906
I0422 20:44:48.324651 32300 trainer.py:136] Epoch[93/1000] loss: 0.19350749254226685
I0422 20:44:52.492077 32300 trainer.py:136] Epoch[94/1000] loss: 0.1912694995601972
I0422 20:44:56.798085 32300 trainer.py:136] Epoch[95/1000] loss: 0.19131634632746378
I0422 20:45:00.856772 32300 trainer.py:136] Epoch[96/1000] loss: 0.1873051499327024
I0422 20:45:05.236810 32300 trainer.py:136] Epoch[97/1000] loss: 0.1855528230468432
I0422 20:45:12.045773 32300 trainer.py:136] Epoch[98/1000] loss: 0.18422773480415344
I0422 20:45:16.522058 32300 trainer.py:136] Epoch[99/1000] loss: 0.18203680217266083
I0422 20:45:17.943845 32300 trainer.py:142] Test: [{'precision': 0.01473774230330672, 'recall': 0.0710028030519228, 'hit_ratio': 0.20339224629418473, 'ndcg': 0.04591714378532798}]
I0422 20:45:22.128288 32300 trainer.py:136] Epoch[100/1000] loss: 0.1807094762722651
I0422 20:45:26.551359 32300 trainer.py:136] Epoch[101/1000] loss: 0.18132524192333221
I0422 20:45:30.639916 32300 trainer.py:136] Epoch[102/1000] loss: 0.17755578209956488
I0422 20:45:34.971527 32300 trainer.py:136] Epoch[103/1000] loss: 0.17769105484088263
I0422 20:45:41.638140 32300 trainer.py:136] Epoch[104/1000] loss: 0.17559323459863663
I0422 20:45:48.204923 32300 trainer.py:136] Epoch[105/1000] loss: 0.17478563636541367
I0422 20:45:53.378678 32300 trainer.py:136] Epoch[106/1000] loss: 0.17258911828200021
I0422 20:45:58.910697 32300 trainer.py:136] Epoch[107/1000] loss: 0.1718109870950381
I0422 20:46:06.355969 32300 trainer.py:136] Epoch[108/1000] loss: 0.1720486357808113
I0422 20:46:11.445025 32300 trainer.py:136] Epoch[109/1000] loss: 0.16842102259397507
I0422 20:46:16.697308 32300 trainer.py:136] Epoch[110/1000] loss: 0.16783800969521204
I0422 20:46:21.860940 32300 trainer.py:136] Epoch[111/1000] loss: 0.16899834324916205
I0422 20:46:29.418585 32300 trainer.py:136] Epoch[112/1000] loss: 0.1648094654083252
I0422 20:46:34.534379 32300 trainer.py:136] Epoch[113/1000] loss: 0.16464980691671371
I0422 20:46:39.666706 32300 trainer.py:136] Epoch[114/1000] loss: 0.16321821759144464
I0422 20:46:44.883379 32300 trainer.py:136] Epoch[115/1000] loss: 0.16315178821484247
I0422 20:46:52.454608 32300 trainer.py:136] Epoch[116/1000] loss: 0.16243052234252295
I0422 20:46:57.521070 32300 trainer.py:136] Epoch[117/1000] loss: 0.15942980349063873
I0422 20:47:02.615674 32300 trainer.py:136] Epoch[118/1000] loss: 0.15970361232757568
I0422 20:47:07.883877 32300 trainer.py:136] Epoch[119/1000] loss: 0.15809153765439987
I0422 20:47:14.979728 32300 trainer.py:136] Epoch[120/1000] loss: 0.157893106341362
I0422 20:47:20.990835 32300 trainer.py:136] Epoch[121/1000] loss: 0.15758173167705536
I0422 20:47:26.396387 32300 trainer.py:136] Epoch[122/1000] loss: 0.15666770935058594
I0422 20:47:31.633143 32300 trainer.py:136] Epoch[123/1000] loss: 0.15433569500843683
I0422 20:47:39.556461 32300 trainer.py:136] Epoch[124/1000] loss: 0.15371081481377283
I0422 20:47:44.766228 32300 trainer.py:136] Epoch[125/1000] loss: 0.15178945660591125
I0422 20:47:49.653315 32300 trainer.py:136] Epoch[126/1000] loss: 0.15156997988621393
I0422 20:47:57.604220 32300 trainer.py:136] Epoch[127/1000] loss: 0.14915497352679571
I0422 20:48:02.609114 32300 trainer.py:136] Epoch[128/1000] loss: 0.15016748756170273
I0422 20:48:07.829682 32300 trainer.py:136] Epoch[129/1000] loss: 0.14954400807619095
I0422 20:48:12.806624 32300 trainer.py:136] Epoch[130/1000] loss: 0.1487456758817037
I0422 20:48:20.306559 32300 trainer.py:136] Epoch[131/1000] loss: 0.14801149318615595
I0422 20:48:25.457878 32300 trainer.py:136] Epoch[132/1000] loss: 0.1461120843887329
I0422 20:48:30.530647 32300 trainer.py:136] Epoch[133/1000] loss: 0.14694981773694357
I0422 20:48:37.322684 32300 trainer.py:136] Epoch[134/1000] loss: 0.14618253211180368
I0422 20:48:43.232083 32300 trainer.py:136] Epoch[135/1000] loss: 0.14420215288798013
I0422 20:48:48.310931 32300 trainer.py:136] Epoch[136/1000] loss: 0.1432385047276815
I0422 20:48:53.523589 32300 trainer.py:136] Epoch[137/1000] loss: 0.14469586312770844
I0422 20:49:01.368267 32300 trainer.py:136] Epoch[138/1000] loss: 0.14368703464667001
I0422 20:49:06.228796 32300 trainer.py:136] Epoch[139/1000] loss: 0.1443589230378469
I0422 20:49:11.227450 32300 trainer.py:136] Epoch[140/1000] loss: 0.14124747862418494
I0422 20:49:18.389173 32300 trainer.py:136] Epoch[141/1000] loss: 0.14037073155244192
I0422 20:49:24.062085 32300 trainer.py:136] Epoch[142/1000] loss: 0.14049874742825827
I0422 20:49:28.937801 32300 trainer.py:136] Epoch[143/1000] loss: 0.13946916659673056
I0422 20:49:33.907524 32300 trainer.py:136] Epoch[144/1000] loss: 0.1377973879377047
I0422 20:49:41.803820 32300 trainer.py:136] Epoch[145/1000] loss: 0.1386628026763598
I0422 20:49:46.971371 32300 trainer.py:136] Epoch[146/1000] loss: 0.1370065982143084
I0422 20:49:52.092344 32300 trainer.py:136] Epoch[147/1000] loss: 0.1361397902170817
I0422 20:50:00.030769 32300 trainer.py:136] Epoch[148/1000] loss: 0.13825396448373795
I0422 20:50:05.103079 32300 trainer.py:136] Epoch[149/1000] loss: 0.13559883336226145
I0422 20:50:07.346240 32300 trainer.py:142] Test: [{'precision': 0.014987172177879123, 'recall': 0.07181823880814282, 'hit_ratio': 0.20510262257696693, 'ndcg': 0.0467431667176206}]
I0422 20:50:12.442711 32300 trainer.py:136] Epoch[150/1000] loss: 0.135645200808843
I0422 20:50:20.326776 32300 trainer.py:136] Epoch[151/1000] loss: 0.13548057029644647
I0422 20:50:25.114372 32300 trainer.py:136] Epoch[152/1000] loss: 0.1356082409620285
I0422 20:50:29.901052 32300 trainer.py:136] Epoch[153/1000] loss: 0.13451960186163583
I0422 20:50:36.213212 32300 trainer.py:136] Epoch[154/1000] loss: 0.1339667166272799
I0422 20:50:42.666632 32300 trainer.py:136] Epoch[155/1000] loss: 0.13164037466049194
I0422 20:50:47.655708 32300 trainer.py:136] Epoch[156/1000] loss: 0.1340943401058515
I0422 20:50:53.300012 32300 trainer.py:136] Epoch[157/1000] loss: 0.1311450625459353
I0422 20:50:59.510066 32300 trainer.py:136] Epoch[158/1000] loss: 0.13102891047795615
I0422 20:51:03.686146 32300 trainer.py:136] Epoch[159/1000] loss: 0.13034402082363764
I0422 20:51:07.820118 32300 trainer.py:136] Epoch[160/1000] loss: 0.13160334279139838
I0422 20:51:11.816106 32300 trainer.py:136] Epoch[161/1000] loss: 0.13153226425250372
I0422 20:51:16.150030 32300 trainer.py:136] Epoch[162/1000] loss: 0.12999111165603003
I0422 20:51:20.392617 32300 trainer.py:136] Epoch[163/1000] loss: 0.12965076665083566
I0422 20:51:25.907853 32300 trainer.py:136] Epoch[164/1000] loss: 0.12883087744315466
I0422 20:51:31.332048 32300 trainer.py:136] Epoch[165/1000] loss: 0.12783312300841013
I0422 20:51:35.433905 32300 trainer.py:136] Epoch[166/1000] loss: 0.1290176436305046
I0422 20:51:39.448416 32300 trainer.py:136] Epoch[167/1000] loss: 0.12803734093904495
I0422 20:51:43.743711 32300 trainer.py:136] Epoch[168/1000] loss: 0.1279145802060763
I0422 20:51:47.976028 32300 trainer.py:136] Epoch[169/1000] loss: 0.1261749987800916
I0422 20:51:52.078840 32300 trainer.py:136] Epoch[170/1000] loss: 0.1275594855348269
I0422 20:51:56.359572 32300 trainer.py:136] Epoch[171/1000] loss: 0.12552978843450546
I0422 20:52:02.757456 32300 trainer.py:136] Epoch[172/1000] loss: 0.12455675130089124
I0422 20:52:07.050571 32300 trainer.py:136] Epoch[173/1000] loss: 0.12501304472486177
I0422 20:52:11.274070 32300 trainer.py:136] Epoch[174/1000] loss: 0.12577740103006363
I0422 20:52:15.499706 32300 trainer.py:136] Epoch[175/1000] loss: 0.1240118866165479
I0422 20:52:19.706637 32300 trainer.py:136] Epoch[176/1000] loss: 0.1235685758292675
I0422 20:52:24.030691 32300 trainer.py:136] Epoch[177/1000] loss: 0.12392107894023259
I0422 20:52:28.611538 32300 trainer.py:136] Epoch[178/1000] loss: 0.12409338603417079
I0422 20:52:36.382091 32300 trainer.py:136] Epoch[179/1000] loss: 0.12296264121929805
I0422 20:52:40.799034 32300 trainer.py:136] Epoch[180/1000] loss: 0.12322035680214564
I0422 20:52:45.034245 32300 trainer.py:136] Epoch[181/1000] loss: 0.12122407803932826
I0422 20:52:49.397339 32300 trainer.py:136] Epoch[182/1000] loss: 0.1244471048315366
I0422 20:52:53.634126 32300 trainer.py:136] Epoch[183/1000] loss: 0.12091462686657906
I0422 20:52:57.760368 32300 trainer.py:136] Epoch[184/1000] loss: 0.12108653659621875
I0422 20:53:04.347757 32300 trainer.py:136] Epoch[185/1000] loss: 0.11953806380430858
I0422 20:53:08.424188 32300 trainer.py:136] Epoch[186/1000] loss: 0.12111989160378774
I0422 20:53:12.473066 32300 trainer.py:136] Epoch[187/1000] loss: 0.11993467807769775
I0422 20:53:16.615371 32300 trainer.py:136] Epoch[188/1000] loss: 0.12088165432214737
I0422 20:53:21.107766 32300 trainer.py:136] Epoch[189/1000] loss: 0.11802454416950543
I0422 20:53:25.861994 32300 trainer.py:136] Epoch[190/1000] loss: 0.1180787521104018
I0422 20:53:31.913566 32300 trainer.py:136] Epoch[191/1000] loss: 0.1190968615313371
I0422 20:53:36.163147 32300 trainer.py:136] Epoch[192/1000] loss: 0.11627671743432681
I0422 20:53:40.284734 32300 trainer.py:136] Epoch[193/1000] loss: 0.11901293819149335
I0422 20:53:44.366095 32300 trainer.py:136] Epoch[194/1000] loss: 0.11646588270862897
I0422 20:53:48.487928 32300 trainer.py:136] Epoch[195/1000] loss: 0.11687581613659859
I0422 20:53:52.664233 32300 trainer.py:136] Epoch[196/1000] loss: 0.11686194563905399
I0422 20:53:56.805591 32300 trainer.py:136] Epoch[197/1000] loss: 0.11742560317118962
I0422 20:54:01.081397 32300 trainer.py:136] Epoch[198/1000] loss: 0.11626773700118065
I0422 20:54:09.189037 32300 trainer.py:136] Epoch[199/1000] loss: 0.11682503049572308
I0422 20:54:11.514397 32300 trainer.py:142] Test: [{'precision': 0.015300741163055867, 'recall': 0.07314246562357597, 'hit_ratio': 0.20823831242873433, 'ndcg': 0.04789408858801645}]
I0422 20:54:16.828416 32300 trainer.py:136] Epoch[200/1000] loss: 0.11610120659073193
I0422 20:54:23.539398 32300 trainer.py:136] Epoch[201/1000] loss: 0.11556599910060565
I0422 20:54:30.015092 32300 trainer.py:136] Epoch[202/1000] loss: 0.11628626535336177
I0422 20:54:35.441396 32300 trainer.py:136] Epoch[203/1000] loss: 0.11592711632450421
I0422 20:54:43.770726 32300 trainer.py:136] Epoch[204/1000] loss: 0.11507013191779454
I0422 20:54:49.110661 32300 trainer.py:136] Epoch[205/1000] loss: 0.11446875209609668
I0422 20:54:54.396588 32300 trainer.py:136] Epoch[206/1000] loss: 0.11536612982551257
I0422 20:55:00.329360 32300 trainer.py:136] Epoch[207/1000] loss: 0.11542422572771709
I0422 20:55:06.882351 32300 trainer.py:136] Epoch[208/1000] loss: 0.11289770031968753
I0422 20:55:12.110879 32300 trainer.py:136] Epoch[209/1000] loss: 0.11407805110017459
I0422 20:55:18.813371 32300 trainer.py:136] Epoch[210/1000] loss: 0.11384616047143936
I0422 20:55:25.461716 32300 trainer.py:136] Epoch[211/1000] loss: 0.11297012493014336
I0422 20:55:30.961659 32300 trainer.py:136] Epoch[212/1000] loss: 0.11388096958398819
I0422 20:55:38.624383 32300 trainer.py:136] Epoch[213/1000] loss: 0.11175491660833359
I0422 20:55:44.205588 32300 trainer.py:136] Epoch[214/1000] loss: 0.11178658157587051
I0422 20:55:49.590289 32300 trainer.py:136] Epoch[215/1000] loss: 0.11119825020432472
I0422 20:55:54.591903 32300 trainer.py:136] Epoch[216/1000] loss: 0.11169779176513354
I0422 20:56:02.423521 32300 trainer.py:136] Epoch[217/1000] loss: 0.11306097855170567
I0422 20:56:07.485400 32300 trainer.py:136] Epoch[218/1000] loss: 0.11226459468404452
I0422 20:56:12.772174 32300 trainer.py:136] Epoch[219/1000] loss: 0.11094952871402104
I0422 20:56:19.570047 32300 trainer.py:136] Epoch[220/1000] loss: 0.11203211545944214
I0422 20:56:25.931345 32300 trainer.py:136] Epoch[221/1000] loss: 0.11182849481701851
I0422 20:56:31.098716 32300 trainer.py:136] Epoch[222/1000] loss: 0.11039857566356659
I0422 20:56:36.226423 32300 trainer.py:136] Epoch[223/1000] loss: 0.11086173107226689
I0422 20:56:44.276302 32300 trainer.py:136] Epoch[224/1000] loss: 0.11116828521092732
I0422 20:56:49.480752 32300 trainer.py:136] Epoch[225/1000] loss: 0.11142728229363759
I0422 20:56:54.537320 32300 trainer.py:136] Epoch[226/1000] loss: 0.109686894963185
I0422 20:57:01.869366 32300 trainer.py:136] Epoch[227/1000] loss: 0.1108481598397096
I0422 20:57:06.379161 32300 trainer.py:136] Epoch[228/1000] loss: 0.1095354085167249
I0422 20:57:11.697220 32300 trainer.py:136] Epoch[229/1000] loss: 0.10921437789996465
I0422 20:57:19.610498 32300 trainer.py:136] Epoch[230/1000] loss: 0.11033049349983533
I0422 20:57:24.796441 32300 trainer.py:136] Epoch[231/1000] loss: 0.10878375545144081
I0422 20:57:29.964082 32300 trainer.py:136] Epoch[232/1000] loss: 0.10818018515904744
I0422 20:57:37.531128 32300 trainer.py:136] Epoch[233/1000] loss: 0.10813163096706073
I0422 20:57:42.546625 32300 trainer.py:136] Epoch[234/1000] loss: 0.1086701788008213
I0422 20:57:47.507120 32300 trainer.py:136] Epoch[235/1000] loss: 0.10914459824562073
I0422 20:57:55.202874 32300 trainer.py:136] Epoch[236/1000] loss: 0.10760035365819931
I0422 20:58:00.186870 32300 trainer.py:136] Epoch[237/1000] loss: 0.10825443516174953
I0422 20:58:05.309081 32300 trainer.py:136] Epoch[238/1000] loss: 0.10754576946298282
I0422 20:58:11.598619 32300 trainer.py:136] Epoch[239/1000] loss: 0.10795727123816808
I0422 20:58:18.423146 32300 trainer.py:136] Epoch[240/1000] loss: 0.10732577120264371
I0422 20:58:23.228903 32300 trainer.py:136] Epoch[241/1000] loss: 0.10772593691945076
I0422 20:58:28.174956 32300 trainer.py:136] Epoch[242/1000] loss: 0.1067168948551019
I0422 20:58:35.504849 32300 trainer.py:136] Epoch[243/1000] loss: 0.10793302208185196
I0422 20:58:40.984886 32300 trainer.py:136] Epoch[244/1000] loss: 0.10570143287380536
I0422 20:58:45.976011 32300 trainer.py:136] Epoch[245/1000] loss: 0.10633342216412227
I0422 20:58:50.989070 32300 trainer.py:136] Epoch[246/1000] loss: 0.10777077948053677
I0422 20:58:58.500122 32300 trainer.py:136] Epoch[247/1000] loss: 0.10780968392888705
I0422 20:59:03.784955 32300 trainer.py:136] Epoch[248/1000] loss: 0.10663270329435666
I0422 20:59:09.340771 32300 trainer.py:136] Epoch[249/1000] loss: 0.10518978536128998
I0422 20:59:11.889659 32300 trainer.py:142] Test: [{'precision': 0.015592930444697827, 'recall': 0.07475377631504972, 'hit_ratio': 0.21436716077537057, 'ndcg': 0.04907222484923325}]
I0422 20:59:19.679949 32300 trainer.py:136] Epoch[250/1000] loss: 0.1050586166481177
I0422 20:59:24.786490 32300 trainer.py:136] Epoch[251/1000] loss: 0.10409829393029213
I0422 20:59:30.783454 32300 trainer.py:136] Epoch[252/1000] loss: 0.10526608924070995
I0422 20:59:38.190975 32300 trainer.py:136] Epoch[253/1000] loss: 0.10494511326154073
I0422 20:59:43.297796 32300 trainer.py:136] Epoch[254/1000] loss: 0.10480262339115143
I0422 20:59:50.021036 32300 trainer.py:136] Epoch[255/1000] loss: 0.10531054561336835
I0422 20:59:56.738018 32300 trainer.py:136] Epoch[256/1000] loss: 0.10567377383510272
I0422 21:00:01.874657 32300 trainer.py:136] Epoch[257/1000] loss: 0.10610166192054749
I0422 21:00:09.543422 32300 trainer.py:136] Epoch[258/1000] loss: 0.10580770919720332
I0422 21:00:14.776083 32300 trainer.py:136] Epoch[259/1000] loss: 0.10568603873252869
I0422 21:00:20.187618 32300 trainer.py:136] Epoch[260/1000] loss: 0.10480001320441563
I0422 21:00:28.713712 32300 trainer.py:136] Epoch[261/1000] loss: 0.10423877586921056
I0422 21:00:33.973512 32300 trainer.py:136] Epoch[262/1000] loss: 0.10462124024828275
I0422 21:00:39.334035 32300 trainer.py:136] Epoch[263/1000] loss: 0.10382624467213948
I0422 21:00:47.441422 32300 trainer.py:136] Epoch[264/1000] loss: 0.10291026532649994
I0422 21:00:52.397117 32300 trainer.py:136] Epoch[265/1000] loss: 0.10334085300564766
I0422 21:00:57.648709 32300 trainer.py:136] Epoch[266/1000] loss: 0.10500291486581166
I0422 21:01:05.148970 32300 trainer.py:136] Epoch[267/1000] loss: 0.10386992121736209
I0422 21:01:10.826551 32300 trainer.py:136] Epoch[268/1000] loss: 0.10464030380050342
I0422 21:01:16.064968 32300 trainer.py:136] Epoch[269/1000] loss: 0.10333206132054329
I0422 21:01:21.342349 32300 trainer.py:136] Epoch[270/1000] loss: 0.10378593082229297
I0422 21:01:29.234771 32300 trainer.py:136] Epoch[271/1000] loss: 0.10315360377232234
I0422 21:01:34.304538 32300 trainer.py:136] Epoch[272/1000] loss: 0.10355199004213016
I0422 21:01:39.408376 32300 trainer.py:136] Epoch[273/1000] loss: 0.10213567316532135
I0422 21:01:47.189911 32300 trainer.py:136] Epoch[274/1000] loss: 0.1025133232275645
I0422 21:01:52.442180 32300 trainer.py:136] Epoch[275/1000] loss: 0.10313332453370094
I0422 21:01:57.560328 32300 trainer.py:136] Epoch[276/1000] loss: 0.10327224433422089
I0422 21:02:02.672475 32300 trainer.py:136] Epoch[277/1000] loss: 0.10216826821366946
I0422 21:02:10.708958 32300 trainer.py:136] Epoch[278/1000] loss: 0.10095273951689403
I0422 21:02:16.110344 32300 trainer.py:136] Epoch[279/1000] loss: 0.10288054247697194
I0422 21:02:21.225429 32300 trainer.py:136] Epoch[280/1000] loss: 0.10021309306224187
I0422 21:02:29.136182 32300 trainer.py:136] Epoch[281/1000] loss: 0.10107746844490369
I0422 21:02:34.889438 32300 trainer.py:136] Epoch[282/1000] loss: 0.10076896101236343
I0422 21:02:40.224492 32300 trainer.py:136] Epoch[283/1000] loss: 0.10156649847825368
I0422 21:02:46.932384 32300 trainer.py:136] Epoch[284/1000] loss: 0.10071067636211713
I0422 21:02:54.005417 32300 trainer.py:136] Epoch[285/1000] loss: 0.10054495433966319
I0422 21:02:59.417328 32300 trainer.py:136] Epoch[286/1000] loss: 0.10067282989621162
I0422 21:03:04.539999 32300 trainer.py:136] Epoch[287/1000] loss: 0.10035362715522449
I0422 21:03:11.592308 32300 trainer.py:136] Epoch[288/1000] loss: 0.10265996679663658
I0422 21:03:18.288425 32300 trainer.py:136] Epoch[289/1000] loss: 0.100880761941274
I0422 21:03:23.461068 32300 trainer.py:136] Epoch[290/1000] loss: 0.09984976922472318
I0422 21:03:31.519248 32300 trainer.py:136] Epoch[291/1000] loss: 0.10046911612153053
I0422 21:03:36.864280 32300 trainer.py:136] Epoch[292/1000] loss: 0.09953420485059421
I0422 21:03:41.607378 32300 trainer.py:136] Epoch[293/1000] loss: 0.09970846648017566
I0422 21:03:49.273501 32300 trainer.py:136] Epoch[294/1000] loss: 0.09949312110741933
I0422 21:03:54.719125 32300 trainer.py:136] Epoch[295/1000] loss: 0.09996023774147034
I0422 21:04:00.041439 32300 trainer.py:136] Epoch[296/1000] loss: 0.10081810131669044
I0422 21:04:08.129888 32300 trainer.py:136] Epoch[297/1000] loss: 0.09949721023440361
I0422 21:04:13.297306 32300 trainer.py:136] Epoch[298/1000] loss: 0.10128877311944962
I0422 21:04:19.775333 32300 trainer.py:136] Epoch[299/1000] loss: 0.09942749266823132
I0422 21:04:22.558441 32300 trainer.py:142] Test: [{'precision': 0.01582810718358038, 'recall': 0.07605485489930465, 'hit_ratio': 0.21736031927023947, 'ndcg': 0.04970677596402608}]
I0422 21:04:27.584893 32300 trainer.py:136] Epoch[300/1000] loss: 0.09961387887597084
I0422 21:04:33.093020 32300 trainer.py:136] Epoch[301/1000] loss: 0.0995921939611435
I0422 21:04:39.705070 32300 trainer.py:136] Epoch[302/1000] loss: 0.09866274148225784
I0422 21:04:45.844957 32300 trainer.py:136] Epoch[303/1000] loss: 0.09963150198260944
I0422 21:04:50.810478 32300 trainer.py:136] Epoch[304/1000] loss: 0.09881308923165004
I0422 21:04:55.905740 32300 trainer.py:136] Epoch[305/1000] loss: 0.09969861805438995
I0422 21:05:03.880400 32300 trainer.py:136] Epoch[306/1000] loss: 0.09952658042311668
I0422 21:05:08.912440 32300 trainer.py:136] Epoch[307/1000] loss: 0.09906411916017532
I0422 21:05:13.782969 32300 trainer.py:136] Epoch[308/1000] loss: 0.09840361028909683
I0422 21:05:19.147776 32300 trainer.py:136] Epoch[309/1000] loss: 0.09968362251917522
I0422 21:05:26.809249 32300 trainer.py:136] Epoch[310/1000] loss: 0.09819574033220609
I0422 21:05:32.134145 32300 trainer.py:136] Epoch[311/1000] loss: 0.09950350597500801
I0422 21:05:38.378845 32300 trainer.py:136] Epoch[312/1000] loss: 0.09925354893008868
I0422 21:05:44.772801 32300 trainer.py:136] Epoch[313/1000] loss: 0.09872206424673398
I0422 21:05:49.838895 32300 trainer.py:136] Epoch[314/1000] loss: 0.09884523351987202
I0422 21:05:54.940357 32300 trainer.py:136] Epoch[315/1000] loss: 0.09806453933318456
I0422 21:06:02.791096 32300 trainer.py:136] Epoch[316/1000] loss: 0.09830121944348018
I0422 21:06:07.710804 32300 trainer.py:136] Epoch[317/1000] loss: 0.09830776477853458
I0422 21:06:12.668556 32300 trainer.py:136] Epoch[318/1000] loss: 0.09784839550654094
I0422 21:06:17.777228 32300 trainer.py:136] Epoch[319/1000] loss: 0.0967340258260568
I0422 21:06:25.277761 32300 trainer.py:136] Epoch[320/1000] loss: 0.09896852200229962
I0422 21:06:30.478972 32300 trainer.py:136] Epoch[321/1000] loss: 0.09736202533046405
I0422 21:06:35.438540 32300 trainer.py:136] Epoch[322/1000] loss: 0.09697296097874641
I0422 21:06:43.425527 32300 trainer.py:136] Epoch[323/1000] loss: 0.09710663184523582
I0422 21:06:48.509417 32300 trainer.py:136] Epoch[324/1000] loss: 0.09821377322077751
I0422 21:06:53.626202 32300 trainer.py:136] Epoch[325/1000] loss: 0.09826296692093213
I0422 21:06:59.042047 32300 trainer.py:136] Epoch[326/1000] loss: 0.09858886400858562
I0422 21:07:06.893976 32300 trainer.py:136] Epoch[327/1000] loss: 0.09759429593880971
I0422 21:07:12.134749 32300 trainer.py:136] Epoch[328/1000] loss: 0.09714574987689654
I0422 21:07:18.899263 32300 trainer.py:136] Epoch[329/1000] loss: 0.09781401976943016
I0422 21:07:25.254094 32300 trainer.py:136] Epoch[330/1000] loss: 0.09707929814855258
I0422 21:07:29.587671 32300 trainer.py:136] Epoch[331/1000] loss: 0.09693897515535355
I0422 21:07:33.991464 32300 trainer.py:136] Epoch[332/1000] loss: 0.09697534640630086
I0422 21:07:38.390149 32300 trainer.py:136] Epoch[333/1000] loss: 0.0971171222627163
I0422 21:07:45.274267 32300 trainer.py:136] Epoch[334/1000] loss: 0.09752010678251584
I0422 21:07:49.389643 32300 trainer.py:136] Epoch[335/1000] loss: 0.09700019905964534
I0422 21:07:53.582095 32300 trainer.py:136] Epoch[336/1000] loss: 0.09796371186772983
I0422 21:07:57.656740 32300 trainer.py:136] Epoch[337/1000] loss: 0.09564453611771266
I0422 21:08:01.792748 32300 trainer.py:136] Epoch[338/1000] loss: 0.09574298933148384
I0422 21:08:05.905246 32300 trainer.py:136] Epoch[339/1000] loss: 0.09665635724862416
I0422 21:08:10.195692 32300 trainer.py:136] Epoch[340/1000] loss: 0.0967296560605367
I0422 21:08:14.280406 32300 trainer.py:136] Epoch[341/1000] loss: 0.09726225957274437
I0422 21:08:20.891205 32300 trainer.py:136] Epoch[342/1000] loss: 0.09610346953074138
I0422 21:08:25.229863 32300 trainer.py:136] Epoch[343/1000] loss: 0.09632827465732892
I0422 21:08:29.618161 32300 trainer.py:136] Epoch[344/1000] loss: 0.09673957154154778
I0422 21:08:34.057311 32300 trainer.py:136] Epoch[345/1000] loss: 0.09594808146357536
I0422 21:08:38.315675 32300 trainer.py:136] Epoch[346/1000] loss: 0.09614500900109609
I0422 21:08:45.137309 32300 trainer.py:136] Epoch[347/1000] loss: 0.09486034388343494
I0422 21:08:49.287286 32300 trainer.py:136] Epoch[348/1000] loss: 0.09517402326067288
I0422 21:08:53.447158 32300 trainer.py:136] Epoch[349/1000] loss: 0.09524049858252208
I0422 21:08:54.906874 32300 trainer.py:142] Test: [{'precision': 0.015949258836944116, 'recall': 0.07607618862946539, 'hit_ratio': 0.2186431014823261, 'ndcg': 0.05012267312048849}]
I0422 21:08:59.067227 32300 trainer.py:136] Epoch[350/1000] loss: 0.09598449617624283
I0422 21:09:03.275301 32300 trainer.py:136] Epoch[351/1000] loss: 0.09508772939443588
I0422 21:09:07.439091 32300 trainer.py:136] Epoch[352/1000] loss: 0.0956349050005277
I0422 21:09:11.724186 32300 trainer.py:136] Epoch[353/1000] loss: 0.09483491877714793
I0422 21:09:18.779186 32300 trainer.py:136] Epoch[354/1000] loss: 0.0953691912194093
I0422 21:09:22.866873 32300 trainer.py:136] Epoch[355/1000] loss: 0.09634681046009064
I0422 21:09:26.936557 32300 trainer.py:136] Epoch[356/1000] loss: 0.09380265946189563
I0422 21:09:31.136955 32300 trainer.py:136] Epoch[357/1000] loss: 0.09611809750398
I0422 21:09:35.363729 32300 trainer.py:136] Epoch[358/1000] loss: 0.09519643833239873
I0422 21:09:39.622397 32300 trainer.py:136] Epoch[359/1000] loss: 0.09458850945035617
I0422 21:09:43.695979 32300 trainer.py:136] Epoch[360/1000] loss: 0.09531329448024432
I0422 21:09:49.512003 32300 trainer.py:136] Epoch[361/1000] loss: 0.09508550415436427
I0422 21:09:54.565789 32300 trainer.py:136] Epoch[362/1000] loss: 0.09528910741209984
I0422 21:09:58.924749 32300 trainer.py:136] Epoch[363/1000] loss: 0.09481304883956909
I0422 21:10:03.005437 32300 trainer.py:136] Epoch[364/1000] loss: 0.09466160585482915
I0422 21:10:07.213306 32300 trainer.py:136] Epoch[365/1000] loss: 0.09446430082122485
I0422 21:10:11.325613 32300 trainer.py:136] Epoch[366/1000] loss: 0.09498848766088486
I0422 21:10:15.612580 32300 trainer.py:136] Epoch[367/1000] loss: 0.09399079655607541
I0422 21:10:23.303888 32300 trainer.py:136] Epoch[368/1000] loss: 0.09544320901234944
I0422 21:10:27.666832 32300 trainer.py:136] Epoch[369/1000] loss: 0.09563163419564565
I0422 21:10:31.931419 32300 trainer.py:136] Epoch[370/1000] loss: 0.0954956163962682
I0422 21:10:36.209983 32300 trainer.py:136] Epoch[371/1000] loss: 0.09447226797540982
I0422 21:10:40.530835 32300 trainer.py:136] Epoch[372/1000] loss: 0.09313254058361053
I0422 21:10:44.795397 32300 trainer.py:136] Epoch[373/1000] loss: 0.09463506812850635
I0422 21:10:48.911926 32300 trainer.py:136] Epoch[374/1000] loss: 0.09484153613448143
I0422 21:10:53.180428 32300 trainer.py:136] Epoch[375/1000] loss: 0.09403591851393382
I0422 21:10:57.352713 32300 trainer.py:136] Epoch[376/1000] loss: 0.09362812712788582
I0422 21:11:04.187675 32300 trainer.py:136] Epoch[377/1000] loss: 0.0939661090572675
I0422 21:11:08.323118 32300 trainer.py:136] Epoch[378/1000] loss: 0.09372948358456294
I0422 21:11:12.582790 32300 trainer.py:136] Epoch[379/1000] loss: 0.09288245687882106
I0422 21:11:16.821856 32300 trainer.py:136] Epoch[380/1000] loss: 0.09433409944176674
I0422 21:11:21.048000 32300 trainer.py:136] Epoch[381/1000] loss: 0.09320109834273656
I0422 21:11:25.154060 32300 trainer.py:136] Epoch[382/1000] loss: 0.09329374010364215
I0422 21:11:29.275522 32300 trainer.py:136] Epoch[383/1000] loss: 0.09262457365791003
I0422 21:11:33.517753 32300 trainer.py:136] Epoch[384/1000] loss: 0.09315943097074826
I0422 21:11:38.743187 32300 trainer.py:136] Epoch[385/1000] loss: 0.09391723449031512
I0422 21:11:44.590660 32300 trainer.py:136] Epoch[386/1000] loss: 0.09351999933520953
I0422 21:11:48.810843 32300 trainer.py:136] Epoch[387/1000] loss: 0.09297635654608409
I0422 21:11:53.115390 32300 trainer.py:136] Epoch[388/1000] loss: 0.09436508019765218
I0422 21:11:57.301645 32300 trainer.py:136] Epoch[389/1000] loss: 0.0926027533908685
I0422 21:12:01.467894 32300 trainer.py:136] Epoch[390/1000] loss: 0.09266149128476779
I0422 21:12:05.562966 32300 trainer.py:136] Epoch[391/1000] loss: 0.09280188009142876
I0422 21:12:09.697428 32300 trainer.py:136] Epoch[392/1000] loss: 0.09347457438707352
I0422 21:12:15.143714 32300 trainer.py:136] Epoch[393/1000] loss: 0.09384719903270404
I0422 21:12:21.454095 32300 trainer.py:136] Epoch[394/1000] loss: 0.0935692625741164
I0422 21:12:25.690356 32300 trainer.py:136] Epoch[395/1000] loss: 0.09223160396019618
I0422 21:12:30.058189 32300 trainer.py:136] Epoch[396/1000] loss: 0.09328653415044148
I0422 21:12:34.065024 32300 trainer.py:136] Epoch[397/1000] loss: 0.0929810032248497
I0422 21:12:38.204971 32300 trainer.py:136] Epoch[398/1000] loss: 0.09449265524744987
I0422 21:12:42.777026 32300 trainer.py:136] Epoch[399/1000] loss: 0.09233686576286952
I0422 21:12:44.630000 32300 trainer.py:142] Test: [{'precision': 0.016106043329532492, 'recall': 0.07698963755769539, 'hit_ratio': 0.22106613454960092, 'ndcg': 0.05053708050535652}]
I0422 21:12:51.062965 32300 trainer.py:136] Epoch[400/1000] loss: 0.09198383241891861
I0422 21:12:55.452901 32300 trainer.py:136] Epoch[401/1000] loss: 0.09218177820245425
I0422 21:12:59.651649 32300 trainer.py:136] Epoch[402/1000] loss: 0.09208449845512708
I0422 21:13:03.904284 32300 trainer.py:136] Epoch[403/1000] loss: 0.09246556336681049
I0422 21:13:08.349310 32300 trainer.py:136] Epoch[404/1000] loss: 0.09307247151931126
I0422 21:13:12.661706 32300 trainer.py:136] Epoch[405/1000] loss: 0.09328307708104451
I0422 21:13:19.657899 32300 trainer.py:136] Epoch[406/1000] loss: 0.09218614300092061
I0422 21:13:23.669345 32300 trainer.py:136] Epoch[407/1000] loss: 0.0933678609629472
I0422 21:13:27.934362 32300 trainer.py:136] Epoch[408/1000] loss: 0.09171488136053085
I0422 21:13:32.130720 32300 trainer.py:136] Epoch[409/1000] loss: 0.09282129009564717
I0422 21:13:36.722277 32300 trainer.py:136] Epoch[410/1000] loss: 0.09269704297184944
I0422 21:13:45.126591 32300 trainer.py:136] Epoch[411/1000] loss: 0.09194479137659073
I0422 21:13:50.479107 32300 trainer.py:136] Epoch[412/1000] loss: 0.09268080318967502
I0422 21:13:55.570074 32300 trainer.py:136] Epoch[413/1000] loss: 0.09178953990340233
I0422 21:14:00.896191 32300 trainer.py:136] Epoch[414/1000] loss: 0.09167831018567085
I0422 21:14:08.804355 32300 trainer.py:136] Epoch[415/1000] loss: 0.09111882497866948
I0422 21:14:14.229605 32300 trainer.py:136] Epoch[416/1000] loss: 0.09209991494814555
I0422 21:14:19.356336 32300 trainer.py:136] Epoch[417/1000] loss: 0.0927005981405576
I0422 21:14:24.504197 32300 trainer.py:136] Epoch[418/1000] loss: 0.09100378801425298
I0422 21:14:32.087874 32300 trainer.py:136] Epoch[419/1000] loss: 0.09253926202654839
I0422 21:14:37.283402 32300 trainer.py:136] Epoch[420/1000] loss: 0.09350715577602386
I0422 21:14:42.719650 32300 trainer.py:136] Epoch[421/1000] loss: 0.0930009422202905
I0422 21:14:50.560533 32300 trainer.py:136] Epoch[422/1000] loss: 0.09251931558052699
I0422 21:14:55.625036 32300 trainer.py:136] Epoch[423/1000] loss: 0.0921522503097852
I0422 21:15:00.539495 32300 trainer.py:136] Epoch[424/1000] loss: 0.09264262641469638
I0422 21:15:05.648206 32300 trainer.py:136] Epoch[425/1000] loss: 0.09192211801807086
I0422 21:15:13.573436 32300 trainer.py:136] Epoch[426/1000] loss: 0.0911493959526221
I0422 21:15:18.646802 32300 trainer.py:136] Epoch[427/1000] loss: 0.0915000115831693
I0422 21:15:23.641127 32300 trainer.py:136] Epoch[428/1000] loss: 0.09145129596193631
I0422 21:15:28.690081 32300 trainer.py:136] Epoch[429/1000] loss: 0.090581680337588
I0422 21:15:36.678164 32300 trainer.py:136] Epoch[430/1000] loss: 0.09060725818077724
I0422 21:15:42.025518 32300 trainer.py:136] Epoch[431/1000] loss: 0.09156194205085437
I0422 21:15:47.200656 32300 trainer.py:136] Epoch[432/1000] loss: 0.09087067345778148
I0422 21:15:54.690909 32300 trainer.py:136] Epoch[433/1000] loss: 0.09096488480766614
I0422 21:16:00.888628 32300 trainer.py:136] Epoch[434/1000] loss: 0.09182608500123024
I0422 21:16:05.990634 32300 trainer.py:136] Epoch[435/1000] loss: 0.09249093507726987
I0422 21:16:12.463735 32300 trainer.py:136] Epoch[436/1000] loss: 0.09135494257013003
I0422 21:16:18.896843 32300 trainer.py:136] Epoch[437/1000] loss: 0.09077256917953491
I0422 21:16:24.044420 32300 trainer.py:136] Epoch[438/1000] loss: 0.09146208812793095
I0422 21:16:29.097381 32300 trainer.py:136] Epoch[439/1000] loss: 0.09171024213234584
I0422 21:16:35.544825 32300 trainer.py:136] Epoch[440/1000] loss: 0.09149825076262157
I0422 21:16:42.323534 32300 trainer.py:136] Epoch[441/1000] loss: 0.0908341109752655
I0422 21:16:47.539143 32300 trainer.py:136] Epoch[442/1000] loss: 0.0901755119363467
I0422 21:16:52.683700 32300 trainer.py:136] Epoch[443/1000] loss: 0.09017923722664516
I0422 21:16:57.798518 32300 trainer.py:136] Epoch[444/1000] loss: 0.09053802117705345
I0422 21:17:05.985760 32300 trainer.py:136] Epoch[445/1000] loss: 0.09011601284146309
I0422 21:17:11.305378 32300 trainer.py:136] Epoch[446/1000] loss: 0.09051133568088214
I0422 21:17:16.856348 32300 trainer.py:136] Epoch[447/1000] loss: 0.09093306586146355
I0422 21:17:24.394860 32300 trainer.py:136] Epoch[448/1000] loss: 0.09029091894626617
I0422 21:17:29.511886 32300 trainer.py:136] Epoch[449/1000] loss: 0.08919356018304825
I0422 21:17:31.783444 32300 trainer.py:142] Test: [{'precision': 0.01611316989737742, 'recall': 0.07737422251186078, 'hit_ratio': 0.221636259977195, 'ndcg': 0.05085226974692573}]
I0422 21:17:38.653384 32300 trainer.py:136] Epoch[450/1000] loss: 0.08901734898487727
I0422 21:17:45.888427 32300 trainer.py:136] Epoch[451/1000] loss: 0.09158998106916745
I0422 21:17:51.080159 32300 trainer.py:136] Epoch[452/1000] loss: 0.09084886809190114
I0422 21:17:58.840293 32300 trainer.py:136] Epoch[453/1000] loss: 0.08944334462285042
I0422 21:18:03.822032 32300 trainer.py:136] Epoch[454/1000] loss: 0.08953121801217397
I0422 21:18:08.956676 32300 trainer.py:136] Epoch[455/1000] loss: 0.08966647957762082
I0422 21:18:13.949798 32300 trainer.py:136] Epoch[456/1000] loss: 0.08984582001964252
I0422 21:18:21.559009 32300 trainer.py:136] Epoch[457/1000] loss: 0.08867152407765388
I0422 21:18:26.653800 32300 trainer.py:136] Epoch[458/1000] loss: 0.09057065472006798
I0422 21:18:31.723253 32300 trainer.py:136] Epoch[459/1000] loss: 0.09009494384129842
I0422 21:18:36.905573 32300 trainer.py:136] Epoch[460/1000] loss: 0.09113167598843575
I0422 21:18:44.639298 32300 trainer.py:136] Epoch[461/1000] loss: 0.08949946487943332
I0422 21:18:50.557774 32300 trainer.py:136] Epoch[462/1000] loss: 0.09013656650980313
I0422 21:18:56.690689 32300 trainer.py:136] Epoch[463/1000] loss: 0.09007654835780461
I0422 21:19:03.767495 32300 trainer.py:136] Epoch[464/1000] loss: 0.08932170396049817
I0422 21:19:08.976362 32300 trainer.py:136] Epoch[465/1000] loss: 0.08850208049019177
I0422 21:19:14.063318 32300 trainer.py:136] Epoch[466/1000] loss: 0.08912036816279094
I0422 21:19:22.380380 32300 trainer.py:136] Epoch[467/1000] loss: 0.09126873686909676
I0422 21:19:27.830066 32300 trainer.py:136] Epoch[468/1000] loss: 0.08971382056673367
I0422 21:19:33.152143 32300 trainer.py:136] Epoch[469/1000] loss: 0.08961885919173558
I0422 21:19:41.226152 32300 trainer.py:136] Epoch[470/1000] loss: 0.09015939012169838
I0422 21:19:46.337895 32300 trainer.py:136] Epoch[471/1000] loss: 0.09045428410172462
I0422 21:19:51.672760 32300 trainer.py:136] Epoch[472/1000] loss: 0.08983700722455978
I0422 21:19:57.869942 32300 trainer.py:136] Epoch[473/1000] loss: 0.08931792030731837
I0422 21:20:05.203358 32300 trainer.py:136] Epoch[474/1000] loss: 0.08890880520145099
I0422 21:20:10.728860 32300 trainer.py:136] Epoch[475/1000] loss: 0.0908493809401989
I0422 21:20:16.975545 32300 trainer.py:136] Epoch[476/1000] loss: 0.09047514572739601
I0422 21:20:23.662791 32300 trainer.py:136] Epoch[477/1000] loss: 0.09142140919963519
I0422 21:20:28.582167 32300 trainer.py:136] Epoch[478/1000] loss: 0.08962225914001465
I0422 21:20:33.636208 32300 trainer.py:136] Epoch[479/1000] loss: 0.08898543566465378
I0422 21:20:40.606054 32300 trainer.py:136] Epoch[480/1000] loss: 0.09054532647132874
I0422 21:20:46.272593 32300 trainer.py:136] Epoch[481/1000] loss: 0.08968186130126317
I0422 21:20:51.457609 32300 trainer.py:136] Epoch[482/1000] loss: 0.090614868948857
I0422 21:20:56.711767 32300 trainer.py:136] Epoch[483/1000] loss: 0.08988326787948608
I0422 21:21:04.272376 32300 trainer.py:136] Epoch[484/1000] loss: 0.0899898111820221
I0422 21:21:09.149908 32300 trainer.py:136] Epoch[485/1000] loss: 0.08925067509214084
I0422 21:21:14.308343 32300 trainer.py:136] Epoch[486/1000] loss: 0.088841928790013
I0422 21:21:22.303845 32300 trainer.py:136] Epoch[487/1000] loss: 0.08810063824057579
I0422 21:21:27.687234 32300 trainer.py:136] Epoch[488/1000] loss: 0.0888407329718272
I0422 21:21:32.697335 32300 trainer.py:136] Epoch[489/1000] loss: 0.08908629789948463
I0422 21:21:39.547241 32300 trainer.py:136] Epoch[490/1000] loss: 0.08917046338319778
I0422 21:21:45.637601 32300 trainer.py:136] Epoch[491/1000] loss: 0.0895256685713927
I0422 21:21:50.857010 32300 trainer.py:136] Epoch[492/1000] loss: 0.08968788509567578
I0422 21:21:55.950874 32300 trainer.py:136] Epoch[493/1000] loss: 0.08927708243330319
I0422 21:22:03.832719 32300 trainer.py:136] Epoch[494/1000] loss: 0.08899946014086406
I0422 21:22:09.072140 32300 trainer.py:136] Epoch[495/1000] loss: 0.08841065193216006
I0422 21:22:14.031314 32300 trainer.py:136] Epoch[496/1000] loss: 0.08937462046742439
I0422 21:22:21.483810 32300 trainer.py:136] Epoch[497/1000] loss: 0.08870705217123032
I0422 21:22:27.081815 32300 trainer.py:136] Epoch[498/1000] loss: 0.09001340717077255
I0422 21:22:31.658676 32300 trainer.py:136] Epoch[499/1000] loss: 0.08837632959087689
I0422 21:22:33.103430 32300 trainer.py:142] Test: [{'precision': 0.016234321550741157, 'recall': 0.0784895098938612, 'hit_ratio': 0.2243443557582668, 'ndcg': 0.051351301507758906}]
I0422 21:22:37.598789 32300 trainer.py:136] Epoch[500/1000] loss: 0.0887134683628877
I0422 21:22:44.507908 32300 trainer.py:136] Epoch[501/1000] loss: 0.08761411781112353
I0422 21:22:48.703193 32300 trainer.py:136] Epoch[502/1000] loss: 0.08769925932089488
I0422 21:22:53.336884 32300 trainer.py:136] Epoch[503/1000] loss: 0.08912894626458485
I0422 21:22:58.778673 32300 trainer.py:136] Epoch[504/1000] loss: 0.0891187662879626
I0422 21:23:06.666061 32300 trainer.py:136] Epoch[505/1000] loss: 0.0897033375998338
I0422 21:23:11.869511 32300 trainer.py:136] Epoch[506/1000] loss: 0.08896550784508388
I0422 21:23:16.859646 32300 trainer.py:136] Epoch[507/1000] loss: 0.0888034316400687
I0422 21:23:24.929704 32300 trainer.py:136] Epoch[508/1000] loss: 0.08957988644639651
I0422 21:23:29.924767 32300 trainer.py:136] Epoch[509/1000] loss: 0.08881715188423793
I0422 21:23:36.046009 32300 trainer.py:136] Epoch[510/1000] loss: 0.08800181249777476
I0422 21:23:42.896508 32300 trainer.py:136] Epoch[511/1000] loss: 0.08813788741827011
I0422 21:23:48.040332 32300 trainer.py:136] Epoch[512/1000] loss: 0.08996831501523654
I0422 21:23:55.942361 32300 trainer.py:136] Epoch[513/1000] loss: 0.08923794950048129
I0422 21:24:01.282385 32300 trainer.py:136] Epoch[514/1000] loss: 0.08908172945181529
I0422 21:24:06.424990 32300 trainer.py:136] Epoch[515/1000] loss: 0.08921479806303978
I0422 21:24:12.994085 32300 trainer.py:136] Epoch[516/1000] loss: 0.0882289819419384
I0422 21:24:19.480476 32300 trainer.py:136] Epoch[517/1000] loss: 0.08706395576397578
I0422 21:24:24.465552 32300 trainer.py:136] Epoch[518/1000] loss: 0.08768073221047719
I0422 21:24:30.844942 32300 trainer.py:136] Epoch[519/1000] loss: 0.08889250581463178
I0422 21:24:37.631832 32300 trainer.py:136] Epoch[520/1000] loss: 0.0880788154900074
I0422 21:24:42.706837 32300 trainer.py:136] Epoch[521/1000] loss: 0.0884437623123328
I0422 21:24:48.370310 32300 trainer.py:136] Epoch[522/1000] loss: 0.08726817617813747
I0422 21:24:55.929498 32300 trainer.py:136] Epoch[523/1000] loss: 0.08719554046789806
I0422 21:25:00.910986 32300 trainer.py:136] Epoch[524/1000] loss: 0.08808727810780208
I0422 21:25:06.299997 32300 trainer.py:136] Epoch[525/1000] loss: 0.08823401232560475
I0422 21:25:14.241061 32300 trainer.py:136] Epoch[526/1000] loss: 0.08849537745118141
I0422 21:25:19.587558 32300 trainer.py:136] Epoch[527/1000] loss: 0.08849418039123218
I0422 21:25:26.493957 32300 trainer.py:136] Epoch[528/1000] loss: 0.08797250067194302
I0422 21:25:33.035132 32300 trainer.py:136] Epoch[529/1000] loss: 0.08975266416867574
I0422 21:25:37.947849 32300 trainer.py:136] Epoch[530/1000] loss: 0.08733022212982178
I0422 21:25:45.590483 32300 trainer.py:136] Epoch[531/1000] loss: 0.0882741150756677
I0422 21:25:50.523587 32300 trainer.py:136] Epoch[532/1000] loss: 0.08765401318669319
I0422 21:25:55.521921 32300 trainer.py:136] Epoch[533/1000] loss: 0.08839737623929977
I0422 21:26:00.303805 32300 trainer.py:136] Epoch[534/1000] loss: 0.08817573015888532
I0422 21:26:07.983011 32300 trainer.py:136] Epoch[535/1000] loss: 0.08844596271713574
I0422 21:26:13.077967 32300 trainer.py:136] Epoch[536/1000] loss: 0.08844487989942233
I0422 21:26:18.012655 32300 trainer.py:136] Epoch[537/1000] loss: 0.08876520891984303
I0422 21:26:22.967913 32300 trainer.py:136] Epoch[538/1000] loss: 0.08852686608831088
I0422 21:26:30.756940 32300 trainer.py:136] Epoch[539/1000] loss: 0.08838087692856789
I0422 21:26:35.615641 32300 trainer.py:136] Epoch[540/1000] loss: 0.0885316642622153
I0422 21:26:40.253166 32300 trainer.py:136] Epoch[541/1000] loss: 0.08901154125730197
I0422 21:26:44.252398 32300 trainer.py:136] Epoch[542/1000] loss: 0.08733345071474712
I0422 21:26:48.256264 32300 trainer.py:136] Epoch[543/1000] loss: 0.08784318963686626
I0422 21:26:52.374786 32300 trainer.py:136] Epoch[544/1000] loss: 0.08715776602427165
I0422 21:26:56.380748 32300 trainer.py:136] Epoch[545/1000] loss: 0.08822233478228252
I0422 21:27:00.376790 32300 trainer.py:136] Epoch[546/1000] loss: 0.08745625242590904
I0422 21:27:06.740176 32300 trainer.py:136] Epoch[547/1000] loss: 0.0874670073390007
I0422 21:27:10.848222 32300 trainer.py:136] Epoch[548/1000] loss: 0.08780862639347713
I0422 21:27:14.890014 32300 trainer.py:136] Epoch[549/1000] loss: 0.08816263203819592
I0422 21:27:16.322336 32300 trainer.py:142] Test: [{'precision': 0.016248574686431014, 'recall': 0.07826699097879003, 'hit_ratio': 0.22363169897377422, 'ndcg': 0.05132443500331572}]
I0422 21:27:20.487714 32300 trainer.py:136] Epoch[550/1000] loss: 0.08714112515250842
I0422 21:27:24.634230 32300 trainer.py:136] Epoch[551/1000] loss: 0.08800447483857472
I0422 21:27:28.791122 32300 trainer.py:136] Epoch[552/1000] loss: 0.08636808519562085
I0422 21:27:32.992921 32300 trainer.py:136] Epoch[553/1000] loss: 0.0881417915225029
I0422 21:27:37.209245 32300 trainer.py:136] Epoch[554/1000] loss: 0.08869753281275432
I0422 21:27:41.331702 32300 trainer.py:136] Epoch[555/1000] loss: 0.08673990642031033
I0422 21:27:45.434227 32300 trainer.py:136] Epoch[556/1000] loss: 0.08702816565831502
I0422 21:27:49.499887 32300 trainer.py:136] Epoch[557/1000] loss: 0.08727960164348285
I0422 21:27:53.616723 32300 trainer.py:136] Epoch[558/1000] loss: 0.08768277739485104
I0422 21:27:57.656626 32300 trainer.py:136] Epoch[559/1000] loss: 0.08726435899734497
I0422 21:28:02.550433 32300 trainer.py:136] Epoch[560/1000] loss: 0.08589832112193108
I0422 21:28:08.681557 32300 trainer.py:136] Epoch[561/1000] loss: 0.08719663073619206
I0422 21:28:12.860858 32300 trainer.py:136] Epoch[562/1000] loss: 0.08675424009561539
I0422 21:28:17.109059 32300 trainer.py:136] Epoch[563/1000] loss: 0.0867137076954047
I0422 21:28:21.742737 32300 trainer.py:136] Epoch[564/1000] loss: 0.08735526725649834
I0422 21:28:29.747916 32300 trainer.py:136] Epoch[565/1000] loss: 0.08560990045468013
I0422 21:28:34.964259 32300 trainer.py:136] Epoch[566/1000] loss: 0.08638548354307811
I0422 21:28:40.048267 32300 trainer.py:136] Epoch[567/1000] loss: 0.08658173307776451
I0422 21:28:45.429782 32300 trainer.py:136] Epoch[568/1000] loss: 0.08720071737964948
I0422 21:28:52.880604 32300 trainer.py:136] Epoch[569/1000] loss: 0.08766078824798267
I0422 21:28:58.020395 32300 trainer.py:136] Epoch[570/1000] loss: 0.08659571160872777
I0422 21:29:03.430721 32300 trainer.py:136] Epoch[571/1000] loss: 0.08692166830102603
I0422 21:29:11.427241 32300 trainer.py:136] Epoch[572/1000] loss: 0.0872575727601846
I0422 21:29:16.468337 32300 trainer.py:136] Epoch[573/1000] loss: 0.0886392630636692
I0422 21:29:22.676113 32300 trainer.py:136] Epoch[574/1000] loss: 0.08622803042332332
I0422 21:29:30.033447 32300 trainer.py:136] Epoch[575/1000] loss: 0.08687272295355797
I0422 21:29:35.041398 32300 trainer.py:136] Epoch[576/1000] loss: 0.08690231790145238
I0422 21:29:40.656773 32300 trainer.py:136] Epoch[577/1000] loss: 0.08624012395739555
I0422 21:29:48.060901 32300 trainer.py:136] Epoch[578/1000] loss: 0.08685989553729694
I0422 21:29:53.263347 32300 trainer.py:136] Epoch[579/1000] loss: 0.0873301091293494
I0422 21:29:58.792577 32300 trainer.py:136] Epoch[580/1000] loss: 0.08663959180315335
I0422 21:30:06.588052 32300 trainer.py:136] Epoch[581/1000] loss: 0.08646005267898242
I0422 21:30:11.644944 32300 trainer.py:136] Epoch[582/1000] loss: 0.08758901928861935
I0422 21:30:17.673249 32300 trainer.py:136] Epoch[583/1000] loss: 0.08700696378946304
I0422 21:30:24.380476 32300 trainer.py:136] Epoch[584/1000] loss: 0.08593522136410077
I0422 21:30:28.472257 32300 trainer.py:136] Epoch[585/1000] loss: 0.08555843060215314
I0422 21:30:32.554558 32300 trainer.py:136] Epoch[586/1000] loss: 0.08784482255578041
I0422 21:30:36.601364 32300 trainer.py:136] Epoch[587/1000] loss: 0.08649273713429768
I0422 21:30:41.014931 32300 trainer.py:136] Epoch[588/1000] loss: 0.08593754718701045
I0422 21:30:46.203445 32300 trainer.py:136] Epoch[589/1000] loss: 0.08695612475275993
I0422 21:30:52.392103 32300 trainer.py:136] Epoch[590/1000] loss: 0.08674007281661034
I0422 21:30:56.730765 32300 trainer.py:136] Epoch[591/1000] loss: 0.08620059862732887
I0422 21:31:01.041796 32300 trainer.py:136] Epoch[592/1000] loss: 0.08589566126465797
I0422 21:31:05.238159 32300 trainer.py:136] Epoch[593/1000] loss: 0.08670223007599513
I0422 21:31:09.503172 32300 trainer.py:136] Epoch[594/1000] loss: 0.08684089531501134
I0422 21:31:15.313637 32300 trainer.py:136] Epoch[595/1000] loss: 0.08597897614041965
I0422 21:31:20.953417 32300 trainer.py:136] Epoch[596/1000] loss: 0.08606235807140668
I0422 21:31:25.429759 32300 trainer.py:136] Epoch[597/1000] loss: 0.08592356865604718
I0422 21:31:29.798508 32300 trainer.py:136] Epoch[598/1000] loss: 0.08673677345116933
I0422 21:31:34.608304 32300 trainer.py:136] Epoch[599/1000] loss: 0.08646979307134946
I0422 21:31:37.076204 32300 trainer.py:142] Test: [{'precision': 0.01639110604332953, 'recall': 0.07898636196559056, 'hit_ratio': 0.22562713797035347, 'ndcg': 0.05157089922916312}]
I0422 21:31:44.452408 32300 trainer.py:136] Epoch[600/1000] loss: 0.08689094831546147
I0422 21:31:49.618938 32300 trainer.py:136] Epoch[601/1000] loss: 0.08705248683691025
I0422 21:31:56.363498 32300 trainer.py:136] Epoch[602/1000] loss: 0.08501854663093884
I0422 21:32:02.893291 32300 trainer.py:136] Epoch[603/1000] loss: 0.08630205318331718
I0422 21:32:08.106958 32300 trainer.py:136] Epoch[604/1000] loss: 0.08587879687547684
I0422 21:32:15.111678 32300 trainer.py:136] Epoch[605/1000] loss: 0.08658881609638532
I0422 21:32:21.294755 32300 trainer.py:136] Epoch[606/1000] loss: 0.08612776299317677
I0422 21:32:26.328084 32300 trainer.py:136] Epoch[607/1000] loss: 0.08485579614837964
I0422 21:32:34.496979 32300 trainer.py:136] Epoch[608/1000] loss: 0.08658595258990924
I0422 21:32:39.614292 32300 trainer.py:136] Epoch[609/1000] loss: 0.08589258665839831
I0422 21:32:44.765980 32300 trainer.py:136] Epoch[610/1000] loss: 0.08567563941081364
I0422 21:32:52.679257 32300 trainer.py:136] Epoch[611/1000] loss: 0.08594278742869695
I0422 21:32:57.227897 32300 trainer.py:136] Epoch[612/1000] loss: 0.08675027266144753
I0422 21:33:01.333467 32300 trainer.py:136] Epoch[613/1000] loss: 0.08594643572966258
I0422 21:33:05.721697 32300 trainer.py:136] Epoch[614/1000] loss: 0.08576355750362079
I0422 21:33:12.538056 32300 trainer.py:136] Epoch[615/1000] loss: 0.08671010658144951
I0422 21:33:16.933769 32300 trainer.py:136] Epoch[616/1000] loss: 0.08630271628499031
I0422 21:33:21.377589 32300 trainer.py:136] Epoch[617/1000] loss: 0.0854674552877744
I0422 21:33:25.493209 32300 trainer.py:136] Epoch[618/1000] loss: 0.08783960714936256
I0422 21:33:29.692255 32300 trainer.py:136] Epoch[619/1000] loss: 0.08616870145003001
I0422 21:33:33.970228 32300 trainer.py:136] Epoch[620/1000] loss: 0.08673817167679469
I0422 21:33:41.416036 32300 trainer.py:136] Epoch[621/1000] loss: 0.0857729824880759
I0422 21:33:46.710112 32300 trainer.py:136] Epoch[622/1000] loss: 0.0858678010602792
I0422 21:33:51.901638 32300 trainer.py:136] Epoch[623/1000] loss: 0.0859619788825512
I0422 21:34:00.317818 32300 trainer.py:136] Epoch[624/1000] loss: 0.08691322927673657
I0422 21:34:05.676745 32300 trainer.py:136] Epoch[625/1000] loss: 0.08538315817713737
I0422 21:34:10.928715 32300 trainer.py:136] Epoch[626/1000] loss: 0.08632983391483624
I0422 21:34:19.003780 32300 trainer.py:136] Epoch[627/1000] loss: 0.0858487697939078
I0422 21:34:24.084674 32300 trainer.py:136] Epoch[628/1000] loss: 0.08694528291622798
I0422 21:34:32.135048 32300 trainer.py:136] Epoch[629/1000] loss: 0.08626338963707288
I0422 21:34:37.806024 32300 trainer.py:136] Epoch[630/1000] loss: 0.08596655229727428
I0422 21:34:43.028109 32300 trainer.py:136] Epoch[631/1000] loss: 0.08615765223900478
I0422 21:34:50.994754 32300 trainer.py:136] Epoch[632/1000] loss: 0.08621445546547572
I0422 21:34:55.343033 32300 trainer.py:136] Epoch[633/1000] loss: 0.08631048972407977
I0422 21:34:59.457911 32300 trainer.py:136] Epoch[634/1000] loss: 0.08591866493225098
I0422 21:35:03.553211 32300 trainer.py:136] Epoch[635/1000] loss: 0.08583594610293706
I0422 21:35:07.638424 32300 trainer.py:136] Epoch[636/1000] loss: 0.08505988617738088
I0422 21:35:12.758008 32300 trainer.py:136] Epoch[637/1000] loss: 0.08531022320191066
I0422 21:35:18.558201 32300 trainer.py:136] Epoch[638/1000] loss: 0.08468255276481311
I0422 21:35:22.717153 32300 trainer.py:136] Epoch[639/1000] loss: 0.08594571799039841
I0422 21:35:26.802841 32300 trainer.py:136] Epoch[640/1000] loss: 0.0856522706647714
I0422 21:35:30.899907 32300 trainer.py:136] Epoch[641/1000] loss: 0.08593540638685226
I0422 21:35:34.954636 32300 trainer.py:136] Epoch[642/1000] loss: 0.08511961996555328
I0422 21:35:39.137755 32300 trainer.py:136] Epoch[643/1000] loss: 0.08588770652810733
I0422 21:35:43.243788 32300 trainer.py:136] Epoch[644/1000] loss: 0.08614551027615865
I0422 21:35:49.865823 32300 trainer.py:136] Epoch[645/1000] loss: 0.08586042746901512
I0422 21:35:54.091879 32300 trainer.py:136] Epoch[646/1000] loss: 0.08515958487987518
I0422 21:35:58.269731 32300 trainer.py:136] Epoch[647/1000] loss: 0.08512127275268237
I0422 21:36:02.458077 32300 trainer.py:136] Epoch[648/1000] loss: 0.08543271695574124
I0422 21:36:06.750976 32300 trainer.py:136] Epoch[649/1000] loss: 0.0857655977209409
I0422 21:36:08.250056 32300 trainer.py:142] Test: [{'precision': 0.0163839794754846, 'recall': 0.07962897202469961, 'hit_ratio': 0.22534207525655645, 'ndcg': 0.05168757544161711}]
I0422 21:36:13.232285 32300 trainer.py:136] Epoch[650/1000] loss: 0.08555521195133527
I0422 21:36:19.371873 32300 trainer.py:136] Epoch[651/1000] loss: 0.08563572292526563
I0422 21:36:23.578500 32300 trainer.py:136] Epoch[652/1000] loss: 0.08506090939044952
I0422 21:36:27.755934 32300 trainer.py:136] Epoch[653/1000] loss: 0.08507450545827548
I0422 21:36:32.119824 32300 trainer.py:136] Epoch[654/1000] loss: 0.08482733493049939
I0422 21:36:36.371919 32300 trainer.py:136] Epoch[655/1000] loss: 0.08571407819787662
I0422 21:36:41.635252 32300 trainer.py:136] Epoch[656/1000] loss: 0.0857178916533788
I0422 21:36:47.604934 32300 trainer.py:136] Epoch[657/1000] loss: 0.08521364629268646
I0422 21:36:51.605579 32300 trainer.py:136] Epoch[658/1000] loss: 0.08582847813765208
I0422 21:36:55.806824 32300 trainer.py:136] Epoch[659/1000] loss: 0.0845882607003053
I0422 21:36:59.887670 32300 trainer.py:136] Epoch[660/1000] loss: 0.08571422100067139
I0422 21:37:04.002999 32300 trainer.py:136] Epoch[661/1000] loss: 0.08466348052024841
I0422 21:37:08.207248 32300 trainer.py:136] Epoch[662/1000] loss: 0.08480546995997429
I0422 21:37:12.372728 32300 trainer.py:136] Epoch[663/1000] loss: 0.08454659208655357
I0422 21:37:16.459250 32300 trainer.py:136] Epoch[664/1000] loss: 0.08567475651701291
I0422 21:37:20.636670 32300 trainer.py:136] Epoch[665/1000] loss: 0.0855678344766299
I0422 21:37:24.738652 32300 trainer.py:136] Epoch[666/1000] loss: 0.08510172739624977
I0422 21:37:31.328348 32300 trainer.py:136] Epoch[667/1000] loss: 0.08427225301663081
I0422 21:37:35.434905 32300 trainer.py:136] Epoch[668/1000] loss: 0.08568911378582318
I0422 21:37:39.541293 32300 trainer.py:136] Epoch[669/1000] loss: 0.08527440577745438
I0422 21:37:43.568084 32300 trainer.py:136] Epoch[670/1000] loss: 0.0847347117960453
I0422 21:37:47.629754 32300 trainer.py:136] Epoch[671/1000] loss: 0.08613870789607365
I0422 21:37:51.652568 32300 trainer.py:136] Epoch[672/1000] loss: 0.08569759751359622
I0422 21:37:56.021177 32300 trainer.py:136] Epoch[673/1000] loss: 0.08474574983119965
I0422 21:38:00.264794 32300 trainer.py:136] Epoch[674/1000] loss: 0.08454490080475807
I0422 21:38:07.328383 32300 trainer.py:136] Epoch[675/1000] loss: 0.08516316736737888
I0422 21:38:11.597401 32300 trainer.py:136] Epoch[676/1000] loss: 0.08549064273635547
I0422 21:38:16.100660 32300 trainer.py:136] Epoch[677/1000] loss: 0.08497650797168414
I0422 21:38:20.370503 32300 trainer.py:136] Epoch[678/1000] loss: 0.08485117927193642
I0422 21:38:24.702280 32300 trainer.py:136] Epoch[679/1000] loss: 0.08520867923895518
I0422 21:38:28.903467 32300 trainer.py:136] Epoch[680/1000] loss: 0.0850294679403305
I0422 21:38:35.741277 32300 trainer.py:136] Epoch[681/1000] loss: 0.08410841847459476
I0422 21:38:39.900659 32300 trainer.py:136] Epoch[682/1000] loss: 0.08375936249891917
I0422 21:38:43.905280 32300 trainer.py:136] Epoch[683/1000] loss: 0.08490401630600293
I0422 21:38:48.045212 32300 trainer.py:136] Epoch[684/1000] loss: 0.08608014757434528
I0422 21:38:52.138933 32300 trainer.py:136] Epoch[685/1000] loss: 0.08514444033304851
I0422 21:38:56.181149 32300 trainer.py:136] Epoch[686/1000] loss: 0.084842083354791
I0422 21:39:00.468374 32300 trainer.py:136] Epoch[687/1000] loss: 0.08526221786936124
I0422 21:39:04.571702 32300 trainer.py:136] Epoch[688/1000] loss: 0.08527509247263272
I0422 21:39:08.706471 32300 trainer.py:136] Epoch[689/1000] loss: 0.08522350092728932
I0422 21:39:12.822177 32300 trainer.py:136] Epoch[690/1000] loss: 0.08607322598497073
I0422 21:39:16.978114 32300 trainer.py:136] Epoch[691/1000] loss: 0.08533607547481854
I0422 21:39:20.986374 32300 trainer.py:136] Epoch[692/1000] loss: 0.08520890275637309
I0422 21:39:25.116370 32300 trainer.py:136] Epoch[693/1000] loss: 0.0855449599524339
I0422 21:39:31.675023 32300 trainer.py:136] Epoch[694/1000] loss: 0.0850244089961052
I0422 21:39:35.830017 32300 trainer.py:136] Epoch[695/1000] loss: 0.08490800360838573
I0422 21:39:40.016319 32300 trainer.py:136] Epoch[696/1000] loss: 0.08480174963672955
I0422 21:39:44.162314 32300 trainer.py:136] Epoch[697/1000] loss: 0.08506453409790993
I0422 21:39:48.292052 32300 trainer.py:136] Epoch[698/1000] loss: 0.08525147040685017
I0422 21:39:52.483271 32300 trainer.py:136] Epoch[699/1000] loss: 0.085682629297177
I0422 21:39:53.891139 32300 trainer.py:142] Test: [{'precision': 0.01645524515393386, 'recall': 0.0798989124603318, 'hit_ratio': 0.22591220068415052, 'ndcg': 0.052041154236244044}]
I0422 21:39:57.888001 32300 trainer.py:136] Epoch[700/1000] loss: 0.08566614737113316
I0422 21:40:01.918266 32300 trainer.py:136] Epoch[701/1000] loss: 0.08597770209113757
I0422 21:40:06.094128 32300 trainer.py:136] Epoch[702/1000] loss: 0.08587028707067172
I0422 21:40:10.238161 32300 trainer.py:136] Epoch[703/1000] loss: 0.08429330339034398
I0422 21:40:14.335290 32300 trainer.py:136] Epoch[704/1000] loss: 0.0850093017021815
I0422 21:40:20.937945 32300 trainer.py:136] Epoch[705/1000] loss: 0.08426624660690625
I0422 21:40:25.013116 32300 trainer.py:136] Epoch[706/1000] loss: 0.08456935236851375
I0422 21:40:29.264773 32300 trainer.py:136] Epoch[707/1000] loss: 0.08636792004108429
I0422 21:40:33.351642 32300 trainer.py:136] Epoch[708/1000] loss: 0.08455510685841243
I0422 21:40:37.504145 32300 trainer.py:136] Epoch[709/1000] loss: 0.08420442044734955
I0422 21:40:41.694453 32300 trainer.py:136] Epoch[710/1000] loss: 0.08534604186813037
I0422 21:40:45.953048 32300 trainer.py:136] Epoch[711/1000] loss: 0.08517863477269809
I0422 21:40:50.114928 32300 trainer.py:136] Epoch[712/1000] loss: 0.08339814345041911
I0422 21:40:54.253942 32300 trainer.py:136] Epoch[713/1000] loss: 0.08447795609633128
I0422 21:40:58.408930 32300 trainer.py:136] Epoch[714/1000] loss: 0.08615986506144206
I0422 21:41:02.531128 32300 trainer.py:136] Epoch[715/1000] loss: 0.08409045015772183
I0422 21:41:06.660184 32300 trainer.py:136] Epoch[716/1000] loss: 0.08361751213669777
I0422 21:41:10.919133 32300 trainer.py:136] Epoch[717/1000] loss: 0.08449158072471619
I0422 21:41:17.617044 32300 trainer.py:136] Epoch[718/1000] loss: 0.08453529452284177
I0422 21:41:21.619954 32300 trainer.py:136] Epoch[719/1000] loss: 0.0843583916624387
I0422 21:41:25.686713 32300 trainer.py:136] Epoch[720/1000] loss: 0.08408775056401889
I0422 21:41:30.222469 32300 trainer.py:136] Epoch[721/1000] loss: 0.08433100084463756
I0422 21:41:34.324107 32300 trainer.py:136] Epoch[722/1000] loss: 0.08396932979424794
I0422 21:41:41.206220 32300 trainer.py:136] Epoch[723/1000] loss: 0.08477631583809853
I0422 21:41:45.380485 32300 trainer.py:136] Epoch[724/1000] loss: 0.08449045196175575
I0422 21:41:49.513947 32300 trainer.py:136] Epoch[725/1000] loss: 0.08459227159619331
I0422 21:41:53.654418 32300 trainer.py:136] Epoch[726/1000] loss: 0.08338739971319835
I0422 21:41:58.012152 32300 trainer.py:136] Epoch[727/1000] loss: 0.08585041885574658
I0422 21:42:02.314710 32300 trainer.py:136] Epoch[728/1000] loss: 0.08459846178690593
I0422 21:42:06.793949 32300 trainer.py:136] Epoch[729/1000] loss: 0.0836128257215023
I0422 21:42:13.591405 32300 trainer.py:136] Epoch[730/1000] loss: 0.0837437945107619
I0422 21:42:17.825502 32300 trainer.py:136] Epoch[731/1000] loss: 0.08366407578190167
I0422 21:42:21.942913 32300 trainer.py:136] Epoch[732/1000] loss: 0.08412823329369228
I0422 21:42:26.320710 32300 trainer.py:136] Epoch[733/1000] loss: 0.08467539648214976
I0422 21:42:30.584831 32300 trainer.py:136] Epoch[734/1000] loss: 0.08386795098582904
I0422 21:42:34.641983 32300 trainer.py:136] Epoch[735/1000] loss: 0.08471126978596051
I0422 21:42:38.961916 32300 trainer.py:136] Epoch[736/1000] loss: 0.08415085698167483
I0422 21:42:45.950533 32300 trainer.py:136] Epoch[737/1000] loss: 0.08343447869022687
I0422 21:42:50.099978 32300 trainer.py:136] Epoch[738/1000] loss: 0.08421126753091812
I0422 21:42:54.652195 32300 trainer.py:136] Epoch[739/1000] loss: 0.08520775785048802
I0422 21:42:58.917360 32300 trainer.py:136] Epoch[740/1000] loss: 0.08474775403738022
I0422 21:43:03.292569 32300 trainer.py:136] Epoch[741/1000] loss: 0.08458095913132031
I0422 21:43:07.550582 32300 trainer.py:136] Epoch[742/1000] loss: 0.08364557723204295
I0422 21:43:11.666064 32300 trainer.py:136] Epoch[743/1000] loss: 0.08401382466157277
I0422 21:43:17.695463 32300 trainer.py:136] Epoch[744/1000] loss: 0.08464423194527626
I0422 21:43:22.285046 32300 trainer.py:136] Epoch[745/1000] loss: 0.08448520054419835
I0422 21:43:26.423073 32300 trainer.py:136] Epoch[746/1000] loss: 0.08385982736945152
I0422 21:43:31.011233 32300 trainer.py:136] Epoch[747/1000] loss: 0.08500923216342926
I0422 21:43:36.217710 32300 trainer.py:136] Epoch[748/1000] loss: 0.08465419585506122
I0422 21:43:43.706465 32300 trainer.py:136] Epoch[749/1000] loss: 0.08406367525458336
I0422 21:43:45.676786 32300 trainer.py:142] Test: [{'precision': 0.01651225769669326, 'recall': 0.08009054733152118, 'hit_ratio': 0.22719498289623719, 'ndcg': 0.05217251215149682}]
I0422 21:43:50.664714 32300 trainer.py:136] Epoch[750/1000] loss: 0.08347157513101895
I0422 21:43:55.797909 32300 trainer.py:136] Epoch[751/1000] loss: 0.08385844280322392
I0422 21:44:02.863600 32300 trainer.py:136] Epoch[752/1000] loss: 0.08467322463790576
I0422 21:44:08.639900 32300 trainer.py:136] Epoch[753/1000] loss: 0.0837328073879083
I0422 21:44:13.781841 32300 trainer.py:136] Epoch[754/1000] loss: 0.08358033746480942
I0422 21:44:18.769188 32300 trainer.py:136] Epoch[755/1000] loss: 0.08424705018599828
I0422 21:44:26.460917 32300 trainer.py:136] Epoch[756/1000] loss: 0.0844444955388705
I0422 21:44:31.529351 32300 trainer.py:136] Epoch[757/1000] loss: 0.08310179660717647
I0422 21:44:36.609498 32300 trainer.py:136] Epoch[758/1000] loss: 0.08408376822868983
I0422 21:44:41.762921 32300 trainer.py:136] Epoch[759/1000] loss: 0.08540285130341847
I0422 21:44:49.677575 32300 trainer.py:136] Epoch[760/1000] loss: 0.08443776642282803
I0422 21:44:54.634877 32300 trainer.py:136] Epoch[761/1000] loss: 0.08449273556470871
I0422 21:44:59.725703 32300 trainer.py:136] Epoch[762/1000] loss: 0.08444418758153915
I0422 21:45:06.374803 32300 trainer.py:136] Epoch[763/1000] loss: 0.08350807925065358
I0422 21:45:12.709947 32300 trainer.py:136] Epoch[764/1000] loss: 0.08584502215186755
I0422 21:45:17.744647 32300 trainer.py:136] Epoch[765/1000] loss: 0.08479009444514911
I0422 21:45:22.681938 32300 trainer.py:136] Epoch[766/1000] loss: 0.08452718332409859
I0422 21:45:29.633768 32300 trainer.py:136] Epoch[767/1000] loss: 0.08392398059368134
I0422 21:45:35.282401 32300 trainer.py:136] Epoch[768/1000] loss: 0.08376978089412053
I0422 21:45:40.459441 32300 trainer.py:136] Epoch[769/1000] loss: 0.08349371453126271
I0422 21:45:45.899620 32300 trainer.py:136] Epoch[770/1000] loss: 0.08359175051252048
I0422 21:45:53.059887 32300 trainer.py:136] Epoch[771/1000] loss: 0.08470317100485165
I0422 21:45:58.064833 32300 trainer.py:136] Epoch[772/1000] loss: 0.08315494904915492
I0422 21:46:03.303457 32300 trainer.py:136] Epoch[773/1000] loss: 0.08385118593772252
I0422 21:46:08.299544 32300 trainer.py:136] Epoch[774/1000] loss: 0.08377668013175328
I0422 21:46:16.203897 32300 trainer.py:136] Epoch[775/1000] loss: 0.08314856390158336
I0422 21:46:21.276751 32300 trainer.py:136] Epoch[776/1000] loss: 0.08438351626197498
I0422 21:46:26.383382 32300 trainer.py:136] Epoch[777/1000] loss: 0.083517221113046
I0422 21:46:31.473204 32300 trainer.py:136] Epoch[778/1000] loss: 0.0840875394642353
I0422 21:46:39.357966 32300 trainer.py:136] Epoch[779/1000] loss: 0.08409226189057033
I0422 21:46:44.472968 32300 trainer.py:136] Epoch[780/1000] loss: 0.08305209254225095
I0422 21:46:49.745186 32300 trainer.py:136] Epoch[781/1000] loss: 0.08435896163185437
I0422 21:46:57.536748 32300 trainer.py:136] Epoch[782/1000] loss: 0.08345070357124011
I0422 21:47:02.853705 32300 trainer.py:136] Epoch[783/1000] loss: 0.08423429727554321
I0422 21:47:08.065440 32300 trainer.py:136] Epoch[784/1000] loss: 0.08340348800023396
I0422 21:47:13.677062 32300 trainer.py:136] Epoch[785/1000] loss: 0.08422081048289935
I0422 21:47:20.955401 32300 trainer.py:136] Epoch[786/1000] loss: 0.08384416624903679
I0422 21:47:25.981652 32300 trainer.py:136] Epoch[787/1000] loss: 0.08450649802883466
I0422 21:47:31.195828 32300 trainer.py:136] Epoch[788/1000] loss: 0.08341699838638306
I0422 21:47:37.445448 32300 trainer.py:136] Epoch[789/1000] loss: 0.08372589324911435
I0422 21:47:44.145198 32300 trainer.py:136] Epoch[790/1000] loss: 0.08414355665445328
I0422 21:47:49.273241 32300 trainer.py:136] Epoch[791/1000] loss: 0.08364462355772655
I0422 21:47:54.279889 32300 trainer.py:136] Epoch[792/1000] loss: 0.08508601288000743
I0422 21:48:00.292626 32300 trainer.py:136] Epoch[793/1000] loss: 0.08291845147808392
I0422 21:48:07.088372 32300 trainer.py:136] Epoch[794/1000] loss: 0.0834571619828542
I0422 21:48:12.377931 32300 trainer.py:136] Epoch[795/1000] loss: 0.08385174597303073
I0422 21:48:17.475693 32300 trainer.py:136] Epoch[796/1000] loss: 0.08319510892033577
I0422 21:48:22.545955 32300 trainer.py:136] Epoch[797/1000] loss: 0.08393808205922444
I0422 21:48:30.405069 32300 trainer.py:136] Epoch[798/1000] loss: 0.08335779110590617
I0422 21:48:35.531855 32300 trainer.py:136] Epoch[799/1000] loss: 0.08384665971000989
I0422 21:48:37.589990 32300 trainer.py:142] Test: [{'precision': 0.01654076396807297, 'recall': 0.07960959120723561, 'hit_ratio': 0.22705245153933865, 'ndcg': 0.05211546383382759}]
I0422 21:48:42.705019 32300 trainer.py:136] Epoch[800/1000] loss: 0.0831795334815979
I0422 21:48:47.995113 32300 trainer.py:136] Epoch[801/1000] loss: 0.0836874507367611
I0422 21:48:55.493754 32300 trainer.py:136] Epoch[802/1000] loss: 0.08394747103254001
I0422 21:49:00.479966 32300 trainer.py:136] Epoch[803/1000] loss: 0.084026999771595
I0422 21:49:05.488857 32300 trainer.py:136] Epoch[804/1000] loss: 0.08370767037073772
I0422 21:49:11.224372 32300 trainer.py:136] Epoch[805/1000] loss: 0.08431574950615565
I0422 21:49:18.060008 32300 trainer.py:136] Epoch[806/1000] loss: 0.0841409054895242
I0422 21:49:23.245340 32300 trainer.py:136] Epoch[807/1000] loss: 0.08308556427558263
I0422 21:49:28.418900 32300 trainer.py:136] Epoch[808/1000] loss: 0.08416059489051501
I0422 21:49:36.146849 32300 trainer.py:136] Epoch[809/1000] loss: 0.08330832918485005
I0422 21:49:41.216718 32300 trainer.py:136] Epoch[810/1000] loss: 0.08355775723854701
I0422 21:49:46.325432 32300 trainer.py:136] Epoch[811/1000] loss: 0.0835399366915226
I0422 21:49:51.421738 32300 trainer.py:136] Epoch[812/1000] loss: 0.0838712751865387
I0422 21:49:59.229231 32300 trainer.py:136] Epoch[813/1000] loss: 0.0826797050734361
I0422 21:50:04.340305 32300 trainer.py:136] Epoch[814/1000] loss: 0.08299907048543294
I0422 21:50:09.388274 32300 trainer.py:136] Epoch[815/1000] loss: 0.08377334972222646
I0422 21:50:14.443276 32300 trainer.py:136] Epoch[816/1000] loss: 0.08371872330705325
I0422 21:50:22.169862 32300 trainer.py:136] Epoch[817/1000] loss: 0.08320235957702
I0422 21:50:27.236983 32300 trainer.py:136] Epoch[818/1000] loss: 0.08347284545501073
I0422 21:50:32.374737 32300 trainer.py:136] Epoch[819/1000] loss: 0.08374916389584541
I0422 21:50:37.329581 32300 trainer.py:136] Epoch[820/1000] loss: 0.08235872040192287
I0422 21:50:45.046471 32300 trainer.py:136] Epoch[821/1000] loss: 0.08385444929202397
I0422 21:50:50.129182 32300 trainer.py:136] Epoch[822/1000] loss: 0.0836483637491862
I0422 21:50:55.242224 32300 trainer.py:136] Epoch[823/1000] loss: 0.08385383461912473
I0422 21:51:00.339564 32300 trainer.py:136] Epoch[824/1000] loss: 0.0835158998767535
I0422 21:51:08.132680 32300 trainer.py:136] Epoch[825/1000] loss: 0.08351203923424085
I0422 21:51:13.119828 32300 trainer.py:136] Epoch[826/1000] loss: 0.08390257010857265
I0422 21:51:18.250852 32300 trainer.py:136] Epoch[827/1000] loss: 0.08284617463747661
I0422 21:51:23.301719 32300 trainer.py:136] Epoch[828/1000] loss: 0.08372873812913895
I0422 21:51:31.187650 32300 trainer.py:136] Epoch[829/1000] loss: 0.08507099747657776
I0422 21:51:36.246707 32300 trainer.py:136] Epoch[830/1000] loss: 0.08368923763434093
I0422 21:51:41.653221 32300 trainer.py:136] Epoch[831/1000] loss: 0.08328080674012502
I0422 21:51:46.787955 32300 trainer.py:136] Epoch[832/1000] loss: 0.08295605207482974
I0422 21:51:54.480556 32300 trainer.py:136] Epoch[833/1000] loss: 0.08355592687924702
I0422 21:51:59.595038 32300 trainer.py:136] Epoch[834/1000] loss: 0.08433122436205547
I0422 21:52:04.666857 32300 trainer.py:136] Epoch[835/1000] loss: 0.08399864037831624
I0422 21:52:11.967811 32300 trainer.py:136] Epoch[836/1000] loss: 0.08319673066337903
I0422 21:52:16.211275 32300 trainer.py:136] Epoch[837/1000] loss: 0.08369449401895206
I0422 21:52:20.304536 32300 trainer.py:136] Epoch[838/1000] loss: 0.0829108605782191
I0422 21:52:24.898300 32300 trainer.py:136] Epoch[839/1000] loss: 0.08256485437353452
I0422 21:52:30.066596 32300 trainer.py:136] Epoch[840/1000] loss: 0.08349848290284474
I0422 21:52:37.952734 32300 trainer.py:136] Epoch[841/1000] loss: 0.08355060095588367
I0422 21:52:43.010809 32300 trainer.py:136] Epoch[842/1000] loss: 0.08337689191102982
I0422 21:52:48.046838 32300 trainer.py:136] Epoch[843/1000] loss: 0.08274684101343155
I0422 21:52:55.417516 32300 trainer.py:136] Epoch[844/1000] loss: 0.08367215842008591
I0422 21:53:00.860219 32300 trainer.py:136] Epoch[845/1000] loss: 0.08263160660862923
I0422 21:53:05.978009 32300 trainer.py:136] Epoch[846/1000] loss: 0.08286592985192935
I0422 21:53:10.979162 32300 trainer.py:136] Epoch[847/1000] loss: 0.0835034449895223
I0422 21:53:18.953365 32300 trainer.py:136] Epoch[848/1000] loss: 0.08235050862034161
I0422 21:53:24.155010 32300 trainer.py:136] Epoch[849/1000] loss: 0.08266183485587437
I0422 21:53:26.348574 32300 trainer.py:142] Test: [{'precision': 0.016597776510832378, 'recall': 0.0805269030327794, 'hit_ratio': 0.22790763968072977, 'ndcg': 0.05251981621135768}]
I0422 21:53:33.109000 32300 trainer.py:136] Epoch[850/1000] loss: 0.08317593236764272
I0422 21:53:39.145303 32300 trainer.py:136] Epoch[851/1000] loss: 0.08349889392654102
I0422 21:53:44.037062 32300 trainer.py:136] Epoch[852/1000] loss: 0.08274403586983681
I0422 21:53:48.815682 32300 trainer.py:136] Epoch[853/1000] loss: 0.08344883223374684
I0422 21:53:56.577457 32300 trainer.py:136] Epoch[854/1000] loss: 0.08310433725516002
I0422 21:54:01.701803 32300 trainer.py:136] Epoch[855/1000] loss: 0.08398330087463061
I0422 21:54:07.062991 32300 trainer.py:136] Epoch[856/1000] loss: 0.08288146431247394
I0422 21:54:15.050261 32300 trainer.py:136] Epoch[857/1000] loss: 0.08240895469983418
I0422 21:54:20.177582 32300 trainer.py:136] Epoch[858/1000] loss: 0.08309548596541087
I0422 21:54:25.694609 32300 trainer.py:136] Epoch[859/1000] loss: 0.08302073925733566
I0422 21:54:33.220146 32300 trainer.py:136] Epoch[860/1000] loss: 0.08403470739722252
I0422 21:54:38.341012 32300 trainer.py:136] Epoch[861/1000] loss: 0.08329817155996959
I0422 21:54:44.235131 32300 trainer.py:136] Epoch[862/1000] loss: 0.08275770023465157
I0422 21:54:51.542417 32300 trainer.py:136] Epoch[863/1000] loss: 0.083140862484773
I0422 21:54:56.597693 32300 trainer.py:136] Epoch[864/1000] loss: 0.08356340850392978
I0422 21:55:02.229942 32300 trainer.py:136] Epoch[865/1000] loss: 0.08305073777834575
I0422 21:55:10.086127 32300 trainer.py:136] Epoch[866/1000] loss: 0.08301916470130284
I0422 21:55:15.255747 32300 trainer.py:136] Epoch[867/1000] loss: 0.08298507581154506
I0422 21:55:20.447613 32300 trainer.py:136] Epoch[868/1000] loss: 0.08249327540397644
I0422 21:55:28.537063 32300 trainer.py:136] Epoch[869/1000] loss: 0.08302091186245282
I0422 21:55:33.643765 32300 trainer.py:136] Epoch[870/1000] loss: 0.0821338618795077
I0422 21:55:38.724584 32300 trainer.py:136] Epoch[871/1000] loss: 0.08289887383580208
I0422 21:55:46.689575 32300 trainer.py:136] Epoch[872/1000] loss: 0.0832837348182996
I0422 21:55:51.740589 32300 trainer.py:136] Epoch[873/1000] loss: 0.0819124107559522
I0422 21:55:57.839800 32300 trainer.py:136] Epoch[874/1000] loss: 0.0837260199089845
I0422 21:56:05.165267 32300 trainer.py:136] Epoch[875/1000] loss: 0.08237172414859135
I0422 21:56:09.820098 32300 trainer.py:136] Epoch[876/1000] loss: 0.08221591636538506
I0422 21:56:16.802744 32300 trainer.py:136] Epoch[877/1000] loss: 0.08328531309962273
I0422 21:56:22.862157 32300 trainer.py:136] Epoch[878/1000] loss: 0.0828803430000941
I0422 21:56:27.923192 32300 trainer.py:136] Epoch[879/1000] loss: 0.08306296666463216
I0422 21:56:33.980695 32300 trainer.py:136] Epoch[880/1000] loss: 0.08281851684053738
I0422 21:56:41.020881 32300 trainer.py:136] Epoch[881/1000] loss: 0.08259950081507365
I0422 21:56:46.050797 32300 trainer.py:136] Epoch[882/1000] loss: 0.0824451744556427
I0422 21:56:52.057242 32300 trainer.py:136] Epoch[883/1000] loss: 0.08248857036232948
I0422 21:56:59.669847 32300 trainer.py:136] Epoch[884/1000] loss: 0.08407921219865482
I0422 21:57:04.732450 32300 trainer.py:136] Epoch[885/1000] loss: 0.08266174048185349
I0422 21:57:11.444160 32300 trainer.py:136] Epoch[886/1000] loss: 0.08336975922187169
I0422 21:57:17.800281 32300 trainer.py:136] Epoch[887/1000] loss: 0.08250696957111359
I0422 21:57:22.960704 32300 trainer.py:136] Epoch[888/1000] loss: 0.08396244049072266
I0422 21:57:30.622624 32300 trainer.py:136] Epoch[889/1000] loss: 0.08311012263099353
I0422 21:57:36.093854 32300 trainer.py:136] Epoch[890/1000] loss: 0.08261306583881378
I0422 21:57:41.307810 32300 trainer.py:136] Epoch[891/1000] loss: 0.08364486694335938
I0422 21:57:48.914703 32300 trainer.py:136] Epoch[892/1000] loss: 0.08283070847392082
I0422 21:57:54.372931 32300 trainer.py:136] Epoch[893/1000] loss: 0.08311405777931213
I0422 21:57:59.555054 32300 trainer.py:136] Epoch[894/1000] loss: 0.08333279937505722
I0422 21:58:07.583687 32300 trainer.py:136] Epoch[895/1000] loss: 0.08289061238368352
I0422 21:58:12.884192 32300 trainer.py:136] Epoch[896/1000] loss: 0.08336009581883748
I0422 21:58:17.454126 32300 trainer.py:136] Epoch[897/1000] loss: 0.0828586146235466
I0422 21:58:21.764846 32300 trainer.py:136] Epoch[898/1000] loss: 0.08219271649916966
I0422 21:58:29.405530 32300 trainer.py:136] Epoch[899/1000] loss: 0.08313563466072083
I0422 21:58:31.468786 32300 trainer.py:142] Test: [{'precision': 0.016633409350057006, 'recall': 0.08075949259068815, 'hit_ratio': 0.22862029646522236, 'ndcg': 0.05277239923551078}]
I0422 21:58:36.747015 32300 trainer.py:136] Epoch[900/1000] loss: 0.08280005554358165
I0422 21:58:44.291963 32300 trainer.py:136] Epoch[901/1000] loss: 0.08215277642011642
I0422 21:58:50.158356 32300 trainer.py:136] Epoch[902/1000] loss: 0.08252668753266335
I0422 21:58:55.311536 32300 trainer.py:136] Epoch[903/1000] loss: 0.08322799205780029
I0422 21:59:03.483927 32300 trainer.py:136] Epoch[904/1000] loss: 0.08278597767154376
I0422 21:59:08.657270 32300 trainer.py:136] Epoch[905/1000] loss: 0.08355715498328209
I0422 21:59:13.875916 32300 trainer.py:136] Epoch[906/1000] loss: 0.0827524686853091
I0422 21:59:21.726313 32300 trainer.py:136] Epoch[907/1000] loss: 0.08283481746912003
I0422 21:59:26.891453 32300 trainer.py:136] Epoch[908/1000] loss: 0.08331556618213654
I0422 21:59:32.012135 32300 trainer.py:136] Epoch[909/1000] loss: 0.08209194491306941
I0422 21:59:40.118282 32300 trainer.py:136] Epoch[910/1000] loss: 0.08184058591723442
I0422 21:59:45.435858 32300 trainer.py:136] Epoch[911/1000] loss: 0.08370976770917575
I0422 21:59:51.142345 32300 trainer.py:136] Epoch[912/1000] loss: 0.08339015270272891
I0422 21:59:57.002721 32300 trainer.py:136] Epoch[913/1000] loss: 0.08268574128548305
I0422 22:00:01.251844 32300 trainer.py:136] Epoch[914/1000] loss: 0.08262464279929797
I0422 22:00:05.267241 32300 trainer.py:136] Epoch[915/1000] loss: 0.0830037755270799
I0422 22:00:09.277710 32300 trainer.py:136] Epoch[916/1000] loss: 0.08278961231311162
I0422 22:00:13.360313 32300 trainer.py:136] Epoch[917/1000] loss: 0.08313445498545964
I0422 22:00:17.654199 32300 trainer.py:136] Epoch[918/1000] loss: 0.08178908253709476
I0422 22:00:21.784598 32300 trainer.py:136] Epoch[919/1000] loss: 0.08248143767317136
I0422 22:00:27.885357 32300 trainer.py:136] Epoch[920/1000] loss: 0.08340006818373998
I0422 22:00:32.707460 32300 trainer.py:136] Epoch[921/1000] loss: 0.08245383699735005
I0422 22:00:36.828526 32300 trainer.py:136] Epoch[922/1000] loss: 0.08345455924669902
I0422 22:00:41.177877 32300 trainer.py:136] Epoch[923/1000] loss: 0.08302576219042142
I0422 22:00:45.450057 32300 trainer.py:136] Epoch[924/1000] loss: 0.08401500682036082
I0422 22:00:49.671173 32300 trainer.py:136] Epoch[925/1000] loss: 0.08350520208477974
I0422 22:00:53.866542 32300 trainer.py:136] Epoch[926/1000] loss: 0.08250896632671356
I0422 22:00:59.399299 32300 trainer.py:136] Epoch[927/1000] loss: 0.08252148826917012
I0422 22:01:04.925364 32300 trainer.py:136] Epoch[928/1000] loss: 0.08316873759031296
I0422 22:01:09.049813 32300 trainer.py:136] Epoch[929/1000] loss: 0.08206196253498395
I0422 22:01:13.499194 32300 trainer.py:136] Epoch[930/1000] loss: 0.08272520328561465
I0422 22:01:18.800995 32300 trainer.py:136] Epoch[931/1000] loss: 0.08194883291920026
I0422 22:01:26.560737 32300 trainer.py:136] Epoch[932/1000] loss: 0.08245466277003288
I0422 22:01:31.513553 32300 trainer.py:136] Epoch[933/1000] loss: 0.08257731546958287
I0422 22:01:36.631205 32300 trainer.py:136] Epoch[934/1000] loss: 0.08180876448750496
I0422 22:01:45.116758 32300 trainer.py:136] Epoch[935/1000] loss: 0.08271646002928416
I0422 22:01:50.609861 32300 trainer.py:136] Epoch[936/1000] loss: 0.08295633519689243
I0422 22:01:57.059377 32300 trainer.py:136] Epoch[937/1000] loss: 0.08255397528409958
I0422 22:02:03.819990 32300 trainer.py:136] Epoch[938/1000] loss: 0.08428457130988438
I0422 22:02:08.986253 32300 trainer.py:136] Epoch[939/1000] loss: 0.08223880703250568
I0422 22:02:16.309788 32300 trainer.py:136] Epoch[940/1000] loss: 0.08290411283572514
I0422 22:02:22.010736 32300 trainer.py:136] Epoch[941/1000] loss: 0.08296312764286995
I0422 22:02:26.714692 32300 trainer.py:136] Epoch[942/1000] loss: 0.08268175522486369
I0422 22:02:32.443922 32300 trainer.py:136] Epoch[943/1000] loss: 0.0817201795677344
I0422 22:02:37.655907 32300 trainer.py:136] Epoch[944/1000] loss: 0.08295860762397449
I0422 22:02:41.941808 32300 trainer.py:136] Epoch[945/1000] loss: 0.08231023202339809
I0422 22:02:46.267064 32300 trainer.py:136] Epoch[946/1000] loss: 0.08234375218550365
I0422 22:02:50.462325 32300 trainer.py:136] Epoch[947/1000] loss: 0.08178265268603961
I0422 22:02:54.565478 32300 trainer.py:136] Epoch[948/1000] loss: 0.08189159135023753
I0422 22:02:58.792027 32300 trainer.py:136] Epoch[949/1000] loss: 0.082579189290603
I0422 22:03:00.245936 32300 trainer.py:142] Test: [{'precision': 0.016711801596351186, 'recall': 0.08132920608135667, 'hit_ratio': 0.23075826681870013, 'ndcg': 0.0528274828686465}]
I0422 22:03:06.929111 32300 trainer.py:136] Epoch[950/1000] loss: 0.08179434513052304
I0422 22:03:11.826664 32300 trainer.py:136] Epoch[951/1000] loss: 0.08286679536104202
I0422 22:03:16.010609 32300 trainer.py:136] Epoch[952/1000] loss: 0.0820778099199136
I0422 22:03:20.299562 32300 trainer.py:136] Epoch[953/1000] loss: 0.08287185430526733
I0422 22:03:24.412357 32300 trainer.py:136] Epoch[954/1000] loss: 0.08158936351537704
I0422 22:03:28.915087 32300 trainer.py:136] Epoch[955/1000] loss: 0.08221785972515742
I0422 22:03:35.388618 32300 trainer.py:136] Epoch[956/1000] loss: 0.08213671048482259
I0422 22:03:40.006438 32300 trainer.py:136] Epoch[957/1000] loss: 0.08178248380621274
I0422 22:03:44.453455 32300 trainer.py:136] Epoch[958/1000] loss: 0.08235252151886623
I0422 22:03:48.690326 32300 trainer.py:136] Epoch[959/1000] loss: 0.08167481422424316
I0422 22:03:52.848728 32300 trainer.py:136] Epoch[960/1000] loss: 0.08231391136844952
I0422 22:03:57.098234 32300 trainer.py:136] Epoch[961/1000] loss: 0.08223727097113927
I0422 22:04:01.715171 32300 trainer.py:136] Epoch[962/1000] loss: 0.08130069573720296
I0422 22:04:08.006721 32300 trainer.py:136] Epoch[963/1000] loss: 0.0831831581890583
I0422 22:04:12.102935 32300 trainer.py:136] Epoch[964/1000] loss: 0.0826632169385751
I0422 22:04:16.309087 32300 trainer.py:136] Epoch[965/1000] loss: 0.08300637826323509
I0422 22:04:20.419682 32300 trainer.py:136] Epoch[966/1000] loss: 0.08163982505599658
I0422 22:04:24.765437 32300 trainer.py:136] Epoch[967/1000] loss: 0.08209566151102383
I0422 22:04:29.112454 32300 trainer.py:136] Epoch[968/1000] loss: 0.0818403996527195
I0422 22:04:33.520778 32300 trainer.py:136] Epoch[969/1000] loss: 0.08177068208654721
I0422 22:04:37.632679 32300 trainer.py:136] Epoch[970/1000] loss: 0.08211081847548485
I0422 22:04:44.521924 32300 trainer.py:136] Epoch[971/1000] loss: 0.08231104165315628
I0422 22:04:48.778937 32300 trainer.py:136] Epoch[972/1000] loss: 0.08241091792782147
I0422 22:04:52.941266 32300 trainer.py:136] Epoch[973/1000] loss: 0.08220308149854343
I0422 22:04:57.103605 32300 trainer.py:136] Epoch[974/1000] loss: 0.08213984593749046
I0422 22:05:01.110243 32300 trainer.py:136] Epoch[975/1000] loss: 0.08158963173627853
I0422 22:05:05.243753 32300 trainer.py:136] Epoch[976/1000] loss: 0.08193549141287804
I0422 22:05:09.353349 32300 trainer.py:136] Epoch[977/1000] loss: 0.08237663035591443
I0422 22:05:13.503728 32300 trainer.py:136] Epoch[978/1000] loss: 0.0830236126979192
I0422 22:05:17.638159 32300 trainer.py:136] Epoch[979/1000] loss: 0.08199835444490115
I0422 22:05:23.200025 32300 trainer.py:136] Epoch[980/1000] loss: 0.08249503374099731
I0422 22:05:28.171964 32300 trainer.py:136] Epoch[981/1000] loss: 0.08180076753099759
I0422 22:05:32.216727 32300 trainer.py:136] Epoch[982/1000] loss: 0.08217650403579076
I0422 22:05:36.300401 32300 trainer.py:136] Epoch[983/1000] loss: 0.08249170705676079
I0422 22:05:40.392052 32300 trainer.py:136] Epoch[984/1000] loss: 0.08143239592512448
I0422 22:05:44.524642 32300 trainer.py:136] Epoch[985/1000] loss: 0.08198677003383636
I0422 22:05:48.654275 32300 trainer.py:136] Epoch[986/1000] loss: 0.08301159739494324
I0422 22:05:52.839207 32300 trainer.py:136] Epoch[987/1000] loss: 0.08184487372636795
I0422 22:05:56.951300 32300 trainer.py:136] Epoch[988/1000] loss: 0.08234621832768123
I0422 22:06:01.003605 32300 trainer.py:136] Epoch[989/1000] loss: 0.08325924724340439
I0422 22:06:05.035448 32300 trainer.py:136] Epoch[990/1000] loss: 0.08261451000968616
I0422 22:06:09.159531 32300 trainer.py:136] Epoch[991/1000] loss: 0.08198653782407443
I0422 22:06:13.314671 32300 trainer.py:136] Epoch[992/1000] loss: 0.0822371815641721
I0422 22:06:19.802460 32300 trainer.py:136] Epoch[993/1000] loss: 0.0825372984011968
I0422 22:06:23.973410 32300 trainer.py:136] Epoch[994/1000] loss: 0.08255436892310779
I0422 22:06:28.173241 32300 trainer.py:136] Epoch[995/1000] loss: 0.08283479884266853
I0422 22:06:32.288740 32300 trainer.py:136] Epoch[996/1000] loss: 0.08208284402887027
I0422 22:06:36.452101 32300 trainer.py:136] Epoch[997/1000] loss: 0.08167882387836774
I0422 22:06:40.769986 32300 trainer.py:136] Epoch[998/1000] loss: 0.08243638277053833
I0422 22:06:44.925451 32300 trainer.py:136] Epoch[999/1000] loss: 0.08178432037432988
I0422 22:06:46.328879 32300 trainer.py:142] Test: [{'precision': 0.01667616875712656, 'recall': 0.08150049773811453, 'hit_ratio': 0.23004561003420754, 'ndcg': 0.05284874530328412}]
