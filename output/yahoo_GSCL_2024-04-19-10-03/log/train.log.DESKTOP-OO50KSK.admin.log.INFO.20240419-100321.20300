I0419 10:03:27.496864 28972 trainer.py:121] Test: [{'precision': 0.0032731850608476707, 'recall': 0.036923412531889244, 'hit_ratio': 0.06336550566512798, 'ndcg': 0.0187551976694393}]
I0419 10:03:32.765805 28972 trainer.py:139] Epoch[0/1000] loss: 0.6805902053328121
I0419 10:03:37.880463 28972 trainer.py:139] Epoch[1/1000] loss: 0.5675100088119507
I0419 10:03:43.223637 28972 trainer.py:139] Epoch[2/1000] loss: 0.5316741711953107
I0419 10:03:48.570430 28972 trainer.py:139] Epoch[3/1000] loss: 0.5162035367068123
I0419 10:03:54.061644 28972 trainer.py:139] Epoch[4/1000] loss: 0.49792976063840527
I0419 10:03:59.518122 28972 trainer.py:139] Epoch[5/1000] loss: 0.4775693434126237
I0419 10:04:05.019478 28972 trainer.py:139] Epoch[6/1000] loss: 0.4595202575711643
I0419 10:04:10.555077 28972 trainer.py:139] Epoch[7/1000] loss: 0.4437685416025274
I0419 10:04:16.003912 28972 trainer.py:139] Epoch[8/1000] loss: 0.42651915024308595
I0419 10:04:21.417891 28972 trainer.py:139] Epoch[9/1000] loss: 0.4085311381255879
I0419 10:04:27.254716 28972 trainer.py:139] Epoch[10/1000] loss: 0.39182668047792774
I0419 10:04:33.330792 28972 trainer.py:139] Epoch[11/1000] loss: 0.3832387222963221
I0419 10:04:40.614455 28972 trainer.py:139] Epoch[12/1000] loss: 0.3691755042356603
I0419 10:04:47.360062 28972 trainer.py:139] Epoch[13/1000] loss: 0.3583881627110874
I0419 10:04:53.080687 28972 trainer.py:139] Epoch[14/1000] loss: 0.34847721808096943
I0419 10:04:59.267068 28972 trainer.py:139] Epoch[15/1000] loss: 0.3366715504842646
I0419 10:05:07.156880 28972 trainer.py:139] Epoch[16/1000] loss: 0.32837696987039905
I0419 10:05:12.985343 28972 trainer.py:139] Epoch[17/1000] loss: 0.32256675292463866
I0419 10:05:18.668601 28972 trainer.py:139] Epoch[18/1000] loss: 0.3153349757194519
I0419 10:05:24.227787 28972 trainer.py:139] Epoch[19/1000] loss: 0.3093111357268165
I0419 10:05:32.151466 28972 trainer.py:139] Epoch[20/1000] loss: 0.3006487366031198
I0419 10:05:37.829771 28972 trainer.py:139] Epoch[21/1000] loss: 0.29547643486191244
I0419 10:05:43.275897 28972 trainer.py:139] Epoch[22/1000] loss: 0.29047521598198833
I0419 10:05:48.585884 28972 trainer.py:139] Epoch[23/1000] loss: 0.2838362490429598
I0419 10:05:54.211443 28972 trainer.py:139] Epoch[24/1000] loss: 0.2785559647223529
I0419 10:06:02.012208 28972 trainer.py:139] Epoch[25/1000] loss: 0.2724471039631787
I0419 10:06:07.938720 28972 trainer.py:139] Epoch[26/1000] loss: 0.26822707582922545
I0419 10:06:13.863390 28972 trainer.py:139] Epoch[27/1000] loss: 0.263145106680253
I0419 10:06:20.628676 28972 trainer.py:139] Epoch[28/1000] loss: 0.25900819196420555
I0419 10:06:27.692539 28972 trainer.py:139] Epoch[29/1000] loss: 0.25612981880412383
I0419 10:06:33.116303 28972 trainer.py:139] Epoch[30/1000] loss: 0.25202474874608655
I0419 10:06:38.676594 28972 trainer.py:139] Epoch[31/1000] loss: 0.24697729243951685
I0419 10:06:44.153591 28972 trainer.py:139] Epoch[32/1000] loss: 0.24406592810855193
I0419 10:06:50.500714 28972 trainer.py:139] Epoch[33/1000] loss: 0.23918417885023005
I0419 10:06:57.416201 28972 trainer.py:139] Epoch[34/1000] loss: 0.24008531780803904
I0419 10:07:03.015251 28972 trainer.py:139] Epoch[35/1000] loss: 0.2362908440477708
I0419 10:07:08.757822 28972 trainer.py:139] Epoch[36/1000] loss: 0.23157686608679154
I0419 10:07:17.078287 28972 trainer.py:139] Epoch[37/1000] loss: 0.22704906235722935
I0419 10:07:23.049963 28972 trainer.py:139] Epoch[38/1000] loss: 0.22517676739131703
I0419 10:07:28.746268 28972 trainer.py:139] Epoch[39/1000] loss: 0.22362911964164062
I0419 10:07:38.132482 28972 trainer.py:139] Epoch[40/1000] loss: 0.22123835805584402
I0419 10:07:45.022479 28972 trainer.py:139] Epoch[41/1000] loss: 0.21923300536239848
I0419 10:07:53.880979 28972 trainer.py:139] Epoch[42/1000] loss: 0.21693932484177983
I0419 10:07:59.502558 28972 trainer.py:139] Epoch[43/1000] loss: 0.21617465597741745
I0419 10:08:05.173049 28972 trainer.py:139] Epoch[44/1000] loss: 0.21217018628821654
I0419 10:08:13.497300 28972 trainer.py:139] Epoch[45/1000] loss: 0.2113625687711379
I0419 10:08:19.201602 28972 trainer.py:139] Epoch[46/1000] loss: 0.20965405597406275
I0419 10:08:24.757863 28972 trainer.py:139] Epoch[47/1000] loss: 0.20776262353448308
I0419 10:08:33.938447 28972 trainer.py:139] Epoch[48/1000] loss: 0.20437107016058528
I0419 10:08:39.890068 28972 trainer.py:139] Epoch[49/1000] loss: 0.20293460435727062
I0419 10:08:40.619188 28972 trainer.py:145] Test: [{'precision': 0.011414183801930346, 'recall': 0.14684637878091508, 'hit_ratio': 0.2161141418380193, 'ndcg': 0.06680202884109467}]
I0419 10:08:48.918942 28972 trainer.py:139] Epoch[50/1000] loss: 0.2005426270120284
I0419 10:08:54.634217 28972 trainer.py:139] Epoch[51/1000] loss: 0.20123071530286005
I0419 10:09:00.587268 28972 trainer.py:139] Epoch[52/1000] loss: 0.19883867484681747
I0419 10:09:08.676974 28972 trainer.py:139] Epoch[53/1000] loss: 0.19533939133672154
I0419 10:09:14.398086 28972 trainer.py:139] Epoch[54/1000] loss: 0.19480002189383788
I0419 10:09:21.082718 28972 trainer.py:139] Epoch[55/1000] loss: 0.19465451731401331
I0419 10:09:28.469013 28972 trainer.py:139] Epoch[56/1000] loss: 0.19324528119143317
I0419 10:09:34.387627 28972 trainer.py:139] Epoch[57/1000] loss: 0.1887346269453273
I0419 10:09:41.936411 28972 trainer.py:139] Epoch[58/1000] loss: 0.19074278982246623
I0419 10:09:48.646111 28972 trainer.py:139] Epoch[59/1000] loss: 0.1895641456632053
I0419 10:09:54.882138 28972 trainer.py:139] Epoch[60/1000] loss: 0.18905867811511545
I0419 10:10:03.580306 28972 trainer.py:139] Epoch[61/1000] loss: 0.18568552679875316
I0419 10:10:09.901672 28972 trainer.py:139] Epoch[62/1000] loss: 0.18530777885633357
I0419 10:10:18.354965 28972 trainer.py:139] Epoch[63/1000] loss: 0.18250498526236592
I0419 10:10:24.148944 28972 trainer.py:139] Epoch[64/1000] loss: 0.18352619514745824
I0419 10:10:29.830770 28972 trainer.py:139] Epoch[65/1000] loss: 0.18329466879367828
I0419 10:10:38.236491 28972 trainer.py:139] Epoch[66/1000] loss: 0.18117663176620707
I0419 10:10:43.882397 28972 trainer.py:139] Epoch[67/1000] loss: 0.18011277125162237
I0419 10:10:49.844866 28972 trainer.py:139] Epoch[68/1000] loss: 0.17777048752588384
I0419 10:10:58.242146 28972 trainer.py:139] Epoch[69/1000] loss: 0.17657369901152217
I0419 10:11:03.891340 28972 trainer.py:139] Epoch[70/1000] loss: 0.17781374559682958
I0419 10:11:09.726329 28972 trainer.py:139] Epoch[71/1000] loss: 0.17591033525326671
I0419 10:11:18.235637 28972 trainer.py:139] Epoch[72/1000] loss: 0.17400000901783214
I0419 10:11:24.104435 28972 trainer.py:139] Epoch[73/1000] loss: 0.1744244685944389
I0419 10:11:32.417159 28972 trainer.py:139] Epoch[74/1000] loss: 0.17183677939807668
I0419 10:11:38.438001 28972 trainer.py:139] Epoch[75/1000] loss: 0.17262550048968373
I0419 10:11:46.219076 28972 trainer.py:139] Epoch[76/1000] loss: 0.16916456818580627
I0419 10:11:53.146003 28972 trainer.py:139] Epoch[77/1000] loss: 0.1716729700565338
I0419 10:11:59.180220 28972 trainer.py:139] Epoch[78/1000] loss: 0.16978660138214335
I0419 10:12:07.792670 28972 trainer.py:139] Epoch[79/1000] loss: 0.16972833608879762
I0419 10:12:13.781046 28972 trainer.py:139] Epoch[80/1000] loss: 0.1680467400480719
I0419 10:12:19.728553 28972 trainer.py:139] Epoch[81/1000] loss: 0.16786152387366576
I0419 10:12:28.130026 28972 trainer.py:139] Epoch[82/1000] loss: 0.16433064814876108
I0419 10:12:34.331038 28972 trainer.py:139] Epoch[83/1000] loss: 0.16369030142531676
I0419 10:12:42.446052 28972 trainer.py:139] Epoch[84/1000] loss: 0.1647972210365183
I0419 10:12:49.068786 28972 trainer.py:139] Epoch[85/1000] loss: 0.16591263869229486
I0419 10:12:54.946465 28972 trainer.py:139] Epoch[86/1000] loss: 0.16425237673170426
I0419 10:13:03.421508 28972 trainer.py:139] Epoch[87/1000] loss: 0.16206873339765213
I0419 10:13:09.270838 28972 trainer.py:139] Epoch[88/1000] loss: 0.1617787348873475
I0419 10:13:15.070230 28972 trainer.py:139] Epoch[89/1000] loss: 0.1617388549972983
I0419 10:13:23.450393 28972 trainer.py:139] Epoch[90/1000] loss: 0.1611510190893622
I0419 10:13:29.322178 28972 trainer.py:139] Epoch[91/1000] loss: 0.16084416911882513
I0419 10:13:36.035606 28972 trainer.py:139] Epoch[92/1000] loss: 0.1597843529546962
I0419 10:13:43.614935 28972 trainer.py:139] Epoch[93/1000] loss: 0.1592176872141221
I0419 10:13:49.601528 28972 trainer.py:139] Epoch[94/1000] loss: 0.15784646570682526
I0419 10:13:58.275480 28972 trainer.py:139] Epoch[95/1000] loss: 0.15580874067895553
I0419 10:14:04.105411 28972 trainer.py:139] Epoch[96/1000] loss: 0.15800606327898362
I0419 10:14:11.498240 28972 trainer.py:139] Epoch[97/1000] loss: 0.15551792172824636
I0419 10:14:18.644254 28972 trainer.py:139] Epoch[98/1000] loss: 0.15504217586096594
I0419 10:14:24.407334 28972 trainer.py:139] Epoch[99/1000] loss: 0.15364997965448043
I0419 10:14:25.187474 28972 trainer.py:145] Test: [{'precision': 0.011540075535039872, 'recall': 0.14731147879490308, 'hit_ratio': 0.22073017205203524, 'ndcg': 0.07062970736477697}]
I0419 10:14:33.284062 28972 trainer.py:139] Epoch[100/1000] loss: 0.1533311360022601
I0419 10:14:39.131263 28972 trainer.py:139] Epoch[101/1000] loss: 0.15301978500450358
I0419 10:14:44.667231 28972 trainer.py:139] Epoch[102/1000] loss: 0.15453615521683411
I0419 10:14:52.853551 28972 trainer.py:139] Epoch[103/1000] loss: 0.152230985900935
I0419 10:14:59.084108 28972 trainer.py:139] Epoch[104/1000] loss: 0.15154070012709675
I0419 10:15:06.225929 28972 trainer.py:139] Epoch[105/1000] loss: 0.1486292244756923
I0419 10:15:13.204208 28972 trainer.py:139] Epoch[106/1000] loss: 0.1507373539840474
I0419 10:15:19.153570 28972 trainer.py:139] Epoch[107/1000] loss: 0.15023548638119416
I0419 10:15:27.454560 28972 trainer.py:139] Epoch[108/1000] loss: 0.14831467761712916
I0419 10:15:33.241745 28972 trainer.py:139] Epoch[109/1000] loss: 0.14715633409864762
I0419 10:15:39.031343 28972 trainer.py:139] Epoch[110/1000] loss: 0.1471730698557461
I0419 10:15:47.254286 28972 trainer.py:139] Epoch[111/1000] loss: 0.14787819367997787
I0419 10:15:52.971571 28972 trainer.py:139] Epoch[112/1000] loss: 0.14573671712594874
I0419 10:15:59.033750 28972 trainer.py:139] Epoch[113/1000] loss: 0.14792013694258296
I0419 10:16:07.422067 28972 trainer.py:139] Epoch[114/1000] loss: 0.1467091581400703
I0419 10:16:13.308231 28972 trainer.py:139] Epoch[115/1000] loss: 0.1449789212030523
I0419 10:16:19.861833 28972 trainer.py:139] Epoch[116/1000] loss: 0.14437618588700013
I0419 10:16:27.289260 28972 trainer.py:139] Epoch[117/1000] loss: 0.14348667246453903
I0419 10:16:33.340426 28972 trainer.py:139] Epoch[118/1000] loss: 0.14392554935287027
I0419 10:16:41.713029 28972 trainer.py:139] Epoch[119/1000] loss: 0.14233066053951487
I0419 10:16:47.687480 28972 trainer.py:139] Epoch[120/1000] loss: 0.14372494027895086
I0419 10:16:54.171806 28972 trainer.py:139] Epoch[121/1000] loss: 0.14140189921154694
I0419 10:17:02.483062 28972 trainer.py:139] Epoch[122/1000] loss: 0.1419701462282854
I0419 10:17:08.201432 28972 trainer.py:139] Epoch[123/1000] loss: 0.14114105175523198
I0419 10:17:15.224058 28972 trainer.py:139] Epoch[124/1000] loss: 0.14148333318093242
I0419 10:17:22.497032 28972 trainer.py:139] Epoch[125/1000] loss: 0.1382908943821402
I0419 10:17:28.145165 28972 trainer.py:139] Epoch[126/1000] loss: 0.13970823147717645
I0419 10:17:36.481070 28972 trainer.py:139] Epoch[127/1000] loss: 0.13897178628865411
I0419 10:17:42.459433 28972 trainer.py:139] Epoch[128/1000] loss: 0.13761913513436036
I0419 10:17:48.608875 28972 trainer.py:139] Epoch[129/1000] loss: 0.13854462258956013
I0419 10:17:57.090643 28972 trainer.py:139] Epoch[130/1000] loss: 0.13765750562443452
I0419 10:18:02.957457 28972 trainer.py:139] Epoch[131/1000] loss: 0.1369295821470373
I0419 10:18:08.718060 28972 trainer.py:139] Epoch[132/1000] loss: 0.13576225410489476
I0419 10:18:17.863538 28972 trainer.py:139] Epoch[133/1000] loss: 0.137332401731435
I0419 10:18:23.657568 28972 trainer.py:139] Epoch[134/1000] loss: 0.13495271258494435
I0419 10:18:32.241155 28972 trainer.py:139] Epoch[135/1000] loss: 0.13527562688378728
I0419 10:18:38.066332 28972 trainer.py:139] Epoch[136/1000] loss: 0.13593745932859533
I0419 10:18:43.687613 28972 trainer.py:139] Epoch[137/1000] loss: 0.1362262420794543
I0419 10:18:51.909781 28972 trainer.py:139] Epoch[138/1000] loss: 0.13373423280084834
I0419 10:18:57.567187 28972 trainer.py:139] Epoch[139/1000] loss: 0.13348162437186523
I0419 10:19:03.398693 28972 trainer.py:139] Epoch[140/1000] loss: 0.13356303993393392
I0419 10:19:12.064452 28972 trainer.py:139] Epoch[141/1000] loss: 0.13343146092751446
I0419 10:19:17.823581 28972 trainer.py:139] Epoch[142/1000] loss: 0.13211216120158925
I0419 10:19:24.547167 28972 trainer.py:139] Epoch[143/1000] loss: 0.13150719509405248
I0419 10:19:31.892155 28972 trainer.py:139] Epoch[144/1000] loss: 0.1303600971313084
I0419 10:19:37.708089 28972 trainer.py:139] Epoch[145/1000] loss: 0.13104985259911595
I0419 10:19:46.534683 28972 trainer.py:139] Epoch[146/1000] loss: 0.1309475276400061
I0419 10:19:52.390716 28972 trainer.py:139] Epoch[147/1000] loss: 0.129801547702621
I0419 10:19:58.018809 28972 trainer.py:139] Epoch[148/1000] loss: 0.1312876019407721
I0419 10:20:05.092232 28972 trainer.py:139] Epoch[149/1000] loss: 0.13003971559159896
I0419 10:20:05.867298 28972 trainer.py:145] Test: [{'precision': 0.011980696600923211, 'recall': 0.15206339214941816, 'hit_ratio': 0.22744439781787662, 'ndcg': 0.072972522610401}]
I0419 10:20:12.272462 28972 trainer.py:139] Epoch[150/1000] loss: 0.12968922143473344
I0419 10:20:18.094975 28972 trainer.py:139] Epoch[151/1000] loss: 0.12868855455342462
I0419 10:20:26.432865 28972 trainer.py:139] Epoch[152/1000] loss: 0.12886661291122437
I0419 10:20:32.281450 28972 trainer.py:139] Epoch[153/1000] loss: 0.12880715683979146
I0419 10:20:40.429552 28972 trainer.py:139] Epoch[154/1000] loss: 0.12729767929105198
I0419 10:20:46.594315 28972 trainer.py:139] Epoch[155/1000] loss: 0.12766314867664785
I0419 10:20:52.346546 28972 trainer.py:139] Epoch[156/1000] loss: 0.126294286812053
I0419 10:21:00.775227 28972 trainer.py:139] Epoch[157/1000] loss: 0.1257502169293516
I0419 10:21:06.739841 28972 trainer.py:139] Epoch[158/1000] loss: 0.12489436917445239
I0419 10:21:13.207582 28972 trainer.py:139] Epoch[159/1000] loss: 0.12517846901627147
I0419 10:21:21.060290 28972 trainer.py:139] Epoch[160/1000] loss: 0.12473275293322171
I0419 10:21:26.775840 28972 trainer.py:139] Epoch[161/1000] loss: 0.12486961045685936
I0419 10:21:32.539719 28972 trainer.py:139] Epoch[162/1000] loss: 0.12395966754240148
I0419 10:21:40.624291 28972 trainer.py:139] Epoch[163/1000] loss: 0.12341327176374547
I0419 10:21:46.422806 28972 trainer.py:139] Epoch[164/1000] loss: 0.12379758717382655
I0419 10:21:53.869020 28972 trainer.py:139] Epoch[165/1000] loss: 0.12311502063975614
I0419 10:22:00.639589 28972 trainer.py:139] Epoch[166/1000] loss: 0.1218378565767232
I0419 10:22:06.411658 28972 trainer.py:139] Epoch[167/1000] loss: 0.12254478081184275
I0419 10:22:13.606620 28972 trainer.py:139] Epoch[168/1000] loss: 0.12207873340915232
I0419 10:22:20.130678 28972 trainer.py:139] Epoch[169/1000] loss: 0.12161773618529825
I0419 10:22:25.872098 28972 trainer.py:139] Epoch[170/1000] loss: 0.12161112269934486
I0419 10:22:33.362650 28972 trainer.py:139] Epoch[171/1000] loss: 0.12094073260531706
I0419 10:22:39.816573 28972 trainer.py:139] Epoch[172/1000] loss: 0.12136121576323229
I0419 10:22:45.819427 28972 trainer.py:139] Epoch[173/1000] loss: 0.11959749284912558
I0419 10:22:53.928999 28972 trainer.py:139] Epoch[174/1000] loss: 0.11945938012179207
I0419 10:22:59.765265 28972 trainer.py:139] Epoch[175/1000] loss: 0.12025322063880808
I0419 10:23:05.600132 28972 trainer.py:139] Epoch[176/1000] loss: 0.12016068661914152
I0419 10:23:13.710008 28972 trainer.py:139] Epoch[177/1000] loss: 0.1198275155004333
I0419 10:23:19.302722 28972 trainer.py:139] Epoch[178/1000] loss: 0.11847462855717715
I0419 10:23:24.977557 28972 trainer.py:139] Epoch[179/1000] loss: 0.11714352141408359
I0419 10:23:33.367619 28972 trainer.py:139] Epoch[180/1000] loss: 0.11693869925597135
I0419 10:23:39.027616 28972 trainer.py:139] Epoch[181/1000] loss: 0.11709854094421163
I0419 10:23:45.493685 28972 trainer.py:139] Epoch[182/1000] loss: 0.11656689512379029
I0419 10:23:53.196130 28972 trainer.py:139] Epoch[183/1000] loss: 0.115847989478532
I0419 10:23:58.925872 28972 trainer.py:139] Epoch[184/1000] loss: 0.11606268584728241
I0419 10:24:06.509331 28972 trainer.py:139] Epoch[185/1000] loss: 0.1163007849279572
I0419 10:24:13.129993 28972 trainer.py:139] Epoch[186/1000] loss: 0.11445986391866908
I0419 10:24:19.081499 28972 trainer.py:139] Epoch[187/1000] loss: 0.11561283118584577
I0419 10:24:27.006775 28972 trainer.py:139] Epoch[188/1000] loss: 0.11536028937381856
I0419 10:24:33.151449 28972 trainer.py:139] Epoch[189/1000] loss: 0.11493522147921954
I0419 10:24:38.826881 28972 trainer.py:139] Epoch[190/1000] loss: 0.11527213804862078
I0419 10:24:47.015543 28972 trainer.py:139] Epoch[191/1000] loss: 0.11414205677369062
I0419 10:24:52.749718 28972 trainer.py:139] Epoch[192/1000] loss: 0.11294782687635983
I0419 10:24:58.461678 28972 trainer.py:139] Epoch[193/1000] loss: 0.11490553573650472
I0419 10:25:06.902763 28972 trainer.py:139] Epoch[194/1000] loss: 0.11343192572102827
I0419 10:25:12.799575 28972 trainer.py:139] Epoch[195/1000] loss: 0.11398805502582998
I0419 10:25:18.731818 28972 trainer.py:139] Epoch[196/1000] loss: 0.11421419811599395
I0419 10:25:26.968259 28972 trainer.py:139] Epoch[197/1000] loss: 0.11242344361894271
I0419 10:25:32.561931 28972 trainer.py:139] Epoch[198/1000] loss: 0.11167000891531215
I0419 10:25:38.343279 28972 trainer.py:139] Epoch[199/1000] loss: 0.11241610523532419
I0419 10:25:39.135952 28972 trainer.py:145] Test: [{'precision': 0.012127570289550993, 'recall': 0.1547221056558027, 'hit_ratio': 0.22912295425933696, 'ndcg': 0.074307623777238}]
I0419 10:25:47.336347 28972 trainer.py:139] Epoch[200/1000] loss: 0.11225473267190597
I0419 10:25:53.077045 28972 trainer.py:139] Epoch[201/1000] loss: 0.11195946747765821
I0419 10:25:58.671703 28972 trainer.py:139] Epoch[202/1000] loss: 0.111117583425606
I0419 10:26:06.854588 28972 trainer.py:139] Epoch[203/1000] loss: 0.11053893276873757
I0419 10:26:12.545619 28972 trainer.py:139] Epoch[204/1000] loss: 0.11203783882014892
I0419 10:26:18.441126 28972 trainer.py:139] Epoch[205/1000] loss: 0.11022189259529114
I0419 10:26:26.778570 28972 trainer.py:139] Epoch[206/1000] loss: 0.10974094753756243
I0419 10:26:32.560543 28972 trainer.py:139] Epoch[207/1000] loss: 0.1091795909930678
I0419 10:26:38.444617 28972 trainer.py:139] Epoch[208/1000] loss: 0.10867927968502045
I0419 10:26:46.703220 28972 trainer.py:139] Epoch[209/1000] loss: 0.10964430868625641
I0419 10:26:52.499517 28972 trainer.py:139] Epoch[210/1000] loss: 0.10828552921028699
I0419 10:26:59.809814 28972 trainer.py:139] Epoch[211/1000] loss: 0.10828016303917941
I0419 10:27:06.943991 28972 trainer.py:139] Epoch[212/1000] loss: 0.10783963036887786
I0419 10:27:12.950306 28972 trainer.py:139] Epoch[213/1000] loss: 0.1081958334235584
I0419 10:27:21.896844 28972 trainer.py:139] Epoch[214/1000] loss: 0.10830010780516793
I0419 10:27:27.786954 28972 trainer.py:139] Epoch[215/1000] loss: 0.10812757076585994
I0419 10:27:36.315638 28972 trainer.py:139] Epoch[216/1000] loss: 0.10747844287577797
I0419 10:27:42.290632 28972 trainer.py:139] Epoch[217/1000] loss: 0.10573492418317233
I0419 10:27:49.408411 28972 trainer.py:139] Epoch[218/1000] loss: 0.10575898254618925
I0419 10:27:56.641802 28972 trainer.py:139] Epoch[219/1000] loss: 0.1046514423454509
I0419 10:28:02.540597 28972 trainer.py:139] Epoch[220/1000] loss: 0.10467715386082144
I0419 10:28:10.854686 28972 trainer.py:139] Epoch[221/1000] loss: 0.10562549005536472
I0419 10:28:17.207640 28972 trainer.py:139] Epoch[222/1000] loss: 0.1044132814687841
I0419 10:28:22.963623 28972 trainer.py:139] Epoch[223/1000] loss: 0.10550057668896283
I0419 10:28:31.368524 28972 trainer.py:139] Epoch[224/1000] loss: 0.10579845133949728
I0419 10:28:36.975574 28972 trainer.py:139] Epoch[225/1000] loss: 0.10654886592836942
I0419 10:28:42.754862 28972 trainer.py:139] Epoch[226/1000] loss: 0.10455952058820163
I0419 10:28:50.799593 28972 trainer.py:139] Epoch[227/1000] loss: 0.10427538130213232
I0419 10:28:56.587665 28972 trainer.py:139] Epoch[228/1000] loss: 0.10491318387143753
I0419 10:29:02.280178 28972 trainer.py:139] Epoch[229/1000] loss: 0.1042592911159291
I0419 10:29:10.398770 28972 trainer.py:139] Epoch[230/1000] loss: 0.10319441031007205
I0419 10:29:16.206853 28972 trainer.py:139] Epoch[231/1000] loss: 0.10488622723256841
I0419 10:29:21.990813 28972 trainer.py:139] Epoch[232/1000] loss: 0.10389455188723172
I0419 10:29:30.302649 28972 trainer.py:139] Epoch[233/1000] loss: 0.10323971378452637
I0419 10:29:36.043719 28972 trainer.py:139] Epoch[234/1000] loss: 0.10196674089221393
I0419 10:29:41.865637 28972 trainer.py:139] Epoch[235/1000] loss: 0.10240612266694799
I0419 10:29:50.254000 28972 trainer.py:139] Epoch[236/1000] loss: 0.10219982354079976
I0419 10:29:56.115894 28972 trainer.py:139] Epoch[237/1000] loss: 0.10208088773138382
I0419 10:30:01.958693 28972 trainer.py:139] Epoch[238/1000] loss: 0.1018125090528937
I0419 10:30:10.169826 28972 trainer.py:139] Epoch[239/1000] loss: 0.10309134029290255
I0419 10:30:16.044161 28972 trainer.py:139] Epoch[240/1000] loss: 0.10253534772816826
I0419 10:30:21.887954 28972 trainer.py:139] Epoch[241/1000] loss: 0.10239955914371154
I0419 10:30:30.006461 28972 trainer.py:139] Epoch[242/1000] loss: 0.10083430830170126
I0419 10:30:35.938173 28972 trainer.py:139] Epoch[243/1000] loss: 0.10106106847524643
I0419 10:30:41.616627 28972 trainer.py:139] Epoch[244/1000] loss: 0.0999928997719989
I0419 10:30:50.140563 28972 trainer.py:139] Epoch[245/1000] loss: 0.1004437094225603
I0419 10:30:55.873250 28972 trainer.py:139] Epoch[246/1000] loss: 0.10150841667371638
I0419 10:31:01.791855 28972 trainer.py:139] Epoch[247/1000] loss: 0.10001986123183194
I0419 10:31:10.408302 28972 trainer.py:139] Epoch[248/1000] loss: 0.10069454636643915
I0419 10:31:16.089303 28972 trainer.py:139] Epoch[249/1000] loss: 0.10076126806876239
I0419 10:31:16.770591 28972 trainer.py:145] Test: [{'precision': 0.012295425933697025, 'recall': 0.15755866621372286, 'hit_ratio': 0.23289970625262274, 'ndcg': 0.07641127844071972}]
I0419 10:31:22.502372 28972 trainer.py:139] Epoch[250/1000] loss: 0.10082626342773438
I0419 10:31:31.103297 28972 trainer.py:139] Epoch[251/1000] loss: 0.10029596966855667
I0419 10:31:36.791823 28972 trainer.py:139] Epoch[252/1000] loss: 0.09865336426917244
I0419 10:31:42.727299 28972 trainer.py:139] Epoch[253/1000] loss: 0.09989549920839422
I0419 10:31:51.133412 28972 trainer.py:139] Epoch[254/1000] loss: 0.0989073997034746
I0419 10:31:57.047470 28972 trainer.py:139] Epoch[255/1000] loss: 0.09873543416752535
I0419 10:32:02.951793 28972 trainer.py:139] Epoch[256/1000] loss: 0.09634388720287997
I0419 10:32:11.210304 28972 trainer.py:139] Epoch[257/1000] loss: 0.09939493019791211
I0419 10:32:17.078771 28972 trainer.py:139] Epoch[258/1000] loss: 0.09700451353017021
I0419 10:32:22.866308 28972 trainer.py:139] Epoch[259/1000] loss: 0.09758154609624077
I0419 10:32:31.126632 28972 trainer.py:139] Epoch[260/1000] loss: 0.09653887985383763
I0419 10:32:37.088304 28972 trainer.py:139] Epoch[261/1000] loss: 0.0975847971789977
I0419 10:32:42.923837 28972 trainer.py:139] Epoch[262/1000] loss: 0.0974240894703304
I0419 10:32:51.111459 28972 trainer.py:139] Epoch[263/1000] loss: 0.09766768751775518
I0419 10:32:56.904873 28972 trainer.py:139] Epoch[264/1000] loss: 0.0969516139696626
I0419 10:33:02.748255 28972 trainer.py:139] Epoch[265/1000] loss: 0.09793296894606422
I0419 10:33:11.149915 28972 trainer.py:139] Epoch[266/1000] loss: 0.09715219587087631
I0419 10:33:16.778735 28972 trainer.py:139] Epoch[267/1000] loss: 0.09532853478894514
I0419 10:33:22.821656 28972 trainer.py:139] Epoch[268/1000] loss: 0.09644400240743861
I0419 10:33:30.852670 28972 trainer.py:139] Epoch[269/1000] loss: 0.09701045427252264
I0419 10:33:36.764835 28972 trainer.py:139] Epoch[270/1000] loss: 0.09676875305526397
I0419 10:33:42.782022 28972 trainer.py:139] Epoch[271/1000] loss: 0.09518348162665087
I0419 10:33:50.778125 28972 trainer.py:139] Epoch[272/1000] loss: 0.0962824952953002
I0419 10:33:56.696759 28972 trainer.py:139] Epoch[273/1000] loss: 0.0947070581948056
I0419 10:34:03.148910 28972 trainer.py:139] Epoch[274/1000] loss: 0.0954758577487048
I0419 10:34:10.898986 28972 trainer.py:139] Epoch[275/1000] loss: 0.09571030998931211
I0419 10:34:16.802608 28972 trainer.py:139] Epoch[276/1000] loss: 0.0946595822187031
I0419 10:34:23.021203 28972 trainer.py:139] Epoch[277/1000] loss: 0.09551633762962677
I0419 10:34:30.857610 28972 trainer.py:139] Epoch[278/1000] loss: 0.09460941526819677
I0419 10:34:36.687697 28972 trainer.py:139] Epoch[279/1000] loss: 0.09382926541216233
I0419 10:34:43.263694 28972 trainer.py:139] Epoch[280/1000] loss: 0.096168771824416
I0419 10:34:51.024850 28972 trainer.py:139] Epoch[281/1000] loss: 0.09504302196642932
I0419 10:34:56.960214 28972 trainer.py:139] Epoch[282/1000] loss: 0.09449708549415364
I0419 10:35:03.845576 28972 trainer.py:139] Epoch[283/1000] loss: 0.09363043264431112
I0419 10:35:10.883305 28972 trainer.py:139] Epoch[284/1000] loss: 0.0940434976535685
I0419 10:35:16.788949 28972 trainer.py:139] Epoch[285/1000] loss: 0.09385439709705465
I0419 10:35:24.449805 28972 trainer.py:139] Epoch[286/1000] loss: 0.09294413424590055
I0419 10:35:30.946445 28972 trainer.py:139] Epoch[287/1000] loss: 0.0933016762137413
I0419 10:35:36.723545 28972 trainer.py:139] Epoch[288/1000] loss: 0.09284539126298007
I0419 10:35:44.193047 28972 trainer.py:139] Epoch[289/1000] loss: 0.09258097585509806
I0419 10:35:50.930894 28972 trainer.py:139] Epoch[290/1000] loss: 0.09347893516806995
I0419 10:35:56.727855 28972 trainer.py:139] Epoch[291/1000] loss: 0.09214292028371025
I0419 10:36:04.053372 28972 trainer.py:139] Epoch[292/1000] loss: 0.09275647822548361
I0419 10:36:11.130727 28972 trainer.py:139] Epoch[293/1000] loss: 0.09179466480717939
I0419 10:36:16.924356 28972 trainer.py:139] Epoch[294/1000] loss: 0.09144078940153122
I0419 10:36:24.873704 28972 trainer.py:139] Epoch[295/1000] loss: 0.09189307032262578
I0419 10:36:31.098315 28972 trainer.py:139] Epoch[296/1000] loss: 0.0910872913458768
I0419 10:36:36.886404 28972 trainer.py:139] Epoch[297/1000] loss: 0.09160088397124234
I0419 10:36:44.944070 28972 trainer.py:139] Epoch[298/1000] loss: 0.09191074616768781
I0419 10:36:51.081929 28972 trainer.py:139] Epoch[299/1000] loss: 0.09151887981330648
I0419 10:36:51.822021 28972 trainer.py:145] Test: [{'precision': 0.01231640788921528, 'recall': 0.15906870091721118, 'hit_ratio': 0.23248006714225766, 'ndcg': 0.07688417278076932}]
I0419 10:36:57.737618 28972 trainer.py:139] Epoch[300/1000] loss: 0.09117072689182618
I0419 10:37:06.143069 28972 trainer.py:139] Epoch[301/1000] loss: 0.0902814269065857
I0419 10:37:12.024826 28972 trainer.py:139] Epoch[302/1000] loss: 0.09125333191717372
I0419 10:37:17.850558 28972 trainer.py:139] Epoch[303/1000] loss: 0.08993999528534272
I0419 10:37:26.087460 28972 trainer.py:139] Epoch[304/1000] loss: 0.09014568697003757
I0419 10:37:31.887655 28972 trainer.py:139] Epoch[305/1000] loss: 0.08943500764229718
I0419 10:37:37.667344 28972 trainer.py:139] Epoch[306/1000] loss: 0.08922054399462308
I0419 10:37:46.048243 28972 trainer.py:139] Epoch[307/1000] loss: 0.09014261338640661
I0419 10:37:51.954591 28972 trainer.py:139] Epoch[308/1000] loss: 0.0910262412884656
I0419 10:37:58.833830 28972 trainer.py:139] Epoch[309/1000] loss: 0.09001198410987854
I0419 10:38:06.084676 28972 trainer.py:139] Epoch[310/1000] loss: 0.08884264791713041
I0419 10:38:11.664214 28972 trainer.py:139] Epoch[311/1000] loss: 0.08931140163365532
I0419 10:38:19.362704 28972 trainer.py:139] Epoch[312/1000] loss: 0.08957152112441905
I0419 10:38:25.807466 28972 trainer.py:139] Epoch[313/1000] loss: 0.0896465852856636
I0419 10:38:31.708144 28972 trainer.py:139] Epoch[314/1000] loss: 0.088641077718314
I0419 10:38:38.002899 28972 trainer.py:139] Epoch[315/1000] loss: 0.0891572951393969
I0419 10:38:45.546962 28972 trainer.py:139] Epoch[316/1000] loss: 0.0889033911859288
I0419 10:38:51.151321 28972 trainer.py:139] Epoch[317/1000] loss: 0.08899979775442797
I0419 10:38:57.309169 28972 trainer.py:139] Epoch[318/1000] loss: 0.0887870679006857
I0419 10:39:05.053326 28972 trainer.py:139] Epoch[319/1000] loss: 0.08958602740484126
I0419 10:39:10.905849 28972 trainer.py:139] Epoch[320/1000] loss: 0.0884804037563941
I0419 10:39:16.879252 28972 trainer.py:139] Epoch[321/1000] loss: 0.0881107765085557
I0419 10:39:24.968313 28972 trainer.py:139] Epoch[322/1000] loss: 0.08788280057556488
I0419 10:39:30.753336 28972 trainer.py:139] Epoch[323/1000] loss: 0.08786397076704923
I0419 10:39:36.686927 28972 trainer.py:139] Epoch[324/1000] loss: 0.08813536736895056
I0419 10:39:45.101797 28972 trainer.py:139] Epoch[325/1000] loss: 0.08793318666079465
I0419 10:39:50.980713 28972 trainer.py:139] Epoch[326/1000] loss: 0.0874920220059507
I0419 10:39:57.340476 28972 trainer.py:139] Epoch[327/1000] loss: 0.0873527912532582
I0419 10:40:05.135547 28972 trainer.py:139] Epoch[328/1000] loss: 0.08746337759144165
I0419 10:40:11.215734 28972 trainer.py:139] Epoch[329/1000] loss: 0.0883706939571044
I0419 10:40:18.129595 28972 trainer.py:139] Epoch[330/1000] loss: 0.08739039608660866
I0419 10:40:25.246015 28972 trainer.py:139] Epoch[331/1000] loss: 0.08647735153927523
I0419 10:40:31.030224 28972 trainer.py:139] Epoch[332/1000] loss: 0.08752356907900642
I0419 10:40:38.396214 28972 trainer.py:139] Epoch[333/1000] loss: 0.08602083562051549
I0419 10:40:45.354373 28972 trainer.py:139] Epoch[334/1000] loss: 0.08576113073264852
I0419 10:40:51.083935 28972 trainer.py:139] Epoch[335/1000] loss: 0.08606478922507342
I0419 10:40:58.721097 28972 trainer.py:139] Epoch[336/1000] loss: 0.08641378230908338
I0419 10:41:05.078352 28972 trainer.py:139] Epoch[337/1000] loss: 0.08663550019264221
I0419 10:41:10.875406 28972 trainer.py:139] Epoch[338/1000] loss: 0.08627257189329933
I0419 10:41:19.094890 28972 trainer.py:139] Epoch[339/1000] loss: 0.08566899597644806
I0419 10:41:24.825310 28972 trainer.py:139] Epoch[340/1000] loss: 0.08580260197905933
I0419 10:41:30.748775 28972 trainer.py:139] Epoch[341/1000] loss: 0.08650725685498294
I0419 10:41:39.049283 28972 trainer.py:139] Epoch[342/1000] loss: 0.08532926527892842
I0419 10:41:44.901458 28972 trainer.py:139] Epoch[343/1000] loss: 0.08585270231260973
I0419 10:41:50.737646 28972 trainer.py:139] Epoch[344/1000] loss: 0.08581963575938169
I0419 10:41:59.141363 28972 trainer.py:139] Epoch[345/1000] loss: 0.08598728039685417
I0419 10:42:04.957439 28972 trainer.py:139] Epoch[346/1000] loss: 0.08543985862942303
I0419 10:42:10.775072 28972 trainer.py:139] Epoch[347/1000] loss: 0.08470155693152372
I0419 10:42:19.073021 28972 trainer.py:139] Epoch[348/1000] loss: 0.08517508121097789
I0419 10:42:24.968356 28972 trainer.py:139] Epoch[349/1000] loss: 0.08531067827168633
I0419 10:42:25.682524 28972 trainer.py:145] Test: [{'precision': 0.012819974821653382, 'recall': 0.1644680574705753, 'hit_ratio': 0.24129248845992446, 'ndcg': 0.07800899513234275}]
I0419 10:42:33.358968 28972 trainer.py:139] Epoch[350/1000] loss: 0.08467856137191548
I0419 10:42:39.801869 28972 trainer.py:139] Epoch[351/1000] loss: 0.08562768864281037
I0419 10:42:45.594842 28972 trainer.py:139] Epoch[352/1000] loss: 0.08478363953969058
I0419 10:42:53.887851 28972 trainer.py:139] Epoch[353/1000] loss: 0.08532719226444468
I0419 10:42:59.554345 28972 trainer.py:139] Epoch[354/1000] loss: 0.08479771061855204
I0419 10:43:05.657893 28972 trainer.py:139] Epoch[355/1000] loss: 0.08396725926329107
I0419 10:43:13.855328 28972 trainer.py:139] Epoch[356/1000] loss: 0.08412192367455538
I0419 10:43:19.751490 28972 trainer.py:139] Epoch[357/1000] loss: 0.08426785732016843
I0419 10:43:25.741797 28972 trainer.py:139] Epoch[358/1000] loss: 0.08361108250477735
I0419 10:43:33.901269 28972 trainer.py:139] Epoch[359/1000] loss: 0.08445339386954027
I0419 10:43:39.595576 28972 trainer.py:139] Epoch[360/1000] loss: 0.0831004517043338
I0419 10:43:45.554025 28972 trainer.py:139] Epoch[361/1000] loss: 0.0831776664537542
I0419 10:43:53.379446 28972 trainer.py:139] Epoch[362/1000] loss: 0.08318810997640386
I0419 10:43:58.959578 28972 trainer.py:139] Epoch[363/1000] loss: 0.08336922701667338
I0419 10:44:05.524355 28972 trainer.py:139] Epoch[364/1000] loss: 0.08295285219655317
I0419 10:44:13.066748 28972 trainer.py:139] Epoch[365/1000] loss: 0.08340975905165952
I0419 10:44:18.919160 28972 trainer.py:139] Epoch[366/1000] loss: 0.08242311766918968
I0419 10:44:25.658691 28972 trainer.py:139] Epoch[367/1000] loss: 0.0842237840680515
I0419 10:44:32.839399 28972 trainer.py:139] Epoch[368/1000] loss: 0.08229709548108718
I0419 10:44:38.693757 28972 trainer.py:139] Epoch[369/1000] loss: 0.08282898059662651
I0419 10:44:46.795966 28972 trainer.py:139] Epoch[370/1000] loss: 0.08249206840991974
I0419 10:44:52.717178 28972 trainer.py:139] Epoch[371/1000] loss: 0.08279118467779721
I0419 10:44:58.362718 28972 trainer.py:139] Epoch[372/1000] loss: 0.08322926917496849
I0419 10:45:06.516373 28972 trainer.py:139] Epoch[373/1000] loss: 0.08349049836397171
I0419 10:45:12.442911 28972 trainer.py:139] Epoch[374/1000] loss: 0.08296940168913673
I0419 10:45:18.129661 28972 trainer.py:139] Epoch[375/1000] loss: 0.08343151387046366
I0419 10:45:26.513219 28972 trainer.py:139] Epoch[376/1000] loss: 0.082443167181576
I0419 10:45:32.522012 28972 trainer.py:139] Epoch[377/1000] loss: 0.08205133808009765
I0419 10:45:38.448698 28972 trainer.py:139] Epoch[378/1000] loss: 0.08248244576594409
I0419 10:45:46.535924 28972 trainer.py:139] Epoch[379/1000] loss: 0.08126650969771777
I0419 10:45:52.436554 28972 trainer.py:139] Epoch[380/1000] loss: 0.08323943746440551
I0419 10:45:58.096947 28972 trainer.py:139] Epoch[381/1000] loss: 0.08170939105398514
I0419 10:46:06.369954 28972 trainer.py:139] Epoch[382/1000] loss: 0.0815006880199208
I0419 10:46:12.162057 28972 trainer.py:139] Epoch[383/1000] loss: 0.08146989959127762
I0419 10:46:17.991962 28972 trainer.py:139] Epoch[384/1000] loss: 0.08204845119925107
I0419 10:46:26.387354 28972 trainer.py:139] Epoch[385/1000] loss: 0.08106655233046588
I0419 10:46:32.262229 28972 trainer.py:139] Epoch[386/1000] loss: 0.08039832991712234
I0419 10:46:38.023802 28972 trainer.py:139] Epoch[387/1000] loss: 0.08072740058688556
I0419 10:46:46.343601 28972 trainer.py:139] Epoch[388/1000] loss: 0.08130423198728
I0419 10:46:52.190393 28972 trainer.py:139] Epoch[389/1000] loss: 0.08042416546274633
I0419 10:46:57.888207 28972 trainer.py:139] Epoch[390/1000] loss: 0.07992526582058739
I0419 10:47:06.022701 28972 trainer.py:139] Epoch[391/1000] loss: 0.0804144840906648
I0419 10:47:11.742003 28972 trainer.py:139] Epoch[392/1000] loss: 0.08095302432775497
I0419 10:47:17.570531 28972 trainer.py:139] Epoch[393/1000] loss: 0.08046356807736789
I0419 10:47:26.012088 28972 trainer.py:139] Epoch[394/1000] loss: 0.08100518014501124
I0419 10:47:31.797993 28972 trainer.py:139] Epoch[395/1000] loss: 0.08070032035603243
I0419 10:47:37.442988 28972 trainer.py:139] Epoch[396/1000] loss: 0.08055663985364578
I0419 10:47:45.751112 28972 trainer.py:139] Epoch[397/1000] loss: 0.08011091982617098
I0419 10:47:51.430447 28972 trainer.py:139] Epoch[398/1000] loss: 0.08080308051670299
I0419 10:47:57.195571 28972 trainer.py:139] Epoch[399/1000] loss: 0.07986574707662358
I0419 10:47:57.929118 28972 trainer.py:145] Test: [{'precision': 0.012715065044062113, 'recall': 0.1622766087831132, 'hit_ratio': 0.23835501468736886, 'ndcg': 0.07787654065489744}]
I0419 10:48:05.975792 28972 trainer.py:139] Epoch[400/1000] loss: 0.08044923973434112
I0419 10:48:11.816731 28972 trainer.py:139] Epoch[401/1000] loss: 0.07990972522427053
I0419 10:48:18.196300 28972 trainer.py:139] Epoch[402/1000] loss: 0.0798149783821667
I0419 10:48:26.177086 28972 trainer.py:139] Epoch[403/1000] loss: 0.07951995467438418
I0419 10:48:32.108916 28972 trainer.py:139] Epoch[404/1000] loss: 0.0817649013855878
I0419 10:48:38.809495 28972 trainer.py:139] Epoch[405/1000] loss: 0.07898754538858638
I0419 10:48:46.375846 28972 trainer.py:139] Epoch[406/1000] loss: 0.07936811359489665
I0419 10:48:52.297433 28972 trainer.py:139] Epoch[407/1000] loss: 0.08044486361391404
I0419 10:48:59.081189 28972 trainer.py:139] Epoch[408/1000] loss: 0.08021586958099813
I0419 10:49:06.171083 28972 trainer.py:139] Epoch[409/1000] loss: 0.07893205960007275
I0419 10:49:12.096093 28972 trainer.py:139] Epoch[410/1000] loss: 0.07912338393576004
I0419 10:49:19.273161 28972 trainer.py:139] Epoch[411/1000] loss: 0.08058726349297692
I0419 10:49:26.173105 28972 trainer.py:139] Epoch[412/1000] loss: 0.07921711881371106
I0419 10:49:32.100039 28972 trainer.py:139] Epoch[413/1000] loss: 0.07994066529414233
I0419 10:49:38.654117 28972 trainer.py:139] Epoch[414/1000] loss: 0.0800400972366333
I0419 10:49:46.364170 28972 trainer.py:139] Epoch[415/1000] loss: 0.07803449078517802
I0419 10:49:52.082968 28972 trainer.py:139] Epoch[416/1000] loss: 0.07797507415799533
I0419 10:49:58.234328 28972 trainer.py:139] Epoch[417/1000] loss: 0.07892165552167331
I0419 10:50:05.968774 28972 trainer.py:139] Epoch[418/1000] loss: 0.07980724687085432
I0419 10:50:11.771773 28972 trainer.py:139] Epoch[419/1000] loss: 0.07961725618909388
I0419 10:50:18.918332 28972 trainer.py:139] Epoch[420/1000] loss: 0.07891280204057693
I0419 10:50:25.907436 28972 trainer.py:139] Epoch[421/1000] loss: 0.07716732603662155
I0419 10:50:31.709481 28972 trainer.py:139] Epoch[422/1000] loss: 0.0782872745219399
I0419 10:50:39.186203 28972 trainer.py:139] Epoch[423/1000] loss: 0.0791178591111127
I0419 10:50:45.805054 28972 trainer.py:139] Epoch[424/1000] loss: 0.07744563721558627
I0419 10:50:51.437445 28972 trainer.py:139] Epoch[425/1000] loss: 0.07857540074516745
I0419 10:50:59.188613 28972 trainer.py:139] Epoch[426/1000] loss: 0.07899897764710818
I0419 10:51:05.707239 28972 trainer.py:139] Epoch[427/1000] loss: 0.07794257691677879
I0419 10:51:11.374634 28972 trainer.py:139] Epoch[428/1000] loss: 0.07784974399734945
I0419 10:51:19.486078 28972 trainer.py:139] Epoch[429/1000] loss: 0.07802569340257083
I0419 10:51:25.508490 28972 trainer.py:139] Epoch[430/1000] loss: 0.07815124795717351
I0419 10:51:31.321562 28972 trainer.py:139] Epoch[431/1000] loss: 0.07821226032341227
I0419 10:51:39.430970 28972 trainer.py:139] Epoch[432/1000] loss: 0.07857024406685549
I0419 10:51:45.712773 28972 trainer.py:139] Epoch[433/1000] loss: 0.07672555613167145
I0419 10:51:51.466446 28972 trainer.py:139] Epoch[434/1000] loss: 0.0784637665047365
I0419 10:51:59.911117 28972 trainer.py:139] Epoch[435/1000] loss: 0.07759078504408107
I0419 10:52:05.691697 28972 trainer.py:139] Epoch[436/1000] loss: 0.07750914684113334
I0419 10:52:11.409679 28972 trainer.py:139] Epoch[437/1000] loss: 0.07684527074589449
I0419 10:52:19.923764 28972 trainer.py:139] Epoch[438/1000] loss: 0.07783472143551882
I0419 10:52:25.672118 28972 trainer.py:139] Epoch[439/1000] loss: 0.07752291682888479
I0419 10:52:31.449346 28972 trainer.py:139] Epoch[440/1000] loss: 0.07678378241903641
I0419 10:52:39.826461 28972 trainer.py:139] Epoch[441/1000] loss: 0.07793550149482839
I0419 10:52:45.717913 28972 trainer.py:139] Epoch[442/1000] loss: 0.07707938858691384
I0419 10:52:51.436165 28972 trainer.py:139] Epoch[443/1000] loss: 0.07710790195885826
I0419 10:52:59.788094 28972 trainer.py:139] Epoch[444/1000] loss: 0.07766635014730341
I0419 10:53:05.575013 28972 trainer.py:139] Epoch[445/1000] loss: 0.07811211619307012
I0419 10:53:11.721008 28972 trainer.py:139] Epoch[446/1000] loss: 0.07740749024293002
I0419 10:53:19.566523 28972 trainer.py:139] Epoch[447/1000] loss: 0.07712328346336589
I0419 10:53:25.404435 28972 trainer.py:139] Epoch[448/1000] loss: 0.07758458966718
I0419 10:53:32.461339 28972 trainer.py:139] Epoch[449/1000] loss: 0.07675830143339493
I0419 10:53:33.293136 28972 trainer.py:145] Test: [{'precision': 0.012819974821653384, 'recall': 0.1641300148538923, 'hit_ratio': 0.2404532102391943, 'ndcg': 0.07793647832658776}]
I0419 10:53:39.979240 28972 trainer.py:139] Epoch[450/1000] loss: 0.07659030267420937
I0419 10:53:45.739301 28972 trainer.py:139] Epoch[451/1000] loss: 0.0770048052072525
I0419 10:53:53.434480 28972 trainer.py:139] Epoch[452/1000] loss: 0.07648758677875295
I0419 10:53:59.968210 28972 trainer.py:139] Epoch[453/1000] loss: 0.07638045181246365
I0419 10:54:05.774201 28972 trainer.py:139] Epoch[454/1000] loss: 0.07699456635643454
I0419 10:54:14.030094 28972 trainer.py:139] Epoch[455/1000] loss: 0.076475107932792
I0419 10:54:20.075082 28972 trainer.py:139] Epoch[456/1000] loss: 0.0772341161089785
I0419 10:54:25.783352 28972 trainer.py:139] Epoch[457/1000] loss: 0.07591054544729345
I0419 10:54:34.346008 28972 trainer.py:139] Epoch[458/1000] loss: 0.0756721448372392
I0419 10:54:40.081816 28972 trainer.py:139] Epoch[459/1000] loss: 0.0757239662549075
I0419 10:54:45.818204 28972 trainer.py:139] Epoch[460/1000] loss: 0.07636093129129971
I0419 10:54:54.221287 28972 trainer.py:139] Epoch[461/1000] loss: 0.07596681661465589
I0419 10:55:00.210987 28972 trainer.py:139] Epoch[462/1000] loss: 0.07601255353759317
I0419 10:55:06.302608 28972 trainer.py:139] Epoch[463/1000] loss: 0.07574823542552836
I0419 10:55:14.679230 28972 trainer.py:139] Epoch[464/1000] loss: 0.07637323921217638
I0419 10:55:20.579055 28972 trainer.py:139] Epoch[465/1000] loss: 0.07565655252512764
I0419 10:55:26.925630 28972 trainer.py:139] Epoch[466/1000] loss: 0.07504635830135907
I0419 10:55:34.982182 28972 trainer.py:139] Epoch[467/1000] loss: 0.07561132881571264
I0419 10:55:40.714006 28972 trainer.py:139] Epoch[468/1000] loss: 0.07521053754231509
I0419 10:55:47.214233 28972 trainer.py:139] Epoch[469/1000] loss: 0.07545985807390775
I0419 10:55:55.074992 28972 trainer.py:139] Epoch[470/1000] loss: 0.07502232667277842
I0419 10:56:00.956430 28972 trainer.py:139] Epoch[471/1000] loss: 0.07464699490981944
I0419 10:56:07.809537 28972 trainer.py:139] Epoch[472/1000] loss: 0.07503740445655935
I0419 10:56:14.936777 28972 trainer.py:139] Epoch[473/1000] loss: 0.07560537185739069
I0419 10:56:20.608893 28972 trainer.py:139] Epoch[474/1000] loss: 0.07482040191397947
I0419 10:56:28.668893 28972 trainer.py:139] Epoch[475/1000] loss: 0.07516130059957504
I0419 10:56:34.668844 28972 trainer.py:139] Epoch[476/1000] loss: 0.0742427242152831
I0419 10:56:40.238545 28972 trainer.py:139] Epoch[477/1000] loss: 0.07568613878067802
I0419 10:56:48.644300 28972 trainer.py:139] Epoch[478/1000] loss: 0.07508836949572843
I0419 10:56:54.454740 28972 trainer.py:139] Epoch[479/1000] loss: 0.07453925118726842
I0419 10:57:00.145048 28972 trainer.py:139] Epoch[480/1000] loss: 0.07499024885542252
I0419 10:57:08.660687 28972 trainer.py:139] Epoch[481/1000] loss: 0.07493988249231787
I0419 10:57:14.421512 28972 trainer.py:139] Epoch[482/1000] loss: 0.07475969940423965
I0419 10:57:20.076499 28972 trainer.py:139] Epoch[483/1000] loss: 0.07408275718198103
I0419 10:57:28.410936 28972 trainer.py:139] Epoch[484/1000] loss: 0.0748035605339443
I0419 10:57:34.205060 28972 trainer.py:139] Epoch[485/1000] loss: 0.07490002670708824
I0419 10:57:40.005257 28972 trainer.py:139] Epoch[486/1000] loss: 0.07433963742326288
I0419 10:57:48.510379 28972 trainer.py:139] Epoch[487/1000] loss: 0.07507864210535498
I0419 10:57:54.410036 28972 trainer.py:139] Epoch[488/1000] loss: 0.07504281576941996
I0419 10:58:00.192160 28972 trainer.py:139] Epoch[489/1000] loss: 0.07442740526269465
I0419 10:58:08.564679 28972 trainer.py:139] Epoch[490/1000] loss: 0.07506079051424475
I0419 10:58:14.256005 28972 trainer.py:139] Epoch[491/1000] loss: 0.07488337246810689
I0419 10:58:19.992639 28972 trainer.py:139] Epoch[492/1000] loss: 0.07376358701902277
I0419 10:58:28.413546 28972 trainer.py:139] Epoch[493/1000] loss: 0.07479371437255074
I0419 10:58:34.286782 28972 trainer.py:139] Epoch[494/1000] loss: 0.07436479759566925
I0419 10:58:40.175203 28972 trainer.py:139] Epoch[495/1000] loss: 0.07385039198047974
I0419 10:58:48.399563 28972 trainer.py:139] Epoch[496/1000] loss: 0.0730944994617911
I0419 10:58:54.098260 28972 trainer.py:139] Epoch[497/1000] loss: 0.0742340854862157
I0419 10:58:59.941187 28972 trainer.py:139] Epoch[498/1000] loss: 0.07428126563044156
I0419 10:59:08.158982 28972 trainer.py:139] Epoch[499/1000] loss: 0.07381133340737399
I0419 10:59:08.896515 28972 trainer.py:145] Test: [{'precision': 0.012840956777171637, 'recall': 0.16451468403839364, 'hit_ratio': 0.24171212757028956, 'ndcg': 0.07887117137410178}]
I0419 10:59:14.714374 28972 trainer.py:139] Epoch[500/1000] loss: 0.07228571877760046
I0419 10:59:20.571855 28972 trainer.py:139] Epoch[501/1000] loss: 0.07274605903555365
I0419 10:59:28.680823 28972 trainer.py:139] Epoch[502/1000] loss: 0.07364677900777143
I0419 10:59:34.542907 28972 trainer.py:139] Epoch[503/1000] loss: 0.07310187904273763
I0419 10:59:40.798458 28972 trainer.py:139] Epoch[504/1000] loss: 0.07358936088926651
I0419 10:59:48.392895 28972 trainer.py:139] Epoch[505/1000] loss: 0.0745804901508724
I0419 10:59:54.088662 28972 trainer.py:139] Epoch[506/1000] loss: 0.07338766446884941
I0419 11:00:00.732414 28972 trainer.py:139] Epoch[507/1000] loss: 0.0741607542423641
I0419 11:00:08.054013 28972 trainer.py:139] Epoch[508/1000] loss: 0.07202621111098458
I0419 11:00:13.912459 28972 trainer.py:139] Epoch[509/1000] loss: 0.07342416398665484
I0419 11:00:21.094312 28972 trainer.py:139] Epoch[510/1000] loss: 0.0728357096805292
I0419 11:00:27.990492 28972 trainer.py:139] Epoch[511/1000] loss: 0.0737598766298855
I0419 11:00:33.760599 28972 trainer.py:139] Epoch[512/1000] loss: 0.07293195408933303
I0419 11:00:40.534228 28972 trainer.py:139] Epoch[513/1000] loss: 0.0725325915743323
I0419 11:00:47.967434 28972 trainer.py:139] Epoch[514/1000] loss: 0.0733075400485712
I0419 11:00:53.807254 28972 trainer.py:139] Epoch[515/1000] loss: 0.07347400486469269
I0419 11:01:02.251395 28972 trainer.py:139] Epoch[516/1000] loss: 0.0737483891494134
I0419 11:01:08.014971 28972 trainer.py:139] Epoch[517/1000] loss: 0.0733134496737929
I0419 11:01:13.798990 28972 trainer.py:139] Epoch[518/1000] loss: 0.07351018269272412
I0419 11:01:22.153301 28972 trainer.py:139] Epoch[519/1000] loss: 0.07240396387436811
I0419 11:01:27.872995 28972 trainer.py:139] Epoch[520/1000] loss: 0.07296451268827214
I0419 11:01:33.719860 28972 trainer.py:139] Epoch[521/1000] loss: 0.07271171448861852
I0419 11:01:42.100227 28972 trainer.py:139] Epoch[522/1000] loss: 0.07229770457043368
I0419 11:01:47.936115 28972 trainer.py:139] Epoch[523/1000] loss: 0.07307245100245756
I0419 11:01:53.769418 28972 trainer.py:139] Epoch[524/1000] loss: 0.07349892749505885
I0419 11:02:02.209383 28972 trainer.py:139] Epoch[525/1000] loss: 0.07253583739785587
I0419 11:02:08.056633 28972 trainer.py:139] Epoch[526/1000] loss: 0.07293662253548117
I0419 11:02:13.867579 28972 trainer.py:139] Epoch[527/1000] loss: 0.0728306152364787
I0419 11:02:22.161584 28972 trainer.py:139] Epoch[528/1000] loss: 0.07322689277284286
I0419 11:02:27.959634 28972 trainer.py:139] Epoch[529/1000] loss: 0.07336699305211797
I0419 11:02:35.079397 28972 trainer.py:139] Epoch[530/1000] loss: 0.07285231045063804
I0419 11:02:42.202477 28972 trainer.py:139] Epoch[531/1000] loss: 0.07227576874634799
I0419 11:02:47.991834 28972 trainer.py:139] Epoch[532/1000] loss: 0.07297000639578875
I0419 11:02:55.271106 28972 trainer.py:139] Epoch[533/1000] loss: 0.07196053862571716
I0419 11:03:02.082797 28972 trainer.py:139] Epoch[534/1000] loss: 0.07231869460905299
I0419 11:03:07.932622 28972 trainer.py:139] Epoch[535/1000] loss: 0.07322641549741521
I0419 11:03:16.051518 28972 trainer.py:139] Epoch[536/1000] loss: 0.07198176576810725
I0419 11:03:22.240615 28972 trainer.py:139] Epoch[537/1000] loss: 0.07151879545520334
I0419 11:03:28.174079 28972 trainer.py:139] Epoch[538/1000] loss: 0.07242877123986974
I0419 11:03:36.684573 28972 trainer.py:139] Epoch[539/1000] loss: 0.07256973052726072
I0419 11:03:42.414875 28972 trainer.py:139] Epoch[540/1000] loss: 0.07119164265253965
I0419 11:03:48.215847 28972 trainer.py:139] Epoch[541/1000] loss: 0.07183901921791189
I0419 11:03:56.563027 28972 trainer.py:139] Epoch[542/1000] loss: 0.0717146032873322
I0419 11:04:02.170300 28972 trainer.py:139] Epoch[543/1000] loss: 0.07230515252141391
I0419 11:04:08.058525 28972 trainer.py:139] Epoch[544/1000] loss: 0.07067960500717163
I0419 11:04:16.636146 28972 trainer.py:139] Epoch[545/1000] loss: 0.07244544169482063
I0419 11:04:22.473681 28972 trainer.py:139] Epoch[546/1000] loss: 0.07221729965770946
I0419 11:04:28.595845 28972 trainer.py:139] Epoch[547/1000] loss: 0.07254456991658491
I0419 11:04:36.687011 28972 trainer.py:139] Epoch[548/1000] loss: 0.07147211625295527
I0419 11:04:42.387309 28972 trainer.py:139] Epoch[549/1000] loss: 0.07198560676153969
I0419 11:04:43.187196 28972 trainer.py:145] Test: [{'precision': 0.01279899286613513, 'recall': 0.16343994165018083, 'hit_ratio': 0.24087284934955938, 'ndcg': 0.07868301386641663}]
I0419 11:04:51.303798 28972 trainer.py:139] Epoch[550/1000] loss: 0.07159368737655528
I0419 11:04:57.443725 28972 trainer.py:139] Epoch[551/1000] loss: 0.0715862429317306
I0419 11:05:03.145609 28972 trainer.py:139] Epoch[552/1000] loss: 0.07215427651124842
I0419 11:05:11.542262 28972 trainer.py:139] Epoch[553/1000] loss: 0.07091492107685875
I0419 11:05:17.380981 28972 trainer.py:139] Epoch[554/1000] loss: 0.07155661723193
I0419 11:05:23.330491 28972 trainer.py:139] Epoch[555/1000] loss: 0.071560758878203
I0419 11:05:31.621039 28972 trainer.py:139] Epoch[556/1000] loss: 0.07134185599930146
I0419 11:05:37.538194 28972 trainer.py:139] Epoch[557/1000] loss: 0.07172394017962848
I0419 11:05:44.496716 28972 trainer.py:139] Epoch[558/1000] loss: 0.07133352712673299
I0419 11:05:51.847135 28972 trainer.py:139] Epoch[559/1000] loss: 0.07119592936599956
I0419 11:05:57.680107 28972 trainer.py:139] Epoch[560/1000] loss: 0.07097045332193375
I0419 11:06:05.419706 28972 trainer.py:139] Epoch[561/1000] loss: 0.07129463860217262
I0419 11:06:11.704308 28972 trainer.py:139] Epoch[562/1000] loss: 0.0714639977497213
I0419 11:06:17.477310 28972 trainer.py:139] Epoch[563/1000] loss: 0.07133516362484764
I0419 11:06:25.670951 28972 trainer.py:139] Epoch[564/1000] loss: 0.07106171285404879
I0419 11:06:31.709551 28972 trainer.py:139] Epoch[565/1000] loss: 0.07137828846188153
I0419 11:06:37.501830 28972 trainer.py:139] Epoch[566/1000] loss: 0.07109069035333745
I0419 11:06:45.889495 28972 trainer.py:139] Epoch[567/1000] loss: 0.07181420746971579
I0419 11:06:51.762263 28972 trainer.py:139] Epoch[568/1000] loss: 0.07101535577984418
I0419 11:06:57.737890 28972 trainer.py:139] Epoch[569/1000] loss: 0.07085834531223073
I0419 11:07:06.348170 28972 trainer.py:139] Epoch[570/1000] loss: 0.07126580441699308
I0419 11:07:12.347669 28972 trainer.py:139] Epoch[571/1000] loss: 0.07075160566498251
I0419 11:07:18.278290 28972 trainer.py:139] Epoch[572/1000] loss: 0.07038779337616528
I0419 11:07:26.663412 28972 trainer.py:139] Epoch[573/1000] loss: 0.07129825169549268
I0419 11:07:32.678755 28972 trainer.py:139] Epoch[574/1000] loss: 0.07143177837133408
I0419 11:07:38.379190 28972 trainer.py:139] Epoch[575/1000] loss: 0.07097998699721168
I0419 11:07:46.810166 28972 trainer.py:139] Epoch[576/1000] loss: 0.07048658150083878
I0419 11:07:52.675062 28972 trainer.py:139] Epoch[577/1000] loss: 0.07047301487011068
I0419 11:07:58.333510 28972 trainer.py:139] Epoch[578/1000] loss: 0.07094943698714762
I0419 11:08:06.715070 28972 trainer.py:139] Epoch[579/1000] loss: 0.07011670093326007
I0419 11:08:12.668547 28972 trainer.py:139] Epoch[580/1000] loss: 0.07115096774171381
I0419 11:08:18.784483 28972 trainer.py:139] Epoch[581/1000] loss: 0.0706581951064222
I0419 11:08:26.702584 28972 trainer.py:139] Epoch[582/1000] loss: 0.06980684180470074
I0419 11:08:32.669616 28972 trainer.py:139] Epoch[583/1000] loss: 0.0709478092544219
I0419 11:08:39.768632 28972 trainer.py:139] Epoch[584/1000] loss: 0.06963031169246225
I0419 11:08:46.526978 28972 trainer.py:139] Epoch[585/1000] loss: 0.07126879429115969
I0419 11:08:52.212362 28972 trainer.py:139] Epoch[586/1000] loss: 0.07052122187965057
I0419 11:08:59.067872 28972 trainer.py:139] Epoch[587/1000] loss: 0.07090147979119245
I0419 11:09:06.588538 28972 trainer.py:139] Epoch[588/1000] loss: 0.07032008469104767
I0419 11:09:12.398581 28972 trainer.py:139] Epoch[589/1000] loss: 0.07064746714690152
I0419 11:09:19.003949 28972 trainer.py:139] Epoch[590/1000] loss: 0.07144984734408996
I0419 11:09:26.569169 28972 trainer.py:139] Epoch[591/1000] loss: 0.06971775258288664
I0419 11:09:32.122385 28972 trainer.py:139] Epoch[592/1000] loss: 0.06924346965901992
I0419 11:09:39.047781 28972 trainer.py:139] Epoch[593/1000] loss: 0.07148071378469467
I0419 11:09:46.151641 28972 trainer.py:139] Epoch[594/1000] loss: 0.07074312734253266
I0419 11:09:51.969962 28972 trainer.py:139] Epoch[595/1000] loss: 0.06970867733745013
I0419 11:09:58.953448 28972 trainer.py:139] Epoch[596/1000] loss: 0.06993244676028981
I0419 11:10:06.293541 28972 trainer.py:139] Epoch[597/1000] loss: 0.06928857722703148
I0419 11:10:12.019191 28972 trainer.py:139] Epoch[598/1000] loss: 0.07006050690132029
I0419 11:10:19.116687 28972 trainer.py:139] Epoch[599/1000] loss: 0.0698179212563178
I0419 11:10:19.911545 28972 trainer.py:145] Test: [{'precision': 0.012861938732689891, 'recall': 0.1640344303898647, 'hit_ratio': 0.24255140579101972, 'ndcg': 0.07874050845570256}]
I0419 11:10:26.587790 28972 trainer.py:139] Epoch[600/1000] loss: 0.06930408363833147
I0419 11:10:32.376783 28972 trainer.py:139] Epoch[601/1000] loss: 0.06974971075268353
I0419 11:10:40.620910 28972 trainer.py:139] Epoch[602/1000] loss: 0.06972534954547882
I0419 11:10:46.443284 28972 trainer.py:139] Epoch[603/1000] loss: 0.06989766175256056
I0419 11:10:52.202305 28972 trainer.py:139] Epoch[604/1000] loss: 0.07024166733026505
I0419 11:11:00.575410 28972 trainer.py:139] Epoch[605/1000] loss: 0.07056838843752355
I0419 11:11:06.455275 28972 trainer.py:139] Epoch[606/1000] loss: 0.07036465318763957
I0419 11:11:12.345927 28972 trainer.py:139] Epoch[607/1000] loss: 0.06945746698800255
I0419 11:11:20.644362 28972 trainer.py:139] Epoch[608/1000] loss: 0.07025113877128153
I0419 11:11:26.330787 28972 trainer.py:139] Epoch[609/1000] loss: 0.06998307959121816
I0419 11:11:32.145817 28972 trainer.py:139] Epoch[610/1000] loss: 0.06981173552134458
I0419 11:11:40.599887 28972 trainer.py:139] Epoch[611/1000] loss: 0.06987676418879453
I0419 11:11:46.298236 28972 trainer.py:139] Epoch[612/1000] loss: 0.07007129490375519
I0419 11:11:52.079370 28972 trainer.py:139] Epoch[613/1000] loss: 0.06913681635085274
I0419 11:12:00.698018 28972 trainer.py:139] Epoch[614/1000] loss: 0.06961710093652501
I0419 11:12:06.470746 28972 trainer.py:139] Epoch[615/1000] loss: 0.0690649647046538
I0419 11:12:12.628312 28972 trainer.py:139] Epoch[616/1000] loss: 0.06907352323041242
I0419 11:12:20.450205 28972 trainer.py:139] Epoch[617/1000] loss: 0.06895877245594473
I0419 11:12:26.227763 28972 trainer.py:139] Epoch[618/1000] loss: 0.06919153955052881
I0419 11:12:32.096115 28972 trainer.py:139] Epoch[619/1000] loss: 0.07023458840215907
I0419 11:12:40.313220 28972 trainer.py:139] Epoch[620/1000] loss: 0.06992207818171557
I0419 11:12:46.039877 28972 trainer.py:139] Epoch[621/1000] loss: 0.06874932655516793
I0419 11:12:52.487028 28972 trainer.py:139] Epoch[622/1000] loss: 0.06850929908892688
I0419 11:13:00.399429 28972 trainer.py:139] Epoch[623/1000] loss: 0.06945882036405451
I0419 11:13:06.311157 28972 trainer.py:139] Epoch[624/1000] loss: 0.06897801336120157
I0419 11:13:13.850077 28972 trainer.py:139] Epoch[625/1000] loss: 0.06941675964523764
I0419 11:13:20.475582 28972 trainer.py:139] Epoch[626/1000] loss: 0.06870982532992083
I0419 11:13:26.197954 28972 trainer.py:139] Epoch[627/1000] loss: 0.07008840275161407
I0419 11:13:34.828779 28972 trainer.py:139] Epoch[628/1000] loss: 0.06929093730800293
I0419 11:13:40.615317 28972 trainer.py:139] Epoch[629/1000] loss: 0.06986752722193212
I0419 11:13:46.523964 28972 trainer.py:139] Epoch[630/1000] loss: 0.06829835518318064
I0419 11:13:55.053188 28972 trainer.py:139] Epoch[631/1000] loss: 0.06894672881154452
I0419 11:14:00.861199 28972 trainer.py:139] Epoch[632/1000] loss: 0.06877643527353511
I0419 11:14:06.372085 28972 trainer.py:139] Epoch[633/1000] loss: 0.07032382400596843
I0419 11:14:14.696011 28972 trainer.py:139] Epoch[634/1000] loss: 0.0692921675303403
I0419 11:14:20.491024 28972 trainer.py:139] Epoch[635/1000] loss: 0.06839488972635831
I0419 11:14:26.371749 28972 trainer.py:139] Epoch[636/1000] loss: 0.06949830405852374
I0419 11:14:34.676695 28972 trainer.py:139] Epoch[637/1000] loss: 0.06849035708343282
I0419 11:14:40.315783 28972 trainer.py:139] Epoch[638/1000] loss: 0.06862357434104471
I0419 11:14:46.307342 28972 trainer.py:139] Epoch[639/1000] loss: 0.06861935073838514
I0419 11:14:54.494989 28972 trainer.py:139] Epoch[640/1000] loss: 0.06864220736657872
I0419 11:15:00.200909 28972 trainer.py:139] Epoch[641/1000] loss: 0.06974873428835589
I0419 11:15:06.047434 28972 trainer.py:139] Epoch[642/1000] loss: 0.06814297814579572
I0419 11:15:14.133122 28972 trainer.py:139] Epoch[643/1000] loss: 0.06853504172142814
I0419 11:15:19.990741 28972 trainer.py:139] Epoch[644/1000] loss: 0.0680086406714776
I0419 11:15:26.095967 28972 trainer.py:139] Epoch[645/1000] loss: 0.06805617318433874
I0419 11:15:33.988833 28972 trainer.py:139] Epoch[646/1000] loss: 0.06921148913748124
I0419 11:15:39.912974 28972 trainer.py:139] Epoch[647/1000] loss: 0.06896631419658661
I0419 11:15:45.792651 28972 trainer.py:139] Epoch[648/1000] loss: 0.06877530935932608
I0419 11:15:53.895259 28972 trainer.py:139] Epoch[649/1000] loss: 0.06935339114245247
I0419 11:15:54.639359 28972 trainer.py:145] Test: [{'precision': 0.012966848510281166, 'recall': 0.16547985399223333, 'hit_ratio': 0.24506924045321024, 'ndcg': 0.07839078260227181}]
I0419 11:16:00.464259 28972 trainer.py:139] Epoch[650/1000] loss: 0.06899431347846985
I0419 11:16:07.303521 28972 trainer.py:139] Epoch[651/1000] loss: 0.06894334098872017
I0419 11:16:14.674718 28972 trainer.py:139] Epoch[652/1000] loss: 0.06829509358195697
I0419 11:16:20.339533 28972 trainer.py:139] Epoch[653/1000] loss: 0.06863377681549858
I0419 11:16:27.106924 28972 trainer.py:139] Epoch[654/1000] loss: 0.06739394629702848
I0419 11:16:34.808779 28972 trainer.py:139] Epoch[655/1000] loss: 0.06865738639060188
I0419 11:16:40.777236 28972 trainer.py:139] Epoch[656/1000] loss: 0.06802080308689791
I0419 11:16:49.085056 28972 trainer.py:139] Epoch[657/1000] loss: 0.06838142345933353
I0419 11:16:54.919256 28972 trainer.py:139] Epoch[658/1000] loss: 0.0677134245634079
I0419 11:17:00.902354 28972 trainer.py:139] Epoch[659/1000] loss: 0.06855302873779745
I0419 11:17:09.207161 28972 trainer.py:139] Epoch[660/1000] loss: 0.06902453653952655
I0419 11:17:15.216582 28972 trainer.py:139] Epoch[661/1000] loss: 0.06943448589128606
I0419 11:17:21.002938 28972 trainer.py:139] Epoch[662/1000] loss: 0.06726646817782346
I0419 11:17:29.376341 28972 trainer.py:139] Epoch[663/1000] loss: 0.06827451858450384
I0419 11:17:35.134997 28972 trainer.py:139] Epoch[664/1000] loss: 0.06858136329580755
I0419 11:17:40.986393 28972 trainer.py:139] Epoch[665/1000] loss: 0.06899650964666815
I0419 11:17:49.402513 28972 trainer.py:139] Epoch[666/1000] loss: 0.06894228651243098
I0419 11:17:55.148829 28972 trainer.py:139] Epoch[667/1000] loss: 0.06814375695060282
I0419 11:18:01.413401 28972 trainer.py:139] Epoch[668/1000] loss: 0.0678172462126788
I0419 11:18:09.073018 28972 trainer.py:139] Epoch[669/1000] loss: 0.0681578039246447
I0419 11:18:14.940358 28972 trainer.py:139] Epoch[670/1000] loss: 0.06785518851350336
I0419 11:18:22.380394 28972 trainer.py:139] Epoch[671/1000] loss: 0.06856092153226628
I0419 11:18:29.216698 28972 trainer.py:139] Epoch[672/1000] loss: 0.06820479824262507
I0419 11:18:35.155101 28972 trainer.py:139] Epoch[673/1000] loss: 0.06781521308071473
I0419 11:18:43.575046 28972 trainer.py:139] Epoch[674/1000] loss: 0.06745212437475429
I0419 11:18:49.525775 28972 trainer.py:139] Epoch[675/1000] loss: 0.0683025086627287
I0419 11:18:55.281091 28972 trainer.py:139] Epoch[676/1000] loss: 0.06750689403099172
I0419 11:19:03.472522 28972 trainer.py:139] Epoch[677/1000] loss: 0.06832421658670201
I0419 11:19:09.376795 28972 trainer.py:139] Epoch[678/1000] loss: 0.0676501568625955
I0419 11:19:15.684276 28972 trainer.py:139] Epoch[679/1000] loss: 0.06768977598232381
I0419 11:19:23.704889 28972 trainer.py:139] Epoch[680/1000] loss: 0.06747816634528778
I0419 11:19:29.565684 28972 trainer.py:139] Epoch[681/1000] loss: 0.06824636459350586
I0419 11:19:36.859660 28972 trainer.py:139] Epoch[682/1000] loss: 0.06758445588981404
I0419 11:19:43.803602 28972 trainer.py:139] Epoch[683/1000] loss: 0.06725663428797442
I0419 11:19:49.684412 28972 trainer.py:139] Epoch[684/1000] loss: 0.06852487869122449
I0419 11:19:57.700577 28972 trainer.py:139] Epoch[685/1000] loss: 0.06806035821928698
I0419 11:20:04.153386 28972 trainer.py:139] Epoch[686/1000] loss: 0.068203866481781
I0419 11:20:09.861206 28972 trainer.py:139] Epoch[687/1000] loss: 0.06725564511383281
I0419 11:20:17.994882 28972 trainer.py:139] Epoch[688/1000] loss: 0.06878778995836482
I0419 11:20:24.128475 28972 trainer.py:139] Epoch[689/1000] loss: 0.06750339795561398
I0419 11:20:29.970055 28972 trainer.py:139] Epoch[690/1000] loss: 0.06801299181054621
I0419 11:20:38.267168 28972 trainer.py:139] Epoch[691/1000] loss: 0.06732025304261376
I0419 11:20:43.958635 28972 trainer.py:139] Epoch[692/1000] loss: 0.06795944667914335
I0419 11:20:49.885733 28972 trainer.py:139] Epoch[693/1000] loss: 0.0673436965135967
I0419 11:20:58.431070 28972 trainer.py:139] Epoch[694/1000] loss: 0.06823453657767352
I0419 11:21:04.244030 28972 trainer.py:139] Epoch[695/1000] loss: 0.0679616638842751
I0419 11:21:10.042533 28972 trainer.py:139] Epoch[696/1000] loss: 0.06682861903134514
I0419 11:21:18.491914 28972 trainer.py:139] Epoch[697/1000] loss: 0.06879221604150884
I0419 11:21:24.169348 28972 trainer.py:139] Epoch[698/1000] loss: 0.06741084859651678
I0419 11:21:29.962467 28972 trainer.py:139] Epoch[699/1000] loss: 0.06763937236631618
I0419 11:21:30.644726 28972 trainer.py:145] Test: [{'precision': 0.0129039026437264, 'recall': 0.1649483111191042, 'hit_ratio': 0.24464960134284516, 'ndcg': 0.07803595663356891}]
I0419 11:21:38.828437 28972 trainer.py:139] Epoch[700/1000] loss: 0.06806278973817825
I0419 11:21:44.740760 28972 trainer.py:139] Epoch[701/1000] loss: 0.06727298086180407
I0419 11:21:50.415095 28972 trainer.py:139] Epoch[702/1000] loss: 0.06715063443955253
I0419 11:21:58.823645 28972 trainer.py:139] Epoch[703/1000] loss: 0.06665305837112315
I0419 11:22:04.611578 28972 trainer.py:139] Epoch[704/1000] loss: 0.06758933996453005
I0419 11:22:10.335907 28972 trainer.py:139] Epoch[705/1000] loss: 0.06698328344260945
I0419 11:22:18.901703 28972 trainer.py:139] Epoch[706/1000] loss: 0.06808964031584122
I0419 11:22:24.570593 28972 trainer.py:139] Epoch[707/1000] loss: 0.06653635422973071
I0419 11:22:30.300204 28972 trainer.py:139] Epoch[708/1000] loss: 0.06777473057017606
I0419 11:22:38.731218 28972 trainer.py:139] Epoch[709/1000] loss: 0.06791487730601255
I0419 11:22:44.503269 28972 trainer.py:139] Epoch[710/1000] loss: 0.067665114560548
I0419 11:22:51.435833 28972 trainer.py:139] Epoch[711/1000] loss: 0.0679878377739121
I0419 11:22:58.592506 28972 trainer.py:139] Epoch[712/1000] loss: 0.06860693412668564
I0419 11:23:04.262950 28972 trainer.py:139] Epoch[713/1000] loss: 0.0666929452734835
I0419 11:23:12.339679 28972 trainer.py:139] Epoch[714/1000] loss: 0.06721822347711115
I0419 11:23:18.411762 28972 trainer.py:139] Epoch[715/1000] loss: 0.06823049047413994
I0419 11:23:24.054190 28972 trainer.py:139] Epoch[716/1000] loss: 0.06784728870672338
I0419 11:23:31.874519 28972 trainer.py:139] Epoch[717/1000] loss: 0.0679829865694046
I0419 11:23:37.994796 28972 trainer.py:139] Epoch[718/1000] loss: 0.06824905118521522
I0419 11:23:43.822574 28972 trainer.py:139] Epoch[719/1000] loss: 0.06687739491462708
I0419 11:23:52.131825 28972 trainer.py:139] Epoch[720/1000] loss: 0.06730798982522067
I0419 11:23:57.856634 28972 trainer.py:139] Epoch[721/1000] loss: 0.06684294036206077
I0419 11:24:03.617337 28972 trainer.py:139] Epoch[722/1000] loss: 0.0665316055802738
I0419 11:24:11.832877 28972 trainer.py:139] Epoch[723/1000] loss: 0.06670801297706716
I0419 11:24:17.713582 28972 trainer.py:139] Epoch[724/1000] loss: 0.06702075810993419
I0419 11:24:23.577359 28972 trainer.py:139] Epoch[725/1000] loss: 0.06751089718411951
I0419 11:24:32.034798 28972 trainer.py:139] Epoch[726/1000] loss: 0.06743257229819018
I0419 11:24:37.612886 28972 trainer.py:139] Epoch[727/1000] loss: 0.06656694324577556
I0419 11:24:43.561899 28972 trainer.py:139] Epoch[728/1000] loss: 0.06648222488515518
I0419 11:24:52.021366 28972 trainer.py:139] Epoch[729/1000] loss: 0.06681506554870044
I0419 11:24:58.005942 28972 trainer.py:139] Epoch[730/1000] loss: 0.0662048509454026
I0419 11:25:04.044420 28972 trainer.py:139] Epoch[731/1000] loss: 0.06734196140485652
I0419 11:25:12.134477 28972 trainer.py:139] Epoch[732/1000] loss: 0.06642490187112023
I0419 11:25:18.022641 28972 trainer.py:139] Epoch[733/1000] loss: 0.06782224905841491
I0419 11:25:24.974115 28972 trainer.py:139] Epoch[734/1000] loss: 0.06669317492667366
I0419 11:25:32.283781 28972 trainer.py:139] Epoch[735/1000] loss: 0.06699848963933833
I0419 11:25:38.199812 28972 trainer.py:139] Epoch[736/1000] loss: 0.06736038230797824
I0419 11:25:45.680002 28972 trainer.py:139] Epoch[737/1000] loss: 0.06669802788425894
I0419 11:25:52.174057 28972 trainer.py:139] Epoch[738/1000] loss: 0.06717329165514778
I0419 11:25:58.066282 28972 trainer.py:139] Epoch[739/1000] loss: 0.06642545672023997
I0419 11:26:06.589027 28972 trainer.py:139] Epoch[740/1000] loss: 0.0667926187024397
I0419 11:26:12.522533 28972 trainer.py:139] Epoch[741/1000] loss: 0.0670679360628128
I0419 11:26:18.409017 28972 trainer.py:139] Epoch[742/1000] loss: 0.06609532324706807
I0419 11:26:26.942062 28972 trainer.py:139] Epoch[743/1000] loss: 0.06725723471711664
I0419 11:26:32.854704 28972 trainer.py:139] Epoch[744/1000] loss: 0.06633760122691884
I0419 11:26:38.696549 28972 trainer.py:139] Epoch[745/1000] loss: 0.0662474439424627
I0419 11:26:47.098879 28972 trainer.py:139] Epoch[746/1000] loss: 0.06680350619203904
I0419 11:26:52.938768 28972 trainer.py:139] Epoch[747/1000] loss: 0.06722294232424568
I0419 11:26:58.581289 28972 trainer.py:139] Epoch[748/1000] loss: 0.06721131766543668
I0419 11:27:07.009325 28972 trainer.py:139] Epoch[749/1000] loss: 0.06584111119017881
I0419 11:27:07.757549 28972 trainer.py:145] Test: [{'precision': 0.012778010910616875, 'recall': 0.16457013634940615, 'hit_ratio': 0.24213176668065464, 'ndcg': 0.07772904796622972}]
I0419 11:27:13.696060 28972 trainer.py:139] Epoch[750/1000] loss: 0.06665329196873833
I0419 11:27:20.601044 28972 trainer.py:139] Epoch[751/1000] loss: 0.06737239395870882
I0419 11:27:27.757772 28972 trainer.py:139] Epoch[752/1000] loss: 0.0664439775487956
I0419 11:27:33.564796 28972 trainer.py:139] Epoch[753/1000] loss: 0.06607783541959875
I0419 11:27:39.539906 28972 trainer.py:139] Epoch[754/1000] loss: 0.0660337218466927
I0419 11:27:47.665405 28972 trainer.py:139] Epoch[755/1000] loss: 0.06622058591421913
I0419 11:27:53.458468 28972 trainer.py:139] Epoch[756/1000] loss: 0.0660783258431098
I0419 11:27:59.751772 28972 trainer.py:139] Epoch[757/1000] loss: 0.06731674644876928
I0419 11:28:07.766540 28972 trainer.py:139] Epoch[758/1000] loss: 0.06694140022291857
I0419 11:28:13.700319 28972 trainer.py:139] Epoch[759/1000] loss: 0.06576698974651449
I0419 11:28:21.919556 28972 trainer.py:139] Epoch[760/1000] loss: 0.06660343575126984
I0419 11:28:27.934395 28972 trainer.py:139] Epoch[761/1000] loss: 0.06587237514117185
I0419 11:28:33.703499 28972 trainer.py:139] Epoch[762/1000] loss: 0.0665283838615698
I0419 11:28:42.097005 28972 trainer.py:139] Epoch[763/1000] loss: 0.06623086640063454
I0419 11:28:47.979669 28972 trainer.py:139] Epoch[764/1000] loss: 0.06677368984502904
I0419 11:28:53.606461 28972 trainer.py:139] Epoch[765/1000] loss: 0.06713912504560807
I0419 11:29:02.002456 28972 trainer.py:139] Epoch[766/1000] loss: 0.06723393543678172
I0419 11:29:07.704740 28972 trainer.py:139] Epoch[767/1000] loss: 0.06648548341849271
I0419 11:29:13.415251 28972 trainer.py:139] Epoch[768/1000] loss: 0.06538156858261894
I0419 11:29:21.952535 28972 trainer.py:139] Epoch[769/1000] loss: 0.06511259845951024
I0419 11:29:27.898067 28972 trainer.py:139] Epoch[770/1000] loss: 0.06635106661740471
I0419 11:29:33.761838 28972 trainer.py:139] Epoch[771/1000] loss: 0.06724206971771576
I0419 11:29:42.201229 28972 trainer.py:139] Epoch[772/1000] loss: 0.06611805759808596
I0419 11:29:48.008939 28972 trainer.py:139] Epoch[773/1000] loss: 0.06577356115860097
I0419 11:29:53.710243 28972 trainer.py:139] Epoch[774/1000] loss: 0.0664388589999255
I0419 11:30:02.074045 28972 trainer.py:139] Epoch[775/1000] loss: 0.06629888669532888
I0419 11:30:07.795165 28972 trainer.py:139] Epoch[776/1000] loss: 0.06731796878225663
I0419 11:30:15.022691 28972 trainer.py:139] Epoch[777/1000] loss: 0.06609241094659357
I0419 11:30:22.201308 28972 trainer.py:139] Epoch[778/1000] loss: 0.06572180197519414
I0419 11:30:27.949846 28972 trainer.py:139] Epoch[779/1000] loss: 0.06548955817432965
I0419 11:30:34.783785 28972 trainer.py:139] Epoch[780/1000] loss: 0.06632479981464498
I0419 11:30:42.140705 28972 trainer.py:139] Epoch[781/1000] loss: 0.06521455023218603
I0419 11:30:47.887427 28972 trainer.py:139] Epoch[782/1000] loss: 0.06648675308508031
I0419 11:30:55.540606 28972 trainer.py:139] Epoch[783/1000] loss: 0.06625305510619107
I0419 11:31:02.301074 28972 trainer.py:139] Epoch[784/1000] loss: 0.06670340019113877
I0419 11:31:08.235630 28972 trainer.py:139] Epoch[785/1000] loss: 0.06605670250513974
I0419 11:31:15.927955 28972 trainer.py:139] Epoch[786/1000] loss: 0.06565502592745949
I0419 11:31:22.379928 28972 trainer.py:139] Epoch[787/1000] loss: 0.06555455988820862
I0419 11:31:28.146009 28972 trainer.py:139] Epoch[788/1000] loss: 0.06592284011490204
I0419 11:31:36.470761 28972 trainer.py:139] Epoch[789/1000] loss: 0.06588055544039782
I0419 11:31:42.236207 28972 trainer.py:139] Epoch[790/1000] loss: 0.06682266820879544
I0419 11:31:48.110346 28972 trainer.py:139] Epoch[791/1000] loss: 0.06594068403629695
I0419 11:31:56.616096 28972 trainer.py:139] Epoch[792/1000] loss: 0.06564228170934845
I0419 11:32:02.395998 28972 trainer.py:139] Epoch[793/1000] loss: 0.06551375897491679
I0419 11:32:08.127870 28972 trainer.py:139] Epoch[794/1000] loss: 0.06605079331818749
I0419 11:32:16.468563 28972 trainer.py:139] Epoch[795/1000] loss: 0.06574489702196683
I0419 11:32:22.369499 28972 trainer.py:139] Epoch[796/1000] loss: 0.06583541500217774
I0419 11:32:27.972206 28972 trainer.py:139] Epoch[797/1000] loss: 0.06552892748047323
I0419 11:32:36.179902 28972 trainer.py:139] Epoch[798/1000] loss: 0.06503893062472343
I0419 11:32:42.159304 28972 trainer.py:139] Epoch[799/1000] loss: 0.06576479796101065
I0419 11:32:42.874909 28972 trainer.py:145] Test: [{'precision': 0.012882920688208148, 'recall': 0.16477346148978544, 'hit_ratio': 0.2433906840117499, 'ndcg': 0.0776522102540084}]
I0419 11:32:49.170875 28972 trainer.py:139] Epoch[800/1000] loss: 0.065615276203436
I0419 11:32:56.991154 28972 trainer.py:139] Epoch[801/1000] loss: 0.06568210265215706
I0419 11:33:02.725268 28972 trainer.py:139] Epoch[802/1000] loss: 0.06570886645246954
I0419 11:33:10.288558 28972 trainer.py:139] Epoch[803/1000] loss: 0.06538197551580037
I0419 11:33:17.130224 28972 trainer.py:139] Epoch[804/1000] loss: 0.06575846233788658
I0419 11:33:22.815572 28972 trainer.py:139] Epoch[805/1000] loss: 0.06611493142212138
I0419 11:33:31.144652 28972 trainer.py:139] Epoch[806/1000] loss: 0.06564794743762296
I0419 11:33:36.904298 28972 trainer.py:139] Epoch[807/1000] loss: 0.06551895290613174
I0419 11:33:42.811935 28972 trainer.py:139] Epoch[808/1000] loss: 0.06681809223750058
I0419 11:33:51.268242 28972 trainer.py:139] Epoch[809/1000] loss: 0.06519024139818023
I0419 11:33:56.972216 28972 trainer.py:139] Epoch[810/1000] loss: 0.06570579988114975
I0419 11:34:02.921741 28972 trainer.py:139] Epoch[811/1000] loss: 0.06589223663596545
I0419 11:34:11.334174 28972 trainer.py:139] Epoch[812/1000] loss: 0.06487950244370629
I0419 11:34:17.385353 28972 trainer.py:139] Epoch[813/1000] loss: 0.06578249571954503
I0419 11:34:23.239742 28972 trainer.py:139] Epoch[814/1000] loss: 0.06577403098344803
I0419 11:34:31.598815 28972 trainer.py:139] Epoch[815/1000] loss: 0.06610627954497057
I0419 11:34:37.496445 28972 trainer.py:139] Epoch[816/1000] loss: 0.06613021168638678
I0419 11:34:43.294251 28972 trainer.py:139] Epoch[817/1000] loss: 0.0656073536066448
I0419 11:34:51.575380 28972 trainer.py:139] Epoch[818/1000] loss: 0.06612212912124746
I0419 11:34:57.413310 28972 trainer.py:139] Epoch[819/1000] loss: 0.06543995308525422
I0419 11:35:03.869124 28972 trainer.py:139] Epoch[820/1000] loss: 0.06577309834606507
I0419 11:35:11.532889 28972 trainer.py:139] Epoch[821/1000] loss: 0.06526277652558159
I0419 11:35:17.482884 28972 trainer.py:139] Epoch[822/1000] loss: 0.06484686933896121
I0419 11:35:24.199711 28972 trainer.py:139] Epoch[823/1000] loss: 0.06457025667323786
I0419 11:35:31.498409 28972 trainer.py:139] Epoch[824/1000] loss: 0.06546148570144877
I0419 11:35:37.184455 28972 trainer.py:139] Epoch[825/1000] loss: 0.06537309288978577
I0419 11:35:44.397130 28972 trainer.py:139] Epoch[826/1000] loss: 0.0656052911106278
I0419 11:35:51.389769 28972 trainer.py:139] Epoch[827/1000] loss: 0.06529630479567192
I0419 11:35:57.346249 28972 trainer.py:139] Epoch[828/1000] loss: 0.06634802327436559
I0419 11:36:05.749251 28972 trainer.py:139] Epoch[829/1000] loss: 0.06614820177064222
I0419 11:36:11.862875 28972 trainer.py:139] Epoch[830/1000] loss: 0.06537353225490626
I0419 11:36:17.563138 28972 trainer.py:139] Epoch[831/1000] loss: 0.06614646534709369
I0419 11:36:25.982480 28972 trainer.py:139] Epoch[832/1000] loss: 0.06624958839486628
I0419 11:36:31.782468 28972 trainer.py:139] Epoch[833/1000] loss: 0.06533050537109375
I0419 11:36:37.681085 28972 trainer.py:139] Epoch[834/1000] loss: 0.06612343450679499
I0419 11:36:46.433068 28972 trainer.py:139] Epoch[835/1000] loss: 0.06560440624461454
I0419 11:36:52.082907 28972 trainer.py:139] Epoch[836/1000] loss: 0.06570570368100614
I0419 11:36:57.905957 28972 trainer.py:139] Epoch[837/1000] loss: 0.06537178465548683
I0419 11:37:06.356731 28972 trainer.py:139] Epoch[838/1000] loss: 0.06509658190257409
I0419 11:37:12.243486 28972 trainer.py:139] Epoch[839/1000] loss: 0.06514954303993899
I0419 11:37:18.485151 28972 trainer.py:139] Epoch[840/1000] loss: 0.06573516261928222
I0419 11:37:26.505350 28972 trainer.py:139] Epoch[841/1000] loss: 0.0649866768542458
I0419 11:37:32.197814 28972 trainer.py:139] Epoch[842/1000] loss: 0.06556129083037376
I0419 11:37:39.152878 28972 trainer.py:139] Epoch[843/1000] loss: 0.0659124340642901
I0419 11:37:45.905678 28972 trainer.py:139] Epoch[844/1000] loss: 0.06478064134716988
I0419 11:37:51.682880 28972 trainer.py:139] Epoch[845/1000] loss: 0.06519868772696047
I0419 11:38:00.227729 28972 trainer.py:139] Epoch[846/1000] loss: 0.06483015133177533
I0419 11:38:06.054275 28972 trainer.py:139] Epoch[847/1000] loss: 0.06522004087181653
I0419 11:38:12.025417 28972 trainer.py:139] Epoch[848/1000] loss: 0.06468484375406713
I0419 11:38:20.457767 28972 trainer.py:139] Epoch[849/1000] loss: 0.06558326412649716
I0419 11:38:21.256663 28972 trainer.py:145] Test: [{'precision': 0.012903902643726402, 'recall': 0.16494131713393148, 'hit_ratio': 0.24506924045321024, 'ndcg': 0.07959556626099946}]
I0419 11:38:27.075006 28972 trainer.py:139] Epoch[850/1000] loss: 0.0651049962376847
I0419 11:38:32.955243 28972 trainer.py:139] Epoch[851/1000] loss: 0.06605701762087204
I0419 11:38:41.366894 28972 trainer.py:139] Epoch[852/1000] loss: 0.06601074885796099
I0419 11:38:47.105599 28972 trainer.py:139] Epoch[853/1000] loss: 0.06577762742252911
I0419 11:38:53.664584 28972 trainer.py:139] Epoch[854/1000] loss: 0.06620923451641027
I0419 11:39:01.424717 28972 trainer.py:139] Epoch[855/1000] loss: 0.06575543038985308
I0419 11:39:07.247979 28972 trainer.py:139] Epoch[856/1000] loss: 0.06441896430709783
I0419 11:39:14.988108 28972 trainer.py:139] Epoch[857/1000] loss: 0.06433409452438354
I0419 11:39:21.595234 28972 trainer.py:139] Epoch[858/1000] loss: 0.06471608535331838
I0419 11:39:27.335441 28972 trainer.py:139] Epoch[859/1000] loss: 0.06470571195378023
I0419 11:39:35.793869 28972 trainer.py:139] Epoch[860/1000] loss: 0.06476740188458387
I0419 11:39:41.548994 28972 trainer.py:139] Epoch[861/1000] loss: 0.0652885971700444
I0419 11:39:47.415351 28972 trainer.py:139] Epoch[862/1000] loss: 0.06468737563666176
I0419 11:39:55.815407 28972 trainer.py:139] Epoch[863/1000] loss: 0.06527674658333554
I0419 11:40:01.716207 28972 trainer.py:139] Epoch[864/1000] loss: 0.0642772062736399
I0419 11:40:07.606855 28972 trainer.py:139] Epoch[865/1000] loss: 0.06570659358711804
I0419 11:40:16.018751 28972 trainer.py:139] Epoch[866/1000] loss: 0.06483628863797468
I0419 11:40:21.784777 28972 trainer.py:139] Epoch[867/1000] loss: 0.0652458593249321
I0419 11:40:27.640069 28972 trainer.py:139] Epoch[868/1000] loss: 0.06466368191382464
I0419 11:40:36.140931 28972 trainer.py:139] Epoch[869/1000] loss: 0.06530873696593677
I0419 11:40:41.812583 28972 trainer.py:139] Epoch[870/1000] loss: 0.06489379068507868
I0419 11:40:47.845797 28972 trainer.py:139] Epoch[871/1000] loss: 0.06458188659128021
I0419 11:40:55.936173 28972 trainer.py:139] Epoch[872/1000] loss: 0.06474795455441755
I0419 11:41:01.761821 28972 trainer.py:139] Epoch[873/1000] loss: 0.06529556718819282
I0419 11:41:08.399716 28972 trainer.py:139] Epoch[874/1000] loss: 0.06447664297678891
I0419 11:41:16.121927 28972 trainer.py:139] Epoch[875/1000] loss: 0.06436555482008878
I0419 11:41:21.909467 28972 trainer.py:139] Epoch[876/1000] loss: 0.06409244611859322
I0419 11:41:29.742791 28972 trainer.py:139] Epoch[877/1000] loss: 0.06406514324686106
I0419 11:41:36.003242 28972 trainer.py:139] Epoch[878/1000] loss: 0.06569887040292516
I0419 11:41:41.799255 28972 trainer.py:139] Epoch[879/1000] loss: 0.06468524148359019
I0419 11:41:50.220568 28972 trainer.py:139] Epoch[880/1000] loss: 0.06483617140089765
I0419 11:41:56.110671 28972 trainer.py:139] Epoch[881/1000] loss: 0.0647340872708489
I0419 11:42:01.898470 28972 trainer.py:139] Epoch[882/1000] loss: 0.0661124034839518
I0419 11:42:10.250461 28972 trainer.py:139] Epoch[883/1000] loss: 0.06499768289573052
I0419 11:42:16.112800 28972 trainer.py:139] Epoch[884/1000] loss: 0.06543086271952181
I0419 11:42:22.029463 28972 trainer.py:139] Epoch[885/1000] loss: 0.06580052700112848
I0419 11:42:30.363481 28972 trainer.py:139] Epoch[886/1000] loss: 0.0645522497156087
I0419 11:42:36.227419 28972 trainer.py:139] Epoch[887/1000] loss: 0.06454123468960032
I0419 11:42:43.152500 28972 trainer.py:139] Epoch[888/1000] loss: 0.06486287077560145
I0419 11:42:50.665623 28972 trainer.py:139] Epoch[889/1000] loss: 0.06532776706358966
I0419 11:42:56.420773 28972 trainer.py:139] Epoch[890/1000] loss: 0.064494918593589
I0419 11:43:04.594728 28972 trainer.py:139] Epoch[891/1000] loss: 0.0652472280404147
I0419 11:43:10.590034 28972 trainer.py:139] Epoch[892/1000] loss: 0.06457924579872805
I0419 11:43:16.414013 28972 trainer.py:139] Epoch[893/1000] loss: 0.06488773599267006
I0419 11:43:24.948120 28972 trainer.py:139] Epoch[894/1000] loss: 0.06430963054299355
I0419 11:43:30.906632 28972 trainer.py:139] Epoch[895/1000] loss: 0.06454168610713061
I0419 11:43:36.694657 28972 trainer.py:139] Epoch[896/1000] loss: 0.06437118526767283
I0419 11:43:45.170920 28972 trainer.py:139] Epoch[897/1000] loss: 0.06405630642000366
I0419 11:43:50.931158 28972 trainer.py:139] Epoch[898/1000] loss: 0.06452684016788707
I0419 11:43:56.996269 28972 trainer.py:139] Epoch[899/1000] loss: 0.06395113183295026
I0419 11:43:57.690693 28972 trainer.py:145] Test: [{'precision': 0.012882920688208148, 'recall': 0.1637273611360896, 'hit_ratio': 0.24422996223248006, 'ndcg': 0.07867025044335778}]
I0419 11:44:06.201551 28972 trainer.py:139] Epoch[900/1000] loss: 0.06511041522026062
I0419 11:44:11.919854 28972 trainer.py:139] Epoch[901/1000] loss: 0.06412923905779333
I0419 11:44:18.420538 28972 trainer.py:139] Epoch[902/1000] loss: 0.06441061352105702
I0419 11:44:26.433871 28972 trainer.py:139] Epoch[903/1000] loss: 0.06465418812106638
I0419 11:44:32.279017 28972 trainer.py:139] Epoch[904/1000] loss: 0.06530214626999463
I0419 11:44:40.107803 28972 trainer.py:139] Epoch[905/1000] loss: 0.06504517201991643
I0419 11:44:46.477392 28972 trainer.py:139] Epoch[906/1000] loss: 0.06484245530822698
I0419 11:44:52.440432 28972 trainer.py:139] Epoch[907/1000] loss: 0.06396446201731176
I0419 11:45:00.827110 28972 trainer.py:139] Epoch[908/1000] loss: 0.06491710267522756
I0419 11:45:06.743810 28972 trainer.py:139] Epoch[909/1000] loss: 0.06534229964017868
I0419 11:45:12.505508 28972 trainer.py:139] Epoch[910/1000] loss: 0.06386621033444125
I0419 11:45:20.658394 28972 trainer.py:139] Epoch[911/1000] loss: 0.0639295674422208
I0419 11:45:26.298465 28972 trainer.py:139] Epoch[912/1000] loss: 0.0653282649376813
I0419 11:45:32.882918 28972 trainer.py:139] Epoch[913/1000] loss: 0.06458201894865316
I0419 11:45:40.249507 28972 trainer.py:139] Epoch[914/1000] loss: 0.06496329254963819
I0419 11:45:46.194989 28972 trainer.py:139] Epoch[915/1000] loss: 0.06424340539995362
I0419 11:45:54.781085 28972 trainer.py:139] Epoch[916/1000] loss: 0.06451182549490649
I0419 11:46:00.516317 28972 trainer.py:139] Epoch[917/1000] loss: 0.06451833226224955
I0419 11:46:06.524768 28972 trainer.py:139] Epoch[918/1000] loss: 0.06507494410171229
I0419 11:46:15.399567 28972 trainer.py:139] Epoch[919/1000] loss: 0.0646823125288767
I0419 11:46:20.971766 28972 trainer.py:139] Epoch[920/1000] loss: 0.06456827065523933
I0419 11:46:26.610341 28972 trainer.py:139] Epoch[921/1000] loss: 0.06398849517983549
I0419 11:46:33.285265 28972 trainer.py:139] Epoch[922/1000] loss: 0.06453401091344216
I0419 11:46:40.125884 28972 trainer.py:139] Epoch[923/1000] loss: 0.06419056675889913
I0419 11:46:45.542135 28972 trainer.py:139] Epoch[924/1000] loss: 0.06448506914517459
I0419 11:46:50.896078 28972 trainer.py:139] Epoch[925/1000] loss: 0.06403518205179888
I0419 11:46:56.529428 28972 trainer.py:139] Epoch[926/1000] loss: 0.06363629199126188
I0419 11:47:01.625296 28972 trainer.py:139] Epoch[927/1000] loss: 0.06366042288787224
I0419 11:47:06.857968 28972 trainer.py:139] Epoch[928/1000] loss: 0.06411232843118556
I0419 11:47:11.989700 28972 trainer.py:139] Epoch[929/1000] loss: 0.06447016557349879
I0419 11:47:17.326660 28972 trainer.py:139] Epoch[930/1000] loss: 0.0642955923343406
I0419 11:47:22.555652 28972 trainer.py:139] Epoch[931/1000] loss: 0.06367902523454498
I0419 11:47:27.731487 28972 trainer.py:139] Epoch[932/1000] loss: 0.06446240732775015
I0419 11:47:32.847913 28972 trainer.py:139] Epoch[933/1000] loss: 0.06470818006817032
I0419 11:47:38.052806 28972 trainer.py:139] Epoch[934/1000] loss: 0.0646649436915622
I0419 11:47:43.590716 28972 trainer.py:139] Epoch[935/1000] loss: 0.06423814704312998
I0419 11:47:48.811907 28972 trainer.py:139] Epoch[936/1000] loss: 0.06401584472726374
I0419 11:47:53.818723 28972 trainer.py:139] Epoch[937/1000] loss: 0.06377482677207273
I0419 11:47:59.077213 28972 trainer.py:139] Epoch[938/1000] loss: 0.06396782748839434
I0419 11:48:04.412921 28972 trainer.py:139] Epoch[939/1000] loss: 0.06424593837822185
I0419 11:48:09.840440 28972 trainer.py:139] Epoch[940/1000] loss: 0.06416196397998754
I0419 11:48:15.103788 28972 trainer.py:139] Epoch[941/1000] loss: 0.06452636070111219
I0419 11:48:20.222066 28972 trainer.py:139] Epoch[942/1000] loss: 0.06395516588407404
I0419 11:48:25.419031 28972 trainer.py:139] Epoch[943/1000] loss: 0.06400607438648448
I0419 11:48:30.711176 28972 trainer.py:139] Epoch[944/1000] loss: 0.06431121116175371
I0419 11:48:35.994440 28972 trainer.py:139] Epoch[945/1000] loss: 0.06391797959804535
I0419 11:48:41.218378 28972 trainer.py:139] Epoch[946/1000] loss: 0.06456665607059703
I0419 11:48:46.407862 28972 trainer.py:139] Epoch[947/1000] loss: 0.06453278266331729
I0419 11:48:51.775792 28972 trainer.py:139] Epoch[948/1000] loss: 0.06452994552605293
I0419 11:48:56.936354 28972 trainer.py:139] Epoch[949/1000] loss: 0.06417173979913487
I0419 11:48:57.566815 28972 trainer.py:145] Test: [{'precision': 0.012715065044062111, 'recall': 0.1619299069466925, 'hit_ratio': 0.2400335711288292, 'ndcg': 0.07832770160707356}]
I0419 11:49:02.895643 28972 trainer.py:139] Epoch[950/1000] loss: 0.06395181027405403
I0419 11:49:08.121942 28972 trainer.py:139] Epoch[951/1000] loss: 0.06378273863126249
I0419 11:49:13.329929 28972 trainer.py:139] Epoch[952/1000] loss: 0.06353374263819526
I0419 11:49:18.624112 28972 trainer.py:139] Epoch[953/1000] loss: 0.0638666054343476
I0419 11:49:24.011291 28972 trainer.py:139] Epoch[954/1000] loss: 0.06391654229339432
I0419 11:49:29.365803 28972 trainer.py:139] Epoch[955/1000] loss: 0.06408234400784268
I0419 11:49:34.678612 28972 trainer.py:139] Epoch[956/1000] loss: 0.06411303579807281
I0419 11:49:39.905501 28972 trainer.py:139] Epoch[957/1000] loss: 0.0644889454192975
I0419 11:49:45.356441 28972 trainer.py:139] Epoch[958/1000] loss: 0.06451264878406245
I0419 11:49:50.590071 28972 trainer.py:139] Epoch[959/1000] loss: 0.0631965181845076
I0419 11:49:55.873112 28972 trainer.py:139] Epoch[960/1000] loss: 0.06371947509400985
I0419 11:50:01.208026 28972 trainer.py:139] Epoch[961/1000] loss: 0.0642887393341345
I0419 11:50:06.448284 28972 trainer.py:139] Epoch[962/1000] loss: 0.06378726836513071
I0419 11:50:11.735479 28972 trainer.py:139] Epoch[963/1000] loss: 0.06375366909538999
I0419 11:50:17.004881 28972 trainer.py:139] Epoch[964/1000] loss: 0.06391798770603012
I0419 11:50:23.733845 28972 trainer.py:139] Epoch[965/1000] loss: 0.06503514156622045
I0419 11:50:29.964721 28972 trainer.py:139] Epoch[966/1000] loss: 0.06479795978349798
I0419 11:50:35.147305 28972 trainer.py:139] Epoch[967/1000] loss: 0.06404971791540875
I0419 11:50:40.521127 28972 trainer.py:139] Epoch[968/1000] loss: 0.06364431517089114
I0419 11:50:46.005638 28972 trainer.py:139] Epoch[969/1000] loss: 0.06383289462503265
I0419 11:50:51.460618 28972 trainer.py:139] Epoch[970/1000] loss: 0.06381368176902041
I0419 11:50:56.891191 28972 trainer.py:139] Epoch[971/1000] loss: 0.06294832137577674
I0419 11:51:02.222291 28972 trainer.py:139] Epoch[972/1000] loss: 0.06424601858153063
I0419 11:51:09.430515 28972 trainer.py:139] Epoch[973/1000] loss: 0.06350619148682146
I0419 11:51:15.108357 28972 trainer.py:139] Epoch[974/1000] loss: 0.06344924867153168
I0419 11:51:20.427062 28972 trainer.py:139] Epoch[975/1000] loss: 0.06424929354997243
I0419 11:51:25.763002 28972 trainer.py:139] Epoch[976/1000] loss: 0.06453271538895719
I0419 11:51:30.926135 28972 trainer.py:139] Epoch[977/1000] loss: 0.06403720466529622
I0419 11:51:36.215795 28972 trainer.py:139] Epoch[978/1000] loss: 0.06412385798552457
I0419 11:51:41.483391 28972 trainer.py:139] Epoch[979/1000] loss: 0.06404503106194384
I0419 11:51:46.811177 28972 trainer.py:139] Epoch[980/1000] loss: 0.06435386266778498
I0419 11:51:52.094249 28972 trainer.py:139] Epoch[981/1000] loss: 0.06384231018669465
I0419 11:51:57.090157 28972 trainer.py:139] Epoch[982/1000] loss: 0.06416991462602335
I0419 11:52:02.405475 28972 trainer.py:139] Epoch[983/1000] loss: 0.06282915021566783
I0419 11:52:07.737514 28972 trainer.py:139] Epoch[984/1000] loss: 0.0631021204240182
I0419 11:52:12.925148 28972 trainer.py:139] Epoch[985/1000] loss: 0.06379365701885785
I0419 11:52:18.236019 28972 trainer.py:139] Epoch[986/1000] loss: 0.06346494594917577
I0419 11:52:24.599900 28972 trainer.py:139] Epoch[987/1000] loss: 0.0636605223750367
I0419 11:52:30.974580 28972 trainer.py:139] Epoch[988/1000] loss: 0.06402281299233437
I0419 11:52:36.353880 28972 trainer.py:139] Epoch[989/1000] loss: 0.0636586936957696
I0419 11:52:41.689013 28972 trainer.py:139] Epoch[990/1000] loss: 0.06406289667767637
I0419 11:52:46.997424 28972 trainer.py:139] Epoch[991/1000] loss: 0.06380881325286977
I0419 11:52:52.136523 28972 trainer.py:139] Epoch[992/1000] loss: 0.06341035335379488
I0419 11:52:57.485643 28972 trainer.py:139] Epoch[993/1000] loss: 0.06337948669405545
I0419 11:53:02.674331 28972 trainer.py:139] Epoch[994/1000] loss: 0.06406568100347239
I0419 11:53:07.874831 28972 trainer.py:139] Epoch[995/1000] loss: 0.06410793127382503
I0419 11:53:13.142174 28972 trainer.py:139] Epoch[996/1000] loss: 0.06335659040247693
I0419 11:53:18.379428 28972 trainer.py:139] Epoch[997/1000] loss: 0.06359965485685012
I0419 11:53:23.601354 28972 trainer.py:139] Epoch[998/1000] loss: 0.06314518456073369
I0419 11:53:28.972856 28972 trainer.py:139] Epoch[999/1000] loss: 0.0639817265464979
I0419 11:53:29.624227 28972 trainer.py:145] Test: [{'precision': 0.012757028955098618, 'recall': 0.1631713393148559, 'hit_ratio': 0.24213176668065464, 'ndcg': 0.07905492415396959}]
