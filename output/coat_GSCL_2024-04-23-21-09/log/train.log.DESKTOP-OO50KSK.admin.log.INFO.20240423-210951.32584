I0423 21:09:53.438190 15928 trainer.py:118] Test: [{'precision': 0.012447257383966247, 'recall': 0.06504201377619098, 'hit_ratio': 0.19831223628691982, 'ndcg': 0.036127798827941045}]
I0423 21:09:55.185481 15928 trainer.py:136] Epoch[0/200] loss: 0.6833512882391611
I0423 21:09:56.886847 15928 trainer.py:136] Epoch[1/200] loss: 0.6431317706902822
I0423 21:09:58.579331 15928 trainer.py:136] Epoch[2/200] loss: 0.6112272183100382
I0423 21:10:00.269243 15928 trainer.py:136] Epoch[3/200] loss: 0.5774087846279145
I0423 21:10:02.015552 15928 trainer.py:136] Epoch[4/200] loss: 0.5388401607672374
I0423 21:10:03.710001 15928 trainer.py:136] Epoch[5/200] loss: 0.4929808497428894
I0423 21:10:05.396908 15928 trainer.py:136] Epoch[6/200] loss: 0.46902501384417217
I0423 21:10:07.087445 15928 trainer.py:136] Epoch[7/200] loss: 0.429914590716362
I0423 21:10:08.784895 15928 trainer.py:136] Epoch[8/200] loss: 0.4033698598543803
I0423 21:10:10.479777 15928 trainer.py:136] Epoch[9/200] loss: 0.38989047408103944
I0423 21:10:12.169322 15928 trainer.py:136] Epoch[10/200] loss: 0.37394843995571136
I0423 21:10:13.849839 15928 trainer.py:136] Epoch[11/200] loss: 0.3453598529100418
I0423 21:10:15.530851 15928 trainer.py:136] Epoch[12/200] loss: 0.3383743544419607
I0423 21:10:17.205331 15928 trainer.py:136] Epoch[13/200] loss: 0.3140176167090734
I0423 21:10:18.882891 15928 trainer.py:136] Epoch[14/200] loss: 0.3236741065979004
I0423 21:10:20.564462 15928 trainer.py:136] Epoch[15/200] loss: 0.32115320563316346
I0423 21:10:22.274055 15928 trainer.py:136] Epoch[16/200] loss: 0.3061995486418406
I0423 21:10:23.964067 15928 trainer.py:136] Epoch[17/200] loss: 0.3034695252776146
I0423 21:10:25.645620 15928 trainer.py:136] Epoch[18/200] loss: 0.29751410633325576
I0423 21:10:27.346558 15928 trainer.py:136] Epoch[19/200] loss: 0.2945793608824412
I0423 21:10:29.020073 15928 trainer.py:136] Epoch[20/200] loss: 0.2857503245274226
I0423 21:10:30.699579 15928 trainer.py:136] Epoch[21/200] loss: 0.27884900371233623
I0423 21:10:32.374117 15928 trainer.py:136] Epoch[22/200] loss: 0.27209630658229195
I0423 21:10:34.049682 15928 trainer.py:136] Epoch[23/200] loss: 0.2667284960548083
I0423 21:10:35.733239 15928 trainer.py:136] Epoch[24/200] loss: 0.275704355041186
I0423 21:10:37.429129 15928 trainer.py:136] Epoch[25/200] loss: 0.27256382604440055
I0423 21:10:39.130953 15928 trainer.py:136] Epoch[26/200] loss: 0.2583313445250193
I0423 21:10:40.811480 15928 trainer.py:136] Epoch[27/200] loss: 0.26171278953552246
I0423 21:10:42.488477 15928 trainer.py:136] Epoch[28/200] loss: 0.2570358216762543
I0423 21:10:44.202421 15928 trainer.py:136] Epoch[29/200] loss: 0.25329633106788
I0423 21:10:45.884300 15928 trainer.py:136] Epoch[30/200] loss: 0.26354849388202034
I0423 21:10:47.562323 15928 trainer.py:136] Epoch[31/200] loss: 0.2530572305123011
I0423 21:10:49.246183 15928 trainer.py:136] Epoch[32/200] loss: 0.2467236578464508
I0423 21:10:50.916151 15928 trainer.py:136] Epoch[33/200] loss: 0.24570330679416658
I0423 21:10:52.582360 15928 trainer.py:136] Epoch[34/200] loss: 0.24027942766745886
I0423 21:10:54.257365 15928 trainer.py:136] Epoch[35/200] loss: 0.22314166774352392
I0423 21:10:55.938888 15928 trainer.py:136] Epoch[36/200] loss: 0.2305873786409696
I0423 21:10:57.614094 15928 trainer.py:136] Epoch[37/200] loss: 0.21996917128562926
I0423 21:10:59.287037 15928 trainer.py:136] Epoch[38/200] loss: 0.22273027747869492
I0423 21:11:00.979497 15928 trainer.py:136] Epoch[39/200] loss: 0.23184588650862376
I0423 21:11:02.653009 15928 trainer.py:136] Epoch[40/200] loss: 0.2283123974998792
I0423 21:11:04.334980 15928 trainer.py:136] Epoch[41/200] loss: 0.23572810391585033
I0423 21:11:06.021490 15928 trainer.py:136] Epoch[42/200] loss: 0.23376758148272833
I0423 21:11:07.687130 15928 trainer.py:136] Epoch[43/200] loss: 0.21764508336782457
I0423 21:11:09.363099 15928 trainer.py:136] Epoch[44/200] loss: 0.21453194667895634
I0423 21:11:11.026686 15928 trainer.py:136] Epoch[45/200] loss: 0.22204467008511225
I0423 21:11:12.707195 15928 trainer.py:136] Epoch[46/200] loss: 0.2228432983160019
I0423 21:11:14.374204 15928 trainer.py:136] Epoch[47/200] loss: 0.22200752496719361
I0423 21:11:16.051632 15928 trainer.py:136] Epoch[48/200] loss: 0.21802950402100882
I0423 21:11:17.723312 15928 trainer.py:136] Epoch[49/200] loss: 0.20813783208529155
I0423 21:11:17.754209 15928 trainer.py:142] Test: [{'precision': 0.02278481012658226, 'recall': 0.14795639194373372, 'hit_ratio': 0.3628691983122363, 'ndcg': 0.07679095392088013}]
I0423 21:11:19.436900 15928 trainer.py:136] Epoch[50/200] loss: 0.20498221566279728
I0423 21:11:21.123273 15928 trainer.py:136] Epoch[51/200] loss: 0.19650646398464838
I0423 21:11:22.802124 15928 trainer.py:136] Epoch[52/200] loss: 0.2089057222008705
I0423 21:11:24.486301 15928 trainer.py:136] Epoch[53/200] loss: 0.21444349686304728
I0423 21:11:26.158878 15928 trainer.py:136] Epoch[54/200] loss: 0.20995318641265234
I0423 21:11:27.841453 15928 trainer.py:136] Epoch[55/200] loss: 0.19696078846851986
I0423 21:11:29.524375 15928 trainer.py:136] Epoch[56/200] loss: 0.2020197187860807
I0423 21:11:31.190268 15928 trainer.py:136] Epoch[57/200] loss: 0.20331744452317554
I0423 21:11:32.850050 15928 trainer.py:136] Epoch[58/200] loss: 0.20700097133715947
I0423 21:11:34.214049 15928 trainer.py:136] Epoch[59/200] loss: 0.19023020913203556
I0423 21:11:35.544727 15928 trainer.py:136] Epoch[60/200] loss: 0.19804514447848
I0423 21:11:36.881889 15928 trainer.py:136] Epoch[61/200] loss: 0.1915169467528661
I0423 21:11:38.231902 15928 trainer.py:136] Epoch[62/200] loss: 0.19753963872790337
I0423 21:11:39.568634 15928 trainer.py:136] Epoch[63/200] loss: 0.18957898716131846
I0423 21:11:40.929690 15928 trainer.py:136] Epoch[64/200] loss: 0.19274734407663346
I0423 21:11:42.279766 15928 trainer.py:136] Epoch[65/200] loss: 0.19617339372634887
I0423 21:11:43.632060 15928 trainer.py:136] Epoch[66/200] loss: 0.19168911824623744
I0423 21:11:44.989691 15928 trainer.py:136] Epoch[67/200] loss: 0.19418948640426
I0423 21:11:46.329589 15928 trainer.py:136] Epoch[68/200] loss: 0.18316799501578013
I0423 21:11:47.655348 15928 trainer.py:136] Epoch[69/200] loss: 0.17992295076449713
I0423 21:11:48.990528 15928 trainer.py:136] Epoch[70/200] loss: 0.1857138844827811
I0423 21:11:50.347484 15928 trainer.py:136] Epoch[71/200] loss: 0.2047057847181956
I0423 21:11:51.695118 15928 trainer.py:136] Epoch[72/200] loss: 0.19146383330225944
I0423 21:11:53.031212 15928 trainer.py:136] Epoch[73/200] loss: 0.18943307598431905
I0423 21:11:54.376020 15928 trainer.py:136] Epoch[74/200] loss: 0.19009248291452727
I0423 21:11:55.719119 15928 trainer.py:136] Epoch[75/200] loss: 0.19586418469746908
I0423 21:11:57.052096 15928 trainer.py:136] Epoch[76/200] loss: 0.17858824133872986
I0423 21:11:58.402179 15928 trainer.py:136] Epoch[77/200] loss: 0.1818003478149573
I0423 21:11:59.748867 15928 trainer.py:136] Epoch[78/200] loss: 0.17741735875606537
I0423 21:12:01.093937 15928 trainer.py:136] Epoch[79/200] loss: 0.18582876821358998
I0423 21:12:02.450540 15928 trainer.py:136] Epoch[80/200] loss: 0.18284959420561792
I0423 21:12:03.799145 15928 trainer.py:136] Epoch[81/200] loss: 0.1806040585041046
I0423 21:12:05.161213 15928 trainer.py:136] Epoch[82/200] loss: 0.19247625917196273
I0423 21:12:06.508324 15928 trainer.py:136] Epoch[83/200] loss: 0.1748909682035446
I0423 21:12:07.856006 15928 trainer.py:136] Epoch[84/200] loss: 0.16946407283345857
I0423 21:12:09.196086 15928 trainer.py:136] Epoch[85/200] loss: 0.17217175687352818
I0423 21:12:10.517264 15928 trainer.py:136] Epoch[86/200] loss: 0.18798459619283675
I0423 21:12:11.843038 15928 trainer.py:136] Epoch[87/200] loss: 0.17579067200422288
I0423 21:12:13.173153 15928 trainer.py:136] Epoch[88/200] loss: 0.16805782814820608
I0423 21:12:14.509239 15928 trainer.py:136] Epoch[89/200] loss: 0.18166458283861478
I0423 21:12:15.833207 15928 trainer.py:136] Epoch[90/200] loss: 0.1649180846909682
I0423 21:12:17.207159 15928 trainer.py:136] Epoch[91/200] loss: 0.1832148271302382
I0423 21:12:18.534813 15928 trainer.py:136] Epoch[92/200] loss: 0.18149434104561807
I0423 21:12:19.900785 15928 trainer.py:136] Epoch[93/200] loss: 0.18170241018136343
I0423 21:12:21.249840 15928 trainer.py:136] Epoch[94/200] loss: 0.1791710965335369
I0423 21:12:22.606369 15928 trainer.py:136] Epoch[95/200] loss: 0.17152851248780887
I0423 21:12:23.975699 15928 trainer.py:136] Epoch[96/200] loss: 0.17596014390389125
I0423 21:12:25.330333 15928 trainer.py:136] Epoch[97/200] loss: 0.18068771908680598
I0423 21:12:26.683677 15928 trainer.py:136] Epoch[98/200] loss: 0.17851689209540686
I0423 21:12:28.022370 15928 trainer.py:136] Epoch[99/200] loss: 0.17862178807457288
I0423 21:12:28.042302 15928 trainer.py:142] Test: [{'precision': 0.024472573839662424, 'recall': 0.1653200058263349, 'hit_ratio': 0.3881856540084388, 'ndcg': 0.08021206552453532}]
I0423 21:12:29.388399 15928 trainer.py:136] Epoch[100/200] loss: 0.18334027429421743
I0423 21:12:30.715684 15928 trainer.py:136] Epoch[101/200] loss: 0.1611949441333612
I0423 21:12:32.063740 15928 trainer.py:136] Epoch[102/200] loss: 0.16901885320742924
I0423 21:12:33.428765 15928 trainer.py:136] Epoch[103/200] loss: 0.16232708543539048
I0423 21:12:34.773998 15928 trainer.py:136] Epoch[104/200] loss: 0.1705595761537552
I0423 21:12:36.137001 15928 trainer.py:136] Epoch[105/200] loss: 0.1693751203517119
I0423 21:12:37.479028 15928 trainer.py:136] Epoch[106/200] loss: 0.17676962688565254
I0423 21:12:38.811742 15928 trainer.py:136] Epoch[107/200] loss: 0.1637142854432265
I0423 21:12:40.165788 15928 trainer.py:136] Epoch[108/200] loss: 0.17106519664327305
I0423 21:12:41.507844 15928 trainer.py:136] Epoch[109/200] loss: 0.1685173364977042
I0423 21:12:42.856346 15928 trainer.py:136] Epoch[110/200] loss: 0.17414945910374324
I0423 21:12:44.211372 15928 trainer.py:136] Epoch[111/200] loss: 0.1738712566594283
I0423 21:12:45.551096 15928 trainer.py:136] Epoch[112/200] loss: 0.16730317225058874
I0423 21:12:46.886223 15928 trainer.py:136] Epoch[113/200] loss: 0.17291520908474922
I0423 21:12:48.230289 15928 trainer.py:136] Epoch[114/200] loss: 0.17438786178827287
I0423 21:12:49.568033 15928 trainer.py:136] Epoch[115/200] loss: 0.17117483764886857
I0423 21:12:50.918717 15928 trainer.py:136] Epoch[116/200] loss: 0.17312490517894427
I0423 21:12:52.260784 15928 trainer.py:136] Epoch[117/200] loss: 0.167285767942667
I0423 21:12:53.610389 15928 trainer.py:136] Epoch[118/200] loss: 0.1686497986316681
I0423 21:12:54.959106 15928 trainer.py:136] Epoch[119/200] loss: 0.1592861719429493
I0423 21:12:56.300175 15928 trainer.py:136] Epoch[120/200] loss: 0.1584791548550129
I0423 21:12:57.667776 15928 trainer.py:136] Epoch[121/200] loss: 0.1604257067044576
I0423 21:12:59.021827 15928 trainer.py:136] Epoch[122/200] loss: 0.15587857514619827
I0423 21:13:00.380827 15928 trainer.py:136] Epoch[123/200] loss: 0.16503680671254795
I0423 21:13:01.720503 15928 trainer.py:136] Epoch[124/200] loss: 0.1575688714782397
I0423 21:13:03.081543 15928 trainer.py:136] Epoch[125/200] loss: 0.16239777977267902
I0423 21:13:04.435706 15928 trainer.py:136] Epoch[126/200] loss: 0.16494598388671874
I0423 21:13:05.733577 15928 trainer.py:136] Epoch[127/200] loss: 0.1681388591726621
I0423 21:13:07.057760 15928 trainer.py:136] Epoch[128/200] loss: 0.1625898855427901
I0423 21:13:08.378956 15928 trainer.py:136] Epoch[129/200] loss: 0.16440622756878534
I0423 21:13:09.705705 15928 trainer.py:136] Epoch[130/200] loss: 0.18184820239742597
I0423 21:13:11.020930 15928 trainer.py:136] Epoch[131/200] loss: 0.17246440971891086
I0423 21:13:12.366994 15928 trainer.py:136] Epoch[132/200] loss: 0.15588025376200676
I0423 21:13:13.705640 15928 trainer.py:136] Epoch[133/200] loss: 0.15464826176563898
I0423 21:13:15.028763 15928 trainer.py:136] Epoch[134/200] loss: 0.1653718980650107
I0423 21:13:16.370808 15928 trainer.py:136] Epoch[135/200] loss: 0.16093727971116703
I0423 21:13:17.692571 15928 trainer.py:136] Epoch[136/200] loss: 0.16707390223940213
I0423 21:13:19.039667 15928 trainer.py:136] Epoch[137/200] loss: 0.1597143826385339
I0423 21:13:20.370763 15928 trainer.py:136] Epoch[138/200] loss: 0.16895741671323777
I0423 21:13:21.722388 15928 trainer.py:136] Epoch[139/200] loss: 0.15997834553321202
I0423 21:13:23.082631 15928 trainer.py:136] Epoch[140/200] loss: 0.15162244985500972
I0423 21:13:24.443035 15928 trainer.py:136] Epoch[141/200] loss: 0.1564821866651376
I0423 21:13:25.776707 15928 trainer.py:136] Epoch[142/200] loss: 0.1552470197280248
I0423 21:13:27.104866 15928 trainer.py:136] Epoch[143/200] loss: 0.17771691580613455
I0423 21:13:28.432564 15928 trainer.py:136] Epoch[144/200] loss: 0.16165173997481663
I0423 21:13:29.772187 15928 trainer.py:136] Epoch[145/200] loss: 0.15295406902829806
I0423 21:13:31.116743 15928 trainer.py:136] Epoch[146/200] loss: 0.16662960425019263
I0423 21:13:32.442894 15928 trainer.py:136] Epoch[147/200] loss: 0.16353491817911467
I0423 21:13:33.765591 15928 trainer.py:136] Epoch[148/200] loss: 0.16011379410823187
I0423 21:13:35.099695 15928 trainer.py:136] Epoch[149/200] loss: 0.1661143844326337
I0423 21:13:35.124612 15928 trainer.py:142] Test: [{'precision': 0.02341772151898733, 'recall': 0.17786880723589583, 'hit_ratio': 0.4028691983122363, 'ndcg': 0.08101245069419997}]
I0423 21:13:36.462711 15928 trainer.py:136] Epoch[150/200] loss: 0.16389381190141042
I0423 21:13:37.804329 15928 trainer.py:136] Epoch[151/200] loss: 0.16837426026662192
I0423 21:13:39.140417 15928 trainer.py:136] Epoch[152/200] loss: 0.15915345350901286
I0423 21:13:40.460568 15928 trainer.py:136] Epoch[153/200] loss: 0.1593981998662154
I0423 21:13:41.793317 15928 trainer.py:136] Epoch[154/200] loss: 0.16797370538115503
I0423 21:13:43.112466 15928 trainer.py:136] Epoch[155/200] loss: 0.15810259605447452
I0423 21:13:44.443618 15928 trainer.py:136] Epoch[156/200] loss: 0.1572163335978985
I0423 21:13:45.763417 15928 trainer.py:136] Epoch[157/200] loss: 0.1682290313144525
I0423 21:13:47.096588 15928 trainer.py:136] Epoch[158/200] loss: 0.16682899345954258
I0423 21:13:48.437705 15928 trainer.py:136] Epoch[159/200] loss: 0.16104239399234455
I0423 21:13:49.585986 15928 trainer.py:136] Epoch[160/200] loss: 0.15086264833807944
I0423 21:13:50.619226 15928 trainer.py:136] Epoch[161/200] loss: 0.15812569186091424
I0423 21:13:51.603498 15928 trainer.py:136] Epoch[162/200] loss: 0.16831081608931223
I0423 21:13:52.608747 15928 trainer.py:136] Epoch[163/200] loss: 0.15863185102740923
I0423 21:13:53.590071 15928 trainer.py:136] Epoch[164/200] loss: 0.16286596432328224
I0423 21:13:54.581848 15928 trainer.py:136] Epoch[165/200] loss: 0.16108056878050167
I0423 21:13:55.571502 15928 trainer.py:136] Epoch[166/200] loss: 0.15255331446727116
I0423 21:13:56.570272 15928 trainer.py:136] Epoch[167/200] loss: 0.1559968374669552
I0423 21:13:57.589881 15928 trainer.py:136] Epoch[168/200] loss: 0.15146252363920212
I0423 21:13:58.552286 15928 trainer.py:136] Epoch[169/200] loss: 0.1507522225379944
I0423 21:13:59.537989 15928 trainer.py:136] Epoch[170/200] loss: 0.16387512534856796
I0423 21:14:00.545724 15928 trainer.py:136] Epoch[171/200] loss: 0.16578058650096258
I0423 21:14:01.551938 15928 trainer.py:136] Epoch[172/200] loss: 0.15990039333701134
I0423 21:14:02.546194 15928 trainer.py:136] Epoch[173/200] loss: 0.15910477191209793
I0423 21:14:03.575355 15928 trainer.py:136] Epoch[174/200] loss: 0.1615296942492326
I0423 21:14:04.594543 15928 trainer.py:136] Epoch[175/200] loss: 0.16107887774705887
I0423 21:14:05.596760 15928 trainer.py:136] Epoch[176/200] loss: 0.15709344272812206
I0423 21:14:06.548756 15928 trainer.py:136] Epoch[177/200] loss: 0.15846450701355935
I0423 21:14:07.540003 15928 trainer.py:136] Epoch[178/200] loss: 0.15541736086209615
I0423 21:14:08.238665 15928 trainer.py:136] Epoch[179/200] loss: 0.1452346384525299
I0423 21:14:08.903133 15928 trainer.py:136] Epoch[180/200] loss: 0.15332085887591043
I0423 21:14:09.540693 15928 trainer.py:136] Epoch[181/200] loss: 0.143837754180034
I0423 21:14:10.171583 15928 trainer.py:136] Epoch[182/200] loss: 0.1515600065390269
I0423 21:14:10.809978 15928 trainer.py:136] Epoch[183/200] loss: 0.16123018364111583
I0423 21:14:11.468774 15928 trainer.py:136] Epoch[184/200] loss: 0.15500614047050476
I0423 21:14:12.116184 15928 trainer.py:136] Epoch[185/200] loss: 0.15585150569677353
I0423 21:14:12.768632 15928 trainer.py:136] Epoch[186/200] loss: 0.1642645185192426
I0423 21:14:13.363641 15928 trainer.py:136] Epoch[187/200] loss: 0.16124265467127163
I0423 21:14:13.965218 15928 trainer.py:136] Epoch[188/200] loss: 0.15685142055153847
I0423 21:14:14.612743 15928 trainer.py:136] Epoch[189/200] loss: 0.16025915270050367
I0423 21:14:15.183832 15928 trainer.py:136] Epoch[190/200] loss: 0.15200456057985623
I0423 21:14:15.617971 15928 trainer.py:136] Epoch[191/200] loss: 0.16197983523209888
I0423 21:14:15.929928 15928 trainer.py:136] Epoch[192/200] loss: 0.15822915062308313
I0423 21:14:16.241884 15928 trainer.py:136] Epoch[193/200] loss: 0.16330489590764047
I0423 21:14:16.574315 15928 trainer.py:136] Epoch[194/200] loss: 0.158570293088754
I0423 21:14:16.902218 15928 trainer.py:136] Epoch[195/200] loss: 0.1690610741575559
I0423 21:14:17.231117 15928 trainer.py:136] Epoch[196/200] loss: 0.15234125008185703
I0423 21:14:17.543632 15928 trainer.py:136] Epoch[197/200] loss: 0.14437362030148507
I0423 21:14:17.868308 15928 trainer.py:136] Epoch[198/200] loss: 0.16116013377904892
I0423 21:14:18.182257 15928 trainer.py:136] Epoch[199/200] loss: 0.15056631043553353
I0423 21:14:18.193221 15928 trainer.py:142] Test: [{'precision': 0.0232067510548523, 'recall': 0.1657811269836586, 'hit_ratio': 0.39130801687763715, 'ndcg': 0.07927543186929512}]
