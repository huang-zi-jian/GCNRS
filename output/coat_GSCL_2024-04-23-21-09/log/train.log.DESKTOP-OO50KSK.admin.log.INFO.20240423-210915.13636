I0423 21:09:17.225937 27448 trainer.py:118] Test: [{'precision': 0.014135021097046408, 'recall': 0.08158559677547017, 'hit_ratio': 0.24472573839662448, 'ndcg': 0.0432471759515794}]
I0423 21:09:17.851617 27448 trainer.py:136] Epoch[0/200] loss: 0.681909054517746
I0423 21:09:18.494467 27448 trainer.py:136] Epoch[1/200] loss: 0.6406552791595459
I0423 21:09:19.154827 27448 trainer.py:136] Epoch[2/200] loss: 0.6059927046298981
I0423 21:09:19.783313 27448 trainer.py:136] Epoch[3/200] loss: 0.5638450960318248
I0423 21:09:20.452076 27448 trainer.py:136] Epoch[4/200] loss: 0.5347019294897716
I0423 21:09:21.107541 27448 trainer.py:136] Epoch[5/200] loss: 0.4988556355237961
I0423 21:09:21.767909 27448 trainer.py:136] Epoch[6/200] loss: 0.4440433273712794
I0423 21:09:22.413748 27448 trainer.py:136] Epoch[7/200] loss: 0.42269531190395354
I0423 21:09:23.041210 27448 trainer.py:136] Epoch[8/200] loss: 0.40118193825085957
I0423 21:09:23.676317 27448 trainer.py:136] Epoch[9/200] loss: 0.3687073250611623
I0423 21:09:24.309201 27448 trainer.py:136] Epoch[10/200] loss: 0.35986521939436594
I0423 21:09:24.941664 27448 trainer.py:136] Epoch[11/200] loss: 0.3524913782874743
I0423 21:09:25.579115 27448 trainer.py:136] Epoch[12/200] loss: 0.3439129481712977
I0423 21:09:26.215984 27448 trainer.py:136] Epoch[13/200] loss: 0.31623072177171707
I0423 21:09:26.870365 27448 trainer.py:136] Epoch[14/200] loss: 0.32495449483394623
I0423 21:09:27.539675 27448 trainer.py:136] Epoch[15/200] loss: 0.3339238514502843
I0423 21:09:28.216410 27448 trainer.py:136] Epoch[16/200] loss: 0.32148615370194117
I0423 21:09:28.931558 27448 trainer.py:136] Epoch[17/200] loss: 0.301384607454141
I0423 21:09:29.761354 27448 trainer.py:136] Epoch[18/200] loss: 0.2946447859207789
I0423 21:09:30.757594 27448 trainer.py:136] Epoch[19/200] loss: 0.30761215736468633
I0423 21:09:31.753880 27448 trainer.py:136] Epoch[20/200] loss: 0.312741752465566
I0423 21:09:32.736188 27448 trainer.py:136] Epoch[21/200] loss: 0.2820318271716436
I0423 21:09:33.717467 27448 trainer.py:136] Epoch[22/200] loss: 0.2741085201501846
I0423 21:09:34.750569 27448 trainer.py:136] Epoch[23/200] loss: 0.29175872455040613
I0423 21:09:35.774729 27448 trainer.py:136] Epoch[24/200] loss: 0.28155650198459625
I0423 21:09:36.809812 27448 trainer.py:136] Epoch[25/200] loss: 0.26476588994264605
I0423 21:09:37.820967 27448 trainer.py:136] Epoch[26/200] loss: 0.2933710689345996
I0423 21:09:38.848092 27448 trainer.py:136] Epoch[27/200] loss: 0.2652239739894867
I0423 21:09:39.855266 27448 trainer.py:136] Epoch[28/200] loss: 0.2555417358875275
I0423 21:09:40.899343 27448 trainer.py:136] Epoch[29/200] loss: 0.2691585083802541
I0423 21:09:42.028109 27448 trainer.py:136] Epoch[30/200] loss: 0.26683379461367923
I0423 21:09:43.373152 27448 trainer.py:136] Epoch[31/200] loss: 0.26380644788344704
I0423 21:09:44.731736 27448 trainer.py:136] Epoch[32/200] loss: 0.2583654274543126
I0423 21:09:46.072853 27448 trainer.py:136] Epoch[33/200] loss: 0.2519684299826622
I0423 21:09:47.418915 27448 trainer.py:136] Epoch[34/200] loss: 0.24053261677424112
I0423 21:09:48.786467 27448 trainer.py:136] Epoch[35/200] loss: 0.24100340803464254
I0423 21:09:50.162412 27448 trainer.py:136] Epoch[36/200] loss: 0.24395487954219183
I0423 21:09:51.508482 27448 trainer.py:136] Epoch[37/200] loss: 0.25245859821637473
I0423 21:09:52.943843 27448 trainer.py:136] Epoch[38/200] loss: 0.23486201614141464
I0423 21:09:54.575520 27448 trainer.py:136] Epoch[39/200] loss: 0.23437570581833522
I0423 21:09:56.294320 27448 trainer.py:136] Epoch[40/200] loss: 0.22571368118127186
I0423 21:09:57.979749 27448 trainer.py:136] Epoch[41/200] loss: 0.2203012079000473
I0423 21:09:59.669250 27448 trainer.py:136] Epoch[42/200] loss: 0.23657211065292358
I0423 21:10:01.400031 27448 trainer.py:136] Epoch[43/200] loss: 0.2217875301837921
I0423 21:10:03.089510 27448 trainer.py:136] Epoch[44/200] loss: 0.21374499201774597
I0423 21:10:04.785952 27448 trainer.py:136] Epoch[45/200] loss: 0.2218351056178411
I0423 21:10:06.480839 27448 trainer.py:136] Epoch[46/200] loss: 0.22130786925554274
I0423 21:10:08.174371 27448 trainer.py:136] Epoch[47/200] loss: 0.21730228414138159
I0423 21:10:09.896726 27448 trainer.py:136] Epoch[48/200] loss: 0.22075217564900715
I0423 21:10:11.585276 27448 trainer.py:136] Epoch[49/200] loss: 0.20489432414372763
I0423 21:10:11.616173 27448 trainer.py:142] Test: [{'precision': 0.02278481012658226, 'recall': 0.15233527606945327, 'hit_ratio': 0.37130801687763715, 'ndcg': 0.07477707477053169}]
I0423 21:10:13.307085 27448 trainer.py:136] Epoch[50/200] loss: 0.21126264631748198
I0423 21:10:14.999558 27448 trainer.py:136] Epoch[51/200] loss: 0.204816272854805
I0423 21:10:16.710986 27448 trainer.py:136] Epoch[52/200] loss: 0.19975397090117136
I0423 21:10:18.392932 27448 trainer.py:136] Epoch[53/200] loss: 0.21490118900934854
I0423 21:10:20.074483 27448 trainer.py:136] Epoch[54/200] loss: 0.2159509390592575
I0423 21:10:21.743828 27448 trainer.py:136] Epoch[55/200] loss: 0.2029003674785296
I0423 21:10:23.426257 27448 trainer.py:136] Epoch[56/200] loss: 0.2101246863603592
I0423 21:10:25.117821 27448 trainer.py:136] Epoch[57/200] loss: 0.20771331290404002
I0423 21:10:26.812345 27448 trainer.py:136] Epoch[58/200] loss: 0.208999598522981
I0423 21:10:28.499259 27448 trainer.py:136] Epoch[59/200] loss: 0.1947134792804718
I0423 21:10:30.180755 27448 trainer.py:136] Epoch[60/200] loss: 0.2065268894036611
I0423 21:10:31.859838 27448 trainer.py:136] Epoch[61/200] loss: 0.20098696996768314
I0423 21:10:33.553343 27448 trainer.py:136] Epoch[62/200] loss: 0.21219910184542337
I0423 21:10:35.233365 27448 trainer.py:136] Epoch[63/200] loss: 0.21286391591032347
I0423 21:10:36.918837 27448 trainer.py:136] Epoch[64/200] loss: 0.2034261092543602
I0423 21:10:38.623198 27448 trainer.py:136] Epoch[65/200] loss: 0.19161367466052373
I0423 21:10:40.319541 27448 trainer.py:136] Epoch[66/200] loss: 0.2029451901714007
I0423 21:10:42.017054 27448 trainer.py:136] Epoch[67/200] loss: 0.20219729989767074
I0423 21:10:43.693542 27448 trainer.py:136] Epoch[68/200] loss: 0.19191077053546907
I0423 21:10:45.382281 27448 trainer.py:136] Epoch[69/200] loss: 0.19175522526105246
I0423 21:10:47.067003 27448 trainer.py:136] Epoch[70/200] loss: 0.1871811603506406
I0423 21:10:48.752834 27448 trainer.py:136] Epoch[71/200] loss: 0.18474590654174486
I0423 21:10:50.422567 27448 trainer.py:136] Epoch[72/200] loss: 0.18384099652369817
I0423 21:10:52.094405 27448 trainer.py:136] Epoch[73/200] loss: 0.19260168224573135
I0423 21:10:53.770992 27448 trainer.py:136] Epoch[74/200] loss: 0.19757234901189805
I0423 21:10:55.453943 27448 trainer.py:136] Epoch[75/200] loss: 0.19088115220268567
I0423 21:10:57.134459 27448 trainer.py:136] Epoch[76/200] loss: 0.19424715638160706
I0423 21:10:58.795680 27448 trainer.py:136] Epoch[77/200] loss: 0.19756579101085664
I0423 21:11:00.463672 27448 trainer.py:136] Epoch[78/200] loss: 0.1808467465142409
I0423 21:11:02.140172 27448 trainer.py:136] Epoch[79/200] loss: 0.175794567912817
I0423 21:11:03.829671 27448 trainer.py:136] Epoch[80/200] loss: 0.1884179890155792
I0423 21:11:05.519581 27448 trainer.py:136] Epoch[81/200] loss: 0.17646041611830393
I0423 21:11:07.198168 27448 trainer.py:136] Epoch[82/200] loss: 0.17881335467100143
I0423 21:11:08.893670 27448 trainer.py:136] Epoch[83/200] loss: 0.18732240150372187
I0423 21:11:10.560246 27448 trainer.py:136] Epoch[84/200] loss: 0.1798226147890091
I0423 21:11:12.232220 27448 trainer.py:136] Epoch[85/200] loss: 0.200201129168272
I0423 21:11:13.901785 27448 trainer.py:136] Epoch[86/200] loss: 0.18258872305353482
I0423 21:11:15.583199 27448 trainer.py:136] Epoch[87/200] loss: 0.17796932607889177
I0423 21:11:17.240074 27448 trainer.py:136] Epoch[88/200] loss: 0.1770339990655581
I0423 21:11:18.923153 27448 trainer.py:136] Epoch[89/200] loss: 0.1696408080557982
I0423 21:11:20.578097 27448 trainer.py:136] Epoch[90/200] loss: 0.1902635375658671
I0423 21:11:22.264694 27448 trainer.py:136] Epoch[91/200] loss: 0.1789391577243805
I0423 21:11:23.958069 27448 trainer.py:136] Epoch[92/200] loss: 0.18028771628936133
I0423 21:11:25.643603 27448 trainer.py:136] Epoch[93/200] loss: 0.17507268488407135
I0423 21:11:27.312984 27448 trainer.py:136] Epoch[94/200] loss: 0.1777349258462588
I0423 21:11:28.977204 27448 trainer.py:136] Epoch[95/200] loss: 0.17417705357074736
I0423 21:11:30.640701 27448 trainer.py:136] Epoch[96/200] loss: 0.18770037020246189
I0423 21:11:32.307424 27448 trainer.py:136] Epoch[97/200] loss: 0.179423459370931
I0423 21:11:33.764554 27448 trainer.py:136] Epoch[98/200] loss: 0.1757547008494536
I0423 21:11:35.087695 27448 trainer.py:136] Epoch[99/200] loss: 0.16780778268973032
I0423 21:11:35.113608 27448 trainer.py:142] Test: [{'precision': 0.02383966244725736, 'recall': 0.16186913180584067, 'hit_ratio': 0.3924050632911392, 'ndcg': 0.07759661763974024}]
I0423 21:11:36.450696 27448 trainer.py:136] Epoch[100/200] loss: 0.1726365844408671
I0423 21:11:37.779567 27448 trainer.py:136] Epoch[101/200] loss: 0.18084989711642266
I0423 21:11:39.116535 27448 trainer.py:136] Epoch[102/200] loss: 0.1702039194603761
I0423 21:11:40.450683 27448 trainer.py:136] Epoch[103/200] loss: 0.1774393379688263
I0423 21:11:41.782429 27448 trainer.py:136] Epoch[104/200] loss: 0.17146647348999977
I0423 21:11:43.109591 27448 trainer.py:136] Epoch[105/200] loss: 0.179522867500782
I0423 21:11:44.449353 27448 trainer.py:136] Epoch[106/200] loss: 0.1757113921145598
I0423 21:11:45.791124 27448 trainer.py:136] Epoch[107/200] loss: 0.17899004022280376
I0423 21:11:47.140403 27448 trainer.py:136] Epoch[108/200] loss: 0.1748180200656255
I0423 21:11:48.473154 27448 trainer.py:136] Epoch[109/200] loss: 0.1763462893664837
I0423 21:11:49.804781 27448 trainer.py:136] Epoch[110/200] loss: 0.16240505129098892
I0423 21:11:51.138426 27448 trainer.py:136] Epoch[111/200] loss: 0.1621773585677147
I0423 21:11:52.463547 27448 trainer.py:136] Epoch[112/200] loss: 0.18668549954891206
I0423 21:11:53.807005 27448 trainer.py:136] Epoch[113/200] loss: 0.1669428991774718
I0423 21:11:55.152449 27448 trainer.py:136] Epoch[114/200] loss: 0.17092601234714191
I0423 21:11:56.487386 27448 trainer.py:136] Epoch[115/200] loss: 0.1740656276543935
I0423 21:11:57.853016 27448 trainer.py:136] Epoch[116/200] loss: 0.16988332370917003
I0423 21:11:59.203119 27448 trainer.py:136] Epoch[117/200] loss: 0.1585429050028324
I0423 21:12:00.551751 27448 trainer.py:136] Epoch[118/200] loss: 0.17714892203609148
I0423 21:12:01.902374 27448 trainer.py:136] Epoch[119/200] loss: 0.164864535878102
I0423 21:12:03.239454 27448 trainer.py:136] Epoch[120/200] loss: 0.16572155157725016
I0423 21:12:04.587134 27448 trainer.py:136] Epoch[121/200] loss: 0.172927575558424
I0423 21:12:05.927267 27448 trainer.py:136] Epoch[122/200] loss: 0.166181331127882
I0423 21:12:07.263435 27448 trainer.py:136] Epoch[123/200] loss: 0.16927621116240818
I0423 21:12:08.599083 27448 trainer.py:136] Epoch[124/200] loss: 0.170356085896492
I0423 21:12:09.934215 27448 trainer.py:136] Epoch[125/200] loss: 0.16164984554052353
I0423 21:12:11.262371 27448 trainer.py:136] Epoch[126/200] loss: 0.166516891370217
I0423 21:12:12.609040 27448 trainer.py:136] Epoch[127/200] loss: 0.16849134787917136
I0423 21:12:13.942136 27448 trainer.py:136] Epoch[128/200] loss: 0.15828045879801114
I0423 21:12:15.275074 27448 trainer.py:136] Epoch[129/200] loss: 0.17280840873718262
I0423 21:12:16.608163 27448 trainer.py:136] Epoch[130/200] loss: 0.16742259586850802
I0423 21:12:17.942257 27448 trainer.py:136] Epoch[131/200] loss: 0.16554272125164668
I0423 21:12:19.275337 27448 trainer.py:136] Epoch[132/200] loss: 0.16670909126599628
I0423 21:12:20.593037 27448 trainer.py:136] Epoch[133/200] loss: 0.16452618390321733
I0423 21:12:21.914158 27448 trainer.py:136] Epoch[134/200] loss: 0.16627672786513964
I0423 21:12:23.250511 27448 trainer.py:136] Epoch[135/200] loss: 0.1674348880847295
I0423 21:12:24.613170 27448 trainer.py:136] Epoch[136/200] loss: 0.1584266868730386
I0423 21:12:25.968620 27448 trainer.py:136] Epoch[137/200] loss: 0.16697515348593395
I0423 21:12:27.305597 27448 trainer.py:136] Epoch[138/200] loss: 0.1712436594069004
I0423 21:12:28.644887 27448 trainer.py:136] Epoch[139/200] loss: 0.15974658106764159
I0423 21:12:29.977545 27448 trainer.py:136] Epoch[140/200] loss: 0.158332130809625
I0423 21:12:31.311691 27448 trainer.py:136] Epoch[141/200] loss: 0.1691046153505643
I0423 21:12:32.653359 27448 trainer.py:136] Epoch[142/200] loss: 0.15520259141921997
I0423 21:12:33.998475 27448 trainer.py:136] Epoch[143/200] loss: 0.167603184034427
I0423 21:12:35.343094 27448 trainer.py:136] Epoch[144/200] loss: 0.163164555033048
I0423 21:12:36.690739 27448 trainer.py:136] Epoch[145/200] loss: 0.17680680950482686
I0423 21:12:38.029753 27448 trainer.py:136] Epoch[146/200] loss: 0.1669903521736463
I0423 21:12:39.356919 27448 trainer.py:136] Epoch[147/200] loss: 0.16601117998361586
I0423 21:12:40.680612 27448 trainer.py:136] Epoch[148/200] loss: 0.15718872497479122
I0423 21:12:42.026566 27448 trainer.py:136] Epoch[149/200] loss: 0.1553169310092926
I0423 21:12:42.050486 27448 trainer.py:142] Test: [{'precision': 0.02489451476793246, 'recall': 0.17753017259346367, 'hit_ratio': 0.4150632911392405, 'ndcg': 0.08289449835964248}]
I0423 21:12:43.393550 27448 trainer.py:136] Epoch[150/200] loss: 0.16895402744412422
I0423 21:12:44.724230 27448 trainer.py:136] Epoch[151/200] loss: 0.157924214998881
I0423 21:12:46.074346 27448 trainer.py:136] Epoch[152/200] loss: 0.17882362008094788
I0423 21:12:47.423427 27448 trainer.py:136] Epoch[153/200] loss: 0.16999781678120296
I0423 21:12:48.766099 27448 trainer.py:136] Epoch[154/200] loss: 0.1552611562112967
I0423 21:12:50.109865 27448 trainer.py:136] Epoch[155/200] loss: 0.15694679816563925
I0423 21:12:51.451934 27448 trainer.py:136] Epoch[156/200] loss: 0.16399360274275143
I0423 21:12:52.797540 27448 trainer.py:136] Epoch[157/200] loss: 0.15496771360437075
I0423 21:12:54.153572 27448 trainer.py:136] Epoch[158/200] loss: 0.1669803979496161
I0423 21:12:55.490329 27448 trainer.py:136] Epoch[159/200] loss: 0.16349502603212993
I0423 21:12:56.812075 27448 trainer.py:136] Epoch[160/200] loss: 0.15751903851826984
I0423 21:12:58.159132 27448 trainer.py:136] Epoch[161/200] loss: 0.17044254392385483
I0423 21:12:59.485277 27448 trainer.py:136] Epoch[162/200] loss: 0.16691079835096995
I0423 21:13:00.839849 27448 trainer.py:136] Epoch[163/200] loss: 0.15431225324670475
I0423 21:13:02.176975 27448 trainer.py:136] Epoch[164/200] loss: 0.15914424608151118
I0423 21:13:03.532727 27448 trainer.py:136] Epoch[165/200] loss: 0.15325383022427558
I0423 21:13:04.892763 27448 trainer.py:136] Epoch[166/200] loss: 0.15774236768484115
I0423 21:13:06.233902 27448 trainer.py:136] Epoch[167/200] loss: 0.1734793372452259
I0423 21:13:07.555711 27448 trainer.py:136] Epoch[168/200] loss: 0.15256575966874758
I0423 21:13:08.884869 27448 trainer.py:136] Epoch[169/200] loss: 0.17148917838931083
I0423 21:13:10.207028 27448 trainer.py:136] Epoch[170/200] loss: 0.15634744515021642
I0423 21:13:11.543748 27448 trainer.py:136] Epoch[171/200] loss: 0.1613246090710163
I0423 21:13:12.877834 27448 trainer.py:136] Epoch[172/200] loss: 0.15927730451027552
I0423 21:13:14.214936 27448 trainer.py:136] Epoch[173/200] loss: 0.1564465676744779
I0423 21:13:15.553542 27448 trainer.py:136] Epoch[174/200] loss: 0.1512310393154621
I0423 21:13:16.885678 27448 trainer.py:136] Epoch[175/200] loss: 0.16328267976641656
I0423 21:13:18.225787 27448 trainer.py:136] Epoch[176/200] loss: 0.15058196981747946
I0423 21:13:19.544527 27448 trainer.py:136] Epoch[177/200] loss: 0.16143255705634754
I0423 21:13:20.882602 27448 trainer.py:136] Epoch[178/200] loss: 0.15434098914265632
I0423 21:13:22.212748 27448 trainer.py:136] Epoch[179/200] loss: 0.1586310495932897
I0423 21:13:23.541671 27448 trainer.py:136] Epoch[180/200] loss: 0.15333282326658568
I0423 21:13:24.872163 27448 trainer.py:136] Epoch[181/200] loss: 0.1606418952345848
I0423 21:13:26.236170 27448 trainer.py:136] Epoch[182/200] loss: 0.1606976367533207
I0423 21:13:27.567871 27448 trainer.py:136] Epoch[183/200] loss: 0.15490186139941214
I0423 21:13:28.920484 27448 trainer.py:136] Epoch[184/200] loss: 0.14630576993028324
I0423 21:13:30.248034 27448 trainer.py:136] Epoch[185/200] loss: 0.16094190205136935
I0423 21:13:31.577788 27448 trainer.py:136] Epoch[186/200] loss: 0.15226301724712055
I0423 21:13:32.905904 27448 trainer.py:136] Epoch[187/200] loss: 0.1521267329653104
I0423 21:13:34.238010 27448 trainer.py:136] Epoch[188/200] loss: 0.15634970118602118
I0423 21:13:35.561725 27448 trainer.py:136] Epoch[189/200] loss: 0.14502070993185043
I0423 21:13:36.911769 27448 trainer.py:136] Epoch[190/200] loss: 0.1560141752163569
I0423 21:13:38.242861 27448 trainer.py:136] Epoch[191/200] loss: 0.15346497570474943
I0423 21:13:39.586493 27448 trainer.py:136] Epoch[192/200] loss: 0.15508929441372554
I0423 21:13:40.944562 27448 trainer.py:136] Epoch[193/200] loss: 0.15189148038625716
I0423 21:13:42.288661 27448 trainer.py:136] Epoch[194/200] loss: 0.14922697544097902
I0423 21:13:43.635321 27448 trainer.py:136] Epoch[195/200] loss: 0.15340969438354174
I0423 21:13:44.980393 27448 trainer.py:136] Epoch[196/200] loss: 0.15487718358635902
I0423 21:13:46.315569 27448 trainer.py:136] Epoch[197/200] loss: 0.17082652499278386
I0423 21:13:47.653331 27448 trainer.py:136] Epoch[198/200] loss: 0.15316433707873026
I0423 21:13:48.981470 27448 trainer.py:136] Epoch[199/200] loss: 0.15440805082519848
I0423 21:13:49.006385 27448 trainer.py:142] Test: [{'precision': 0.022573839662447238, 'recall': 0.1713909320871346, 'hit_ratio': 0.4070886075949367, 'ndcg': 0.08087608589071712}]
