I0423 09:22:24.106666 10636 trainer.py:118] Test: [{'precision': 0.016244725738396616, 'recall': 0.09942391176568391, 'hit_ratio': 0.270042194092827, 'ndcg': 0.05447776257772639}]
I0423 09:22:25.273825 10636 trainer.py:136] Epoch[0/200] loss: 0.6630067547162374
I0423 09:22:26.533440 10636 trainer.py:136] Epoch[1/200] loss: 0.6212162435054779
I0423 09:22:27.911262 10636 trainer.py:136] Epoch[2/200] loss: 0.5922191917896271
I0423 09:22:29.454504 10636 trainer.py:136] Epoch[3/200] loss: 0.5629641811052958
I0423 09:22:31.144397 10636 trainer.py:136] Epoch[4/200] loss: 0.5167364865541458
I0423 09:22:32.833773 10636 trainer.py:136] Epoch[5/200] loss: 0.48408845166365305
I0423 09:22:34.530810 10636 trainer.py:136] Epoch[6/200] loss: 0.4465942313273748
I0423 09:22:36.241941 10636 trainer.py:136] Epoch[7/200] loss: 0.43075172205766044
I0423 09:22:37.920577 10636 trainer.py:136] Epoch[8/200] loss: 0.40422835350036623
I0423 09:22:39.600356 10636 trainer.py:136] Epoch[9/200] loss: 0.39524839917818705
I0423 09:22:41.290551 10636 trainer.py:136] Epoch[10/200] loss: 0.3625085572401682
I0423 09:22:43.023862 10636 trainer.py:136] Epoch[11/200] loss: 0.3440278400977453
I0423 09:22:44.817570 10636 trainer.py:136] Epoch[12/200] loss: 0.3494634320338567
I0423 09:22:46.504480 10636 trainer.py:136] Epoch[13/200] loss: 0.33443033148845036
I0423 09:22:48.182126 10636 trainer.py:136] Epoch[14/200] loss: 0.33658142685890197
I0423 09:22:49.950346 10636 trainer.py:136] Epoch[15/200] loss: 0.32495442281166714
I0423 09:22:51.723025 10636 trainer.py:136] Epoch[16/200] loss: 0.3161781211694082
I0423 09:22:53.497289 10636 trainer.py:136] Epoch[17/200] loss: 0.3134181872010231
I0423 09:22:55.193064 10636 trainer.py:136] Epoch[18/200] loss: 0.3033116891980171
I0423 09:22:56.875574 10636 trainer.py:136] Epoch[19/200] loss: 0.2963704158862432
I0423 09:22:58.549065 10636 trainer.py:136] Epoch[20/200] loss: 0.2866235305865606
I0423 09:23:00.225579 10636 trainer.py:136] Epoch[21/200] loss: 0.30406312545140585
I0423 09:23:01.903094 10636 trainer.py:136] Epoch[22/200] loss: 0.30074508438507713
I0423 09:23:03.567097 10636 trainer.py:136] Epoch[23/200] loss: 0.27715270469586056
I0423 09:23:05.242657 10636 trainer.py:136] Epoch[24/200] loss: 0.27191439469655354
I0423 09:23:06.937310 10636 trainer.py:136] Epoch[25/200] loss: 0.2722909952203433
I0423 09:23:08.601042 10636 trainer.py:136] Epoch[26/200] loss: 0.27015479455391567
I0423 09:23:10.288650 10636 trainer.py:136] Epoch[27/200] loss: 0.26995108723640443
I0423 09:23:11.959254 10636 trainer.py:136] Epoch[28/200] loss: 0.2637582093477249
I0423 09:23:13.628257 10636 trainer.py:136] Epoch[29/200] loss: 0.2740879828731219
I0423 09:23:15.303766 10636 trainer.py:136] Epoch[30/200] loss: 0.2560538331667582
I0423 09:23:17.021230 10636 trainer.py:136] Epoch[31/200] loss: 0.2585730125506719
I0423 09:23:18.695198 10636 trainer.py:136] Epoch[32/200] loss: 0.26836407035589216
I0423 09:23:20.376798 10636 trainer.py:136] Epoch[33/200] loss: 0.23508129914601644
I0423 09:23:22.113232 10636 trainer.py:136] Epoch[34/200] loss: 0.24208422352870304
I0423 09:23:23.876134 10636 trainer.py:136] Epoch[35/200] loss: 0.23665421108404797
I0423 09:23:25.663383 10636 trainer.py:136] Epoch[36/200] loss: 0.2402502472201983
I0423 09:23:27.327086 10636 trainer.py:136] Epoch[37/200] loss: 0.23852335214614867
I0423 09:23:29.034227 10636 trainer.py:136] Epoch[38/200] loss: 0.23386133313179017
I0423 09:23:30.710284 10636 trainer.py:136] Epoch[39/200] loss: 0.24782518297433853
I0423 09:23:32.374946 10636 trainer.py:136] Epoch[40/200] loss: 0.2303799048066139
I0423 09:23:34.090419 10636 trainer.py:136] Epoch[41/200] loss: 0.23797834813594818
I0423 09:23:35.751897 10636 trainer.py:136] Epoch[42/200] loss: 0.2211589256922404
I0423 09:23:37.418359 10636 trainer.py:136] Epoch[43/200] loss: 0.24190651675065358
I0423 09:23:39.117887 10636 trainer.py:136] Epoch[44/200] loss: 0.22251763294140497
I0423 09:23:40.799962 10636 trainer.py:136] Epoch[45/200] loss: 0.231867977976799
I0423 09:23:42.499816 10636 trainer.py:136] Epoch[46/200] loss: 0.2350283627708753
I0423 09:23:44.177197 10636 trainer.py:136] Epoch[47/200] loss: 0.2176132430632909
I0423 09:23:45.841721 10636 trainer.py:136] Epoch[48/200] loss: 0.21746862381696702
I0423 09:23:47.504766 10636 trainer.py:136] Epoch[49/200] loss: 0.20992881407340366
I0423 09:23:47.534667 10636 trainer.py:142] Test: [{'precision': 0.02468354430379745, 'recall': 0.16420603540856704, 'hit_ratio': 0.3881856540084388, 'ndcg': 0.07931426309888347}]
I0423 09:23:49.249420 10636 trainer.py:136] Epoch[50/200] loss: 0.21330116589864095
I0423 09:23:50.915567 10636 trainer.py:136] Epoch[51/200] loss: 0.20558361808458964
I0423 09:23:52.599479 10636 trainer.py:136] Epoch[52/200] loss: 0.2037687008579572
I0423 09:23:54.284992 10636 trainer.py:136] Epoch[53/200] loss: 0.209907661875089
I0423 09:23:55.982503 10636 trainer.py:136] Epoch[54/200] loss: 0.2154550611972809
I0423 09:23:57.738225 10636 trainer.py:136] Epoch[55/200] loss: 0.20711749345064162
I0423 09:23:59.469579 10636 trainer.py:136] Epoch[56/200] loss: 0.20836791048447292
I0423 09:24:01.143115 10636 trainer.py:136] Epoch[57/200] loss: 0.21029731382926306
I0423 09:24:02.817824 10636 trainer.py:136] Epoch[58/200] loss: 0.19917595237493516
I0423 09:24:04.499806 10636 trainer.py:136] Epoch[59/200] loss: 0.20622636129458746
I0423 09:24:06.184427 10636 trainer.py:136] Epoch[60/200] loss: 0.19815057267745337
I0423 09:24:07.860949 10636 trainer.py:136] Epoch[61/200] loss: 0.19812700450420379
I0423 09:24:09.537798 10636 trainer.py:136] Epoch[62/200] loss: 0.209247188270092
I0423 09:24:11.195384 10636 trainer.py:136] Epoch[63/200] loss: 0.20338867058356602
I0423 09:24:12.871999 10636 trainer.py:136] Epoch[64/200] loss: 0.1925497055053711
I0423 09:24:14.565057 10636 trainer.py:136] Epoch[65/200] loss: 0.19229436442255973
I0423 09:24:16.243678 10636 trainer.py:136] Epoch[66/200] loss: 0.19194508890310924
I0423 09:24:17.929288 10636 trainer.py:136] Epoch[67/200] loss: 0.18771056135495504
I0423 09:24:19.603327 10636 trainer.py:136] Epoch[68/200] loss: 0.19789504955212275
I0423 09:24:21.276014 10636 trainer.py:136] Epoch[69/200] loss: 0.19394832799832026
I0423 09:24:22.949584 10636 trainer.py:136] Epoch[70/200] loss: 0.19034409349163373
I0423 09:24:24.611635 10636 trainer.py:136] Epoch[71/200] loss: 0.1843406639993191
I0423 09:24:26.273922 10636 trainer.py:136] Epoch[72/200] loss: 0.18089648683865864
I0423 09:24:27.937617 10636 trainer.py:136] Epoch[73/200] loss: 0.1979993482430776
I0423 09:24:29.605553 10636 trainer.py:136] Epoch[74/200] loss: 0.18278498202562332
I0423 09:24:31.334552 10636 trainer.py:136] Epoch[75/200] loss: 0.18924280206362407
I0423 09:24:32.994061 10636 trainer.py:136] Epoch[76/200] loss: 0.18827048018574716
I0423 09:24:34.649617 10636 trainer.py:136] Epoch[77/200] loss: 0.17877068122227988
I0423 09:24:36.329206 10636 trainer.py:136] Epoch[78/200] loss: 0.1829027146100998
I0423 09:24:38.015349 10636 trainer.py:136] Epoch[79/200] loss: 0.1752104530731837
I0423 09:24:39.687677 10636 trainer.py:136] Epoch[80/200] loss: 0.18163548509279887
I0423 09:24:41.363343 10636 trainer.py:136] Epoch[81/200] loss: 0.18574077238639194
I0423 09:24:43.052954 10636 trainer.py:136] Epoch[82/200] loss: 0.17452268972992896
I0423 09:24:44.804322 10636 trainer.py:136] Epoch[83/200] loss: 0.18091429099440576
I0423 09:24:46.492296 10636 trainer.py:136] Epoch[84/200] loss: 0.19014480064312617
I0423 09:24:48.164916 10636 trainer.py:136] Epoch[85/200] loss: 0.18064709529280662
I0423 09:24:49.880330 10636 trainer.py:136] Epoch[86/200] loss: 0.18358026345570883
I0423 09:24:51.632036 10636 trainer.py:136] Epoch[87/200] loss: 0.1786730686823527
I0423 09:24:53.345483 10636 trainer.py:136] Epoch[88/200] loss: 0.17894636789957682
I0423 09:24:55.167672 10636 trainer.py:136] Epoch[89/200] loss: 0.18077590266863505
I0423 09:24:56.888173 10636 trainer.py:136] Epoch[90/200] loss: 0.184598487863938
I0423 09:24:58.546204 10636 trainer.py:136] Epoch[91/200] loss: 0.1889646167556445
I0423 09:25:00.212433 10636 trainer.py:136] Epoch[92/200] loss: 0.17867562596996625
I0423 09:25:01.888915 10636 trainer.py:136] Epoch[93/200] loss: 0.1730966165661812
I0423 09:25:03.559317 10636 trainer.py:136] Epoch[94/200] loss: 0.17695469508568445
I0423 09:25:05.227886 10636 trainer.py:136] Epoch[95/200] loss: 0.18235141634941102
I0423 09:25:06.917238 10636 trainer.py:136] Epoch[96/200] loss: 0.17717593039075533
I0423 09:25:08.600349 10636 trainer.py:136] Epoch[97/200] loss: 0.1733625424404939
I0423 09:25:10.276856 10636 trainer.py:136] Epoch[98/200] loss: 0.17840563580393792
I0423 09:25:11.848408 10636 trainer.py:136] Epoch[99/200] loss: 0.17972835674881935
I0423 09:25:11.873325 10636 trainer.py:142] Test: [{'precision': 0.024894514767932467, 'recall': 0.16666426634781062, 'hit_ratio': 0.3881856540084388, 'ndcg': 0.07927542765648263}]
I0423 09:25:13.228634 10636 trainer.py:136] Epoch[100/200] loss: 0.1800171762704849
I0423 09:25:14.266055 10636 trainer.py:136] Epoch[101/200] loss: 0.1813653772075971
I0423 09:25:15.288368 10636 trainer.py:136] Epoch[102/200] loss: 0.16886523341139156
I0423 09:25:16.274286 10636 trainer.py:136] Epoch[103/200] loss: 0.1707318050165971
I0423 09:25:17.270558 10636 trainer.py:136] Epoch[104/200] loss: 0.17940644671519598
I0423 09:25:18.281750 10636 trainer.py:136] Epoch[105/200] loss: 0.1780285636583964
I0423 09:25:19.297961 10636 trainer.py:136] Epoch[106/200] loss: 0.17461922143896422
I0423 09:25:20.299022 10636 trainer.py:136] Epoch[107/200] loss: 0.16726190820336342
I0423 09:25:21.287970 10636 trainer.py:136] Epoch[108/200] loss: 0.15924964348475137
I0423 09:25:22.289742 10636 trainer.py:136] Epoch[109/200] loss: 0.1767096037666003
I0423 09:25:23.275475 10636 trainer.py:136] Epoch[110/200] loss: 0.15835724398493767
I0423 09:25:24.268107 10636 trainer.py:136] Epoch[111/200] loss: 0.18033631692330043
I0423 09:25:25.261987 10636 trainer.py:136] Epoch[112/200] loss: 0.16188024431467057
I0423 09:25:26.264691 10636 trainer.py:136] Epoch[113/200] loss: 0.17168813198804855
I0423 09:25:27.303719 10636 trainer.py:136] Epoch[114/200] loss: 0.16384416148066522
I0423 09:25:28.290222 10636 trainer.py:136] Epoch[115/200] loss: 0.16823170483112335
I0423 09:25:29.290294 10636 trainer.py:136] Epoch[116/200] loss: 0.17203760047753652
I0423 09:25:30.294533 10636 trainer.py:136] Epoch[117/200] loss: 0.16136421834429104
I0423 09:25:31.317810 10636 trainer.py:136] Epoch[118/200] loss: 0.17568889086445172
I0423 09:25:32.314476 10636 trainer.py:136] Epoch[119/200] loss: 0.16925184031327564
I0423 09:25:33.305962 10636 trainer.py:136] Epoch[120/200] loss: 0.16755693753560383
I0423 09:25:34.305917 10636 trainer.py:136] Epoch[121/200] loss: 0.16430016060670216
I0423 09:25:35.327316 10636 trainer.py:136] Epoch[122/200] loss: 0.17192107165853182
I0423 09:25:36.324311 10636 trainer.py:136] Epoch[123/200] loss: 0.15960797145962716
I0423 09:25:37.308362 10636 trainer.py:136] Epoch[124/200] loss: 0.16244886989394824
I0423 09:25:38.305703 10636 trainer.py:136] Epoch[125/200] loss: 0.17327878375848135
I0423 09:25:39.285036 10636 trainer.py:136] Epoch[126/200] loss: 0.17416874021291734
I0423 09:25:40.299022 10636 trainer.py:136] Epoch[127/200] loss: 0.16803583552440007
I0423 09:25:41.305127 10636 trainer.py:136] Epoch[128/200] loss: 0.16540395468473434
I0423 09:25:42.300729 10636 trainer.py:136] Epoch[129/200] loss: 0.1683524544040362
I0423 09:25:43.306084 10636 trainer.py:136] Epoch[130/200] loss: 0.1602243202428023
I0423 09:25:44.304819 10636 trainer.py:136] Epoch[131/200] loss: 0.17401138295729954
I0423 09:25:45.290959 10636 trainer.py:136] Epoch[132/200] loss: 0.15866532524426777
I0423 09:25:46.284886 10636 trainer.py:136] Epoch[133/200] loss: 0.16455035308996838
I0423 09:25:47.269158 10636 trainer.py:136] Epoch[134/200] loss: 0.1707705783347289
I0423 09:25:48.271408 10636 trainer.py:136] Epoch[135/200] loss: 0.16401097426811853
I0423 09:25:49.263089 10636 trainer.py:136] Epoch[136/200] loss: 0.1653687283396721
I0423 09:25:50.279392 10636 trainer.py:136] Epoch[137/200] loss: 0.1683616481721401
I0423 09:25:51.251066 10636 trainer.py:136] Epoch[138/200] loss: 0.170947119841973
I0423 09:25:52.261750 10636 trainer.py:136] Epoch[139/200] loss: 0.16679118424654008
I0423 09:25:53.275966 10636 trainer.py:136] Epoch[140/200] loss: 0.15929534311095875
I0423 09:25:54.292624 10636 trainer.py:136] Epoch[141/200] loss: 0.1530238591134548
I0423 09:25:55.281005 10636 trainer.py:136] Epoch[142/200] loss: 0.1605847306549549
I0423 09:25:56.272140 10636 trainer.py:136] Epoch[143/200] loss: 0.16187227467695872
I0423 09:25:57.281481 10636 trainer.py:136] Epoch[144/200] loss: 0.1536007285118103
I0423 09:25:58.281996 10636 trainer.py:136] Epoch[145/200] loss: 0.16385742550094923
I0423 09:25:59.284991 10636 trainer.py:136] Epoch[146/200] loss: 0.16776496122280757
I0423 09:26:00.291489 10636 trainer.py:136] Epoch[147/200] loss: 0.15829420338074365
I0423 09:26:01.285093 10636 trainer.py:136] Epoch[148/200] loss: 0.1587275482714176
I0423 09:26:02.297005 10636 trainer.py:136] Epoch[149/200] loss: 0.1638983855644862
I0423 09:26:02.316937 10636 trainer.py:142] Test: [{'precision': 0.02383966244725737, 'recall': 0.1592451383590624, 'hit_ratio': 0.3670886075949367, 'ndcg': 0.07791046517147673}]
I0423 09:26:03.314172 10636 trainer.py:136] Epoch[150/200] loss: 0.1525919459760189
I0423 09:26:04.297200 10636 trainer.py:136] Epoch[151/200] loss: 0.1696164871255557
I0423 09:26:05.314304 10636 trainer.py:136] Epoch[152/200] loss: 0.17338551680246989
I0423 09:26:06.328133 10636 trainer.py:136] Epoch[153/200] loss: 0.16102864667773248
I0423 09:26:07.321536 10636 trainer.py:136] Epoch[154/200] loss: 0.1544451154768467
I0423 09:26:08.325513 10636 trainer.py:136] Epoch[155/200] loss: 0.1583830175300439
I0423 09:26:09.303854 10636 trainer.py:136] Epoch[156/200] loss: 0.16590458005666733
I0423 09:26:10.293125 10636 trainer.py:136] Epoch[157/200] loss: 0.15918719073136647
I0423 09:26:11.293997 10636 trainer.py:136] Epoch[158/200] loss: 0.16881443907817203
I0423 09:26:12.296211 10636 trainer.py:136] Epoch[159/200] loss: 0.1527511030435562
I0423 09:26:13.283906 10636 trainer.py:136] Epoch[160/200] loss: 0.14940728694200517
I0423 09:26:14.283185 10636 trainer.py:136] Epoch[161/200] loss: 0.15964053844412168
I0423 09:26:15.303499 10636 trainer.py:136] Epoch[162/200] loss: 0.15775519733627638
I0423 09:26:16.273900 10636 trainer.py:136] Epoch[163/200] loss: 0.16706780344247818
I0423 09:26:17.261503 10636 trainer.py:136] Epoch[164/200] loss: 0.15611414934198062
I0423 09:26:18.238848 10636 trainer.py:136] Epoch[165/200] loss: 0.15841601888338724
I0423 09:26:19.231083 10636 trainer.py:136] Epoch[166/200] loss: 0.15385737071434658
I0423 09:26:20.233051 10636 trainer.py:136] Epoch[167/200] loss: 0.14331688582897187
I0423 09:26:21.226759 10636 trainer.py:136] Epoch[168/200] loss: 0.14934346104661625
I0423 09:26:22.203082 10636 trainer.py:136] Epoch[169/200] loss: 0.14730466529726982
I0423 09:26:23.174801 10636 trainer.py:136] Epoch[170/200] loss: 0.1579883838693301
I0423 09:26:24.173537 10636 trainer.py:136] Epoch[171/200] loss: 0.16357768500844638
I0423 09:26:25.186685 10636 trainer.py:136] Epoch[172/200] loss: 0.15457711319128672
I0423 09:26:26.187592 10636 trainer.py:136] Epoch[173/200] loss: 0.158099594215552
I0423 09:26:27.159902 10636 trainer.py:136] Epoch[174/200] loss: 0.15761113439997038
I0423 09:26:28.164683 10636 trainer.py:136] Epoch[175/200] loss: 0.15440086449186008
I0423 09:26:29.163921 10636 trainer.py:136] Epoch[176/200] loss: 0.14406996220350266
I0423 09:26:30.162661 10636 trainer.py:136] Epoch[177/200] loss: 0.14534500141938528
I0423 09:26:31.125010 10636 trainer.py:136] Epoch[178/200] loss: 0.1576065440972646
I0423 09:26:32.107263 10636 trainer.py:136] Epoch[179/200] loss: 0.15921838184197742
I0423 09:26:33.110462 10636 trainer.py:136] Epoch[180/200] loss: 0.15245795945326487
I0423 09:26:34.088721 10636 trainer.py:136] Epoch[181/200] loss: 0.1573457007606824
I0423 09:26:35.077970 10636 trainer.py:136] Epoch[182/200] loss: 0.1654485377172629
I0423 09:26:36.076185 10636 trainer.py:136] Epoch[183/200] loss: 0.16890144671003024
I0423 09:26:37.027575 10636 trainer.py:136] Epoch[184/200] loss: 0.15214219292004902
I0423 09:26:38.008857 10636 trainer.py:136] Epoch[185/200] loss: 0.1472116289039453
I0423 09:26:38.998163 10636 trainer.py:136] Epoch[186/200] loss: 0.15828993991017343
I0423 09:26:39.972765 10636 trainer.py:136] Epoch[187/200] loss: 0.14775662024815878
I0423 09:26:40.978951 10636 trainer.py:136] Epoch[188/200] loss: 0.15422391320268314
I0423 09:26:41.958231 10636 trainer.py:136] Epoch[189/200] loss: 0.14881518706679345
I0423 09:26:42.956481 10636 trainer.py:136] Epoch[190/200] loss: 0.1725549745062987
I0423 09:26:43.929845 10636 trainer.py:136] Epoch[191/200] loss: 0.15472010299563407
I0423 09:26:44.919113 10636 trainer.py:136] Epoch[192/200] loss: 0.16536924292643865
I0423 09:26:45.899425 10636 trainer.py:136] Epoch[193/200] loss: 0.15066470901171367
I0423 09:26:46.903632 10636 trainer.py:136] Epoch[194/200] loss: 0.1549864741663138
I0423 09:26:47.940725 10636 trainer.py:136] Epoch[195/200] loss: 0.16773386547962824
I0423 09:26:48.959867 10636 trainer.py:136] Epoch[196/200] loss: 0.1496496856212616
I0423 09:26:49.958137 10636 trainer.py:136] Epoch[197/200] loss: 0.15626607884963353
I0423 09:26:50.965417 10636 trainer.py:136] Epoch[198/200] loss: 0.15275413741668065
I0423 09:26:51.961733 10636 trainer.py:136] Epoch[199/200] loss: 0.14526652718583744
I0423 09:26:51.980669 10636 trainer.py:142] Test: [{'precision': 0.0232067510548523, 'recall': 0.15164208740158105, 'hit_ratio': 0.35864978902953587, 'ndcg': 0.0757056538359339}]
