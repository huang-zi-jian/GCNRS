I0423 09:22:25.674484 18180 trainer.py:118] Test: [{'precision': 0.01898734177215189, 'recall': 0.12088200126174811, 'hit_ratio': 0.32489451476793246, 'ndcg': 0.06382906845716652}]
I0423 09:22:27.033609 18180 trainer.py:136] Epoch[0/200] loss: 0.6674879093964895
I0423 09:22:28.457434 18180 trainer.py:136] Epoch[1/200] loss: 0.6274966796239217
I0423 09:22:30.060455 18180 trainer.py:136] Epoch[2/200] loss: 0.5842898786067963
I0423 09:22:31.743960 18180 trainer.py:136] Epoch[3/200] loss: 0.5598533630371094
I0423 09:22:33.414829 18180 trainer.py:136] Epoch[4/200] loss: 0.5247398674488067
I0423 09:22:35.130974 18180 trainer.py:136] Epoch[5/200] loss: 0.4888350427150726
I0423 09:22:36.827592 18180 trainer.py:136] Epoch[6/200] loss: 0.4535723805427551
I0423 09:22:38.517419 18180 trainer.py:136] Epoch[7/200] loss: 0.4303007870912552
I0423 09:22:40.196605 18180 trainer.py:136] Epoch[8/200] loss: 0.3931183705727259
I0423 09:22:41.894092 18180 trainer.py:136] Epoch[9/200] loss: 0.36658091843128204
I0423 09:22:43.655304 18180 trainer.py:136] Epoch[10/200] loss: 0.3868987540404002
I0423 09:22:45.392646 18180 trainer.py:136] Epoch[11/200] loss: 0.360698335369428
I0423 09:22:47.067257 18180 trainer.py:136] Epoch[12/200] loss: 0.34090954264005024
I0423 09:22:48.785680 18180 trainer.py:136] Epoch[13/200] loss: 0.32956389983495077
I0423 09:22:50.553328 18180 trainer.py:136] Epoch[14/200] loss: 0.32217395305633545
I0423 09:22:52.335551 18180 trainer.py:136] Epoch[15/200] loss: 0.31438274731238686
I0423 09:22:54.064305 18180 trainer.py:136] Epoch[16/200] loss: 0.31419928520917895
I0423 09:22:55.746215 18180 trainer.py:136] Epoch[17/200] loss: 0.3225744118293126
I0423 09:22:57.436243 18180 trainer.py:136] Epoch[18/200] loss: 0.29588254491488136
I0423 09:22:59.115718 18180 trainer.py:136] Epoch[19/200] loss: 0.3046627556284269
I0423 09:23:00.785706 18180 trainer.py:136] Epoch[20/200] loss: 0.3086489334702492
I0423 09:23:02.493120 18180 trainer.py:136] Epoch[21/200] loss: 0.2812113896012306
I0423 09:23:04.172642 18180 trainer.py:136] Epoch[22/200] loss: 0.2780458296338717
I0423 09:23:05.847301 18180 trainer.py:136] Epoch[23/200] loss: 0.2656981577475866
I0423 09:23:07.536306 18180 trainer.py:136] Epoch[24/200] loss: 0.26512374629577
I0423 09:23:09.200645 18180 trainer.py:136] Epoch[25/200] loss: 0.28178819914658865
I0423 09:23:10.893165 18180 trainer.py:136] Epoch[26/200] loss: 0.285639422138532
I0423 09:23:12.563233 18180 trainer.py:136] Epoch[27/200] loss: 0.2636894668142001
I0423 09:23:14.241751 18180 trainer.py:136] Epoch[28/200] loss: 0.26031684279441836
I0423 09:23:15.918356 18180 trainer.py:136] Epoch[29/200] loss: 0.26136815051237744
I0423 09:23:17.626206 18180 trainer.py:136] Epoch[30/200] loss: 0.26821491022904714
I0423 09:23:19.308825 18180 trainer.py:136] Epoch[31/200] loss: 0.25613733182350795
I0423 09:23:20.984359 18180 trainer.py:136] Epoch[32/200] loss: 0.2576061283548673
I0423 09:23:22.747329 18180 trainer.py:136] Epoch[33/200] loss: 0.235930398106575
I0423 09:23:24.524963 18180 trainer.py:136] Epoch[34/200] loss: 0.24287245720624923
I0423 09:23:26.281933 18180 trainer.py:136] Epoch[35/200] loss: 0.24184734473625819
I0423 09:23:27.984090 18180 trainer.py:136] Epoch[36/200] loss: 0.22564151336749394
I0423 09:23:29.698006 18180 trainer.py:136] Epoch[37/200] loss: 0.23207004219293595
I0423 09:23:31.358740 18180 trainer.py:136] Epoch[38/200] loss: 0.22849714607000352
I0423 09:23:33.037367 18180 trainer.py:136] Epoch[39/200] loss: 0.23332840700944266
I0423 09:23:34.727288 18180 trainer.py:136] Epoch[40/200] loss: 0.23424601008494694
I0423 09:23:36.404167 18180 trainer.py:136] Epoch[41/200] loss: 0.23030363967021306
I0423 09:23:38.107633 18180 trainer.py:136] Epoch[42/200] loss: 0.2512846057613691
I0423 09:23:39.766717 18180 trainer.py:136] Epoch[43/200] loss: 0.24162208487590153
I0423 09:23:41.462745 18180 trainer.py:136] Epoch[44/200] loss: 0.2162451947728793
I0423 09:23:43.136238 18180 trainer.py:136] Epoch[45/200] loss: 0.2260630135734876
I0423 09:23:44.811605 18180 trainer.py:136] Epoch[46/200] loss: 0.23016789356867473
I0423 09:23:46.472610 18180 trainer.py:136] Epoch[47/200] loss: 0.22990218649307886
I0423 09:23:48.134605 18180 trainer.py:136] Epoch[48/200] loss: 0.21774041603008906
I0423 09:23:49.821619 18180 trainer.py:136] Epoch[49/200] loss: 0.21738718797763187
I0423 09:23:49.851519 18180 trainer.py:142] Test: [{'precision': 0.02257383966244724, 'recall': 0.15212430560531826, 'hit_ratio': 0.35864978902953587, 'ndcg': 0.07913377883184572}]
I0423 09:23:51.547453 18180 trainer.py:136] Epoch[50/200] loss: 0.20560921281576156
I0423 09:23:53.216967 18180 trainer.py:136] Epoch[51/200] loss: 0.20579892098903657
I0423 09:23:54.905491 18180 trainer.py:136] Epoch[52/200] loss: 0.21699527104695637
I0423 09:23:56.632329 18180 trainer.py:136] Epoch[53/200] loss: 0.21310989161332447
I0423 09:23:58.359741 18180 trainer.py:136] Epoch[54/200] loss: 0.19862241049607596
I0423 09:24:00.070130 18180 trainer.py:136] Epoch[55/200] loss: 0.2074276422460874
I0423 09:24:01.749089 18180 trainer.py:136] Epoch[56/200] loss: 0.20541684329509735
I0423 09:24:03.443730 18180 trainer.py:136] Epoch[57/200] loss: 0.21004317104816436
I0423 09:24:05.115357 18180 trainer.py:136] Epoch[58/200] loss: 0.21746248106161753
I0423 09:24:06.795913 18180 trainer.py:136] Epoch[59/200] loss: 0.20653704355160396
I0423 09:24:08.464905 18180 trainer.py:136] Epoch[60/200] loss: 0.20422261208295822
I0423 09:24:10.126409 18180 trainer.py:136] Epoch[61/200] loss: 0.2016400933265686
I0423 09:24:11.798979 18180 trainer.py:136] Epoch[62/200] loss: 0.1871909146507581
I0423 09:24:13.488094 18180 trainer.py:136] Epoch[63/200] loss: 0.20288762946923575
I0423 09:24:15.164656 18180 trainer.py:136] Epoch[64/200] loss: 0.1961294191579024
I0423 09:24:16.857237 18180 trainer.py:136] Epoch[65/200] loss: 0.1955850770076116
I0423 09:24:18.541241 18180 trainer.py:136] Epoch[66/200] loss: 0.18742904737591742
I0423 09:24:20.239880 18180 trainer.py:136] Epoch[67/200] loss: 0.18228970915079118
I0423 09:24:21.909486 18180 trainer.py:136] Epoch[68/200] loss: 0.19308253328005473
I0423 09:24:23.584460 18180 trainer.py:136] Epoch[69/200] loss: 0.18517406582832335
I0423 09:24:25.257782 18180 trainer.py:136] Epoch[70/200] loss: 0.18385068873564403
I0423 09:24:26.926337 18180 trainer.py:136] Epoch[71/200] loss: 0.18580502619345982
I0423 09:24:28.577477 18180 trainer.py:136] Epoch[72/200] loss: 0.19366419464349746
I0423 09:24:30.238982 18180 trainer.py:136] Epoch[73/200] loss: 0.1938996930917104
I0423 09:24:31.958085 18180 trainer.py:136] Epoch[74/200] loss: 0.1783689171075821
I0423 09:24:33.628937 18180 trainer.py:136] Epoch[75/200] loss: 0.18790017887949945
I0423 09:24:35.317031 18180 trainer.py:136] Epoch[76/200] loss: 0.1937695066134135
I0423 09:24:36.980580 18180 trainer.py:136] Epoch[77/200] loss: 0.18727800597747166
I0423 09:24:38.653515 18180 trainer.py:136] Epoch[78/200] loss: 0.17939416617155074
I0423 09:24:40.323147 18180 trainer.py:136] Epoch[79/200] loss: 0.18702640732129414
I0423 09:24:42.000848 18180 trainer.py:136] Epoch[80/200] loss: 0.17636627008517583
I0423 09:24:43.714740 18180 trainer.py:136] Epoch[81/200] loss: 0.1767557536562284
I0423 09:24:45.424248 18180 trainer.py:136] Epoch[82/200] loss: 0.1765980079770088
I0423 09:24:47.090884 18180 trainer.py:136] Epoch[83/200] loss: 0.1943990339835485
I0423 09:24:48.760923 18180 trainer.py:136] Epoch[84/200] loss: 0.17788683027029037
I0423 09:24:50.511220 18180 trainer.py:136] Epoch[85/200] loss: 0.1833435853322347
I0423 09:24:52.264515 18180 trainer.py:136] Epoch[86/200] loss: 0.1854561428229014
I0423 09:24:53.997897 18180 trainer.py:136] Epoch[87/200] loss: 0.17197514648238818
I0423 09:24:55.752715 18180 trainer.py:136] Epoch[88/200] loss: 0.1869600442548593
I0423 09:24:57.461255 18180 trainer.py:136] Epoch[89/200] loss: 0.18849310626586277
I0423 09:24:59.142765 18180 trainer.py:136] Epoch[90/200] loss: 0.18812567815184594
I0423 09:25:00.817944 18180 trainer.py:136] Epoch[91/200] loss: 0.18503968119621278
I0423 09:25:02.497879 18180 trainer.py:136] Epoch[92/200] loss: 0.18380966434876125
I0423 09:25:04.167861 18180 trainer.py:136] Epoch[93/200] loss: 0.1790758023659388
I0423 09:25:05.842452 18180 trainer.py:136] Epoch[94/200] loss: 0.18358997156222662
I0423 09:25:07.553921 18180 trainer.py:136] Epoch[95/200] loss: 0.17727413872877756
I0423 09:25:09.225816 18180 trainer.py:136] Epoch[96/200] loss: 0.1688777508834998
I0423 09:25:10.897343 18180 trainer.py:136] Epoch[97/200] loss: 0.17913095628221828
I0423 09:25:12.349372 18180 trainer.py:136] Epoch[98/200] loss: 0.17617561668157578
I0423 09:25:13.591410 18180 trainer.py:136] Epoch[99/200] loss: 0.17628335033853848
I0423 09:25:13.606245 18180 trainer.py:142] Test: [{'precision': 0.023628691983122337, 'recall': 0.16323541671642935, 'hit_ratio': 0.379746835443038, 'ndcg': 0.07902336103397822}]
I0423 09:25:14.617023 18180 trainer.py:136] Epoch[100/200] loss: 0.175010135024786
I0423 09:25:15.631644 18180 trainer.py:136] Epoch[101/200] loss: 0.17868489970763524
I0423 09:25:16.657256 18180 trainer.py:136] Epoch[102/200] loss: 0.1796855203807354
I0423 09:25:17.673508 18180 trainer.py:136] Epoch[103/200] loss: 0.17669751768310865
I0423 09:25:18.657493 18180 trainer.py:136] Epoch[104/200] loss: 0.18566827848553658
I0423 09:25:19.625263 18180 trainer.py:136] Epoch[105/200] loss: 0.17565150906642277
I0423 09:25:20.636113 18180 trainer.py:136] Epoch[106/200] loss: 0.17619735822081567
I0423 09:25:21.634991 18180 trainer.py:136] Epoch[107/200] loss: 0.1701249378422896
I0423 09:25:22.651531 18180 trainer.py:136] Epoch[108/200] loss: 0.1735790640115738
I0423 09:25:23.656694 18180 trainer.py:136] Epoch[109/200] loss: 0.17022804245352746
I0423 09:25:24.657830 18180 trainer.py:136] Epoch[110/200] loss: 0.1699209287762642
I0423 09:25:25.651240 18180 trainer.py:136] Epoch[111/200] loss: 0.17340342352787655
I0423 09:25:26.658376 18180 trainer.py:136] Epoch[112/200] loss: 0.18067248190442722
I0423 09:25:27.691422 18180 trainer.py:136] Epoch[113/200] loss: 0.17021647095680237
I0423 09:25:28.686613 18180 trainer.py:136] Epoch[114/200] loss: 0.17575138434767723
I0423 09:25:29.673013 18180 trainer.py:136] Epoch[115/200] loss: 0.17647025833527247
I0423 09:25:30.648349 18180 trainer.py:136] Epoch[116/200] loss: 0.168118300785621
I0423 09:25:31.658669 18180 trainer.py:136] Epoch[117/200] loss: 0.16862909570336343
I0423 09:25:32.643375 18180 trainer.py:136] Epoch[118/200] loss: 0.16194590826829275
I0423 09:25:33.622963 18180 trainer.py:136] Epoch[119/200] loss: 0.16595617607235907
I0423 09:25:34.614494 18180 trainer.py:136] Epoch[120/200] loss: 0.1586048496266206
I0423 09:25:35.620335 18180 trainer.py:136] Epoch[121/200] loss: 0.16373826613028844
I0423 09:25:36.603198 18180 trainer.py:136] Epoch[122/200] loss: 0.15837786570191384
I0423 09:25:37.597051 18180 trainer.py:136] Epoch[123/200] loss: 0.16474865972995759
I0423 09:25:38.580792 18180 trainer.py:136] Epoch[124/200] loss: 0.16318375393748283
I0423 09:25:39.617571 18180 trainer.py:136] Epoch[125/200] loss: 0.17014703080058097
I0423 09:25:40.639882 18180 trainer.py:136] Epoch[126/200] loss: 0.1715073674917221
I0423 09:25:41.649633 18180 trainer.py:136] Epoch[127/200] loss: 0.15709438025951386
I0423 09:25:42.663043 18180 trainer.py:136] Epoch[128/200] loss: 0.17260316014289856
I0423 09:25:43.683929 18180 trainer.py:136] Epoch[129/200] loss: 0.1613861846427123
I0423 09:25:44.676857 18180 trainer.py:136] Epoch[130/200] loss: 0.16423795595765114
I0423 09:25:45.668359 18180 trainer.py:136] Epoch[131/200] loss: 0.17386180609464646
I0423 09:25:46.664096 18180 trainer.py:136] Epoch[132/200] loss: 0.16388828406731287
I0423 09:25:47.659732 18180 trainer.py:136] Epoch[133/200] loss: 0.15956957737604777
I0423 09:25:48.646499 18180 trainer.py:136] Epoch[134/200] loss: 0.16216175978382427
I0423 09:25:49.640339 18180 trainer.py:136] Epoch[135/200] loss: 0.16902501732110978
I0423 09:25:50.648825 18180 trainer.py:136] Epoch[136/200] loss: 0.16130370249350864
I0423 09:25:51.651939 18180 trainer.py:136] Epoch[137/200] loss: 0.16906216914455097
I0423 09:25:52.671380 18180 trainer.py:136] Epoch[138/200] loss: 0.16934044534961382
I0423 09:25:53.678293 18180 trainer.py:136] Epoch[139/200] loss: 0.1612388886511326
I0423 09:25:54.679652 18180 trainer.py:136] Epoch[140/200] loss: 0.1653831906616688
I0423 09:25:55.691079 18180 trainer.py:136] Epoch[141/200] loss: 0.167410026739041
I0423 09:25:56.696499 18180 trainer.py:136] Epoch[142/200] loss: 0.16528510649998981
I0423 09:25:57.695643 18180 trainer.py:136] Epoch[143/200] loss: 0.16002143224080403
I0423 09:25:58.700819 18180 trainer.py:136] Epoch[144/200] loss: 0.16954333409667016
I0423 09:25:59.707956 18180 trainer.py:136] Epoch[145/200] loss: 0.16438261047005653
I0423 09:26:00.699446 18180 trainer.py:136] Epoch[146/200] loss: 0.15880486294627189
I0423 09:26:01.700399 18180 trainer.py:136] Epoch[147/200] loss: 0.15718333075443905
I0423 09:26:02.700654 18180 trainer.py:136] Epoch[148/200] loss: 0.14936900635560355
I0423 09:26:03.693902 18180 trainer.py:136] Epoch[149/200] loss: 0.1519537332157294
I0423 09:26:03.713835 18180 trainer.py:142] Test: [{'precision': 0.024050632911392388, 'recall': 0.16154765300334917, 'hit_ratio': 0.38396624472573837, 'ndcg': 0.0784880607108949}]
I0423 09:26:04.707709 18180 trainer.py:136] Epoch[150/200] loss: 0.17009359672665597
I0423 09:26:05.719946 18180 trainer.py:136] Epoch[151/200] loss: 0.16824330935875575
I0423 09:26:06.720525 18180 trainer.py:136] Epoch[152/200] loss: 0.1585126447180907
I0423 09:26:07.730936 18180 trainer.py:136] Epoch[153/200] loss: 0.16508128196001054
I0423 09:26:08.731156 18180 trainer.py:136] Epoch[154/200] loss: 0.16081496824820837
I0423 09:26:09.716474 18180 trainer.py:136] Epoch[155/200] loss: 0.15979385177294414
I0423 09:26:10.729665 18180 trainer.py:136] Epoch[156/200] loss: 0.1719721699754397
I0423 09:26:11.707613 18180 trainer.py:136] Epoch[157/200] loss: 0.15863551199436188
I0423 09:26:12.708831 18180 trainer.py:136] Epoch[158/200] loss: 0.15680941740671794
I0423 09:26:13.687556 18180 trainer.py:136] Epoch[159/200] loss: 0.15996382310986518
I0423 09:26:14.660921 18180 trainer.py:136] Epoch[160/200] loss: 0.1569318284591039
I0423 09:26:15.624425 18180 trainer.py:136] Epoch[161/200] loss: 0.15267879143357277
I0423 09:26:16.618746 18180 trainer.py:136] Epoch[162/200] loss: 0.15808078398307165
I0423 09:26:17.608343 18180 trainer.py:136] Epoch[163/200] loss: 0.1576268307864666
I0423 09:26:18.593581 18180 trainer.py:136] Epoch[164/200] loss: 0.1608560229341189
I0423 09:26:19.574674 18180 trainer.py:136] Epoch[165/200] loss: 0.15325963497161865
I0423 09:26:20.559957 18180 trainer.py:136] Epoch[166/200] loss: 0.1615261733531952
I0423 09:26:21.564629 18180 trainer.py:136] Epoch[167/200] loss: 0.15694206381837528
I0423 09:26:22.557895 18180 trainer.py:136] Epoch[168/200] loss: 0.15040169929464658
I0423 09:26:23.550544 18180 trainer.py:136] Epoch[169/200] loss: 0.14672723934054374
I0423 09:26:24.539314 18180 trainer.py:136] Epoch[170/200] loss: 0.14817030231157938
I0423 09:26:25.515069 18180 trainer.py:136] Epoch[171/200] loss: 0.1595465083916982
I0423 09:26:26.524465 18180 trainer.py:136] Epoch[172/200] loss: 0.16026588703195255
I0423 09:26:27.530661 18180 trainer.py:136] Epoch[173/200] loss: 0.1558483106394609
I0423 09:26:28.510526 18180 trainer.py:136] Epoch[174/200] loss: 0.15463399787743887
I0423 09:26:29.494814 18180 trainer.py:136] Epoch[175/200] loss: 0.15885576009750366
I0423 09:26:30.488570 18180 trainer.py:136] Epoch[176/200] loss: 0.16505519996086757
I0423 09:26:31.467862 18180 trainer.py:136] Epoch[177/200] loss: 0.15407836313048998
I0423 09:26:32.450116 18180 trainer.py:136] Epoch[178/200] loss: 0.1435550426443418
I0423 09:26:33.451322 18180 trainer.py:136] Epoch[179/200] loss: 0.15351762448747952
I0423 09:26:34.438550 18180 trainer.py:136] Epoch[180/200] loss: 0.1620365045964718
I0423 09:26:35.413846 18180 trainer.py:136] Epoch[181/200] loss: 0.1558380628625552
I0423 09:26:36.399105 18180 trainer.py:136] Epoch[182/200] loss: 0.15618888586759566
I0423 09:26:37.368435 18180 trainer.py:136] Epoch[183/200] loss: 0.15490945180257162
I0423 09:26:38.361677 18180 trainer.py:136] Epoch[184/200] loss: 0.1602730060617129
I0423 09:26:39.343010 18180 trainer.py:136] Epoch[185/200] loss: 0.14681829338272412
I0423 09:26:40.333559 18180 trainer.py:136] Epoch[186/200] loss: 0.159958104044199
I0423 09:26:41.319811 18180 trainer.py:136] Epoch[187/200] loss: 0.15309222042560577
I0423 09:26:42.306067 18180 trainer.py:136] Epoch[188/200] loss: 0.16204818362991016
I0423 09:26:43.291361 18180 trainer.py:136] Epoch[189/200] loss: 0.15933358271916706
I0423 09:26:44.282664 18180 trainer.py:136] Epoch[190/200] loss: 0.1541508585214615
I0423 09:26:45.258976 18180 trainer.py:136] Epoch[191/200] loss: 0.14236893405516943
I0423 09:26:46.241282 18180 trainer.py:136] Epoch[192/200] loss: 0.16081523249546686
I0423 09:26:47.210606 18180 trainer.py:136] Epoch[193/200] loss: 0.15656081090370813
I0423 09:26:48.172948 18180 trainer.py:136] Epoch[194/200] loss: 0.1599159926176071
I0423 09:26:49.152224 18180 trainer.py:136] Epoch[195/200] loss: 0.15389998704195024
I0423 09:26:50.157471 18180 trainer.py:136] Epoch[196/200] loss: 0.16097649037837983
I0423 09:26:51.161760 18180 trainer.py:136] Epoch[197/200] loss: 0.16214337075750032
I0423 09:26:52.088309 18180 trainer.py:136] Epoch[198/200] loss: 0.15845599298675855
I0423 09:26:52.760062 18180 trainer.py:136] Epoch[199/200] loss: 0.1608017601072788
I0423 09:26:52.777006 18180 trainer.py:142] Test: [{'precision': 0.024050632911392384, 'recall': 0.1629541227642493, 'hit_ratio': 0.379746835443038, 'ndcg': 0.0780843078407188}]
