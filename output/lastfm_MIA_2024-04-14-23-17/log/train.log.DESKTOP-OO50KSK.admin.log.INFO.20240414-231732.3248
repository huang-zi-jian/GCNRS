I0414 23:17:35.141458 31272 trainer.py:121] Test: {'precision': 0.047747989276139415, 'recall': 0.10513254036436497, 'hit_ratio': 0.3442359249329759, 'ndcg': 0.1075684534838417}
I0414 23:17:40.068975 31272 trainer.py:139] Epoch[0/1500] loss: 0.5675640048519257
I0414 23:17:46.362917 31272 trainer.py:139] Epoch[1/1500] loss: 0.4881327844435169
I0414 23:17:51.020336 31272 trainer.py:139] Epoch[2/1500] loss: 0.45442558680811235
I0414 23:17:56.071438 31272 trainer.py:139] Epoch[3/1500] loss: 0.4294790615958552
I0414 23:18:01.885986 31272 trainer.py:139] Epoch[4/1500] loss: 0.41848826023840136
I0414 23:18:07.189244 31272 trainer.py:139] Epoch[5/1500] loss: 0.3975025155851918
I0414 23:18:11.925400 31272 trainer.py:139] Epoch[6/1500] loss: 0.3817809589447514
I0414 23:18:16.617702 31272 trainer.py:139] Epoch[7/1500] loss: 0.36631057435466396
I0414 23:18:22.200028 31272 trainer.py:139] Epoch[8/1500] loss: 0.3450777597965733
I0414 23:18:28.102282 31272 trainer.py:139] Epoch[9/1500] loss: 0.32855251623738196
I0414 23:18:32.714850 31272 trainer.py:139] Epoch[10/1500] loss: 0.31715095812274563
I0414 23:18:37.498846 31272 trainer.py:139] Epoch[11/1500] loss: 0.3013686066673648
I0414 23:18:41.999789 31272 trainer.py:139] Epoch[12/1500] loss: 0.2869225855796568
I0414 23:18:48.433266 31272 trainer.py:139] Epoch[13/1500] loss: 0.28004705329095164
I0414 23:18:53.285035 31272 trainer.py:139] Epoch[14/1500] loss: 0.2746055092542402
I0414 23:18:58.143780 31272 trainer.py:139] Epoch[15/1500] loss: 0.265896427054559
I0414 23:19:02.650703 31272 trainer.py:139] Epoch[16/1500] loss: 0.2545863245764086
I0414 23:19:08.493595 31272 trainer.py:139] Epoch[17/1500] loss: 0.24565777807466446
I0414 23:19:13.839804 31272 trainer.py:139] Epoch[18/1500] loss: 0.2424459236283456
I0414 23:19:18.568982 31272 trainer.py:139] Epoch[19/1500] loss: 0.23669558234753146
I0414 23:19:23.453640 31272 trainer.py:139] Epoch[20/1500] loss: 0.22824230838206508
I0414 23:19:28.567533 31272 trainer.py:139] Epoch[21/1500] loss: 0.2249794174586573
I0414 23:19:34.664136 31272 trainer.py:139] Epoch[22/1500] loss: 0.21792524572341673
I0414 23:19:39.380369 31272 trainer.py:139] Epoch[23/1500] loss: 0.217442833127514
I0414 23:19:44.102561 31272 trainer.py:139] Epoch[24/1500] loss: 0.206267517901236
I0414 23:19:49.165626 31272 trainer.py:139] Epoch[25/1500] loss: 0.2070660788205362
I0414 23:19:55.496446 31272 trainer.py:139] Epoch[26/1500] loss: 0.20525553582176084
I0414 23:20:00.381103 31272 trainer.py:139] Epoch[27/1500] loss: 0.20189838303673652
I0414 23:20:04.931879 31272 trainer.py:139] Epoch[28/1500] loss: 0.19450897170651343
I0414 23:20:09.609232 31272 trainer.py:139] Epoch[29/1500] loss: 0.19268659382097184
I0414 23:20:16.075598 31272 trainer.py:139] Epoch[30/1500] loss: 0.19034606843225418
I0414 23:20:20.960258 31272 trainer.py:139] Epoch[31/1500] loss: 0.1857165655782146
I0414 23:20:25.550899 31272 trainer.py:139] Epoch[32/1500] loss: 0.18020214669166074
I0414 23:20:30.170445 31272 trainer.py:139] Epoch[33/1500] loss: 0.18152721466556673
I0414 23:20:35.800612 31272 trainer.py:139] Epoch[34/1500] loss: 0.1782535204002934
I0414 23:20:41.532968 31272 trainer.py:139] Epoch[35/1500] loss: 0.17614641497212072
I0414 23:20:46.132580 31272 trainer.py:139] Epoch[36/1500] loss: 0.17518951239124422
I0414 23:20:51.022222 31272 trainer.py:139] Epoch[37/1500] loss: 0.1681966560502206
I0414 23:20:55.644758 31272 trainer.py:139] Epoch[38/1500] loss: 0.16917918430220696
I0414 23:21:00.957439 31272 trainer.py:139] Epoch[39/1500] loss: 0.16602645045326603
I0414 23:21:06.437105 31272 trainer.py:139] Epoch[40/1500] loss: 0.167923292325389
I0414 23:21:11.219108 31272 trainer.py:139] Epoch[41/1500] loss: 0.16304703825904476
I0414 23:21:15.859584 31272 trainer.py:139] Epoch[42/1500] loss: 0.16344796409530024
I0414 23:21:20.544909 31272 trainer.py:139] Epoch[43/1500] loss: 0.15910405016714527
I0414 23:21:26.553806 31272 trainer.py:139] Epoch[44/1500] loss: 0.15867439296937758
I0414 23:21:31.543039 31272 trainer.py:139] Epoch[45/1500] loss: 0.15531833421799443
I0414 23:21:36.202955 31272 trainer.py:139] Epoch[46/1500] loss: 0.1534835446265436
I0414 23:21:40.755724 31272 trainer.py:139] Epoch[47/1500] loss: 0.15467832501857512
I0414 23:21:45.286566 31272 trainer.py:139] Epoch[48/1500] loss: 0.15418022534539622
I0414 23:21:51.300448 31272 trainer.py:139] Epoch[49/1500] loss: 0.14868262265959092
I0414 23:21:51.649281 31272 trainer.py:145] Test: {'precision': 0.11836461126005371, 'recall': 0.27843798726112257, 'hit_ratio': 0.8487935656836462, 'ndcg': 0.2602044259303129}
I0414 23:21:56.539832 31272 trainer.py:139] Epoch[50/1500] loss: 0.1481723141285681
I0414 23:22:01.274500 31272 trainer.py:139] Epoch[51/1500] loss: 0.1493635211260088
I0414 23:22:06.089394 31272 trainer.py:139] Epoch[52/1500] loss: 0.14564857752092422
I0414 23:22:10.773722 31272 trainer.py:139] Epoch[53/1500] loss: 0.14600478016561078
I0414 23:22:16.590213 31272 trainer.py:139] Epoch[54/1500] loss: 0.14493861698335217
I0414 23:22:21.874598 31272 trainer.py:139] Epoch[55/1500] loss: 0.14358852034614933
I0414 23:22:26.510997 31272 trainer.py:139] Epoch[56/1500] loss: 0.14233189244424144
I0414 23:22:31.442008 31272 trainer.py:139] Epoch[57/1500] loss: 0.1421668572771934
I0414 23:22:36.142205 31272 trainer.py:139] Epoch[58/1500] loss: 0.13915770140386396
I0414 23:22:42.340975 31272 trainer.py:139] Epoch[59/1500] loss: 0.13853403541349596
I0414 23:22:47.215667 31272 trainer.py:139] Epoch[60/1500] loss: 0.13917675349981554
I0414 23:22:51.784382 31272 trainer.py:139] Epoch[61/1500] loss: 0.13638780722695013
I0414 23:22:56.351518 31272 trainer.py:139] Epoch[62/1500] loss: 0.13574379009585227
I0414 23:23:01.064751 31272 trainer.py:139] Epoch[63/1500] loss: 0.13507405356053384
I0414 23:23:07.607862 31272 trainer.py:139] Epoch[64/1500] loss: 0.13375424737891844
I0414 23:23:12.228380 31272 trainer.py:139] Epoch[65/1500] loss: 0.13425001598173572
I0414 23:23:16.830983 31272 trainer.py:139] Epoch[66/1500] loss: 0.130991846082672
I0414 23:23:21.419632 31272 trainer.py:139] Epoch[67/1500] loss: 0.1296843758994533
I0414 23:23:27.698626 31272 trainer.py:139] Epoch[68/1500] loss: 0.1274842168054273
I0414 23:23:32.875728 31272 trainer.py:139] Epoch[69/1500] loss: 0.12620012293900212
I0414 23:23:37.472350 31272 trainer.py:139] Epoch[70/1500] loss: 0.1278699196634754
I0414 23:23:42.140731 31272 trainer.py:139] Epoch[71/1500] loss: 0.1273888099578119
I0414 23:23:46.870907 31272 trainer.py:139] Epoch[72/1500] loss: 0.12743912156551115
I0414 23:23:53.369168 31272 trainer.py:139] Epoch[73/1500] loss: 0.12327386222539409
I0414 23:23:58.035556 31272 trainer.py:139] Epoch[74/1500] loss: 0.12349734359210537
I0414 23:24:02.596299 31272 trainer.py:139] Epoch[75/1500] loss: 0.12465249747037888
I0414 23:24:07.185945 31272 trainer.py:139] Epoch[76/1500] loss: 0.12427508037897848
I0414 23:24:12.299837 31272 trainer.py:139] Epoch[77/1500] loss: 0.1233589964047555
I0414 23:24:18.046612 31272 trainer.py:139] Epoch[78/1500] loss: 0.12553673357732834
I0414 23:24:22.809678 31272 trainer.py:139] Epoch[79/1500] loss: 0.12056439057473213
I0414 23:24:27.194010 31272 trainer.py:139] Epoch[80/1500] loss: 0.12156077378219174
I0414 23:24:32.135478 31272 trainer.py:139] Epoch[81/1500] loss: 0.1196871510436458
I0414 23:24:37.550364 31272 trainer.py:139] Epoch[82/1500] loss: 0.11825899948035518
I0414 23:24:43.413748 31272 trainer.py:139] Epoch[83/1500] loss: 0.11742439505554014
I0414 23:24:48.046250 31272 trainer.py:139] Epoch[84/1500] loss: 0.11925827279206246
I0414 23:24:52.541213 31272 trainer.py:139] Epoch[85/1500] loss: 0.11900573632409496
I0414 23:24:57.270391 31272 trainer.py:139] Epoch[86/1500] loss: 0.114915780002071
I0414 23:25:02.864678 31272 trainer.py:139] Epoch[87/1500] loss: 0.11257044850818572
I0414 23:25:08.414111 31272 trainer.py:139] Epoch[88/1500] loss: 0.11515799957898355
I0414 23:25:13.037644 31272 trainer.py:139] Epoch[89/1500] loss: 0.11515659141925073
I0414 23:25:17.460846 31272 trainer.py:139] Epoch[90/1500] loss: 0.11486143017968824
I0414 23:25:22.346502 31272 trainer.py:139] Epoch[91/1500] loss: 0.11333344131708145
I0414 23:25:28.023511 31272 trainer.py:139] Epoch[92/1500] loss: 0.1113575783468062
I0414 23:25:33.216139 31272 trainer.py:139] Epoch[93/1500] loss: 0.11055399020833354
I0414 23:25:37.931364 31272 trainer.py:139] Epoch[94/1500] loss: 0.11044953234734074
I0414 23:25:42.734300 31272 trainer.py:139] Epoch[95/1500] loss: 0.1092721356018897
I0414 23:25:47.363809 31272 trainer.py:139] Epoch[96/1500] loss: 0.11178254095777389
I0414 23:25:53.654207 31272 trainer.py:139] Epoch[97/1500] loss: 0.11010921434048683
I0414 23:25:58.447172 31272 trainer.py:139] Epoch[98/1500] loss: 0.1076453717485551
I0414 23:26:03.145455 31272 trainer.py:139] Epoch[99/1500] loss: 0.10916067034967485
I0414 23:26:03.393625 31272 trainer.py:145] Test: {'precision': 0.1266219839142092, 'recall': 0.29988679432852294, 'hit_ratio': 0.8718498659517426, 'ndcg': 0.280142390505318}
I0414 23:26:08.068983 31272 trainer.py:139] Epoch[100/1500] loss: 0.10808192457883589
I0414 23:26:12.774243 31272 trainer.py:139] Epoch[101/1500] loss: 0.10606494618038978
I0414 23:26:19.056227 31272 trainer.py:139] Epoch[102/1500] loss: 0.10768944385551638
I0414 23:26:23.956261 31272 trainer.py:139] Epoch[103/1500] loss: 0.10581760132505048
I0414 23:26:28.671486 31272 trainer.py:139] Epoch[104/1500] loss: 0.10612781033400566
I0414 23:26:33.297251 31272 trainer.py:139] Epoch[105/1500] loss: 0.1060710417166833
I0414 23:26:37.905833 31272 trainer.py:139] Epoch[106/1500] loss: 0.10588685879784246
I0414 23:26:44.257098 31272 trainer.py:139] Epoch[107/1500] loss: 0.10400607412861239
I0414 23:26:48.977306 31272 trainer.py:139] Epoch[108/1500] loss: 0.10324947848435372
I0414 23:26:53.676006 31272 trainer.py:139] Epoch[109/1500] loss: 0.10490314157739762
I0414 23:26:58.312959 31272 trainer.py:139] Epoch[110/1500] loss: 0.10256435313532429
I0414 23:27:03.460740 31272 trainer.py:139] Epoch[111/1500] loss: 0.10313216404568765
I0414 23:27:09.604184 31272 trainer.py:139] Epoch[112/1500] loss: 0.10241312389412234
I0414 23:27:14.168913 31272 trainer.py:139] Epoch[113/1500] loss: 0.10315770752006961
I0414 23:27:18.769522 31272 trainer.py:139] Epoch[114/1500] loss: 0.10121864753384743
I0414 23:27:23.438902 31272 trainer.py:139] Epoch[115/1500] loss: 0.10178026028217808
I0414 23:27:28.405733 31272 trainer.py:139] Epoch[116/1500] loss: 0.10098398236497756
I0414 23:27:34.520276 31272 trainer.py:139] Epoch[117/1500] loss: 0.10150071978569031
I0414 23:27:39.365153 31272 trainer.py:139] Epoch[118/1500] loss: 0.09934690234161192
I0414 23:27:44.312604 31272 trainer.py:139] Epoch[119/1500] loss: 0.0978371272644689
I0414 23:27:48.966035 31272 trainer.py:139] Epoch[120/1500] loss: 0.09845843935205091
I0414 23:27:54.339060 31272 trainer.py:139] Epoch[121/1500] loss: 0.0992463457007562
I0414 23:28:00.066897 31272 trainer.py:139] Epoch[122/1500] loss: 0.09974873065948486
I0414 23:28:04.902721 31272 trainer.py:139] Epoch[123/1500] loss: 0.09947102108309346
I0414 23:28:09.405657 31272 trainer.py:139] Epoch[124/1500] loss: 0.09708384760925846
I0414 23:28:14.206595 31272 trainer.py:139] Epoch[125/1500] loss: 0.09557357670799378
I0414 23:28:19.535767 31272 trainer.py:139] Epoch[126/1500] loss: 0.09807545162977711
I0414 23:28:25.391178 31272 trainer.py:139] Epoch[127/1500] loss: 0.09473768501512465
I0414 23:28:29.987800 31272 trainer.py:139] Epoch[128/1500] loss: 0.0951321237990933
I0414 23:28:34.595385 31272 trainer.py:139] Epoch[129/1500] loss: 0.0956738043215967
I0414 23:28:39.202299 31272 trainer.py:139] Epoch[130/1500] loss: 0.09361694176350871
I0414 23:28:45.025820 31272 trainer.py:139] Epoch[131/1500] loss: 0.09338335043961002
I0414 23:28:50.192533 31272 trainer.py:139] Epoch[132/1500] loss: 0.09484642647927807
I0414 23:28:55.023371 31272 trainer.py:139] Epoch[133/1500] loss: 0.09335414680742449
I0414 23:28:59.507372 31272 trainer.py:139] Epoch[134/1500] loss: 0.09238588882069435
I0414 23:29:04.154823 31272 trainer.py:139] Epoch[135/1500] loss: 0.09391513971551772
I0414 23:29:10.534481 31272 trainer.py:139] Epoch[136/1500] loss: 0.09480668676476325
I0414 23:29:15.163060 31272 trainer.py:139] Epoch[137/1500] loss: 0.09256238442274832
I0414 23:29:19.818487 31272 trainer.py:139] Epoch[138/1500] loss: 0.09218894834479978
I0414 23:29:24.595505 31272 trainer.py:139] Epoch[139/1500] loss: 0.09176174623350944
I0414 23:29:29.290798 31272 trainer.py:139] Epoch[140/1500] loss: 0.09022117189822658
I0414 23:29:35.645989 31272 trainer.py:139] Epoch[141/1500] loss: 0.09104608912621776
I0414 23:29:40.450915 31272 trainer.py:139] Epoch[142/1500] loss: 0.0905123487595589
I0414 23:29:45.126274 31272 trainer.py:139] Epoch[143/1500] loss: 0.08947630635192318
I0414 23:29:49.625223 31272 trainer.py:139] Epoch[144/1500] loss: 0.09352677892292699
I0414 23:29:54.558720 31272 trainer.py:139] Epoch[145/1500] loss: 0.09033894586947656
I0414 23:30:00.789873 31272 trainer.py:139] Epoch[146/1500] loss: 0.0899284775218656
I0414 23:30:05.586825 31272 trainer.py:139] Epoch[147/1500] loss: 0.08940913095589607
I0414 23:30:10.231289 31272 trainer.py:139] Epoch[148/1500] loss: 0.0879888323045546
I0414 23:30:14.809969 31272 trainer.py:139] Epoch[149/1500] loss: 0.08787457957383125
I0414 23:30:15.075083 31272 trainer.py:145] Test: {'precision': 0.13021447721179635, 'recall': 0.3078761782558503, 'hit_ratio': 0.8798927613941019, 'ndcg': 0.2885083693335915}
I0414 23:30:20.584652 31272 trainer.py:139] Epoch[150/1500] loss: 0.08866504339441177
I0414 23:30:26.327439 31272 trainer.py:139] Epoch[151/1500] loss: 0.08948689843377759
I0414 23:30:31.098480 31272 trainer.py:139] Epoch[152/1500] loss: 0.08848081553174604
I0414 23:30:35.987124 31272 trainer.py:139] Epoch[153/1500] loss: 0.08708641197412245
I0414 23:30:41.073110 31272 trainer.py:139] Epoch[154/1500] loss: 0.08786440688756204
I0414 23:30:47.470706 31272 trainer.py:139] Epoch[155/1500] loss: 0.0860220470255421
I0414 23:30:52.445065 31272 trainer.py:139] Epoch[156/1500] loss: 0.08725044539859218
I0414 23:30:57.193182 31272 trainer.py:139] Epoch[157/1500] loss: 0.08568225536615617
I0414 23:31:01.675187 31272 trainer.py:139] Epoch[158/1500] loss: 0.08696778671395394
I0414 23:31:08.179427 31272 trainer.py:139] Epoch[159/1500] loss: 0.08555349731637586
I0414 23:31:12.909604 31272 trainer.py:139] Epoch[160/1500] loss: 0.0852632830219884
I0414 23:31:17.604896 31272 trainer.py:139] Epoch[161/1500] loss: 0.0851301317734103
I0414 23:31:22.236400 31272 trainer.py:139] Epoch[162/1500] loss: 0.08573813904677668
I0414 23:31:28.728619 31272 trainer.py:139] Epoch[163/1500] loss: 0.08460594353175932
I0414 23:31:33.404909 31272 trainer.py:139] Epoch[164/1500] loss: 0.0842363243141482
I0414 23:31:38.111649 31272 trainer.py:139] Epoch[165/1500] loss: 0.08367185799344894
I0414 23:31:42.888670 31272 trainer.py:139] Epoch[166/1500] loss: 0.0841194182153671
I0414 23:31:49.499553 31272 trainer.py:139] Epoch[167/1500] loss: 0.08458311759656476
I0414 23:31:54.188865 31272 trainer.py:139] Epoch[168/1500] loss: 0.08491019303760221
I0414 23:31:59.036647 31272 trainer.py:139] Epoch[169/1500] loss: 0.08436684791118867
I0414 23:32:03.893399 31272 trainer.py:139] Epoch[170/1500] loss: 0.08262714238897446
I0414 23:32:09.320246 31272 trainer.py:139] Epoch[171/1500] loss: 0.08402457496812267
I0414 23:32:15.199574 31272 trainer.py:139] Epoch[172/1500] loss: 0.0823021694537132
I0414 23:32:19.890881 31272 trainer.py:139] Epoch[173/1500] loss: 0.08279262555222358
I0414 23:32:24.654942 31272 trainer.py:139] Epoch[174/1500] loss: 0.08140705766216401
I0414 23:32:29.497744 31272 trainer.py:139] Epoch[175/1500] loss: 0.0834386017053358
I0414 23:32:35.947167 31272 trainer.py:139] Epoch[176/1500] loss: 0.08259607202583744
I0414 23:32:40.708238 31272 trainer.py:139] Epoch[177/1500] loss: 0.0832058407606617
I0414 23:32:45.501203 31272 trainer.py:139] Epoch[178/1500] loss: 0.0803652016385909
I0414 23:32:50.819415 31272 trainer.py:139] Epoch[179/1500] loss: 0.08053297477383767
I0414 23:32:56.864671 31272 trainer.py:139] Epoch[180/1500] loss: 0.08016715775574407
I0414 23:33:01.455313 31272 trainer.py:139] Epoch[181/1500] loss: 0.08082418432158808
I0414 23:33:06.148613 31272 trainer.py:139] Epoch[182/1500] loss: 0.07893899924332096
I0414 23:33:10.870815 31272 trainer.py:139] Epoch[183/1500] loss: 0.08077719951829603
I0414 23:33:15.652817 31272 trainer.py:139] Epoch[184/1500] loss: 0.08216085669494444
I0414 23:33:21.790284 31272 trainer.py:139] Epoch[185/1500] loss: 0.07968015632321758
I0414 23:33:26.448699 31272 trainer.py:139] Epoch[186/1500] loss: 0.08034212911321272
I0414 23:33:31.079208 31272 trainer.py:139] Epoch[187/1500] loss: 0.07764658932724307
I0414 23:33:35.856228 31272 trainer.py:139] Epoch[188/1500] loss: 0.08089017531564159
I0414 23:33:40.618298 31272 trainer.py:139] Epoch[189/1500] loss: 0.07953134419456605
I0414 23:33:46.832508 31272 trainer.py:139] Epoch[190/1500] loss: 0.07996018399153987
I0414 23:33:51.601552 31272 trainer.py:139] Epoch[191/1500] loss: 0.07919439336945934
I0414 23:33:56.257976 31272 trainer.py:139] Epoch[192/1500] loss: 0.07818093535400206
I0414 23:34:00.753934 31272 trainer.py:139] Epoch[193/1500] loss: 0.07751847971831599
I0414 23:34:05.218009 31272 trainer.py:139] Epoch[194/1500] loss: 0.07978667655298786
I0414 23:34:11.496008 31272 trainer.py:139] Epoch[195/1500] loss: 0.07721003866003405
I0414 23:34:16.153426 31272 trainer.py:139] Epoch[196/1500] loss: 0.07682798346204142
I0414 23:34:20.777956 31272 trainer.py:139] Epoch[197/1500] loss: 0.07791995173019747
I0414 23:34:25.370592 31272 trainer.py:139] Epoch[198/1500] loss: 0.07883309741174022
I0414 23:34:30.820822 31272 trainer.py:139] Epoch[199/1500] loss: 0.07659155550983644
I0414 23:34:31.171648 31272 trainer.py:145] Test: {'precision': 0.13345844504021456, 'recall': 0.31584814723554683, 'hit_ratio': 0.8841823056300268, 'ndcg': 0.2968850563901746}
I0414 23:34:36.412116 31272 trainer.py:139] Epoch[200/1500] loss: 0.07736291039374567
I0414 23:34:41.014155 31272 trainer.py:139] Epoch[201/1500] loss: 0.0766549885513321
I0414 23:34:45.550978 31272 trainer.py:139] Epoch[202/1500] loss: 0.07608434221436901
I0414 23:34:50.198429 31272 trainer.py:139] Epoch[203/1500] loss: 0.0770152939423438
I0414 23:34:55.901364 31272 trainer.py:139] Epoch[204/1500] loss: 0.0761137508576916
I0414 23:35:01.130864 31272 trainer.py:139] Epoch[205/1500] loss: 0.07746696712509278
I0414 23:35:05.764363 31272 trainer.py:139] Epoch[206/1500] loss: 0.07733534636997408
I0414 23:35:10.407830 31272 trainer.py:139] Epoch[207/1500] loss: 0.07471246248291384
I0414 23:35:15.037341 31272 trainer.py:139] Epoch[208/1500] loss: 0.07655971377126632
I0414 23:35:21.144412 31272 trainer.py:139] Epoch[209/1500] loss: 0.07438572880721861
I0414 23:35:25.903490 31272 trainer.py:139] Epoch[210/1500] loss: 0.07359202566646761
I0414 23:35:30.332672 31272 trainer.py:139] Epoch[211/1500] loss: 0.076351314542755
I0414 23:35:34.963182 31272 trainer.py:139] Epoch[212/1500] loss: 0.0748539254550011
I0414 23:35:39.562794 31272 trainer.py:139] Epoch[213/1500] loss: 0.07575574565318323
I0414 23:35:45.720195 31272 trainer.py:139] Epoch[214/1500] loss: 0.07374769353097485
I0414 23:35:50.443393 31272 trainer.py:139] Epoch[215/1500] loss: 0.07526931503126698
I0414 23:35:55.195495 31272 trainer.py:139] Epoch[216/1500] loss: 0.07626560859141811
I0414 23:35:59.843945 31272 trainer.py:139] Epoch[217/1500] loss: 0.07386708175463061
I0414 23:36:04.662824 31272 trainer.py:139] Epoch[218/1500] loss: 0.07273799132916235
I0414 23:36:11.057435 31272 trainer.py:139] Epoch[219/1500] loss: 0.0725264070976165
I0414 23:36:15.691926 31272 trainer.py:139] Epoch[220/1500] loss: 0.07292706531382376
I0414 23:36:20.165959 31272 trainer.py:139] Epoch[221/1500] loss: 0.07404999290743182
I0414 23:36:24.839326 31272 trainer.py:139] Epoch[222/1500] loss: 0.07361634964904477
I0414 23:36:30.970812 31272 trainer.py:139] Epoch[223/1500] loss: 0.07473669922159563
I0414 23:36:35.583382 31272 trainer.py:139] Epoch[224/1500] loss: 0.07170918007050792
I0414 23:36:40.316548 31272 trainer.py:139] Epoch[225/1500] loss: 0.07328656327820593
I0414 23:36:44.956027 31272 trainer.py:139] Epoch[226/1500] loss: 0.07231937925661763
I0414 23:36:49.509792 31272 trainer.py:139] Epoch[227/1500] loss: 0.07457210484050936
I0414 23:36:55.750913 31272 trainer.py:139] Epoch[228/1500] loss: 0.07154382092337455
I0414 23:37:00.566802 31272 trainer.py:139] Epoch[229/1500] loss: 0.07208832641763072
I0414 23:37:05.113592 31272 trainer.py:139] Epoch[230/1500] loss: 0.07115991774105257
I0414 23:37:09.876657 31272 trainer.py:139] Epoch[231/1500] loss: 0.07134977607957778
I0414 23:37:14.496202 31272 trainer.py:139] Epoch[232/1500] loss: 0.07211975969614522
I0414 23:37:20.736326 31272 trainer.py:139] Epoch[233/1500] loss: 0.07107879581951326
I0414 23:37:25.470488 31272 trainer.py:139] Epoch[234/1500] loss: 0.07065002716356708
I0414 23:37:29.860802 31272 trainer.py:139] Epoch[235/1500] loss: 0.0719578544939718
I0414 23:37:34.650778 31272 trainer.py:139] Epoch[236/1500] loss: 0.07160404228395031
I0414 23:37:39.346070 31272 trainer.py:139] Epoch[237/1500] loss: 0.0709425053529201
I0414 23:37:45.592182 31272 trainer.py:139] Epoch[238/1500] loss: 0.07162248283143967
I0414 23:37:50.407073 31272 trainer.py:139] Epoch[239/1500] loss: 0.0704084490576098
I0414 23:37:54.932933 31272 trainer.py:139] Epoch[240/1500] loss: 0.07256063746829186
I0414 23:37:59.377064 31272 trainer.py:139] Epoch[241/1500] loss: 0.07143149116346913
I0414 23:38:04.073354 31272 trainer.py:139] Epoch[242/1500] loss: 0.07050324964427179
I0414 23:38:10.185905 31272 trainer.py:139] Epoch[243/1500] loss: 0.07116239950541527
I0414 23:38:14.839843 31272 trainer.py:139] Epoch[244/1500] loss: 0.07132645155633649
I0414 23:38:19.273013 31272 trainer.py:139] Epoch[245/1500] loss: 0.06971190232903726
I0414 23:38:23.828772 31272 trainer.py:139] Epoch[246/1500] loss: 0.07033598519140674
I0414 23:38:28.352638 31272 trainer.py:139] Epoch[247/1500] loss: 0.07070829046349372
I0414 23:38:34.448246 31272 trainer.py:139] Epoch[248/1500] loss: 0.0714239576651204
I0414 23:38:39.224267 31272 trainer.py:139] Epoch[249/1500] loss: 0.06890945328820136
I0414 23:38:39.502337 31272 trainer.py:145] Test: {'precision': 0.1348793565683647, 'recall': 0.3193306812341666, 'hit_ratio': 0.8863270777479892, 'ndcg': 0.3010664315572402}
I0414 23:38:43.984343 31272 trainer.py:139] Epoch[250/1500] loss: 0.0707717941653344
I0414 23:38:48.813189 31272 trainer.py:139] Epoch[251/1500] loss: 0.0697046461845598
I0414 23:38:53.628081 31272 trainer.py:139] Epoch[252/1500] loss: 0.06885082442914287
I0414 23:38:59.972313 31272 trainer.py:139] Epoch[253/1500] loss: 0.0688756306565577
I0414 23:39:04.733384 31272 trainer.py:139] Epoch[254/1500] loss: 0.06947003677487373
I0414 23:39:09.287149 31272 trainer.py:139] Epoch[255/1500] loss: 0.06843333475051387
I0414 23:39:13.972475 31272 trainer.py:139] Epoch[256/1500] loss: 0.06907415930782596
I0414 23:39:19.188028 31272 trainer.py:139] Epoch[257/1500] loss: 0.06715656059884256
I0414 23:39:25.053406 31272 trainer.py:139] Epoch[258/1500] loss: 0.06797392029435403
I0414 23:39:29.460661 31272 trainer.py:139] Epoch[259/1500] loss: 0.06907833932388213
I0414 23:39:34.016829 31272 trainer.py:139] Epoch[260/1500] loss: 0.06806601415718755
I0414 23:39:38.663284 31272 trainer.py:139] Epoch[261/1500] loss: 0.0688803204365315
I0414 23:39:43.350604 31272 trainer.py:139] Epoch[262/1500] loss: 0.06804900207827168
I0414 23:39:49.675446 31272 trainer.py:139] Epoch[263/1500] loss: 0.06935920109671931
I0414 23:39:54.211271 31272 trainer.py:139] Epoch[264/1500] loss: 0.06834500523344163
I0414 23:39:59.102906 31272 trainer.py:139] Epoch[265/1500] loss: 0.06894851259646877
I0414 23:40:03.736405 31272 trainer.py:139] Epoch[266/1500] loss: 0.06745304023065875
I0414 23:40:08.789501 31272 trainer.py:139] Epoch[267/1500] loss: 0.0668453749629759
I0414 23:40:14.634945 31272 trainer.py:139] Epoch[268/1500] loss: 0.06785520009936825
I0414 23:40:19.344190 31272 trainer.py:139] Epoch[269/1500] loss: 0.0673139008783525
I0414 23:40:23.854104 31272 trainer.py:139] Epoch[270/1500] loss: 0.06809787680545161
I0414 23:40:28.305212 31272 trainer.py:139] Epoch[271/1500] loss: 0.06593623384833336
I0414 23:40:33.164954 31272 trainer.py:139] Epoch[272/1500] loss: 0.06785831324035121
I0414 23:40:39.208735 31272 trainer.py:139] Epoch[273/1500] loss: 0.06604409818687747
I0414 23:40:43.828281 31272 trainer.py:139] Epoch[274/1500] loss: 0.06630506306405991
I0414 23:40:48.480716 31272 trainer.py:139] Epoch[275/1500] loss: 0.06635183865024198
I0414 23:40:52.941792 31272 trainer.py:139] Epoch[276/1500] loss: 0.06647289243917312
I0414 23:40:58.520131 31272 trainer.py:139] Epoch[277/1500] loss: 0.06718961161471182
I0414 23:41:03.858272 31272 trainer.py:139] Epoch[278/1500] loss: 0.06683061368042423
I0414 23:41:08.302405 31272 trainer.py:139] Epoch[279/1500] loss: 0.06818789496056495
I0414 23:41:13.094373 31272 trainer.py:139] Epoch[280/1500] loss: 0.06401272118091583
I0414 23:41:17.977039 31272 trainer.py:139] Epoch[281/1500] loss: 0.06679721152590166
I0414 23:41:24.082613 31272 trainer.py:139] Epoch[282/1500] loss: 0.06594965510791348
I0414 23:41:28.681228 31272 trainer.py:139] Epoch[283/1500] loss: 0.06592758264272444
I0414 23:41:33.206091 31272 trainer.py:139] Epoch[284/1500] loss: 0.06543796329248336
I0414 23:41:37.748894 31272 trainer.py:139] Epoch[285/1500] loss: 0.0662992127960728
I0414 23:41:42.333556 31272 trainer.py:139] Epoch[286/1500] loss: 0.06613633000562268
I0414 23:41:48.541786 31272 trainer.py:139] Epoch[287/1500] loss: 0.06646910405928089
I0414 23:41:53.064656 31272 trainer.py:139] Epoch[288/1500] loss: 0.0662250617338765
I0414 23:41:57.540682 31272 trainer.py:139] Epoch[289/1500] loss: 0.06708242143354108
I0414 23:42:02.228002 31272 trainer.py:139] Epoch[290/1500] loss: 0.0651967306771586
I0414 23:42:06.914324 31272 trainer.py:139] Epoch[291/1500] loss: 0.06534405329054402
I0414 23:42:13.135511 31272 trainer.py:139] Epoch[292/1500] loss: 0.06483969657171157
I0414 23:42:17.801899 31272 trainer.py:139] Epoch[293/1500] loss: 0.06547158632066942
I0414 23:42:22.310816 31272 trainer.py:139] Epoch[294/1500] loss: 0.06381541875100905
I0414 23:42:26.802789 31272 trainer.py:139] Epoch[295/1500] loss: 0.06624781256241183
I0414 23:42:31.662039 31272 trainer.py:139] Epoch[296/1500] loss: 0.06529600377525052
I0414 23:42:37.724756 31272 trainer.py:139] Epoch[297/1500] loss: 0.06412641331553459
I0414 23:42:42.408088 31272 trainer.py:139] Epoch[298/1500] loss: 0.0653450503464668
I0414 23:42:46.968831 31272 trainer.py:139] Epoch[299/1500] loss: 0.06410003934175737
I0414 23:42:47.253877 31272 trainer.py:145] Test: {'precision': 0.13638069705093842, 'recall': 0.3219838342981381, 'hit_ratio': 0.8879356568364611, 'ndcg': 0.3028579801497119}
I0414 23:42:52.050829 31272 trainer.py:139] Epoch[300/1500] loss: 0.06386131276526759
I0414 23:42:57.078012 31272 trainer.py:139] Epoch[301/1500] loss: 0.0632694661617279
I0414 23:43:02.892560 31272 trainer.py:139] Epoch[302/1500] loss: 0.064235893468703
I0414 23:43:07.445329 31272 trainer.py:139] Epoch[303/1500] loss: 0.06476219983831528
I0414 23:43:12.099760 31272 trainer.py:139] Epoch[304/1500] loss: 0.06405510933649156
I0414 23:43:16.656515 31272 trainer.py:139] Epoch[305/1500] loss: 0.06348067630202539
I0414 23:43:21.326889 31272 trainer.py:139] Epoch[306/1500] loss: 0.0626903336134649
I0414 23:43:27.504222 31272 trainer.py:139] Epoch[307/1500] loss: 0.0636214796573885
I0414 23:43:32.105829 31272 trainer.py:139] Epoch[308/1500] loss: 0.06394700417595525
I0414 23:43:36.757268 31272 trainer.py:139] Epoch[309/1500] loss: 0.06236868604056297
I0414 23:43:41.310038 31272 trainer.py:139] Epoch[310/1500] loss: 0.06457020798998495
I0414 23:43:45.736229 31272 trainer.py:139] Epoch[311/1500] loss: 0.06530038519732413
I0414 23:43:52.057083 31272 trainer.py:139] Epoch[312/1500] loss: 0.06245204614054772
I0414 23:43:56.692575 31272 trainer.py:139] Epoch[313/1500] loss: 0.06573101565722496
I0414 23:44:01.226409 31272 trainer.py:139] Epoch[314/1500] loss: 0.06415152669914308
I0414 23:44:05.921645 31272 trainer.py:139] Epoch[315/1500] loss: 0.06244063785960598
I0414 23:44:10.521257 31272 trainer.py:139] Epoch[316/1500] loss: 0.06273258080886256
I0414 23:44:16.897923 31272 trainer.py:139] Epoch[317/1500] loss: 0.06347996441106643
I0414 23:44:21.675939 31272 trainer.py:139] Epoch[318/1500] loss: 0.062466597364794825
I0414 23:44:26.054292 31272 trainer.py:139] Epoch[319/1500] loss: 0.06137095343682074
I0414 23:44:30.762541 31272 trainer.py:139] Epoch[320/1500] loss: 0.06378052539883121
I0414 23:44:35.392053 31272 trainer.py:139] Epoch[321/1500] loss: 0.0629634797092407
I0414 23:44:41.841477 31272 trainer.py:139] Epoch[322/1500] loss: 0.06211176082011192
I0414 23:44:46.473979 31272 trainer.py:139] Epoch[323/1500] loss: 0.06302842593962146
I0414 23:44:51.045685 31272 trainer.py:139] Epoch[324/1500] loss: 0.06225364354829634
I0414 23:44:55.600450 31272 trainer.py:139] Epoch[325/1500] loss: 0.0632917043422499
I0414 23:45:00.191090 31272 trainer.py:139] Epoch[326/1500] loss: 0.06308484017368286
I0414 23:45:06.354471 31272 trainer.py:139] Epoch[327/1500] loss: 0.06304057615418587
I0414 23:45:11.097604 31272 trainer.py:139] Epoch[328/1500] loss: 0.061012372735046574
I0414 23:45:15.661337 31272 trainer.py:139] Epoch[329/1500] loss: 0.06056676324336759
I0414 23:45:20.196165 31272 trainer.py:139] Epoch[330/1500] loss: 0.061335303370029695
I0414 23:45:24.975177 31272 trainer.py:139] Epoch[331/1500] loss: 0.06061814497074773
I0414 23:45:31.101772 31272 trainer.py:139] Epoch[332/1500] loss: 0.06214030195147761
I0414 23:45:35.622650 31272 trainer.py:139] Epoch[333/1500] loss: 0.06270267057322687
I0414 23:45:40.333888 31272 trainer.py:139] Epoch[334/1500] loss: 0.06383032748295416
I0414 23:45:44.928947 31272 trainer.py:139] Epoch[335/1500] loss: 0.06305640226890964
I0414 23:45:50.378715 31272 trainer.py:139] Epoch[336/1500] loss: 0.06222612603056815
I0414 23:45:55.778650 31272 trainer.py:139] Epoch[337/1500] loss: 0.06184199308195422
I0414 23:46:00.385239 31272 trainer.py:139] Epoch[338/1500] loss: 0.06191290999131818
I0414 23:46:05.002791 31272 trainer.py:139] Epoch[339/1500] loss: 0.05966091961149247
I0414 23:46:09.497754 31272 trainer.py:139] Epoch[340/1500] loss: 0.06063061664181371
I0414 23:46:14.823935 31272 trainer.py:139] Epoch[341/1500] loss: 0.06251743003245323
I0414 23:46:20.468053 31272 trainer.py:139] Epoch[342/1500] loss: 0.06237356436829413
I0414 23:46:25.118495 31272 trainer.py:139] Epoch[343/1500] loss: 0.06204980695920606
I0414 23:46:29.809776 31272 trainer.py:139] Epoch[344/1500] loss: 0.06236090823527305
I0414 23:46:34.331648 31272 trainer.py:139] Epoch[345/1500] loss: 0.05977732339693654
I0414 23:46:39.905004 31272 trainer.py:139] Epoch[346/1500] loss: 0.0616283017781473
I0414 23:46:45.175371 31272 trainer.py:139] Epoch[347/1500] loss: 0.06156865146852309
I0414 23:46:49.633460 31272 trainer.py:139] Epoch[348/1500] loss: 0.06154792972149387
I0414 23:46:54.255454 31272 trainer.py:139] Epoch[349/1500] loss: 0.06157158050806292
I0414 23:46:54.518573 31272 trainer.py:145] Test: {'precision': 0.1368900804289545, 'recall': 0.32368921485740615, 'hit_ratio': 0.8906166219839142, 'ndcg': 0.3042299969681231}
I0414 23:46:59.054399 31272 trainer.py:139] Epoch[350/1500] loss: 0.06150155382290963
I0414 23:47:05.473368 31272 trainer.py:139] Epoch[351/1500] loss: 0.06134273472332185
I0414 23:47:09.947400 31272 trainer.py:139] Epoch[352/1500] loss: 0.0603065898101176
I0414 23:47:14.710467 31272 trainer.py:139] Epoch[353/1500] loss: 0.060169239558519855
I0414 23:47:19.348948 31272 trainer.py:139] Epoch[354/1500] loss: 0.06248707168044582
I0414 23:47:24.084110 31272 trainer.py:139] Epoch[355/1500] loss: 0.059134196129537395
I0414 23:47:30.365094 31272 trainer.py:139] Epoch[356/1500] loss: 0.06066667865360937
I0414 23:47:35.257170 31272 trainer.py:139] Epoch[357/1500] loss: 0.06063897403017167
I0414 23:47:40.109935 31272 trainer.py:139] Epoch[358/1500] loss: 0.06055495731772915
I0414 23:47:44.481311 31272 trainer.py:139] Epoch[359/1500] loss: 0.05918841869119675
I0414 23:47:48.742057 31272 trainer.py:139] Epoch[360/1500] loss: 0.06119583426944671
I0414 23:47:55.164571 31272 trainer.py:139] Epoch[361/1500] loss: 0.060110053708476406
I0414 23:47:59.931623 31272 trainer.py:139] Epoch[362/1500] loss: 0.06038277379928097
I0414 23:48:04.434559 31272 trainer.py:139] Epoch[363/1500] loss: 0.059322750976970116
I0414 23:48:09.277358 31272 trainer.py:139] Epoch[364/1500] loss: 0.06011218938135331
I0414 23:48:14.869650 31272 trainer.py:139] Epoch[365/1500] loss: 0.059740524498685714
I0414 23:48:20.353261 31272 trainer.py:139] Epoch[366/1500] loss: 0.06018294333930938
I0414 23:48:24.973803 31272 trainer.py:139] Epoch[367/1500] loss: 0.060216045908389554
I0414 23:48:29.575408 31272 trainer.py:139] Epoch[368/1500] loss: 0.05948764854861844
I0414 23:48:34.338474 31272 trainer.py:139] Epoch[369/1500] loss: 0.05938519309124639
I0414 23:48:39.925257 31272 trainer.py:139] Epoch[370/1500] loss: 0.05973988507063158
I0414 23:48:45.317219 31272 trainer.py:139] Epoch[371/1500] loss: 0.060394259830636364
I0414 23:48:49.886931 31272 trainer.py:139] Epoch[372/1500] loss: 0.060154613227613514
I0414 23:48:54.419767 31272 trainer.py:139] Epoch[373/1500] loss: 0.05977069454327706
I0414 23:48:58.967552 31272 trainer.py:139] Epoch[374/1500] loss: 0.059141343639742945
I0414 23:49:04.377901 31272 trainer.py:139] Epoch[375/1500] loss: 0.058904483433692686
I0414 23:49:09.990580 31272 trainer.py:139] Epoch[376/1500] loss: 0.05899886113982047
I0414 23:49:14.556305 31272 trainer.py:139] Epoch[377/1500] loss: 0.05984622083844677
I0414 23:49:19.314388 31272 trainer.py:139] Epoch[378/1500] loss: 0.058425997774447166
I0414 23:49:24.005693 31272 trainer.py:139] Epoch[379/1500] loss: 0.05881636517663156
I0414 23:49:29.404633 31272 trainer.py:139] Epoch[380/1500] loss: 0.057895731301076954
I0414 23:49:34.738766 31272 trainer.py:139] Epoch[381/1500] loss: 0.059639831103624835
I0414 23:49:39.297514 31272 trainer.py:139] Epoch[382/1500] loss: 0.060651530902231895
I0414 23:49:44.017723 31272 trainer.py:139] Epoch[383/1500] loss: 0.06018126551662722
I0414 23:49:48.804173 31272 trainer.py:139] Epoch[384/1500] loss: 0.05931067430684643
I0414 23:49:54.258924 31272 trainer.py:139] Epoch[385/1500] loss: 0.05904051685525525
I0414 23:49:59.643909 31272 trainer.py:139] Epoch[386/1500] loss: 0.06029104982172289
I0414 23:50:04.108971 31272 trainer.py:139] Epoch[387/1500] loss: 0.058071972261513435
I0414 23:50:08.901937 31272 trainer.py:139] Epoch[388/1500] loss: 0.05823161428974521
I0414 23:50:13.299226 31272 trainer.py:139] Epoch[389/1500] loss: 0.05827741949788986
I0414 23:50:19.075902 31272 trainer.py:139] Epoch[390/1500] loss: 0.059253504920390346
I0414 23:50:24.169860 31272 trainer.py:139] Epoch[391/1500] loss: 0.05668202559313466
I0414 23:50:28.731600 31272 trainer.py:139] Epoch[392/1500] loss: 0.05849149102164853
I0414 23:50:33.413934 31272 trainer.py:139] Epoch[393/1500] loss: 0.058804100920115746
I0414 23:50:38.014543 31272 trainer.py:139] Epoch[394/1500] loss: 0.058224915977447264
I0414 23:50:44.408154 31272 trainer.py:139] Epoch[395/1500] loss: 0.059117058111775304
I0414 23:50:49.162699 31272 trainer.py:139] Epoch[396/1500] loss: 0.05872559439270727
I0414 23:50:53.768291 31272 trainer.py:139] Epoch[397/1500] loss: 0.05818121339524946
I0414 23:50:58.272224 31272 trainer.py:139] Epoch[398/1500] loss: 0.058365925185142026
I0414 23:51:02.867849 31272 trainer.py:139] Epoch[399/1500] loss: 0.05842533899891761
I0414 23:51:03.133959 31272 trainer.py:145] Test: {'precision': 0.13734584450402157, 'recall': 0.3255248966106876, 'hit_ratio': 0.8932975871313673, 'ndcg': 0.30708913278143407}
I0414 23:51:09.515609 31272 trainer.py:139] Epoch[400/1500] loss: 0.05847191762539648
I0414 23:51:14.228770 31272 trainer.py:139] Epoch[401/1500] loss: 0.05805127935544137
I0414 23:51:18.758125 31272 trainer.py:139] Epoch[402/1500] loss: 0.05733499772125675
I0414 23:51:23.441390 31272 trainer.py:139] Epoch[403/1500] loss: 0.05876423142129375
I0414 23:51:28.294661 31272 trainer.py:139] Epoch[404/1500] loss: 0.05873889992794683
I0414 23:51:34.716122 31272 trainer.py:139] Epoch[405/1500] loss: 0.058555915110534235
I0414 23:51:39.309263 31272 trainer.py:139] Epoch[406/1500] loss: 0.057802435491354234
I0414 23:51:43.907879 31272 trainer.py:139] Epoch[407/1500] loss: 0.058430073362204335
I0414 23:51:48.689881 31272 trainer.py:139] Epoch[408/1500] loss: 0.05834345122979533
I0414 23:51:53.268563 31272 trainer.py:139] Epoch[409/1500] loss: 0.05781913644844486
I0414 23:51:59.600379 31272 trainer.py:139] Epoch[410/1500] loss: 0.05805909825909522
I0414 23:52:04.172086 31272 trainer.py:139] Epoch[411/1500] loss: 0.05728146181471886
I0414 23:52:08.813968 31272 trainer.py:139] Epoch[412/1500] loss: 0.05687838492374266
I0414 23:52:13.322885 31272 trainer.py:139] Epoch[413/1500] loss: 0.05703711437602197
I0414 23:52:17.619019 31272 trainer.py:139] Epoch[414/1500] loss: 0.059329999190184377
I0414 23:52:23.482848 31272 trainer.py:139] Epoch[415/1500] loss: 0.05758142531398804
I0414 23:52:28.539929 31272 trainer.py:139] Epoch[416/1500] loss: 0.059058867154582854
I0414 23:52:33.144524 31272 trainer.py:139] Epoch[417/1500] loss: 0.05739508244779802
I0414 23:52:37.935497 31272 trainer.py:139] Epoch[418/1500] loss: 0.05651016040675102
I0414 23:52:42.750390 31272 trainer.py:139] Epoch[419/1500] loss: 0.05761567587333341
I0414 23:52:48.446533 31272 trainer.py:139] Epoch[420/1500] loss: 0.05700051399969285
I0414 23:52:53.648129 31272 trainer.py:139] Epoch[421/1500] loss: 0.0574629423358748
I0414 23:52:58.049406 31272 trainer.py:139] Epoch[422/1500] loss: 0.05633401666437426
I0414 23:53:02.753089 31272 trainer.py:139] Epoch[423/1500] loss: 0.056030347582794
I0414 23:53:07.356687 31272 trainer.py:139] Epoch[424/1500] loss: 0.05702722096635449
I0414 23:53:13.688968 31272 trainer.py:139] Epoch[425/1500] loss: 0.05667759309853277
I0414 23:53:18.449041 31272 trainer.py:139] Epoch[426/1500] loss: 0.05729594502237535
I0414 23:53:22.900151 31272 trainer.py:139] Epoch[427/1500] loss: 0.05651687890771897
I0414 23:53:27.398103 31272 trainer.py:139] Epoch[428/1500] loss: 0.05714392085229197
I0414 23:53:31.874128 31272 trainer.py:139] Epoch[429/1500] loss: 0.057095695166818554
I0414 23:53:38.341949 31272 trainer.py:139] Epoch[430/1500] loss: 0.05593551166595951
I0414 23:53:42.981359 31272 trainer.py:139] Epoch[431/1500] loss: 0.05636506551696408
I0414 23:53:47.345265 31272 trainer.py:139] Epoch[432/1500] loss: 0.056370905089762904
I0414 23:53:51.898035 31272 trainer.py:139] Epoch[433/1500] loss: 0.056734280841004466
I0414 23:53:56.982027 31272 trainer.py:139] Epoch[434/1500] loss: 0.055544364115884225
I0414 23:54:02.898685 31272 trainer.py:139] Epoch[435/1500] loss: 0.05799282234041921
I0414 23:54:07.614908 31272 trainer.py:139] Epoch[436/1500] loss: 0.05518099425300475
I0414 23:54:12.358041 31272 trainer.py:139] Epoch[437/1500] loss: 0.05698904383086389
I0414 23:54:17.046356 31272 trainer.py:139] Epoch[438/1500] loss: 0.056521191592178034
I0414 23:54:22.402438 31272 trainer.py:139] Epoch[439/1500] loss: 0.05637472062822311
I0414 23:54:27.719652 31272 trainer.py:139] Epoch[440/1500] loss: 0.05671388379508449
I0414 23:54:32.312719 31272 trainer.py:139] Epoch[441/1500] loss: 0.056662587629210566
I0414 23:54:36.832599 31272 trainer.py:139] Epoch[442/1500] loss: 0.05590591098993055
I0414 23:54:41.314605 31272 trainer.py:139] Epoch[443/1500] loss: 0.05429612712994698
I0414 23:54:47.085299 31272 trainer.py:139] Epoch[444/1500] loss: 0.056530915441051606
I0414 23:54:52.187234 31272 trainer.py:139] Epoch[445/1500] loss: 0.05645536342936178
I0414 23:54:56.907440 31272 trainer.py:139] Epoch[446/1500] loss: 0.055518498944659385
I0414 23:55:01.582799 31272 trainer.py:139] Epoch[447/1500] loss: 0.05512150365018075
I0414 23:55:06.282078 31272 trainer.py:139] Epoch[448/1500] loss: 0.05711190931258663
I0414 23:55:12.417554 31272 trainer.py:139] Epoch[449/1500] loss: 0.05636367682487734
I0414 23:55:12.727515 31272 trainer.py:145] Test: {'precision': 0.13833780160857914, 'recall': 0.32762187119859426, 'hit_ratio': 0.8927613941018767, 'ndcg': 0.3077747765803399}
I0414 23:55:17.326548 31272 trainer.py:139] Epoch[450/1500] loss: 0.05630005535579497
I0414 23:55:21.997920 31272 trainer.py:139] Epoch[451/1500] loss: 0.054390710207723805
I0414 23:55:26.554184 31272 trainer.py:139] Epoch[452/1500] loss: 0.055629333060595296
I0414 23:55:31.238513 31272 trainer.py:139] Epoch[453/1500] loss: 0.05635299125025349
I0414 23:55:37.589266 31272 trainer.py:139] Epoch[454/1500] loss: 0.055659753781172536
I0414 23:55:42.332399 31272 trainer.py:139] Epoch[455/1500] loss: 0.054477265284907435
I0414 23:55:46.849242 31272 trainer.py:139] Epoch[456/1500] loss: 0.05521394528688923
I0414 23:55:51.531577 31272 trainer.py:139] Epoch[457/1500] loss: 0.05502931160792228
I0414 23:55:56.324542 31272 trainer.py:139] Epoch[458/1500] loss: 0.054664384333356734
I0414 23:56:02.828783 31272 trainer.py:139] Epoch[459/1500] loss: 0.055830247820385044
I0414 23:56:07.453314 31272 trainer.py:139] Epoch[460/1500] loss: 0.054560392013480584
I0414 23:56:11.914390 31272 trainer.py:139] Epoch[461/1500] loss: 0.05583542909833693
I0414 23:56:16.331612 31272 trainer.py:139] Epoch[462/1500] loss: 0.0549112090901021
I0414 23:56:20.915280 31272 trainer.py:139] Epoch[463/1500] loss: 0.05582069881981419
I0414 23:56:26.972014 31272 trainer.py:139] Epoch[464/1500] loss: 0.05598374468184287
I0414 23:56:31.725490 31272 trainer.py:139] Epoch[465/1500] loss: 0.05564353627062613
I0414 23:56:36.310153 31272 trainer.py:139] Epoch[466/1500] loss: 0.05475147284807697
I0414 23:56:40.789590 31272 trainer.py:139] Epoch[467/1500] loss: 0.05648579364342074
I0414 23:56:46.549326 31272 trainer.py:139] Epoch[468/1500] loss: 0.05625270186893402
I0414 23:56:51.676169 31272 trainer.py:139] Epoch[469/1500] loss: 0.05528200742217802
I0414 23:56:56.372459 31272 trainer.py:139] Epoch[470/1500] loss: 0.0543117877696791
I0414 23:57:00.915261 31272 trainer.py:139] Epoch[471/1500] loss: 0.05450503984766622
I0414 23:57:05.810883 31272 trainer.py:139] Epoch[472/1500] loss: 0.05568403161821827
I0414 23:57:11.655332 31272 trainer.py:139] Epoch[473/1500] loss: 0.0545357865912299
I0414 23:57:16.563911 31272 trainer.py:139] Epoch[474/1500] loss: 0.055896875118055654
I0414 23:57:21.186445 31272 trainer.py:139] Epoch[475/1500] loss: 0.055788308261863644
I0414 23:57:25.740211 31272 trainer.py:139] Epoch[476/1500] loss: 0.05493742696219875
I0414 23:57:30.360753 31272 trainer.py:139] Epoch[477/1500] loss: 0.05581406744257096
I0414 23:57:36.701984 31272 trainer.py:139] Epoch[478/1500] loss: 0.05535702419377143
I0414 23:57:41.531826 31272 trainer.py:139] Epoch[479/1500] loss: 0.05517601630380077
I0414 23:57:46.225125 31272 trainer.py:139] Epoch[480/1500] loss: 0.05500208490317868
I0414 23:57:50.704141 31272 trainer.py:139] Epoch[481/1500] loss: 0.05576688123326148
I0414 23:57:55.647603 31272 trainer.py:139] Epoch[482/1500] loss: 0.05456725063343202
I0414 23:58:01.758161 31272 trainer.py:139] Epoch[483/1500] loss: 0.057294249053924315
I0414 23:58:06.525213 31272 trainer.py:139] Epoch[484/1500] loss: 0.055500163306151665
I0414 23:58:10.972335 31272 trainer.py:139] Epoch[485/1500] loss: 0.05509740727082375
I0414 23:58:15.810150 31272 trainer.py:139] Epoch[486/1500] loss: 0.05434059880433544
I0414 23:58:20.454614 31272 trainer.py:139] Epoch[487/1500] loss: 0.05493821167657452
I0414 23:58:26.803373 31272 trainer.py:139] Epoch[488/1500] loss: 0.05392940702938264
I0414 23:58:31.510626 31272 trainer.py:139] Epoch[489/1500] loss: 0.054092231296723886
I0414 23:58:36.220869 31272 trainer.py:139] Epoch[490/1500] loss: 0.05482646666707531
I0414 23:58:40.734767 31272 trainer.py:139] Epoch[491/1500] loss: 0.055378667529552214
I0414 23:58:45.501819 31272 trainer.py:139] Epoch[492/1500] loss: 0.054618620704258644
I0414 23:58:51.689120 31272 trainer.py:139] Epoch[493/1500] loss: 0.05534541102186326
I0414 23:58:56.323616 31272 trainer.py:139] Epoch[494/1500] loss: 0.05549291653498527
I0414 23:59:01.140503 31272 trainer.py:139] Epoch[495/1500] loss: 0.05277091144554077
I0414 23:59:05.863700 31272 trainer.py:139] Epoch[496/1500] loss: 0.05404416772146379
I0414 23:59:10.612813 31272 trainer.py:139] Epoch[497/1500] loss: 0.05377380982522042
I0414 23:59:16.493093 31272 trainer.py:139] Epoch[498/1500] loss: 0.054467388939472935
I0414 23:59:21.188384 31272 trainer.py:139] Epoch[499/1500] loss: 0.05345593464951361
I0414 23:59:21.443531 31272 trainer.py:145] Test: {'precision': 0.13892761394101885, 'recall': 0.3289953651458148, 'hit_ratio': 0.8954423592493298, 'ndcg': 0.310023606511744}
I0414 23:59:26.048127 31272 trainer.py:139] Epoch[500/1500] loss: 0.05359117242117082
I0414 23:59:30.900892 31272 trainer.py:139] Epoch[501/1500] loss: 0.05529248570242236
I0414 23:59:35.727744 31272 trainer.py:139] Epoch[502/1500] loss: 0.05405297154380429
I0414 23:59:41.544287 31272 trainer.py:139] Epoch[503/1500] loss: 0.05470597059015305
I0414 23:59:46.150874 31272 trainer.py:139] Epoch[504/1500] loss: 0.05428423720502084
I0414 23:59:50.712613 31272 trainer.py:139] Epoch[505/1500] loss: 0.05469794475263165
I0414 23:59:55.484649 31272 trainer.py:139] Epoch[506/1500] loss: 0.05518324781329401
I0415 00:00:00.229774 31272 trainer.py:139] Epoch[507/1500] loss: 0.054925310755929636
I0415 00:00:06.489832 31272 trainer.py:139] Epoch[508/1500] loss: 0.05421274335634324
I0415 00:00:11.088448 31272 trainer.py:139] Epoch[509/1500] loss: 0.05445031761642425
I0415 00:00:15.699023 31272 trainer.py:139] Epoch[510/1500] loss: 0.05454324954940427
I0415 00:00:20.539829 31272 trainer.py:139] Epoch[511/1500] loss: 0.0545014988991522
I0415 00:00:25.270004 31272 trainer.py:139] Epoch[512/1500] loss: 0.05350940890850559
I0415 00:00:31.435884 31272 trainer.py:139] Epoch[513/1500] loss: 0.0539043937479296
I0415 00:00:36.165063 31272 trainer.py:139] Epoch[514/1500] loss: 0.05414155786556582
I0415 00:00:40.720283 31272 trainer.py:139] Epoch[515/1500] loss: 0.05370187843518873
I0415 00:00:45.365741 31272 trainer.py:139] Epoch[516/1500] loss: 0.05350292293775466
I0415 00:00:49.923494 31272 trainer.py:139] Epoch[517/1500] loss: 0.05529859001117368
I0415 00:00:56.302156 31272 trainer.py:139] Epoch[518/1500] loss: 0.053984600810274
I0415 00:01:01.018377 31272 trainer.py:139] Epoch[519/1500] loss: 0.05385756168153978
I0415 00:01:05.635930 31272 trainer.py:139] Epoch[520/1500] loss: 0.053848123718653954
I0415 00:01:10.173749 31272 trainer.py:139] Epoch[521/1500] loss: 0.054543508997847955
I0415 00:01:14.891400 31272 trainer.py:139] Epoch[522/1500] loss: 0.05284553333636253
I0415 00:01:21.270540 31272 trainer.py:139] Epoch[523/1500] loss: 0.054357080449981075
I0415 00:01:25.996730 31272 trainer.py:139] Epoch[524/1500] loss: 0.053573390769381675
I0415 00:01:30.660129 31272 trainer.py:139] Epoch[525/1500] loss: 0.053453443992522456
I0415 00:01:35.464057 31272 trainer.py:139] Epoch[526/1500] loss: 0.05407188099718863
I0415 00:01:39.988919 31272 trainer.py:139] Epoch[527/1500] loss: 0.05379054406958242
I0415 00:01:46.337681 31272 trainer.py:139] Epoch[528/1500] loss: 0.052841894809276826
I0415 00:01:51.175496 31272 trainer.py:139] Epoch[529/1500] loss: 0.05363758833658311
I0415 00:01:55.624612 31272 trainer.py:139] Epoch[530/1500] loss: 0.05353293940424919
I0415 00:02:00.255123 31272 trainer.py:139] Epoch[531/1500] loss: 0.053506608211225076
I0415 00:02:04.675334 31272 trainer.py:139] Epoch[532/1500] loss: 0.053922914809757666
I0415 00:02:11.052001 31272 trainer.py:139] Epoch[533/1500] loss: 0.052816782507204244
I0415 00:02:15.879850 31272 trainer.py:139] Epoch[534/1500] loss: 0.05499615207795174
I0415 00:02:20.419661 31272 trainer.py:139] Epoch[535/1500] loss: 0.052796128536424326
I0415 00:02:24.984390 31272 trainer.py:139] Epoch[536/1500] loss: 0.053539698402727806
I0415 00:02:29.644801 31272 trainer.py:139] Epoch[537/1500] loss: 0.05400268048528702
I0415 00:02:35.727916 31272 trainer.py:139] Epoch[538/1500] loss: 0.05329865073004077
I0415 00:02:40.115238 31272 trainer.py:139] Epoch[539/1500] loss: 0.0541974296492915
I0415 00:02:44.712832 31272 trainer.py:139] Epoch[540/1500] loss: 0.053151203499686335
I0415 00:02:49.546661 31272 trainer.py:139] Epoch[541/1500] loss: 0.05372203417843388
I0415 00:02:54.081491 31272 trainer.py:139] Epoch[542/1500] loss: 0.05421347074931668
I0415 00:03:00.366465 31272 trainer.py:139] Epoch[543/1500] loss: 0.051839558708090934
I0415 00:03:05.091657 31272 trainer.py:139] Epoch[544/1500] loss: 0.054726504750790134
I0415 00:03:09.730139 31272 trainer.py:139] Epoch[545/1500] loss: 0.05254323047495658
I0415 00:03:14.338722 31272 trainer.py:139] Epoch[546/1500] loss: 0.05286382379070405
I0415 00:03:18.850627 31272 trainer.py:139] Epoch[547/1500] loss: 0.05350005302217699
I0415 00:03:24.884441 31272 trainer.py:139] Epoch[548/1500] loss: 0.05280291120852194
I0415 00:03:29.463123 31272 trainer.py:139] Epoch[549/1500] loss: 0.0533527574471889
I0415 00:03:29.721261 31272 trainer.py:145] Test: {'precision': 0.13935656836461133, 'recall': 0.3303051887746732, 'hit_ratio': 0.8949061662198391, 'ndcg': 0.310348592944949}
I0415 00:03:34.327850 31272 trainer.py:139] Epoch[550/1500] loss: 0.052126634265145945
I0415 00:03:38.984272 31272 trainer.py:139] Epoch[551/1500] loss: 0.054057215730990135
I0415 00:03:43.767272 31272 trainer.py:139] Epoch[552/1500] loss: 0.052999978704798605
I0415 00:03:49.601751 31272 trainer.py:139] Epoch[553/1500] loss: 0.05372959207142553
I0415 00:03:54.192394 31272 trainer.py:139] Epoch[554/1500] loss: 0.05219740937313726
I0415 00:03:58.811939 31272 trainer.py:139] Epoch[555/1500] loss: 0.054009062868933526
I0415 00:04:03.575005 31272 trainer.py:139] Epoch[556/1500] loss: 0.053456320877998106
I0415 00:04:08.390894 31272 trainer.py:139] Epoch[557/1500] loss: 0.05309776877683978
I0415 00:04:14.622047 31272 trainer.py:139] Epoch[558/1500] loss: 0.05243755877017975
I0415 00:04:19.242590 31272 trainer.py:139] Epoch[559/1500] loss: 0.05264992723541875
I0415 00:04:23.814297 31272 trainer.py:139] Epoch[560/1500] loss: 0.051992041930075616
I0415 00:04:28.378029 31272 trainer.py:139] Epoch[561/1500] loss: 0.05376602228610746
I0415 00:04:33.434114 31272 trainer.py:139] Epoch[562/1500] loss: 0.053618372568199714
I0415 00:04:39.353312 31272 trainer.py:139] Epoch[563/1500] loss: 0.05140381955331372
I0415 00:04:44.190130 31272 trainer.py:139] Epoch[564/1500] loss: 0.0531844604880579
I0415 00:04:48.617320 31272 trainer.py:139] Epoch[565/1500] loss: 0.05229844405285774
I0415 00:04:53.477063 31272 trainer.py:139] Epoch[566/1500] loss: 0.051981139567590526
I0415 00:04:58.128502 31272 trainer.py:139] Epoch[567/1500] loss: 0.05216233600531855
I0415 00:05:04.233079 31272 trainer.py:139] Epoch[568/1500] loss: 0.05252825901392968
I0415 00:05:08.816176 31272 trainer.py:139] Epoch[569/1500] loss: 0.053181075521053806
I0415 00:05:13.545355 31272 trainer.py:139] Epoch[570/1500] loss: 0.05216813568145998
I0415 00:05:18.139983 31272 trainer.py:139] Epoch[571/1500] loss: 0.05283401437824772
I0415 00:05:22.700727 31272 trainer.py:139] Epoch[572/1500] loss: 0.05292895604525843
I0415 00:05:28.870086 31272 trainer.py:139] Epoch[573/1500] loss: 0.052949572042111426
I0415 00:05:33.378005 31272 trainer.py:139] Epoch[574/1500] loss: 0.05137887561032849
I0415 00:05:38.220806 31272 trainer.py:139] Epoch[575/1500] loss: 0.05267514456664362
I0415 00:05:42.716763 31272 trainer.py:139] Epoch[576/1500] loss: 0.05315377274828573
I0415 00:05:47.372189 31272 trainer.py:139] Epoch[577/1500] loss: 0.052917607489132115
I0415 00:05:53.765799 31272 trainer.py:139] Epoch[578/1500] loss: 0.05310407665468032
I0415 00:05:58.386342 31272 trainer.py:139] Epoch[579/1500] loss: 0.05199740370435099
I0415 00:06:03.060704 31272 trainer.py:139] Epoch[580/1500] loss: 0.05254487669275653
I0415 00:06:07.795863 31272 trainer.py:139] Epoch[581/1500] loss: 0.05225922467727815
I0415 00:06:12.493149 31272 trainer.py:139] Epoch[582/1500] loss: 0.05188536848272047
I0415 00:06:18.936071 31272 trainer.py:139] Epoch[583/1500] loss: 0.05256705526863375
I0415 00:06:23.563591 31272 trainer.py:139] Epoch[584/1500] loss: 0.05233395436117726
I0415 00:06:28.267853 31272 trainer.py:139] Epoch[585/1500] loss: 0.053332459421888474
I0415 00:06:32.858495 31272 trainer.py:139] Epoch[586/1500] loss: 0.0508824068932764
I0415 00:06:37.591662 31272 trainer.py:139] Epoch[587/1500] loss: 0.05188025750460163
I0415 00:06:43.720158 31272 trainer.py:139] Epoch[588/1500] loss: 0.05233711376786232
I0415 00:06:48.226085 31272 trainer.py:139] Epoch[589/1500] loss: 0.05081638129007432
I0415 00:06:52.760914 31272 trainer.py:139] Epoch[590/1500] loss: 0.051994442098563715
I0415 00:06:57.389430 31272 trainer.py:139] Epoch[591/1500] loss: 0.05327639512477383
I0415 00:07:02.018942 31272 trainer.py:139] Epoch[592/1500] loss: 0.051918215568988554
I0415 00:07:08.341789 31272 trainer.py:139] Epoch[593/1500] loss: 0.05278262520028699
I0415 00:07:12.949823 31272 trainer.py:139] Epoch[594/1500] loss: 0.051821153971456715
I0415 00:07:17.501596 31272 trainer.py:139] Epoch[595/1500] loss: 0.051656830094514355
I0415 00:07:22.217818 31272 trainer.py:139] Epoch[596/1500] loss: 0.052744020978289265
I0415 00:07:26.786536 31272 trainer.py:139] Epoch[597/1500] loss: 0.05188106757498557
I0415 00:07:32.932008 31272 trainer.py:139] Epoch[598/1500] loss: 0.05247050235348363
I0415 00:07:37.530550 31272 trainer.py:139] Epoch[599/1500] loss: 0.05235332707243581
I0415 00:07:37.800156 31272 trainer.py:145] Test: {'precision': 0.13951742627345853, 'recall': 0.3310444562096512, 'hit_ratio': 0.8975871313672922, 'ndcg': 0.3118437189415975}
I0415 00:07:42.593122 31272 trainer.py:139] Epoch[600/1500] loss: 0.051616733232813496
I0415 00:07:47.360174 31272 trainer.py:139] Epoch[601/1500] loss: 0.05139480747522846
I0415 00:07:52.032543 31272 trainer.py:139] Epoch[602/1500] loss: 0.052699199847636685
I0415 00:07:58.155060 31272 trainer.py:139] Epoch[603/1500] loss: 0.05231686320997054
I0415 00:08:02.607166 31272 trainer.py:139] Epoch[604/1500] loss: 0.053481960248562596
I0415 00:08:07.311427 31272 trainer.py:139] Epoch[605/1500] loss: 0.05225418484018695
I0415 00:08:11.932966 31272 trainer.py:139] Epoch[606/1500] loss: 0.05204581505348606
I0415 00:08:16.779729 31272 trainer.py:139] Epoch[607/1500] loss: 0.05219638696120631
I0415 00:08:22.638129 31272 trainer.py:139] Epoch[608/1500] loss: 0.05167001173380883
I0415 00:08:27.352357 31272 trainer.py:139] Epoch[609/1500] loss: 0.051177024360625975
I0415 00:08:32.192166 31272 trainer.py:139] Epoch[610/1500] loss: 0.052035452377411626
I0415 00:08:36.558558 31272 trainer.py:139] Epoch[611/1500] loss: 0.05054171371363824
I0415 00:08:41.745208 31272 trainer.py:139] Epoch[612/1500] loss: 0.051922286830602155
I0415 00:08:47.160093 31272 trainer.py:139] Epoch[613/1500] loss: 0.05037219678201983
I0415 00:08:51.923159 31272 trainer.py:139] Epoch[614/1500] loss: 0.05172474129546073
I0415 00:08:56.468950 31272 trainer.py:139] Epoch[615/1500] loss: 0.05231910487336497
I0415 00:09:01.277863 31272 trainer.py:139] Epoch[616/1500] loss: 0.050759657977088805
I0415 00:09:06.356872 31272 trainer.py:139] Epoch[617/1500] loss: 0.05291316910616813
I0415 00:09:11.874412 31272 trainer.py:139] Epoch[618/1500] loss: 0.05281849950551987
I0415 00:09:16.527845 31272 trainer.py:139] Epoch[619/1500] loss: 0.05039238352929392
I0415 00:09:21.129452 31272 trainer.py:139] Epoch[620/1500] loss: 0.052073289309778524
I0415 00:09:25.634380 31272 trainer.py:139] Epoch[621/1500] loss: 0.051635258981297096
I0415 00:09:31.232651 31272 trainer.py:139] Epoch[622/1500] loss: 0.05101782263767335
I0415 00:09:36.576772 31272 trainer.py:139] Epoch[623/1500] loss: 0.051356943624634895
I0415 00:09:41.269076 31272 trainer.py:139] Epoch[624/1500] loss: 0.05074774954588183
I0415 00:09:45.846761 31272 trainer.py:139] Epoch[625/1500] loss: 0.05028797974509577
I0415 00:09:50.507169 31272 trainer.py:139] Epoch[626/1500] loss: 0.051977061576420264
I0415 00:09:55.432692 31272 trainer.py:139] Epoch[627/1500] loss: 0.05185930394837933
I0415 00:10:01.221326 31272 trainer.py:139] Epoch[628/1500] loss: 0.05120236847189165
I0415 00:10:05.856820 31272 trainer.py:139] Epoch[629/1500] loss: 0.05126845596298095
I0415 00:10:10.541149 31272 trainer.py:139] Epoch[630/1500] loss: 0.05113140205221792
I0415 00:10:15.025146 31272 trainer.py:139] Epoch[631/1500] loss: 0.052395215678599574
I0415 00:10:20.439036 31272 trainer.py:139] Epoch[632/1500] loss: 0.049643951918809645
I0415 00:10:25.668540 31272 trainer.py:139] Epoch[633/1500] loss: 0.05117549554955575
I0415 00:10:30.342903 31272 trainer.py:139] Epoch[634/1500] loss: 0.050887697526524146
I0415 00:10:34.852815 31272 trainer.py:139] Epoch[635/1500] loss: 0.052616355279760975
I0415 00:10:39.496280 31272 trainer.py:139] Epoch[636/1500] loss: 0.05248202047040386
I0415 00:10:45.472289 31272 trainer.py:139] Epoch[637/1500] loss: 0.051959019394651536
I0415 00:10:50.260725 31272 trainer.py:139] Epoch[638/1500] loss: 0.05148212215112102
I0415 00:10:54.831434 31272 trainer.py:139] Epoch[639/1500] loss: 0.05032203094132485
I0415 00:10:59.359286 31272 trainer.py:139] Epoch[640/1500] loss: 0.05151864669976696
I0415 00:11:04.013716 31272 trainer.py:139] Epoch[641/1500] loss: 0.05061443210128815
I0415 00:11:09.972780 31272 trainer.py:139] Epoch[642/1500] loss: 0.052061656790394935
I0415 00:11:14.860428 31272 trainer.py:139] Epoch[643/1500] loss: 0.05114490442699002
I0415 00:11:19.239778 31272 trainer.py:139] Epoch[644/1500] loss: 0.050711809266959465
I0415 00:11:23.844375 31272 trainer.py:139] Epoch[645/1500] loss: 0.05103178959219686
I0415 00:11:28.345316 31272 trainer.py:139] Epoch[646/1500] loss: 0.05178888490603816
I0415 00:11:34.590425 31272 trainer.py:139] Epoch[647/1500] loss: 0.051870740829936916
I0415 00:11:39.554816 31272 trainer.py:139] Epoch[648/1500] loss: 0.051032786527948994
I0415 00:11:44.057751 31272 trainer.py:139] Epoch[649/1500] loss: 0.05176828224812784
I0415 00:11:44.306917 31272 trainer.py:145] Test: {'precision': 0.13943699731903492, 'recall': 0.3301127583275511, 'hit_ratio': 0.8959785522788204, 'ndcg': 0.31148957351258777}
I0415 00:11:48.967327 31272 trainer.py:139] Epoch[650/1500] loss: 0.05171839904881293
I0415 00:11:53.551989 31272 trainer.py:139] Epoch[651/1500] loss: 0.05134202840347444
I0415 00:11:59.952577 31272 trainer.py:139] Epoch[652/1500] loss: 0.05003563747290642
I0415 00:12:04.431593 31272 trainer.py:139] Epoch[653/1500] loss: 0.05122689686475262
I0415 00:12:09.017251 31272 trainer.py:139] Epoch[654/1500] loss: 0.051165077955492085
I0415 00:12:13.458394 31272 trainer.py:139] Epoch[655/1500] loss: 0.05174068205298916
I0415 00:12:18.128771 31272 trainer.py:139] Epoch[656/1500] loss: 0.04992082955375794
I0415 00:12:23.896474 31272 trainer.py:139] Epoch[657/1500] loss: 0.050733121412415656
I0415 00:12:29.005383 31272 trainer.py:139] Epoch[658/1500] loss: 0.04992749469895517
I0415 00:12:33.539216 31272 trainer.py:139] Epoch[659/1500] loss: 0.04971287014984315
I0415 00:12:38.009261 31272 trainer.py:139] Epoch[660/1500] loss: 0.050672014874796716
I0415 00:12:42.541100 31272 trainer.py:139] Epoch[661/1500] loss: 0.05083931189390921
I0415 00:12:48.195186 31272 trainer.py:139] Epoch[662/1500] loss: 0.05269374482093319
I0415 00:12:53.379840 31272 trainer.py:139] Epoch[663/1500] loss: 0.050704515028384425
I0415 00:12:57.998390 31272 trainer.py:139] Epoch[664/1500] loss: 0.05084035833997111
I0415 00:13:02.648832 31272 trainer.py:139] Epoch[665/1500] loss: 0.05055857678094218
I0415 00:13:07.253427 31272 trainer.py:139] Epoch[666/1500] loss: 0.051090915116571614
I0415 00:13:13.050038 31272 trainer.py:139] Epoch[667/1500] loss: 0.050531366779919595
I0415 00:13:18.115090 31272 trainer.py:139] Epoch[668/1500] loss: 0.0510537113633848
I0415 00:13:22.821347 31272 trainer.py:139] Epoch[669/1500] loss: 0.0499704125667772
I0415 00:13:27.703015 31272 trainer.py:139] Epoch[670/1500] loss: 0.05023696393735947
I0415 00:13:32.353458 31272 trainer.py:139] Epoch[671/1500] loss: 0.05072318353960591
I0415 00:13:37.870004 31272 trainer.py:139] Epoch[672/1500] loss: 0.05075658725634698
I0415 00:13:43.338630 31272 trainer.py:139] Epoch[673/1500] loss: 0.05171688573975717
I0415 00:13:48.127754 31272 trainer.py:139] Epoch[674/1500] loss: 0.05084146787562678
I0415 00:13:52.705440 31272 trainer.py:139] Epoch[675/1500] loss: 0.05055247090997234
I0415 00:13:57.165520 31272 trainer.py:139] Epoch[676/1500] loss: 0.05024090493398328
I0415 00:14:01.770116 31272 trainer.py:139] Epoch[677/1500] loss: 0.050900212459025845
I0415 00:14:08.185653 31272 trainer.py:139] Epoch[678/1500] loss: 0.05145478633142287
I0415 00:14:12.725464 31272 trainer.py:139] Epoch[679/1500] loss: 0.05009579466235253
I0415 00:14:17.333051 31272 trainer.py:139] Epoch[680/1500] loss: 0.05038794730940173
I0415 00:14:22.161898 31272 trainer.py:139] Epoch[681/1500] loss: 0.05011849261579975
I0415 00:14:26.613005 31272 trainer.py:139] Epoch[682/1500] loss: 0.051030735455213055
I0415 00:14:32.822233 31272 trainer.py:139] Epoch[683/1500] loss: 0.05061431024824419
I0415 00:14:37.350085 31272 trainer.py:139] Epoch[684/1500] loss: 0.04981434164989379
I0415 00:14:42.028435 31272 trainer.py:139] Epoch[685/1500] loss: 0.05119831042905008
I0415 00:14:46.567250 31272 trainer.py:139] Epoch[686/1500] loss: 0.0502608175719938
I0415 00:14:51.067196 31272 trainer.py:139] Epoch[687/1500] loss: 0.0506162375452057
I0415 00:14:56.503013 31272 trainer.py:139] Epoch[688/1500] loss: 0.050135927334908514
I0415 00:15:02.235832 31272 trainer.py:139] Epoch[689/1500] loss: 0.05103433396547071
I0415 00:15:06.777638 31272 trainer.py:139] Epoch[690/1500] loss: 0.051300108913452394
I0415 00:15:11.327418 31272 trainer.py:139] Epoch[691/1500] loss: 0.051393637133221474
I0415 00:15:15.975866 31272 trainer.py:139] Epoch[692/1500] loss: 0.050397805629238006
I0415 00:15:20.587438 31272 trainer.py:139] Epoch[693/1500] loss: 0.04974216102592407
I0415 00:15:26.914272 31272 trainer.py:139] Epoch[694/1500] loss: 0.05092961905944732
I0415 00:15:31.565712 31272 trainer.py:139] Epoch[695/1500] loss: 0.05154816734213983
I0415 00:15:36.171305 31272 trainer.py:139] Epoch[696/1500] loss: 0.049957825291541316
I0415 00:15:40.731050 31272 trainer.py:139] Epoch[697/1500] loss: 0.05033577545996635
I0415 00:15:45.434316 31272 trainer.py:139] Epoch[698/1500] loss: 0.050294691997189674
I0415 00:15:51.630057 31272 trainer.py:139] Epoch[699/1500] loss: 0.05107408209193137
I0415 00:15:51.881217 31272 trainer.py:145] Test: {'precision': 0.140804289544236, 'recall': 0.334076125472593, 'hit_ratio': 0.896514745308311, 'ndcg': 0.3128797606391251}
I0415 00:15:56.499766 31272 trainer.py:139] Epoch[700/1500] loss: 0.05169082481053568
I0415 00:16:01.135258 31272 trainer.py:139] Epoch[701/1500] loss: 0.049351510261335683
I0415 00:16:05.608295 31272 trainer.py:139] Epoch[702/1500] loss: 0.05060341713889953
I0415 00:16:10.174020 31272 trainer.py:139] Epoch[703/1500] loss: 0.04931383207440376
I0415 00:16:15.505185 31272 trainer.py:139] Epoch[704/1500] loss: 0.05003450186021866
I0415 00:16:21.003791 31272 trainer.py:139] Epoch[705/1500] loss: 0.0502191225607549
I0415 00:16:25.638285 31272 trainer.py:139] Epoch[706/1500] loss: 0.049581483727501284
I0415 00:16:30.266802 31272 trainer.py:139] Epoch[707/1500] loss: 0.04930998072508843
I0415 00:16:34.967078 31272 trainer.py:139] Epoch[708/1500] loss: 0.04880952835083008
I0415 00:16:39.877650 31272 trainer.py:139] Epoch[709/1500] loss: 0.050158718060101234
I0415 00:16:46.087901 31272 trainer.py:139] Epoch[710/1500] loss: 0.050444689008497426
I0415 00:16:50.997476 31272 trainer.py:139] Epoch[711/1500] loss: 0.05081846637110556
I0415 00:16:55.691773 31272 trainer.py:139] Epoch[712/1500] loss: 0.04970758768819993
I0415 00:17:00.239559 31272 trainer.py:139] Epoch[713/1500] loss: 0.04966771734818336
I0415 00:17:05.304614 31272 trainer.py:139] Epoch[714/1500] loss: 0.05070158286440757
I0415 00:17:10.971144 31272 trainer.py:139] Epoch[715/1500] loss: 0.0500223177575296
I0415 00:17:15.754143 31272 trainer.py:139] Epoch[716/1500] loss: 0.05047361144135075
I0415 00:17:20.378673 31272 trainer.py:139] Epoch[717/1500] loss: 0.05125637064057012
I0415 00:17:25.212501 31272 trainer.py:139] Epoch[718/1500] loss: 0.049278554416471915
I0415 00:17:30.027393 31272 trainer.py:139] Epoch[719/1500] loss: 0.049943762200493964
I0415 00:17:35.988450 31272 trainer.py:139] Epoch[720/1500] loss: 0.05131788323483159
I0415 00:17:40.740553 31272 trainer.py:139] Epoch[721/1500] loss: 0.048590756472079985
I0415 00:17:45.275381 31272 trainer.py:139] Epoch[722/1500] loss: 0.05021878103575399
I0415 00:17:50.082300 31272 trainer.py:139] Epoch[723/1500] loss: 0.05082599530296941
I0415 00:17:54.637063 31272 trainer.py:139] Epoch[724/1500] loss: 0.04936589168444756
I0415 00:18:00.952934 31272 trainer.py:139] Epoch[725/1500] loss: 0.049564377795304024
I0415 00:18:05.406037 31272 trainer.py:139] Epoch[726/1500] loss: 0.049871490246826605
I0415 00:18:09.812295 31272 trainer.py:139] Epoch[727/1500] loss: 0.04965130744441863
I0415 00:18:14.529515 31272 trainer.py:139] Epoch[728/1500] loss: 0.05069650264997636
I0415 00:18:19.186934 31272 trainer.py:139] Epoch[729/1500] loss: 0.049747589735254165
I0415 00:18:24.478232 31272 trainer.py:139] Epoch[730/1500] loss: 0.050028504743691415
I0415 00:18:30.114377 31272 trainer.py:139] Epoch[731/1500] loss: 0.049029564785380515
I0415 00:18:34.687079 31272 trainer.py:139] Epoch[732/1500] loss: 0.04859480946775405
I0415 00:18:39.250812 31272 trainer.py:139] Epoch[733/1500] loss: 0.049404380422446034
I0415 00:18:43.888298 31272 trainer.py:139] Epoch[734/1500] loss: 0.04995860760250399
I0415 00:18:48.468975 31272 trainer.py:139] Epoch[735/1500] loss: 0.04968188114223942
I0415 00:18:54.744977 31272 trainer.py:139] Epoch[736/1500] loss: 0.0491410004756143
I0415 00:18:59.499073 31272 trainer.py:139] Epoch[737/1500] loss: 0.049391087865637194
I0415 00:19:03.965132 31272 trainer.py:139] Epoch[738/1500] loss: 0.04903900743492188
I0415 00:19:08.823877 31272 trainer.py:139] Epoch[739/1500] loss: 0.04975963107520534
I0415 00:19:13.435450 31272 trainer.py:139] Epoch[740/1500] loss: 0.049485300216943987
I0415 00:19:19.303964 31272 trainer.py:139] Epoch[741/1500] loss: 0.0494712988936132
I0415 00:19:24.294269 31272 trainer.py:139] Epoch[742/1500] loss: 0.04954432876360032
I0415 00:19:28.964567 31272 trainer.py:139] Epoch[743/1500] loss: 0.049689666758621895
I0415 00:19:33.747609 31272 trainer.py:139] Epoch[744/1500] loss: 0.04983631869958293
I0415 00:19:38.236752 31272 trainer.py:139] Epoch[745/1500] loss: 0.049308361665856455
I0415 00:19:44.096143 31272 trainer.py:139] Epoch[746/1500] loss: 0.04914881325056476
I0415 00:19:49.117342 31272 trainer.py:139] Epoch[747/1500] loss: 0.04942213719890964
I0415 00:19:53.961138 31272 trainer.py:139] Epoch[748/1500] loss: 0.049103979982676044
I0415 00:19:58.735167 31272 trainer.py:139] Epoch[749/1500] loss: 0.04951161314402857
I0415 00:19:58.991310 31272 trainer.py:145] Test: {'precision': 0.14018766756032178, 'recall': 0.33335316158372474, 'hit_ratio': 0.900804289544236, 'ndcg': 0.31293232102703106}
I0415 00:20:03.819159 31272 trainer.py:139] Epoch[750/1500] loss: 0.050027645884021636
I0415 00:20:09.063638 31272 trainer.py:139] Epoch[751/1500] loss: 0.0486395105479225
I0415 00:20:14.708751 31272 trainer.py:139] Epoch[752/1500] loss: 0.04945862990233206
I0415 00:20:19.146904 31272 trainer.py:139] Epoch[753/1500] loss: 0.04888502844879704
I0415 00:20:23.853091 31272 trainer.py:139] Epoch[754/1500] loss: 0.04849456551094209
I0415 00:20:28.526964 31272 trainer.py:139] Epoch[755/1500] loss: 0.04904021971648739
I0415 00:20:33.646836 31272 trainer.py:139] Epoch[756/1500] loss: 0.04893095827391071
I0415 00:20:39.271020 31272 trainer.py:139] Epoch[757/1500] loss: 0.05028538033366203
I0415 00:20:43.872626 31272 trainer.py:139] Epoch[758/1500] loss: 0.05068917536447125
I0415 00:20:48.487189 31272 trainer.py:139] Epoch[759/1500] loss: 0.04754839104510123
I0415 00:20:53.152580 31272 trainer.py:139] Epoch[760/1500] loss: 0.04981898985082103
I0415 00:20:57.839355 31272 trainer.py:139] Epoch[761/1500] loss: 0.048898999008440205
I0415 00:21:04.045592 31272 trainer.py:139] Epoch[762/1500] loss: 0.04878041568783022
I0415 00:21:08.530587 31272 trainer.py:139] Epoch[763/1500] loss: 0.049449564828988046
I0415 00:21:13.089336 31272 trainer.py:139] Epoch[764/1500] loss: 0.04955285643377612
I0415 00:21:17.698916 31272 trainer.py:139] Epoch[765/1500] loss: 0.04816632537591842
I0415 00:21:22.121122 31272 trainer.py:139] Epoch[766/1500] loss: 0.0489275278823991
I0415 00:21:27.818064 31272 trainer.py:139] Epoch[767/1500] loss: 0.04987650568927488
I0415 00:21:32.789431 31272 trainer.py:139] Epoch[768/1500] loss: 0.0495902540222291
I0415 00:21:37.631233 31272 trainer.py:139] Epoch[769/1500] loss: 0.04940455995740429
I0415 00:21:42.253770 31272 trainer.py:139] Epoch[770/1500] loss: 0.04861662404671792
I0415 00:21:46.825475 31272 trainer.py:139] Epoch[771/1500] loss: 0.04985637902732818
I0415 00:21:52.476570 31272 trainer.py:139] Epoch[772/1500] loss: 0.04950226615032842
I0415 00:21:57.716042 31272 trainer.py:139] Epoch[773/1500] loss: 0.04914179167920543
I0415 00:22:02.228944 31272 trainer.py:139] Epoch[774/1500] loss: 0.048516554577696706
I0415 00:22:07.017285 31272 trainer.py:139] Epoch[775/1500] loss: 0.04876492376769743
I0415 00:22:11.649787 31272 trainer.py:139] Epoch[776/1500] loss: 0.049018367403937925
I0415 00:22:16.237440 31272 trainer.py:139] Epoch[777/1500] loss: 0.04772696680118961
I0415 00:22:22.546334 31272 trainer.py:139] Epoch[778/1500] loss: 0.05046855862582884
I0415 00:22:27.258570 31272 trainer.py:139] Epoch[779/1500] loss: 0.05005102075876728
I0415 00:22:31.869145 31272 trainer.py:139] Epoch[780/1500] loss: 0.04912684281026163
I0415 00:22:36.346167 31272 trainer.py:139] Epoch[781/1500] loss: 0.048341153249625235
I0415 00:22:41.121193 31272 trainer.py:139] Epoch[782/1500] loss: 0.049006133550597776
I0415 00:22:46.297353 31272 trainer.py:139] Epoch[783/1500] loss: 0.048192054994644656
I0415 00:22:51.928514 31272 trainer.py:139] Epoch[784/1500] loss: 0.04718854867162243
I0415 00:22:56.620816 31272 trainer.py:139] Epoch[785/1500] loss: 0.0498044153134669
I0415 00:23:01.478566 31272 trainer.py:139] Epoch[786/1500] loss: 0.048273735229046114
I0415 00:23:06.102530 31272 trainer.py:139] Epoch[787/1500] loss: 0.04930836983746098
I0415 00:23:10.876559 31272 trainer.py:139] Epoch[788/1500] loss: 0.0495095299857278
I0415 00:23:17.198408 31272 trainer.py:139] Epoch[789/1500] loss: 0.049947184059889085
I0415 00:23:21.980411 31272 trainer.py:139] Epoch[790/1500] loss: 0.04947787967901076
I0415 00:23:26.360756 31272 trainer.py:139] Epoch[791/1500] loss: 0.04969662367816894
I0415 00:23:31.075983 31272 trainer.py:139] Epoch[792/1500] loss: 0.04997212343638943
I0415 00:23:35.774821 31272 trainer.py:139] Epoch[793/1500] loss: 0.0483608148511379
I0415 00:23:41.214623 31272 trainer.py:139] Epoch[794/1500] loss: 0.048391127297955173
I0415 00:23:46.419211 31272 trainer.py:139] Epoch[795/1500] loss: 0.05037994538584063
I0415 00:23:51.100549 31272 trainer.py:139] Epoch[796/1500] loss: 0.049223828700280955
I0415 00:23:55.796839 31272 trainer.py:139] Epoch[797/1500] loss: 0.049261901046960585
I0415 00:24:00.498111 31272 trainer.py:139] Epoch[798/1500] loss: 0.04953583113608822
I0415 00:24:06.137246 31272 trainer.py:139] Epoch[799/1500] loss: 0.049377068757049496
I0415 00:24:06.526945 31272 trainer.py:145] Test: {'precision': 0.14008042895442363, 'recall': 0.332289748529695, 'hit_ratio': 0.9013404825737266, 'ndcg': 0.3131960485825042}
I0415 00:24:11.851130 31272 trainer.py:139] Epoch[800/1500] loss: 0.047596478293980324
I0415 00:24:16.705891 31272 trainer.py:139] Epoch[801/1500] loss: 0.04995675793578548
I0415 00:24:21.281589 31272 trainer.py:139] Epoch[802/1500] loss: 0.048533996627215414
I0415 00:24:25.991832 31272 trainer.py:139] Epoch[803/1500] loss: 0.04835288539048164
I0415 00:24:31.844255 31272 trainer.py:139] Epoch[804/1500] loss: 0.048703253749878175
I0415 00:24:37.153924 31272 trainer.py:139] Epoch[805/1500] loss: 0.04897607406300883
I0415 00:24:41.837682 31272 trainer.py:139] Epoch[806/1500] loss: 0.04887050137885155
I0415 00:24:46.486129 31272 trainer.py:139] Epoch[807/1500] loss: 0.04906451341605956
I0415 00:24:51.038899 31272 trainer.py:139] Epoch[808/1500] loss: 0.04833898705340201
I0415 00:24:55.798975 31272 trainer.py:139] Epoch[809/1500] loss: 0.04921342324345342
I0415 00:25:02.103882 31272 trainer.py:139] Epoch[810/1500] loss: 0.04899246473946879
I0415 00:25:06.798229 31272 trainer.py:139] Epoch[811/1500] loss: 0.048582468542360494
I0415 00:25:11.377908 31272 trainer.py:139] Epoch[812/1500] loss: 0.04948590671823871
I0415 00:25:16.007853 31272 trainer.py:139] Epoch[813/1500] loss: 0.04761252900765788
I0415 00:25:20.799824 31272 trainer.py:139] Epoch[814/1500] loss: 0.049411153721232566
I0415 00:25:26.808166 31272 trainer.py:139] Epoch[815/1500] loss: 0.0496737344130393
I0415 00:25:32.104447 31272 trainer.py:139] Epoch[816/1500] loss: 0.0497769363705189
I0415 00:25:36.893427 31272 trainer.py:139] Epoch[817/1500] loss: 0.04948924181442107
I0415 00:25:41.544866 31272 trainer.py:139] Epoch[818/1500] loss: 0.04864776807446634
I0415 00:25:46.362747 31272 trainer.py:139] Epoch[819/1500] loss: 0.048164886452497974
I0415 00:25:51.896237 31272 trainer.py:139] Epoch[820/1500] loss: 0.049063591947478634
I0415 00:25:57.107801 31272 trainer.py:139] Epoch[821/1500] loss: 0.04906748271276874
I0415 00:26:01.548943 31272 trainer.py:139] Epoch[822/1500] loss: 0.04818560663730868
I0415 00:26:06.150535 31272 trainer.py:139] Epoch[823/1500] loss: 0.04930356529451186
I0415 00:26:10.790014 31272 trainer.py:139] Epoch[824/1500] loss: 0.04885639214227276
I0415 00:26:16.140116 31272 trainer.py:139] Epoch[825/1500] loss: 0.04917386017980114
I0415 00:26:21.517127 31272 trainer.py:139] Epoch[826/1500] loss: 0.04842636866434928
I0415 00:26:26.363349 31272 trainer.py:139] Epoch[827/1500] loss: 0.04882613653617521
I0415 00:26:31.039704 31272 trainer.py:139] Epoch[828/1500] loss: 0.04984553410641609
I0415 00:26:35.774302 31272 trainer.py:139] Epoch[829/1500] loss: 0.050114392393058343
I0415 00:26:40.338038 31272 trainer.py:139] Epoch[830/1500] loss: 0.04867214084632935
I0415 00:26:46.438627 31272 trainer.py:139] Epoch[831/1500] loss: 0.04896916497138239
I0415 00:26:51.239566 31272 trainer.py:139] Epoch[832/1500] loss: 0.049101392948819746
I0415 00:26:55.833198 31272 trainer.py:139] Epoch[833/1500] loss: 0.0490103961238938
I0415 00:27:00.587293 31272 trainer.py:139] Epoch[834/1500] loss: 0.04873954913308544
I0415 00:27:05.133086 31272 trainer.py:139] Epoch[835/1500] loss: 0.0488288814742719
I0415 00:27:11.490022 31272 trainer.py:139] Epoch[836/1500] loss: 0.04888327780269807
I0415 00:27:15.949106 31272 trainer.py:139] Epoch[837/1500] loss: 0.04839914532438401
I0415 00:27:20.460016 31272 trainer.py:139] Epoch[838/1500] loss: 0.048542138910101305
I0415 00:27:25.166270 31272 trainer.py:139] Epoch[839/1500] loss: 0.048896820194298224
I0415 00:27:29.735435 31272 trainer.py:139] Epoch[840/1500] loss: 0.048001291410576914
I0415 00:27:35.560947 31272 trainer.py:139] Epoch[841/1500] loss: 0.04740723955535119
I0415 00:27:40.608061 31272 trainer.py:139] Epoch[842/1500] loss: 0.04792823510304574
I0415 00:27:45.259500 31272 trainer.py:139] Epoch[843/1500] loss: 0.04831303259538066
I0415 00:27:50.081370 31272 trainer.py:139] Epoch[844/1500] loss: 0.04825254721987632
I0415 00:27:54.688954 31272 trainer.py:139] Epoch[845/1500] loss: 0.04898140615513248
I0415 00:27:59.386579 31272 trainer.py:139] Epoch[846/1500] loss: 0.04843908776679347
I0415 00:28:05.707433 31272 trainer.py:139] Epoch[847/1500] loss: 0.04766712950602654
I0415 00:28:10.272162 31272 trainer.py:139] Epoch[848/1500] loss: 0.04835171480813334
I0415 00:28:14.892704 31272 trainer.py:139] Epoch[849/1500] loss: 0.04790717315289282
I0415 00:28:15.148847 31272 trainer.py:145] Test: {'precision': 0.1406702412868633, 'recall': 0.3336844661935342, 'hit_ratio': 0.900804289544236, 'ndcg': 0.31381825979090083}
I0415 00:28:19.783342 31272 trainer.py:139] Epoch[850/1500] loss: 0.047701969021751035
I0415 00:28:24.290265 31272 trainer.py:139] Epoch[851/1500] loss: 0.04821204886801781
I0415 00:28:30.521419 31272 trainer.py:139] Epoch[852/1500] loss: 0.0484391839033173
I0415 00:28:35.055674 31272 trainer.py:139] Epoch[853/1500] loss: 0.048580954512280804
I0415 00:28:39.755950 31272 trainer.py:139] Epoch[854/1500] loss: 0.04870418278921035
I0415 00:28:44.355565 31272 trainer.py:139] Epoch[855/1500] loss: 0.04883082667666097
I0415 00:28:48.883417 31272 trainer.py:139] Epoch[856/1500] loss: 0.04791523299870953
I0415 00:28:54.082025 31272 trainer.py:139] Epoch[857/1500] loss: 0.04823706130827627
I0415 00:28:59.704215 31272 trainer.py:139] Epoch[858/1500] loss: 0.046989110328497424
I0415 00:29:04.257982 31272 trainer.py:139] Epoch[859/1500] loss: 0.047975642666701346
I0415 00:29:09.090814 31272 trainer.py:139] Epoch[860/1500] loss: 0.04846568886310824
I0415 00:29:13.512022 31272 trainer.py:139] Epoch[861/1500] loss: 0.04798226791524118
I0415 00:29:18.317945 31272 trainer.py:139] Epoch[862/1500] loss: 0.04960340477766529
I0415 00:29:24.216708 31272 trainer.py:139] Epoch[863/1500] loss: 0.048210452641210245
I0415 00:29:28.730609 31272 trainer.py:139] Epoch[864/1500] loss: 0.048438839854732636
I0415 00:29:33.223578 31272 trainer.py:139] Epoch[865/1500] loss: 0.04696295350309341
I0415 00:29:37.885979 31272 trainer.py:139] Epoch[866/1500] loss: 0.04913922831896813
I0415 00:29:42.443732 31272 trainer.py:139] Epoch[867/1500] loss: 0.048483851696214365
I0415 00:29:48.767576 31272 trainer.py:139] Epoch[868/1500] loss: 0.04799045045529642
I0415 00:29:53.371175 31272 trainer.py:139] Epoch[869/1500] loss: 0.04797048169759012
I0415 00:29:58.078427 31272 trainer.py:139] Epoch[870/1500] loss: 0.047646248773221045
I0415 00:30:02.857440 31272 trainer.py:139] Epoch[871/1500] loss: 0.04816435085188958
I0415 00:30:07.570672 31272 trainer.py:139] Epoch[872/1500] loss: 0.04842970508240884
I0415 00:30:13.821760 31272 trainer.py:139] Epoch[873/1500] loss: 0.04737919148418211
I0415 00:30:18.720371 31272 trainer.py:139] Epoch[874/1500] loss: 0.048861385593491215
I0415 00:30:23.377792 31272 trainer.py:139] Epoch[875/1500] loss: 0.04791180909641327
I0415 00:30:28.075076 31272 trainer.py:139] Epoch[876/1500] loss: 0.04795888114360071
I0415 00:30:32.849106 31272 trainer.py:139] Epoch[877/1500] loss: 0.049325045078031475
I0415 00:30:37.586698 31272 trainer.py:139] Epoch[878/1500] loss: 0.0492050843613763
I0415 00:30:43.465030 31272 trainer.py:139] Epoch[879/1500] loss: 0.04793777521098814
I0415 00:30:48.238062 31272 trainer.py:139] Epoch[880/1500] loss: 0.04833996247860693
I0415 00:30:53.034455 31272 trainer.py:139] Epoch[881/1500] loss: 0.0479579274692843
I0415 00:30:57.569284 31272 trainer.py:139] Epoch[882/1500] loss: 0.0481266773516132
I0415 00:31:02.248050 31272 trainer.py:139] Epoch[883/1500] loss: 0.04865937848244944
I0415 00:31:08.354623 31272 trainer.py:139] Epoch[884/1500] loss: 0.04780828760516259
I0415 00:31:13.205395 31272 trainer.py:139] Epoch[885/1500] loss: 0.04834685042019813
I0415 00:31:17.894143 31272 trainer.py:139] Epoch[886/1500] loss: 0.0480695478618145
I0415 00:31:22.429403 31272 trainer.py:139] Epoch[887/1500] loss: 0.04760340481035171
I0415 00:31:27.107753 31272 trainer.py:139] Epoch[888/1500] loss: 0.048004661836931785
I0415 00:31:31.893743 31272 trainer.py:139] Epoch[889/1500] loss: 0.046379623634199944
I0415 00:31:38.381039 31272 trainer.py:139] Epoch[890/1500] loss: 0.04804615628334784
I0415 00:31:43.071347 31272 trainer.py:139] Epoch[891/1500] loss: 0.04770812440303064
I0415 00:31:47.987900 31272 trainer.py:139] Epoch[892/1500] loss: 0.047714044490168174
I0415 00:31:52.561022 31272 trainer.py:139] Epoch[893/1500] loss: 0.04717997473574454
I0415 00:31:57.219437 31272 trainer.py:139] Epoch[894/1500] loss: 0.04787508999147723
I0415 00:32:03.577658 31272 trainer.py:139] Epoch[895/1500] loss: 0.04848944588053611
I0415 00:32:08.064648 31272 trainer.py:139] Epoch[896/1500] loss: 0.0468587790045046
I0415 00:32:12.787847 31272 trainer.py:139] Epoch[897/1500] loss: 0.048233411845660976
I0415 00:32:17.334964 31272 trainer.py:139] Epoch[898/1500] loss: 0.048868626716636845
I0415 00:32:22.013314 31272 trainer.py:139] Epoch[899/1500] loss: 0.04776281298648927
I0415 00:32:22.264474 31272 trainer.py:145] Test: {'precision': 0.14016085790884725, 'recall': 0.33201113505639623, 'hit_ratio': 0.8997319034852547, 'ndcg': 0.3126329892567206}
I0415 00:32:27.809922 31272 trainer.py:139] Epoch[900/1500] loss: 0.0489603339904739
I0415 00:32:33.242746 31272 trainer.py:139] Epoch[901/1500] loss: 0.048148762074209026
I0415 00:32:37.964949 31272 trainer.py:139] Epoch[902/1500] loss: 0.04826467255911519
I0415 00:32:42.730009 31272 trainer.py:139] Epoch[903/1500] loss: 0.04828117523462542
I0415 00:32:47.279786 31272 trainer.py:139] Epoch[904/1500] loss: 0.04688194538316419
I0415 00:32:52.998656 31272 trainer.py:139] Epoch[905/1500] loss: 0.04922063396342339
I0415 00:32:58.256066 31272 trainer.py:139] Epoch[906/1500] loss: 0.04782184682065441
I0415 00:33:03.071955 31272 trainer.py:139] Epoch[907/1500] loss: 0.04831583221112528
I0415 00:33:07.600805 31272 trainer.py:139] Epoch[908/1500] loss: 0.04783986412709759
I0415 00:33:12.260218 31272 trainer.py:139] Epoch[909/1500] loss: 0.04789022055845107
I0415 00:33:16.853849 31272 trainer.py:139] Epoch[910/1500] loss: 0.04845788558163951
I0415 00:33:22.938493 31272 trainer.py:139] Epoch[911/1500] loss: 0.047314396788997036
I0415 00:33:27.488272 31272 trainer.py:139] Epoch[912/1500] loss: 0.04908983169063445
I0415 00:33:32.376919 31272 trainer.py:139] Epoch[913/1500] loss: 0.04802427500967057
I0415 00:33:36.923708 31272 trainer.py:139] Epoch[914/1500] loss: 0.04801673165732814
I0415 00:33:41.600063 31272 trainer.py:139] Epoch[915/1500] loss: 0.047797936345300364
I0415 00:33:47.304977 31272 trainer.py:139] Epoch[916/1500] loss: 0.04754297964034542
I0415 00:33:52.472689 31272 trainer.py:139] Epoch[917/1500] loss: 0.04815133949441294
I0415 00:33:56.977620 31272 trainer.py:139] Epoch[918/1500] loss: 0.0481097636924636
I0415 00:34:01.591185 31272 trainer.py:139] Epoch[919/1500] loss: 0.047348085790872574
I0415 00:34:06.364217 31272 trainer.py:139] Epoch[920/1500] loss: 0.0475625537576214
I0415 00:34:11.214989 31272 trainer.py:139] Epoch[921/1500] loss: 0.04855208471417427
I0415 00:34:16.914920 31272 trainer.py:139] Epoch[922/1500] loss: 0.04745519978384818
I0415 00:34:21.779644 31272 trainer.py:139] Epoch[923/1500] loss: 0.04788348523359145
I0415 00:34:26.584079 31272 trainer.py:139] Epoch[924/1500] loss: 0.048078050296152794
I0415 00:34:31.072039 31272 trainer.py:139] Epoch[925/1500] loss: 0.04803294808633866
I0415 00:34:36.105645 31272 trainer.py:139] Epoch[926/1500] loss: 0.047787448571574305
I0415 00:34:41.775677 31272 trainer.py:139] Epoch[927/1500] loss: 0.04739482905114851
I0415 00:34:46.604523 31272 trainer.py:139] Epoch[928/1500] loss: 0.04721399612965122
I0415 00:34:51.346658 31272 trainer.py:139] Epoch[929/1500] loss: 0.04759029395157291
I0415 00:34:55.894443 31272 trainer.py:139] Epoch[930/1500] loss: 0.047403708941513495
I0415 00:35:01.465805 31272 trainer.py:139] Epoch[931/1500] loss: 0.046512012640314716
I0415 00:35:06.996303 31272 trainer.py:139] Epoch[932/1500] loss: 0.04811015160333726
I0415 00:35:11.390601 31272 trainer.py:139] Epoch[933/1500] loss: 0.04746611860971297
I0415 00:35:16.239381 31272 trainer.py:139] Epoch[934/1500] loss: 0.04686709505415732
I0415 00:35:20.784178 31272 trainer.py:139] Epoch[935/1500] loss: 0.04756907421735025
I0415 00:35:25.689766 31272 trainer.py:139] Epoch[936/1500] loss: 0.047853140460868034
I0415 00:35:31.993223 31272 trainer.py:139] Epoch[937/1500] loss: 0.04741120879207888
I0415 00:35:36.633699 31272 trainer.py:139] Epoch[938/1500] loss: 0.04671300767410186
I0415 00:35:41.222347 31272 trainer.py:139] Epoch[939/1500] loss: 0.047618581162345026
I0415 00:35:45.857841 31272 trainer.py:139] Epoch[940/1500] loss: 0.04752409554296924
I0415 00:35:50.425559 31272 trainer.py:139] Epoch[941/1500] loss: 0.04846013349390799
I0415 00:35:55.780645 31272 trainer.py:139] Epoch[942/1500] loss: 0.047732050861081766
I0415 00:36:01.213903 31272 trainer.py:139] Epoch[943/1500] loss: 0.048048233913798484
I0415 00:36:05.940093 31272 trainer.py:139] Epoch[944/1500] loss: 0.04729023623851038
I0415 00:36:10.579571 31272 trainer.py:139] Epoch[945/1500] loss: 0.04811219234139689
I0415 00:36:15.250943 31272 trainer.py:139] Epoch[946/1500] loss: 0.04732902251905011
I0415 00:36:20.846225 31272 trainer.py:139] Epoch[947/1500] loss: 0.048055708047843745
I0415 00:36:26.123002 31272 trainer.py:139] Epoch[948/1500] loss: 0.048056420539655996
I0415 00:36:30.608994 31272 trainer.py:139] Epoch[949/1500] loss: 0.048607978729471084
I0415 00:36:30.836233 31272 trainer.py:145] Test: {'precision': 0.14026809651474534, 'recall': 0.33095124394958814, 'hit_ratio': 0.8954423592493298, 'ndcg': 0.31337221370408225}
I0415 00:36:35.177709 31272 trainer.py:139] Epoch[950/1500] loss: 0.047471166618408694
I0415 00:36:39.720943 31272 trainer.py:139] Epoch[951/1500] loss: 0.048034620381170706
I0415 00:36:44.136170 31272 trainer.py:139] Epoch[952/1500] loss: 0.04783076636733547
I0415 00:36:50.539747 31272 trainer.py:139] Epoch[953/1500] loss: 0.04723966758578054
I0415 00:36:55.080556 31272 trainer.py:139] Epoch[954/1500] loss: 0.046821585585994106
I0415 00:36:59.624747 31272 trainer.py:139] Epoch[955/1500] loss: 0.04733445014684431
I0415 00:37:04.455586 31272 trainer.py:139] Epoch[956/1500] loss: 0.047421172862091375
I0415 00:37:09.225628 31272 trainer.py:139] Epoch[957/1500] loss: 0.04867964670542748
I0415 00:37:15.677045 31272 trainer.py:139] Epoch[958/1500] loss: 0.04734719797007499
I0415 00:37:20.251742 31272 trainer.py:139] Epoch[959/1500] loss: 0.04732956508955648
I0415 00:37:24.858330 31272 trainer.py:139] Epoch[960/1500] loss: 0.047146392805922414
I0415 00:37:29.444986 31272 trainer.py:139] Epoch[961/1500] loss: 0.04859245412292019
I0415 00:37:34.155229 31272 trainer.py:139] Epoch[962/1500] loss: 0.04847479707771732
I0415 00:37:39.030919 31272 trainer.py:139] Epoch[963/1500] loss: 0.047297505000906605
I0415 00:37:44.976217 31272 trainer.py:139] Epoch[964/1500] loss: 0.04766545997511956
I0415 00:37:49.747256 31272 trainer.py:139] Epoch[965/1500] loss: 0.04797777581599451
I0415 00:37:54.283086 31272 trainer.py:139] Epoch[966/1500] loss: 0.04712225881315047
I0415 00:37:59.039173 31272 trainer.py:139] Epoch[967/1500] loss: 0.04668462108219824
I0415 00:38:03.698584 31272 trainer.py:139] Epoch[968/1500] loss: 0.04727236878487372
I0415 00:38:09.801168 31272 trainer.py:139] Epoch[969/1500] loss: 0.04668085541455976
I0415 00:38:14.360914 31272 trainer.py:139] Epoch[970/1500] loss: 0.0465995300441019
I0415 00:38:19.047235 31272 trainer.py:139] Epoch[971/1500] loss: 0.048904149402533806
I0415 00:38:23.892028 31272 trainer.py:139] Epoch[972/1500] loss: 0.04704105709829638
I0415 00:38:28.467721 31272 trainer.py:139] Epoch[973/1500] loss: 0.045698718077713446
I0415 00:38:34.585257 31272 trainer.py:139] Epoch[974/1500] loss: 0.04862035546571978
I0415 00:38:39.205797 31272 trainer.py:139] Epoch[975/1500] loss: 0.04702430494850682
I0415 00:38:43.909062 31272 trainer.py:139] Epoch[976/1500] loss: 0.04766116387421085
I0415 00:38:48.349210 31272 trainer.py:139] Epoch[977/1500] loss: 0.048280789366652886
I0415 00:38:53.018587 31272 trainer.py:139] Epoch[978/1500] loss: 0.047056586271332156
I0415 00:38:58.393609 31272 trainer.py:139] Epoch[979/1500] loss: 0.04776583455743328
I0415 00:39:03.660985 31272 trainer.py:139] Epoch[980/1500] loss: 0.04795048626199845
I0415 00:39:08.461924 31272 trainer.py:139] Epoch[981/1500] loss: 0.04716917824360632
I0415 00:39:12.987783 31272 trainer.py:139] Epoch[982/1500] loss: 0.045517017043405966
I0415 00:39:17.664139 31272 trainer.py:139] Epoch[983/1500] loss: 0.04724463532047887
I0415 00:39:22.972380 31272 trainer.py:139] Epoch[984/1500] loss: 0.047394365432762334
I0415 00:39:28.550719 31272 trainer.py:139] Epoch[985/1500] loss: 0.04736335839956037
I0415 00:39:33.375576 31272 trainer.py:139] Epoch[986/1500] loss: 0.04758751428415699
I0415 00:39:37.871536 31272 trainer.py:139] Epoch[987/1500] loss: 0.046564588743832805
I0415 00:39:42.594736 31272 trainer.py:139] Epoch[988/1500] loss: 0.048383939290238966
I0415 00:39:47.196340 31272 trainer.py:139] Epoch[989/1500] loss: 0.04750294466653178
I0415 00:39:53.341780 31272 trainer.py:139] Epoch[990/1500] loss: 0.047318197786808014
I0415 00:39:58.295211 31272 trainer.py:139] Epoch[991/1500] loss: 0.04738819767390528
I0415 00:40:02.918743 31272 trainer.py:139] Epoch[992/1500] loss: 0.04717456861849754
I0415 00:40:07.321014 31272 trainer.py:139] Epoch[993/1500] loss: 0.04659861218064062
I0415 00:40:11.889730 31272 trainer.py:139] Epoch[994/1500] loss: 0.047913118956550475
I0415 00:40:16.837179 31272 trainer.py:139] Epoch[995/1500] loss: 0.048080820590257645
I0415 00:40:22.581960 31272 trainer.py:139] Epoch[996/1500] loss: 0.047017612164058996
I0415 00:40:27.423763 31272 trainer.py:139] Epoch[997/1500] loss: 0.04937607554658767
I0415 00:40:32.137992 31272 trainer.py:139] Epoch[998/1500] loss: 0.046612935921838204
I0415 00:40:36.710625 31272 trainer.py:139] Epoch[999/1500] loss: 0.047250010794208895
I0415 00:40:36.970759 31272 trainer.py:145] Test: {'precision': 0.14061662198391428, 'recall': 0.3326734138664435, 'hit_ratio': 0.8981233243967829, 'ndcg': 0.3141489091568104}
I0415 00:40:41.549437 31272 trainer.py:139] Epoch[1000/1500] loss: 0.04755490681817455
I0415 00:40:47.802961 31272 trainer.py:139] Epoch[1001/1500] loss: 0.04793927313820008
I0415 00:40:52.304900 31272 trainer.py:139] Epoch[1002/1500] loss: 0.04767035933271531
I0415 00:40:56.933415 31272 trainer.py:139] Epoch[1003/1500] loss: 0.04797623198359243
I0415 00:41:01.537016 31272 trainer.py:139] Epoch[1004/1500] loss: 0.04678653817503683
I0415 00:41:06.096760 31272 trainer.py:139] Epoch[1005/1500] loss: 0.04638401551112052
I0415 00:41:11.905328 31272 trainer.py:139] Epoch[1006/1500] loss: 0.047478863669018594
I0415 00:41:16.968390 31272 trainer.py:139] Epoch[1007/1500] loss: 0.047914456215596965
I0415 00:41:21.454382 31272 trainer.py:139] Epoch[1008/1500] loss: 0.047740261040387616
I0415 00:41:26.094858 31272 trainer.py:139] Epoch[1009/1500] loss: 0.04815488176480416
I0415 00:41:30.895797 31272 trainer.py:139] Epoch[1010/1500] loss: 0.04728723918237994
I0415 00:41:35.613016 31272 trainer.py:139] Epoch[1011/1500] loss: 0.0477257345712954
I0415 00:41:41.770417 31272 trainer.py:139] Epoch[1012/1500] loss: 0.04579170024202716
I0415 00:41:46.559396 31272 trainer.py:139] Epoch[1013/1500] loss: 0.04649304562518673
I0415 00:41:51.185918 31272 trainer.py:139] Epoch[1014/1500] loss: 0.04754678712737176
I0415 00:41:55.906132 31272 trainer.py:139] Epoch[1015/1500] loss: 0.046987502925818964
I0415 00:42:00.394118 31272 trainer.py:139] Epoch[1016/1500] loss: 0.046555696956572995
I0415 00:42:05.448211 31272 trainer.py:139] Epoch[1017/1500] loss: 0.04591171755906074
I0415 00:42:11.064422 31272 trainer.py:139] Epoch[1018/1500] loss: 0.04669687019721154
I0415 00:42:15.683066 31272 trainer.py:139] Epoch[1019/1500] loss: 0.0467041484530895
I0415 00:42:20.368391 31272 trainer.py:139] Epoch[1020/1500] loss: 0.04713604527135049
I0415 00:42:25.225066 31272 trainer.py:139] Epoch[1021/1500] loss: 0.047784691376070824
I0415 00:42:29.803750 31272 trainer.py:139] Epoch[1022/1500] loss: 0.04716552397416484
I0415 00:42:36.055834 31272 trainer.py:139] Epoch[1023/1500] loss: 0.046333941120293834
I0415 00:42:40.923550 31272 trainer.py:139] Epoch[1024/1500] loss: 0.04742651072240645
I0415 00:42:45.615850 31272 trainer.py:139] Epoch[1025/1500] loss: 0.046930080339793234
I0415 00:42:50.263737 31272 trainer.py:139] Epoch[1026/1500] loss: 0.04700402999597211
I0415 00:42:54.934112 31272 trainer.py:139] Epoch[1027/1500] loss: 0.047413191968394865
I0415 00:43:01.407455 31272 trainer.py:139] Epoch[1028/1500] loss: 0.04735828106922488
I0415 00:43:05.965208 31272 trainer.py:139] Epoch[1029/1500] loss: 0.04632588728300987
I0415 00:43:10.594720 31272 trainer.py:139] Epoch[1030/1500] loss: 0.04780977183291989
I0415 00:43:15.304964 31272 trainer.py:139] Epoch[1031/1500] loss: 0.04669132972917249
I0415 00:43:20.093942 31272 trainer.py:139] Epoch[1032/1500] loss: 0.04727862847428168
I0415 00:43:25.990217 31272 trainer.py:139] Epoch[1033/1500] loss: 0.04692336520360362
I0415 00:43:30.637669 31272 trainer.py:139] Epoch[1034/1500] loss: 0.04646254799539043
I0415 00:43:35.363858 31272 trainer.py:139] Epoch[1035/1500] loss: 0.046706941579618765
I0415 00:43:39.871778 31272 trainer.py:139] Epoch[1036/1500] loss: 0.04779180187371469
I0415 00:43:44.415576 31272 trainer.py:139] Epoch[1037/1500] loss: 0.04681514143463104
I0415 00:43:50.630783 31272 trainer.py:139] Epoch[1038/1500] loss: 0.04786327361099182
I0415 00:43:55.329066 31272 trainer.py:139] Epoch[1039/1500] loss: 0.0468514105004649
I0415 00:43:59.852932 31272 trainer.py:139] Epoch[1040/1500] loss: 0.04724525107491401
I0415 00:44:04.568157 31272 trainer.py:139] Epoch[1041/1500] loss: 0.04720127438345263
I0415 00:44:09.397999 31272 trainer.py:139] Epoch[1042/1500] loss: 0.047327709654646534
I0415 00:44:15.484638 31272 trainer.py:139] Epoch[1043/1500] loss: 0.0457974212063897
I0415 00:44:20.021460 31272 trainer.py:139] Epoch[1044/1500] loss: 0.04674551960441374
I0415 00:44:24.788511 31272 trainer.py:139] Epoch[1045/1500] loss: 0.04602574713287815
I0415 00:44:29.255567 31272 trainer.py:139] Epoch[1046/1500] loss: 0.04646934628967316
I0415 00:44:33.748537 31272 trainer.py:139] Epoch[1047/1500] loss: 0.04619579569947335
I0415 00:44:39.182371 31272 trainer.py:139] Epoch[1048/1500] loss: 0.04649758867679104
I0415 00:44:44.901751 31272 trainer.py:139] Epoch[1049/1500] loss: 0.04750129784787855
I0415 00:44:45.165867 31272 trainer.py:145] Test: {'precision': 0.14029490616621992, 'recall': 0.3322235276682527, 'hit_ratio': 0.9002680965147453, 'ndcg': 0.314021151757941}
I0415 00:44:49.734581 31272 trainer.py:139] Epoch[1050/1500] loss: 0.04790458179289295
I0415 00:44:54.310275 31272 trainer.py:139] Epoch[1051/1500] loss: 0.04705180047500518
I0415 00:44:59.027493 31272 trainer.py:139] Epoch[1052/1500] loss: 0.04764830405192991
I0415 00:45:03.611158 31272 trainer.py:139] Epoch[1053/1500] loss: 0.04760918525918838
I0415 00:45:09.733675 31272 trainer.py:139] Epoch[1054/1500] loss: 0.04691315574511405
I0415 00:45:14.332292 31272 trainer.py:139] Epoch[1055/1500] loss: 0.047120026883579066
I0415 00:45:18.920940 31272 trainer.py:139] Epoch[1056/1500] loss: 0.04709393651254715
I0415 00:45:23.577362 31272 trainer.py:139] Epoch[1057/1500] loss: 0.04674463430719991
I0415 00:45:28.267653 31272 trainer.py:139] Epoch[1058/1500] loss: 0.046898929582488154
I0415 00:45:34.648277 31272 trainer.py:139] Epoch[1059/1500] loss: 0.0459405678895212
I0415 00:45:39.213007 31272 trainer.py:139] Epoch[1060/1500] loss: 0.045178167401782925
I0415 00:45:43.775743 31272 trainer.py:139] Epoch[1061/1500] loss: 0.04621694200942593
I0415 00:45:48.224288 31272 trainer.py:139] Epoch[1062/1500] loss: 0.0476510803545675
I0415 00:45:52.894663 31272 trainer.py:139] Epoch[1063/1500] loss: 0.04746907889362304
I0415 00:45:58.126588 31272 trainer.py:139] Epoch[1064/1500] loss: 0.048120236324687156
I0415 00:46:03.874359 31272 trainer.py:139] Epoch[1065/1500] loss: 0.04796757320723226
I0415 00:46:08.656360 31272 trainer.py:139] Epoch[1066/1500] loss: 0.047858603178493435
I0415 00:46:13.421419 31272 trainer.py:139] Epoch[1067/1500] loss: 0.046181333882193414
I0415 00:46:18.120698 31272 trainer.py:139] Epoch[1068/1500] loss: 0.047832585630878326
I0415 00:46:22.860841 31272 trainer.py:139] Epoch[1069/1500] loss: 0.04732945501323669
I0415 00:46:29.278371 31272 trainer.py:139] Epoch[1070/1500] loss: 0.046543466948693796
I0415 00:46:33.871006 31272 trainer.py:139] Epoch[1071/1500] loss: 0.046337376198460976
I0415 00:46:38.543336 31272 trainer.py:139] Epoch[1072/1500] loss: 0.04609764559615043
I0415 00:46:43.016371 31272 trainer.py:139] Epoch[1073/1500] loss: 0.04649515630256745
I0415 00:46:47.637912 31272 trainer.py:139] Epoch[1074/1500] loss: 0.04676082009269345
I0415 00:46:54.045474 31272 trainer.py:139] Epoch[1075/1500] loss: 0.04730827830010845
I0415 00:46:58.510537 31272 trainer.py:139] Epoch[1076/1500] loss: 0.04617242358865276
I0415 00:47:03.194865 31272 trainer.py:139] Epoch[1077/1500] loss: 0.04673835995697206
I0415 00:47:07.754612 31272 trainer.py:139] Epoch[1078/1500] loss: 0.04801281890080821
I0415 00:47:12.351234 31272 trainer.py:139] Epoch[1079/1500] loss: 0.046116863407434955
I0415 00:47:17.708312 31272 trainer.py:139] Epoch[1080/1500] loss: 0.04654852829633221
I0415 00:47:23.360404 31272 trainer.py:139] Epoch[1081/1500] loss: 0.046905228808041544
I0415 00:47:28.054700 31272 trainer.py:139] Epoch[1082/1500] loss: 0.046480319673015226
I0415 00:47:32.745008 31272 trainer.py:139] Epoch[1083/1500] loss: 0.04702367753751816
I0415 00:47:37.400434 31272 trainer.py:139] Epoch[1084/1500] loss: 0.046150444976745114
I0415 00:47:43.164153 31272 trainer.py:139] Epoch[1085/1500] loss: 0.04756945888361623
I0415 00:47:48.011934 31272 trainer.py:139] Epoch[1086/1500] loss: 0.04724067545706226
I0415 00:47:52.555733 31272 trainer.py:139] Epoch[1087/1500] loss: 0.04676557103953054
I0415 00:47:57.252022 31272 trainer.py:139] Epoch[1088/1500] loss: 0.046377693573313374
I0415 00:48:01.895488 31272 trainer.py:139] Epoch[1089/1500] loss: 0.04684880988732461
I0415 00:48:06.942603 31272 trainer.py:139] Epoch[1090/1500] loss: 0.04749164009286511
I0415 00:48:12.645524 31272 trainer.py:139] Epoch[1091/1500] loss: 0.04685337985715558
I0415 00:48:17.472376 31272 trainer.py:139] Epoch[1092/1500] loss: 0.04633280658914197
I0415 00:48:22.172651 31272 trainer.py:139] Epoch[1093/1500] loss: 0.04674546156198748
I0415 00:48:26.689542 31272 trainer.py:139] Epoch[1094/1500] loss: 0.04633894106072764
I0415 00:48:31.217394 31272 trainer.py:139] Epoch[1095/1500] loss: 0.04603292889172031
I0415 00:48:37.441572 31272 trainer.py:139] Epoch[1096/1500] loss: 0.047369082007677324
I0415 00:48:42.046167 31272 trainer.py:139] Epoch[1097/1500] loss: 0.047349602104194706
I0415 00:48:46.669701 31272 trainer.py:139] Epoch[1098/1500] loss: 0.046602542482076154
I0415 00:48:51.286255 31272 trainer.py:139] Epoch[1099/1500] loss: 0.04707294041591306
I0415 00:48:51.527448 31272 trainer.py:145] Test: {'precision': 0.14075067024128693, 'recall': 0.3336472278094263, 'hit_ratio': 0.9002680965147453, 'ndcg': 0.3149529658858105}
I0415 00:48:56.255630 31272 trainer.py:139] Epoch[1100/1500] loss: 0.04768371161433958
I0415 00:49:00.842287 31272 trainer.py:139] Epoch[1101/1500] loss: 0.04722967070917929
I0415 00:49:07.140217 31272 trainer.py:139] Epoch[1102/1500] loss: 0.04663878198592893
I0415 00:49:11.764745 31272 trainer.py:139] Epoch[1103/1500] loss: 0.045625712121686625
I0415 00:49:16.344425 31272 trainer.py:139] Epoch[1104/1500] loss: 0.0474803656820328
I0415 00:49:20.903174 31272 trainer.py:139] Epoch[1105/1500] loss: 0.04670181918528772
I0415 00:49:25.616369 31272 trainer.py:139] Epoch[1106/1500] loss: 0.04810362080893209
I0415 00:49:31.175726 31272 trainer.py:139] Epoch[1107/1500] loss: 0.04675705815034528
I0415 00:49:36.293116 31272 trainer.py:139] Epoch[1108/1500] loss: 0.04758353639514216
I0415 00:49:40.943557 31272 trainer.py:139] Epoch[1109/1500] loss: 0.04749105906774921
I0415 00:49:45.549150 31272 trainer.py:139] Epoch[1110/1500] loss: 0.04704814464334519
I0415 00:49:50.145772 31272 trainer.py:139] Epoch[1111/1500] loss: 0.04681987868201348
I0415 00:49:55.162427 31272 trainer.py:139] Epoch[1112/1500] loss: 0.04670943295763385
I0415 00:50:01.395573 31272 trainer.py:139] Epoch[1113/1500] loss: 0.047280763666475975
I0415 00:50:06.094853 31272 trainer.py:139] Epoch[1114/1500] loss: 0.04658247013726542
I0415 00:50:10.867884 31272 trainer.py:139] Epoch[1115/1500] loss: 0.046894571113009605
I0415 00:50:15.473477 31272 trainer.py:139] Epoch[1116/1500] loss: 0.04726969486763401
I0415 00:50:20.045182 31272 trainer.py:139] Epoch[1117/1500] loss: 0.04658051616241855
I0415 00:50:25.363455 31272 trainer.py:139] Epoch[1118/1500] loss: 0.04627790290021127
I0415 00:50:30.754420 31272 trainer.py:139] Epoch[1119/1500] loss: 0.046634244822686716
I0415 00:50:35.571306 31272 trainer.py:139] Epoch[1120/1500] loss: 0.04685632259615006
I0415 00:50:40.057729 31272 trainer.py:139] Epoch[1121/1500] loss: 0.04626580423885776
I0415 00:50:44.650364 31272 trainer.py:139] Epoch[1122/1500] loss: 0.04754699394106865
I0415 00:50:49.590838 31272 trainer.py:139] Epoch[1123/1500] loss: 0.04708171455610183
I0415 00:50:55.605714 31272 trainer.py:139] Epoch[1124/1500] loss: 0.04680455331840823
I0415 00:51:00.250623 31272 trainer.py:139] Epoch[1125/1500] loss: 0.04721423851386193
I0415 00:51:04.891098 31272 trainer.py:139] Epoch[1126/1500] loss: 0.047591037327243436
I0415 00:51:09.562471 31272 trainer.py:139] Epoch[1127/1500] loss: 0.04681089808863978
I0415 00:51:14.146136 31272 trainer.py:139] Epoch[1128/1500] loss: 0.047042018703876004
I0415 00:51:20.339418 31272 trainer.py:139] Epoch[1129/1500] loss: 0.04657234864369515
I0415 00:51:25.251983 31272 trainer.py:139] Epoch[1130/1500] loss: 0.046418122466533415
I0415 00:51:29.702095 31272 trainer.py:139] Epoch[1131/1500] loss: 0.04670438350689027
I0415 00:51:34.429281 31272 trainer.py:139] Epoch[1132/1500] loss: 0.04655109766510225
I0415 00:51:39.097665 31272 trainer.py:139] Epoch[1133/1500] loss: 0.04577949366742565
I0415 00:51:45.627734 31272 trainer.py:139] Epoch[1134/1500] loss: 0.04594759775265571
I0415 00:51:50.176027 31272 trainer.py:139] Epoch[1135/1500] loss: 0.04683981078767007
I0415 00:51:55.002879 31272 trainer.py:139] Epoch[1136/1500] loss: 0.04609245915086039
I0415 00:51:59.694184 31272 trainer.py:139] Epoch[1137/1500] loss: 0.04710133457856794
I0415 00:52:04.159708 31272 trainer.py:139] Epoch[1138/1500] loss: 0.0481930322224094
I0415 00:52:09.114134 31272 trainer.py:139] Epoch[1139/1500] loss: 0.04704641310438033
I0415 00:52:14.868881 31272 trainer.py:139] Epoch[1140/1500] loss: 0.0483477478546481
I0415 00:52:19.315006 31272 trainer.py:139] Epoch[1141/1500] loss: 0.04686529117245828
I0415 00:52:23.702329 31272 trainer.py:139] Epoch[1142/1500] loss: 0.047022129378972516
I0415 00:52:28.351774 31272 trainer.py:139] Epoch[1143/1500] loss: 0.04687256930816558
I0415 00:52:32.945408 31272 trainer.py:139] Epoch[1144/1500] loss: 0.04779221033377032
I0415 00:52:39.070914 31272 trainer.py:139] Epoch[1145/1500] loss: 0.046888394581694755
I0415 00:52:43.893779 31272 trainer.py:139] Epoch[1146/1500] loss: 0.046390397173743096
I0415 00:52:48.586083 31272 trainer.py:139] Epoch[1147/1500] loss: 0.046836902537653526
I0415 00:52:53.263435 31272 trainer.py:139] Epoch[1148/1500] loss: 0.04666731722893253
I0415 00:52:57.924840 31272 trainer.py:139] Epoch[1149/1500] loss: 0.047658220414192445
I0415 00:52:58.182976 31272 trainer.py:145] Test: {'precision': 0.14077747989276143, 'recall': 0.33288207451312657, 'hit_ratio': 0.8970509383378016, 'ndcg': 0.31484712413880866}
I0415 00:53:02.734749 31272 trainer.py:139] Epoch[1150/1500] loss: 0.04576961563960198
I0415 00:53:09.043643 31272 trainer.py:139] Epoch[1151/1500] loss: 0.046343297367134405
I0415 00:53:13.673156 31272 trainer.py:139] Epoch[1152/1500] loss: 0.047841057541870305
I0415 00:53:18.322602 31272 trainer.py:139] Epoch[1153/1500] loss: 0.046378852018425544
I0415 00:53:22.951117 31272 trainer.py:139] Epoch[1154/1500] loss: 0.046589937061071396
I0415 00:53:27.593586 31272 trainer.py:139] Epoch[1155/1500] loss: 0.046290169920652144
I0415 00:53:33.258635 31272 trainer.py:139] Epoch[1156/1500] loss: 0.04579604284897927
I0415 00:53:38.415382 31272 trainer.py:139] Epoch[1157/1500] loss: 0.046479605979496436
I0415 00:53:43.005028 31272 trainer.py:139] Epoch[1158/1500] loss: 0.04660950528998529
I0415 00:53:47.555804 31272 trainer.py:139] Epoch[1159/1500] loss: 0.04719984182907689
I0415 00:53:52.218206 31272 trainer.py:139] Epoch[1160/1500] loss: 0.04636164598407284
I0415 00:53:56.922467 31272 trainer.py:139] Epoch[1161/1500] loss: 0.04454403538857737
I0415 00:54:03.349449 31272 trainer.py:139] Epoch[1162/1500] loss: 0.047186945114404924
I0415 00:54:08.059691 31272 trainer.py:139] Epoch[1163/1500] loss: 0.04662110644482797
I0415 00:54:12.776911 31272 trainer.py:139] Epoch[1164/1500] loss: 0.04720598026629417
I0415 00:54:17.268287 31272 trainer.py:139] Epoch[1165/1500] loss: 0.04728967107592091
I0415 00:54:21.877867 31272 trainer.py:139] Epoch[1166/1500] loss: 0.04555126231524252
I0415 00:54:28.067636 31272 trainer.py:139] Epoch[1167/1500] loss: 0.04552838518734901
I0415 00:54:32.602466 31272 trainer.py:139] Epoch[1168/1500] loss: 0.047493033832119357
I0415 00:54:37.289785 31272 trainer.py:139] Epoch[1169/1500] loss: 0.047650800957795114
I0415 00:54:42.066803 31272 trainer.py:139] Epoch[1170/1500] loss: 0.045831220885438305
I0415 00:54:46.639505 31272 trainer.py:139] Epoch[1171/1500] loss: 0.04642595314691143
I0415 00:54:51.842102 31272 trainer.py:139] Epoch[1172/1500] loss: 0.04712862317119875
I0415 00:54:57.546019 31272 trainer.py:139] Epoch[1173/1500] loss: 0.046193582636694756
I0415 00:55:02.408751 31272 trainer.py:139] Epoch[1174/1500] loss: 0.0462420450583581
I0415 00:55:06.895169 31272 trainer.py:139] Epoch[1175/1500] loss: 0.04567531796713029
I0415 00:55:11.685146 31272 trainer.py:139] Epoch[1176/1500] loss: 0.044817909838691834
I0415 00:55:16.389839 31272 trainer.py:139] Epoch[1177/1500] loss: 0.04595803926067968
I0415 00:55:22.243760 31272 trainer.py:139] Epoch[1178/1500] loss: 0.04625412232933506
I0415 00:55:27.193202 31272 trainer.py:139] Epoch[1179/1500] loss: 0.04606202665355898
I0415 00:55:32.094804 31272 trainer.py:139] Epoch[1180/1500] loss: 0.04566249527758168
I0415 00:55:36.554884 31272 trainer.py:139] Epoch[1181/1500] loss: 0.04655495598431556
I0415 00:55:41.079745 31272 trainer.py:139] Epoch[1182/1500] loss: 0.04596445541228018
I0415 00:55:45.822831 31272 trainer.py:139] Epoch[1183/1500] loss: 0.04696465031273903
I0415 00:55:51.970478 31272 trainer.py:139] Epoch[1184/1500] loss: 0.04643696354281518
I0415 00:55:56.428565 31272 trainer.py:139] Epoch[1185/1500] loss: 0.04556929115806856
I0415 00:56:01.177601 31272 trainer.py:139] Epoch[1186/1500] loss: 0.04570060655955346
I0415 00:56:05.804562 31272 trainer.py:139] Epoch[1187/1500] loss: 0.04588563680168121
I0415 00:56:10.414645 31272 trainer.py:139] Epoch[1188/1500] loss: 0.0460148281868427
I0415 00:56:16.407596 31272 trainer.py:139] Epoch[1189/1500] loss: 0.04684239746101441
I0415 00:56:21.054479 31272 trainer.py:139] Epoch[1190/1500] loss: 0.047486290215484554
I0415 00:56:25.663486 31272 trainer.py:139] Epoch[1191/1500] loss: 0.0460559812284285
I0415 00:56:30.271071 31272 trainer.py:139] Epoch[1192/1500] loss: 0.04599255022983397
I0415 00:56:35.024171 31272 trainer.py:139] Epoch[1193/1500] loss: 0.04616901050171544
I0415 00:56:40.843703 31272 trainer.py:139] Epoch[1194/1500] loss: 0.0455998184700166
I0415 00:56:45.849954 31272 trainer.py:139] Epoch[1195/1500] loss: 0.04651666733045732
I0415 00:56:50.296081 31272 trainer.py:139] Epoch[1196/1500] loss: 0.046423721217340036
I0415 00:56:55.033232 31272 trainer.py:139] Epoch[1197/1500] loss: 0.047158842485758565
I0415 00:56:59.561085 31272 trainer.py:139] Epoch[1198/1500] loss: 0.047189133422028635
I0415 00:57:04.185615 31272 trainer.py:139] Epoch[1199/1500] loss: 0.04497584520328429
I0415 00:57:04.401890 31272 trainer.py:145] Test: {'precision': 0.1401340482573727, 'recall': 0.3314131035779832, 'hit_ratio': 0.8975871313672922, 'ndcg': 0.31354512313033345}
I0415 00:57:10.640022 31272 trainer.py:139] Epoch[1200/1500] loss: 0.045726205072095315
I0415 00:57:15.459897 31272 trainer.py:139] Epoch[1201/1500] loss: 0.047437222854745005
I0415 00:57:20.033596 31272 trainer.py:139] Epoch[1202/1500] loss: 0.04685609547361251
I0415 00:57:24.828553 31272 trainer.py:139] Epoch[1203/1500] loss: 0.0469468601288334
I0415 00:57:29.517865 31272 trainer.py:139] Epoch[1204/1500] loss: 0.044966587856892615
I0415 00:57:34.800601 31272 trainer.py:139] Epoch[1205/1500] loss: 0.046363651512130614
I0415 00:57:40.379935 31272 trainer.py:139] Epoch[1206/1500] loss: 0.04648804075775608
I0415 00:57:44.807047 31272 trainer.py:139] Epoch[1207/1500] loss: 0.04669716629770494
I0415 00:57:49.483908 31272 trainer.py:139] Epoch[1208/1500] loss: 0.047135692330137376
I0415 00:57:54.239001 31272 trainer.py:139] Epoch[1209/1500] loss: 0.04659560515034583
I0415 00:57:58.773831 31272 trainer.py:139] Epoch[1210/1500] loss: 0.04605918870337548
I0415 00:58:05.071294 31272 trainer.py:139] Epoch[1211/1500] loss: 0.04581282768518694
I0415 00:58:09.651969 31272 trainer.py:139] Epoch[1212/1500] loss: 0.045711500750434016
I0415 00:58:14.256565 31272 trainer.py:139] Epoch[1213/1500] loss: 0.04561384695191537
I0415 00:58:18.895048 31272 trainer.py:139] Epoch[1214/1500] loss: 0.04548368278530336
I0415 00:58:23.627655 31272 trainer.py:139] Epoch[1215/1500] loss: 0.045428244937812126
I0415 00:58:28.592046 31272 trainer.py:139] Epoch[1216/1500] loss: 0.04593746989004074
I0415 00:58:34.537156 31272 trainer.py:139] Epoch[1217/1500] loss: 0.04608857860007594
I0415 00:58:39.058032 31272 trainer.py:139] Epoch[1218/1500] loss: 0.04605419489164506
I0415 00:58:43.701498 31272 trainer.py:139] Epoch[1219/1500] loss: 0.045609393066936926
I0415 00:58:48.408730 31272 trainer.py:139] Epoch[1220/1500] loss: 0.04604127161925839
I0415 00:58:53.000805 31272 trainer.py:139] Epoch[1221/1500] loss: 0.045858926950923855
I0415 00:58:58.840269 31272 trainer.py:139] Epoch[1222/1500] loss: 0.045212432501777526
I0415 00:59:03.962135 31272 trainer.py:139] Epoch[1223/1500] loss: 0.04704770565994324
I0415 00:59:08.754104 31272 trainer.py:139] Epoch[1224/1500] loss: 0.046553950636617596
I0415 00:59:13.493249 31272 trainer.py:139] Epoch[1225/1500] loss: 0.04638464676757013
I0415 00:59:18.080901 31272 trainer.py:139] Epoch[1226/1500] loss: 0.04550307027755245
I0415 00:59:24.402752 31272 trainer.py:139] Epoch[1227/1500] loss: 0.0463764997980287
I0415 00:59:28.920638 31272 trainer.py:139] Epoch[1228/1500] loss: 0.04576097260559759
I0415 00:59:33.539186 31272 trainer.py:139] Epoch[1229/1500] loss: 0.0468830271593986
I0415 00:59:38.203582 31272 trainer.py:139] Epoch[1230/1500] loss: 0.04602369041212143
I0415 00:59:43.025450 31272 trainer.py:139] Epoch[1231/1500] loss: 0.04655484242304679
I0415 00:59:48.291833 31272 trainer.py:139] Epoch[1232/1500] loss: 0.04658015024277472
I0415 00:59:53.790437 31272 trainer.py:139] Epoch[1233/1500] loss: 0.04609278120821522
I0415 00:59:58.288390 31272 trainer.py:139] Epoch[1234/1500] loss: 0.04749291594470701
I0415 01:00:02.950792 31272 trainer.py:139] Epoch[1235/1500] loss: 0.046206191662819154
I0415 01:00:07.765684 31272 trainer.py:139] Epoch[1236/1500] loss: 0.046572437930491664
I0415 01:00:12.317458 31272 trainer.py:139] Epoch[1237/1500] loss: 0.046409170233434244
I0415 01:00:18.526684 31272 trainer.py:139] Epoch[1238/1500] loss: 0.047176364568933364
I0415 01:00:22.982778 31272 trainer.py:139] Epoch[1239/1500] loss: 0.046081112277123235
I0415 01:00:27.516610 31272 trainer.py:139] Epoch[1240/1500] loss: 0.04634658547659074
I0415 01:00:32.225854 31272 trainer.py:139] Epoch[1241/1500] loss: 0.046090658754110336
I0415 01:00:36.964005 31272 trainer.py:139] Epoch[1242/1500] loss: 0.046350617081888264
I0415 01:00:42.654966 31272 trainer.py:139] Epoch[1243/1500] loss: 0.047095585614442825
I0415 01:00:47.844603 31272 trainer.py:139] Epoch[1244/1500] loss: 0.046760511975134575
I0415 01:00:52.549862 31272 trainer.py:139] Epoch[1245/1500] loss: 0.045061262865220345
I0415 01:00:57.133529 31272 trainer.py:139] Epoch[1246/1500] loss: 0.045750180199261636
I0415 01:01:01.793938 31272 trainer.py:139] Epoch[1247/1500] loss: 0.04566697956573579
I0415 01:01:06.412488 31272 trainer.py:139] Epoch[1248/1500] loss: 0.04665741528714857
I0415 01:01:12.733340 31272 trainer.py:139] Epoch[1249/1500] loss: 0.04675023137561737
I0415 01:01:12.970547 31272 trainer.py:145] Test: {'precision': 0.14024128686327084, 'recall': 0.33245125071532594, 'hit_ratio': 0.8970509383378016, 'ndcg': 0.31383515698978237}
I0415 01:01:17.566174 31272 trainer.py:139] Epoch[1250/1500] loss: 0.046587538214460496
I0415 01:01:22.289373 31272 trainer.py:139] Epoch[1251/1500] loss: 0.04650365789571116
I0415 01:01:27.016558 31272 trainer.py:139] Epoch[1252/1500] loss: 0.04542397443325289
I0415 01:01:31.555373 31272 trainer.py:139] Epoch[1253/1500] loss: 0.045614715545408184
I0415 01:01:37.203479 31272 trainer.py:139] Epoch[1254/1500] loss: 0.045985872466717995
I0415 01:01:42.347269 31272 trainer.py:139] Epoch[1255/1500] loss: 0.04607048750885071
I0415 01:01:47.041027 31272 trainer.py:139] Epoch[1256/1500] loss: 0.04642485743088107
I0415 01:01:51.817049 31272 trainer.py:139] Epoch[1257/1500] loss: 0.04553317374760105
I0415 01:01:56.362838 31272 trainer.py:139] Epoch[1258/1500] loss: 0.04661768422492089
I0415 01:02:01.002318 31272 trainer.py:139] Epoch[1259/1500] loss: 0.04640719462786951
I0415 01:02:06.975626 31272 trainer.py:139] Epoch[1260/1500] loss: 0.045550674079887325
I0415 01:02:11.441686 31272 trainer.py:139] Epoch[1261/1500] loss: 0.04643286596382818
I0415 01:02:15.916224 31272 trainer.py:139] Epoch[1262/1500] loss: 0.04569954016516285
I0415 01:02:20.533775 31272 trainer.py:139] Epoch[1263/1500] loss: 0.046754819851729176
I0415 01:02:25.366607 31272 trainer.py:139] Epoch[1264/1500] loss: 0.046077367158666734
I0415 01:02:31.297765 31272 trainer.py:139] Epoch[1265/1500] loss: 0.046189379067190235
I0415 01:02:36.115647 31272 trainer.py:139] Epoch[1266/1500] loss: 0.046445098735632434
I0415 01:02:40.729213 31272 trainer.py:139] Epoch[1267/1500] loss: 0.04647239658140367
I0415 01:02:45.228111 31272 trainer.py:139] Epoch[1268/1500] loss: 0.04581831239404217
I0415 01:02:50.063199 31272 trainer.py:139] Epoch[1269/1500] loss: 0.04554633880334516
I0415 01:02:55.958478 31272 trainer.py:139] Epoch[1270/1500] loss: 0.045777937817958095
I0415 01:03:01.128183 31272 trainer.py:139] Epoch[1271/1500] loss: 0.04616704859560536
I0415 01:03:05.695902 31272 trainer.py:139] Epoch[1272/1500] loss: 0.04578183783638862
I0415 01:03:10.433054 31272 trainer.py:139] Epoch[1273/1500] loss: 0.04521082678148823
I0415 01:03:15.091469 31272 trainer.py:139] Epoch[1274/1500] loss: 0.04607487505962772
I0415 01:03:19.661604 31272 trainer.py:139] Epoch[1275/1500] loss: 0.04546829793722399
I0415 01:03:25.867839 31272 trainer.py:139] Epoch[1276/1500] loss: 0.045181246774811896
I0415 01:03:30.361806 31272 trainer.py:139] Epoch[1277/1500] loss: 0.04476532916868887
I0415 01:03:35.032181 31272 trainer.py:139] Epoch[1278/1500] loss: 0.04537827701818559
I0415 01:03:39.609868 31272 trainer.py:139] Epoch[1279/1500] loss: 0.045701352819319696
I0415 01:03:44.249347 31272 trainer.py:139] Epoch[1280/1500] loss: 0.046393726141222065
I0415 01:03:48.833013 31272 trainer.py:139] Epoch[1281/1500] loss: 0.04656276659619424
I0415 01:03:55.064165 31272 trainer.py:139] Epoch[1282/1500] loss: 0.04519425440699824
I0415 01:03:59.846167 31272 trainer.py:139] Epoch[1283/1500] loss: 0.046633240075842027
I0415 01:04:04.444784 31272 trainer.py:139] Epoch[1284/1500] loss: 0.045692622901931886
I0415 01:04:09.062335 31272 trainer.py:139] Epoch[1285/1500] loss: 0.047006144518813776
I0415 01:04:13.566269 31272 trainer.py:139] Epoch[1286/1500] loss: 0.04611503200665597
I0415 01:04:19.891109 31272 trainer.py:139] Epoch[1287/1500] loss: 0.04512304488208986
I0415 01:04:24.546535 31272 trainer.py:139] Epoch[1288/1500] loss: 0.046654918501454014
I0415 01:04:28.974720 31272 trainer.py:139] Epoch[1289/1500] loss: 0.04647526000776599
I0415 01:04:33.807552 31272 trainer.py:139] Epoch[1290/1500] loss: 0.04621034956747486
I0415 01:04:38.759986 31272 trainer.py:139] Epoch[1291/1500] loss: 0.0458035914888305
I0415 01:04:44.324370 31272 trainer.py:139] Epoch[1292/1500] loss: 0.04579603912368897
I0415 01:04:49.430297 31272 trainer.py:139] Epoch[1293/1500] loss: 0.04672592601949169
I0415 01:04:54.132565 31272 trainer.py:139] Epoch[1294/1500] loss: 0.04542221837947445
I0415 01:04:58.679355 31272 trainer.py:139] Epoch[1295/1500] loss: 0.04610448907459936
I0415 01:05:03.153387 31272 trainer.py:139] Epoch[1296/1500] loss: 0.04554123515563627
I0415 01:05:07.571607 31272 trainer.py:139] Epoch[1297/1500] loss: 0.04668685072852719
I0415 01:05:13.805145 31272 trainer.py:139] Epoch[1298/1500] loss: 0.04530270253458331
I0415 01:05:18.416718 31272 trainer.py:139] Epoch[1299/1500] loss: 0.045906544933396
I0415 01:05:18.704754 31272 trainer.py:145] Test: {'precision': 0.14048257372654166, 'recall': 0.33264843936662275, 'hit_ratio': 0.896514745308311, 'ndcg': 0.3141464089926215}
I0415 01:05:23.370146 31272 trainer.py:139] Epoch[1300/1500] loss: 0.046038299077941526
I0415 01:05:28.088363 31272 trainer.py:139] Epoch[1301/1500] loss: 0.047125961631536484
I0415 01:05:32.774684 31272 trainer.py:139] Epoch[1302/1500] loss: 0.046194116314572674
I0415 01:05:37.535759 31272 trainer.py:139] Epoch[1303/1500] loss: 0.04630921468619378
I0415 01:05:43.625435 31272 trainer.py:139] Epoch[1304/1500] loss: 0.04701197303591236
I0415 01:05:48.304781 31272 trainer.py:139] Epoch[1305/1500] loss: 0.04576455381128096
I0415 01:05:52.768846 31272 trainer.py:139] Epoch[1306/1500] loss: 0.045907782811310985
I0415 01:05:57.261816 31272 trainer.py:139] Epoch[1307/1500] loss: 0.045875702293649796
I0415 01:06:01.875381 31272 trainer.py:139] Epoch[1308/1500] loss: 0.04578948765993118
I0415 01:06:06.647418 31272 trainer.py:139] Epoch[1309/1500] loss: 0.04547569504187953
I0415 01:06:12.437649 31272 trainer.py:139] Epoch[1310/1500] loss: 0.04665036439414947
I0415 01:06:17.018325 31272 trainer.py:139] Epoch[1311/1500] loss: 0.047110553590520736
I0415 01:06:21.842188 31272 trainer.py:139] Epoch[1312/1500] loss: 0.04528891667723656
I0415 01:06:26.585318 31272 trainer.py:139] Epoch[1313/1500] loss: 0.045476026472545436
I0415 01:06:31.253636 31272 trainer.py:139] Epoch[1314/1500] loss: 0.04604398819708055
I0415 01:06:37.020621 31272 trainer.py:139] Epoch[1315/1500] loss: 0.045696251935535864
I0415 01:06:42.113583 31272 trainer.py:139] Epoch[1316/1500] loss: 0.04568805629687925
I0415 01:06:46.592065 31272 trainer.py:139] Epoch[1317/1500] loss: 0.04524646543206707
I0415 01:06:51.280380 31272 trainer.py:139] Epoch[1318/1500] loss: 0.045717041578985027
I0415 01:06:55.684592 31272 trainer.py:139] Epoch[1319/1500] loss: 0.0463256120922104
I0415 01:07:00.236870 31272 trainer.py:139] Epoch[1320/1500] loss: 0.04600878011795782
I0415 01:07:06.629970 31272 trainer.py:139] Epoch[1321/1500] loss: 0.04419092161040152
I0415 01:07:11.374100 31272 trainer.py:139] Epoch[1322/1500] loss: 0.046363257833065524
I0415 01:07:15.897965 31272 trainer.py:139] Epoch[1323/1500] loss: 0.04589847054693007
I0415 01:07:20.460701 31272 trainer.py:139] Epoch[1324/1500] loss: 0.04526136515121306
I0415 01:07:25.177920 31272 trainer.py:139] Epoch[1325/1500] loss: 0.046322034010964054
I0415 01:07:30.212080 31272 trainer.py:139] Epoch[1326/1500] loss: 0.04567522183060646
I0415 01:07:36.286186 31272 trainer.py:139] Epoch[1327/1500] loss: 0.046522806729039835
I0415 01:07:41.017358 31272 trainer.py:139] Epoch[1328/1500] loss: 0.045096322653755065
I0415 01:07:45.603451 31272 trainer.py:139] Epoch[1329/1500] loss: 0.04617773429039986
I0415 01:07:50.369505 31272 trainer.py:139] Epoch[1330/1500] loss: 0.046797070171563857
I0415 01:07:55.422521 31272 trainer.py:139] Epoch[1331/1500] loss: 0.04571519683926336
I0415 01:08:01.557510 31272 trainer.py:139] Epoch[1332/1500] loss: 0.044577317492615794
I0415 01:08:06.312598 31272 trainer.py:139] Epoch[1333/1500] loss: 0.046714093415967876
I0415 01:08:10.918192 31272 trainer.py:139] Epoch[1334/1500] loss: 0.045654734897036704
I0415 01:08:15.580595 31272 trainer.py:139] Epoch[1335/1500] loss: 0.045808891615559975
I0415 01:08:20.065589 31272 trainer.py:139] Epoch[1336/1500] loss: 0.04536223267355273
I0415 01:08:26.311693 31272 trainer.py:139] Epoch[1337/1500] loss: 0.04581052028844433
I0415 01:08:31.077668 31272 trainer.py:139] Epoch[1338/1500] loss: 0.04419368277153661
I0415 01:08:35.745560 31272 trainer.py:139] Epoch[1339/1500] loss: 0.04599011665390384
I0415 01:08:40.520587 31272 trainer.py:139] Epoch[1340/1500] loss: 0.04509504932549692
I0415 01:08:45.186975 31272 trainer.py:139] Epoch[1341/1500] loss: 0.046162545680999756
I0415 01:08:50.531097 31272 trainer.py:139] Epoch[1342/1500] loss: 0.04542142369093433
I0415 01:08:56.023721 31272 trainer.py:139] Epoch[1343/1500] loss: 0.04589516369085158
I0415 01:09:00.769844 31272 trainer.py:139] Epoch[1344/1500] loss: 0.04505327331923669
I0415 01:09:05.377429 31272 trainer.py:139] Epoch[1345/1500] loss: 0.046378706491762595
I0415 01:09:09.890332 31272 trainer.py:139] Epoch[1346/1500] loss: 0.0449392604491403
I0415 01:09:14.502900 31272 trainer.py:139] Epoch[1347/1500] loss: 0.0463856661752347
I0415 01:09:20.095192 31272 trainer.py:139] Epoch[1348/1500] loss: 0.0458950700779115
I0415 01:09:25.460244 31272 trainer.py:139] Epoch[1349/1500] loss: 0.046140397748639504
I0415 01:09:25.705424 31272 trainer.py:145] Test: {'precision': 0.1402144772117963, 'recall': 0.3327733747529522, 'hit_ratio': 0.8981233243967829, 'ndcg': 0.3132703114530261}
I0415 01:09:30.223310 31272 trainer.py:139] Epoch[1350/1500] loss: 0.04608740693619175
I0415 01:09:34.954482 31272 trainer.py:139] Epoch[1351/1500] loss: 0.046184885285554395
I0415 01:09:39.561072 31272 trainer.py:139] Epoch[1352/1500] loss: 0.04603364270540976
I0415 01:09:44.134770 31272 trainer.py:139] Epoch[1353/1500] loss: 0.046483742854287545
I0415 01:09:50.185528 31272 trainer.py:139] Epoch[1354/1500] loss: 0.046261088982705145
I0415 01:09:54.885802 31272 trainer.py:139] Epoch[1355/1500] loss: 0.04630769825270099
I0415 01:09:59.570132 31272 trainer.py:139] Epoch[1356/1500] loss: 0.04529664929836027
I0415 01:10:04.322234 31272 trainer.py:139] Epoch[1357/1500] loss: 0.04624198905883297
I0415 01:10:08.883973 31272 trainer.py:139] Epoch[1358/1500] loss: 0.045322621541638526
I0415 01:10:14.465301 31272 trainer.py:139] Epoch[1359/1500] loss: 0.045575408805762566
I0415 01:10:19.694807 31272 trainer.py:139] Epoch[1360/1500] loss: 0.04545066409534024
I0415 01:10:24.511691 31272 trainer.py:139] Epoch[1361/1500] loss: 0.045678484584054636
I0415 01:10:29.370872 31272 trainer.py:139] Epoch[1362/1500] loss: 0.045144937331638026
I0415 01:10:33.734276 31272 trainer.py:139] Epoch[1363/1500] loss: 0.0460574665377217
I0415 01:10:38.848168 31272 trainer.py:139] Epoch[1364/1500] loss: 0.04600148888364915
I0415 01:10:44.505242 31272 trainer.py:139] Epoch[1365/1500] loss: 0.045281487727357496
I0415 01:10:49.180600 31272 trainer.py:139] Epoch[1366/1500] loss: 0.046086772194793145
I0415 01:10:53.659616 31272 trainer.py:139] Epoch[1367/1500] loss: 0.045889405473586053
I0415 01:10:58.239294 31272 trainer.py:139] Epoch[1368/1500] loss: 0.04529977205299562
I0415 01:11:02.980433 31272 trainer.py:139] Epoch[1369/1500] loss: 0.04592648857543545
I0415 01:11:08.751128 31272 trainer.py:139] Epoch[1370/1500] loss: 0.04696839663290208
I0415 01:11:13.754830 31272 trainer.py:139] Epoch[1371/1500] loss: 0.04618674552729053
I0415 01:11:18.457099 31272 trainer.py:139] Epoch[1372/1500] loss: 0.04631694766782945
I0415 01:11:23.016292 31272 trainer.py:139] Epoch[1373/1500] loss: 0.045511636282167124
I0415 01:11:27.684674 31272 trainer.py:139] Epoch[1374/1500] loss: 0.045264902614778085
I0415 01:11:32.247410 31272 trainer.py:139] Epoch[1375/1500] loss: 0.045583376841199015
I0415 01:11:38.495963 31272 trainer.py:139] Epoch[1376/1500] loss: 0.044223224083262104
I0415 01:11:43.080625 31272 trainer.py:139] Epoch[1377/1500] loss: 0.045863882308044744
I0415 01:11:47.791865 31272 trainer.py:139] Epoch[1378/1500] loss: 0.04571395319315695
I0415 01:11:52.427358 31272 trainer.py:139] Epoch[1379/1500] loss: 0.04571779192455353
I0415 01:11:56.858532 31272 trainer.py:139] Epoch[1380/1500] loss: 0.04655268824388904
I0415 01:12:01.386384 31272 trainer.py:139] Epoch[1381/1500] loss: 0.04538893062741526
I0415 01:12:07.785451 31272 trainer.py:139] Epoch[1382/1500] loss: 0.04520683927882102
I0415 01:12:12.360147 31272 trainer.py:139] Epoch[1383/1500] loss: 0.044683761293849635
I0415 01:12:17.061421 31272 trainer.py:139] Epoch[1384/1500] loss: 0.04515183596841751
I0415 01:12:21.689935 31272 trainer.py:139] Epoch[1385/1500] loss: 0.046015962958335876
I0415 01:12:26.229748 31272 trainer.py:139] Epoch[1386/1500] loss: 0.04584797904376061
I0415 01:12:31.723370 31272 trainer.py:139] Epoch[1387/1500] loss: 0.04630323078843855
I0415 01:12:37.105365 31272 trainer.py:139] Epoch[1388/1500] loss: 0.04504871813039626
I0415 01:12:41.822584 31272 trainer.py:139] Epoch[1389/1500] loss: 0.04538803247194136
I0415 01:12:46.433159 31272 trainer.py:139] Epoch[1390/1500] loss: 0.045364700377948826
I0415 01:12:51.140412 31272 trainer.py:139] Epoch[1391/1500] loss: 0.045452110589511936
I0415 01:12:55.935372 31272 trainer.py:139] Epoch[1392/1500] loss: 0.046044385481265285
I0415 01:13:01.683143 31272 trainer.py:139] Epoch[1393/1500] loss: 0.043706384397322134
I0415 01:13:06.205013 31272 trainer.py:139] Epoch[1394/1500] loss: 0.04533456338028754
I0415 01:13:10.908787 31272 trainer.py:139] Epoch[1395/1500] loss: 0.04557474161828718
I0415 01:13:15.467534 31272 trainer.py:139] Epoch[1396/1500] loss: 0.04554781798393496
I0415 01:13:20.153858 31272 trainer.py:139] Epoch[1397/1500] loss: 0.04529253513582291
I0415 01:13:25.235857 31272 trainer.py:139] Epoch[1398/1500] loss: 0.045602180904919104
I0415 01:13:30.988611 31272 trainer.py:139] Epoch[1399/1500] loss: 0.046798749796805844
I0415 01:13:31.229803 31272 trainer.py:145] Test: {'precision': 0.1408310991957105, 'recall': 0.3330632556302799, 'hit_ratio': 0.8975871313672922, 'ndcg': 0.31420285694876154}
I0415 01:13:35.824432 31272 trainer.py:139] Epoch[1400/1500] loss: 0.04570527182471368
I0415 01:13:40.598462 31272 trainer.py:139] Epoch[1401/1500] loss: 0.04560841295507646
I0415 01:13:45.249901 31272 trainer.py:139] Epoch[1402/1500] loss: 0.04595132616739119
I0415 01:13:49.994029 31272 trainer.py:139] Epoch[1403/1500] loss: 0.04617380783442528
I0415 01:13:56.167379 31272 trainer.py:139] Epoch[1404/1500] loss: 0.046584087754449534
I0415 01:14:00.908516 31272 trainer.py:139] Epoch[1405/1500] loss: 0.045604010983820886
I0415 01:14:05.663608 31272 trainer.py:139] Epoch[1406/1500] loss: 0.044337186241342176
I0415 01:14:10.205414 31272 trainer.py:139] Epoch[1407/1500] loss: 0.04531055857096949
I0415 01:14:14.694396 31272 trainer.py:139] Epoch[1408/1500] loss: 0.045768710874742075
I0415 01:14:20.376389 31272 trainer.py:139] Epoch[1409/1500] loss: 0.04492740945950631
I0415 01:14:25.815193 31272 trainer.py:139] Epoch[1410/1500] loss: 0.04597544766241504
I0415 01:14:30.437728 31272 trainer.py:139] Epoch[1411/1500] loss: 0.04675173254743699
I0415 01:14:35.277538 31272 trainer.py:139] Epoch[1412/1500] loss: 0.045008737593889236
I0415 01:14:40.005720 31272 trainer.py:139] Epoch[1413/1500] loss: 0.045916604418908394
I0415 01:14:44.789658 31272 trainer.py:139] Epoch[1414/1500] loss: 0.04616154634183453
I0415 01:14:51.114526 31272 trainer.py:139] Epoch[1415/1500] loss: 0.04636494803332513
I0415 01:14:55.777923 31272 trainer.py:139] Epoch[1416/1500] loss: 0.045693681725571235
I0415 01:15:00.469229 31272 trainer.py:139] Epoch[1417/1500] loss: 0.04564389995028896
I0415 01:15:05.143591 31272 trainer.py:139] Epoch[1418/1500] loss: 0.046395986551238645
I0415 01:15:09.841872 31272 trainer.py:139] Epoch[1419/1500] loss: 0.04622564248500332
I0415 01:15:15.013571 31272 trainer.py:139] Epoch[1420/1500] loss: 0.04570098774087045
I0415 01:15:20.649718 31272 trainer.py:139] Epoch[1421/1500] loss: 0.04448404763975451
I0415 01:15:25.375907 31272 trainer.py:139] Epoch[1422/1500] loss: 0.0459969571280864
I0415 01:15:30.029338 31272 trainer.py:139] Epoch[1423/1500] loss: 0.046390788689736395
I0415 01:15:34.562172 31272 trainer.py:139] Epoch[1424/1500] loss: 0.04661889362239068
I0415 01:15:39.226568 31272 trainer.py:139] Epoch[1425/1500] loss: 0.04579907078896799
I0415 01:15:45.000253 31272 trainer.py:139] Epoch[1426/1500] loss: 0.04571486108245388
I0415 01:15:49.973615 31272 trainer.py:139] Epoch[1427/1500] loss: 0.045297215782826944
I0415 01:15:54.631474 31272 trainer.py:139] Epoch[1428/1500] loss: 0.045286079928759604
I0415 01:15:59.271951 31272 trainer.py:139] Epoch[1429/1500] loss: 0.04578607865879612
I0415 01:16:03.864587 31272 trainer.py:139] Epoch[1430/1500] loss: 0.04630940743992405
I0415 01:16:08.578815 31272 trainer.py:139] Epoch[1431/1500] loss: 0.0454462380899537
I0415 01:16:14.789040 31272 trainer.py:139] Epoch[1432/1500] loss: 0.04623778645069369
I0415 01:16:19.319882 31272 trainer.py:139] Epoch[1433/1500] loss: 0.046032642765391256
I0415 01:16:23.995240 31272 trainer.py:139] Epoch[1434/1500] loss: 0.045826125890016556
I0415 01:16:28.687543 31272 trainer.py:139] Epoch[1435/1500] loss: 0.046201168168937004
I0415 01:16:33.370876 31272 trainer.py:139] Epoch[1436/1500] loss: 0.0454935438690647
I0415 01:16:38.597391 31272 trainer.py:139] Epoch[1437/1500] loss: 0.04554128346423949
I0415 01:16:44.013272 31272 trainer.py:139] Epoch[1438/1500] loss: 0.04585826757454103
I0415 01:16:48.807234 31272 trainer.py:139] Epoch[1439/1500] loss: 0.045815073554554296
I0415 01:16:53.569302 31272 trainer.py:139] Epoch[1440/1500] loss: 0.04543919224412211
I0415 01:16:58.190842 31272 trainer.py:139] Epoch[1441/1500] loss: 0.044788150897910516
I0415 01:17:03.282807 31272 trainer.py:139] Epoch[1442/1500] loss: 0.0451311431825161
I0415 01:17:08.780416 31272 trainer.py:139] Epoch[1443/1500] loss: 0.046164742280398643
I0415 01:17:13.284348 31272 trainer.py:139] Epoch[1444/1500] loss: 0.04592175168856498
I0415 01:17:17.729476 31272 trainer.py:139] Epoch[1445/1500] loss: 0.04520076549341602
I0415 01:17:22.445700 31272 trainer.py:139] Epoch[1446/1500] loss: 0.04547284879992085
I0415 01:17:27.114082 31272 trainer.py:139] Epoch[1447/1500] loss: 0.0447793165522237
I0415 01:17:33.309356 31272 trainer.py:139] Epoch[1448/1500] loss: 0.04607820859359157
I0415 01:17:38.126242 31272 trainer.py:139] Epoch[1449/1500] loss: 0.04463509974941131
I0415 01:17:38.376405 31272 trainer.py:145] Test: {'precision': 0.1402949061662199, 'recall': 0.33207425475048896, 'hit_ratio': 0.8970509383378016, 'ndcg': 0.31440282387264956}
I0415 01:17:42.927181 31272 trainer.py:139] Epoch[1450/1500] loss: 0.0472412159846675
I0415 01:17:47.542738 31272 trainer.py:139] Epoch[1451/1500] loss: 0.04489515469439568
I0415 01:17:52.081554 31272 trainer.py:139] Epoch[1452/1500] loss: 0.04611702059065142
I0415 01:17:57.050931 31272 trainer.py:139] Epoch[1453/1500] loss: 0.0456608422100544
I0415 01:18:03.081754 31272 trainer.py:139] Epoch[1454/1500] loss: 0.04497086725408031
I0415 01:18:07.921563 31272 trainer.py:139] Epoch[1455/1500] loss: 0.04512258330660482
I0415 01:18:12.605893 31272 trainer.py:139] Epoch[1456/1500] loss: 0.04633572889912513
I0415 01:18:17.295205 31272 trainer.py:139] Epoch[1457/1500] loss: 0.045790952299871755
I0415 01:18:22.168901 31272 trainer.py:139] Epoch[1458/1500] loss: 0.045354205514154124
I0415 01:18:28.106038 31272 trainer.py:139] Epoch[1459/1500] loss: 0.045557499052055424
I0415 01:18:32.795312 31272 trainer.py:139] Epoch[1460/1500] loss: 0.046086722924824686
I0415 01:18:37.334127 31272 trainer.py:139] Epoch[1461/1500] loss: 0.04548490612256911
I0415 01:18:41.778259 31272 trainer.py:139] Epoch[1462/1500] loss: 0.045403717145804434
I0415 01:18:46.489499 31272 trainer.py:139] Epoch[1463/1500] loss: 0.04674159615270553
I0415 01:18:52.318003 31272 trainer.py:139] Epoch[1464/1500] loss: 0.046257740066897486
I0415 01:18:57.444849 31272 trainer.py:139] Epoch[1465/1500] loss: 0.045481294994392706
I0415 01:19:02.060408 31272 trainer.py:139] Epoch[1466/1500] loss: 0.04590901840598353
I0415 01:19:06.528460 31272 trainer.py:139] Epoch[1467/1500] loss: 0.045780985586104855
I0415 01:19:11.136046 31272 trainer.py:139] Epoch[1468/1500] loss: 0.04570643075050846
I0415 01:19:15.606091 31272 trainer.py:139] Epoch[1469/1500] loss: 0.04487217145581399
I0415 01:19:21.907012 31272 trainer.py:139] Epoch[1470/1500] loss: 0.045294980488477216
I0415 01:19:26.607288 31272 trainer.py:139] Epoch[1471/1500] loss: 0.046172984665439974
I0415 01:19:30.972684 31272 trainer.py:139] Epoch[1472/1500] loss: 0.04504416041797207
I0415 01:19:35.561332 31272 trainer.py:139] Epoch[1473/1500] loss: 0.045682723964414286
I0415 01:19:39.803143 31272 trainer.py:139] Epoch[1474/1500] loss: 0.04521551163446519
I0415 01:19:45.750247 31272 trainer.py:139] Epoch[1475/1500] loss: 0.04533276142131898
I0415 01:19:49.952189 31272 trainer.py:139] Epoch[1476/1500] loss: 0.045745973144808126
I0415 01:19:54.174065 31272 trainer.py:139] Epoch[1477/1500] loss: 0.04625896268313931
I0415 01:19:58.254416 31272 trainer.py:139] Epoch[1478/1500] loss: 0.04510444078233934
I0415 01:20:02.448385 31272 trainer.py:139] Epoch[1479/1500] loss: 0.046228756827692834
I0415 01:20:06.811787 31272 trainer.py:139] Epoch[1480/1500] loss: 0.045332995994437124
I0415 01:20:10.886156 31272 trainer.py:139] Epoch[1481/1500] loss: 0.046687146949191245
I0415 01:20:15.082120 31272 trainer.py:139] Epoch[1482/1500] loss: 0.04590370890594298
I0415 01:20:19.388712 31272 trainer.py:139] Epoch[1483/1500] loss: 0.04406865409785701
I0415 01:20:23.622548 31272 trainer.py:139] Epoch[1484/1500] loss: 0.04438238699109324
I0415 01:20:29.582609 31272 trainer.py:139] Epoch[1485/1500] loss: 0.044308935201937155
I0415 01:20:33.837376 31272 trainer.py:139] Epoch[1486/1500] loss: 0.04528445065502198
I0415 01:20:38.102108 31272 trainer.py:139] Epoch[1487/1500] loss: 0.04475137387071886
I0415 01:20:42.260197 31272 trainer.py:139] Epoch[1488/1500] loss: 0.0443030396296132
I0415 01:20:46.462141 31272 trainer.py:139] Epoch[1489/1500] loss: 0.045248093984780774
I0415 01:20:50.652125 31272 trainer.py:139] Epoch[1490/1500] loss: 0.04549262720730997
I0415 01:20:54.761377 31272 trainer.py:139] Epoch[1491/1500] loss: 0.044766799096138246
I0415 01:20:58.847705 31272 trainer.py:139] Epoch[1492/1500] loss: 0.04636991048051465
I0415 01:21:03.606786 31272 trainer.py:139] Epoch[1493/1500] loss: 0.04505303345860973
I0415 01:21:08.983795 31272 trainer.py:139] Epoch[1494/1500] loss: 0.04610158947686995
I0415 01:21:13.161820 31272 trainer.py:139] Epoch[1495/1500] loss: 0.04503321419319799
I0415 01:21:17.277051 31272 trainer.py:139] Epoch[1496/1500] loss: 0.04636013615996607
I0415 01:21:21.403248 31272 trainer.py:139] Epoch[1497/1500] loss: 0.04509947917634441
I0415 01:21:25.459676 31272 trainer.py:139] Epoch[1498/1500] loss: 0.04512587658339931
I0415 01:21:29.075580 31272 trainer.py:139] Epoch[1499/1500] loss: 0.04646877067223672
I0415 01:21:29.275910 31272 trainer.py:145] Test: {'precision': 0.14053619302949066, 'recall': 0.33246277627644943, 'hit_ratio': 0.8949061662198391, 'ndcg': 0.31381767267415056}
