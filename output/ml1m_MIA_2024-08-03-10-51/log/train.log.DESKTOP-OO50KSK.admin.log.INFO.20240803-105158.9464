I0803 10:52:06.284953 16372 trainer.py:119] Test: [{'precision': 0.07732053422370624, 'recall': 0.08715557621616297, 'hit_ratio': 0.5792988313856428, 'ndcg': 0.1015964836238348}]
I0803 10:52:22.367131 16372 trainer.py:139] Epoch[0/1000] loss: 0.5855820998549461
I0803 10:52:38.144219 16372 trainer.py:139] Epoch[1/1000] loss: 0.5073003135621548
I0803 10:52:53.823528 16372 trainer.py:139] Epoch[2/1000] loss: 0.4640595130622387
I0803 10:53:09.526763 16372 trainer.py:139] Epoch[3/1000] loss: 0.440724391490221
I0803 10:53:25.574755 16372 trainer.py:139] Epoch[4/1000] loss: 0.4278297498822212
I0803 10:53:41.774024 16372 trainer.py:139] Epoch[5/1000] loss: 0.43196042627096176
I0803 10:53:57.789542 16372 trainer.py:139] Epoch[6/1000] loss: 0.4285118952393532
I0803 10:54:13.501375 16372 trainer.py:139] Epoch[7/1000] loss: 0.4249802716076374
I0803 10:54:29.625330 16372 trainer.py:139] Epoch[8/1000] loss: 0.4233388751745224
I0803 10:54:46.133857 16372 trainer.py:139] Epoch[9/1000] loss: 0.4193362705409527
I0803 10:55:02.772879 16372 trainer.py:139] Epoch[10/1000] loss: 0.4195196181535721
I0803 10:55:18.857033 16372 trainer.py:139] Epoch[11/1000] loss: 0.41890447214245796
I0803 10:55:34.841388 16372 trainer.py:139] Epoch[12/1000] loss: 0.4132930189371109
I0803 10:55:50.889156 16372 trainer.py:139] Epoch[13/1000] loss: 0.4179980605840683
I0803 10:56:06.553062 16372 trainer.py:139] Epoch[14/1000] loss: 0.41435689106583595
I0803 10:56:22.734011 16372 trainer.py:139] Epoch[15/1000] loss: 0.4141359254717827
I0803 10:56:38.846662 16372 trainer.py:139] Epoch[16/1000] loss: 0.40959908068180084
I0803 10:56:54.857567 16372 trainer.py:139] Epoch[17/1000] loss: 0.4028598628938198
I0803 10:57:10.870384 16372 trainer.py:139] Epoch[18/1000] loss: 0.40560881793498993
I0803 10:57:26.784633 16372 trainer.py:139] Epoch[19/1000] loss: 0.40224316716194153
I0803 10:57:42.522525 16372 trainer.py:139] Epoch[20/1000] loss: 0.3990749157965183
I0803 10:57:58.358531 16372 trainer.py:139] Epoch[21/1000] loss: 0.39429162070155144
I0803 10:58:14.639152 16372 trainer.py:139] Epoch[22/1000] loss: 0.39336811378598213
I0803 10:58:30.235834 16372 trainer.py:139] Epoch[23/1000] loss: 0.39057639241218567
I0803 10:58:46.381431 16372 trainer.py:139] Epoch[24/1000] loss: 0.38905564695596695
I0803 10:59:02.215413 16372 trainer.py:139] Epoch[25/1000] loss: 0.38624174892902374
I0803 10:59:18.017594 16372 trainer.py:139] Epoch[26/1000] loss: 0.38541336730122566
I0803 10:59:34.071523 16372 trainer.py:139] Epoch[27/1000] loss: 0.38115573674440384
I0803 10:59:50.111816 16372 trainer.py:139] Epoch[28/1000] loss: 0.3779507093131542
I0803 11:00:05.826163 16372 trainer.py:139] Epoch[29/1000] loss: 0.3803930804133415
I0803 11:00:21.510993 16372 trainer.py:139] Epoch[30/1000] loss: 0.3770959936082363
I0803 11:00:37.448902 16372 trainer.py:139] Epoch[31/1000] loss: 0.37628408148884773
I0803 11:00:52.892301 16372 trainer.py:139] Epoch[32/1000] loss: 0.37607602402567863
I0803 11:01:08.690550 16372 trainer.py:139] Epoch[33/1000] loss: 0.3731115758419037
I0803 11:01:24.555513 16372 trainer.py:139] Epoch[34/1000] loss: 0.37152116373181343
I0803 11:01:40.199091 16372 trainer.py:139] Epoch[35/1000] loss: 0.3702762685716152
I0803 11:01:56.397016 16372 trainer.py:139] Epoch[36/1000] loss: 0.3694324865937233
I0803 11:02:12.053671 16372 trainer.py:139] Epoch[37/1000] loss: 0.37038853764533997
I0803 11:02:28.146704 16372 trainer.py:139] Epoch[38/1000] loss: 0.366938941180706
I0803 11:02:44.249561 16372 trainer.py:139] Epoch[39/1000] loss: 0.36424385383725166
I0803 11:03:00.972208 16372 trainer.py:139] Epoch[40/1000] loss: 0.36638644710183144
I0803 11:03:16.811336 16372 trainer.py:139] Epoch[41/1000] loss: 0.3672973960638046
I0803 11:03:32.791055 16372 trainer.py:139] Epoch[42/1000] loss: 0.3609895333647728
I0803 11:03:48.624790 16372 trainer.py:139] Epoch[43/1000] loss: 0.36119309067726135
I0803 11:04:04.523591 16372 trainer.py:139] Epoch[44/1000] loss: 0.35953928530216217
I0803 11:04:20.517809 16372 trainer.py:139] Epoch[45/1000] loss: 0.36026033759117126
I0803 11:04:36.174207 16372 trainer.py:139] Epoch[46/1000] loss: 0.3601231500506401
I0803 11:04:52.062268 16372 trainer.py:139] Epoch[47/1000] loss: 0.35935311391949654
I0803 11:05:08.230080 16372 trainer.py:139] Epoch[48/1000] loss: 0.36008359864354134
I0803 11:05:24.248782 16372 trainer.py:139] Epoch[49/1000] loss: 0.3573612757027149
I0803 11:05:24.906181 16372 trainer.py:145] Test: [{'precision': 0.15428213689482473, 'recall': 0.1987028985277783, 'hit_ratio': 0.8335559265442404, 'ndcg': 0.23087790746004083}]
I0803 11:05:41.067334 16372 trainer.py:139] Epoch[50/1000] loss: 0.35478245839476585
I0803 11:05:56.759698 16372 trainer.py:139] Epoch[51/1000] loss: 0.3530576415359974
I0803 11:06:12.619893 16372 trainer.py:139] Epoch[52/1000] loss: 0.35284551978111267
I0803 11:06:28.518565 16372 trainer.py:139] Epoch[53/1000] loss: 0.35376235470175743
I0803 11:06:44.591303 16372 trainer.py:139] Epoch[54/1000] loss: 0.35142311826348305
I0803 11:07:00.236986 16372 trainer.py:139] Epoch[55/1000] loss: 0.3483061343431473
I0803 11:07:15.934815 16372 trainer.py:139] Epoch[56/1000] loss: 0.35150883719325066
I0803 11:07:31.541866 16372 trainer.py:139] Epoch[57/1000] loss: 0.3485623747110367
I0803 11:07:47.485018 16372 trainer.py:139] Epoch[58/1000] loss: 0.3503640405833721
I0803 11:08:03.308071 16372 trainer.py:139] Epoch[59/1000] loss: 0.3486589044332504
I0803 11:08:19.111068 16372 trainer.py:139] Epoch[60/1000] loss: 0.34913769736886024
I0803 11:08:34.954966 16372 trainer.py:139] Epoch[61/1000] loss: 0.34348004311323166
I0803 11:08:50.929774 16372 trainer.py:139] Epoch[62/1000] loss: 0.3444194011390209
I0803 11:09:06.610347 16372 trainer.py:139] Epoch[63/1000] loss: 0.3431834653019905
I0803 11:09:22.660606 16372 trainer.py:139] Epoch[64/1000] loss: 0.3402469679713249
I0803 11:09:39.042711 16372 trainer.py:139] Epoch[65/1000] loss: 0.3400214910507202
I0803 11:09:55.045962 16372 trainer.py:139] Epoch[66/1000] loss: 0.34006938710808754
I0803 11:10:10.665697 16372 trainer.py:139] Epoch[67/1000] loss: 0.3395405672490597
I0803 11:10:26.420507 16372 trainer.py:139] Epoch[68/1000] loss: 0.33789435401558876
I0803 11:10:42.206186 16372 trainer.py:139] Epoch[69/1000] loss: 0.3399185463786125
I0803 11:10:57.915268 16372 trainer.py:139] Epoch[70/1000] loss: 0.3367149196565151
I0803 11:11:13.772912 16372 trainer.py:139] Epoch[71/1000] loss: 0.33512282744050026
I0803 11:11:30.330298 16372 trainer.py:139] Epoch[72/1000] loss: 0.3330574482679367
I0803 11:11:46.179863 16372 trainer.py:139] Epoch[73/1000] loss: 0.332063402980566
I0803 11:12:01.948096 16372 trainer.py:139] Epoch[74/1000] loss: 0.33555058017373085
I0803 11:12:18.098949 16372 trainer.py:139] Epoch[75/1000] loss: 0.3334004729986191
I0803 11:12:34.062633 16372 trainer.py:139] Epoch[76/1000] loss: 0.33294008672237396
I0803 11:12:49.914097 16372 trainer.py:139] Epoch[77/1000] loss: 0.3289409354329109
I0803 11:13:05.693910 16372 trainer.py:139] Epoch[78/1000] loss: 0.32859666272997856
I0803 11:13:21.495944 16372 trainer.py:139] Epoch[79/1000] loss: 0.32857901602983475
I0803 11:13:37.487974 16372 trainer.py:139] Epoch[80/1000] loss: 0.3290182463824749
I0803 11:13:53.164407 16372 trainer.py:139] Epoch[81/1000] loss: 0.32838718965649605
I0803 11:14:09.119449 16372 trainer.py:139] Epoch[82/1000] loss: 0.3271181583404541
I0803 11:14:25.301169 16372 trainer.py:139] Epoch[83/1000] loss: 0.3276306129992008
I0803 11:14:41.383584 16372 trainer.py:139] Epoch[84/1000] loss: 0.32645565271377563
I0803 11:14:56.979942 16372 trainer.py:139] Epoch[85/1000] loss: 0.3261983059346676
I0803 11:15:12.853353 16372 trainer.py:139] Epoch[86/1000] loss: 0.32180149480700493
I0803 11:15:28.855776 16372 trainer.py:139] Epoch[87/1000] loss: 0.3230672962963581
I0803 11:15:44.609885 16372 trainer.py:139] Epoch[88/1000] loss: 0.3227067142724991
I0803 11:16:00.203828 16372 trainer.py:139] Epoch[89/1000] loss: 0.31808606162667274
I0803 11:16:16.083700 16372 trainer.py:139] Epoch[90/1000] loss: 0.3205900490283966
I0803 11:16:32.114565 16372 trainer.py:139] Epoch[91/1000] loss: 0.31716614589095116
I0803 11:16:48.220507 16372 trainer.py:139] Epoch[92/1000] loss: 0.3214268237352371
I0803 11:17:03.919883 16372 trainer.py:139] Epoch[93/1000] loss: 0.3147754855453968
I0803 11:17:19.709592 16372 trainer.py:139] Epoch[94/1000] loss: 0.31612102314829826
I0803 11:17:35.625029 16372 trainer.py:139] Epoch[95/1000] loss: 0.31532156094908714
I0803 11:17:51.402597 16372 trainer.py:139] Epoch[96/1000] loss: 0.31528546661138535
I0803 11:18:07.293920 16372 trainer.py:139] Epoch[97/1000] loss: 0.3138657622039318
I0803 11:18:23.280276 16372 trainer.py:139] Epoch[98/1000] loss: 0.31144680455327034
I0803 11:18:39.108110 16372 trainer.py:139] Epoch[99/1000] loss: 0.3137759603559971
I0803 11:18:39.836215 16372 trainer.py:145] Test: [{'precision': 0.1618447412353923, 'recall': 0.2156071849652744, 'hit_ratio': 0.8534223706176962, 'ndcg': 0.2467940789616917}]
I0803 11:18:55.410300 16372 trainer.py:139] Epoch[100/1000] loss: 0.3100614733994007
I0803 11:19:11.206935 16372 trainer.py:139] Epoch[101/1000] loss: 0.31137942150235176
I0803 11:19:27.605762 16372 trainer.py:139] Epoch[102/1000] loss: 0.3099236488342285
I0803 11:19:44.078290 16372 trainer.py:139] Epoch[103/1000] loss: 0.31115972250699997
I0803 11:20:00.526204 16372 trainer.py:139] Epoch[104/1000] loss: 0.31091122329235077
I0803 11:20:16.709948 16372 trainer.py:139] Epoch[105/1000] loss: 0.30737877637147903
I0803 11:20:32.516318 16372 trainer.py:139] Epoch[106/1000] loss: 0.305503785610199
I0803 11:20:48.282424 16372 trainer.py:139] Epoch[107/1000] loss: 0.3068709410727024
I0803 11:21:03.971931 16372 trainer.py:139] Epoch[108/1000] loss: 0.30661604553461075
I0803 11:21:19.784520 16372 trainer.py:139] Epoch[109/1000] loss: 0.3038843609392643
I0803 11:21:35.549125 16372 trainer.py:139] Epoch[110/1000] loss: 0.3034585490822792
I0803 11:21:51.306968 16372 trainer.py:139] Epoch[111/1000] loss: 0.3052659258246422
I0803 11:22:06.935431 16372 trainer.py:139] Epoch[112/1000] loss: 0.304415512830019
I0803 11:22:22.631052 16372 trainer.py:139] Epoch[113/1000] loss: 0.3013951815664768
I0803 11:22:38.401320 16372 trainer.py:139] Epoch[114/1000] loss: 0.2993798032402992
I0803 11:22:53.942844 16372 trainer.py:139] Epoch[115/1000] loss: 0.29875122383236885
I0803 11:23:09.580991 16372 trainer.py:139] Epoch[116/1000] loss: 0.2991740219295025
I0803 11:23:25.842107 16372 trainer.py:139] Epoch[117/1000] loss: 0.2996002696454525
I0803 11:23:41.452395 16372 trainer.py:139] Epoch[118/1000] loss: 0.29846811294555664
I0803 11:23:57.169135 16372 trainer.py:139] Epoch[119/1000] loss: 0.2954314388334751
I0803 11:24:13.351430 16372 trainer.py:139] Epoch[120/1000] loss: 0.2960456684231758
I0803 11:24:29.208213 16372 trainer.py:139] Epoch[121/1000] loss: 0.29562782868742943
I0803 11:24:44.907237 16372 trainer.py:139] Epoch[122/1000] loss: 0.29570548608899117
I0803 11:25:00.476382 16372 trainer.py:139] Epoch[123/1000] loss: 0.2956167086958885
I0803 11:25:16.404165 16372 trainer.py:139] Epoch[124/1000] loss: 0.2924661226570606
I0803 11:25:32.326726 16372 trainer.py:139] Epoch[125/1000] loss: 0.29227160662412643
I0803 11:25:47.989065 16372 trainer.py:139] Epoch[126/1000] loss: 0.29340969026088715
I0803 11:26:03.834983 16372 trainer.py:139] Epoch[127/1000] loss: 0.29209888353943825
I0803 11:26:19.701216 16372 trainer.py:139] Epoch[128/1000] loss: 0.2899356000125408
I0803 11:26:35.954879 16372 trainer.py:139] Epoch[129/1000] loss: 0.292287852615118
I0803 11:26:51.866735 16372 trainer.py:139] Epoch[130/1000] loss: 0.291391059756279
I0803 11:27:07.863220 16372 trainer.py:139] Epoch[131/1000] loss: 0.2889997847378254
I0803 11:27:23.638742 16372 trainer.py:139] Epoch[132/1000] loss: 0.2887410819530487
I0803 11:27:39.391788 16372 trainer.py:139] Epoch[133/1000] loss: 0.28729913383722305
I0803 11:27:55.108636 16372 trainer.py:139] Epoch[134/1000] loss: 0.28769687935709953
I0803 11:28:10.769421 16372 trainer.py:139] Epoch[135/1000] loss: 0.2870360165834427
I0803 11:28:26.416260 16372 trainer.py:139] Epoch[136/1000] loss: 0.2862912267446518
I0803 11:28:42.258901 16372 trainer.py:139] Epoch[137/1000] loss: 0.2849135436117649
I0803 11:28:57.967274 16372 trainer.py:139] Epoch[138/1000] loss: 0.2875872515141964
I0803 11:29:13.531364 16372 trainer.py:139] Epoch[139/1000] loss: 0.2850400134921074
I0803 11:29:29.486938 16372 trainer.py:139] Epoch[140/1000] loss: 0.2833918556571007
I0803 11:29:45.057488 16372 trainer.py:139] Epoch[141/1000] loss: 0.28331222012639046
I0803 11:30:01.070593 16372 trainer.py:139] Epoch[142/1000] loss: 0.2827412746846676
I0803 11:30:16.996195 16372 trainer.py:139] Epoch[143/1000] loss: 0.28194737061858177
I0803 11:30:32.998287 16372 trainer.py:139] Epoch[144/1000] loss: 0.2825869806110859
I0803 11:30:48.703168 16372 trainer.py:139] Epoch[145/1000] loss: 0.2808462306857109
I0803 11:31:04.416321 16372 trainer.py:139] Epoch[146/1000] loss: 0.2814103551208973
I0803 11:31:20.323137 16372 trainer.py:139] Epoch[147/1000] loss: 0.2812250927090645
I0803 11:31:36.366386 16372 trainer.py:139] Epoch[148/1000] loss: 0.28024400770664215
I0803 11:31:51.969442 16372 trainer.py:139] Epoch[149/1000] loss: 0.27870816364884377
I0803 11:31:52.625248 16372 trainer.py:145] Test: [{'precision': 0.17083472454090154, 'recall': 0.2339003286929437, 'hit_ratio': 0.8716193656093489, 'ndcg': 0.2633920277178875}]
I0803 11:32:08.919890 16372 trainer.py:139] Epoch[150/1000] loss: 0.27956388518214226
I0803 11:32:25.184819 16372 trainer.py:139] Epoch[151/1000] loss: 0.27781619504094124
I0803 11:32:41.189999 16372 trainer.py:139] Epoch[152/1000] loss: 0.2762826308608055
I0803 11:32:56.769380 16372 trainer.py:139] Epoch[153/1000] loss: 0.2778690345585346
I0803 11:33:12.745020 16372 trainer.py:139] Epoch[154/1000] loss: 0.27853303402662277
I0803 11:33:28.848609 16372 trainer.py:139] Epoch[155/1000] loss: 0.27620498090982437
I0803 11:33:44.733543 16372 trainer.py:139] Epoch[156/1000] loss: 0.2747432440519333
I0803 11:34:00.493221 16372 trainer.py:139] Epoch[157/1000] loss: 0.2777516841888428
I0803 11:34:16.213692 16372 trainer.py:139] Epoch[158/1000] loss: 0.2742983140051365
I0803 11:34:32.095611 16372 trainer.py:139] Epoch[159/1000] loss: 0.2751898057758808
I0803 11:34:47.749589 16372 trainer.py:139] Epoch[160/1000] loss: 0.2722756713628769
I0803 11:35:03.593269 16372 trainer.py:139] Epoch[161/1000] loss: 0.27342650294303894
I0803 11:35:19.406646 16372 trainer.py:139] Epoch[162/1000] loss: 0.2717111110687256
I0803 11:35:35.354159 16372 trainer.py:139] Epoch[163/1000] loss: 0.2728458046913147
I0803 11:35:51.248156 16372 trainer.py:139] Epoch[164/1000] loss: 0.27246756851673126
I0803 11:36:07.179685 16372 trainer.py:139] Epoch[165/1000] loss: 0.27231376990675926
I0803 11:36:22.805161 16372 trainer.py:139] Epoch[166/1000] loss: 0.2707221433520317
I0803 11:36:38.488001 16372 trainer.py:139] Epoch[167/1000] loss: 0.26994409412145615
I0803 11:36:54.250113 16372 trainer.py:139] Epoch[168/1000] loss: 0.2717866636812687
I0803 11:37:10.365398 16372 trainer.py:139] Epoch[169/1000] loss: 0.26941492408514023
I0803 11:37:25.800750 16372 trainer.py:139] Epoch[170/1000] loss: 0.2693217545747757
I0803 11:37:41.593445 16372 trainer.py:139] Epoch[171/1000] loss: 0.2701830379664898
I0803 11:37:57.402558 16372 trainer.py:139] Epoch[172/1000] loss: 0.26787811145186424
I0803 11:38:13.122754 16372 trainer.py:139] Epoch[173/1000] loss: 0.2691732384264469
I0803 11:38:28.899026 16372 trainer.py:139] Epoch[174/1000] loss: 0.26847073435783386
I0803 11:38:44.657472 16372 trainer.py:139] Epoch[175/1000] loss: 0.26657892763614655
I0803 11:39:00.836737 16372 trainer.py:139] Epoch[176/1000] loss: 0.266222320497036
I0803 11:39:16.872651 16372 trainer.py:139] Epoch[177/1000] loss: 0.26641082018613815
I0803 11:39:32.843383 16372 trainer.py:139] Epoch[178/1000] loss: 0.2660076469182968
I0803 11:39:48.858394 16372 trainer.py:139] Epoch[179/1000] loss: 0.26513876020908356
I0803 11:40:04.760568 16372 trainer.py:139] Epoch[180/1000] loss: 0.26460904255509377
I0803 11:40:20.503738 16372 trainer.py:139] Epoch[181/1000] loss: 0.2653533034026623
I0803 11:40:36.441250 16372 trainer.py:139] Epoch[182/1000] loss: 0.26492947340011597
I0803 11:40:52.103672 16372 trainer.py:139] Epoch[183/1000] loss: 0.26274900510907173
I0803 11:41:07.882086 16372 trainer.py:139] Epoch[184/1000] loss: 0.263282660394907
I0803 11:41:23.762964 16372 trainer.py:139] Epoch[185/1000] loss: 0.2642320618033409
I0803 11:41:39.835447 16372 trainer.py:139] Epoch[186/1000] loss: 0.2619146555662155
I0803 11:41:55.755120 16372 trainer.py:139] Epoch[187/1000] loss: 0.26256583631038666
I0803 11:42:11.599680 16372 trainer.py:139] Epoch[188/1000] loss: 0.26206132769584656
I0803 11:42:27.469294 16372 trainer.py:139] Epoch[189/1000] loss: 0.26222629472613335
I0803 11:42:43.295324 16372 trainer.py:139] Epoch[190/1000] loss: 0.2609941214323044
I0803 11:42:58.816266 16372 trainer.py:139] Epoch[191/1000] loss: 0.2611645720899105
I0803 11:43:14.150211 16372 trainer.py:139] Epoch[192/1000] loss: 0.2600107118487358
I0803 11:43:29.848288 16372 trainer.py:139] Epoch[193/1000] loss: 0.2616018280386925
I0803 11:43:45.798299 16372 trainer.py:139] Epoch[194/1000] loss: 0.2599169686436653
I0803 11:44:01.320846 16372 trainer.py:139] Epoch[195/1000] loss: 0.25927698984742165
I0803 11:44:16.794839 16372 trainer.py:139] Epoch[196/1000] loss: 0.25780972838401794
I0803 11:44:32.331050 16372 trainer.py:139] Epoch[197/1000] loss: 0.26069851964712143
I0803 11:44:47.813430 16372 trainer.py:139] Epoch[198/1000] loss: 0.25776736438274384
I0803 11:45:03.679543 16372 trainer.py:139] Epoch[199/1000] loss: 0.2577642500400543
I0803 11:45:04.265116 16372 trainer.py:145] Test: [{'precision': 0.17813856427378963, 'recall': 0.246989364935839, 'hit_ratio': 0.8839732888146912, 'ndcg': 0.2762891662995792}]
I0803 11:45:19.974202 16372 trainer.py:139] Epoch[200/1000] loss: 0.2571127936244011
I0803 11:45:35.899965 16372 trainer.py:139] Epoch[201/1000] loss: 0.2565426789224148
I0803 11:45:51.501639 16372 trainer.py:139] Epoch[202/1000] loss: 0.2547899857163429
I0803 11:46:06.961117 16372 trainer.py:139] Epoch[203/1000] loss: 0.2582652010023594
I0803 11:46:22.747456 16372 trainer.py:139] Epoch[204/1000] loss: 0.2568069063127041
I0803 11:46:38.206350 16372 trainer.py:139] Epoch[205/1000] loss: 0.25471435487270355
I0803 11:46:53.964349 16372 trainer.py:139] Epoch[206/1000] loss: 0.25681204721331596
I0803 11:47:09.386281 16372 trainer.py:139] Epoch[207/1000] loss: 0.25678008794784546
I0803 11:47:24.983179 16372 trainer.py:139] Epoch[208/1000] loss: 0.25497938320040703
I0803 11:47:40.720375 16372 trainer.py:139] Epoch[209/1000] loss: 0.2556079290807247
I0803 11:47:56.247639 16372 trainer.py:139] Epoch[210/1000] loss: 0.25379207357764244
I0803 11:48:11.780139 16372 trainer.py:139] Epoch[211/1000] loss: 0.2541680932044983
I0803 11:48:27.148877 16372 trainer.py:139] Epoch[212/1000] loss: 0.2538176663219929
I0803 11:48:42.892294 16372 trainer.py:139] Epoch[213/1000] loss: 0.2554778903722763
I0803 11:48:58.305903 16372 trainer.py:139] Epoch[214/1000] loss: 0.25375862419605255
I0803 11:49:13.732269 16372 trainer.py:139] Epoch[215/1000] loss: 0.252273615449667
I0803 11:49:29.403737 16372 trainer.py:139] Epoch[216/1000] loss: 0.25168810226023197
I0803 11:49:45.407548 16372 trainer.py:139] Epoch[217/1000] loss: 0.25119660794734955
I0803 11:50:01.070080 16372 trainer.py:139] Epoch[218/1000] loss: 0.25241587683558464
I0803 11:50:16.678374 16372 trainer.py:139] Epoch[219/1000] loss: 0.25310011208057404
I0803 11:50:32.308540 16372 trainer.py:139] Epoch[220/1000] loss: 0.2520739212632179
I0803 11:50:48.021619 16372 trainer.py:139] Epoch[221/1000] loss: 0.2512952294200659
I0803 11:51:04.205359 16372 trainer.py:139] Epoch[222/1000] loss: 0.25230016000568867
I0803 11:51:20.347366 16372 trainer.py:139] Epoch[223/1000] loss: 0.2510043177753687
I0803 11:51:36.096484 16372 trainer.py:139] Epoch[224/1000] loss: 0.24973855912685394
I0803 11:51:51.508258 16372 trainer.py:139] Epoch[225/1000] loss: 0.2501197885721922
I0803 11:52:06.922965 16372 trainer.py:139] Epoch[226/1000] loss: 0.2496448252350092
I0803 11:52:22.425220 16372 trainer.py:139] Epoch[227/1000] loss: 0.25022583082318306
I0803 11:52:38.159043 16372 trainer.py:139] Epoch[228/1000] loss: 0.248642198741436
I0803 11:52:53.704317 16372 trainer.py:139] Epoch[229/1000] loss: 0.24929369427263737
I0803 11:53:09.379337 16372 trainer.py:139] Epoch[230/1000] loss: 0.24935834854841232
I0803 11:53:25.037797 16372 trainer.py:139] Epoch[231/1000] loss: 0.24894865229725838
I0803 11:53:40.553444 16372 trainer.py:139] Epoch[232/1000] loss: 0.2490349654108286
I0803 11:53:55.939694 16372 trainer.py:139] Epoch[233/1000] loss: 0.24849908240139484
I0803 11:54:11.483446 16372 trainer.py:139] Epoch[234/1000] loss: 0.24787863343954086
I0803 11:54:27.025225 16372 trainer.py:139] Epoch[235/1000] loss: 0.24641269259154797
I0803 11:54:42.671485 16372 trainer.py:139] Epoch[236/1000] loss: 0.24707220681011677
I0803 11:54:58.258440 16372 trainer.py:139] Epoch[237/1000] loss: 0.24865921214222908
I0803 11:55:14.140846 16372 trainer.py:139] Epoch[238/1000] loss: 0.24746756441891193
I0803 11:55:29.911748 16372 trainer.py:139] Epoch[239/1000] loss: 0.24695155210793018
I0803 11:55:45.389277 16372 trainer.py:139] Epoch[240/1000] loss: 0.24565595015883446
I0803 11:56:00.811811 16372 trainer.py:139] Epoch[241/1000] loss: 0.2456718198955059
I0803 11:56:16.537625 16372 trainer.py:139] Epoch[242/1000] loss: 0.24726343899965286
I0803 11:56:31.965364 16372 trainer.py:139] Epoch[243/1000] loss: 0.24592589400708675
I0803 11:56:47.941363 16372 trainer.py:139] Epoch[244/1000] loss: 0.24513776414096355
I0803 11:57:03.442620 16372 trainer.py:139] Epoch[245/1000] loss: 0.24593452736735344
I0803 11:57:19.139269 16372 trainer.py:139] Epoch[246/1000] loss: 0.24580960907042027
I0803 11:57:34.551820 16372 trainer.py:139] Epoch[247/1000] loss: 0.24542004615068436
I0803 11:57:50.371965 16372 trainer.py:139] Epoch[248/1000] loss: 0.24519809894263744
I0803 11:58:06.358262 16372 trainer.py:139] Epoch[249/1000] loss: 0.24401439540088177
I0803 11:58:06.963880 16372 trainer.py:145] Test: [{'precision': 0.18307178631051751, 'recall': 0.25543190803380195, 'hit_ratio': 0.8918196994991653, 'ndcg': 0.28509634660905164}]
I0803 11:58:22.513216 16372 trainer.py:139] Epoch[250/1000] loss: 0.24549048021435738
I0803 11:58:38.181677 16372 trainer.py:139] Epoch[251/1000] loss: 0.24569178745150566
I0803 11:58:53.521969 16372 trainer.py:139] Epoch[252/1000] loss: 0.2441813386976719
I0803 11:59:08.910311 16372 trainer.py:139] Epoch[253/1000] loss: 0.24420354329049587
I0803 11:59:24.284257 16372 trainer.py:139] Epoch[254/1000] loss: 0.24331309087574482
I0803 11:59:39.843015 16372 trainer.py:139] Epoch[255/1000] loss: 0.2444780431687832
I0803 11:59:55.285932 16372 trainer.py:139] Epoch[256/1000] loss: 0.24434898421168327
I0803 12:00:10.688783 16372 trainer.py:139] Epoch[257/1000] loss: 0.24336144514381886
I0803 12:00:26.205988 16372 trainer.py:139] Epoch[258/1000] loss: 0.24333992414176464
I0803 12:00:41.656759 16372 trainer.py:139] Epoch[259/1000] loss: 0.24405476450920105
I0803 12:00:57.195705 16372 trainer.py:139] Epoch[260/1000] loss: 0.24349462985992432
I0803 12:01:12.687937 16372 trainer.py:139] Epoch[261/1000] loss: 0.24303286895155907
I0803 12:01:28.369497 16372 trainer.py:139] Epoch[262/1000] loss: 0.24189329147338867
I0803 12:01:44.221600 16372 trainer.py:139] Epoch[263/1000] loss: 0.24380727112293243
I0803 12:01:59.959363 16372 trainer.py:139] Epoch[264/1000] loss: 0.242020633071661
I0803 12:02:15.410025 16372 trainer.py:139] Epoch[265/1000] loss: 0.24208577536046505
I0803 12:02:31.014529 16372 trainer.py:139] Epoch[266/1000] loss: 0.24221529997885227
I0803 12:02:46.591029 16372 trainer.py:139] Epoch[267/1000] loss: 0.2412167601287365
I0803 12:03:02.012907 16372 trainer.py:139] Epoch[268/1000] loss: 0.24133818224072456
I0803 12:03:17.565415 16372 trainer.py:139] Epoch[269/1000] loss: 0.24223089776933193
I0803 12:03:33.386206 16372 trainer.py:139] Epoch[270/1000] loss: 0.24010321870446205
I0803 12:03:49.250181 16372 trainer.py:139] Epoch[271/1000] loss: 0.24056623317301273
I0803 12:04:04.821392 16372 trainer.py:139] Epoch[272/1000] loss: 0.24033741094172
I0803 12:04:20.743680 16372 trainer.py:139] Epoch[273/1000] loss: 0.24021033570170403
I0803 12:04:36.529480 16372 trainer.py:139] Epoch[274/1000] loss: 0.2404133826494217
I0803 12:04:51.988805 16372 trainer.py:139] Epoch[275/1000] loss: 0.23959842137992382
I0803 12:05:07.616233 16372 trainer.py:139] Epoch[276/1000] loss: 0.23933514021337032
I0803 12:05:23.170209 16372 trainer.py:139] Epoch[277/1000] loss: 0.23976225219666958
I0803 12:05:38.815528 16372 trainer.py:139] Epoch[278/1000] loss: 0.23959136381745338
I0803 12:05:54.379001 16372 trainer.py:139] Epoch[279/1000] loss: 0.23782258108258247
I0803 12:06:09.838708 16372 trainer.py:139] Epoch[280/1000] loss: 0.2391371726989746
I0803 12:06:25.390761 16372 trainer.py:139] Epoch[281/1000] loss: 0.23941665142774582
I0803 12:06:40.847682 16372 trainer.py:139] Epoch[282/1000] loss: 0.2396565917879343
I0803 12:06:56.314767 16372 trainer.py:139] Epoch[283/1000] loss: 0.23808537982404232
I0803 12:07:11.563353 16372 trainer.py:139] Epoch[284/1000] loss: 0.2386310175061226
I0803 12:07:26.905567 16372 trainer.py:139] Epoch[285/1000] loss: 0.23836607672274113
I0803 12:07:42.561405 16372 trainer.py:139] Epoch[286/1000] loss: 0.23906362429261208
I0803 12:07:58.117615 16372 trainer.py:139] Epoch[287/1000] loss: 0.238433500751853
I0803 12:08:13.752176 16372 trainer.py:139] Epoch[288/1000] loss: 0.2379962895065546
I0803 12:08:29.322995 16372 trainer.py:139] Epoch[289/1000] loss: 0.2378323581069708
I0803 12:08:44.732654 16372 trainer.py:139] Epoch[290/1000] loss: 0.23861226253211498
I0803 12:09:00.381680 16372 trainer.py:139] Epoch[291/1000] loss: 0.23841788433492184
I0803 12:09:16.252599 16372 trainer.py:139] Epoch[292/1000] loss: 0.23761447705328465
I0803 12:09:31.838395 16372 trainer.py:139] Epoch[293/1000] loss: 0.2365596443414688
I0803 12:09:47.306273 16372 trainer.py:139] Epoch[294/1000] loss: 0.23780567571520805
I0803 12:10:02.883052 16372 trainer.py:139] Epoch[295/1000] loss: 0.23782365955412388
I0803 12:10:18.377079 16372 trainer.py:139] Epoch[296/1000] loss: 0.23550863191485405
I0803 12:10:33.884563 16372 trainer.py:139] Epoch[297/1000] loss: 0.2369621843099594
I0803 12:10:49.425226 16372 trainer.py:139] Epoch[298/1000] loss: 0.23710413090884686
I0803 12:11:05.115741 16372 trainer.py:139] Epoch[299/1000] loss: 0.23583276942372322
I0803 12:11:05.760583 16372 trainer.py:145] Test: [{'precision': 0.186677796327212, 'recall': 0.2614211354531163, 'hit_ratio': 0.8979966611018364, 'ndcg': 0.2914267373110695}]
I0803 12:11:21.651359 16372 trainer.py:139] Epoch[300/1000] loss: 0.23580758087337017
I0803 12:11:37.426960 16372 trainer.py:139] Epoch[301/1000] loss: 0.23652517423033714
I0803 12:11:52.617877 16372 trainer.py:139] Epoch[302/1000] loss: 0.23583975806832314
I0803 12:12:07.879617 16372 trainer.py:139] Epoch[303/1000] loss: 0.23568197898566723
I0803 12:12:23.305771 16372 trainer.py:139] Epoch[304/1000] loss: 0.23530090600252151
I0803 12:12:38.753625 16372 trainer.py:139] Epoch[305/1000] loss: 0.23638933897018433
I0803 12:12:54.353816 16372 trainer.py:139] Epoch[306/1000] loss: 0.23525847308337688
I0803 12:13:09.919578 16372 trainer.py:139] Epoch[307/1000] loss: 0.23578214831650257
I0803 12:13:25.424838 16372 trainer.py:139] Epoch[308/1000] loss: 0.23512776009738445
I0803 12:13:40.962012 16372 trainer.py:139] Epoch[309/1000] loss: 0.2347110640257597
I0803 12:13:56.742554 16372 trainer.py:139] Epoch[310/1000] loss: 0.23533229157328606
I0803 12:14:12.394295 16372 trainer.py:139] Epoch[311/1000] loss: 0.23501385748386383
I0803 12:14:28.306221 16372 trainer.py:139] Epoch[312/1000] loss: 0.2336085271090269
I0803 12:14:44.093667 16372 trainer.py:139] Epoch[313/1000] loss: 0.23575414903461933
I0803 12:14:59.812020 16372 trainer.py:139] Epoch[314/1000] loss: 0.23503954894840717
I0803 12:15:15.289159 16372 trainer.py:139] Epoch[315/1000] loss: 0.23392472229897976
I0803 12:15:31.286120 16372 trainer.py:139] Epoch[316/1000] loss: 0.23264978267252445
I0803 12:15:47.176446 16372 trainer.py:139] Epoch[317/1000] loss: 0.2334306463599205
I0803 12:16:02.522006 16372 trainer.py:139] Epoch[318/1000] loss: 0.23351815901696682
I0803 12:16:18.032258 16372 trainer.py:139] Epoch[319/1000] loss: 0.234759371727705
I0803 12:16:33.944274 16372 trainer.py:139] Epoch[320/1000] loss: 0.23431164771318436
I0803 12:16:49.174315 16372 trainer.py:139] Epoch[321/1000] loss: 0.23348292335867882
I0803 12:17:04.576943 16372 trainer.py:139] Epoch[322/1000] loss: 0.2337738759815693
I0803 12:17:20.058578 16372 trainer.py:139] Epoch[323/1000] loss: 0.23342224024236202
I0803 12:17:35.638628 16372 trainer.py:139] Epoch[324/1000] loss: 0.23425191454589367
I0803 12:17:51.264050 16372 trainer.py:139] Epoch[325/1000] loss: 0.23349521309137344
I0803 12:18:06.925231 16372 trainer.py:139] Epoch[326/1000] loss: 0.2335483729839325
I0803 12:18:22.466012 16372 trainer.py:139] Epoch[327/1000] loss: 0.2332464326173067
I0803 12:18:37.986278 16372 trainer.py:139] Epoch[328/1000] loss: 0.23283366672694683
I0803 12:18:53.564668 16372 trainer.py:139] Epoch[329/1000] loss: 0.23336957208812237
I0803 12:19:09.104296 16372 trainer.py:139] Epoch[330/1000] loss: 0.2317985389381647
I0803 12:19:24.938524 16372 trainer.py:139] Epoch[331/1000] loss: 0.23124372959136963
I0803 12:19:40.605141 16372 trainer.py:139] Epoch[332/1000] loss: 0.2324946541339159
I0803 12:19:56.618568 16372 trainer.py:139] Epoch[333/1000] loss: 0.23244187980890274
I0803 12:20:12.170487 16372 trainer.py:139] Epoch[334/1000] loss: 0.2330602016299963
I0803 12:20:27.933042 16372 trainer.py:139] Epoch[335/1000] loss: 0.23184093087911606
I0803 12:20:43.558233 16372 trainer.py:139] Epoch[336/1000] loss: 0.23209650069475174
I0803 12:20:59.091659 16372 trainer.py:139] Epoch[337/1000] loss: 0.231428612023592
I0803 12:21:14.888075 16372 trainer.py:139] Epoch[338/1000] loss: 0.23232697322964668
I0803 12:21:30.714942 16372 trainer.py:139] Epoch[339/1000] loss: 0.2311802376061678
I0803 12:21:46.529467 16372 trainer.py:139] Epoch[340/1000] loss: 0.2313432339578867
I0803 12:22:01.917189 16372 trainer.py:139] Epoch[341/1000] loss: 0.2310757413506508
I0803 12:22:17.402979 16372 trainer.py:139] Epoch[342/1000] loss: 0.23183397948741913
I0803 12:22:33.271937 16372 trainer.py:139] Epoch[343/1000] loss: 0.23198700696229935
I0803 12:22:48.861750 16372 trainer.py:139] Epoch[344/1000] loss: 0.2305036000907421
I0803 12:23:04.427851 16372 trainer.py:139] Epoch[345/1000] loss: 0.23099138215184212
I0803 12:23:20.066570 16372 trainer.py:139] Epoch[346/1000] loss: 0.23189054243266582
I0803 12:23:36.115091 16372 trainer.py:139] Epoch[347/1000] loss: 0.23082929849624634
I0803 12:23:51.642736 16372 trainer.py:139] Epoch[348/1000] loss: 0.23066965863108635
I0803 12:24:06.969083 16372 trainer.py:139] Epoch[349/1000] loss: 0.2307039126753807
I0803 12:24:07.544158 16372 trainer.py:145] Test: [{'precision': 0.18892320534223708, 'recall': 0.2646664858817491, 'hit_ratio': 0.9001669449081803, 'ndcg': 0.2953711283136704}]
I0803 12:24:23.205322 16372 trainer.py:139] Epoch[350/1000] loss: 0.22997584380209446
I0803 12:24:38.725172 16372 trainer.py:139] Epoch[351/1000] loss: 0.23023070022463799
I0803 12:24:54.284877 16372 trainer.py:139] Epoch[352/1000] loss: 0.22953411377966404
I0803 12:25:09.660050 16372 trainer.py:139] Epoch[353/1000] loss: 0.2313255649060011
I0803 12:25:25.244033 16372 trainer.py:139] Epoch[354/1000] loss: 0.23031346686184406
I0803 12:25:40.873675 16372 trainer.py:139] Epoch[355/1000] loss: 0.22966923005878925
I0803 12:25:56.223459 16372 trainer.py:139] Epoch[356/1000] loss: 0.22871015779674053
I0803 12:26:11.759049 16372 trainer.py:139] Epoch[357/1000] loss: 0.2294496688991785
I0803 12:26:27.222086 16372 trainer.py:139] Epoch[358/1000] loss: 0.23148036375641823
I0803 12:26:42.695568 16372 trainer.py:139] Epoch[359/1000] loss: 0.2295236624777317
I0803 12:26:58.580668 16372 trainer.py:139] Epoch[360/1000] loss: 0.22943749092519283
I0803 12:27:14.043421 16372 trainer.py:139] Epoch[361/1000] loss: 0.2304601613432169
I0803 12:27:30.240015 16372 trainer.py:139] Epoch[362/1000] loss: 0.2291689645498991
I0803 12:27:46.032445 16372 trainer.py:139] Epoch[363/1000] loss: 0.228062080219388
I0803 12:28:01.935438 16372 trainer.py:139] Epoch[364/1000] loss: 0.22944189235568047
I0803 12:28:17.527818 16372 trainer.py:139] Epoch[365/1000] loss: 0.2299274243414402
I0803 12:28:33.172051 16372 trainer.py:139] Epoch[366/1000] loss: 0.22847838886082172
I0803 12:28:48.619601 16372 trainer.py:139] Epoch[367/1000] loss: 0.2289550956338644
I0803 12:29:04.646057 16372 trainer.py:139] Epoch[368/1000] loss: 0.22936316952109337
I0803 12:29:20.116039 16372 trainer.py:139] Epoch[369/1000] loss: 0.22946852631866932
I0803 12:29:35.669325 16372 trainer.py:139] Epoch[370/1000] loss: 0.2288266010582447
I0803 12:29:51.238084 16372 trainer.py:139] Epoch[371/1000] loss: 0.2281339429318905
I0803 12:30:06.788887 16372 trainer.py:139] Epoch[372/1000] loss: 0.22989559546113014
I0803 12:30:22.809191 16372 trainer.py:139] Epoch[373/1000] loss: 0.22838203608989716
I0803 12:30:38.284366 16372 trainer.py:139] Epoch[374/1000] loss: 0.2282395176589489
I0803 12:30:53.801699 16372 trainer.py:139] Epoch[375/1000] loss: 0.22828377783298492
I0803 12:31:09.406402 16372 trainer.py:139] Epoch[376/1000] loss: 0.22703318484127522
I0803 12:31:24.839380 16372 trainer.py:139] Epoch[377/1000] loss: 0.22945876605808735
I0803 12:31:40.281862 16372 trainer.py:139] Epoch[378/1000] loss: 0.22783836722373962
I0803 12:31:55.695945 16372 trainer.py:139] Epoch[379/1000] loss: 0.22727858647704124
I0803 12:32:11.275043 16372 trainer.py:139] Epoch[380/1000] loss: 0.22747562639415264
I0803 12:32:26.724786 16372 trainer.py:139] Epoch[381/1000] loss: 0.22841422446072102
I0803 12:32:42.291000 16372 trainer.py:139] Epoch[382/1000] loss: 0.22720425948500633
I0803 12:32:57.757423 16372 trainer.py:139] Epoch[383/1000] loss: 0.22638880088925362
I0803 12:33:13.456198 16372 trainer.py:139] Epoch[384/1000] loss: 0.226680563762784
I0803 12:33:29.213894 16372 trainer.py:139] Epoch[385/1000] loss: 0.22789809666574
I0803 12:33:44.837102 16372 trainer.py:139] Epoch[386/1000] loss: 0.2268935013562441
I0803 12:34:00.686341 16372 trainer.py:139] Epoch[387/1000] loss: 0.22843405604362488
I0803 12:34:16.400052 16372 trainer.py:139] Epoch[388/1000] loss: 0.22770125232636929
I0803 12:34:32.315413 16372 trainer.py:139] Epoch[389/1000] loss: 0.22694338858127594
I0803 12:34:47.822594 16372 trainer.py:139] Epoch[390/1000] loss: 0.22809483669698238
I0803 12:35:03.394464 16372 trainer.py:139] Epoch[391/1000] loss: 0.227693323045969
I0803 12:35:19.118355 16372 trainer.py:139] Epoch[392/1000] loss: 0.2275137696415186
I0803 12:35:35.083804 16372 trainer.py:139] Epoch[393/1000] loss: 0.22676353342831135
I0803 12:35:50.911488 16372 trainer.py:139] Epoch[394/1000] loss: 0.22610913962125778
I0803 12:36:06.619430 16372 trainer.py:139] Epoch[395/1000] loss: 0.22585243731737137
I0803 12:36:23.296859 16372 trainer.py:139] Epoch[396/1000] loss: 0.22675782442092896
I0803 12:36:40.041194 16372 trainer.py:139] Epoch[397/1000] loss: 0.2265228684991598
I0803 12:36:56.291699 16372 trainer.py:139] Epoch[398/1000] loss: 0.22682566568255424
I0803 12:37:12.479093 16372 trainer.py:139] Epoch[399/1000] loss: 0.2258302327245474
I0803 12:37:13.124518 16372 trainer.py:145] Test: [{'precision': 0.1901335559265442, 'recall': 0.2668609341340061, 'hit_ratio': 0.9010016694490818, 'ndcg': 0.29826530350120484}]
I0803 12:37:29.364213 16372 trainer.py:139] Epoch[400/1000] loss: 0.22602504678070545
I0803 12:37:45.322838 16372 trainer.py:139] Epoch[401/1000] loss: 0.22601376473903656
I0803 12:38:01.923102 16372 trainer.py:139] Epoch[402/1000] loss: 0.22433829680085182
I0803 12:38:18.265371 16372 trainer.py:139] Epoch[403/1000] loss: 0.22546126879751682
I0803 12:38:34.722746 16372 trainer.py:139] Epoch[404/1000] loss: 0.2255681324750185
I0803 12:38:50.779277 16372 trainer.py:139] Epoch[405/1000] loss: 0.22608170472085476
I0803 12:39:06.820478 16372 trainer.py:139] Epoch[406/1000] loss: 0.22594856657087803
I0803 12:39:22.996797 16372 trainer.py:139] Epoch[407/1000] loss: 0.22559700720012188
I0803 12:39:39.070494 16372 trainer.py:139] Epoch[408/1000] loss: 0.2256547510623932
I0803 12:39:55.069473 16372 trainer.py:139] Epoch[409/1000] loss: 0.22547578439116478
I0803 12:40:11.016646 16372 trainer.py:139] Epoch[410/1000] loss: 0.22604183293879032
I0803 12:40:27.156197 16372 trainer.py:139] Epoch[411/1000] loss: 0.22412649914622307
I0803 12:40:42.805179 16372 trainer.py:139] Epoch[412/1000] loss: 0.2247837893664837
I0803 12:40:58.551124 16372 trainer.py:139] Epoch[413/1000] loss: 0.22665686160326004
I0803 12:41:14.739722 16372 trainer.py:139] Epoch[414/1000] loss: 0.22545459680259228
I0803 12:41:30.517648 16372 trainer.py:139] Epoch[415/1000] loss: 0.22473672963678837
I0803 12:41:46.573873 16372 trainer.py:139] Epoch[416/1000] loss: 0.22553781233727932
I0803 12:42:02.517667 16372 trainer.py:139] Epoch[417/1000] loss: 0.22484974190592766
I0803 12:42:18.343316 16372 trainer.py:139] Epoch[418/1000] loss: 0.22495194897055626
I0803 12:42:34.282177 16372 trainer.py:139] Epoch[419/1000] loss: 0.22483415342867374
I0803 12:42:50.045263 16372 trainer.py:139] Epoch[420/1000] loss: 0.22425169311463833
I0803 12:43:06.360833 16372 trainer.py:139] Epoch[421/1000] loss: 0.22430667467415333
I0803 12:43:22.133332 16372 trainer.py:139] Epoch[422/1000] loss: 0.2239625547081232
I0803 12:43:38.473798 16372 trainer.py:139] Epoch[423/1000] loss: 0.22377519495785236
I0803 12:43:54.310739 16372 trainer.py:139] Epoch[424/1000] loss: 0.2249275967478752
I0803 12:44:10.632313 16372 trainer.py:139] Epoch[425/1000] loss: 0.22213830798864365
I0803 12:44:26.651107 16372 trainer.py:139] Epoch[426/1000] loss: 0.22404072061181068
I0803 12:44:42.780282 16372 trainer.py:139] Epoch[427/1000] loss: 0.22509326227009296
I0803 12:44:58.753834 16372 trainer.py:139] Epoch[428/1000] loss: 0.22321635484695435
I0803 12:45:15.667128 16372 trainer.py:139] Epoch[429/1000] loss: 0.22435483522713184
I0803 12:45:32.022036 16372 trainer.py:139] Epoch[430/1000] loss: 0.2243940718472004
I0803 12:45:48.256447 16372 trainer.py:139] Epoch[431/1000] loss: 0.22393894009292126
I0803 12:46:04.179254 16372 trainer.py:139] Epoch[432/1000] loss: 0.22266715206205845
I0803 12:46:20.479767 16372 trainer.py:139] Epoch[433/1000] loss: 0.22399216890335083
I0803 12:46:36.175529 16372 trainer.py:139] Epoch[434/1000] loss: 0.2239548098295927
I0803 12:46:52.025589 16372 trainer.py:139] Epoch[435/1000] loss: 0.2235090546309948
I0803 12:47:07.603791 16372 trainer.py:139] Epoch[436/1000] loss: 0.22329215332865715
I0803 12:47:23.835968 16372 trainer.py:139] Epoch[437/1000] loss: 0.2235877327620983
I0803 12:47:40.444070 16372 trainer.py:139] Epoch[438/1000] loss: 0.22261548787355423
I0803 12:47:56.463648 16372 trainer.py:139] Epoch[439/1000] loss: 0.22311106324195862
I0803 12:48:12.612641 16372 trainer.py:139] Epoch[440/1000] loss: 0.22376355715095997
I0803 12:48:28.489394 16372 trainer.py:139] Epoch[441/1000] loss: 0.22327203676104546
I0803 12:48:44.508758 16372 trainer.py:139] Epoch[442/1000] loss: 0.22349021397531033
I0803 12:49:00.808432 16372 trainer.py:139] Epoch[443/1000] loss: 0.22301862761378288
I0803 12:49:17.371527 16372 trainer.py:139] Epoch[444/1000] loss: 0.22353410720825195
I0803 12:49:33.515260 16372 trainer.py:139] Epoch[445/1000] loss: 0.2227921150624752
I0803 12:49:49.845754 16372 trainer.py:139] Epoch[446/1000] loss: 0.2227411288768053
I0803 12:50:05.374984 16372 trainer.py:139] Epoch[447/1000] loss: 0.2217193078249693
I0803 12:50:21.225069 16372 trainer.py:139] Epoch[448/1000] loss: 0.22352031618356705
I0803 12:50:37.607001 16372 trainer.py:139] Epoch[449/1000] loss: 0.22216169349849224
I0803 12:50:38.191610 16372 trainer.py:145] Test: [{'precision': 0.19167779632721196, 'recall': 0.2687476349497926, 'hit_ratio': 0.9023372287145242, 'ndcg': 0.3012111746656497}]
I0803 12:50:54.057419 16372 trainer.py:139] Epoch[450/1000] loss: 0.22243625484406948
I0803 12:51:10.049823 16372 trainer.py:139] Epoch[451/1000] loss: 0.22307780385017395
I0803 12:51:26.255709 16372 trainer.py:139] Epoch[452/1000] loss: 0.22140365839004517
I0803 12:51:42.957921 16372 trainer.py:139] Epoch[453/1000] loss: 0.22318389639258385
I0803 12:51:59.058998 16372 trainer.py:139] Epoch[454/1000] loss: 0.2229928057640791
I0803 12:52:15.037667 16372 trainer.py:139] Epoch[455/1000] loss: 0.22287833504378796
I0803 12:52:30.953468 16372 trainer.py:139] Epoch[456/1000] loss: 0.22218346782028675
I0803 12:52:46.793286 16372 trainer.py:139] Epoch[457/1000] loss: 0.22165445797145367
I0803 12:53:02.615689 16372 trainer.py:139] Epoch[458/1000] loss: 0.22251764871180058
I0803 12:53:18.711630 16372 trainer.py:139] Epoch[459/1000] loss: 0.22120982222259045
I0803 12:53:34.946225 16372 trainer.py:139] Epoch[460/1000] loss: 0.2229328639805317
I0803 12:53:51.511949 16372 trainer.py:139] Epoch[461/1000] loss: 0.2225882038474083
I0803 12:54:07.465666 16372 trainer.py:139] Epoch[462/1000] loss: 0.22226989828050137
I0803 12:54:23.447613 16372 trainer.py:139] Epoch[463/1000] loss: 0.2214475404471159
I0803 12:54:39.266254 16372 trainer.py:139] Epoch[464/1000] loss: 0.22191292606294155
I0803 12:54:55.258009 16372 trainer.py:139] Epoch[465/1000] loss: 0.22234316542744637
I0803 12:55:11.218727 16372 trainer.py:139] Epoch[466/1000] loss: 0.22192677482962608
I0803 12:55:27.316781 16372 trainer.py:139] Epoch[467/1000] loss: 0.22205597534775734
I0803 12:55:43.024425 16372 trainer.py:139] Epoch[468/1000] loss: 0.22239319421350956
I0803 12:55:58.653557 16372 trainer.py:139] Epoch[469/1000] loss: 0.2218310460448265
I0803 12:56:14.678717 16372 trainer.py:139] Epoch[470/1000] loss: 0.22060451842844486
I0803 12:56:30.811223 16372 trainer.py:139] Epoch[471/1000] loss: 0.2215926442295313
I0803 12:56:46.902394 16372 trainer.py:139] Epoch[472/1000] loss: 0.22283581271767616
I0803 12:57:03.088914 16372 trainer.py:139] Epoch[473/1000] loss: 0.22162752225995064
I0803 12:57:19.145295 16372 trainer.py:139] Epoch[474/1000] loss: 0.2215629555284977
I0803 12:57:35.275054 16372 trainer.py:139] Epoch[475/1000] loss: 0.22169427387416363
I0803 12:57:51.598511 16372 trainer.py:139] Epoch[476/1000] loss: 0.22100102342665195
I0803 12:58:07.599064 16372 trainer.py:139] Epoch[477/1000] loss: 0.22146904654800892
I0803 12:58:24.160253 16372 trainer.py:139] Epoch[478/1000] loss: 0.22092993557453156
I0803 12:58:40.436866 16372 trainer.py:139] Epoch[479/1000] loss: 0.220761114731431
I0803 12:58:56.737294 16372 trainer.py:139] Epoch[480/1000] loss: 0.22105980850756168
I0803 12:59:12.997089 16372 trainer.py:139] Epoch[481/1000] loss: 0.22059975750744343
I0803 12:59:29.163897 16372 trainer.py:139] Epoch[482/1000] loss: 0.22094380855560303
I0803 12:59:45.727011 16372 trainer.py:139] Epoch[483/1000] loss: 0.2215464822947979
I0803 13:00:02.243565 16372 trainer.py:139] Epoch[484/1000] loss: 0.2202749978750944
I0803 13:00:18.333269 16372 trainer.py:139] Epoch[485/1000] loss: 0.220219811424613
I0803 13:00:34.213479 16372 trainer.py:139] Epoch[486/1000] loss: 0.22046497650444508
I0803 13:00:50.352190 16372 trainer.py:139] Epoch[487/1000] loss: 0.2204541563987732
I0803 13:01:06.167454 16372 trainer.py:139] Epoch[488/1000] loss: 0.22082269750535488
I0803 13:01:21.794117 16372 trainer.py:139] Epoch[489/1000] loss: 0.22075153142213821
I0803 13:01:37.557779 16372 trainer.py:139] Epoch[490/1000] loss: 0.22096441313624382
I0803 13:01:53.579314 16372 trainer.py:139] Epoch[491/1000] loss: 0.2207912616431713
I0803 13:02:09.512107 16372 trainer.py:139] Epoch[492/1000] loss: 0.22027486003935337
I0803 13:02:25.601165 16372 trainer.py:139] Epoch[493/1000] loss: 0.21961120329797268
I0803 13:02:41.521135 16372 trainer.py:139] Epoch[494/1000] loss: 0.21941888704895973
I0803 13:02:57.351260 16372 trainer.py:139] Epoch[495/1000] loss: 0.21918000280857086
I0803 13:03:13.277983 16372 trainer.py:139] Epoch[496/1000] loss: 0.22007272392511368
I0803 13:03:29.064282 16372 trainer.py:139] Epoch[497/1000] loss: 0.22030914388597012
I0803 13:03:45.502956 16372 trainer.py:139] Epoch[498/1000] loss: 0.2194683961570263
I0803 13:04:01.282012 16372 trainer.py:139] Epoch[499/1000] loss: 0.21968219801783562
I0803 13:04:01.884565 16372 trainer.py:145] Test: [{'precision': 0.19279632721202003, 'recall': 0.27137952336241267, 'hit_ratio': 0.9063439065108514, 'ndcg': 0.30306373540091364}]
I0803 13:04:18.028691 16372 trainer.py:139] Epoch[500/1000] loss: 0.22036140598356724
I0803 13:04:34.063064 16372 trainer.py:139] Epoch[501/1000] loss: 0.2199260126799345
I0803 13:04:50.447429 16372 trainer.py:139] Epoch[502/1000] loss: 0.22008170373737812
I0803 13:05:06.704787 16372 trainer.py:139] Epoch[503/1000] loss: 0.21966340392827988
I0803 13:05:22.775016 16372 trainer.py:139] Epoch[504/1000] loss: 0.21960163302719593
I0803 13:05:39.060450 16372 trainer.py:139] Epoch[505/1000] loss: 0.2193464133888483
I0803 13:05:54.989221 16372 trainer.py:139] Epoch[506/1000] loss: 0.21899552457034588
I0803 13:06:10.848119 16372 trainer.py:139] Epoch[507/1000] loss: 0.22104284912347794
I0803 13:06:27.298091 16372 trainer.py:139] Epoch[508/1000] loss: 0.21951127611100674
I0803 13:06:43.508658 16372 trainer.py:139] Epoch[509/1000] loss: 0.21981661953032017
I0803 13:06:59.281268 16372 trainer.py:139] Epoch[510/1000] loss: 0.2201063372194767
I0803 13:07:15.169015 16372 trainer.py:139] Epoch[511/1000] loss: 0.21839546784758568
I0803 13:07:30.803771 16372 trainer.py:139] Epoch[512/1000] loss: 0.21971523202955723
I0803 13:07:46.655650 16372 trainer.py:139] Epoch[513/1000] loss: 0.21975795179605484
I0803 13:08:02.553378 16372 trainer.py:139] Epoch[514/1000] loss: 0.21939212456345558
I0803 13:08:18.696481 16372 trainer.py:139] Epoch[515/1000] loss: 0.2202053852379322
I0803 13:08:34.623220 16372 trainer.py:139] Epoch[516/1000] loss: 0.21927575021982193
I0803 13:08:51.089309 16372 trainer.py:139] Epoch[517/1000] loss: 0.21876822598278522
I0803 13:09:07.435626 16372 trainer.py:139] Epoch[518/1000] loss: 0.21805579960346222
I0803 13:09:23.236796 16372 trainer.py:139] Epoch[519/1000] loss: 0.21961784735321999
I0803 13:09:39.201044 16372 trainer.py:139] Epoch[520/1000] loss: 0.21856493316590786
I0803 13:09:55.186281 16372 trainer.py:139] Epoch[521/1000] loss: 0.21871214918792248
I0803 13:10:10.857810 16372 trainer.py:139] Epoch[522/1000] loss: 0.21843311376869678
I0803 13:10:27.225193 16372 trainer.py:139] Epoch[523/1000] loss: 0.21829131990671158
I0803 13:10:43.272974 16372 trainer.py:139] Epoch[524/1000] loss: 0.21944437734782696
I0803 13:10:59.106510 16372 trainer.py:139] Epoch[525/1000] loss: 0.21851690486073494
I0803 13:11:15.137686 16372 trainer.py:139] Epoch[526/1000] loss: 0.2175869159400463
I0803 13:11:31.243422 16372 trainer.py:139] Epoch[527/1000] loss: 0.2200060412287712
I0803 13:11:47.124382 16372 trainer.py:139] Epoch[528/1000] loss: 0.21914744935929775
I0803 13:12:02.900833 16372 trainer.py:139] Epoch[529/1000] loss: 0.21790187247097492
I0803 13:12:18.794633 16372 trainer.py:139] Epoch[530/1000] loss: 0.21865820698440075
I0803 13:12:34.672878 16372 trainer.py:139] Epoch[531/1000] loss: 0.2186512853950262
I0803 13:12:50.459939 16372 trainer.py:139] Epoch[532/1000] loss: 0.2194325216114521
I0803 13:13:06.425186 16372 trainer.py:139] Epoch[533/1000] loss: 0.21878421865403652
I0803 13:13:21.998353 16372 trainer.py:139] Epoch[534/1000] loss: 0.218085166066885
I0803 13:13:37.939346 16372 trainer.py:139] Epoch[535/1000] loss: 0.21860766597092152
I0803 13:13:53.724522 16372 trainer.py:139] Epoch[536/1000] loss: 0.2182939574122429
I0803 13:14:09.670251 16372 trainer.py:139] Epoch[537/1000] loss: 0.21828706935048103
I0803 13:14:25.414727 16372 trainer.py:139] Epoch[538/1000] loss: 0.21840029396116734
I0803 13:14:41.367353 16372 trainer.py:139] Epoch[539/1000] loss: 0.21741992235183716
I0803 13:14:57.130829 16372 trainer.py:139] Epoch[540/1000] loss: 0.2183142937719822
I0803 13:15:12.978425 16372 trainer.py:139] Epoch[541/1000] loss: 0.21808255277574062
I0803 13:15:29.234071 16372 trainer.py:139] Epoch[542/1000] loss: 0.21783967688679695
I0803 13:15:45.486293 16372 trainer.py:139] Epoch[543/1000] loss: 0.21780697256326675
I0803 13:16:02.203126 16372 trainer.py:139] Epoch[544/1000] loss: 0.21864469163119793
I0803 13:16:18.108629 16372 trainer.py:139] Epoch[545/1000] loss: 0.21785219386219978
I0803 13:16:34.126601 16372 trainer.py:139] Epoch[546/1000] loss: 0.2180387768894434
I0803 13:16:49.940738 16372 trainer.py:139] Epoch[547/1000] loss: 0.21733828261494637
I0803 13:17:05.812517 16372 trainer.py:139] Epoch[548/1000] loss: 0.21698449179530144
I0803 13:17:21.982926 16372 trainer.py:139] Epoch[549/1000] loss: 0.21773594431579113
I0803 13:17:22.540062 16372 trainer.py:145] Test: [{'precision': 0.1942821368948247, 'recall': 0.27412143903202263, 'hit_ratio': 0.9068447412353923, 'ndcg': 0.30507213332954014}]
I0803 13:17:38.483634 16372 trainer.py:139] Epoch[550/1000] loss: 0.21706047095358372
I0803 13:17:54.167546 16372 trainer.py:139] Epoch[551/1000] loss: 0.21722427383065224
I0803 13:18:10.238039 16372 trainer.py:139] Epoch[552/1000] loss: 0.21727626770734787
I0803 13:18:25.926612 16372 trainer.py:139] Epoch[553/1000] loss: 0.21800511702895164
I0803 13:18:42.022429 16372 trainer.py:139] Epoch[554/1000] loss: 0.21816875413060188
I0803 13:18:57.996429 16372 trainer.py:139] Epoch[555/1000] loss: 0.21784522756934166
I0803 13:19:13.990111 16372 trainer.py:139] Epoch[556/1000] loss: 0.21840793825685978
I0803 13:19:29.754543 16372 trainer.py:139] Epoch[557/1000] loss: 0.21732784062623978
I0803 13:19:45.980680 16372 trainer.py:139] Epoch[558/1000] loss: 0.21673371456563473
I0803 13:20:01.748943 16372 trainer.py:139] Epoch[559/1000] loss: 0.21727938577532768
I0803 13:20:17.598188 16372 trainer.py:139] Epoch[560/1000] loss: 0.21856596134603024
I0803 13:20:33.680777 16372 trainer.py:139] Epoch[561/1000] loss: 0.2176535800099373
I0803 13:20:49.548881 16372 trainer.py:139] Epoch[562/1000] loss: 0.21662242524325848
I0803 13:21:05.774869 16372 trainer.py:139] Epoch[563/1000] loss: 0.217748761177063
I0803 13:21:22.260396 16372 trainer.py:139] Epoch[564/1000] loss: 0.21792160347104073
I0803 13:21:38.359494 16372 trainer.py:139] Epoch[565/1000] loss: 0.21657653339207172
I0803 13:21:54.555375 16372 trainer.py:139] Epoch[566/1000] loss: 0.21650035679340363
I0803 13:22:10.400439 16372 trainer.py:139] Epoch[567/1000] loss: 0.21613436192274094
I0803 13:22:26.259295 16372 trainer.py:139] Epoch[568/1000] loss: 0.21598461084067822
I0803 13:22:42.420326 16372 trainer.py:139] Epoch[569/1000] loss: 0.21699786558747292
I0803 13:22:58.330945 16372 trainer.py:139] Epoch[570/1000] loss: 0.21718670055270195
I0803 13:23:14.091347 16372 trainer.py:139] Epoch[571/1000] loss: 0.2170407585799694
I0803 13:23:30.152620 16372 trainer.py:139] Epoch[572/1000] loss: 0.21679033152759075
I0803 13:23:46.259210 16372 trainer.py:139] Epoch[573/1000] loss: 0.21688822470605373
I0803 13:24:02.265558 16372 trainer.py:139] Epoch[574/1000] loss: 0.2158875409513712
I0803 13:24:18.116336 16372 trainer.py:139] Epoch[575/1000] loss: 0.21661355905234814
I0803 13:24:34.191537 16372 trainer.py:139] Epoch[576/1000] loss: 0.21712967194616795
I0803 13:24:50.259924 16372 trainer.py:139] Epoch[577/1000] loss: 0.2169218547642231
I0803 13:25:06.146038 16372 trainer.py:139] Epoch[578/1000] loss: 0.2149982899427414
I0803 13:25:21.946188 16372 trainer.py:139] Epoch[579/1000] loss: 0.21681107953190804
I0803 13:25:37.854901 16372 trainer.py:139] Epoch[580/1000] loss: 0.21622956730425358
I0803 13:25:53.523893 16372 trainer.py:139] Epoch[581/1000] loss: 0.2172231711447239
I0803 13:26:09.506503 16372 trainer.py:139] Epoch[582/1000] loss: 0.21653448417782784
I0803 13:26:25.674664 16372 trainer.py:139] Epoch[583/1000] loss: 0.21513349004089832
I0803 13:26:41.690858 16372 trainer.py:139] Epoch[584/1000] loss: 0.2163666058331728
I0803 13:26:57.520855 16372 trainer.py:139] Epoch[585/1000] loss: 0.217527586966753
I0803 13:27:13.519188 16372 trainer.py:139] Epoch[586/1000] loss: 0.21595680341124535
I0803 13:27:29.839060 16372 trainer.py:139] Epoch[587/1000] loss: 0.2165131215006113
I0803 13:27:45.849386 16372 trainer.py:139] Epoch[588/1000] loss: 0.2157493308186531
I0803 13:28:02.112054 16372 trainer.py:139] Epoch[589/1000] loss: 0.21612801402807236
I0803 13:28:18.184353 16372 trainer.py:139] Epoch[590/1000] loss: 0.21577336266636848
I0803 13:28:34.225778 16372 trainer.py:139] Epoch[591/1000] loss: 0.21645312942564487
I0803 13:28:49.885194 16372 trainer.py:139] Epoch[592/1000] loss: 0.21645209193229675
I0803 13:29:05.468377 16372 trainer.py:139] Epoch[593/1000] loss: 0.21611514128744602
I0803 13:29:21.233121 16372 trainer.py:139] Epoch[594/1000] loss: 0.214796619489789
I0803 13:29:37.600293 16372 trainer.py:139] Epoch[595/1000] loss: 0.2158010397106409
I0803 13:29:53.646520 16372 trainer.py:139] Epoch[596/1000] loss: 0.2160974219441414
I0803 13:30:10.176939 16372 trainer.py:139] Epoch[597/1000] loss: 0.2155113685876131
I0803 13:30:25.939994 16372 trainer.py:139] Epoch[598/1000] loss: 0.2158596608787775
I0803 13:30:41.593876 16372 trainer.py:139] Epoch[599/1000] loss: 0.2161648739129305
I0803 13:30:42.213353 16372 trainer.py:145] Test: [{'precision': 0.19499999999999992, 'recall': 0.27474897778312374, 'hit_ratio': 0.9063439065108514, 'ndcg': 0.3068855362062133}]
I0803 13:30:57.823134 16372 trainer.py:139] Epoch[600/1000] loss: 0.21611089073121548
I0803 13:31:13.568782 16372 trainer.py:139] Epoch[601/1000] loss: 0.21487285196781158
I0803 13:31:29.673112 16372 trainer.py:139] Epoch[602/1000] loss: 0.2156380284577608
I0803 13:31:45.546546 16372 trainer.py:139] Epoch[603/1000] loss: 0.21523783914744854
I0803 13:32:02.044470 16372 trainer.py:139] Epoch[604/1000] loss: 0.21592841297388077
I0803 13:32:17.837614 16372 trainer.py:139] Epoch[605/1000] loss: 0.21602739952504635
I0803 13:32:33.537361 16372 trainer.py:139] Epoch[606/1000] loss: 0.2148445751518011
I0803 13:32:49.441224 16372 trainer.py:139] Epoch[607/1000] loss: 0.21599295549094677
I0803 13:33:05.296169 16372 trainer.py:139] Epoch[608/1000] loss: 0.21501681581139565
I0803 13:33:21.247661 16372 trainer.py:139] Epoch[609/1000] loss: 0.21478694304823875
I0803 13:33:37.335557 16372 trainer.py:139] Epoch[610/1000] loss: 0.21521237306296825
I0803 13:33:53.117743 16372 trainer.py:139] Epoch[611/1000] loss: 0.21542817167937756
I0803 13:34:09.104331 16372 trainer.py:139] Epoch[612/1000] loss: 0.21408088132739067
I0803 13:34:25.308973 16372 trainer.py:139] Epoch[613/1000] loss: 0.21505154483020306
I0803 13:34:41.469358 16372 trainer.py:139] Epoch[614/1000] loss: 0.2149197794497013
I0803 13:34:57.318973 16372 trainer.py:139] Epoch[615/1000] loss: 0.21424780040979385
I0803 13:35:13.663084 16372 trainer.py:139] Epoch[616/1000] loss: 0.2154600415378809
I0803 13:35:29.748989 16372 trainer.py:139] Epoch[617/1000] loss: 0.2155182771384716
I0803 13:35:46.126139 16372 trainer.py:139] Epoch[618/1000] loss: 0.2152740489691496
I0803 13:36:02.235484 16372 trainer.py:139] Epoch[619/1000] loss: 0.21539644710719585
I0803 13:36:18.318593 16372 trainer.py:139] Epoch[620/1000] loss: 0.21619398891925812
I0803 13:36:34.486606 16372 trainer.py:139] Epoch[621/1000] loss: 0.21462170779705048
I0803 13:36:50.374964 16372 trainer.py:139] Epoch[622/1000] loss: 0.2149744238704443
I0803 13:37:05.997404 16372 trainer.py:139] Epoch[623/1000] loss: 0.21485829539597034
I0803 13:37:21.817980 16372 trainer.py:139] Epoch[624/1000] loss: 0.21571137197315693
I0803 13:37:37.977079 16372 trainer.py:139] Epoch[625/1000] loss: 0.2140867169946432
I0803 13:37:53.761078 16372 trainer.py:139] Epoch[626/1000] loss: 0.21357264928519726
I0803 13:38:09.631721 16372 trainer.py:139] Epoch[627/1000] loss: 0.21567744761705399
I0803 13:38:25.522346 16372 trainer.py:139] Epoch[628/1000] loss: 0.21432441659271717
I0803 13:38:41.277417 16372 trainer.py:139] Epoch[629/1000] loss: 0.21468788385391235
I0803 13:38:57.493976 16372 trainer.py:139] Epoch[630/1000] loss: 0.21405624970793724
I0803 13:39:13.802832 16372 trainer.py:139] Epoch[631/1000] loss: 0.21463439986109734
I0803 13:39:29.536316 16372 trainer.py:139] Epoch[632/1000] loss: 0.21431756764650345
I0803 13:39:45.757856 16372 trainer.py:139] Epoch[633/1000] loss: 0.21549548767507076
I0803 13:40:01.840846 16372 trainer.py:139] Epoch[634/1000] loss: 0.21511551178991795
I0803 13:40:17.827677 16372 trainer.py:139] Epoch[635/1000] loss: 0.213411258533597
I0803 13:40:33.829493 16372 trainer.py:139] Epoch[636/1000] loss: 0.21522005647420883
I0803 13:40:49.834511 16372 trainer.py:139] Epoch[637/1000] loss: 0.21327139623463154
I0803 13:41:05.555194 16372 trainer.py:139] Epoch[638/1000] loss: 0.21352526918053627
I0803 13:41:21.820235 16372 trainer.py:139] Epoch[639/1000] loss: 0.21399985253810883
I0803 13:41:37.836613 16372 trainer.py:139] Epoch[640/1000] loss: 0.21434945054352283
I0803 13:41:53.624458 16372 trainer.py:139] Epoch[641/1000] loss: 0.2136342078447342
I0803 13:42:09.527975 16372 trainer.py:139] Epoch[642/1000] loss: 0.21401694603264332
I0803 13:42:25.174424 16372 trainer.py:139] Epoch[643/1000] loss: 0.21446643583476543
I0803 13:42:41.346395 16372 trainer.py:139] Epoch[644/1000] loss: 0.21296806819736958
I0803 13:42:57.348937 16372 trainer.py:139] Epoch[645/1000] loss: 0.21343802101910114
I0803 13:43:12.851781 16372 trainer.py:139] Epoch[646/1000] loss: 0.21315951272845268
I0803 13:43:28.758217 16372 trainer.py:139] Epoch[647/1000] loss: 0.21408376097679138
I0803 13:43:44.594797 16372 trainer.py:139] Epoch[648/1000] loss: 0.2137443907558918
I0803 13:44:00.540489 16372 trainer.py:139] Epoch[649/1000] loss: 0.21420059725642204
I0803 13:44:01.121143 16372 trainer.py:145] Test: [{'precision': 0.19571786310517528, 'recall': 0.2755910806156449, 'hit_ratio': 0.9068447412353923, 'ndcg': 0.3080398395081395}]
I0803 13:44:17.320322 16372 trainer.py:139] Epoch[650/1000] loss: 0.21379157155752182
I0803 13:44:33.653993 16372 trainer.py:139] Epoch[651/1000] loss: 0.2133653238415718
I0803 13:44:50.196017 16372 trainer.py:139] Epoch[652/1000] loss: 0.21425501443445683
I0803 13:45:06.075906 16372 trainer.py:139] Epoch[653/1000] loss: 0.21362727507948875
I0803 13:45:22.315498 16372 trainer.py:139] Epoch[654/1000] loss: 0.2137720212340355
I0803 13:45:38.317380 16372 trainer.py:139] Epoch[655/1000] loss: 0.2137669436633587
I0803 13:45:54.017776 16372 trainer.py:139] Epoch[656/1000] loss: 0.21371773444116116
I0803 13:46:10.040097 16372 trainer.py:139] Epoch[657/1000] loss: 0.21306919492781162
I0803 13:46:25.968761 16372 trainer.py:139] Epoch[658/1000] loss: 0.2135526593774557
I0803 13:46:41.881841 16372 trainer.py:139] Epoch[659/1000] loss: 0.21441945806145668
I0803 13:46:57.454292 16372 trainer.py:139] Epoch[660/1000] loss: 0.21451385132968426
I0803 13:47:13.716382 16372 trainer.py:139] Epoch[661/1000] loss: 0.213600879535079
I0803 13:47:29.808359 16372 trainer.py:139] Epoch[662/1000] loss: 0.21376015804708004
I0803 13:47:45.869089 16372 trainer.py:139] Epoch[663/1000] loss: 0.21381106227636337
I0803 13:48:01.712691 16372 trainer.py:139] Epoch[664/1000] loss: 0.2133733183145523
I0803 13:48:17.895164 16372 trainer.py:139] Epoch[665/1000] loss: 0.2133130319416523
I0803 13:48:33.929028 16372 trainer.py:139] Epoch[666/1000] loss: 0.21378982812166214
I0803 13:48:49.651408 16372 trainer.py:139] Epoch[667/1000] loss: 0.2128350678831339
I0803 13:49:05.886312 16372 trainer.py:139] Epoch[668/1000] loss: 0.2129834070801735
I0803 13:49:21.975092 16372 trainer.py:139] Epoch[669/1000] loss: 0.2133314609527588
I0803 13:49:37.876814 16372 trainer.py:139] Epoch[670/1000] loss: 0.21403479762375355
I0803 13:49:53.628060 16372 trainer.py:139] Epoch[671/1000] loss: 0.21312637254595757
I0803 13:50:09.646381 16372 trainer.py:139] Epoch[672/1000] loss: 0.21265818178653717
I0803 13:50:25.769978 16372 trainer.py:139] Epoch[673/1000] loss: 0.21328802034258842
I0803 13:50:42.041860 16372 trainer.py:139] Epoch[674/1000] loss: 0.2136376015841961
I0803 13:50:58.102612 16372 trainer.py:139] Epoch[675/1000] loss: 0.21285072714090347
I0803 13:51:13.977333 16372 trainer.py:139] Epoch[676/1000] loss: 0.21364758349955082
I0803 13:51:30.165072 16372 trainer.py:139] Epoch[677/1000] loss: 0.21357698552310467
I0803 13:51:46.102751 16372 trainer.py:139] Epoch[678/1000] loss: 0.21293341927230358
I0803 13:52:02.144381 16372 trainer.py:139] Epoch[679/1000] loss: 0.21252270601689816
I0803 13:52:18.175702 16372 trainer.py:139] Epoch[680/1000] loss: 0.21316584944725037
I0803 13:52:33.831339 16372 trainer.py:139] Epoch[681/1000] loss: 0.2127501517534256
I0803 13:52:49.606756 16372 trainer.py:139] Epoch[682/1000] loss: 0.2128958236426115
I0803 13:53:05.398630 16372 trainer.py:139] Epoch[683/1000] loss: 0.21380703710019588
I0803 13:53:22.102172 16372 trainer.py:139] Epoch[684/1000] loss: 0.21288050338625908
I0803 13:53:38.442413 16372 trainer.py:139] Epoch[685/1000] loss: 0.21291165053844452
I0803 13:53:54.458682 16372 trainer.py:139] Epoch[686/1000] loss: 0.21399258077144623
I0803 13:54:10.143959 16372 trainer.py:139] Epoch[687/1000] loss: 0.21299932338297367
I0803 13:54:25.950052 16372 trainer.py:139] Epoch[688/1000] loss: 0.21307340636849403
I0803 13:54:41.684440 16372 trainer.py:139] Epoch[689/1000] loss: 0.2112964615225792
I0803 13:54:57.430916 16372 trainer.py:139] Epoch[690/1000] loss: 0.21230891719460487
I0803 13:55:13.064759 16372 trainer.py:139] Epoch[691/1000] loss: 0.212915463373065
I0803 13:55:29.425060 16372 trainer.py:139] Epoch[692/1000] loss: 0.21350098587572575
I0803 13:55:45.857492 16372 trainer.py:139] Epoch[693/1000] loss: 0.21231053210794926
I0803 13:56:01.869673 16372 trainer.py:139] Epoch[694/1000] loss: 0.21157850325107574
I0803 13:56:17.961801 16372 trainer.py:139] Epoch[695/1000] loss: 0.21167357824742794
I0803 13:56:33.940934 16372 trainer.py:139] Epoch[696/1000] loss: 0.21322619542479515
I0803 13:56:50.220784 16372 trainer.py:139] Epoch[697/1000] loss: 0.21274248138070107
I0803 13:57:06.082674 16372 trainer.py:139] Epoch[698/1000] loss: 0.21253344975411892
I0803 13:57:22.239316 16372 trainer.py:139] Epoch[699/1000] loss: 0.21298134699463844
I0803 13:57:22.809008 16372 trainer.py:145] Test: [{'precision': 0.19674457429048414, 'recall': 0.27734006017769036, 'hit_ratio': 0.9065108514190318, 'ndcg': 0.30956377214287145}]
I0803 13:57:39.211631 16372 trainer.py:139] Epoch[700/1000] loss: 0.21234423853456974
I0803 13:57:55.149595 16372 trainer.py:139] Epoch[701/1000] loss: 0.21241206116974354
I0803 13:58:11.123153 16372 trainer.py:139] Epoch[702/1000] loss: 0.21220757625997066
I0803 13:58:27.133361 16372 trainer.py:139] Epoch[703/1000] loss: 0.21291857585310936
I0803 13:58:43.308203 16372 trainer.py:139] Epoch[704/1000] loss: 0.2117383722215891
I0803 13:58:59.172170 16372 trainer.py:139] Epoch[705/1000] loss: 0.21199804544448853
I0803 13:59:15.299718 16372 trainer.py:139] Epoch[706/1000] loss: 0.2131334524601698
I0803 13:59:31.461544 16372 trainer.py:139] Epoch[707/1000] loss: 0.21305795945227146
I0803 13:59:47.730026 16372 trainer.py:139] Epoch[708/1000] loss: 0.21304654143750668
I0803 14:00:03.689948 16372 trainer.py:139] Epoch[709/1000] loss: 0.21218431740999222
I0803 14:00:19.444856 16372 trainer.py:139] Epoch[710/1000] loss: 0.21294963918626308
I0803 14:00:35.062018 16372 trainer.py:139] Epoch[711/1000] loss: 0.21326174214482307
I0803 14:00:51.139317 16372 trainer.py:139] Epoch[712/1000] loss: 0.21232855319976807
I0803 14:01:06.784814 16372 trainer.py:139] Epoch[713/1000] loss: 0.21259237080812454
I0803 14:01:22.699891 16372 trainer.py:139] Epoch[714/1000] loss: 0.21178824454545975
I0803 14:01:38.716108 16372 trainer.py:139] Epoch[715/1000] loss: 0.21233257092535496
I0803 14:01:54.549705 16372 trainer.py:139] Epoch[716/1000] loss: 0.21229080855846405
I0803 14:02:10.535677 16372 trainer.py:139] Epoch[717/1000] loss: 0.21231797523796558
I0803 14:02:26.607742 16372 trainer.py:139] Epoch[718/1000] loss: 0.21228300593793392
I0803 14:02:42.812091 16372 trainer.py:139] Epoch[719/1000] loss: 0.21280547603964806
I0803 14:02:58.704100 16372 trainer.py:139] Epoch[720/1000] loss: 0.21215909346938133
I0803 14:03:15.091676 16372 trainer.py:139] Epoch[721/1000] loss: 0.21117081493139267
I0803 14:03:31.030153 16372 trainer.py:139] Epoch[722/1000] loss: 0.21138408407568932
I0803 14:03:46.931766 16372 trainer.py:139] Epoch[723/1000] loss: 0.2127646654844284
I0803 14:04:03.569679 16372 trainer.py:139] Epoch[724/1000] loss: 0.2118032816797495
I0803 14:04:19.160424 16372 trainer.py:139] Epoch[725/1000] loss: 0.2114371955394745
I0803 14:04:34.894450 16372 trainer.py:139] Epoch[726/1000] loss: 0.21119174361228943
I0803 14:04:51.078989 16372 trainer.py:139] Epoch[727/1000] loss: 0.2118911761790514
I0803 14:05:06.813663 16372 trainer.py:139] Epoch[728/1000] loss: 0.2108778990805149
I0803 14:05:22.734070 16372 trainer.py:139] Epoch[729/1000] loss: 0.21100165508687496
I0803 14:05:38.692492 16372 trainer.py:139] Epoch[730/1000] loss: 0.2109286915510893
I0803 14:05:54.478938 16372 trainer.py:139] Epoch[731/1000] loss: 0.21278294175863266
I0803 14:06:10.136745 16372 trainer.py:139] Epoch[732/1000] loss: 0.21032763458788395
I0803 14:06:25.916919 16372 trainer.py:139] Epoch[733/1000] loss: 0.21262185461819172
I0803 14:06:41.873608 16372 trainer.py:139] Epoch[734/1000] loss: 0.21215013042092323
I0803 14:06:58.001197 16372 trainer.py:139] Epoch[735/1000] loss: 0.21137794107198715
I0803 14:07:14.292721 16372 trainer.py:139] Epoch[736/1000] loss: 0.2114508245140314
I0803 14:07:30.067298 16372 trainer.py:139] Epoch[737/1000] loss: 0.2119962014257908
I0803 14:07:46.049548 16372 trainer.py:139] Epoch[738/1000] loss: 0.21164644323289394
I0803 14:08:01.789283 16372 trainer.py:139] Epoch[739/1000] loss: 0.2111314907670021
I0803 14:08:17.713387 16372 trainer.py:139] Epoch[740/1000] loss: 0.2104450762271881
I0803 14:08:33.709765 16372 trainer.py:139] Epoch[741/1000] loss: 0.21091395802795887
I0803 14:08:49.771892 16372 trainer.py:139] Epoch[742/1000] loss: 0.210840230807662
I0803 14:09:05.818600 16372 trainer.py:139] Epoch[743/1000] loss: 0.21035332791507244
I0803 14:09:22.030764 16372 trainer.py:139] Epoch[744/1000] loss: 0.2112772986292839
I0803 14:09:38.460895 16372 trainer.py:139] Epoch[745/1000] loss: 0.211454838514328
I0803 14:09:54.523243 16372 trainer.py:139] Epoch[746/1000] loss: 0.21102464757859707
I0803 14:10:10.501066 16372 trainer.py:139] Epoch[747/1000] loss: 0.21078743413090706
I0803 14:10:26.351037 16372 trainer.py:139] Epoch[748/1000] loss: 0.21043173968791962
I0803 14:10:42.229952 16372 trainer.py:139] Epoch[749/1000] loss: 0.2119462788105011
I0803 14:10:42.849412 16372 trainer.py:145] Test: [{'precision': 0.19723706176961603, 'recall': 0.27749791356745696, 'hit_ratio': 0.9058430717863105, 'ndcg': 0.310879511345533}]
I0803 14:10:58.611747 16372 trainer.py:139] Epoch[750/1000] loss: 0.21145647019147873
I0803 14:11:15.199922 16372 trainer.py:139] Epoch[751/1000] loss: 0.2119749467819929
I0803 14:11:31.760612 16372 trainer.py:139] Epoch[752/1000] loss: 0.21069115586578846
I0803 14:11:47.568663 16372 trainer.py:139] Epoch[753/1000] loss: 0.21055882796645164
I0803 14:12:03.214514 16372 trainer.py:139] Epoch[754/1000] loss: 0.21021223068237305
I0803 14:12:19.067215 16372 trainer.py:139] Epoch[755/1000] loss: 0.21115098893642426
I0803 14:12:35.069557 16372 trainer.py:139] Epoch[756/1000] loss: 0.2111582476645708
I0803 14:12:50.837761 16372 trainer.py:139] Epoch[757/1000] loss: 0.21076994575560093
I0803 14:13:06.569361 16372 trainer.py:139] Epoch[758/1000] loss: 0.21096946857869625
I0803 14:13:22.701587 16372 trainer.py:139] Epoch[759/1000] loss: 0.2103466223925352
I0803 14:13:38.790578 16372 trainer.py:139] Epoch[760/1000] loss: 0.21172528713941574
I0803 14:13:54.725465 16372 trainer.py:139] Epoch[761/1000] loss: 0.21160119771957397
I0803 14:14:10.680149 16372 trainer.py:139] Epoch[762/1000] loss: 0.2101093102246523
I0803 14:14:26.916188 16372 trainer.py:139] Epoch[763/1000] loss: 0.21010525152087212
I0803 14:14:42.915856 16372 trainer.py:139] Epoch[764/1000] loss: 0.21182115375995636
I0803 14:14:58.747208 16372 trainer.py:139] Epoch[765/1000] loss: 0.2108207307755947
I0803 14:15:15.148954 16372 trainer.py:139] Epoch[766/1000] loss: 0.2112231757491827
I0803 14:15:31.138322 16372 trainer.py:139] Epoch[767/1000] loss: 0.20965830981731415
I0803 14:15:47.075228 16372 trainer.py:139] Epoch[768/1000] loss: 0.21074439398944378
I0803 14:16:03.107333 16372 trainer.py:139] Epoch[769/1000] loss: 0.21093659475445747
I0803 14:16:19.244376 16372 trainer.py:139] Epoch[770/1000] loss: 0.21097685024142265
I0803 14:16:34.998618 16372 trainer.py:139] Epoch[771/1000] loss: 0.21046021580696106
I0803 14:16:50.900929 16372 trainer.py:139] Epoch[772/1000] loss: 0.21156485006213188
I0803 14:17:06.542923 16372 trainer.py:139] Epoch[773/1000] loss: 0.21023625880479813
I0803 14:17:22.530490 16372 trainer.py:139] Epoch[774/1000] loss: 0.21088459342718124
I0803 14:17:38.890074 16372 trainer.py:139] Epoch[775/1000] loss: 0.2104936446994543
I0803 14:17:54.624781 16372 trainer.py:139] Epoch[776/1000] loss: 0.21066115237772465
I0803 14:18:10.350356 16372 trainer.py:139] Epoch[777/1000] loss: 0.20992057025432587
I0803 14:18:26.116208 16372 trainer.py:139] Epoch[778/1000] loss: 0.21156026795506477
I0803 14:18:42.000021 16372 trainer.py:139] Epoch[779/1000] loss: 0.21105200238525867
I0803 14:18:57.601189 16372 trainer.py:139] Epoch[780/1000] loss: 0.2095829714089632
I0803 14:19:13.402535 16372 trainer.py:139] Epoch[781/1000] loss: 0.20942049100995064
I0803 14:19:29.260655 16372 trainer.py:139] Epoch[782/1000] loss: 0.2104583326727152
I0803 14:19:45.257385 16372 trainer.py:139] Epoch[783/1000] loss: 0.21055870689451694
I0803 14:20:01.224740 16372 trainer.py:139] Epoch[784/1000] loss: 0.21077315509319305
I0803 14:20:17.199361 16372 trainer.py:139] Epoch[785/1000] loss: 0.21054594591259956
I0803 14:20:33.710985 16372 trainer.py:139] Epoch[786/1000] loss: 0.20942074619233608
I0803 14:20:49.644869 16372 trainer.py:139] Epoch[787/1000] loss: 0.21040901355445385
I0803 14:21:05.554383 16372 trainer.py:139] Epoch[788/1000] loss: 0.21039438247680664
I0803 14:21:21.573719 16372 trainer.py:139] Epoch[789/1000] loss: 0.21125785261392593
I0803 14:21:37.536225 16372 trainer.py:139] Epoch[790/1000] loss: 0.20989112742245197
I0803 14:21:53.750695 16372 trainer.py:139] Epoch[791/1000] loss: 0.21137269958853722
I0803 14:22:09.754205 16372 trainer.py:139] Epoch[792/1000] loss: 0.20973478443920612
I0803 14:22:25.747164 16372 trainer.py:139] Epoch[793/1000] loss: 0.21073690801858902
I0803 14:22:41.509881 16372 trainer.py:139] Epoch[794/1000] loss: 0.20960895344614983
I0803 14:22:57.613584 16372 trainer.py:139] Epoch[795/1000] loss: 0.20917781069874763
I0803 14:23:13.972914 16372 trainer.py:139] Epoch[796/1000] loss: 0.2088756151497364
I0803 14:23:30.080200 16372 trainer.py:139] Epoch[797/1000] loss: 0.2096636388450861
I0803 14:23:46.209976 16372 trainer.py:139] Epoch[798/1000] loss: 0.20969758555293083
I0803 14:24:02.482420 16372 trainer.py:139] Epoch[799/1000] loss: 0.21001124754548073
I0803 14:24:03.027144 16372 trainer.py:145] Test: [{'precision': 0.19768781302170277, 'recall': 0.27839733116412, 'hit_ratio': 0.906677796327212, 'ndcg': 0.3117577581400354}]
I0803 14:24:18.950463 16372 trainer.py:139] Epoch[800/1000] loss: 0.20976364240050316
I0803 14:24:34.889208 16372 trainer.py:139] Epoch[801/1000] loss: 0.2096316423267126
I0803 14:24:50.611068 16372 trainer.py:139] Epoch[802/1000] loss: 0.21123328432440758
I0803 14:25:06.146160 16372 trainer.py:139] Epoch[803/1000] loss: 0.21021291054785252
I0803 14:25:22.369515 16372 trainer.py:139] Epoch[804/1000] loss: 0.2095075622200966
I0803 14:25:38.340988 16372 trainer.py:139] Epoch[805/1000] loss: 0.21070586517453194
I0803 14:25:53.973616 16372 trainer.py:139] Epoch[806/1000] loss: 0.2099899686872959
I0803 14:26:09.929519 16372 trainer.py:139] Epoch[807/1000] loss: 0.20957967266440392
I0803 14:26:25.987016 16372 trainer.py:139] Epoch[808/1000] loss: 0.21055381186306477
I0803 14:26:41.974576 16372 trainer.py:139] Epoch[809/1000] loss: 0.21002267114818096
I0803 14:26:58.211340 16372 trainer.py:139] Epoch[810/1000] loss: 0.2092815786600113
I0803 14:27:14.839367 16372 trainer.py:139] Epoch[811/1000] loss: 0.20984525047242641
I0803 14:27:31.232764 16372 trainer.py:139] Epoch[812/1000] loss: 0.20955139957368374
I0803 14:27:47.109067 16372 trainer.py:139] Epoch[813/1000] loss: 0.2087668515741825
I0803 14:28:03.390176 16372 trainer.py:139] Epoch[814/1000] loss: 0.21027596108615398
I0803 14:28:19.354925 16372 trainer.py:139] Epoch[815/1000] loss: 0.20924853906035423
I0803 14:28:35.199667 16372 trainer.py:139] Epoch[816/1000] loss: 0.209388280287385
I0803 14:28:51.135427 16372 trainer.py:139] Epoch[817/1000] loss: 0.209346367046237
I0803 14:29:06.886693 16372 trainer.py:139] Epoch[818/1000] loss: 0.2090649399906397
I0803 14:29:22.896990 16372 trainer.py:139] Epoch[819/1000] loss: 0.20890563912689686
I0803 14:29:38.991251 16372 trainer.py:139] Epoch[820/1000] loss: 0.20833586901426315
I0803 14:29:55.187116 16372 trainer.py:139] Epoch[821/1000] loss: 0.21009141951799393
I0803 14:30:11.232976 16372 trainer.py:139] Epoch[822/1000] loss: 0.2089456468820572
I0803 14:30:27.154268 16372 trainer.py:139] Epoch[823/1000] loss: 0.20894981361925602
I0803 14:30:43.116233 16372 trainer.py:139] Epoch[824/1000] loss: 0.20943382009863853
I0803 14:30:59.176646 16372 trainer.py:139] Epoch[825/1000] loss: 0.20933305099606514
I0803 14:31:14.938792 16372 trainer.py:139] Epoch[826/1000] loss: 0.20873096026480198
I0803 14:31:30.633154 16372 trainer.py:139] Epoch[827/1000] loss: 0.209066117182374
I0803 14:31:46.389020 16372 trainer.py:139] Epoch[828/1000] loss: 0.20910414680838585
I0803 14:32:02.032498 16372 trainer.py:139] Epoch[829/1000] loss: 0.20865792408585548
I0803 14:32:18.492744 16372 trainer.py:139] Epoch[830/1000] loss: 0.2085129301995039
I0803 14:32:34.624805 16372 trainer.py:139] Epoch[831/1000] loss: 0.20940442010760307
I0803 14:32:50.798259 16372 trainer.py:139] Epoch[832/1000] loss: 0.20938928984105587
I0803 14:33:07.172788 16372 trainer.py:139] Epoch[833/1000] loss: 0.20911902748048306
I0803 14:33:23.833194 16372 trainer.py:139] Epoch[834/1000] loss: 0.2094371933490038
I0803 14:33:40.206250 16372 trainer.py:139] Epoch[835/1000] loss: 0.20936115644872189
I0803 14:33:56.697025 16372 trainer.py:139] Epoch[836/1000] loss: 0.2094607651233673
I0803 14:34:12.785993 16372 trainer.py:139] Epoch[837/1000] loss: 0.2097521275281906
I0803 14:34:29.054495 16372 trainer.py:139] Epoch[838/1000] loss: 0.20910370163619518
I0803 14:34:45.543409 16372 trainer.py:139] Epoch[839/1000] loss: 0.20954849757254124
I0803 14:35:01.590489 16372 trainer.py:139] Epoch[840/1000] loss: 0.20844843424856663
I0803 14:35:18.413552 16372 trainer.py:139] Epoch[841/1000] loss: 0.20935013704001904
I0803 14:35:34.940736 16372 trainer.py:139] Epoch[842/1000] loss: 0.20902184955775738
I0803 14:35:51.439120 16372 trainer.py:139] Epoch[843/1000] loss: 0.20859788171947002
I0803 14:36:07.556667 16372 trainer.py:139] Epoch[844/1000] loss: 0.20815588906407356
I0803 14:36:23.697130 16372 trainer.py:139] Epoch[845/1000] loss: 0.2081936802715063
I0803 14:36:40.009044 16372 trainer.py:139] Epoch[846/1000] loss: 0.20914354175329208
I0803 14:36:56.182961 16372 trainer.py:139] Epoch[847/1000] loss: 0.2088928408920765
I0803 14:37:12.406999 16372 trainer.py:139] Epoch[848/1000] loss: 0.20899763144552708
I0803 14:37:28.372482 16372 trainer.py:139] Epoch[849/1000] loss: 0.20993959344923496
I0803 14:37:28.989981 16372 trainer.py:145] Test: [{'precision': 0.1980050083472454, 'recall': 0.2796047548405562, 'hit_ratio': 0.9086811352253756, 'ndcg': 0.3124513611680094}]
I0803 14:37:45.432881 16372 trainer.py:139] Epoch[850/1000] loss: 0.20881386287510395
I0803 14:38:01.359532 16372 trainer.py:139] Epoch[851/1000] loss: 0.20925749093294144
I0803 14:38:17.461249 16372 trainer.py:139] Epoch[852/1000] loss: 0.20878488384187222
I0803 14:38:33.274450 16372 trainer.py:139] Epoch[853/1000] loss: 0.20839893072843552
I0803 14:38:49.394324 16372 trainer.py:139] Epoch[854/1000] loss: 0.20838921703398228
I0803 14:39:05.457025 16372 trainer.py:139] Epoch[855/1000] loss: 0.20798813365399837
I0803 14:39:22.005092 16372 trainer.py:139] Epoch[856/1000] loss: 0.20796657167375088
I0803 14:39:38.285239 16372 trainer.py:139] Epoch[857/1000] loss: 0.2095744777470827
I0803 14:39:54.159174 16372 trainer.py:139] Epoch[858/1000] loss: 0.20902658253908157
I0803 14:40:10.147267 16372 trainer.py:139] Epoch[859/1000] loss: 0.20939075201749802
I0803 14:40:26.144613 16372 trainer.py:139] Epoch[860/1000] loss: 0.20871030166745186
I0803 14:40:41.991108 16372 trainer.py:139] Epoch[861/1000] loss: 0.20965338125824928
I0803 14:40:57.874010 16372 trainer.py:139] Epoch[862/1000] loss: 0.20772618241608143
I0803 14:41:13.909662 16372 trainer.py:139] Epoch[863/1000] loss: 0.20858972147107124
I0803 14:41:30.422866 16372 trainer.py:139] Epoch[864/1000] loss: 0.20830382220447063
I0803 14:41:46.231721 16372 trainer.py:139] Epoch[865/1000] loss: 0.20849130116403103
I0803 14:42:02.461185 16372 trainer.py:139] Epoch[866/1000] loss: 0.20908554457128048
I0803 14:42:18.360831 16372 trainer.py:139] Epoch[867/1000] loss: 0.2084000911563635
I0803 14:42:34.156517 16372 trainer.py:139] Epoch[868/1000] loss: 0.2070522904396057
I0803 14:42:49.726872 16372 trainer.py:139] Epoch[869/1000] loss: 0.2073537316173315
I0803 14:43:05.989106 16372 trainer.py:139] Epoch[870/1000] loss: 0.20903633162379265
I0803 14:43:22.103880 16372 trainer.py:139] Epoch[871/1000] loss: 0.2081629503518343
I0803 14:43:37.702754 16372 trainer.py:139] Epoch[872/1000] loss: 0.20764422789216042
I0803 14:43:53.683195 16372 trainer.py:139] Epoch[873/1000] loss: 0.20940737426280975
I0803 14:44:09.401391 16372 trainer.py:139] Epoch[874/1000] loss: 0.20891547948122025
I0803 14:44:25.398853 16372 trainer.py:139] Epoch[875/1000] loss: 0.20848554372787476
I0803 14:44:41.950919 16372 trainer.py:139] Epoch[876/1000] loss: 0.20869198814034462
I0803 14:44:58.116338 16372 trainer.py:139] Epoch[877/1000] loss: 0.20819832384586334
I0803 14:45:13.983248 16372 trainer.py:139] Epoch[878/1000] loss: 0.20752443373203278
I0803 14:45:29.943216 16372 trainer.py:139] Epoch[879/1000] loss: 0.20771137066185474
I0803 14:45:46.476253 16372 trainer.py:139] Epoch[880/1000] loss: 0.20807546004652977
I0803 14:46:02.299220 16372 trainer.py:139] Epoch[881/1000] loss: 0.20920578949153423
I0803 14:46:18.621475 16372 trainer.py:139] Epoch[882/1000] loss: 0.2075810469686985
I0803 14:46:34.627894 16372 trainer.py:139] Epoch[883/1000] loss: 0.20869289711117744
I0803 14:46:50.716632 16372 trainer.py:139] Epoch[884/1000] loss: 0.20946530438959599
I0803 14:47:06.764598 16372 trainer.py:139] Epoch[885/1000] loss: 0.20797947235405445
I0803 14:47:22.964965 16372 trainer.py:139] Epoch[886/1000] loss: 0.2082930989563465
I0803 14:47:38.949328 16372 trainer.py:139] Epoch[887/1000] loss: 0.20844713784754276
I0803 14:47:54.658432 16372 trainer.py:139] Epoch[888/1000] loss: 0.20784262381494045
I0803 14:48:10.587835 16372 trainer.py:139] Epoch[889/1000] loss: 0.2076979298144579
I0803 14:48:26.610417 16372 trainer.py:139] Epoch[890/1000] loss: 0.2080204114317894
I0803 14:48:42.581185 16372 trainer.py:139] Epoch[891/1000] loss: 0.208284055814147
I0803 14:48:58.142831 16372 trainer.py:139] Epoch[892/1000] loss: 0.20848473533988
I0803 14:49:14.036393 16372 trainer.py:139] Epoch[893/1000] loss: 0.2076063696295023
I0803 14:49:29.941890 16372 trainer.py:139] Epoch[894/1000] loss: 0.2083081416785717
I0803 14:49:45.610590 16372 trainer.py:139] Epoch[895/1000] loss: 0.20808905363082886
I0803 14:50:01.230634 16372 trainer.py:139] Epoch[896/1000] loss: 0.20910387486219406
I0803 14:50:17.143732 16372 trainer.py:139] Epoch[897/1000] loss: 0.2067468110471964
I0803 14:50:33.202882 16372 trainer.py:139] Epoch[898/1000] loss: 0.20941604115068913
I0803 14:50:49.221957 16372 trainer.py:139] Epoch[899/1000] loss: 0.2076511364430189
I0803 14:50:49.799577 16372 trainer.py:145] Test: [{'precision': 0.19869782971619362, 'recall': 0.2804900659733578, 'hit_ratio': 0.9096828046744574, 'ndcg': 0.3133525257016337}]
I0803 14:51:05.763183 16372 trainer.py:139] Epoch[900/1000] loss: 0.2073932010680437
I0803 14:51:22.279633 16372 trainer.py:139] Epoch[901/1000] loss: 0.20723419822752476
I0803 14:51:38.199365 16372 trainer.py:139] Epoch[902/1000] loss: 0.20894098840653896
I0803 14:51:54.365424 16372 trainer.py:139] Epoch[903/1000] loss: 0.20751244015991688
I0803 14:52:10.516261 16372 trainer.py:139] Epoch[904/1000] loss: 0.20905010774731636
I0803 14:52:26.498810 16372 trainer.py:139] Epoch[905/1000] loss: 0.2073009591549635
I0803 14:52:42.470885 16372 trainer.py:139] Epoch[906/1000] loss: 0.20821192301809788
I0803 14:52:58.452129 16372 trainer.py:139] Epoch[907/1000] loss: 0.20783679746091366
I0803 14:53:14.580749 16372 trainer.py:139] Epoch[908/1000] loss: 0.2067873328924179
I0803 14:53:30.830203 16372 trainer.py:139] Epoch[909/1000] loss: 0.20749247446656227
I0803 14:53:46.827633 16372 trainer.py:139] Epoch[910/1000] loss: 0.20820962078869343
I0803 14:54:02.692442 16372 trainer.py:139] Epoch[911/1000] loss: 0.2074765730649233
I0803 14:54:18.818250 16372 trainer.py:139] Epoch[912/1000] loss: 0.20761470682919025
I0803 14:54:34.863348 16372 trainer.py:139] Epoch[913/1000] loss: 0.20680025219917297
I0803 14:54:50.398921 16372 trainer.py:139] Epoch[914/1000] loss: 0.207535021007061
I0803 14:55:06.373496 16372 trainer.py:139] Epoch[915/1000] loss: 0.2074356097728014
I0803 14:55:22.533345 16372 trainer.py:139] Epoch[916/1000] loss: 0.20676345191895962
I0803 14:55:38.131004 16372 trainer.py:139] Epoch[917/1000] loss: 0.2077212780714035
I0803 14:55:54.019592 16372 trainer.py:139] Epoch[918/1000] loss: 0.20802404545247555
I0803 14:56:09.979579 16372 trainer.py:139] Epoch[919/1000] loss: 0.2080566268414259
I0803 14:56:25.950353 16372 trainer.py:139] Epoch[920/1000] loss: 0.20745445229113102
I0803 14:56:42.124179 16372 trainer.py:139] Epoch[921/1000] loss: 0.20846153981983662
I0803 14:56:58.267164 16372 trainer.py:139] Epoch[922/1000] loss: 0.20765391364693642
I0803 14:57:14.833808 16372 trainer.py:139] Epoch[923/1000] loss: 0.2074142023921013
I0803 14:57:30.951651 16372 trainer.py:139] Epoch[924/1000] loss: 0.20713490061461926
I0803 14:57:46.806575 16372 trainer.py:139] Epoch[925/1000] loss: 0.20723394118249416
I0803 14:58:02.547375 16372 trainer.py:139] Epoch[926/1000] loss: 0.20759215205907822
I0803 14:58:18.238320 16372 trainer.py:139] Epoch[927/1000] loss: 0.20706665143370628
I0803 14:58:34.203792 16372 trainer.py:139] Epoch[928/1000] loss: 0.20743604935705662
I0803 14:58:50.202751 16372 trainer.py:139] Epoch[929/1000] loss: 0.20681126974523067
I0803 14:59:05.895808 16372 trainer.py:139] Epoch[930/1000] loss: 0.20730463229119778
I0803 14:59:22.491530 16372 trainer.py:139] Epoch[931/1000] loss: 0.20827575959265232
I0803 14:59:38.909877 16372 trainer.py:139] Epoch[932/1000] loss: 0.20852399431169033
I0803 14:59:55.247021 16372 trainer.py:139] Epoch[933/1000] loss: 0.20657171867787838
I0803 15:00:12.966315 16372 trainer.py:139] Epoch[934/1000] loss: 0.20731906965374947
I0803 15:00:29.446271 16372 trainer.py:139] Epoch[935/1000] loss: 0.20699257776141167
I0803 15:00:45.573797 16372 trainer.py:139] Epoch[936/1000] loss: 0.20696008764207363
I0803 15:01:01.688517 16372 trainer.py:139] Epoch[937/1000] loss: 0.20761536620557308
I0803 15:01:17.920674 16372 trainer.py:139] Epoch[938/1000] loss: 0.20646293833851814
I0803 15:01:33.650057 16372 trainer.py:139] Epoch[939/1000] loss: 0.20630100555717945
I0803 15:01:49.438107 16372 trainer.py:139] Epoch[940/1000] loss: 0.2069233190268278
I0803 15:02:05.880541 16372 trainer.py:139] Epoch[941/1000] loss: 0.20774820819497108
I0803 15:02:21.870306 16372 trainer.py:139] Epoch[942/1000] loss: 0.207445552572608
I0803 15:02:38.501636 16372 trainer.py:139] Epoch[943/1000] loss: 0.20800908096134663
I0803 15:02:54.886680 16372 trainer.py:139] Epoch[944/1000] loss: 0.20702187344431877
I0803 15:03:11.175534 16372 trainer.py:139] Epoch[945/1000] loss: 0.20672933384776115
I0803 15:03:27.658344 16372 trainer.py:139] Epoch[946/1000] loss: 0.20689342729747295
I0803 15:03:44.027178 16372 trainer.py:139] Epoch[947/1000] loss: 0.2075140755623579
I0803 15:04:00.494073 16372 trainer.py:139] Epoch[948/1000] loss: 0.20736907981336117
I0803 15:04:16.610037 16372 trainer.py:139] Epoch[949/1000] loss: 0.20769205316901207
I0803 15:04:17.187653 16372 trainer.py:145] Test: [{'precision': 0.19887312186978293, 'recall': 0.2805623850765572, 'hit_ratio': 0.9086811352253756, 'ndcg': 0.31382963434719047}]
I0803 15:04:33.300982 16372 trainer.py:139] Epoch[950/1000] loss: 0.20712585002183914
I0803 15:04:49.556063 16372 trainer.py:139] Epoch[951/1000] loss: 0.207698380574584
I0803 15:05:07.152266 16372 trainer.py:139] Epoch[952/1000] loss: 0.20767201483249664
I0803 15:05:25.231400 16372 trainer.py:139] Epoch[953/1000] loss: 0.20695361867547035
I0803 15:05:43.903613 16372 trainer.py:139] Epoch[954/1000] loss: 0.20681983418762684
I0803 15:06:03.242383 16372 trainer.py:139] Epoch[955/1000] loss: 0.20747537724673748
I0803 15:06:22.007987 16372 trainer.py:139] Epoch[956/1000] loss: 0.20609254948794842
I0803 15:06:40.009123 16372 trainer.py:139] Epoch[957/1000] loss: 0.2079947628080845
I0803 15:06:57.817263 16372 trainer.py:139] Epoch[958/1000] loss: 0.20679248869419098
I0803 15:07:15.937009 16372 trainer.py:139] Epoch[959/1000] loss: 0.20698090642690659
I0803 15:07:34.586623 16372 trainer.py:139] Epoch[960/1000] loss: 0.2064979374408722
I0803 15:07:56.624619 16372 trainer.py:139] Epoch[961/1000] loss: 0.20683085173368454
I0803 15:08:15.176464 16372 trainer.py:139] Epoch[962/1000] loss: 0.2071871142834425
I0803 15:08:33.398060 16372 trainer.py:139] Epoch[963/1000] loss: 0.2063589170575142
I0803 15:08:51.373229 16372 trainer.py:139] Epoch[964/1000] loss: 0.207228260114789
I0803 15:09:09.474884 16372 trainer.py:139] Epoch[965/1000] loss: 0.20623831264674664
I0803 15:09:27.770183 16372 trainer.py:139] Epoch[966/1000] loss: 0.20771325752139091
I0803 15:09:46.016336 16372 trainer.py:139] Epoch[967/1000] loss: 0.20824962481856346
I0803 15:10:03.855342 16372 trainer.py:139] Epoch[968/1000] loss: 0.20613504946231842
I0803 15:10:21.535057 16372 trainer.py:139] Epoch[969/1000] loss: 0.2068693656474352
I0803 15:10:40.005962 16372 trainer.py:139] Epoch[970/1000] loss: 0.20543973706662655
I0803 15:10:58.249382 16372 trainer.py:139] Epoch[971/1000] loss: 0.20630447939038277
I0803 15:11:16.656581 16372 trainer.py:139] Epoch[972/1000] loss: 0.20591680333018303
I0803 15:11:35.179855 16372 trainer.py:139] Epoch[973/1000] loss: 0.20771081745624542
I0803 15:11:53.295878 16372 trainer.py:139] Epoch[974/1000] loss: 0.20756427012383938
I0803 15:12:11.391205 16372 trainer.py:139] Epoch[975/1000] loss: 0.20678376033902168
I0803 15:12:29.863659 16372 trainer.py:139] Epoch[976/1000] loss: 0.20817015133798122
I0803 15:12:48.076332 16372 trainer.py:139] Epoch[977/1000] loss: 0.20604314096271992
I0803 15:13:06.204409 16372 trainer.py:139] Epoch[978/1000] loss: 0.20703343488276005
I0803 15:13:23.636786 16372 trainer.py:139] Epoch[979/1000] loss: 0.2062397636473179
I0803 15:13:41.260478 16372 trainer.py:139] Epoch[980/1000] loss: 0.20654080249369144
I0803 15:13:58.704263 16372 trainer.py:139] Epoch[981/1000] loss: 0.20594601519405842
I0803 15:14:16.547838 16372 trainer.py:139] Epoch[982/1000] loss: 0.2066397238522768
I0803 15:14:34.810148 16372 trainer.py:139] Epoch[983/1000] loss: 0.2064424566924572
I0803 15:14:52.677925 16372 trainer.py:139] Epoch[984/1000] loss: 0.20491451397538185
I0803 15:15:11.181711 16372 trainer.py:139] Epoch[985/1000] loss: 0.20741048268973827
I0803 15:15:29.025023 16372 trainer.py:139] Epoch[986/1000] loss: 0.2064143419265747
I0803 15:15:47.218369 16372 trainer.py:139] Epoch[987/1000] loss: 0.20584548637270927
I0803 15:16:05.418405 16372 trainer.py:139] Epoch[988/1000] loss: 0.20557304844260216
I0803 15:16:23.316555 16372 trainer.py:139] Epoch[989/1000] loss: 0.2058127298951149
I0803 15:16:40.711479 16372 trainer.py:139] Epoch[990/1000] loss: 0.205589160323143
I0803 15:16:58.962529 16372 trainer.py:139] Epoch[991/1000] loss: 0.2065421175211668
I0803 15:17:16.378186 16372 trainer.py:139] Epoch[992/1000] loss: 0.20631697587668896
I0803 15:17:33.504788 16372 trainer.py:139] Epoch[993/1000] loss: 0.2061704695224762
I0803 15:17:50.486776 16372 trainer.py:139] Epoch[994/1000] loss: 0.20616095699369907
I0803 15:18:07.127577 16372 trainer.py:139] Epoch[995/1000] loss: 0.2066162507981062
I0803 15:18:23.858566 16372 trainer.py:139] Epoch[996/1000] loss: 0.20620235987007618
I0803 15:18:42.567988 16372 trainer.py:139] Epoch[997/1000] loss: 0.2067638821899891
I0803 15:19:00.567670 16372 trainer.py:139] Epoch[998/1000] loss: 0.2060451190918684
I0803 15:19:18.196678 16372 trainer.py:139] Epoch[999/1000] loss: 0.20560082606971264
I0803 15:19:18.844052 16372 trainer.py:145] Test: [{'precision': 0.19932387312186972, 'recall': 0.2810404099963731, 'hit_ratio': 0.9091819699499165, 'ndcg': 0.3144440005191601}]
