I0422 15:51:57.145641 34428 trainer.py:118] Test: [{'precision': 0.0055373432155074115, 'recall': 0.01976548078652784, 'hit_ratio': 0.07440136830102623, 'ndcg': 0.015321780835830762}]
I0422 15:52:01.260528 34428 trainer.py:136] Epoch[0/1000] loss: 0.6951980392138163
I0422 15:52:05.306180 34428 trainer.py:136] Epoch[1/1000] loss: 0.6898847917715708
I0422 15:52:09.285669 34428 trainer.py:136] Epoch[2/1000] loss: 0.6861187020937601
I0422 15:52:13.029908 34428 trainer.py:136] Epoch[3/1000] loss: 0.6822704076766968
I0422 15:52:16.965060 34428 trainer.py:136] Epoch[4/1000] loss: 0.6778905590375265
I0422 15:52:20.753768 34428 trainer.py:136] Epoch[5/1000] loss: 0.673948218425115
I0422 15:52:24.730437 34428 trainer.py:136] Epoch[6/1000] loss: 0.6708779732386271
I0422 15:52:28.764425 34428 trainer.py:136] Epoch[7/1000] loss: 0.6665912369887034
I0422 15:52:32.586952 34428 trainer.py:136] Epoch[8/1000] loss: 0.6627073884010315
I0422 15:52:36.442364 34428 trainer.py:136] Epoch[9/1000] loss: 0.6575383444627126
I0422 15:52:40.442239 34428 trainer.py:136] Epoch[10/1000] loss: 0.653415193160375
I0422 15:52:44.722587 34428 trainer.py:136] Epoch[11/1000] loss: 0.6475506027539571
I0422 15:52:48.757857 34428 trainer.py:136] Epoch[12/1000] loss: 0.6434606115023295
I0422 15:52:53.149485 34428 trainer.py:136] Epoch[13/1000] loss: 0.6369786957899729
I0422 15:52:57.229296 34428 trainer.py:136] Epoch[14/1000] loss: 0.6314403812090555
I0422 15:53:01.207248 34428 trainer.py:136] Epoch[15/1000] loss: 0.6243964731693268
I0422 15:53:05.184385 34428 trainer.py:136] Epoch[16/1000] loss: 0.6176810562610626
I0422 15:53:09.181421 34428 trainer.py:136] Epoch[17/1000] loss: 0.6106994152069092
I0422 15:53:13.274036 34428 trainer.py:136] Epoch[18/1000] loss: 0.6023524006207784
I0422 15:53:17.193272 34428 trainer.py:136] Epoch[19/1000] loss: 0.5950648387273153
I0422 15:53:21.195298 34428 trainer.py:136] Epoch[20/1000] loss: 0.5868963201840719
I0422 15:53:25.119495 34428 trainer.py:136] Epoch[21/1000] loss: 0.5775047739346822
I0422 15:53:29.120503 34428 trainer.py:136] Epoch[22/1000] loss: 0.5691096087296804
I0422 15:53:33.296794 34428 trainer.py:136] Epoch[23/1000] loss: 0.5610326528549194
I0422 15:53:37.464735 34428 trainer.py:136] Epoch[24/1000] loss: 0.551749994357427
I0422 15:53:41.926299 34428 trainer.py:136] Epoch[25/1000] loss: 0.5414603253205618
I0422 15:53:45.873441 34428 trainer.py:136] Epoch[26/1000] loss: 0.5323816537857056
I0422 15:53:49.942793 34428 trainer.py:136] Epoch[27/1000] loss: 0.5230225821336111
I0422 15:53:54.055759 34428 trainer.py:136] Epoch[28/1000] loss: 0.5155470569928488
I0422 15:53:58.028804 34428 trainer.py:136] Epoch[29/1000] loss: 0.5049209843079249
I0422 15:54:02.163152 34428 trainer.py:136] Epoch[30/1000] loss: 0.49660690625508624
I0422 15:54:06.459918 34428 trainer.py:136] Epoch[31/1000] loss: 0.48712803423404694
I0422 15:54:10.580523 34428 trainer.py:136] Epoch[32/1000] loss: 0.47749649981657666
I0422 15:54:14.805817 34428 trainer.py:136] Epoch[33/1000] loss: 0.4696192393700282
I0422 15:54:18.952192 34428 trainer.py:136] Epoch[34/1000] loss: 0.4599718352158864
I0422 15:54:23.937779 34428 trainer.py:136] Epoch[35/1000] loss: 0.45116671919822693
I0422 15:54:28.649271 34428 trainer.py:136] Epoch[36/1000] loss: 0.44345525403817493
I0422 15:54:32.843195 34428 trainer.py:136] Epoch[37/1000] loss: 0.4338299334049225
I0422 15:54:36.862075 34428 trainer.py:136] Epoch[38/1000] loss: 0.42668285469214123
I0422 15:54:40.913839 34428 trainer.py:136] Epoch[39/1000] loss: 0.4196919898192088
I0422 15:54:45.270080 34428 trainer.py:136] Epoch[40/1000] loss: 0.4109831750392914
I0422 15:54:49.417397 34428 trainer.py:136] Epoch[41/1000] loss: 0.40432381133238476
I0422 15:54:53.852493 34428 trainer.py:136] Epoch[42/1000] loss: 0.39753269652525586
I0422 15:54:58.124030 34428 trainer.py:136] Epoch[43/1000] loss: 0.39096466700236004
I0422 15:55:02.328631 34428 trainer.py:136] Epoch[44/1000] loss: 0.38230808079242706
I0422 15:55:06.659824 34428 trainer.py:136] Epoch[45/1000] loss: 0.37629572053750354
I0422 15:55:11.030452 34428 trainer.py:136] Epoch[46/1000] loss: 0.3695969084898631
I0422 15:55:15.518914 34428 trainer.py:136] Epoch[47/1000] loss: 0.362522155046463
I0422 15:55:20.153234 34428 trainer.py:136] Epoch[48/1000] loss: 0.35453533629576367
I0422 15:55:24.914349 34428 trainer.py:136] Epoch[49/1000] loss: 0.3503139515717824
I0422 15:55:26.391218 34428 trainer.py:142] Test: [{'precision': 0.01385404789053591, 'recall': 0.06535458608858943, 'hit_ratio': 0.1878563283922463, 'ndcg': 0.04382478687348692}]
I0422 15:55:30.896625 34428 trainer.py:136] Epoch[50/1000] loss: 0.34580929080645245
I0422 15:55:35.436484 34428 trainer.py:136] Epoch[51/1000] loss: 0.33884474138418835
I0422 15:55:39.853802 34428 trainer.py:136] Epoch[52/1000] loss: 0.33335307240486145
I0422 15:55:44.256048 34428 trainer.py:136] Epoch[53/1000] loss: 0.3290929247935613
I0422 15:55:48.490167 34428 trainer.py:136] Epoch[54/1000] loss: 0.32248449822266895
I0422 15:55:52.806064 34428 trainer.py:136] Epoch[55/1000] loss: 0.31653913855552673
I0422 15:55:57.059129 34428 trainer.py:136] Epoch[56/1000] loss: 0.31255384782950085
I0422 15:56:01.325615 34428 trainer.py:136] Epoch[57/1000] loss: 0.3070172220468521
I0422 15:56:06.110619 34428 trainer.py:136] Epoch[58/1000] loss: 0.30313583215077716
I0422 15:56:10.737641 34428 trainer.py:136] Epoch[59/1000] loss: 0.30054110785325366
I0422 15:56:15.490568 34428 trainer.py:136] Epoch[60/1000] loss: 0.2930361131827037
I0422 15:56:20.033708 34428 trainer.py:136] Epoch[61/1000] loss: 0.2906960000594457
I0422 15:56:24.819668 34428 trainer.py:136] Epoch[62/1000] loss: 0.28566105167071026
I0422 15:56:29.431147 34428 trainer.py:136] Epoch[63/1000] loss: 0.2810893754164378
I0422 15:56:34.114222 34428 trainer.py:136] Epoch[64/1000] loss: 0.28090595205624896
I0422 15:56:38.866990 34428 trainer.py:136] Epoch[65/1000] loss: 0.2758459597826004
I0422 15:56:43.844156 34428 trainer.py:136] Epoch[66/1000] loss: 0.2702082445224126
I0422 15:56:48.528815 34428 trainer.py:136] Epoch[67/1000] loss: 0.2681029836336772
I0422 15:56:53.277619 34428 trainer.py:136] Epoch[68/1000] loss: 0.26394028464953107
I0422 15:56:57.939990 34428 trainer.py:136] Epoch[69/1000] loss: 0.26068321863810223
I0422 15:57:02.838612 34428 trainer.py:136] Epoch[70/1000] loss: 0.2562598834435145
I0422 15:57:07.378825 34428 trainer.py:136] Epoch[71/1000] loss: 0.2542361666758855
I0422 15:57:11.934705 34428 trainer.py:136] Epoch[72/1000] loss: 0.2516172875960668
I0422 15:57:18.485859 34428 trainer.py:136] Epoch[73/1000] loss: 0.24760315815607706
I0422 15:57:23.464459 34428 trainer.py:136] Epoch[74/1000] loss: 0.24332033097743988
I0422 15:57:27.990469 34428 trainer.py:136] Epoch[75/1000] loss: 0.24239027500152588
I0422 15:57:32.657376 34428 trainer.py:136] Epoch[76/1000] loss: 0.23986207197109857
I0422 15:57:37.519649 34428 trainer.py:136] Epoch[77/1000] loss: 0.23835669457912445
I0422 15:57:42.087675 34428 trainer.py:136] Epoch[78/1000] loss: 0.2347493494550387
I0422 15:57:46.528324 34428 trainer.py:136] Epoch[79/1000] loss: 0.23355400065581003
I0422 15:57:51.067994 34428 trainer.py:136] Epoch[80/1000] loss: 0.22992091129223505
I0422 15:57:55.910235 34428 trainer.py:136] Epoch[81/1000] loss: 0.22725221266349158
I0422 15:58:03.337526 34428 trainer.py:136] Epoch[82/1000] loss: 0.22550399353106818
I0422 15:58:07.960820 34428 trainer.py:136] Epoch[83/1000] loss: 0.22185932596524557
I0422 15:58:12.486527 34428 trainer.py:136] Epoch[84/1000] loss: 0.21992811808983484
I0422 15:58:17.089402 34428 trainer.py:136] Epoch[85/1000] loss: 0.21824215849240622
I0422 15:58:21.811399 34428 trainer.py:136] Epoch[86/1000] loss: 0.21427450825770697
I0422 15:58:29.070729 34428 trainer.py:136] Epoch[87/1000] loss: 0.21184991548458734
I0422 15:58:33.820565 34428 trainer.py:136] Epoch[88/1000] loss: 0.2122503121693929
I0422 15:58:38.595537 34428 trainer.py:136] Epoch[89/1000] loss: 0.21128840247790018
I0422 15:58:43.436252 34428 trainer.py:136] Epoch[90/1000] loss: 0.20853473991155624
I0422 15:58:49.386076 34428 trainer.py:136] Epoch[91/1000] loss: 0.206393301486969
I0422 15:58:55.033842 34428 trainer.py:136] Epoch[92/1000] loss: 0.20553013930718103
I0422 15:58:59.500284 34428 trainer.py:136] Epoch[93/1000] loss: 0.20184815675020218
I0422 15:59:04.357123 34428 trainer.py:136] Epoch[94/1000] loss: 0.20013606548309326
I0422 15:59:09.880296 34428 trainer.py:136] Epoch[95/1000] loss: 0.19781692077716193
I0422 15:59:16.729100 34428 trainer.py:136] Epoch[96/1000] loss: 0.19704179217418036
I0422 15:59:21.424232 34428 trainer.py:136] Epoch[97/1000] loss: 0.19576201091210046
I0422 15:59:26.197126 34428 trainer.py:136] Epoch[98/1000] loss: 0.19268961995840073
I0422 15:59:30.896801 34428 trainer.py:136] Epoch[99/1000] loss: 0.19278626392285028
I0422 15:59:32.494641 34428 trainer.py:142] Test: [{'precision': 0.014352907639680721, 'recall': 0.06844725837562043, 'hit_ratio': 0.19555302166476624, 'ndcg': 0.04590756832303802}]
I0422 15:59:37.039864 34428 trainer.py:136] Epoch[100/1000] loss: 0.19307291011015573
I0422 15:59:43.916411 34428 trainer.py:136] Epoch[101/1000] loss: 0.18716787050167719
I0422 15:59:48.909372 34428 trainer.py:136] Epoch[102/1000] loss: 0.18914392093817392
I0422 15:59:53.598603 34428 trainer.py:136] Epoch[103/1000] loss: 0.1855380137761434
I0422 15:59:58.441428 34428 trainer.py:136] Epoch[104/1000] loss: 0.1840056007107099
I0422 16:00:05.690461 34428 trainer.py:136] Epoch[105/1000] loss: 0.18476567169030508
I0422 16:00:10.326121 34428 trainer.py:136] Epoch[106/1000] loss: 0.18245198825995126
I0422 16:00:14.857137 34428 trainer.py:136] Epoch[107/1000] loss: 0.18043823291858038
I0422 16:00:19.326020 34428 trainer.py:136] Epoch[108/1000] loss: 0.17995050301154455
I0422 16:00:23.818429 34428 trainer.py:136] Epoch[109/1000] loss: 0.17864594608545303
I0422 16:00:29.345795 34428 trainer.py:136] Epoch[110/1000] loss: 0.17683261384566626
I0422 16:00:35.473051 34428 trainer.py:136] Epoch[111/1000] loss: 0.17730935911337534
I0422 16:00:40.025244 34428 trainer.py:136] Epoch[112/1000] loss: 0.1742808868487676
I0422 16:00:44.517693 34428 trainer.py:136] Epoch[113/1000] loss: 0.17273829132318497
I0422 16:00:49.005043 34428 trainer.py:136] Epoch[114/1000] loss: 0.17258075127998987
I0422 16:00:53.520385 34428 trainer.py:136] Epoch[115/1000] loss: 0.17090115447839102
I0422 16:00:58.615345 34428 trainer.py:136] Epoch[116/1000] loss: 0.16976632922887802
I0422 16:01:04.884961 34428 trainer.py:136] Epoch[117/1000] loss: 0.1693249593178431
I0422 16:01:09.377193 34428 trainer.py:136] Epoch[118/1000] loss: 0.16766391942898431
I0422 16:01:13.874666 34428 trainer.py:136] Epoch[119/1000] loss: 0.16822957495848337
I0422 16:01:18.603245 34428 trainer.py:136] Epoch[120/1000] loss: 0.16735468804836273
I0422 16:01:25.360533 34428 trainer.py:136] Epoch[121/1000] loss: 0.16452468931674957
I0422 16:01:30.089620 34428 trainer.py:136] Epoch[122/1000] loss: 0.16420774161815643
I0422 16:01:34.768646 34428 trainer.py:136] Epoch[123/1000] loss: 0.16443946460882822
I0422 16:01:39.458068 34428 trainer.py:136] Epoch[124/1000] loss: 0.16251218815644583
I0422 16:01:43.990704 34428 trainer.py:136] Epoch[125/1000] loss: 0.16151698182026544
I0422 16:01:48.464154 34428 trainer.py:136] Epoch[126/1000] loss: 0.15960968534151712
I0422 16:01:55.300340 34428 trainer.py:136] Epoch[127/1000] loss: 0.15985201547543207
I0422 16:01:59.839344 34428 trainer.py:136] Epoch[128/1000] loss: 0.1599709317088127
I0422 16:02:04.601528 34428 trainer.py:136] Epoch[129/1000] loss: 0.158182921508948
I0422 16:02:09.493745 34428 trainer.py:136] Epoch[130/1000] loss: 0.15666204939285913
I0422 16:02:16.981382 34428 trainer.py:136] Epoch[131/1000] loss: 0.15524124105771384
I0422 16:02:21.856724 34428 trainer.py:136] Epoch[132/1000] loss: 0.1549247826139132
I0422 16:02:26.565009 34428 trainer.py:136] Epoch[133/1000] loss: 0.15354694426059723
I0422 16:02:32.673170 34428 trainer.py:136] Epoch[134/1000] loss: 0.15251519282658896
I0422 16:02:38.683495 34428 trainer.py:136] Epoch[135/1000] loss: 0.15412255376577377
I0422 16:02:43.098021 34428 trainer.py:136] Epoch[136/1000] loss: 0.15334443499644598
I0422 16:02:47.544648 34428 trainer.py:136] Epoch[137/1000] loss: 0.15171942859888077
I0422 16:02:54.015464 34428 trainer.py:136] Epoch[138/1000] loss: 0.1509065181016922
I0422 16:02:59.579724 34428 trainer.py:136] Epoch[139/1000] loss: 0.1491688589255015
I0422 16:03:04.055117 34428 trainer.py:136] Epoch[140/1000] loss: 0.15009473512570062
I0422 16:03:08.496938 34428 trainer.py:136] Epoch[141/1000] loss: 0.14886982490619025
I0422 16:03:12.891514 34428 trainer.py:136] Epoch[142/1000] loss: 0.1486028035481771
I0422 16:03:18.856604 34428 trainer.py:136] Epoch[143/1000] loss: 0.1471865971883138
I0422 16:03:24.360061 34428 trainer.py:136] Epoch[144/1000] loss: 0.1468548501531283
I0422 16:03:28.927981 34428 trainer.py:136] Epoch[145/1000] loss: 0.14733810226122537
I0422 16:03:33.307733 34428 trainer.py:136] Epoch[146/1000] loss: 0.1443013995885849
I0422 16:03:37.797078 34428 trainer.py:136] Epoch[147/1000] loss: 0.1440963273247083
I0422 16:03:42.921906 34428 trainer.py:136] Epoch[148/1000] loss: 0.144242229561011
I0422 16:03:49.072553 34428 trainer.py:136] Epoch[149/1000] loss: 0.1428743153810501
I0422 16:03:50.635453 34428 trainer.py:142] Test: [{'precision': 0.014858893956670463, 'recall': 0.0709452239657505, 'hit_ratio': 0.20496009122006842, 'ndcg': 0.04717950379617598}]
I0422 16:03:55.006053 34428 trainer.py:136] Epoch[150/1000] loss: 0.14188416302204132
I0422 16:03:59.732523 34428 trainer.py:136] Epoch[151/1000] loss: 0.1403449426094691
I0422 16:04:05.401938 34428 trainer.py:136] Epoch[152/1000] loss: 0.14153078943490982
I0422 16:04:11.826678 34428 trainer.py:136] Epoch[153/1000] loss: 0.1406696488459905
I0422 16:04:16.455742 34428 trainer.py:136] Epoch[154/1000] loss: 0.14069708933432898
I0422 16:04:21.266162 34428 trainer.py:136] Epoch[155/1000] loss: 0.13908346245686212
I0422 16:04:26.091390 34428 trainer.py:136] Epoch[156/1000] loss: 0.13889338821172714
I0422 16:04:33.657094 34428 trainer.py:136] Epoch[157/1000] loss: 0.1386545573671659
I0422 16:04:38.195831 34428 trainer.py:136] Epoch[158/1000] loss: 0.13710236301024756
I0422 16:04:42.712973 34428 trainer.py:136] Epoch[159/1000] loss: 0.13777904957532883
I0422 16:04:47.091583 34428 trainer.py:136] Epoch[160/1000] loss: 0.1382613703608513
I0422 16:04:54.184743 34428 trainer.py:136] Epoch[161/1000] loss: 0.1347506046295166
I0422 16:04:58.912698 34428 trainer.py:136] Epoch[162/1000] loss: 0.13657486687103906
I0422 16:05:03.523776 34428 trainer.py:136] Epoch[163/1000] loss: 0.13654448091983795
I0422 16:05:08.102100 34428 trainer.py:136] Epoch[164/1000] loss: 0.13477182388305664
I0422 16:05:13.812947 34428 trainer.py:136] Epoch[165/1000] loss: 0.13396173218886057
I0422 16:05:20.251004 34428 trainer.py:136] Epoch[166/1000] loss: 0.13564548393090567
I0422 16:05:25.027287 34428 trainer.py:136] Epoch[167/1000] loss: 0.13411094496647516
I0422 16:05:29.845556 34428 trainer.py:136] Epoch[168/1000] loss: 0.13242634882529578
I0422 16:05:37.073572 34428 trainer.py:136] Epoch[169/1000] loss: 0.13203810900449753
I0422 16:05:41.495941 34428 trainer.py:136] Epoch[170/1000] loss: 0.1317805623014768
I0422 16:05:45.844377 34428 trainer.py:136] Epoch[171/1000] loss: 0.13136324286460876
I0422 16:05:50.214291 34428 trainer.py:136] Epoch[172/1000] loss: 0.1301524688800176
I0422 16:05:54.677405 34428 trainer.py:136] Epoch[173/1000] loss: 0.13097905864318213
I0422 16:06:01.680476 34428 trainer.py:136] Epoch[174/1000] loss: 0.13113369047641754
I0422 16:06:06.239709 34428 trainer.py:136] Epoch[175/1000] loss: 0.12880331774552664
I0422 16:06:10.879179 34428 trainer.py:136] Epoch[176/1000] loss: 0.12985086937745413
I0422 16:06:15.306793 34428 trainer.py:136] Epoch[177/1000] loss: 0.12945564091205597
I0422 16:06:21.387057 34428 trainer.py:136] Epoch[178/1000] loss: 0.12949003279209137
I0422 16:06:27.043039 34428 trainer.py:136] Epoch[179/1000] loss: 0.12920263906319937
I0422 16:06:31.375420 34428 trainer.py:136] Epoch[180/1000] loss: 0.12670706709225973
I0422 16:06:36.018247 34428 trainer.py:136] Epoch[181/1000] loss: 0.12777768447995186
I0422 16:06:40.518875 34428 trainer.py:136] Epoch[182/1000] loss: 0.1269861782590548
I0422 16:06:45.103075 34428 trainer.py:136] Epoch[183/1000] loss: 0.12744601567586264
I0422 16:06:52.175769 34428 trainer.py:136] Epoch[184/1000] loss: 0.1261803259452184
I0422 16:06:56.657592 34428 trainer.py:136] Epoch[185/1000] loss: 0.12569980695843697
I0422 16:07:01.112602 34428 trainer.py:136] Epoch[186/1000] loss: 0.12537625059485435
I0422 16:07:05.577316 34428 trainer.py:136] Epoch[187/1000] loss: 0.12530935058991113
I0422 16:07:09.982846 34428 trainer.py:136] Epoch[188/1000] loss: 0.12537295743823051
I0422 16:07:16.690545 34428 trainer.py:136] Epoch[189/1000] loss: 0.12426898628473282
I0422 16:07:21.434217 34428 trainer.py:136] Epoch[190/1000] loss: 0.1253762592871984
I0422 16:07:26.125215 34428 trainer.py:136] Epoch[191/1000] loss: 0.12419836844007175
I0422 16:07:31.207341 34428 trainer.py:136] Epoch[192/1000] loss: 0.12322788561383884
I0422 16:07:38.209314 34428 trainer.py:136] Epoch[193/1000] loss: 0.12268441667159398
I0422 16:07:42.987632 34428 trainer.py:136] Epoch[194/1000] loss: 0.12496655806899071
I0422 16:07:47.635943 34428 trainer.py:136] Epoch[195/1000] loss: 0.12265028183658917
I0422 16:07:52.106244 34428 trainer.py:136] Epoch[196/1000] loss: 0.12326521302262942
I0422 16:07:58.494246 34428 trainer.py:136] Epoch[197/1000] loss: 0.12092661981781323
I0422 16:08:03.989437 34428 trainer.py:136] Epoch[198/1000] loss: 0.12242208048701286
I0422 16:08:08.716834 34428 trainer.py:136] Epoch[199/1000] loss: 0.12044885382056236
I0422 16:08:10.212033 34428 trainer.py:142] Test: [{'precision': 0.015151083238312426, 'recall': 0.07220998068631884, 'hit_ratio': 0.20838084378563285, 'ndcg': 0.04772971140763599}]
I0422 16:08:17.940882 34428 trainer.py:136] Epoch[200/1000] loss: 0.11987100541591644
I0422 16:08:22.437115 34428 trainer.py:136] Epoch[201/1000] loss: 0.121082687129577
I0422 16:08:26.916031 34428 trainer.py:136] Epoch[202/1000] loss: 0.12236919874946277
I0422 16:08:31.695821 34428 trainer.py:136] Epoch[203/1000] loss: 0.12098030373454094
I0422 16:08:39.082844 34428 trainer.py:136] Epoch[204/1000] loss: 0.12028723582625389
I0422 16:08:43.722326 34428 trainer.py:136] Epoch[205/1000] loss: 0.11944569895664851
I0422 16:08:48.182888 34428 trainer.py:136] Epoch[206/1000] loss: 0.11975727106134097
I0422 16:08:52.525178 34428 trainer.py:136] Epoch[207/1000] loss: 0.11846413960059483
I0422 16:08:59.382600 34428 trainer.py:136] Epoch[208/1000] loss: 0.1193186454474926
I0422 16:09:03.808106 34428 trainer.py:136] Epoch[209/1000] loss: 0.11914644266168277
I0422 16:09:08.201445 34428 trainer.py:136] Epoch[210/1000] loss: 0.11791589483618736
I0422 16:09:12.728616 34428 trainer.py:136] Epoch[211/1000] loss: 0.11662605404853821
I0422 16:09:17.189467 34428 trainer.py:136] Epoch[212/1000] loss: 0.11802858486771584
I0422 16:09:24.316680 34428 trainer.py:136] Epoch[213/1000] loss: 0.11532064651449521
I0422 16:09:29.080080 34428 trainer.py:136] Epoch[214/1000] loss: 0.11670975635449092
I0422 16:09:33.547946 34428 trainer.py:136] Epoch[215/1000] loss: 0.11747194329897563
I0422 16:09:38.135519 34428 trainer.py:136] Epoch[216/1000] loss: 0.11704141770799954
I0422 16:09:45.385281 34428 trainer.py:136] Epoch[217/1000] loss: 0.11629517376422882
I0422 16:09:49.980026 34428 trainer.py:136] Epoch[218/1000] loss: 0.1157834567129612
I0422 16:09:54.664869 34428 trainer.py:136] Epoch[219/1000] loss: 0.11639980475107829
I0422 16:09:59.296254 34428 trainer.py:136] Epoch[220/1000] loss: 0.11605951065818469
I0422 16:10:03.855067 34428 trainer.py:136] Epoch[221/1000] loss: 0.11557205766439438
I0422 16:10:11.692677 34428 trainer.py:136] Epoch[222/1000] loss: 0.11544177557031314
I0422 16:10:16.338027 34428 trainer.py:136] Epoch[223/1000] loss: 0.11595455060402553
I0422 16:10:20.788395 34428 trainer.py:136] Epoch[224/1000] loss: 0.11487456659475963
I0422 16:10:25.302324 34428 trainer.py:136] Epoch[225/1000] loss: 0.11507311835885048
I0422 16:10:30.728325 34428 trainer.py:136] Epoch[226/1000] loss: 0.11286189531286557
I0422 16:10:37.271746 34428 trainer.py:136] Epoch[227/1000] loss: 0.11398036032915115
I0422 16:10:41.841382 34428 trainer.py:136] Epoch[228/1000] loss: 0.11394590511918068
I0422 16:10:46.389088 34428 trainer.py:136] Epoch[229/1000] loss: 0.11378204450011253
I0422 16:10:51.327349 34428 trainer.py:136] Epoch[230/1000] loss: 0.11391800766189893
I0422 16:10:57.876582 34428 trainer.py:136] Epoch[231/1000] loss: 0.11457497378190358
I0422 16:11:02.405413 34428 trainer.py:136] Epoch[232/1000] loss: 0.11222956577936809
I0422 16:11:06.974183 34428 trainer.py:136] Epoch[233/1000] loss: 0.11221120754877727
I0422 16:11:11.412888 34428 trainer.py:136] Epoch[234/1000] loss: 0.11230471854408582
I0422 16:11:18.469454 34428 trainer.py:136] Epoch[235/1000] loss: 0.11262840777635574
I0422 16:11:23.108874 34428 trainer.py:136] Epoch[236/1000] loss: 0.11207692945996921
I0422 16:11:27.509542 34428 trainer.py:136] Epoch[237/1000] loss: 0.11378912130991618
I0422 16:11:32.015750 34428 trainer.py:136] Epoch[238/1000] loss: 0.11164245381951332
I0422 16:11:38.900847 34428 trainer.py:136] Epoch[239/1000] loss: 0.11112599695722263
I0422 16:11:43.683733 34428 trainer.py:136] Epoch[240/1000] loss: 0.11098338415225346
I0422 16:11:48.212057 34428 trainer.py:136] Epoch[241/1000] loss: 0.11147902657588322
I0422 16:11:55.362244 34428 trainer.py:136] Epoch[242/1000] loss: 0.11035760740439098
I0422 16:11:59.780007 34428 trainer.py:136] Epoch[243/1000] loss: 0.11032377928495407
I0422 16:12:04.219041 34428 trainer.py:136] Epoch[244/1000] loss: 0.11034959554672241
I0422 16:12:08.807004 34428 trainer.py:136] Epoch[245/1000] loss: 0.11021019145846367
I0422 16:12:13.540040 34428 trainer.py:136] Epoch[246/1000] loss: 0.11001487324635188
I0422 16:12:20.475271 34428 trainer.py:136] Epoch[247/1000] loss: 0.11029970521728198
I0422 16:12:24.976125 34428 trainer.py:136] Epoch[248/1000] loss: 0.11082059269150098
I0422 16:12:29.613394 34428 trainer.py:136] Epoch[249/1000] loss: 0.11005330954988797
I0422 16:12:31.338737 34428 trainer.py:142] Test: [{'precision': 0.015364880273660201, 'recall': 0.07276805125512117, 'hit_ratio': 0.2112314709236032, 'ndcg': 0.047980457765447744}]
I0422 16:12:37.785809 34428 trainer.py:136] Epoch[250/1000] loss: 0.10937408730387688
I0422 16:12:42.656377 34428 trainer.py:136] Epoch[251/1000] loss: 0.1092962957918644
I0422 16:12:47.240966 34428 trainer.py:136] Epoch[252/1000] loss: 0.10772128154834111
I0422 16:12:51.832931 34428 trainer.py:136] Epoch[253/1000] loss: 0.10927361870805423
I0422 16:12:56.337813 34428 trainer.py:136] Epoch[254/1000] loss: 0.10887082790335019
I0422 16:13:03.687004 34428 trainer.py:136] Epoch[255/1000] loss: 0.10837298755844434
I0422 16:13:08.197056 34428 trainer.py:136] Epoch[256/1000] loss: 0.10838219026724498
I0422 16:13:12.618008 34428 trainer.py:136] Epoch[257/1000] loss: 0.10682900374134381
I0422 16:13:17.259451 34428 trainer.py:136] Epoch[258/1000] loss: 0.10761566335956256
I0422 16:13:21.705881 34428 trainer.py:136] Epoch[259/1000] loss: 0.10855607688426971
I0422 16:13:28.676894 34428 trainer.py:136] Epoch[260/1000] loss: 0.10870431860287984
I0422 16:13:33.532654 34428 trainer.py:136] Epoch[261/1000] loss: 0.10706677536169688
I0422 16:13:38.368482 34428 trainer.py:136] Epoch[262/1000] loss: 0.1091676726937294
I0422 16:13:45.812524 34428 trainer.py:136] Epoch[263/1000] loss: 0.10699185853203137
I0422 16:13:50.243641 34428 trainer.py:136] Epoch[264/1000] loss: 0.1075116793314616
I0422 16:13:54.703079 34428 trainer.py:136] Epoch[265/1000] loss: 0.10813650240500768
I0422 16:13:59.438115 34428 trainer.py:136] Epoch[266/1000] loss: 0.10842210426926613
I0422 16:14:06.520147 34428 trainer.py:136] Epoch[267/1000] loss: 0.10679636398951213
I0422 16:14:11.056905 34428 trainer.py:136] Epoch[268/1000] loss: 0.10673489545782407
I0422 16:14:15.504525 34428 trainer.py:136] Epoch[269/1000] loss: 0.10745438933372498
I0422 16:14:20.106061 34428 trainer.py:136] Epoch[270/1000] loss: 0.10690202191472054
I0422 16:14:27.339798 34428 trainer.py:136] Epoch[271/1000] loss: 0.10649422307809193
I0422 16:14:31.956682 34428 trainer.py:136] Epoch[272/1000] loss: 0.10695128267010053
I0422 16:14:36.366828 34428 trainer.py:136] Epoch[273/1000] loss: 0.10629284133513768
I0422 16:14:40.843165 34428 trainer.py:136] Epoch[274/1000] loss: 0.1059932845334212
I0422 16:14:46.640279 34428 trainer.py:136] Epoch[275/1000] loss: 0.10491419335206349
I0422 16:14:52.294994 34428 trainer.py:136] Epoch[276/1000] loss: 0.10463250055909157
I0422 16:14:56.816132 34428 trainer.py:136] Epoch[277/1000] loss: 0.1053732509414355
I0422 16:15:01.447500 34428 trainer.py:136] Epoch[278/1000] loss: 0.10659917071461678
I0422 16:15:08.335383 34428 trainer.py:136] Epoch[279/1000] loss: 0.1046270194152991
I0422 16:15:13.048348 34428 trainer.py:136] Epoch[280/1000] loss: 0.10535404706994693
I0422 16:15:17.292990 34428 trainer.py:136] Epoch[281/1000] loss: 0.10450526575247447
I0422 16:15:21.932767 34428 trainer.py:136] Epoch[282/1000] loss: 0.10583576808373134
I0422 16:15:26.850156 34428 trainer.py:136] Epoch[283/1000] loss: 0.1058218777179718
I0422 16:15:33.217891 34428 trainer.py:136] Epoch[284/1000] loss: 0.10497153302033742
I0422 16:15:37.621108 34428 trainer.py:136] Epoch[285/1000] loss: 0.10474320749441783
I0422 16:15:42.066757 34428 trainer.py:136] Epoch[286/1000] loss: 0.1042187971373399
I0422 16:15:46.605569 34428 trainer.py:136] Epoch[287/1000] loss: 0.10456623882055283
I0422 16:15:52.725208 34428 trainer.py:136] Epoch[288/1000] loss: 0.10457853848735492
I0422 16:15:58.642942 34428 trainer.py:136] Epoch[289/1000] loss: 0.10380672042568524
I0422 16:16:03.106334 34428 trainer.py:136] Epoch[290/1000] loss: 0.10369848211606343
I0422 16:16:07.634279 34428 trainer.py:136] Epoch[291/1000] loss: 0.10420971363782883
I0422 16:16:12.223603 34428 trainer.py:136] Epoch[292/1000] loss: 0.10373535131414731
I0422 16:16:19.203011 34428 trainer.py:136] Epoch[293/1000] loss: 0.10378626485665639
I0422 16:16:23.522882 34428 trainer.py:136] Epoch[294/1000] loss: 0.10398169482747714
I0422 16:16:28.100657 34428 trainer.py:136] Epoch[295/1000] loss: 0.10318911944826444
I0422 16:16:32.519204 34428 trainer.py:136] Epoch[296/1000] loss: 0.1031167209148407
I0422 16:16:39.283561 34428 trainer.py:136] Epoch[297/1000] loss: 0.10221869001785915
I0422 16:16:43.704031 34428 trainer.py:136] Epoch[298/1000] loss: 0.1027141809463501
I0422 16:16:48.068679 34428 trainer.py:136] Epoch[299/1000] loss: 0.10258253291249275
I0422 16:16:49.888726 34428 trainer.py:142] Test: [{'precision': 0.015521664766248564, 'recall': 0.07272679890447986, 'hit_ratio': 0.2130843785632839, 'ndcg': 0.048432836218613336}]
I0422 16:16:54.296593 34428 trainer.py:136] Epoch[300/1000] loss: 0.10362047205368678
I0422 16:17:01.815371 34428 trainer.py:136] Epoch[301/1000] loss: 0.1021745999654134
I0422 16:17:06.456283 34428 trainer.py:136] Epoch[302/1000] loss: 0.1024685800075531
I0422 16:17:10.982864 34428 trainer.py:136] Epoch[303/1000] loss: 0.102113821854194
I0422 16:17:16.695009 34428 trainer.py:136] Epoch[304/1000] loss: 0.10148408512274425
I0422 16:17:22.468563 34428 trainer.py:136] Epoch[305/1000] loss: 0.10058513780434926
I0422 16:17:26.873275 34428 trainer.py:136] Epoch[306/1000] loss: 0.1036643534898758
I0422 16:17:31.295681 34428 trainer.py:136] Epoch[307/1000] loss: 0.1013560766975085
I0422 16:17:37.157835 34428 trainer.py:136] Epoch[308/1000] loss: 0.10152597352862358
I0422 16:17:42.576222 34428 trainer.py:136] Epoch[309/1000] loss: 0.10217100754380226
I0422 16:17:47.224684 34428 trainer.py:136] Epoch[310/1000] loss: 0.1011763463417689
I0422 16:17:51.723872 34428 trainer.py:136] Epoch[311/1000] loss: 0.10152882958451907
I0422 16:17:56.218135 34428 trainer.py:136] Epoch[312/1000] loss: 0.10128205766280492
I0422 16:18:03.320545 34428 trainer.py:136] Epoch[313/1000] loss: 0.10060566912094752
I0422 16:18:07.855256 34428 trainer.py:136] Epoch[314/1000] loss: 0.10069202010830243
I0422 16:18:12.249505 34428 trainer.py:136] Epoch[315/1000] loss: 0.10183409849802653
I0422 16:18:16.621102 34428 trainer.py:136] Epoch[316/1000] loss: 0.10178595905502637
I0422 16:18:21.690019 34428 trainer.py:136] Epoch[317/1000] loss: 0.10022615765531857
I0422 16:18:28.238461 34428 trainer.py:136] Epoch[318/1000] loss: 0.1002928080658118
I0422 16:18:32.757831 34428 trainer.py:136] Epoch[319/1000] loss: 0.10032705838481586
I0422 16:18:37.251213 34428 trainer.py:136] Epoch[320/1000] loss: 0.1010733259220918
I0422 16:18:41.674702 34428 trainer.py:136] Epoch[321/1000] loss: 0.09965767711400986
I0422 16:18:48.638616 34428 trainer.py:136] Epoch[322/1000] loss: 0.09954559057950974
I0422 16:18:53.095005 34428 trainer.py:136] Epoch[323/1000] loss: 0.10033343732357025
I0422 16:18:57.549382 34428 trainer.py:136] Epoch[324/1000] loss: 0.09890661016106606
I0422 16:19:02.028538 34428 trainer.py:136] Epoch[325/1000] loss: 0.1011333850522836
I0422 16:19:06.697353 34428 trainer.py:136] Epoch[326/1000] loss: 0.09990727404753368
I0422 16:19:13.077111 34428 trainer.py:136] Epoch[327/1000] loss: 0.10011670490105946
I0422 16:19:18.824531 34428 trainer.py:136] Epoch[328/1000] loss: 0.09984460473060608
I0422 16:19:23.301475 34428 trainer.py:136] Epoch[329/1000] loss: 0.10000261167685191
I0422 16:19:27.983442 34428 trainer.py:136] Epoch[330/1000] loss: 0.10042898853619893
I0422 16:19:35.252519 34428 trainer.py:136] Epoch[331/1000] loss: 0.09984978288412094
I0422 16:19:39.763280 34428 trainer.py:136] Epoch[332/1000] loss: 0.09924442941943805
I0422 16:19:44.232167 34428 trainer.py:136] Epoch[333/1000] loss: 0.0985218696296215
I0422 16:19:48.760277 34428 trainer.py:136] Epoch[334/1000] loss: 0.09889863431453705
I0422 16:19:55.989018 34428 trainer.py:136] Epoch[335/1000] loss: 0.09839083875219028
I0422 16:20:00.358841 34428 trainer.py:136] Epoch[336/1000] loss: 0.09959969917933147
I0422 16:20:04.842390 34428 trainer.py:136] Epoch[337/1000] loss: 0.10054163262248039
I0422 16:20:09.450731 34428 trainer.py:136] Epoch[338/1000] loss: 0.0986408218741417
I0422 16:20:16.671247 34428 trainer.py:136] Epoch[339/1000] loss: 0.09950936213135719
I0422 16:20:21.359453 34428 trainer.py:136] Epoch[340/1000] loss: 0.09864021092653275
I0422 16:20:25.809946 34428 trainer.py:136] Epoch[341/1000] loss: 0.09870502725243568
I0422 16:20:30.391751 34428 trainer.py:136] Epoch[342/1000] loss: 0.09786993513504665
I0422 16:20:34.855523 34428 trainer.py:136] Epoch[343/1000] loss: 0.09747760742902756
I0422 16:20:41.663866 34428 trainer.py:136] Epoch[344/1000] loss: 0.09838008508086205
I0422 16:20:46.243040 34428 trainer.py:136] Epoch[345/1000] loss: 0.0984492152929306
I0422 16:20:50.741294 34428 trainer.py:136] Epoch[346/1000] loss: 0.098114096870025
I0422 16:20:55.224570 34428 trainer.py:136] Epoch[347/1000] loss: 0.0968657818933328
I0422 16:20:59.676668 34428 trainer.py:136] Epoch[348/1000] loss: 0.09908521175384521
I0422 16:21:06.753316 34428 trainer.py:136] Epoch[349/1000] loss: 0.09747812151908875
I0422 16:21:08.233613 34428 trainer.py:142] Test: [{'precision': 0.015771094640820972, 'recall': 0.07406239633319958, 'hit_ratio': 0.21579247434435575, 'ndcg': 0.04886014603126048}]
I0422 16:21:12.811211 34428 trainer.py:136] Epoch[350/1000] loss: 0.09822744379440944
I0422 16:21:17.534157 34428 trainer.py:136] Epoch[351/1000] loss: 0.09900141134858131
I0422 16:21:22.007817 34428 trainer.py:136] Epoch[352/1000] loss: 0.09745289757847786
I0422 16:21:26.874198 34428 trainer.py:136] Epoch[353/1000] loss: 0.09748395284016927
I0422 16:21:33.625800 34428 trainer.py:136] Epoch[354/1000] loss: 0.0974250001211961
I0422 16:21:38.176389 34428 trainer.py:136] Epoch[355/1000] loss: 0.09743818392356236
I0422 16:21:42.626775 34428 trainer.py:136] Epoch[356/1000] loss: 0.09741939480106036
I0422 16:21:47.275928 34428 trainer.py:136] Epoch[357/1000] loss: 0.0978055236240228
I0422 16:21:55.044900 34428 trainer.py:136] Epoch[358/1000] loss: 0.09739705796043079
I0422 16:21:59.872558 34428 trainer.py:136] Epoch[359/1000] loss: 0.09729298576712608
I0422 16:22:04.440196 34428 trainer.py:136] Epoch[360/1000] loss: 0.09724569941560428
I0422 16:22:11.597635 34428 trainer.py:136] Epoch[361/1000] loss: 0.09648143003384273
I0422 16:22:16.514885 34428 trainer.py:136] Epoch[362/1000] loss: 0.0966779353717963
I0422 16:22:21.233025 34428 trainer.py:136] Epoch[363/1000] loss: 0.09705480684836705
I0422 16:22:29.041634 34428 trainer.py:136] Epoch[364/1000] loss: 0.0965454913675785
I0422 16:22:33.818794 34428 trainer.py:136] Epoch[365/1000] loss: 0.09677018970251083
I0422 16:22:38.453123 34428 trainer.py:136] Epoch[366/1000] loss: 0.0964764803647995
I0422 16:22:42.987242 34428 trainer.py:136] Epoch[367/1000] loss: 0.0961245025197665
I0422 16:22:49.980969 34428 trainer.py:136] Epoch[368/1000] loss: 0.09547232836484909
I0422 16:22:54.438052 34428 trainer.py:136] Epoch[369/1000] loss: 0.09602319325009982
I0422 16:22:58.772511 34428 trainer.py:136] Epoch[370/1000] loss: 0.09640842055281003
I0422 16:23:03.159047 34428 trainer.py:136] Epoch[371/1000] loss: 0.09598618124922116
I0422 16:23:09.227411 34428 trainer.py:136] Epoch[372/1000] loss: 0.09610106299320857
I0422 16:23:14.492653 34428 trainer.py:136] Epoch[373/1000] loss: 0.09586424008011818
I0422 16:23:18.957032 34428 trainer.py:136] Epoch[374/1000] loss: 0.09566541761159897
I0422 16:23:23.399276 34428 trainer.py:136] Epoch[375/1000] loss: 0.09582580874363582
I0422 16:23:29.929355 34428 trainer.py:136] Epoch[376/1000] loss: 0.09525528674324353
I0422 16:23:35.066002 34428 trainer.py:136] Epoch[377/1000] loss: 0.09620634838938713
I0422 16:23:39.563745 34428 trainer.py:136] Epoch[378/1000] loss: 0.09573485205570857
I0422 16:23:44.261488 34428 trainer.py:136] Epoch[379/1000] loss: 0.09666519487897555
I0422 16:23:51.481518 34428 trainer.py:136] Epoch[380/1000] loss: 0.09587050850192706
I0422 16:23:56.565169 34428 trainer.py:136] Epoch[381/1000] loss: 0.09593408058087032
I0422 16:24:01.038065 34428 trainer.py:136] Epoch[382/1000] loss: 0.09649549797177315
I0422 16:24:05.486225 34428 trainer.py:136] Epoch[383/1000] loss: 0.09585345660646756
I0422 16:24:11.967147 34428 trainer.py:136] Epoch[384/1000] loss: 0.09566403677066167
I0422 16:24:16.877185 34428 trainer.py:136] Epoch[385/1000] loss: 0.09544916699330012
I0422 16:24:21.223040 34428 trainer.py:136] Epoch[386/1000] loss: 0.09536523123582204
I0422 16:24:25.601312 34428 trainer.py:136] Epoch[387/1000] loss: 0.09464857603112857
I0422 16:24:30.713119 34428 trainer.py:136] Epoch[388/1000] loss: 0.0945133442680041
I0422 16:24:37.570217 34428 trainer.py:136] Epoch[389/1000] loss: 0.09533596287171046
I0422 16:24:42.006188 34428 trainer.py:136] Epoch[390/1000] loss: 0.095159446199735
I0422 16:24:46.859786 34428 trainer.py:136] Epoch[391/1000] loss: 0.09488892679413159
I0422 16:24:51.655552 34428 trainer.py:136] Epoch[392/1000] loss: 0.09546419357260068
I0422 16:24:58.991266 34428 trainer.py:136] Epoch[393/1000] loss: 0.09550196553270023
I0422 16:25:03.781837 34428 trainer.py:136] Epoch[394/1000] loss: 0.09529064347346623
I0422 16:25:08.460942 34428 trainer.py:136] Epoch[395/1000] loss: 0.09550752863287926
I0422 16:25:13.518011 34428 trainer.py:136] Epoch[396/1000] loss: 0.09469135229786237
I0422 16:25:20.054722 34428 trainer.py:136] Epoch[397/1000] loss: 0.09636031463742256
I0422 16:25:24.700397 34428 trainer.py:136] Epoch[398/1000] loss: 0.09420931835969289
I0422 16:25:29.234793 34428 trainer.py:136] Epoch[399/1000] loss: 0.09454733381668727
I0422 16:25:30.779631 34428 trainer.py:142] Test: [{'precision': 0.015927879133409335, 'recall': 0.07543686157030095, 'hit_ratio': 0.21964082098061574, 'ndcg': 0.049636382140015665}]
I0422 16:25:37.828415 34428 trainer.py:136] Epoch[400/1000] loss: 0.09487378597259521
I0422 16:25:42.901925 34428 trainer.py:136] Epoch[401/1000] loss: 0.09456434100866318
I0422 16:25:47.351942 34428 trainer.py:136] Epoch[402/1000] loss: 0.093755508462588
I0422 16:25:51.868165 34428 trainer.py:136] Epoch[403/1000] loss: 0.09362675746281941
I0422 16:25:59.151567 34428 trainer.py:136] Epoch[404/1000] loss: 0.0943609078725179
I0422 16:26:03.618464 34428 trainer.py:136] Epoch[405/1000] loss: 0.09427611902356148
I0422 16:26:08.250291 34428 trainer.py:136] Epoch[406/1000] loss: 0.09386715417106946
I0422 16:26:12.629880 34428 trainer.py:136] Epoch[407/1000] loss: 0.09422230596343677
I0422 16:26:18.846042 34428 trainer.py:136] Epoch[408/1000] loss: 0.09394624705115955
I0422 16:26:24.958012 34428 trainer.py:136] Epoch[409/1000] loss: 0.09498544409871101
I0422 16:26:29.296962 34428 trainer.py:136] Epoch[410/1000] loss: 0.09397706761956215
I0422 16:26:34.404801 34428 trainer.py:136] Epoch[411/1000] loss: 0.09462643166383107
I0422 16:26:41.440318 34428 trainer.py:136] Epoch[412/1000] loss: 0.09317331512769063
I0422 16:26:46.200134 34428 trainer.py:136] Epoch[413/1000] loss: 0.09424549341201782
I0422 16:26:52.195347 34428 trainer.py:136] Epoch[414/1000] loss: 0.09391422445575397
I0422 16:26:58.647695 34428 trainer.py:136] Epoch[415/1000] loss: 0.0931493267416954
I0422 16:27:03.163457 34428 trainer.py:136] Epoch[416/1000] loss: 0.09406604742010434
I0422 16:27:10.301281 34428 trainer.py:136] Epoch[417/1000] loss: 0.093991219997406
I0422 16:27:15.130922 34428 trainer.py:136] Epoch[418/1000] loss: 0.09343698124090831
I0422 16:27:19.578519 34428 trainer.py:136] Epoch[419/1000] loss: 0.09361579269170761
I0422 16:27:24.069175 34428 trainer.py:136] Epoch[420/1000] loss: 0.09399016822377841
I0422 16:27:28.473714 34428 trainer.py:136] Epoch[421/1000] loss: 0.09341513986388843
I0422 16:27:35.594658 34428 trainer.py:136] Epoch[422/1000] loss: 0.0943136674662431
I0422 16:27:40.263942 34428 trainer.py:136] Epoch[423/1000] loss: 0.0941086324552695
I0422 16:27:44.750720 34428 trainer.py:136] Epoch[424/1000] loss: 0.0931059035162131
I0422 16:27:49.575677 34428 trainer.py:136] Epoch[425/1000] loss: 0.09391301001111667
I0422 16:27:54.609353 34428 trainer.py:136] Epoch[426/1000] loss: 0.09291257212559383
I0422 16:28:02.139374 34428 trainer.py:136] Epoch[427/1000] loss: 0.09421566625436147
I0422 16:28:06.847318 34428 trainer.py:136] Epoch[428/1000] loss: 0.09299888586004575
I0422 16:28:11.750844 34428 trainer.py:136] Epoch[429/1000] loss: 0.09278445442517598
I0422 16:28:19.413839 34428 trainer.py:136] Epoch[430/1000] loss: 0.09267640486359596
I0422 16:28:24.065988 34428 trainer.py:136] Epoch[431/1000] loss: 0.09318165729443233
I0422 16:28:29.225834 34428 trainer.py:136] Epoch[432/1000] loss: 0.09275468563040097
I0422 16:28:36.808860 34428 trainer.py:136] Epoch[433/1000] loss: 0.0929473526775837
I0422 16:28:41.598805 34428 trainer.py:136] Epoch[434/1000] loss: 0.0934809719522794
I0422 16:28:46.467881 34428 trainer.py:136] Epoch[435/1000] loss: 0.09328587477405866
I0422 16:28:54.086862 34428 trainer.py:136] Epoch[436/1000] loss: 0.09329407041271527
I0422 16:28:58.919371 34428 trainer.py:136] Epoch[437/1000] loss: 0.09221683690945308
I0422 16:29:03.528387 34428 trainer.py:136] Epoch[438/1000] loss: 0.09265099590023358
I0422 16:29:10.254550 34428 trainer.py:136] Epoch[439/1000] loss: 0.09348379199703534
I0422 16:29:15.052879 34428 trainer.py:136] Epoch[440/1000] loss: 0.09357226267457008
I0422 16:29:19.395154 34428 trainer.py:136] Epoch[441/1000] loss: 0.09183343375722568
I0422 16:29:23.883751 34428 trainer.py:136] Epoch[442/1000] loss: 0.0928611693282922
I0422 16:29:30.164830 34428 trainer.py:136] Epoch[443/1000] loss: 0.09335529804229736
I0422 16:29:36.180384 34428 trainer.py:136] Epoch[444/1000] loss: 0.09236513823270798
I0422 16:29:40.596967 34428 trainer.py:136] Epoch[445/1000] loss: 0.09178989877303441
I0422 16:29:44.950329 34428 trainer.py:136] Epoch[446/1000] loss: 0.09254271288712819
I0422 16:29:49.298718 34428 trainer.py:136] Epoch[447/1000] loss: 0.09131052469213803
I0422 16:29:55.754639 34428 trainer.py:136] Epoch[448/1000] loss: 0.09169156476855278
I0422 16:30:00.739802 34428 trainer.py:136] Epoch[449/1000] loss: 0.09163794418176015
I0422 16:30:02.240940 34428 trainer.py:142] Test: [{'precision': 0.016020524515393375, 'recall': 0.07641438307273159, 'hit_ratio': 0.22149372862029645, 'ndcg': 0.05018985632768269}]
I0422 16:30:06.752405 34428 trainer.py:136] Epoch[450/1000] loss: 0.0925324484705925
I0422 16:30:11.207404 34428 trainer.py:136] Epoch[451/1000] loss: 0.09261569753289223
I0422 16:30:15.662728 34428 trainer.py:136] Epoch[452/1000] loss: 0.09168002754449844
I0422 16:30:22.518902 34428 trainer.py:136] Epoch[453/1000] loss: 0.0916959544022878
I0422 16:30:27.084949 34428 trainer.py:136] Epoch[454/1000] loss: 0.09272085130214691
I0422 16:30:31.717379 34428 trainer.py:136] Epoch[455/1000] loss: 0.09172228847940762
I0422 16:30:36.204487 34428 trainer.py:136] Epoch[456/1000] loss: 0.091761764138937
I0422 16:30:40.642952 34428 trainer.py:136] Epoch[457/1000] loss: 0.0915727677444617
I0422 16:30:47.990571 34428 trainer.py:136] Epoch[458/1000] loss: 0.09191737820704778
I0422 16:30:52.522305 34428 trainer.py:136] Epoch[459/1000] loss: 0.09170036390423775
I0422 16:30:57.195248 34428 trainer.py:136] Epoch[460/1000] loss: 0.09222604458530743
I0422 16:31:02.711091 34428 trainer.py:136] Epoch[461/1000] loss: 0.09094769010941188
I0422 16:31:08.749731 34428 trainer.py:136] Epoch[462/1000] loss: 0.09141338989138603
I0422 16:31:13.313159 34428 trainer.py:136] Epoch[463/1000] loss: 0.09249947095910709
I0422 16:31:17.840728 34428 trainer.py:136] Epoch[464/1000] loss: 0.0916086696088314
I0422 16:31:22.397213 34428 trainer.py:136] Epoch[465/1000] loss: 0.09062315026919048
I0422 16:31:26.970754 34428 trainer.py:136] Epoch[466/1000] loss: 0.0922669917345047
I0422 16:31:34.075601 34428 trainer.py:136] Epoch[467/1000] loss: 0.09110540648301442
I0422 16:31:38.904343 34428 trainer.py:136] Epoch[468/1000] loss: 0.09189372385541598
I0422 16:31:43.698194 34428 trainer.py:136] Epoch[469/1000] loss: 0.09175570184985797
I0422 16:31:48.936032 34428 trainer.py:136] Epoch[470/1000] loss: 0.0912499912083149
I0422 16:31:55.380939 34428 trainer.py:136] Epoch[471/1000] loss: 0.09133930504322052
I0422 16:31:59.839915 34428 trainer.py:136] Epoch[472/1000] loss: 0.09151668722430865
I0422 16:32:04.458187 34428 trainer.py:136] Epoch[473/1000] loss: 0.09148534387350082
I0422 16:32:09.503414 34428 trainer.py:136] Epoch[474/1000] loss: 0.09245576585332553
I0422 16:32:16.236371 34428 trainer.py:136] Epoch[475/1000] loss: 0.09100137526790301
I0422 16:32:20.780420 34428 trainer.py:136] Epoch[476/1000] loss: 0.09194722771644592
I0422 16:32:25.422793 34428 trainer.py:136] Epoch[477/1000] loss: 0.09152867024143536
I0422 16:32:29.927941 34428 trainer.py:136] Epoch[478/1000] loss: 0.09185488894581795
I0422 16:32:37.155559 34428 trainer.py:136] Epoch[479/1000] loss: 0.09198192258675893
I0422 16:32:41.857039 34428 trainer.py:136] Epoch[480/1000] loss: 0.09096801777680714
I0422 16:32:46.310956 34428 trainer.py:136] Epoch[481/1000] loss: 0.09026958793401718
I0422 16:32:50.775444 34428 trainer.py:136] Epoch[482/1000] loss: 0.09024763852357864
I0422 16:32:57.679747 34428 trainer.py:136] Epoch[483/1000] loss: 0.09067955737312634
I0422 16:33:02.647083 34428 trainer.py:136] Epoch[484/1000] loss: 0.09113272900382678
I0422 16:33:07.328860 34428 trainer.py:136] Epoch[485/1000] loss: 0.09068350121378899
I0422 16:33:11.698526 34428 trainer.py:136] Epoch[486/1000] loss: 0.08993375549713771
I0422 16:33:18.918742 34428 trainer.py:136] Epoch[487/1000] loss: 0.09028548747301102
I0422 16:33:24.091779 34428 trainer.py:136] Epoch[488/1000] loss: 0.09063445031642914
I0422 16:33:28.658474 34428 trainer.py:136] Epoch[489/1000] loss: 0.09055863072474797
I0422 16:33:33.190144 34428 trainer.py:136] Epoch[490/1000] loss: 0.09109168127179146
I0422 16:33:39.061415 34428 trainer.py:136] Epoch[491/1000] loss: 0.08977531393369038
I0422 16:33:44.971347 34428 trainer.py:136] Epoch[492/1000] loss: 0.09074235955874126
I0422 16:33:49.357376 34428 trainer.py:136] Epoch[493/1000] loss: 0.0902620479464531
I0422 16:33:53.702162 34428 trainer.py:136] Epoch[494/1000] loss: 0.09008120000362396
I0422 16:33:58.289706 34428 trainer.py:136] Epoch[495/1000] loss: 0.08969177305698395
I0422 16:34:02.848761 34428 trainer.py:136] Epoch[496/1000] loss: 0.0901780016720295
I0422 16:34:09.220186 34428 trainer.py:136] Epoch[497/1000] loss: 0.08970160533984502
I0422 16:34:14.024061 34428 trainer.py:136] Epoch[498/1000] loss: 0.08961970483263333
I0422 16:34:18.550035 34428 trainer.py:136] Epoch[499/1000] loss: 0.09062100574374199
I0422 16:34:20.002199 34428 trainer.py:142] Test: [{'precision': 0.016063283922462934, 'recall': 0.07655334247153071, 'hit_ratio': 0.22220638540478904, 'ndcg': 0.05042760950484877}]
I0422 16:34:24.280914 34428 trainer.py:136] Epoch[500/1000] loss: 0.08987939233581226
I0422 16:34:28.712839 34428 trainer.py:136] Epoch[501/1000] loss: 0.0907162179549535
I0422 16:34:35.443436 34428 trainer.py:136] Epoch[502/1000] loss: 0.0903961571554343
I0422 16:34:39.844966 34428 trainer.py:136] Epoch[503/1000] loss: 0.09018856659531593
I0422 16:34:44.183953 34428 trainer.py:136] Epoch[504/1000] loss: 0.09018603339791298
I0422 16:34:48.785829 34428 trainer.py:136] Epoch[505/1000] loss: 0.08899489293495814
I0422 16:34:54.139429 34428 trainer.py:136] Epoch[506/1000] loss: 0.09024785583217938
I0422 16:35:00.369139 34428 trainer.py:136] Epoch[507/1000] loss: 0.0893361692627271
I0422 16:35:04.784630 34428 trainer.py:136] Epoch[508/1000] loss: 0.08987858394781749
I0422 16:35:09.231933 34428 trainer.py:136] Epoch[509/1000] loss: 0.09020823488632838
I0422 16:35:13.651432 34428 trainer.py:136] Epoch[510/1000] loss: 0.09012900044520696
I0422 16:35:20.055617 34428 trainer.py:136] Epoch[511/1000] loss: 0.09064310913284619
I0422 16:35:25.300610 34428 trainer.py:136] Epoch[512/1000] loss: 0.0896358775595824
I0422 16:35:29.997199 34428 trainer.py:136] Epoch[513/1000] loss: 0.08972455809513728
I0422 16:35:34.711827 34428 trainer.py:136] Epoch[514/1000] loss: 0.08972100292642911
I0422 16:35:41.739480 34428 trainer.py:136] Epoch[515/1000] loss: 0.09004119783639908
I0422 16:35:47.072561 34428 trainer.py:136] Epoch[516/1000] loss: 0.0895589937766393
I0422 16:35:52.257706 34428 trainer.py:136] Epoch[517/1000] loss: 0.09033589934309323
I0422 16:36:00.520677 34428 trainer.py:136] Epoch[518/1000] loss: 0.08948146800200145
I0422 16:36:05.525016 34428 trainer.py:136] Epoch[519/1000] loss: 0.08962640042106311
I0422 16:36:10.402589 34428 trainer.py:136] Epoch[520/1000] loss: 0.09007654339075089
I0422 16:36:18.076961 34428 trainer.py:136] Epoch[521/1000] loss: 0.08885770291090012
I0422 16:36:22.917206 34428 trainer.py:136] Epoch[522/1000] loss: 0.0897238552570343
I0422 16:36:27.715340 34428 trainer.py:136] Epoch[523/1000] loss: 0.0893975558380286
I0422 16:36:32.527093 34428 trainer.py:136] Epoch[524/1000] loss: 0.08877718945344289
I0422 16:36:39.820957 34428 trainer.py:136] Epoch[525/1000] loss: 0.089163888245821
I0422 16:36:44.699545 34428 trainer.py:136] Epoch[526/1000] loss: 0.08941669886310895
I0422 16:36:49.437505 34428 trainer.py:136] Epoch[527/1000] loss: 0.08847939098874728
I0422 16:36:54.223328 34428 trainer.py:136] Epoch[528/1000] loss: 0.09058916320403416
I0422 16:37:02.069341 34428 trainer.py:136] Epoch[529/1000] loss: 0.08939057091871898
I0422 16:37:07.458388 34428 trainer.py:136] Epoch[530/1000] loss: 0.08887689560651779
I0422 16:37:15.474050 34428 trainer.py:136] Epoch[531/1000] loss: 0.08852145696679752
I0422 16:37:20.362124 34428 trainer.py:136] Epoch[532/1000] loss: 0.08914617697397868
I0422 16:37:25.153166 34428 trainer.py:136] Epoch[533/1000] loss: 0.08909092843532562
I0422 16:37:31.323483 34428 trainer.py:136] Epoch[534/1000] loss: 0.08905674392978351
I0422 16:37:37.771677 34428 trainer.py:136] Epoch[535/1000] loss: 0.08976790060599645
I0422 16:37:42.906879 34428 trainer.py:136] Epoch[536/1000] loss: 0.08880916610360146
I0422 16:37:48.353128 34428 trainer.py:136] Epoch[537/1000] loss: 0.0888672557969888
I0422 16:37:54.839007 34428 trainer.py:136] Epoch[538/1000] loss: 0.08832379306356113
I0422 16:37:59.290986 34428 trainer.py:136] Epoch[539/1000] loss: 0.08889185264706612
I0422 16:38:04.092282 34428 trainer.py:136] Epoch[540/1000] loss: 0.08835880334178607
I0422 16:38:11.640972 34428 trainer.py:136] Epoch[541/1000] loss: 0.08885484437147777
I0422 16:38:16.533518 34428 trainer.py:136] Epoch[542/1000] loss: 0.08829249069094658
I0422 16:38:21.391741 34428 trainer.py:136] Epoch[543/1000] loss: 0.08859472225109737
I0422 16:38:26.687911 34428 trainer.py:136] Epoch[544/1000] loss: 0.08875198538104694
I0422 16:38:33.756431 34428 trainer.py:136] Epoch[545/1000] loss: 0.08861737449963887
I0422 16:38:38.539318 34428 trainer.py:136] Epoch[546/1000] loss: 0.08810833841562271
I0422 16:38:43.546404 34428 trainer.py:136] Epoch[547/1000] loss: 0.0885187437136968
I0422 16:38:50.035202 34428 trainer.py:136] Epoch[548/1000] loss: 0.08875937759876251
I0422 16:38:55.880062 34428 trainer.py:136] Epoch[549/1000] loss: 0.08922265097498894
I0422 16:38:57.775915 34428 trainer.py:142] Test: [{'precision': 0.016155929304446974, 'recall': 0.07698401482725728, 'hit_ratio': 0.22291904218928163, 'ndcg': 0.05077410986688782}]
I0422 16:39:02.889650 34428 trainer.py:136] Epoch[550/1000] loss: 0.08908023064335187
I0422 16:39:10.906866 34428 trainer.py:136] Epoch[551/1000] loss: 0.08826576545834541
I0422 16:39:15.895113 34428 trainer.py:136] Epoch[552/1000] loss: 0.08757106959819794
I0422 16:39:21.144369 34428 trainer.py:136] Epoch[553/1000] loss: 0.08911881595849991
I0422 16:39:28.860041 34428 trainer.py:136] Epoch[554/1000] loss: 0.08876089379191399
I0422 16:39:33.714141 34428 trainer.py:136] Epoch[555/1000] loss: 0.0877588614821434
I0422 16:39:38.606652 34428 trainer.py:136] Epoch[556/1000] loss: 0.08906778320670128
I0422 16:39:45.057568 34428 trainer.py:136] Epoch[557/1000] loss: 0.08840883647402127
I0422 16:39:50.950109 34428 trainer.py:136] Epoch[558/1000] loss: 0.08891909196972847
I0422 16:39:55.770043 34428 trainer.py:136] Epoch[559/1000] loss: 0.08821653450528781
I0422 16:40:00.586650 34428 trainer.py:136] Epoch[560/1000] loss: 0.08762217313051224
I0422 16:40:08.799715 34428 trainer.py:136] Epoch[561/1000] loss: 0.08828621978561084
I0422 16:40:14.052901 34428 trainer.py:136] Epoch[562/1000] loss: 0.08793281763792038
I0422 16:40:19.411955 34428 trainer.py:136] Epoch[563/1000] loss: 0.0882360612352689
I0422 16:40:26.283544 34428 trainer.py:136] Epoch[564/1000] loss: 0.08907174815734227
I0422 16:40:31.030591 34428 trainer.py:136] Epoch[565/1000] loss: 0.08898188918828964
I0422 16:40:35.938635 34428 trainer.py:136] Epoch[566/1000] loss: 0.08885711058974266
I0422 16:40:43.483281 34428 trainer.py:136] Epoch[567/1000] loss: 0.0875168318549792
I0422 16:40:48.371777 34428 trainer.py:136] Epoch[568/1000] loss: 0.08777040491501491
I0422 16:40:53.181577 34428 trainer.py:136] Epoch[569/1000] loss: 0.08813922976454099
I0422 16:41:00.597055 34428 trainer.py:136] Epoch[570/1000] loss: 0.08861849208672841
I0422 16:41:05.426251 34428 trainer.py:136] Epoch[571/1000] loss: 0.08864448592066765
I0422 16:41:10.355849 34428 trainer.py:136] Epoch[572/1000] loss: 0.0885139877597491
I0422 16:41:18.203785 34428 trainer.py:136] Epoch[573/1000] loss: 0.08782003819942474
I0422 16:41:23.019061 34428 trainer.py:136] Epoch[574/1000] loss: 0.08754085749387741
I0422 16:41:27.858480 34428 trainer.py:136] Epoch[575/1000] loss: 0.08949763576189677
I0422 16:41:35.610360 34428 trainer.py:136] Epoch[576/1000] loss: 0.0874910478790601
I0422 16:41:40.259692 34428 trainer.py:136] Epoch[577/1000] loss: 0.08883020033439
I0422 16:41:45.131338 34428 trainer.py:136] Epoch[578/1000] loss: 0.08841241523623466
I0422 16:41:51.043079 34428 trainer.py:136] Epoch[579/1000] loss: 0.0882450540860494
I0422 16:41:57.423335 34428 trainer.py:136] Epoch[580/1000] loss: 0.08680424715081851
I0422 16:42:02.226093 34428 trainer.py:136] Epoch[581/1000] loss: 0.08755860974391301
I0422 16:42:07.107534 34428 trainer.py:136] Epoch[582/1000] loss: 0.08808136358857155
I0422 16:42:15.025662 34428 trainer.py:136] Epoch[583/1000] loss: 0.08699251338839531
I0422 16:42:19.989134 34428 trainer.py:136] Epoch[584/1000] loss: 0.0889543890953064
I0422 16:42:25.539962 34428 trainer.py:136] Epoch[585/1000] loss: 0.08720336730281512
I0422 16:42:32.520347 34428 trainer.py:136] Epoch[586/1000] loss: 0.08836793278654416
I0422 16:42:37.559800 34428 trainer.py:136] Epoch[587/1000] loss: 0.08772361030181249
I0422 16:42:45.340242 34428 trainer.py:136] Epoch[588/1000] loss: 0.08851734176278114
I0422 16:42:50.284932 34428 trainer.py:136] Epoch[589/1000] loss: 0.08737998083233833
I0422 16:42:55.519259 34428 trainer.py:136] Epoch[590/1000] loss: 0.08846373980244
I0422 16:43:03.760401 34428 trainer.py:136] Epoch[591/1000] loss: 0.08801516145467758
I0422 16:43:09.151913 34428 trainer.py:136] Epoch[592/1000] loss: 0.0875246413052082
I0422 16:43:16.343363 34428 trainer.py:136] Epoch[593/1000] loss: 0.08737482999761899
I0422 16:43:22.175348 34428 trainer.py:136] Epoch[594/1000] loss: 0.08748455221454303
I0422 16:43:27.304986 34428 trainer.py:136] Epoch[595/1000] loss: 0.08861407389243443
I0422 16:43:34.069872 34428 trainer.py:136] Epoch[596/1000] loss: 0.0884326621890068
I0422 16:43:40.283213 34428 trainer.py:136] Epoch[597/1000] loss: 0.0880691260099411
I0422 16:43:45.482648 34428 trainer.py:136] Epoch[598/1000] loss: 0.08631657436490059
I0422 16:43:53.723249 34428 trainer.py:136] Epoch[599/1000] loss: 0.0880337084333102
I0422 16:43:55.767039 34428 trainer.py:142] Test: [{'precision': 0.016205815279361453, 'recall': 0.0766658236481326, 'hit_ratio': 0.22277651083238312, 'ndcg': 0.0511118888442814}]
I0422 16:44:00.885347 34428 trainer.py:136] Epoch[600/1000] loss: 0.0875159427523613
I0422 16:44:08.119306 34428 trainer.py:136] Epoch[601/1000] loss: 0.08767830828825633
I0422 16:44:14.133136 34428 trainer.py:136] Epoch[602/1000] loss: 0.08788284907738368
I0422 16:44:19.469396 34428 trainer.py:136] Epoch[603/1000] loss: 0.08747957646846771
I0422 16:44:27.608254 34428 trainer.py:136] Epoch[604/1000] loss: 0.08739818880955379
I0422 16:44:32.591473 34428 trainer.py:136] Epoch[605/1000] loss: 0.08722088237603505
I0422 16:44:40.370771 34428 trainer.py:136] Epoch[606/1000] loss: 0.08683035771052043
I0422 16:44:45.574512 34428 trainer.py:136] Epoch[607/1000] loss: 0.08809258416295052
I0422 16:44:50.389253 34428 trainer.py:136] Epoch[608/1000] loss: 0.08659239858388901
I0422 16:44:57.748697 34428 trainer.py:136] Epoch[609/1000] loss: 0.08807811265190442
I0422 16:45:02.275503 34428 trainer.py:136] Epoch[610/1000] loss: 0.08731785540779431
I0422 16:45:07.414673 34428 trainer.py:136] Epoch[611/1000] loss: 0.0877089612185955
I0422 16:45:14.671266 34428 trainer.py:136] Epoch[612/1000] loss: 0.08740103617310524
I0422 16:45:19.943537 34428 trainer.py:136] Epoch[613/1000] loss: 0.08656186237931252
I0422 16:45:24.702547 34428 trainer.py:136] Epoch[614/1000] loss: 0.08732478072245915
I0422 16:45:29.348845 34428 trainer.py:136] Epoch[615/1000] loss: 0.08797507112224896
I0422 16:45:36.731717 34428 trainer.py:136] Epoch[616/1000] loss: 0.0869356965025266
I0422 16:45:41.682189 34428 trainer.py:136] Epoch[617/1000] loss: 0.0877714070181052
I0422 16:45:46.516841 34428 trainer.py:136] Epoch[618/1000] loss: 0.08714788282910983
I0422 16:45:54.960259 34428 trainer.py:136] Epoch[619/1000] loss: 0.08716972296436627
I0422 16:45:59.997043 34428 trainer.py:136] Epoch[620/1000] loss: 0.08692659065127373
I0422 16:46:04.836822 34428 trainer.py:136] Epoch[621/1000] loss: 0.08691482121745746
I0422 16:46:11.472094 34428 trainer.py:136] Epoch[622/1000] loss: 0.08783547828594844
I0422 16:46:17.436788 34428 trainer.py:136] Epoch[623/1000] loss: 0.08685268213351567
I0422 16:46:22.586467 34428 trainer.py:136] Epoch[624/1000] loss: 0.08721170822779338
I0422 16:46:29.075328 34428 trainer.py:136] Epoch[625/1000] loss: 0.08640398333470027
I0422 16:46:34.173817 34428 trainer.py:136] Epoch[626/1000] loss: 0.08741300428907077
I0422 16:46:38.525507 34428 trainer.py:136] Epoch[627/1000] loss: 0.08736113955577214
I0422 16:46:43.131287 34428 trainer.py:136] Epoch[628/1000] loss: 0.08645626778403918
I0422 16:46:49.375668 34428 trainer.py:136] Epoch[629/1000] loss: 0.08706185345848401
I0422 16:46:55.048471 34428 trainer.py:136] Epoch[630/1000] loss: 0.08681116501490276
I0422 16:46:59.702955 34428 trainer.py:136] Epoch[631/1000] loss: 0.08672559633851051
I0422 16:47:04.318958 34428 trainer.py:136] Epoch[632/1000] loss: 0.08690183237195015
I0422 16:47:08.916233 34428 trainer.py:136] Epoch[633/1000] loss: 0.08669833093881607
I0422 16:47:15.754424 34428 trainer.py:136] Epoch[634/1000] loss: 0.08757633964220683
I0422 16:47:20.326966 34428 trainer.py:136] Epoch[635/1000] loss: 0.08734488114714622
I0422 16:47:24.879057 34428 trainer.py:136] Epoch[636/1000] loss: 0.08782905712723732
I0422 16:47:29.395107 34428 trainer.py:136] Epoch[637/1000] loss: 0.08641322702169418
I0422 16:47:36.745848 34428 trainer.py:136] Epoch[638/1000] loss: 0.08691022917628288
I0422 16:47:41.145513 34428 trainer.py:136] Epoch[639/1000] loss: 0.08602690448363622
I0422 16:47:45.618218 34428 trainer.py:136] Epoch[640/1000] loss: 0.08691223586599033
I0422 16:47:50.090696 34428 trainer.py:136] Epoch[641/1000] loss: 0.08761165663599968
I0422 16:47:54.579984 34428 trainer.py:136] Epoch[642/1000] loss: 0.08732982600728671
I0422 16:48:01.740695 34428 trainer.py:136] Epoch[643/1000] loss: 0.08740195880333583
I0422 16:48:06.215017 34428 trainer.py:136] Epoch[644/1000] loss: 0.08679896841446559
I0422 16:48:10.759197 34428 trainer.py:136] Epoch[645/1000] loss: 0.08662259951233864
I0422 16:48:15.469950 34428 trainer.py:136] Epoch[646/1000] loss: 0.08760568623741467
I0422 16:48:22.761091 34428 trainer.py:136] Epoch[647/1000] loss: 0.08713459720214208
I0422 16:48:27.496636 34428 trainer.py:136] Epoch[648/1000] loss: 0.08714539309342702
I0422 16:48:32.023858 34428 trainer.py:136] Epoch[649/1000] loss: 0.08602461591362953
I0422 16:48:33.514031 34428 trainer.py:142] Test: [{'precision': 0.016227194982896233, 'recall': 0.07730253602210371, 'hit_ratio': 0.22277651083238312, 'ndcg': 0.05129265674237696}]
I0422 16:48:38.058677 34428 trainer.py:136] Epoch[650/1000] loss: 0.08640094101428986
I0422 16:48:44.107993 34428 trainer.py:136] Epoch[651/1000] loss: 0.08630987256765366
I0422 16:48:49.534760 34428 trainer.py:136] Epoch[652/1000] loss: 0.08703044801950455
I0422 16:48:54.101342 34428 trainer.py:136] Epoch[653/1000] loss: 0.0862766628464063
I0422 16:48:58.691884 34428 trainer.py:136] Epoch[654/1000] loss: 0.08656259005268414
I0422 16:49:03.044375 34428 trainer.py:136] Epoch[655/1000] loss: 0.08738591521978378
I0422 16:49:08.800463 34428 trainer.py:136] Epoch[656/1000] loss: 0.08688763777414958
I0422 16:49:14.202428 34428 trainer.py:136] Epoch[657/1000] loss: 0.08649161830544472
I0422 16:49:18.473510 34428 trainer.py:136] Epoch[658/1000] loss: 0.0867000271876653
I0422 16:49:22.869077 34428 trainer.py:136] Epoch[659/1000] loss: 0.08616443475087483
I0422 16:49:27.209372 34428 trainer.py:136] Epoch[660/1000] loss: 0.08643013735612233
I0422 16:49:33.654882 34428 trainer.py:136] Epoch[661/1000] loss: 0.08593524744113286
I0422 16:49:38.561390 34428 trainer.py:136] Epoch[662/1000] loss: 0.086939986795187
I0422 16:49:42.913071 34428 trainer.py:136] Epoch[663/1000] loss: 0.08533190935850143
I0422 16:49:47.211484 34428 trainer.py:136] Epoch[664/1000] loss: 0.08596739172935486
I0422 16:49:51.520394 34428 trainer.py:136] Epoch[665/1000] loss: 0.08634444201985995
I0422 16:49:58.338547 34428 trainer.py:136] Epoch[666/1000] loss: 0.08624901498357455
I0422 16:50:02.639029 34428 trainer.py:136] Epoch[667/1000] loss: 0.08651976411541303
I0422 16:50:06.924634 34428 trainer.py:136] Epoch[668/1000] loss: 0.08680165683229764
I0422 16:50:11.317238 34428 trainer.py:136] Epoch[669/1000] loss: 0.08652849371234576
I0422 16:50:15.683812 34428 trainer.py:136] Epoch[670/1000] loss: 0.0860733079413573
I0422 16:50:22.491321 34428 trainer.py:136] Epoch[671/1000] loss: 0.08545222505927086
I0422 16:50:26.792410 34428 trainer.py:136] Epoch[672/1000] loss: 0.08564930533369382
I0422 16:50:31.059997 34428 trainer.py:136] Epoch[673/1000] loss: 0.08560299376646678
I0422 16:50:35.309641 34428 trainer.py:136] Epoch[674/1000] loss: 0.08624448751409848
I0422 16:50:40.982212 34428 trainer.py:136] Epoch[675/1000] loss: 0.08637409160534541
I0422 16:50:46.463818 34428 trainer.py:136] Epoch[676/1000] loss: 0.08661280696590741
I0422 16:50:50.814306 34428 trainer.py:136] Epoch[677/1000] loss: 0.08585347111026446
I0422 16:50:55.138721 34428 trainer.py:136] Epoch[678/1000] loss: 0.08598281070590019
I0422 16:50:59.359384 34428 trainer.py:136] Epoch[679/1000] loss: 0.08600185563166936
I0422 16:51:06.115391 34428 trainer.py:136] Epoch[680/1000] loss: 0.08548316359519958
I0422 16:51:10.349562 34428 trainer.py:136] Epoch[681/1000] loss: 0.08721453448136647
I0422 16:51:14.709011 34428 trainer.py:136] Epoch[682/1000] loss: 0.0860772393643856
I0422 16:51:19.142592 34428 trainer.py:136] Epoch[683/1000] loss: 0.0862954743206501
I0422 16:51:23.953841 34428 trainer.py:136] Epoch[684/1000] loss: 0.08590648944179217
I0422 16:51:30.602601 34428 trainer.py:136] Epoch[685/1000] loss: 0.08592064802845319
I0422 16:51:35.111797 34428 trainer.py:136] Epoch[686/1000] loss: 0.08597767973939578
I0422 16:51:39.479915 34428 trainer.py:136] Epoch[687/1000] loss: 0.08604632318019867
I0422 16:51:43.968135 34428 trainer.py:136] Epoch[688/1000] loss: 0.08614731455842654
I0422 16:51:51.335602 34428 trainer.py:136] Epoch[689/1000] loss: 0.08567304660876592
I0422 16:51:56.105962 34428 trainer.py:136] Epoch[690/1000] loss: 0.0852891964217027
I0422 16:52:01.060967 34428 trainer.py:136] Epoch[691/1000] loss: 0.08480932315190633
I0422 16:52:08.662705 34428 trainer.py:136] Epoch[692/1000] loss: 0.08627454191446304
I0422 16:52:13.523283 34428 trainer.py:136] Epoch[693/1000] loss: 0.08665366222461064
I0422 16:52:18.547924 34428 trainer.py:136] Epoch[694/1000] loss: 0.08650122582912445
I0422 16:52:25.743857 34428 trainer.py:136] Epoch[695/1000] loss: 0.08577732741832733
I0422 16:52:31.019398 34428 trainer.py:136] Epoch[696/1000] loss: 0.08516446873545647
I0422 16:52:35.852385 34428 trainer.py:136] Epoch[697/1000] loss: 0.08603022247552872
I0422 16:52:43.322824 34428 trainer.py:136] Epoch[698/1000] loss: 0.08629293367266655
I0422 16:52:48.992302 34428 trainer.py:136] Epoch[699/1000] loss: 0.08540519202748935
I0422 16:52:50.682847 34428 trainer.py:142] Test: [{'precision': 0.016291334093500563, 'recall': 0.07743568350273451, 'hit_ratio': 0.2234891676168757, 'ndcg': 0.051681983841343725}]
I0422 16:52:55.566242 34428 trainer.py:136] Epoch[700/1000] loss: 0.08589796473582585
I0422 16:53:02.908068 34428 trainer.py:136] Epoch[701/1000] loss: 0.08583180358012517
I0422 16:53:07.642106 34428 trainer.py:136] Epoch[702/1000] loss: 0.085389893501997
I0422 16:53:12.622979 34428 trainer.py:136] Epoch[703/1000] loss: 0.08539768556753795
I0422 16:53:20.481294 34428 trainer.py:136] Epoch[704/1000] loss: 0.08476502075791359
I0422 16:53:25.229327 34428 trainer.py:136] Epoch[705/1000] loss: 0.08521213009953499
I0422 16:53:30.106310 34428 trainer.py:136] Epoch[706/1000] loss: 0.08519208927949269
I0422 16:53:38.338876 34428 trainer.py:136] Epoch[707/1000] loss: 0.08607590571045876
I0422 16:53:43.294015 34428 trainer.py:136] Epoch[708/1000] loss: 0.08523770173390706
I0422 16:53:48.305207 34428 trainer.py:136] Epoch[709/1000] loss: 0.08578056966265042
I0422 16:53:56.103362 34428 trainer.py:136] Epoch[710/1000] loss: 0.08536738157272339
I0422 16:54:01.431938 34428 trainer.py:136] Epoch[711/1000] loss: 0.08646192774176598
I0422 16:54:07.943159 34428 trainer.py:136] Epoch[712/1000] loss: 0.08562969292203586
I0422 16:54:14.674512 34428 trainer.py:136] Epoch[713/1000] loss: 0.08651373659571011
I0422 16:54:19.543720 34428 trainer.py:136] Epoch[714/1000] loss: 0.08505801111459732
I0422 16:54:26.872114 34428 trainer.py:136] Epoch[715/1000] loss: 0.08394669617215793
I0422 16:54:32.919967 34428 trainer.py:136] Epoch[716/1000] loss: 0.08528892199198405
I0422 16:54:38.309422 34428 trainer.py:136] Epoch[717/1000] loss: 0.08556614940365155
I0422 16:54:46.331180 34428 trainer.py:136] Epoch[718/1000] loss: 0.08536939074595769
I0422 16:54:51.437750 34428 trainer.py:136] Epoch[719/1000] loss: 0.08438442274928093
I0422 16:54:56.553857 34428 trainer.py:136] Epoch[720/1000] loss: 0.08574770018458366
I0422 16:55:04.573371 34428 trainer.py:136] Epoch[721/1000] loss: 0.0860326128701369
I0422 16:55:09.493793 34428 trainer.py:136] Epoch[722/1000] loss: 0.08472898478309314
I0422 16:55:14.606828 34428 trainer.py:136] Epoch[723/1000] loss: 0.08573334043224652
I0422 16:55:22.589960 34428 trainer.py:136] Epoch[724/1000] loss: 0.08510924751559894
I0422 16:55:27.662721 34428 trainer.py:136] Epoch[725/1000] loss: 0.08539546156922977
I0422 16:55:32.654922 34428 trainer.py:136] Epoch[726/1000] loss: 0.08496062830090523
I0422 16:55:40.581374 34428 trainer.py:136] Epoch[727/1000] loss: 0.08610124389330547
I0422 16:55:45.773900 34428 trainer.py:136] Epoch[728/1000] loss: 0.08469505856434505
I0422 16:55:50.806166 34428 trainer.py:136] Epoch[729/1000] loss: 0.08534562463561694
I0422 16:55:58.937345 34428 trainer.py:136] Epoch[730/1000] loss: 0.08494253704945247
I0422 16:56:04.098951 34428 trainer.py:136] Epoch[731/1000] loss: 0.08659559364120166
I0422 16:56:09.255148 34428 trainer.py:136] Epoch[732/1000] loss: 0.08554352819919586
I0422 16:56:17.149760 34428 trainer.py:136] Epoch[733/1000] loss: 0.08518184348940849
I0422 16:56:22.388436 34428 trainer.py:136] Epoch[734/1000] loss: 0.08583657443523407
I0422 16:56:27.450066 34428 trainer.py:136] Epoch[735/1000] loss: 0.08482203508416812
I0422 16:56:35.901619 34428 trainer.py:136] Epoch[736/1000] loss: 0.08399908989667892
I0422 16:56:41.128590 34428 trainer.py:136] Epoch[737/1000] loss: 0.08609840522209804
I0422 16:56:46.375108 34428 trainer.py:136] Epoch[738/1000] loss: 0.0855966421465079
I0422 16:56:54.486391 34428 trainer.py:136] Epoch[739/1000] loss: 0.0846036250392596
I0422 16:56:59.281278 34428 trainer.py:136] Epoch[740/1000] loss: 0.08472380166252454
I0422 16:57:03.975893 34428 trainer.py:136] Epoch[741/1000] loss: 0.08504145344098409
I0422 16:57:11.178318 34428 trainer.py:136] Epoch[742/1000] loss: 0.08428866912921269
I0422 16:57:15.887836 34428 trainer.py:136] Epoch[743/1000] loss: 0.08577040955424309
I0422 16:57:20.323358 34428 trainer.py:136] Epoch[744/1000] loss: 0.08481436098615329
I0422 16:57:24.826932 34428 trainer.py:136] Epoch[745/1000] loss: 0.08532975241541862
I0422 16:57:32.209424 34428 trainer.py:136] Epoch[746/1000] loss: 0.08395287518699963
I0422 16:57:37.066478 34428 trainer.py:136] Epoch[747/1000] loss: 0.08468728885054588
I0422 16:57:42.142000 34428 trainer.py:136] Epoch[748/1000] loss: 0.0857694111764431
I0422 16:57:50.550263 34428 trainer.py:136] Epoch[749/1000] loss: 0.08577857663234074
I0422 16:57:52.541765 34428 trainer.py:142] Test: [{'precision': 0.016391106043329523, 'recall': 0.07766386097166661, 'hit_ratio': 0.22576966932725198, 'ndcg': 0.05174016773983556}]
I0422 16:57:58.056919 34428 trainer.py:136] Epoch[750/1000] loss: 0.08407004301746686
I0422 16:58:06.461096 34428 trainer.py:136] Epoch[751/1000] loss: 0.08499555910627048
I0422 16:58:11.883281 34428 trainer.py:136] Epoch[752/1000] loss: 0.08466047917803128
I0422 16:58:19.084609 34428 trainer.py:136] Epoch[753/1000] loss: 0.0845530057946841
I0422 16:58:24.929964 34428 trainer.py:136] Epoch[754/1000] loss: 0.08442384377121925
I0422 16:58:30.525801 34428 trainer.py:136] Epoch[755/1000] loss: 0.08530535052220027
I0422 16:58:38.875110 34428 trainer.py:136] Epoch[756/1000] loss: 0.08439614499608676
I0422 16:58:43.978002 34428 trainer.py:136] Epoch[757/1000] loss: 0.0848679319024086
I0422 16:58:52.308049 34428 trainer.py:136] Epoch[758/1000] loss: 0.08523817732930183
I0422 16:58:57.189594 34428 trainer.py:136] Epoch[759/1000] loss: 0.08499425897995631
I0422 16:59:01.846287 34428 trainer.py:136] Epoch[760/1000] loss: 0.08483993262052536
I0422 16:59:09.633960 34428 trainer.py:136] Epoch[761/1000] loss: 0.08469598864515622
I0422 16:59:14.681681 34428 trainer.py:136] Epoch[762/1000] loss: 0.08484439551830292
I0422 16:59:19.835256 34428 trainer.py:136] Epoch[763/1000] loss: 0.08457382520039876
I0422 16:59:27.512461 34428 trainer.py:136] Epoch[764/1000] loss: 0.08606614420811336
I0422 16:59:32.570399 34428 trainer.py:136] Epoch[765/1000] loss: 0.08463083455959956
I0422 16:59:37.648783 34428 trainer.py:136] Epoch[766/1000] loss: 0.08445899561047554
I0422 16:59:45.557162 34428 trainer.py:136] Epoch[767/1000] loss: 0.08408236751953761
I0422 16:59:50.517346 34428 trainer.py:136] Epoch[768/1000] loss: 0.08365781977772713
I0422 16:59:55.583866 34428 trainer.py:136] Epoch[769/1000] loss: 0.08517476916313171
I0422 17:00:03.480759 34428 trainer.py:136] Epoch[770/1000] loss: 0.08531758685906728
I0422 17:00:08.420082 34428 trainer.py:136] Epoch[771/1000] loss: 0.08476261173685391
I0422 17:00:13.321768 34428 trainer.py:136] Epoch[772/1000] loss: 0.08517718563477199
I0422 17:00:21.223058 34428 trainer.py:136] Epoch[773/1000] loss: 0.08447189877430598
I0422 17:00:26.259081 34428 trainer.py:136] Epoch[774/1000] loss: 0.0846885306139787
I0422 17:00:31.329254 34428 trainer.py:136] Epoch[775/1000] loss: 0.08498889332016309
I0422 17:00:39.357023 34428 trainer.py:136] Epoch[776/1000] loss: 0.08398121471206348
I0422 17:00:44.371100 34428 trainer.py:136] Epoch[777/1000] loss: 0.0845139001806577
I0422 17:00:49.392225 34428 trainer.py:136] Epoch[778/1000] loss: 0.08436939989527066
I0422 17:00:57.409128 34428 trainer.py:136] Epoch[779/1000] loss: 0.08486819018920262
I0422 17:01:02.663426 34428 trainer.py:136] Epoch[780/1000] loss: 0.08533658211429913
I0422 17:01:07.753224 34428 trainer.py:136] Epoch[781/1000] loss: 0.08562119180957477
I0422 17:01:15.571443 34428 trainer.py:136] Epoch[782/1000] loss: 0.08465810865163803
I0422 17:01:20.703539 34428 trainer.py:136] Epoch[783/1000] loss: 0.08476176982124646
I0422 17:01:26.325293 34428 trainer.py:136] Epoch[784/1000] loss: 0.08406062920888265
I0422 17:01:33.578723 34428 trainer.py:136] Epoch[785/1000] loss: 0.08385243515173595
I0422 17:01:38.602815 34428 trainer.py:136] Epoch[786/1000] loss: 0.08487362787127495
I0422 17:01:45.091915 34428 trainer.py:136] Epoch[787/1000] loss: 0.08485779414574306
I0422 17:01:51.594021 34428 trainer.py:136] Epoch[788/1000] loss: 0.08428298681974411
I0422 17:01:56.606176 34428 trainer.py:136] Epoch[789/1000] loss: 0.08471594999233882
I0422 17:02:03.814108 34428 trainer.py:136] Epoch[790/1000] loss: 0.0849132922788461
I0422 17:02:09.634110 34428 trainer.py:136] Epoch[791/1000] loss: 0.08480807642141978
I0422 17:02:14.733323 34428 trainer.py:136] Epoch[792/1000] loss: 0.0844202737013499
I0422 17:02:22.468135 34428 trainer.py:136] Epoch[793/1000] loss: 0.08440362041195233
I0422 17:02:27.509018 34428 trainer.py:136] Epoch[794/1000] loss: 0.08538299674789111
I0422 17:02:32.566473 34428 trainer.py:136] Epoch[795/1000] loss: 0.08459467565019925
I0422 17:02:40.447279 34428 trainer.py:136] Epoch[796/1000] loss: 0.08459192886948586
I0422 17:02:45.537150 34428 trainer.py:136] Epoch[797/1000] loss: 0.08369204153617223
I0422 17:02:51.029897 34428 trainer.py:136] Epoch[798/1000] loss: 0.08425243571400642
I0422 17:02:57.827955 34428 trainer.py:136] Epoch[799/1000] loss: 0.08418768023451169
I0422 17:02:59.297297 34428 trainer.py:142] Test: [{'precision': 0.016433865450399075, 'recall': 0.07844790789221795, 'hit_ratio': 0.22676738882554162, 'ndcg': 0.05224230242414268}]
I0422 17:03:03.754333 34428 trainer.py:136] Epoch[800/1000] loss: 0.08451320106784503
I0422 17:03:08.433620 34428 trainer.py:136] Epoch[801/1000] loss: 0.08487593506773312
I0422 17:03:15.571480 34428 trainer.py:136] Epoch[802/1000] loss: 0.08421370262900989
I0422 17:03:20.222706 34428 trainer.py:136] Epoch[803/1000] loss: 0.08369943002859752
I0422 17:03:24.694430 34428 trainer.py:136] Epoch[804/1000] loss: 0.08433055380980174
I0422 17:03:29.315012 34428 trainer.py:136] Epoch[805/1000] loss: 0.08466438949108124
I0422 17:03:33.877029 34428 trainer.py:136] Epoch[806/1000] loss: 0.08391864473621051
I0422 17:03:38.430649 34428 trainer.py:136] Epoch[807/1000] loss: 0.08409205575784047
I0422 17:03:45.489126 34428 trainer.py:136] Epoch[808/1000] loss: 0.08432816714048386
I0422 17:03:49.864385 34428 trainer.py:136] Epoch[809/1000] loss: 0.08486951018373172
I0422 17:03:54.362927 34428 trainer.py:136] Epoch[810/1000] loss: 0.08427755162119865
I0422 17:03:58.946226 34428 trainer.py:136] Epoch[811/1000] loss: 0.08332171539465587
I0422 17:04:05.765496 34428 trainer.py:136] Epoch[812/1000] loss: 0.0840285209318002
I0422 17:04:10.884999 34428 trainer.py:136] Epoch[813/1000] loss: 0.08539456129074097
I0422 17:04:15.419507 34428 trainer.py:136] Epoch[814/1000] loss: 0.08366384729743004
I0422 17:04:19.969433 34428 trainer.py:136] Epoch[815/1000] loss: 0.08404367168744405
I0422 17:04:26.231650 34428 trainer.py:136] Epoch[816/1000] loss: 0.08372010663151741
I0422 17:04:31.903535 34428 trainer.py:136] Epoch[817/1000] loss: 0.08462320392330487
I0422 17:04:36.442804 34428 trainer.py:136] Epoch[818/1000] loss: 0.08386893197894096
I0422 17:04:40.909148 34428 trainer.py:136] Epoch[819/1000] loss: 0.08337228248516719
I0422 17:04:46.211200 34428 trainer.py:136] Epoch[820/1000] loss: 0.08495453124245007
I0422 17:04:52.599138 34428 trainer.py:136] Epoch[821/1000] loss: 0.08417391031980515
I0422 17:04:57.196950 34428 trainer.py:136] Epoch[822/1000] loss: 0.08513642599185307
I0422 17:05:01.715169 34428 trainer.py:136] Epoch[823/1000] loss: 0.08321663613120715
I0422 17:05:06.411464 34428 trainer.py:136] Epoch[824/1000] loss: 0.08487705265482266
I0422 17:05:10.901274 34428 trainer.py:136] Epoch[825/1000] loss: 0.08397066717346509
I0422 17:05:15.439038 34428 trainer.py:136] Epoch[826/1000] loss: 0.0841159460445245
I0422 17:05:19.887450 34428 trainer.py:136] Epoch[827/1000] loss: 0.08466027677059174
I0422 17:05:26.974795 34428 trainer.py:136] Epoch[828/1000] loss: 0.08371375625332196
I0422 17:05:31.360824 34428 trainer.py:136] Epoch[829/1000] loss: 0.08457175021370252
I0422 17:05:35.888653 34428 trainer.py:136] Epoch[830/1000] loss: 0.08495753382643063
I0422 17:05:40.424302 34428 trainer.py:136] Epoch[831/1000] loss: 0.08449047679702441
I0422 17:05:44.904613 34428 trainer.py:136] Epoch[832/1000] loss: 0.08282103762030602
I0422 17:05:49.335604 34428 trainer.py:136] Epoch[833/1000] loss: 0.08423871174454689
I0422 17:05:56.082273 34428 trainer.py:136] Epoch[834/1000] loss: 0.08280469477176666
I0422 17:06:00.417815 34428 trainer.py:136] Epoch[835/1000] loss: 0.0839618407189846
I0422 17:06:04.892194 34428 trainer.py:136] Epoch[836/1000] loss: 0.08396835997700691
I0422 17:06:09.289918 34428 trainer.py:136] Epoch[837/1000] loss: 0.08392681802312534
I0422 17:06:13.818317 34428 trainer.py:136] Epoch[838/1000] loss: 0.08465407167871793
I0422 17:06:18.311329 34428 trainer.py:136] Epoch[839/1000] loss: 0.08361524467666943
I0422 17:06:24.912244 34428 trainer.py:136] Epoch[840/1000] loss: 0.08273165052135785
I0422 17:06:29.602469 34428 trainer.py:136] Epoch[841/1000] loss: 0.08403129503130913
I0422 17:06:34.069409 34428 trainer.py:136] Epoch[842/1000] loss: 0.08375980705022812
I0422 17:06:38.509428 34428 trainer.py:136] Epoch[843/1000] loss: 0.08388305082917213
I0422 17:06:43.052499 34428 trainer.py:136] Epoch[844/1000] loss: 0.08430248374740283
I0422 17:06:47.595290 34428 trainer.py:136] Epoch[845/1000] loss: 0.08285394807656606
I0422 17:06:52.121200 34428 trainer.py:136] Epoch[846/1000] loss: 0.08410575613379478
I0422 17:06:58.996784 34428 trainer.py:136] Epoch[847/1000] loss: 0.08369038254022598
I0422 17:07:03.414945 34428 trainer.py:136] Epoch[848/1000] loss: 0.08335548142592113
I0422 17:07:07.923723 34428 trainer.py:136] Epoch[849/1000] loss: 0.08433092013001442
I0422 17:07:09.372994 34428 trainer.py:142] Test: [{'precision': 0.01651225769669326, 'recall': 0.07868720894303306, 'hit_ratio': 0.22776510832383123, 'ndcg': 0.052317612590626575}]
I0422 17:07:13.960909 34428 trainer.py:136] Epoch[850/1000] loss: 0.08458088090022405
I0422 17:07:18.514499 34428 trainer.py:136] Epoch[851/1000] loss: 0.0841493122279644
I0422 17:07:24.199460 34428 trainer.py:136] Epoch[852/1000] loss: 0.08463737244407336
I0422 17:07:30.024817 34428 trainer.py:136] Epoch[853/1000] loss: 0.08373962218562762
I0422 17:07:34.499743 34428 trainer.py:136] Epoch[854/1000] loss: 0.08348340416948001
I0422 17:07:39.004186 34428 trainer.py:136] Epoch[855/1000] loss: 0.08370299140612285
I0422 17:07:43.444266 34428 trainer.py:136] Epoch[856/1000] loss: 0.08269030476609866
I0422 17:07:47.977346 34428 trainer.py:136] Epoch[857/1000] loss: 0.08416185279687245
I0422 17:07:54.464718 34428 trainer.py:136] Epoch[858/1000] loss: 0.08358464762568474
I0422 17:07:59.618350 34428 trainer.py:136] Epoch[859/1000] loss: 0.08392199377218883
I0422 17:08:04.114905 34428 trainer.py:136] Epoch[860/1000] loss: 0.08341242993871371
I0422 17:08:08.546986 34428 trainer.py:136] Epoch[861/1000] loss: 0.08513069897890091
I0422 17:08:12.902794 34428 trainer.py:136] Epoch[862/1000] loss: 0.08387980610132217
I0422 17:08:17.487256 34428 trainer.py:136] Epoch[863/1000] loss: 0.08387193952997525
I0422 17:08:24.364454 34428 trainer.py:136] Epoch[864/1000] loss: 0.08426444480816524
I0422 17:08:28.928256 34428 trainer.py:136] Epoch[865/1000] loss: 0.08440818140904109
I0422 17:08:33.437071 34428 trainer.py:136] Epoch[866/1000] loss: 0.0841347190241019
I0422 17:08:37.898365 34428 trainer.py:136] Epoch[867/1000] loss: 0.08351186662912369
I0422 17:08:42.332365 34428 trainer.py:136] Epoch[868/1000] loss: 0.08417101204395294
I0422 17:08:46.973195 34428 trainer.py:136] Epoch[869/1000] loss: 0.08386299759149551
I0422 17:08:53.965984 34428 trainer.py:136] Epoch[870/1000] loss: 0.08422636364897092
I0422 17:08:58.457347 34428 trainer.py:136] Epoch[871/1000] loss: 0.08299346764882405
I0422 17:09:02.859912 34428 trainer.py:136] Epoch[872/1000] loss: 0.0838419571518898
I0422 17:09:07.180350 34428 trainer.py:136] Epoch[873/1000] loss: 0.08405012140671413
I0422 17:09:11.800635 34428 trainer.py:136] Epoch[874/1000] loss: 0.08390503625075023
I0422 17:09:17.671488 34428 trainer.py:136] Epoch[875/1000] loss: 0.08348567659656207
I0422 17:09:23.435299 34428 trainer.py:136] Epoch[876/1000] loss: 0.08454918613036473
I0422 17:09:28.339622 34428 trainer.py:136] Epoch[877/1000] loss: 0.08437107006708781
I0422 17:09:34.164824 34428 trainer.py:136] Epoch[878/1000] loss: 0.08415873721241951
I0422 17:09:40.594854 34428 trainer.py:136] Epoch[879/1000] loss: 0.08371073380112648
I0422 17:09:45.769298 34428 trainer.py:136] Epoch[880/1000] loss: 0.08351728320121765
I0422 17:09:51.746773 34428 trainer.py:136] Epoch[881/1000] loss: 0.08371181786060333
I0422 17:09:58.953806 34428 trainer.py:136] Epoch[882/1000] loss: 0.08347733070453008
I0422 17:10:04.263560 34428 trainer.py:136] Epoch[883/1000] loss: 0.08335672070582707
I0422 17:10:12.333564 34428 trainer.py:136] Epoch[884/1000] loss: 0.08267538249492645
I0422 17:10:17.460244 34428 trainer.py:136] Epoch[885/1000] loss: 0.08513753985365231
I0422 17:10:22.717186 34428 trainer.py:136] Epoch[886/1000] loss: 0.08393192167083423
I0422 17:10:31.031976 34428 trainer.py:136] Epoch[887/1000] loss: 0.08307361975312233
I0422 17:10:36.232924 34428 trainer.py:136] Epoch[888/1000] loss: 0.08331334839264552
I0422 17:10:41.631321 34428 trainer.py:136] Epoch[889/1000] loss: 0.08467469985286395
I0422 17:10:49.795931 34428 trainer.py:136] Epoch[890/1000] loss: 0.08392716447512309
I0422 17:10:55.243122 34428 trainer.py:136] Epoch[891/1000] loss: 0.08277776837348938
I0422 17:11:01.940814 34428 trainer.py:136] Epoch[892/1000] loss: 0.08382687096794446
I0422 17:11:08.251687 34428 trainer.py:136] Epoch[893/1000] loss: 0.08380122358600299
I0422 17:11:13.621395 34428 trainer.py:136] Epoch[894/1000] loss: 0.08253922561804454
I0422 17:11:21.906409 34428 trainer.py:136] Epoch[895/1000] loss: 0.08390212928255399
I0422 17:11:27.124739 34428 trainer.py:136] Epoch[896/1000] loss: 0.08373703931768735
I0422 17:11:32.206084 34428 trainer.py:136] Epoch[897/1000] loss: 0.08305128663778305
I0422 17:11:40.476311 34428 trainer.py:136] Epoch[898/1000] loss: 0.08367511878410976
I0422 17:11:45.933980 34428 trainer.py:136] Epoch[899/1000] loss: 0.08370501672228177
I0422 17:11:47.828768 34428 trainer.py:142] Test: [{'precision': 0.016547890535917893, 'recall': 0.07891156371645204, 'hit_ratio': 0.22690992018244013, 'ndcg': 0.05245755201692761}]
I0422 17:11:56.143842 34428 trainer.py:136] Epoch[900/1000] loss: 0.08345728119214375
I0422 17:12:01.221702 34428 trainer.py:136] Epoch[901/1000] loss: 0.08231629555424054
I0422 17:12:06.491957 34428 trainer.py:136] Epoch[902/1000] loss: 0.0829261268178622
I0422 17:12:14.528250 34428 trainer.py:136] Epoch[903/1000] loss: 0.08388431370258331
I0422 17:12:19.396687 34428 trainer.py:136] Epoch[904/1000] loss: 0.0841938890516758
I0422 17:12:24.673071 34428 trainer.py:136] Epoch[905/1000] loss: 0.08335121224323909
I0422 17:12:33.349480 34428 trainer.py:136] Epoch[906/1000] loss: 0.0836865504582723
I0422 17:12:38.586831 34428 trainer.py:136] Epoch[907/1000] loss: 0.08385166650017102
I0422 17:12:45.227497 34428 trainer.py:136] Epoch[908/1000] loss: 0.08362194647391637
I0422 17:12:51.722185 34428 trainer.py:136] Epoch[909/1000] loss: 0.08253072450558345
I0422 17:12:57.158344 34428 trainer.py:136] Epoch[910/1000] loss: 0.08348983774582545
I0422 17:13:05.694193 34428 trainer.py:136] Epoch[911/1000] loss: 0.08309638624389966
I0422 17:13:10.914068 34428 trainer.py:136] Epoch[912/1000] loss: 0.08404417584339778
I0422 17:13:16.540642 34428 trainer.py:136] Epoch[913/1000] loss: 0.08354768405357997
I0422 17:13:24.222368 34428 trainer.py:136] Epoch[914/1000] loss: 0.08342556531230609
I0422 17:13:29.239033 34428 trainer.py:136] Epoch[915/1000] loss: 0.08272005741794904
I0422 17:13:36.288220 34428 trainer.py:136] Epoch[916/1000] loss: 0.08392994726697604
I0422 17:13:42.317563 34428 trainer.py:136] Epoch[917/1000] loss: 0.08292362590630849
I0422 17:13:47.742494 34428 trainer.py:136] Epoch[918/1000] loss: 0.08277783667047818
I0422 17:13:56.001525 34428 trainer.py:136] Epoch[919/1000] loss: 0.0830556886891524
I0422 17:14:01.102293 34428 trainer.py:136] Epoch[920/1000] loss: 0.08340976138909657
I0422 17:14:06.767455 34428 trainer.py:136] Epoch[921/1000] loss: 0.08377905562520027
I0422 17:14:14.582295 34428 trainer.py:136] Epoch[922/1000] loss: 0.08317335198322932
I0422 17:14:19.877001 34428 trainer.py:136] Epoch[923/1000] loss: 0.08365446080764134
I0422 17:14:28.408346 34428 trainer.py:136] Epoch[924/1000] loss: 0.08279448375105858
I0422 17:14:33.586898 34428 trainer.py:136] Epoch[925/1000] loss: 0.08401587853829066
I0422 17:14:40.173020 34428 trainer.py:136] Epoch[926/1000] loss: 0.0830321970085303
I0422 17:14:46.755631 34428 trainer.py:136] Epoch[927/1000] loss: 0.08313416813810666
I0422 17:14:52.243381 34428 trainer.py:136] Epoch[928/1000] loss: 0.08290666093428929
I0422 17:15:00.329732 34428 trainer.py:136] Epoch[929/1000] loss: 0.08308129136761029
I0422 17:15:05.716893 34428 trainer.py:136] Epoch[930/1000] loss: 0.08222926283876102
I0422 17:15:12.321857 34428 trainer.py:136] Epoch[931/1000] loss: 0.08370908349752426
I0422 17:15:19.381285 34428 trainer.py:136] Epoch[932/1000] loss: 0.0832914337515831
I0422 17:15:24.570820 34428 trainer.py:136] Epoch[933/1000] loss: 0.08285506069660187
I0422 17:15:32.548760 34428 trainer.py:136] Epoch[934/1000] loss: 0.08343024676044782
I0422 17:15:37.745059 34428 trainer.py:136] Epoch[935/1000] loss: 0.08322277789314587
I0422 17:15:45.446085 34428 trainer.py:136] Epoch[936/1000] loss: 0.08322007705767949
I0422 17:15:50.873942 34428 trainer.py:136] Epoch[937/1000] loss: 0.08331166580319405
I0422 17:15:55.911004 34428 trainer.py:136] Epoch[938/1000] loss: 0.08223290989796321
I0422 17:16:04.031127 34428 trainer.py:136] Epoch[939/1000] loss: 0.08311495433251063
I0422 17:16:09.316656 34428 trainer.py:136] Epoch[940/1000] loss: 0.08319780106345813
I0422 17:16:14.571994 34428 trainer.py:136] Epoch[941/1000] loss: 0.08295934523145358
I0422 17:16:22.670614 34428 trainer.py:136] Epoch[942/1000] loss: 0.08236994097630183
I0422 17:16:27.813981 34428 trainer.py:136] Epoch[943/1000] loss: 0.08310282106200854
I0422 17:16:35.519295 34428 trainer.py:136] Epoch[944/1000] loss: 0.08423657342791557
I0422 17:16:40.554351 34428 trainer.py:136] Epoch[945/1000] loss: 0.08300303295254707
I0422 17:16:45.576757 34428 trainer.py:136] Epoch[946/1000] loss: 0.08343201378981273
I0422 17:16:53.301418 34428 trainer.py:136] Epoch[947/1000] loss: 0.08348396047949791
I0422 17:16:58.143627 34428 trainer.py:136] Epoch[948/1000] loss: 0.08246658866604169
I0422 17:17:03.023638 34428 trainer.py:136] Epoch[949/1000] loss: 0.08362162361542384
I0422 17:17:05.228109 34428 trainer.py:142] Test: [{'precision': 0.016647662485746857, 'recall': 0.07939074343050342, 'hit_ratio': 0.2281927023945268, 'ndcg': 0.052908456722643604}]
I0422 17:17:12.418247 34428 trainer.py:136] Epoch[950/1000] loss: 0.0838135580221812
I0422 17:17:17.439825 34428 trainer.py:136] Epoch[951/1000] loss: 0.0831311469276746
I0422 17:17:24.444154 34428 trainer.py:136] Epoch[952/1000] loss: 0.08396130924423535
I0422 17:17:30.075407 34428 trainer.py:136] Epoch[953/1000] loss: 0.08320975427826245
I0422 17:17:35.016748 34428 trainer.py:136] Epoch[954/1000] loss: 0.0829037328561147
I0422 17:17:43.061081 34428 trainer.py:136] Epoch[955/1000] loss: 0.08275473862886429
I0422 17:17:47.917861 34428 trainer.py:136] Epoch[956/1000] loss: 0.08258675038814545
I0422 17:17:53.166774 34428 trainer.py:136] Epoch[957/1000] loss: 0.08350338662664096
I0422 17:18:00.593108 34428 trainer.py:136] Epoch[958/1000] loss: 0.08380602796872456
I0422 17:18:05.539091 34428 trainer.py:136] Epoch[959/1000] loss: 0.08289770533641179
I0422 17:18:10.616384 34428 trainer.py:136] Epoch[960/1000] loss: 0.08250036587317784
I0422 17:18:18.652175 34428 trainer.py:136] Epoch[961/1000] loss: 0.0829157109061877
I0422 17:18:23.531715 34428 trainer.py:136] Epoch[962/1000] loss: 0.08295399819811185
I0422 17:18:31.060867 34428 trainer.py:136] Epoch[963/1000] loss: 0.08310485382874806
I0422 17:18:37.244543 34428 trainer.py:136] Epoch[964/1000] loss: 0.08264524241288503
I0422 17:18:42.532833 34428 trainer.py:136] Epoch[965/1000] loss: 0.08369758849342664
I0422 17:18:50.906217 34428 trainer.py:136] Epoch[966/1000] loss: 0.08242227012912433
I0422 17:18:56.060885 34428 trainer.py:136] Epoch[967/1000] loss: 0.08240934585531552
I0422 17:19:03.449252 34428 trainer.py:136] Epoch[968/1000] loss: 0.08374187722802162
I0422 17:19:09.686679 34428 trainer.py:136] Epoch[969/1000] loss: 0.08246829981605212
I0422 17:19:14.864110 34428 trainer.py:136] Epoch[970/1000] loss: 0.0820126086473465
I0422 17:19:23.020044 34428 trainer.py:136] Epoch[971/1000] loss: 0.08296894406278928
I0422 17:19:28.229859 34428 trainer.py:136] Epoch[972/1000] loss: 0.08253370101253192
I0422 17:19:34.826867 34428 trainer.py:136] Epoch[973/1000] loss: 0.0835697241127491
I0422 17:19:41.681201 34428 trainer.py:136] Epoch[974/1000] loss: 0.08215067535638809
I0422 17:19:46.837668 34428 trainer.py:136] Epoch[975/1000] loss: 0.08329903955260913
I0422 17:19:55.355013 34428 trainer.py:136] Epoch[976/1000] loss: 0.08372803156574567
I0422 17:20:00.527706 34428 trainer.py:136] Epoch[977/1000] loss: 0.08190314595897992
I0422 17:20:05.623165 34428 trainer.py:136] Epoch[978/1000] loss: 0.08306853100657463
I0422 17:20:13.947028 34428 trainer.py:136] Epoch[979/1000] loss: 0.082012423624595
I0422 17:20:19.270142 34428 trainer.py:136] Epoch[980/1000] loss: 0.0831111657122771
I0422 17:20:27.594745 34428 trainer.py:136] Epoch[981/1000] loss: 0.08267182235916455
I0422 17:20:32.860948 34428 trainer.py:136] Epoch[982/1000] loss: 0.08271944771210353
I0422 17:20:38.058488 34428 trainer.py:136] Epoch[983/1000] loss: 0.08167249336838722
I0422 17:20:46.343341 34428 trainer.py:136] Epoch[984/1000] loss: 0.08343388636906941
I0422 17:20:51.506994 34428 trainer.py:136] Epoch[985/1000] loss: 0.08312695845961571
I0422 17:20:58.294444 34428 trainer.py:136] Epoch[986/1000] loss: 0.0829704999923706
I0422 17:21:05.006861 34428 trainer.py:136] Epoch[987/1000] loss: 0.08288903410236041
I0422 17:21:10.234779 34428 trainer.py:136] Epoch[988/1000] loss: 0.08271970351537068
I0422 17:21:18.037125 34428 trainer.py:136] Epoch[989/1000] loss: 0.0825946033000946
I0422 17:21:23.212241 34428 trainer.py:136] Epoch[990/1000] loss: 0.08195015912254651
I0422 17:21:30.206079 34428 trainer.py:136] Epoch[991/1000] loss: 0.08274474988381068
I0422 17:21:36.329162 34428 trainer.py:136] Epoch[992/1000] loss: 0.0823897918065389
I0422 17:21:41.678147 34428 trainer.py:136] Epoch[993/1000] loss: 0.08248623833060265
I0422 17:21:49.753158 34428 trainer.py:136] Epoch[994/1000] loss: 0.08260253816843033
I0422 17:21:54.836755 34428 trainer.py:136] Epoch[995/1000] loss: 0.08343388140201569
I0422 17:21:59.851742 34428 trainer.py:136] Epoch[996/1000] loss: 0.08247740566730499
I0422 17:22:07.646096 34428 trainer.py:136] Epoch[997/1000] loss: 0.08302692696452141
I0422 17:22:12.275581 34428 trainer.py:136] Epoch[998/1000] loss: 0.08299836268027623
I0422 17:22:16.794196 34428 trainer.py:136] Epoch[999/1000] loss: 0.08226991320649783
I0422 17:22:18.191682 34428 trainer.py:142] Test: [{'precision': 0.01656927023945267, 'recall': 0.07927112118992286, 'hit_ratio': 0.22762257696693272, 'ndcg': 0.052775556129770286}]
