I0423 09:13:23.265527 20284 trainer.py:118] Test: [{'precision': 0.014978902953586492, 'recall': 0.07616296034017551, 'hit_ratio': 0.23628691983122363, 'ndcg': 0.04474711315946463}]
I0423 09:13:23.627317 20284 trainer.py:136] Epoch[0/200] loss: 0.6919137875239054
I0423 09:13:23.985724 20284 trainer.py:136] Epoch[1/200] loss: 0.6497336606184642
I0423 09:13:24.357481 20284 trainer.py:136] Epoch[2/200] loss: 0.6085444947083791
I0423 09:13:24.708307 20284 trainer.py:136] Epoch[3/200] loss: 0.5710307161013285
I0423 09:13:25.068678 20284 trainer.py:136] Epoch[4/200] loss: 0.526731742421786
I0423 09:13:25.437457 20284 trainer.py:136] Epoch[5/200] loss: 0.4808511565128962
I0423 09:13:25.777748 20284 trainer.py:136] Epoch[6/200] loss: 0.4648741791645686
I0423 09:13:26.108220 20284 trainer.py:136] Epoch[7/200] loss: 0.4175410767396291
I0423 09:13:26.436125 20284 trainer.py:136] Epoch[8/200] loss: 0.38340908487637837
I0423 09:13:26.782020 20284 trainer.py:136] Epoch[9/200] loss: 0.3698859016100566
I0423 09:13:27.121390 20284 trainer.py:136] Epoch[10/200] loss: 0.3690795530875524
I0423 09:13:27.488163 20284 trainer.py:136] Epoch[11/200] loss: 0.3563763986031214
I0423 09:13:27.861514 20284 trainer.py:136] Epoch[12/200] loss: 0.36508159736792245
I0423 09:13:28.324986 20284 trainer.py:136] Epoch[13/200] loss: 0.3334835723042488
I0423 09:13:28.965400 20284 trainer.py:136] Epoch[14/200] loss: 0.32244833012421925
I0423 09:13:29.607253 20284 trainer.py:136] Epoch[15/200] loss: 0.3282043054699898
I0423 09:13:30.242129 20284 trainer.py:136] Epoch[16/200] loss: 0.3104087129235268
I0423 09:13:30.886542 20284 trainer.py:136] Epoch[17/200] loss: 0.3093998670578003
I0423 09:13:31.521418 20284 trainer.py:136] Epoch[18/200] loss: 0.29062592685222627
I0423 09:13:32.174850 20284 trainer.py:136] Epoch[19/200] loss: 0.2885650252302488
I0423 09:13:32.805943 20284 trainer.py:136] Epoch[20/200] loss: 0.28169110318024954
I0423 09:13:33.636166 20284 trainer.py:136] Epoch[21/200] loss: 0.30187762826681136
I0423 09:13:34.257119 20284 trainer.py:136] Epoch[22/200] loss: 0.2889028569062551
I0423 09:13:34.885017 20284 trainer.py:136] Epoch[23/200] loss: 0.2840734049677849
I0423 09:13:35.552783 20284 trainer.py:136] Epoch[24/200] loss: 0.2858782112598419
I0423 09:13:36.247033 20284 trainer.py:136] Epoch[25/200] loss: 0.2674959595004717
I0423 09:13:36.882461 20284 trainer.py:136] Epoch[26/200] loss: 0.25661477595567705
I0423 09:13:37.537269 20284 trainer.py:136] Epoch[27/200] loss: 0.2703692510724068
I0423 09:13:38.253533 20284 trainer.py:136] Epoch[28/200] loss: 0.26882215638955437
I0423 09:13:39.265694 20284 trainer.py:136] Epoch[29/200] loss: 0.2508064125974973
I0423 09:13:40.270969 20284 trainer.py:136] Epoch[30/200] loss: 0.23784864842891693
I0423 09:13:41.285132 20284 trainer.py:136] Epoch[31/200] loss: 0.26434156199296316
I0423 09:13:42.304084 20284 trainer.py:136] Epoch[32/200] loss: 0.26347347150246303
I0423 09:13:43.346522 20284 trainer.py:136] Epoch[33/200] loss: 0.26002428978681563
I0423 09:13:44.397657 20284 trainer.py:136] Epoch[34/200] loss: 0.2518311575055122
I0423 09:13:45.432793 20284 trainer.py:136] Epoch[35/200] loss: 0.2417061761021614
I0423 09:13:46.445989 20284 trainer.py:136] Epoch[36/200] loss: 0.24124952803055447
I0423 09:13:47.503009 20284 trainer.py:136] Epoch[37/200] loss: 0.23254744410514833
I0423 09:13:48.514205 20284 trainer.py:136] Epoch[38/200] loss: 0.23344117005666096
I0423 09:13:49.503440 20284 trainer.py:136] Epoch[39/200] loss: 0.2378512000044187
I0423 09:13:50.496732 20284 trainer.py:136] Epoch[40/200] loss: 0.23796579738457999
I0423 09:13:51.502961 20284 trainer.py:136] Epoch[41/200] loss: 0.22342206686735153
I0423 09:13:52.570933 20284 trainer.py:136] Epoch[42/200] loss: 0.22331553151210148
I0423 09:13:53.573142 20284 trainer.py:136] Epoch[43/200] loss: 0.21465861896673838
I0423 09:13:54.582367 20284 trainer.py:136] Epoch[44/200] loss: 0.22528605957825978
I0423 09:13:55.594538 20284 trainer.py:136] Epoch[45/200] loss: 0.21840678304433822
I0423 09:13:56.613784 20284 trainer.py:136] Epoch[46/200] loss: 0.22047741760810216
I0423 09:13:57.645405 20284 trainer.py:136] Epoch[47/200] loss: 0.23765925715367
I0423 09:13:58.679554 20284 trainer.py:136] Epoch[48/200] loss: 0.21809157033761342
I0423 09:13:59.675353 20284 trainer.py:136] Epoch[49/200] loss: 0.2225791444381078
I0423 09:13:59.700230 20284 trainer.py:142] Test: [{'precision': 0.023206751054852304, 'recall': 0.16021150673049406, 'hit_ratio': 0.3755274261603376, 'ndcg': 0.07864789734819874}]
I0423 09:14:00.728391 20284 trainer.py:136] Epoch[50/200] loss: 0.2206335668762525
I0423 09:14:01.717430 20284 trainer.py:136] Epoch[51/200] loss: 0.21582169930140177
I0423 09:14:02.754192 20284 trainer.py:136] Epoch[52/200] loss: 0.21706073532501857
I0423 09:14:03.754659 20284 trainer.py:136] Epoch[53/200] loss: 0.21494419227043787
I0423 09:14:04.758849 20284 trainer.py:136] Epoch[54/200] loss: 0.19504550099372864
I0423 09:14:05.812537 20284 trainer.py:136] Epoch[55/200] loss: 0.20319398641586303
I0423 09:14:06.797820 20284 trainer.py:136] Epoch[56/200] loss: 0.19990959167480468
I0423 09:14:07.785577 20284 trainer.py:136] Epoch[57/200] loss: 0.21262273341417312
I0423 09:14:08.797453 20284 trainer.py:136] Epoch[58/200] loss: 0.2093295340736707
I0423 09:14:09.820598 20284 trainer.py:136] Epoch[59/200] loss: 0.19593944102525712
I0423 09:14:10.852756 20284 trainer.py:136] Epoch[60/200] loss: 0.2105320319533348
I0423 09:14:11.861928 20284 trainer.py:136] Epoch[61/200] loss: 0.21261958181858062
I0423 09:14:12.878080 20284 trainer.py:136] Epoch[62/200] loss: 0.2099349026878675
I0423 09:14:13.878194 20284 trainer.py:136] Epoch[63/200] loss: 0.19748107641935347
I0423 09:14:14.872525 20284 trainer.py:136] Epoch[64/200] loss: 0.2004838521281878
I0423 09:14:15.933691 20284 trainer.py:136] Epoch[65/200] loss: 0.1965545559922854
I0423 09:14:16.962518 20284 trainer.py:136] Epoch[66/200] loss: 0.19255585670471193
I0423 09:14:17.971654 20284 trainer.py:136] Epoch[67/200] loss: 0.1919048083325227
I0423 09:14:18.995451 20284 trainer.py:136] Epoch[68/200] loss: 0.1986109733581543
I0423 09:14:20.009710 20284 trainer.py:136] Epoch[69/200] loss: 0.19954198996225994
I0423 09:14:21.024905 20284 trainer.py:136] Epoch[70/200] loss: 0.19442338546117147
I0423 09:14:22.037116 20284 trainer.py:136] Epoch[71/200] loss: 0.19127270927031834
I0423 09:14:23.044298 20284 trainer.py:136] Epoch[72/200] loss: 0.18911074871818226
I0423 09:14:24.067709 20284 trainer.py:136] Epoch[73/200] loss: 0.18644924610853195
I0423 09:14:25.087795 20284 trainer.py:136] Epoch[74/200] loss: 0.18353703195850055
I0423 09:14:26.150344 20284 trainer.py:136] Epoch[75/200] loss: 0.18212133944034575
I0423 09:14:27.144706 20284 trainer.py:136] Epoch[76/200] loss: 0.18800666977961858
I0423 09:14:28.193746 20284 trainer.py:136] Epoch[77/200] loss: 0.17924875617027283
I0423 09:14:29.218922 20284 trainer.py:136] Epoch[78/200] loss: 0.1810801049073537
I0423 09:14:30.294864 20284 trainer.py:136] Epoch[79/200] loss: 0.17456547742088635
I0423 09:14:31.320132 20284 trainer.py:136] Epoch[80/200] loss: 0.17697449798385304
I0423 09:14:32.337670 20284 trainer.py:136] Epoch[81/200] loss: 0.1809148167570432
I0423 09:14:33.435499 20284 trainer.py:136] Epoch[82/200] loss: 0.1738998532295227
I0423 09:14:34.481572 20284 trainer.py:136] Epoch[83/200] loss: 0.1831634352604548
I0423 09:14:35.489859 20284 trainer.py:136] Epoch[84/200] loss: 0.17288273125886916
I0423 09:14:36.459176 20284 trainer.py:136] Epoch[85/200] loss: 0.17719035645325978
I0423 09:14:37.459373 20284 trainer.py:136] Epoch[86/200] loss: 0.16695755273103713
I0423 09:14:38.468558 20284 trainer.py:136] Epoch[87/200] loss: 0.1730569653213024
I0423 09:14:39.472770 20284 trainer.py:136] Epoch[88/200] loss: 0.1838335618376732
I0423 09:14:40.472024 20284 trainer.py:136] Epoch[89/200] loss: 0.17950463891029358
I0423 09:14:41.478170 20284 trainer.py:136] Epoch[90/200] loss: 0.17922762607534726
I0423 09:14:42.487358 20284 trainer.py:136] Epoch[91/200] loss: 0.17581442097822825
I0423 09:14:43.495653 20284 trainer.py:136] Epoch[92/200] loss: 0.16958395118514696
I0423 09:14:44.498833 20284 trainer.py:136] Epoch[93/200] loss: 0.1673223870495955
I0423 09:14:45.487156 20284 trainer.py:136] Epoch[94/200] loss: 0.17827345753709475
I0423 09:14:46.481395 20284 trainer.py:136] Epoch[95/200] loss: 0.1726327416797479
I0423 09:14:47.491513 20284 trainer.py:136] Epoch[96/200] loss: 0.178103177746137
I0423 09:14:48.472885 20284 trainer.py:136] Epoch[97/200] loss: 0.17743586003780365
I0423 09:14:49.470072 20284 trainer.py:136] Epoch[98/200] loss: 0.17553840080897012
I0423 09:14:50.495226 20284 trainer.py:136] Epoch[99/200] loss: 0.16478107819954554
I0423 09:14:50.516157 20284 trainer.py:142] Test: [{'precision': 0.025105485232067484, 'recall': 0.1651341508936445, 'hit_ratio': 0.39662447257383965, 'ndcg': 0.08045989189519229}]
I0423 09:14:51.530331 20284 trainer.py:136] Epoch[100/200] loss: 0.17774744282166163
I0423 09:14:52.536542 20284 trainer.py:136] Epoch[101/200] loss: 0.1856875906387965
I0423 09:14:53.552700 20284 trainer.py:136] Epoch[102/200] loss: 0.17274970983465512
I0423 09:14:54.559883 20284 trainer.py:136] Epoch[103/200] loss: 0.17081836387515067
I0423 09:14:55.559062 20284 trainer.py:136] Epoch[104/200] loss: 0.169808841496706
I0423 09:14:56.546301 20284 trainer.py:136] Epoch[105/200] loss: 0.17364048560460407
I0423 09:14:57.543179 20284 trainer.py:136] Epoch[106/200] loss: 0.17894420077403386
I0423 09:14:58.541291 20284 trainer.py:136] Epoch[107/200] loss: 0.16784180800120035
I0423 09:14:59.552476 20284 trainer.py:136] Epoch[108/200] loss: 0.1673724388082822
I0423 09:15:00.557673 20284 trainer.py:136] Epoch[109/200] loss: 0.17230024014910061
I0423 09:15:01.578830 20284 trainer.py:136] Epoch[110/200] loss: 0.17237182334065437
I0423 09:15:02.605975 20284 trainer.py:136] Epoch[111/200] loss: 0.16582578271627427
I0423 09:15:03.608274 20284 trainer.py:136] Epoch[112/200] loss: 0.18750149210294087
I0423 09:15:04.613530 20284 trainer.py:136] Epoch[113/200] loss: 0.17156339362263678
I0423 09:15:05.588790 20284 trainer.py:136] Epoch[114/200] loss: 0.1730402261018753
I0423 09:15:06.613946 20284 trainer.py:136] Epoch[115/200] loss: 0.16191640769441923
I0423 09:15:07.632079 20284 trainer.py:136] Epoch[116/200] loss: 0.1658880000313123
I0423 09:15:08.652229 20284 trainer.py:136] Epoch[117/200] loss: 0.15992433428764344
I0423 09:15:09.685392 20284 trainer.py:136] Epoch[118/200] loss: 0.1624221888681253
I0423 09:15:10.714509 20284 trainer.py:136] Epoch[119/200] loss: 0.15066519950826962
I0423 09:15:11.753662 20284 trainer.py:136] Epoch[120/200] loss: 0.18489682252208392
I0423 09:15:12.798249 20284 trainer.py:136] Epoch[121/200] loss: 0.17102298885583878
I0423 09:15:13.775978 20284 trainer.py:136] Epoch[122/200] loss: 0.1610061640540759
I0423 09:15:14.791782 20284 trainer.py:136] Epoch[123/200] loss: 0.17745572378238042
I0423 09:15:15.792984 20284 trainer.py:136] Epoch[124/200] loss: 0.1662527285516262
I0423 09:15:16.806168 20284 trainer.py:136] Epoch[125/200] loss: 0.16161521499355633
I0423 09:15:17.794431 20284 trainer.py:136] Epoch[126/200] loss: 0.17135288640856744
I0423 09:15:18.819727 20284 trainer.py:136] Epoch[127/200] loss: 0.16823583990335464
I0423 09:15:19.815901 20284 trainer.py:136] Epoch[128/200] loss: 0.17049415955940883
I0423 09:15:20.791173 20284 trainer.py:136] Epoch[129/200] loss: 0.175703539699316
I0423 09:15:21.806427 20284 trainer.py:136] Epoch[130/200] loss: 0.16678603241840997
I0423 09:15:22.806012 20284 trainer.py:136] Epoch[131/200] loss: 0.1733849915365378
I0423 09:15:23.812217 20284 trainer.py:136] Epoch[132/200] loss: 0.17391254603862763
I0423 09:15:24.810454 20284 trainer.py:136] Epoch[133/200] loss: 0.1632169835269451
I0423 09:15:25.820324 20284 trainer.py:136] Epoch[134/200] loss: 0.16346718693772952
I0423 09:15:26.803485 20284 trainer.py:136] Epoch[135/200] loss: 0.1646833265821139
I0423 09:15:27.809690 20284 trainer.py:136] Epoch[136/200] loss: 0.16781063377857208
I0423 09:15:28.809896 20284 trainer.py:136] Epoch[137/200] loss: 0.15612097978591918
I0423 09:15:29.814104 20284 trainer.py:136] Epoch[138/200] loss: 0.16227365508675576
I0423 09:15:30.815336 20284 trainer.py:136] Epoch[139/200] loss: 0.1574489193658034
I0423 09:15:31.829350 20284 trainer.py:136] Epoch[140/200] loss: 0.16416088392337164
I0423 09:15:32.845261 20284 trainer.py:136] Epoch[141/200] loss: 0.15518393317858378
I0423 09:15:33.874956 20284 trainer.py:136] Epoch[142/200] loss: 0.16023892313241958
I0423 09:15:34.904150 20284 trainer.py:136] Epoch[143/200] loss: 0.1568976451953252
I0423 09:15:35.924325 20284 trainer.py:136] Epoch[144/200] loss: 0.15732272565364838
I0423 09:15:36.937488 20284 trainer.py:136] Epoch[145/200] loss: 0.15580104117592175
I0423 09:15:37.952701 20284 trainer.py:136] Epoch[146/200] loss: 0.16794445713361103
I0423 09:15:38.944525 20284 trainer.py:136] Epoch[147/200] loss: 0.15964097529649734
I0423 09:15:39.931780 20284 trainer.py:136] Epoch[148/200] loss: 0.161272032558918
I0423 09:15:40.926044 20284 trainer.py:136] Epoch[149/200] loss: 0.15540460422635077
I0423 09:15:40.949965 20284 trainer.py:142] Test: [{'precision': 0.025105485232067484, 'recall': 0.16918277456252134, 'hit_ratio': 0.39662447257383965, 'ndcg': 0.08116948735528423}]
I0423 09:15:41.951184 20284 trainer.py:136] Epoch[150/200] loss: 0.1621063026289145
I0423 09:15:42.938444 20284 trainer.py:136] Epoch[151/200] loss: 0.15559632380803426
I0423 09:15:43.930726 20284 trainer.py:136] Epoch[152/200] loss: 0.1529881849884987
I0423 09:15:44.930915 20284 trainer.py:136] Epoch[153/200] loss: 0.16914498110612233
I0423 09:15:45.930121 20284 trainer.py:136] Epoch[154/200] loss: 0.16576498871048292
I0423 09:15:46.929328 20284 trainer.py:136] Epoch[155/200] loss: 0.15688827633857727
I0423 09:15:47.946432 20284 trainer.py:136] Epoch[156/200] loss: 0.16495421528816223
I0423 09:15:48.950223 20284 trainer.py:136] Epoch[157/200] loss: 0.15735462456941604
I0423 09:15:49.948434 20284 trainer.py:136] Epoch[158/200] loss: 0.17032881453633308
I0423 09:15:50.960600 20284 trainer.py:136] Epoch[159/200] loss: 0.15383393118778865
I0423 09:15:51.958828 20284 trainer.py:136] Epoch[160/200] loss: 0.16244243159890176
I0423 09:15:52.961090 20284 trainer.py:136] Epoch[161/200] loss: 0.1600697321196397
I0423 09:15:53.945359 20284 trainer.py:136] Epoch[162/200] loss: 0.16360462506612142
I0423 09:15:54.940657 20284 trainer.py:136] Epoch[163/200] loss: 0.16864476824800173
I0423 09:15:55.941876 20284 trainer.py:136] Epoch[164/200] loss: 0.15948481063048045
I0423 09:15:56.928145 20284 trainer.py:136] Epoch[165/200] loss: 0.1591167022784551
I0423 09:15:57.925353 20284 trainer.py:136] Epoch[166/200] loss: 0.15855619584520658
I0423 09:15:58.933541 20284 trainer.py:136] Epoch[167/200] loss: 0.15703571538130442
I0423 09:15:59.925784 20284 trainer.py:136] Epoch[168/200] loss: 0.15481009135643642
I0423 09:16:00.932057 20284 trainer.py:136] Epoch[169/200] loss: 0.15407912532488505
I0423 09:16:01.934247 20284 trainer.py:136] Epoch[170/200] loss: 0.1598067656159401
I0423 09:16:02.961436 20284 trainer.py:136] Epoch[171/200] loss: 0.16642242819070815
I0423 09:16:03.964618 20284 trainer.py:136] Epoch[172/200] loss: 0.1525360107421875
I0423 09:16:04.953871 20284 trainer.py:136] Epoch[173/200] loss: 0.17140497788786888
I0423 09:16:05.949108 20284 trainer.py:136] Epoch[174/200] loss: 0.1448853721221288
I0423 09:16:06.938454 20284 trainer.py:136] Epoch[175/200] loss: 0.15959394921859105
I0423 09:16:07.932181 20284 trainer.py:136] Epoch[176/200] loss: 0.1654454621175925
I0423 09:16:08.922443 20284 trainer.py:136] Epoch[177/200] loss: 0.15608442574739456
I0423 09:16:09.921702 20284 trainer.py:136] Epoch[178/200] loss: 0.15303805644313495
I0423 09:16:10.918945 20284 trainer.py:136] Epoch[179/200] loss: 0.16134676386912664
I0423 09:16:11.918304 20284 trainer.py:136] Epoch[180/200] loss: 0.15794067904353143
I0423 09:16:12.919481 20284 trainer.py:136] Epoch[181/200] loss: 0.17170774067441621
I0423 09:16:13.917623 20284 trainer.py:136] Epoch[182/200] loss: 0.15064698408047358
I0423 09:16:14.901987 20284 trainer.py:136] Epoch[183/200] loss: 0.1531753274301688
I0423 09:16:15.899258 20284 trainer.py:136] Epoch[184/200] loss: 0.15370116929213207
I0423 09:16:16.888544 20284 trainer.py:136] Epoch[185/200] loss: 0.15683446725209554
I0423 09:16:17.863787 20284 trainer.py:136] Epoch[186/200] loss: 0.16620050569375355
I0423 09:16:18.838078 20284 trainer.py:136] Epoch[187/200] loss: 0.15898149187366167
I0423 09:16:19.838345 20284 trainer.py:136] Epoch[188/200] loss: 0.15852424974242846
I0423 09:16:20.831662 20284 trainer.py:136] Epoch[189/200] loss: 0.1560392566025257
I0423 09:16:21.813941 20284 trainer.py:136] Epoch[190/200] loss: 0.14795352493723232
I0423 09:16:22.782700 20284 trainer.py:136] Epoch[191/200] loss: 0.16677900527914366
I0423 09:16:23.771399 20284 trainer.py:136] Epoch[192/200] loss: 0.15873751565814018
I0423 09:16:24.760659 20284 trainer.py:136] Epoch[193/200] loss: 0.14937343051036198
I0423 09:16:25.783038 20284 trainer.py:136] Epoch[194/200] loss: 0.16532097707192103
I0423 09:16:26.816998 20284 trainer.py:136] Epoch[195/200] loss: 0.15434161871671676
I0423 09:16:27.829161 20284 trainer.py:136] Epoch[196/200] loss: 0.15235140671332678
I0423 09:16:28.841325 20284 trainer.py:136] Epoch[197/200] loss: 0.15543050095438957
I0423 09:16:29.846503 20284 trainer.py:136] Epoch[198/200] loss: 0.15595996230840684
I0423 09:16:30.850688 20284 trainer.py:136] Epoch[199/200] loss: 0.15297893782456715
I0423 09:16:30.871618 20284 trainer.py:142] Test: [{'precision': 0.0253164556962025, 'recall': 0.17122215571582658, 'hit_ratio': 0.4050632911392405, 'ndcg': 0.0807090527543363}]
