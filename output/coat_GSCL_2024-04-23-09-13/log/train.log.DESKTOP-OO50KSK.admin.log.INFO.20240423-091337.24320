I0423 09:13:38.326289 11924 trainer.py:118] Test: [{'precision': 0.015189873417721517, 'recall': 0.08522733712607126, 'hit_ratio': 0.24472573839662448, 'ndcg': 0.04573781996218}]
I0423 09:13:39.347420 11924 trainer.py:136] Epoch[0/200] loss: 0.6867455462614696
I0423 09:13:40.370595 11924 trainer.py:136] Epoch[1/200] loss: 0.6453720986843109
I0423 09:13:41.400708 11924 trainer.py:136] Epoch[2/200] loss: 0.6039611518383026
I0423 09:13:42.404746 11924 trainer.py:136] Epoch[3/200] loss: 0.5618218511343003
I0423 09:13:43.481071 11924 trainer.py:136] Epoch[4/200] loss: 0.5233598341544469
I0423 09:13:44.537190 11924 trainer.py:136] Epoch[5/200] loss: 0.4871028006076813
I0423 09:13:45.578305 11924 trainer.py:136] Epoch[6/200] loss: 0.44997199475765226
I0423 09:13:46.631369 11924 trainer.py:136] Epoch[7/200] loss: 0.4183117667833964
I0423 09:13:47.684402 11924 trainer.py:136] Epoch[8/200] loss: 0.39266701340675353
I0423 09:13:48.691611 11924 trainer.py:136] Epoch[9/200] loss: 0.3831667512655258
I0423 09:13:49.708752 11924 trainer.py:136] Epoch[10/200] loss: 0.3579726313551267
I0423 09:13:50.706032 11924 trainer.py:136] Epoch[11/200] loss: 0.3509299874305725
I0423 09:13:51.722227 11924 trainer.py:136] Epoch[12/200] loss: 0.359578275680542
I0423 09:13:52.707478 11924 trainer.py:136] Epoch[13/200] loss: 0.33381713430086773
I0423 09:13:53.707691 11924 trainer.py:136] Epoch[14/200] loss: 0.31242282142241795
I0423 09:13:54.682034 11924 trainer.py:136] Epoch[15/200] loss: 0.303019143640995
I0423 09:13:55.680251 11924 trainer.py:136] Epoch[16/200] loss: 0.3063034027814865
I0423 09:13:56.663579 11924 trainer.py:136] Epoch[17/200] loss: 0.3117907995978991
I0423 09:13:57.673311 11924 trainer.py:136] Epoch[18/200] loss: 0.3043313796321551
I0423 09:13:58.710451 11924 trainer.py:136] Epoch[19/200] loss: 0.30276983926693596
I0423 09:13:59.709201 11924 trainer.py:136] Epoch[20/200] loss: 0.31236704339583715
I0423 09:14:00.739354 11924 trainer.py:136] Epoch[21/200] loss: 0.283814445634683
I0423 09:14:01.761283 11924 trainer.py:136] Epoch[22/200] loss: 0.2986047178506851
I0423 09:14:02.781913 11924 trainer.py:136] Epoch[23/200] loss: 0.2630675752957662
I0423 09:14:03.779126 11924 trainer.py:136] Epoch[24/200] loss: 0.28574694991111754
I0423 09:14:04.770809 11924 trainer.py:136] Epoch[25/200] loss: 0.3004026715954145
I0423 09:14:05.826491 11924 trainer.py:136] Epoch[26/200] loss: 0.27745482623577117
I0423 09:14:06.840677 11924 trainer.py:136] Epoch[27/200] loss: 0.2771925623218218
I0423 09:14:07.856966 11924 trainer.py:136] Epoch[28/200] loss: 0.2701205492019653
I0423 09:14:08.903140 11924 trainer.py:136] Epoch[29/200] loss: 0.26605795274178184
I0423 09:14:09.925289 11924 trainer.py:136] Epoch[30/200] loss: 0.25567388186852136
I0423 09:14:10.951426 11924 trainer.py:136] Epoch[31/200] loss: 0.2566424056887627
I0423 09:14:11.986510 11924 trainer.py:136] Epoch[32/200] loss: 0.2564198672771454
I0423 09:14:13.003659 11924 trainer.py:136] Epoch[33/200] loss: 0.24472521642843884
I0423 09:14:14.015734 11924 trainer.py:136] Epoch[34/200] loss: 0.2571785181760788
I0423 09:14:15.045489 11924 trainer.py:136] Epoch[35/200] loss: 0.2493722379207611
I0423 09:14:16.053292 11924 trainer.py:136] Epoch[36/200] loss: 0.240263365705808
I0423 09:14:17.074104 11924 trainer.py:136] Epoch[37/200] loss: 0.2536231284340223
I0423 09:14:18.110231 11924 trainer.py:136] Epoch[38/200] loss: 0.23507000207901002
I0423 09:14:19.100139 11924 trainer.py:136] Epoch[39/200] loss: 0.24365352590878805
I0423 09:14:20.101403 11924 trainer.py:136] Epoch[40/200] loss: 0.23316574841737747
I0423 09:14:21.075784 11924 trainer.py:136] Epoch[41/200] loss: 0.23944016645352045
I0423 09:14:22.068012 11924 trainer.py:136] Epoch[42/200] loss: 0.23565500924984614
I0423 09:14:23.083207 11924 trainer.py:136] Epoch[43/200] loss: 0.22570010075966518
I0423 09:14:24.136433 11924 trainer.py:136] Epoch[44/200] loss: 0.2269859085480372
I0423 09:14:25.157602 11924 trainer.py:136] Epoch[45/200] loss: 0.22045084536075593
I0423 09:14:26.223101 11924 trainer.py:136] Epoch[46/200] loss: 0.23056033203999202
I0423 09:14:27.242340 11924 trainer.py:136] Epoch[47/200] loss: 0.22439324259757995
I0423 09:14:28.264509 11924 trainer.py:136] Epoch[48/200] loss: 0.2200288360317548
I0423 09:14:29.292675 11924 trainer.py:136] Epoch[49/200] loss: 0.21472461620966593
I0423 09:14:29.314601 11924 trainer.py:142] Test: [{'precision': 0.023206751054852304, 'recall': 0.16067170054511823, 'hit_ratio': 0.3670886075949367, 'ndcg': 0.07614316316168733}]
I0423 09:14:30.354665 11924 trainer.py:136] Epoch[50/200] loss: 0.22280549158652624
I0423 09:14:31.369965 11924 trainer.py:136] Epoch[51/200] loss: 0.21475203037261964
I0423 09:14:32.385510 11924 trainer.py:136] Epoch[52/200] loss: 0.2272820547223091
I0423 09:14:33.445465 11924 trainer.py:136] Epoch[53/200] loss: 0.22034119764963786
I0423 09:14:34.498514 11924 trainer.py:136] Epoch[54/200] loss: 0.21324287354946136
I0423 09:14:35.519756 11924 trainer.py:136] Epoch[55/200] loss: 0.20725192328294118
I0423 09:14:36.513991 11924 trainer.py:136] Epoch[56/200] loss: 0.20532187074422836
I0423 09:14:37.508210 11924 trainer.py:136] Epoch[57/200] loss: 0.20715263833602268
I0423 09:14:38.498495 11924 trainer.py:136] Epoch[58/200] loss: 0.2111548418800036
I0423 09:14:39.508692 11924 trainer.py:136] Epoch[59/200] loss: 0.2086875264843305
I0423 09:14:40.506869 11924 trainer.py:136] Epoch[60/200] loss: 0.19309637447198233
I0423 09:14:41.514051 11924 trainer.py:136] Epoch[61/200] loss: 0.19602468907833098
I0423 09:14:42.512275 11924 trainer.py:136] Epoch[62/200] loss: 0.19918251385291416
I0423 09:14:43.495653 11924 trainer.py:136] Epoch[63/200] loss: 0.20229699114958447
I0423 09:14:44.509796 11924 trainer.py:136] Epoch[64/200] loss: 0.2031773805618286
I0423 09:14:45.526027 11924 trainer.py:136] Epoch[65/200] loss: 0.2096888502438863
I0423 09:14:46.529193 11924 trainer.py:136] Epoch[66/200] loss: 0.19905862112840017
I0423 09:14:47.529386 11924 trainer.py:136] Epoch[67/200] loss: 0.18786531190077463
I0423 09:14:48.550580 11924 trainer.py:136] Epoch[68/200] loss: 0.19901030411322912
I0423 09:14:49.538843 11924 trainer.py:136] Epoch[69/200] loss: 0.19803556551535925
I0423 09:14:50.518150 11924 trainer.py:136] Epoch[70/200] loss: 0.19510350426038106
I0423 09:14:51.515432 11924 trainer.py:136] Epoch[71/200] loss: 0.19702113568782806
I0423 09:14:52.502615 11924 trainer.py:136] Epoch[72/200] loss: 0.19102231909831366
I0423 09:14:53.488869 11924 trainer.py:136] Epoch[73/200] loss: 0.17702225595712662
I0423 09:14:54.500085 11924 trainer.py:136] Epoch[74/200] loss: 0.19402824143568675
I0423 09:14:55.501255 11924 trainer.py:136] Epoch[75/200] loss: 0.19866497615973155
I0423 09:14:56.498460 11924 trainer.py:136] Epoch[76/200] loss: 0.18246569832166035
I0423 09:14:57.507652 11924 trainer.py:136] Epoch[77/200] loss: 0.18687034224470456
I0423 09:14:58.492455 11924 trainer.py:136] Epoch[78/200] loss: 0.18657142966985701
I0423 09:14:59.490683 11924 trainer.py:136] Epoch[79/200] loss: 0.18509672880172728
I0423 09:15:00.512823 11924 trainer.py:136] Epoch[80/200] loss: 0.1762972633043925
I0423 09:15:01.512053 11924 trainer.py:136] Epoch[81/200] loss: 0.17913287704189618
I0423 09:15:02.536209 11924 trainer.py:136] Epoch[82/200] loss: 0.17509057919184368
I0423 09:15:03.564420 11924 trainer.py:136] Epoch[83/200] loss: 0.2004135400056839
I0423 09:15:04.584582 11924 trainer.py:136] Epoch[84/200] loss: 0.1940586139758428
I0423 09:15:05.586797 11924 trainer.py:136] Epoch[85/200] loss: 0.18720797151327134
I0423 09:15:06.603980 11924 trainer.py:136] Epoch[86/200] loss: 0.18607313334941863
I0423 09:15:07.634072 11924 trainer.py:136] Epoch[87/200] loss: 0.18976594855388004
I0423 09:15:08.649239 11924 trainer.py:136] Epoch[88/200] loss: 0.1908541962504387
I0423 09:15:09.651506 11924 trainer.py:136] Epoch[89/200] loss: 0.18649583210547765
I0423 09:15:10.671652 11924 trainer.py:136] Epoch[90/200] loss: 0.17798910439014434
I0423 09:15:11.655950 11924 trainer.py:136] Epoch[91/200] loss: 0.16926277925570807
I0423 09:15:12.636236 11924 trainer.py:136] Epoch[92/200] loss: 0.18652286877234778
I0423 09:15:13.634451 11924 trainer.py:136] Epoch[93/200] loss: 0.18789126574993134
I0423 09:15:14.618801 11924 trainer.py:136] Epoch[94/200] loss: 0.17141881535450618
I0423 09:15:15.630026 11924 trainer.py:136] Epoch[95/200] loss: 0.18267992834250132
I0423 09:15:16.656096 11924 trainer.py:136] Epoch[96/200] loss: 0.16707010790705681
I0423 09:15:17.649347 11924 trainer.py:136] Epoch[97/200] loss: 0.16732676128546398
I0423 09:15:18.639603 11924 trainer.py:136] Epoch[98/200] loss: 0.17162099157770475
I0423 09:15:19.637938 11924 trainer.py:136] Epoch[99/200] loss: 0.1763153093556563
I0423 09:15:19.660861 11924 trainer.py:142] Test: [{'precision': 0.024261603375527404, 'recall': 0.16126635905116912, 'hit_ratio': 0.3881856540084388, 'ndcg': 0.07802000460059512}]
I0423 09:15:20.654106 11924 trainer.py:136] Epoch[100/200] loss: 0.17086874842643737
I0423 09:15:21.650299 11924 trainer.py:136] Epoch[101/200] loss: 0.1846278950572014
I0423 09:15:22.660080 11924 trainer.py:136] Epoch[102/200] loss: 0.17097734088699024
I0423 09:15:23.672105 11924 trainer.py:136] Epoch[103/200] loss: 0.16520409335692723
I0423 09:15:24.698253 11924 trainer.py:136] Epoch[104/200] loss: 0.1667838046948115
I0423 09:15:25.693133 11924 trainer.py:136] Epoch[105/200] loss: 0.18424552008509637
I0423 09:15:26.705253 11924 trainer.py:136] Epoch[106/200] loss: 0.16648255760471026
I0423 09:15:27.720417 11924 trainer.py:136] Epoch[107/200] loss: 0.17248851185043654
I0423 09:15:28.728659 11924 trainer.py:136] Epoch[108/200] loss: 0.16327288995186487
I0423 09:15:29.716865 11924 trainer.py:136] Epoch[109/200] loss: 0.16473367189367613
I0423 09:15:30.718080 11924 trainer.py:136] Epoch[110/200] loss: 0.17089512969056767
I0423 09:15:31.717135 11924 trainer.py:136] Epoch[111/200] loss: 0.16470276415348054
I0423 09:15:32.726095 11924 trainer.py:136] Epoch[112/200] loss: 0.17359090422590573
I0423 09:15:33.708256 11924 trainer.py:136] Epoch[113/200] loss: 0.1769669272005558
I0423 09:15:34.691225 11924 trainer.py:136] Epoch[114/200] loss: 0.1608877787987391
I0423 09:15:35.709455 11924 trainer.py:136] Epoch[115/200] loss: 0.16707048068443933
I0423 09:15:36.718667 11924 trainer.py:136] Epoch[116/200] loss: 0.1664473650356134
I0423 09:15:37.703925 11924 trainer.py:136] Epoch[117/200] loss: 0.167930373052756
I0423 09:15:38.702751 11924 trainer.py:136] Epoch[118/200] loss: 0.16991496408979098
I0423 09:15:39.690032 11924 trainer.py:136] Epoch[119/200] loss: 0.17312452122569083
I0423 09:15:40.681273 11924 trainer.py:136] Epoch[120/200] loss: 0.16337855656941733
I0423 09:15:41.670554 11924 trainer.py:136] Epoch[121/200] loss: 0.15907130738099415
I0423 09:15:42.664796 11924 trainer.py:136] Epoch[122/200] loss: 0.16024692629774412
I0423 09:15:43.683950 11924 trainer.py:136] Epoch[123/200] loss: 0.16660668725768726
I0423 09:15:44.688172 11924 trainer.py:136] Epoch[124/200] loss: 0.16427127967278163
I0423 09:15:45.677418 11924 trainer.py:136] Epoch[125/200] loss: 0.17183163315057753
I0423 09:15:46.690576 11924 trainer.py:136] Epoch[126/200] loss: 0.17545835698644321
I0423 09:15:47.717647 11924 trainer.py:136] Epoch[127/200] loss: 0.16269039809703828
I0423 09:15:48.740290 11924 trainer.py:136] Epoch[128/200] loss: 0.15763390536109606
I0423 09:15:49.763504 11924 trainer.py:136] Epoch[129/200] loss: 0.16878056873877842
I0423 09:15:50.772677 11924 trainer.py:136] Epoch[130/200] loss: 0.16161259214083354
I0423 09:15:51.824278 11924 trainer.py:136] Epoch[131/200] loss: 0.1618041957418124
I0423 09:15:52.830527 11924 trainer.py:136] Epoch[132/200] loss: 0.1573725511630376
I0423 09:15:53.826757 11924 trainer.py:136] Epoch[133/200] loss: 0.16345984091361362
I0423 09:15:54.810094 11924 trainer.py:136] Epoch[134/200] loss: 0.15759343082706134
I0423 09:15:55.806330 11924 trainer.py:136] Epoch[135/200] loss: 0.16379994327823322
I0423 09:15:56.796586 11924 trainer.py:136] Epoch[136/200] loss: 0.16460914462804793
I0423 09:15:57.791800 11924 trainer.py:136] Epoch[137/200] loss: 0.16805945038795472
I0423 09:15:58.776505 11924 trainer.py:136] Epoch[138/200] loss: 0.16648705651362736
I0423 09:15:59.772733 11924 trainer.py:136] Epoch[139/200] loss: 0.16425349190831184
I0423 09:16:00.778523 11924 trainer.py:136] Epoch[140/200] loss: 0.17026426220933596
I0423 09:16:01.784747 11924 trainer.py:136] Epoch[141/200] loss: 0.1636321648955345
I0423 09:16:02.787019 11924 trainer.py:136] Epoch[142/200] loss: 0.1539751241604487
I0423 09:16:03.782229 11924 trainer.py:136] Epoch[143/200] loss: 0.15541954363385838
I0423 09:16:04.787425 11924 trainer.py:136] Epoch[144/200] loss: 0.17297381858030955
I0423 09:16:05.799608 11924 trainer.py:136] Epoch[145/200] loss: 0.1616933430234591
I0423 09:16:06.803866 11924 trainer.py:136] Epoch[146/200] loss: 0.15642411063114803
I0423 09:16:07.784675 11924 trainer.py:136] Epoch[147/200] loss: 0.15660378535588582
I0423 09:16:08.783863 11924 trainer.py:136] Epoch[148/200] loss: 0.1524819975097974
I0423 09:16:09.749632 11924 trainer.py:136] Epoch[149/200] loss: 0.1640674129128456
I0423 09:16:09.768570 11924 trainer.py:142] Test: [{'precision': 0.0232067510548523, 'recall': 0.15500756861516352, 'hit_ratio': 0.3755274261603376, 'ndcg': 0.07817417384516248}]
I0423 09:16:10.774848 11924 trainer.py:136] Epoch[150/200] loss: 0.15866762548685073
I0423 09:16:11.754151 11924 trainer.py:136] Epoch[151/200] loss: 0.15738723427057266
I0423 09:16:12.765383 11924 trainer.py:136] Epoch[152/200] loss: 0.1613343263665835
I0423 09:16:13.757564 11924 trainer.py:136] Epoch[153/200] loss: 0.16523950472474097
I0423 09:16:14.790361 11924 trainer.py:136] Epoch[154/200] loss: 0.1598941393196583
I0423 09:16:15.769121 11924 trainer.py:136] Epoch[155/200] loss: 0.1600984014570713
I0423 09:16:16.754357 11924 trainer.py:136] Epoch[156/200] loss: 0.1660260759294033
I0423 09:16:17.767564 11924 trainer.py:136] Epoch[157/200] loss: 0.1580506627758344
I0423 09:16:18.772747 11924 trainer.py:136] Epoch[158/200] loss: 0.15176820109287897
I0423 09:16:19.762984 11924 trainer.py:136] Epoch[159/200] loss: 0.1572528081635634
I0423 09:16:20.768276 11924 trainer.py:136] Epoch[160/200] loss: 0.15293567702174188
I0423 09:16:21.793051 11924 trainer.py:136] Epoch[161/200] loss: 0.16002192869782447
I0423 09:16:22.810182 11924 trainer.py:136] Epoch[162/200] loss: 0.1553350269794464
I0423 09:16:23.830770 11924 trainer.py:136] Epoch[163/200] loss: 0.16680331205328305
I0423 09:16:24.846975 11924 trainer.py:136] Epoch[164/200] loss: 0.1588930830359459
I0423 09:16:25.818442 11924 trainer.py:136] Epoch[165/200] loss: 0.1611242619653543
I0423 09:16:26.809062 11924 trainer.py:136] Epoch[166/200] loss: 0.15714910353223482
I0423 09:16:27.797267 11924 trainer.py:136] Epoch[167/200] loss: 0.1691258872548739
I0423 09:16:28.771010 11924 trainer.py:136] Epoch[168/200] loss: 0.1718877834578355
I0423 09:16:29.769222 11924 trainer.py:136] Epoch[169/200] loss: 0.16197475666801134
I0423 09:16:30.741508 11924 trainer.py:136] Epoch[170/200] loss: 0.1593123495578766
I0423 09:16:31.404869 11924 trainer.py:136] Epoch[171/200] loss: 0.16109046712517738
I0423 09:16:32.056749 11924 trainer.py:136] Epoch[172/200] loss: 0.15144587581356367
I0423 09:16:32.702587 11924 trainer.py:136] Epoch[173/200] loss: 0.1525087185204029
I0423 09:16:33.317094 11924 trainer.py:136] Epoch[174/200] loss: 0.153202310949564
I0423 09:16:33.923653 11924 trainer.py:136] Epoch[175/200] loss: 0.15435300494233767
I0423 09:16:34.608362 11924 trainer.py:136] Epoch[176/200] loss: 0.16132142667969068
I0423 09:16:35.234821 11924 trainer.py:136] Epoch[177/200] loss: 0.1548716257015864
I0423 09:16:35.850330 11924 trainer.py:136] Epoch[178/200] loss: 0.16024045373002688
I0423 09:16:36.471251 11924 trainer.py:136] Epoch[179/200] loss: 0.15727525154749553
I0423 09:16:37.094717 11924 trainer.py:136] Epoch[180/200] loss: 0.15360456729928654
I0423 09:16:37.698696 11924 trainer.py:136] Epoch[181/200] loss: 0.15950901284813881
I0423 09:16:38.307591 11924 trainer.py:136] Epoch[182/200] loss: 0.16009738072752952
I0423 09:16:38.934470 11924 trainer.py:136] Epoch[183/200] loss: 0.15831130842367808
I0423 09:16:39.537454 11924 trainer.py:136] Epoch[184/200] loss: 0.15203863630692163
I0423 09:16:40.037394 11924 trainer.py:136] Epoch[185/200] loss: 0.16661319757501283
I0423 09:16:40.389215 11924 trainer.py:136] Epoch[186/200] loss: 0.15253555551171302
I0423 09:16:40.721104 11924 trainer.py:136] Epoch[187/200] loss: 0.1545187788705031
I0423 09:16:41.079529 11924 trainer.py:136] Epoch[188/200] loss: 0.16120445355772972
I0423 09:16:41.426369 11924 trainer.py:136] Epoch[189/200] loss: 0.1606016308069229
I0423 09:16:41.771215 11924 trainer.py:136] Epoch[190/200] loss: 0.16403740619619686
I0423 09:16:42.112639 11924 trainer.py:136] Epoch[191/200] loss: 0.15138493825991947
I0423 09:16:42.482401 11924 trainer.py:136] Epoch[192/200] loss: 0.14838382502396902
I0423 09:16:42.828821 11924 trainer.py:136] Epoch[193/200] loss: 0.1501443527638912
I0423 09:16:43.159714 11924 trainer.py:136] Epoch[194/200] loss: 0.1641698437432448
I0423 09:16:43.497583 11924 trainer.py:136] Epoch[195/200] loss: 0.15317939321200053
I0423 09:16:43.840029 11924 trainer.py:136] Epoch[196/200] loss: 0.16494913895924887
I0423 09:16:44.182882 11924 trainer.py:136] Epoch[197/200] loss: 0.1585572135945161
I0423 09:16:44.523742 11924 trainer.py:136] Epoch[198/200] loss: 0.1559950570265452
I0423 09:16:44.855185 11924 trainer.py:136] Epoch[199/200] loss: 0.15094424337148665
I0423 09:16:44.866149 11924 trainer.py:142] Test: [{'precision': 0.023628691983122337, 'recall': 0.15985679814793738, 'hit_ratio': 0.3755274261603376, 'ndcg': 0.07819226585598173}]
