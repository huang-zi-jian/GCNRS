I0424 13:52:57.265151 35684 trainer.py:118] Test: [{'precision': 0.008566134549600913, 'recall': 0.0334433323872287, 'hit_ratio': 0.11345496009122007, 'ndcg': 0.02390817540121315}]
I0424 13:53:03.446619 35684 trainer.py:136] Epoch[0/1000] loss: 0.7200551154249806
I0424 13:53:09.512305 35684 trainer.py:136] Epoch[1/1000] loss: 0.695929952597214
I0424 13:53:15.799650 35684 trainer.py:136] Epoch[2/1000] loss: 0.669785775370517
I0424 13:53:22.050910 35684 trainer.py:136] Epoch[3/1000] loss: 0.6383805578037843
I0424 13:53:28.356163 35684 trainer.py:136] Epoch[4/1000] loss: 0.5991054813740617
I0424 13:53:34.573993 35684 trainer.py:136] Epoch[5/1000] loss: 0.5582328984292887
I0424 13:53:40.755855 35684 trainer.py:136] Epoch[6/1000] loss: 0.5170377922260155
I0424 13:53:46.998424 35684 trainer.py:136] Epoch[7/1000] loss: 0.4772308322332673
I0424 13:53:53.248535 35684 trainer.py:136] Epoch[8/1000] loss: 0.44057731608213
I0424 13:53:59.631888 35684 trainer.py:136] Epoch[9/1000] loss: 0.412177123760773
I0424 13:54:05.771970 35684 trainer.py:136] Epoch[10/1000] loss: 0.3834120055376473
I0424 13:54:12.046448 35684 trainer.py:136] Epoch[11/1000] loss: 0.36230871131864645
I0424 13:54:18.185329 35684 trainer.py:136] Epoch[12/1000] loss: 0.34300577539508625
I0424 13:54:24.298017 35684 trainer.py:136] Epoch[13/1000] loss: 0.32552535554109996
I0424 13:54:30.491943 35684 trainer.py:136] Epoch[14/1000] loss: 0.3095094036247771
I0424 13:54:36.564925 35684 trainer.py:136] Epoch[15/1000] loss: 0.2948546242915978
I0424 13:54:42.720037 35684 trainer.py:136] Epoch[16/1000] loss: 0.28366307131314683
I0424 13:54:48.953132 35684 trainer.py:136] Epoch[17/1000] loss: 0.2724205508070477
I0424 13:54:55.156025 35684 trainer.py:136] Epoch[18/1000] loss: 0.26461227793814773
I0424 13:55:01.180420 35684 trainer.py:136] Epoch[19/1000] loss: 0.25396581069897795
I0424 13:55:07.562675 35684 trainer.py:136] Epoch[20/1000] loss: 0.2480167754120746
I0424 13:55:13.890612 35684 trainer.py:136] Epoch[21/1000] loss: 0.2412019086591268
I0424 13:55:20.130664 35684 trainer.py:136] Epoch[22/1000] loss: 0.2352747460037975
I0424 13:55:26.271666 35684 trainer.py:136] Epoch[23/1000] loss: 0.2288072935100329
I0424 13:55:32.475327 35684 trainer.py:136] Epoch[24/1000] loss: 0.22203161201234592
I0424 13:55:38.813045 35684 trainer.py:136] Epoch[25/1000] loss: 0.2190135252677788
I0424 13:55:45.132428 35684 trainer.py:136] Epoch[26/1000] loss: 0.21419292208501847
I0424 13:55:51.398338 35684 trainer.py:136] Epoch[27/1000] loss: 0.21023724190259385
I0424 13:55:57.557529 35684 trainer.py:136] Epoch[28/1000] loss: 0.20546523241673487
I0424 13:56:03.689913 35684 trainer.py:136] Epoch[29/1000] loss: 0.20145433560266332
I0424 13:56:09.827526 35684 trainer.py:136] Epoch[30/1000] loss: 0.1970946622096886
I0424 13:56:15.953186 35684 trainer.py:136] Epoch[31/1000] loss: 0.1945510968818503
I0424 13:56:22.016070 35684 trainer.py:136] Epoch[32/1000] loss: 0.19184311264652318
I0424 13:56:28.147382 35684 trainer.py:136] Epoch[33/1000] loss: 0.18934981322894662
I0424 13:56:34.205651 35684 trainer.py:136] Epoch[34/1000] loss: 0.18695279981120158
I0424 13:56:40.432587 35684 trainer.py:136] Epoch[35/1000] loss: 0.18448271261433424
I0424 13:56:46.784380 35684 trainer.py:136] Epoch[36/1000] loss: 0.1816633174480018
I0424 13:56:52.938491 35684 trainer.py:136] Epoch[37/1000] loss: 0.18007412325527708
I0424 13:56:59.093769 35684 trainer.py:136] Epoch[38/1000] loss: 0.1770533058097807
I0424 13:57:05.211794 35684 trainer.py:136] Epoch[39/1000] loss: 0.177256479354228
I0424 13:57:11.382318 35684 trainer.py:136] Epoch[40/1000] loss: 0.1760766415272729
I0424 13:57:17.549196 35684 trainer.py:136] Epoch[41/1000] loss: 0.1725590895798247
I0424 13:57:23.549360 35684 trainer.py:136] Epoch[42/1000] loss: 0.1704732447357501
I0424 13:57:29.710031 35684 trainer.py:136] Epoch[43/1000] loss: 0.16954982028169147
I0424 13:57:35.775053 35684 trainer.py:136] Epoch[44/1000] loss: 0.1691947551602024
I0424 13:57:41.965175 35684 trainer.py:136] Epoch[45/1000] loss: 0.16568651694362446
I0424 13:57:48.171845 35684 trainer.py:136] Epoch[46/1000] loss: 0.16367562822366166
I0424 13:57:54.502765 35684 trainer.py:136] Epoch[47/1000] loss: 0.1632090599860175
I0424 13:58:00.750806 35684 trainer.py:136] Epoch[48/1000] loss: 0.16257580660157284
I0424 13:58:06.771170 35684 trainer.py:136] Epoch[49/1000] loss: 0.16233339173308872
I0424 13:58:08.117012 35684 trainer.py:142] Test: [{'precision': 0.015386259977194974, 'recall': 0.0739890867887179, 'hit_ratio': 0.2112314709236032, 'ndcg': 0.04875271318859916}]
I0424 13:58:14.173131 35684 trainer.py:136] Epoch[50/1000] loss: 0.16061834258548283
I0424 13:58:20.287214 35684 trainer.py:136] Epoch[51/1000] loss: 0.15835188506013256
I0424 13:58:26.491535 35684 trainer.py:136] Epoch[52/1000] loss: 0.15834447968814333
I0424 13:58:32.699132 35684 trainer.py:136] Epoch[53/1000] loss: 0.15748362344200328
I0424 13:58:38.965189 35684 trainer.py:136] Epoch[54/1000] loss: 0.15687209241471048
I0424 13:58:45.056557 35684 trainer.py:136] Epoch[55/1000] loss: 0.15590771199282955
I0424 13:58:51.235132 35684 trainer.py:136] Epoch[56/1000] loss: 0.15418864458294237
I0424 13:58:57.459505 35684 trainer.py:136] Epoch[57/1000] loss: 0.15348879866680856
I0424 13:59:03.639969 35684 trainer.py:136] Epoch[58/1000] loss: 0.15382252911389885
I0424 13:59:09.845471 35684 trainer.py:136] Epoch[59/1000] loss: 0.15182886588371405
I0424 13:59:15.910833 35684 trainer.py:136] Epoch[60/1000] loss: 0.15091839079129493
I0424 13:59:22.110248 35684 trainer.py:136] Epoch[61/1000] loss: 0.150246883095321
I0424 13:59:28.326690 35684 trainer.py:136] Epoch[62/1000] loss: 0.15011960848913355
I0424 13:59:34.712612 35684 trainer.py:136] Epoch[63/1000] loss: 0.14914316873429184
I0424 13:59:40.816009 35684 trainer.py:136] Epoch[64/1000] loss: 0.14905922746254227
I0424 13:59:46.904315 35684 trainer.py:136] Epoch[65/1000] loss: 0.14733284408763303
I0424 13:59:53.018486 35684 trainer.py:136] Epoch[66/1000] loss: 0.14699642865334528
I0424 13:59:59.170115 35684 trainer.py:136] Epoch[67/1000] loss: 0.14569144582344315
I0424 14:00:05.160725 35684 trainer.py:136] Epoch[68/1000] loss: 0.1462013547198247
I0424 14:00:11.389356 35684 trainer.py:136] Epoch[69/1000] loss: 0.1453802777548968
I0424 14:00:17.779667 35684 trainer.py:136] Epoch[70/1000] loss: 0.14566896956855968
I0424 14:00:23.842547 35684 trainer.py:136] Epoch[71/1000] loss: 0.14375270094911932
I0424 14:00:30.186029 35684 trainer.py:136] Epoch[72/1000] loss: 0.14405456437902936
I0424 14:00:36.325054 35684 trainer.py:136] Epoch[73/1000] loss: 0.14341040359715285
I0424 14:00:42.394402 35684 trainer.py:136] Epoch[74/1000] loss: 0.1431033674438121
I0424 14:00:48.538019 35684 trainer.py:136] Epoch[75/1000] loss: 0.1435452368804964
I0424 14:00:54.685371 35684 trainer.py:136] Epoch[76/1000] loss: 0.14198756167444132
I0424 14:01:00.917947 35684 trainer.py:136] Epoch[77/1000] loss: 0.142819634180958
I0424 14:01:07.095824 35684 trainer.py:136] Epoch[78/1000] loss: 0.14114282242322373
I0424 14:01:13.301226 35684 trainer.py:136] Epoch[79/1000] loss: 0.14118899455515005
I0424 14:01:19.350667 35684 trainer.py:136] Epoch[80/1000] loss: 0.140924670433594
I0424 14:01:25.489284 35684 trainer.py:136] Epoch[81/1000] loss: 0.1411737685991546
I0424 14:01:31.576021 35684 trainer.py:136] Epoch[82/1000] loss: 0.1397884619438042
I0424 14:01:37.740622 35684 trainer.py:136] Epoch[83/1000] loss: 0.1392116278915082
I0424 14:01:43.822828 35684 trainer.py:136] Epoch[84/1000] loss: 0.13903547621379464
I0424 14:01:49.971240 35684 trainer.py:136] Epoch[85/1000] loss: 0.1398607224731122
I0424 14:01:56.278270 35684 trainer.py:136] Epoch[86/1000] loss: 0.13762534801232612
I0424 14:02:02.323604 35684 trainer.py:136] Epoch[87/1000] loss: 0.13722427467168388
I0424 14:02:08.556842 35684 trainer.py:136] Epoch[88/1000] loss: 0.13806063972287258
I0424 14:02:14.722554 35684 trainer.py:136] Epoch[89/1000] loss: 0.13757296967304358
I0424 14:02:20.773799 35684 trainer.py:136] Epoch[90/1000] loss: 0.13691128916659598
I0424 14:02:26.777520 35684 trainer.py:136] Epoch[91/1000] loss: 0.13670547104487984
I0424 14:02:32.965629 35684 trainer.py:136] Epoch[92/1000] loss: 0.135778681706574
I0424 14:02:39.263724 35684 trainer.py:136] Epoch[93/1000] loss: 0.1355186655359753
I0424 14:02:45.560883 35684 trainer.py:136] Epoch[94/1000] loss: 0.1357475963689513
I0424 14:02:52.172499 35684 trainer.py:136] Epoch[95/1000] loss: 0.1360627354706748
I0424 14:02:58.596748 35684 trainer.py:136] Epoch[96/1000] loss: 0.13599940124204604
I0424 14:03:04.857373 35684 trainer.py:136] Epoch[97/1000] loss: 0.1358515776820102
I0424 14:03:10.989714 35684 trainer.py:136] Epoch[98/1000] loss: 0.13509206675877006
I0424 14:03:17.174056 35684 trainer.py:136] Epoch[99/1000] loss: 0.1343322800377668
I0424 14:03:18.601658 35684 trainer.py:142] Test: [{'precision': 0.01588511972633979, 'recall': 0.07627579390272263, 'hit_ratio': 0.21992588369441277, 'ndcg': 0.05005426562038147}]
I0424 14:03:24.673734 35684 trainer.py:136] Epoch[100/1000] loss: 0.13416763609748775
I0424 14:03:30.970849 35684 trainer.py:136] Epoch[101/1000] loss: 0.13638359788110702
I0424 14:03:37.102377 35684 trainer.py:136] Epoch[102/1000] loss: 0.1351544887332593
I0424 14:03:43.282479 35684 trainer.py:136] Epoch[103/1000] loss: 0.13393952785912205
I0424 14:03:49.529765 35684 trainer.py:136] Epoch[104/1000] loss: 0.1350497520070965
I0424 14:03:55.785067 35684 trainer.py:136] Epoch[105/1000] loss: 0.1342372039364556
I0424 14:04:02.107237 35684 trainer.py:136] Epoch[106/1000] loss: 0.1344320246223676
I0424 14:04:08.322298 35684 trainer.py:136] Epoch[107/1000] loss: 0.13323272916220003
I0424 14:04:14.549740 35684 trainer.py:136] Epoch[108/1000] loss: 0.1330948251031213
I0424 14:04:20.885309 35684 trainer.py:136] Epoch[109/1000] loss: 0.13263460021402876
I0424 14:04:27.096451 35684 trainer.py:136] Epoch[110/1000] loss: 0.13329180544715816
I0424 14:04:33.497266 35684 trainer.py:136] Epoch[111/1000] loss: 0.13186571305080996
I0424 14:04:39.696436 35684 trainer.py:136] Epoch[112/1000] loss: 0.1331070494853844
I0424 14:04:45.863929 35684 trainer.py:136] Epoch[113/1000] loss: 0.13197244804794506
I0424 14:04:52.247166 35684 trainer.py:136] Epoch[114/1000] loss: 0.13278275021051955
I0424 14:04:58.440399 35684 trainer.py:136] Epoch[115/1000] loss: 0.13118717314328177
I0424 14:05:04.697710 35684 trainer.py:136] Epoch[116/1000] loss: 0.13182065484382338
I0424 14:05:10.704243 35684 trainer.py:136] Epoch[117/1000] loss: 0.13170020294896626
I0424 14:05:16.877244 35684 trainer.py:136] Epoch[118/1000] loss: 0.13064515413874286
I0424 14:05:23.046247 35684 trainer.py:136] Epoch[119/1000] loss: 0.1311361005498191
I0424 14:05:29.271282 35684 trainer.py:136] Epoch[120/1000] loss: 0.13163620006229917
I0424 14:05:35.450892 35684 trainer.py:136] Epoch[121/1000] loss: 0.1319050730790122
I0424 14:05:41.636764 35684 trainer.py:136] Epoch[122/1000] loss: 0.13085090002771152
I0424 14:05:47.865064 35684 trainer.py:136] Epoch[123/1000] loss: 0.1305550254755101
I0424 14:05:54.062340 35684 trainer.py:136] Epoch[124/1000] loss: 0.13141404458526837
I0424 14:06:00.215316 35684 trainer.py:136] Epoch[125/1000] loss: 0.13039979010315264
I0424 14:06:06.337620 35684 trainer.py:136] Epoch[126/1000] loss: 0.13015500708656796
I0424 14:06:12.615661 35684 trainer.py:136] Epoch[127/1000] loss: 0.13064690275212465
I0424 14:06:18.870268 35684 trainer.py:136] Epoch[128/1000] loss: 0.13043212537038124
I0424 14:06:25.035435 35684 trainer.py:136] Epoch[129/1000] loss: 0.12964519896244597
I0424 14:06:31.049735 35684 trainer.py:136] Epoch[130/1000] loss: 0.12966061497138717
I0424 14:06:37.195479 35684 trainer.py:136] Epoch[131/1000] loss: 0.1287726944280883
I0424 14:06:43.392510 35684 trainer.py:136] Epoch[132/1000] loss: 0.12949510272276604
I0424 14:06:49.409014 35684 trainer.py:136] Epoch[133/1000] loss: 0.1297063857822095
I0424 14:06:55.644435 35684 trainer.py:136] Epoch[134/1000] loss: 0.1292394784800077
I0424 14:07:01.848701 35684 trainer.py:136] Epoch[135/1000] loss: 0.1301044300198555
I0424 14:07:08.053202 35684 trainer.py:136] Epoch[136/1000] loss: 0.12991040907168794
I0424 14:07:14.475324 35684 trainer.py:136] Epoch[137/1000] loss: 0.12888783241732646
I0424 14:07:20.568818 35684 trainer.py:136] Epoch[138/1000] loss: 0.1293950425618786
I0424 14:07:26.795395 35684 trainer.py:136] Epoch[139/1000] loss: 0.1287759514683384
I0424 14:07:32.888733 35684 trainer.py:136] Epoch[140/1000] loss: 0.129037716757443
I0424 14:07:39.036274 35684 trainer.py:136] Epoch[141/1000] loss: 0.12898119109666953
I0424 14:07:45.201769 35684 trainer.py:136] Epoch[142/1000] loss: 0.1288387092240786
I0424 14:07:51.499583 35684 trainer.py:136] Epoch[143/1000] loss: 0.12858076229438944
I0424 14:07:57.608926 35684 trainer.py:136] Epoch[144/1000] loss: 0.12757310738502922
I0424 14:08:04.033671 35684 trainer.py:136] Epoch[145/1000] loss: 0.12800728554947902
I0424 14:08:10.148302 35684 trainer.py:136] Epoch[146/1000] loss: 0.12871976310418823
I0424 14:08:16.366997 35684 trainer.py:136] Epoch[147/1000] loss: 0.12773600574267113
I0424 14:08:22.592591 35684 trainer.py:136] Epoch[148/1000] loss: 0.12735181137666865
I0424 14:08:28.824139 35684 trainer.py:136] Epoch[149/1000] loss: 0.12794603167449015
I0424 14:08:30.233365 35684 trainer.py:142] Test: [{'precision': 0.01651938426453819, 'recall': 0.0790289182543013, 'hit_ratio': 0.22805017103762829, 'ndcg': 0.05152496042441201}]
I0424 14:08:36.551661 35684 trainer.py:136] Epoch[150/1000] loss: 0.1269118280734046
I0424 14:08:42.835805 35684 trainer.py:136] Epoch[151/1000] loss: 0.12762577995910482
I0424 14:08:48.903672 35684 trainer.py:136] Epoch[152/1000] loss: 0.1267281361555649
I0424 14:08:55.138779 35684 trainer.py:136] Epoch[153/1000] loss: 0.12726910589104992
I0424 14:09:01.299056 35684 trainer.py:136] Epoch[154/1000] loss: 0.12727118965427756
I0424 14:09:07.510995 35684 trainer.py:136] Epoch[155/1000] loss: 0.12651790337542357
I0424 14:09:13.731006 35684 trainer.py:136] Epoch[156/1000] loss: 0.12741662612405874
I0424 14:09:29.055441 35684 trainer.py:136] Epoch[157/1000] loss: 0.12702070113460898
I0424 14:09:44.737364 35684 trainer.py:136] Epoch[158/1000] loss: 0.12670144009388098
I0424 14:10:00.999461 35684 trainer.py:136] Epoch[159/1000] loss: 0.12624932282556922
I0424 14:10:10.924170 35684 trainer.py:136] Epoch[160/1000] loss: 0.12693259309409027
I0424 14:10:17.458885 35684 trainer.py:136] Epoch[161/1000] loss: 0.12653322050632057
I0424 14:10:23.761370 35684 trainer.py:136] Epoch[162/1000] loss: 0.12671872960813976
I0424 14:10:35.093684 35684 trainer.py:136] Epoch[163/1000] loss: 0.12725768667661538
I0424 14:10:50.518162 35684 trainer.py:136] Epoch[164/1000] loss: 0.1275566130623979
I0424 14:11:06.723861 35684 trainer.py:136] Epoch[165/1000] loss: 0.12610007999307019
I0424 14:11:22.773778 35684 trainer.py:136] Epoch[166/1000] loss: 0.1266964325460337
I0424 14:11:30.219464 35684 trainer.py:136] Epoch[167/1000] loss: 0.12701664953413655
I0424 14:11:36.674153 35684 trainer.py:136] Epoch[168/1000] loss: 0.12672410981129792
I0424 14:11:42.827128 35684 trainer.py:136] Epoch[169/1000] loss: 0.12621565668259638
I0424 14:11:49.135211 35684 trainer.py:136] Epoch[170/1000] loss: 0.1254606111827543
I0424 14:11:55.316704 35684 trainer.py:136] Epoch[171/1000] loss: 0.12620137897083314
I0424 14:12:01.587357 35684 trainer.py:136] Epoch[172/1000] loss: 0.12602199942378675
I0424 14:12:07.765915 35684 trainer.py:136] Epoch[173/1000] loss: 0.12668180895053735
I0424 14:12:14.075901 35684 trainer.py:136] Epoch[174/1000] loss: 0.12638068906331468
I0424 14:12:20.365795 35684 trainer.py:136] Epoch[175/1000] loss: 0.1262000155145839
I0424 14:12:26.547917 35684 trainer.py:136] Epoch[176/1000] loss: 0.12575234245445768
I0424 14:12:32.893577 35684 trainer.py:136] Epoch[177/1000] loss: 0.12526893565210245
I0424 14:12:39.162461 35684 trainer.py:136] Epoch[178/1000] loss: 0.1259002834558487
I0424 14:12:45.206169 35684 trainer.py:136] Epoch[179/1000] loss: 0.12617375360707106
I0424 14:12:51.236207 35684 trainer.py:136] Epoch[180/1000] loss: 0.125421904027462
I0424 14:12:57.483569 35684 trainer.py:136] Epoch[181/1000] loss: 0.12493213329274776
I0424 14:13:03.656030 35684 trainer.py:136] Epoch[182/1000] loss: 0.12519032659672075
I0424 14:13:09.868564 35684 trainer.py:136] Epoch[183/1000] loss: 0.12594340425931802
I0424 14:13:15.998551 35684 trainer.py:136] Epoch[184/1000] loss: 0.1251104581406561
I0424 14:13:22.150454 35684 trainer.py:136] Epoch[185/1000] loss: 0.1258923194165957
I0424 14:13:28.249622 35684 trainer.py:136] Epoch[186/1000] loss: 0.12628345974421096
I0424 14:13:34.535637 35684 trainer.py:136] Epoch[187/1000] loss: 0.12566131706965172
I0424 14:13:40.736513 35684 trainer.py:136] Epoch[188/1000] loss: 0.12588228196915935
I0424 14:13:46.975372 35684 trainer.py:136] Epoch[189/1000] loss: 0.12483296290797702
I0424 14:13:53.122027 35684 trainer.py:136] Epoch[190/1000] loss: 0.1248465041487904
I0424 14:13:59.331124 35684 trainer.py:136] Epoch[191/1000] loss: 0.12511443864491026
I0424 14:14:05.309642 35684 trainer.py:136] Epoch[192/1000] loss: 0.12555625188653752
I0424 14:14:11.614999 35684 trainer.py:136] Epoch[193/1000] loss: 0.12516491721242162
I0424 14:14:17.825543 35684 trainer.py:136] Epoch[194/1000] loss: 0.12534366510177064
I0424 14:14:24.056144 35684 trainer.py:136] Epoch[195/1000] loss: 0.12519411325959837
I0424 14:14:30.258381 35684 trainer.py:136] Epoch[196/1000] loss: 0.12466557311304545
I0424 14:14:36.442025 35684 trainer.py:136] Epoch[197/1000] loss: 0.12441393935074241
I0424 14:14:42.732737 35684 trainer.py:136] Epoch[198/1000] loss: 0.1242915937456034
I0424 14:14:48.836423 35684 trainer.py:136] Epoch[199/1000] loss: 0.12467154633190672
I0424 14:14:50.232242 35684 trainer.py:142] Test: [{'precision': 0.01649087799315848, 'recall': 0.07947139725935634, 'hit_ratio': 0.2273375142531357, 'ndcg': 0.052362893764849865}]
I0424 14:14:56.441516 35684 trainer.py:136] Epoch[200/1000] loss: 0.12453816767971394
I0424 14:15:02.540751 35684 trainer.py:136] Epoch[201/1000] loss: 0.12458369072716115
I0424 14:15:08.653901 35684 trainer.py:136] Epoch[202/1000] loss: 0.12451437103041148
I0424 14:15:14.796738 35684 trainer.py:136] Epoch[203/1000] loss: 0.12403180740647397
I0424 14:15:21.022063 35684 trainer.py:136] Epoch[204/1000] loss: 0.12453117398387295
I0424 14:15:27.133707 35684 trainer.py:136] Epoch[205/1000] loss: 0.12452184383646916
I0424 14:15:33.398397 35684 trainer.py:136] Epoch[206/1000] loss: 0.12454981849355212
I0424 14:15:46.952771 35684 trainer.py:136] Epoch[207/1000] loss: 0.12459810305449923
I0424 14:16:02.567998 35684 trainer.py:136] Epoch[208/1000] loss: 0.12374160590313249
I0424 14:16:18.255552 35684 trainer.py:136] Epoch[209/1000] loss: 0.12450749326055333
I0424 14:16:33.919882 35684 trainer.py:136] Epoch[210/1000] loss: 0.1235868327193341
I0424 14:16:49.591002 35684 trainer.py:136] Epoch[211/1000] loss: 0.1234598658600096
I0424 14:17:05.367460 35684 trainer.py:136] Epoch[212/1000] loss: 0.1244135478795585
I0424 14:17:20.875134 35684 trainer.py:136] Epoch[213/1000] loss: 0.12471363706103826
I0424 14:17:36.521843 35684 trainer.py:136] Epoch[214/1000] loss: 0.12424078116477547
I0424 14:17:52.492800 35684 trainer.py:136] Epoch[215/1000] loss: 0.12453081900790586
I0424 14:18:08.507075 35684 trainer.py:136] Epoch[216/1000] loss: 0.12427801739866451
I0424 14:18:23.992128 35684 trainer.py:136] Epoch[217/1000] loss: 0.1238071653297392
I0424 14:18:39.644953 35684 trainer.py:136] Epoch[218/1000] loss: 0.1241847486314127
I0424 14:18:55.343414 35684 trainer.py:136] Epoch[219/1000] loss: 0.12278540445081258
I0424 14:19:11.413421 35684 trainer.py:136] Epoch[220/1000] loss: 0.12369991144386389
I0424 14:19:27.633739 35684 trainer.py:136] Epoch[221/1000] loss: 0.12341922142748106
I0424 14:19:43.311258 35684 trainer.py:136] Epoch[222/1000] loss: 0.12458744139994606
I0424 14:19:58.995315 35684 trainer.py:136] Epoch[223/1000] loss: 0.1242819537045592
I0424 14:20:14.618241 35684 trainer.py:136] Epoch[224/1000] loss: 0.12377984670259184
I0424 14:20:30.523851 35684 trainer.py:136] Epoch[225/1000] loss: 0.12410096887309673
I0424 14:20:46.155158 35684 trainer.py:136] Epoch[226/1000] loss: 0.12386426203331705
I0424 14:21:01.692077 35684 trainer.py:136] Epoch[227/1000] loss: 0.12414347961292428
I0424 14:21:17.461259 35684 trainer.py:136] Epoch[228/1000] loss: 0.12306780633279833
I0424 14:21:33.231054 35684 trainer.py:136] Epoch[229/1000] loss: 0.12442945423772779
I0424 14:21:48.788036 35684 trainer.py:136] Epoch[230/1000] loss: 0.12408577019380311
I0424 14:22:04.184244 35684 trainer.py:136] Epoch[231/1000] loss: 0.12401986160015656
I0424 14:22:19.912439 35684 trainer.py:136] Epoch[232/1000] loss: 0.12209966702986572
I0424 14:22:35.625537 35684 trainer.py:136] Epoch[233/1000] loss: 0.12326893816560001
I0424 14:22:51.011116 35684 trainer.py:136] Epoch[234/1000] loss: 0.1226057263754182
I0424 14:23:06.756253 35684 trainer.py:136] Epoch[235/1000] loss: 0.12363861059233294
I0424 14:23:22.652947 35684 trainer.py:136] Epoch[236/1000] loss: 0.12236088981567803
I0424 14:23:38.153455 35684 trainer.py:136] Epoch[237/1000] loss: 0.12291459360365141
I0424 14:23:53.867162 35684 trainer.py:136] Epoch[238/1000] loss: 0.12313687018418716
I0424 14:24:09.217272 35684 trainer.py:136] Epoch[239/1000] loss: 0.12373101332430113
I0424 14:24:24.525081 35684 trainer.py:136] Epoch[240/1000] loss: 0.12269653746132124
I0424 14:24:40.186199 35684 trainer.py:136] Epoch[241/1000] loss: 0.12324019534102941
I0424 14:24:55.527943 35684 trainer.py:136] Epoch[242/1000] loss: 0.123372882604599
I0424 14:25:11.227940 35684 trainer.py:136] Epoch[243/1000] loss: 0.1227407711794821
I0424 14:25:26.738922 35684 trainer.py:136] Epoch[244/1000] loss: 0.12337328645132356
I0424 14:25:42.241084 35684 trainer.py:136] Epoch[245/1000] loss: 0.12297265143212625
I0424 14:25:57.618993 35684 trainer.py:136] Epoch[246/1000] loss: 0.1226911573844441
I0424 14:26:13.045392 35684 trainer.py:136] Epoch[247/1000] loss: 0.12308515684079316
I0424 14:26:29.114061 35684 trainer.py:136] Epoch[248/1000] loss: 0.12317906888359684
I0424 14:26:44.323350 35684 trainer.py:136] Epoch[249/1000] loss: 0.12227595887951932
I0424 14:26:46.913473 35684 trainer.py:142] Test: [{'precision': 0.016612029646522225, 'recall': 0.07921273784384697, 'hit_ratio': 0.2283352337514253, 'ndcg': 0.052163724662843844}]
I0424 14:27:02.528950 35684 trainer.py:136] Epoch[250/1000] loss: 0.12180728793649351
I0424 14:27:17.868107 35684 trainer.py:136] Epoch[251/1000] loss: 0.1241036990689019
I0424 14:27:33.538180 35684 trainer.py:136] Epoch[252/1000] loss: 0.12416909736091808
I0424 14:27:48.841325 35684 trainer.py:136] Epoch[253/1000] loss: 0.12346526778350442
I0424 14:28:04.501086 35684 trainer.py:136] Epoch[254/1000] loss: 0.12292455717668695
I0424 14:28:19.889350 35684 trainer.py:136] Epoch[255/1000] loss: 0.1224891847725642
I0424 14:28:35.365020 35684 trainer.py:136] Epoch[256/1000] loss: 0.12275903103715283
I0424 14:28:50.743322 35684 trainer.py:136] Epoch[257/1000] loss: 0.1218871020917165
I0424 14:29:06.241878 35684 trainer.py:136] Epoch[258/1000] loss: 0.12285098042023385
I0424 14:29:21.908440 35684 trainer.py:136] Epoch[259/1000] loss: 0.12289184117216174
I0424 14:29:37.161116 35684 trainer.py:136] Epoch[260/1000] loss: 0.12290391868959039
I0424 14:29:52.491611 35684 trainer.py:136] Epoch[261/1000] loss: 0.12280616985034135
I0424 14:30:08.132083 35684 trainer.py:136] Epoch[262/1000] loss: 0.12278326575533818
I0424 14:30:23.532071 35684 trainer.py:136] Epoch[263/1000] loss: 0.12274055220818116
I0424 14:30:39.466248 35684 trainer.py:136] Epoch[264/1000] loss: 0.12164713694887647
I0424 14:30:54.983494 35684 trainer.py:136] Epoch[265/1000] loss: 0.12204609849190308
I0424 14:31:10.678074 35684 trainer.py:136] Epoch[266/1000] loss: 0.12159123978877472
I0424 14:31:26.167539 35684 trainer.py:136] Epoch[267/1000] loss: 0.12317702224699117
I0424 14:31:41.940699 35684 trainer.py:136] Epoch[268/1000] loss: 0.12255968570204104
I0424 14:31:57.558167 35684 trainer.py:136] Epoch[269/1000] loss: 0.12263715986983251
I0424 14:32:13.395799 35684 trainer.py:136] Epoch[270/1000] loss: 0.12303860611834769
I0424 14:32:29.066012 35684 trainer.py:136] Epoch[271/1000] loss: 0.12242903535143804
I0424 14:32:44.610702 35684 trainer.py:136] Epoch[272/1000] loss: 0.12194473422684912
I0424 14:33:00.393555 35684 trainer.py:136] Epoch[273/1000] loss: 0.1224634326615576
I0424 14:33:13.907573 35684 trainer.py:136] Epoch[274/1000] loss: 0.12309258734270678
I0424 14:33:20.195026 35684 trainer.py:136] Epoch[275/1000] loss: 0.12222891389313391
I0424 14:33:26.694195 35684 trainer.py:136] Epoch[276/1000] loss: 0.12259198965157493
I0424 14:33:33.369764 35684 trainer.py:136] Epoch[277/1000] loss: 0.121931730690649
I0424 14:33:39.810283 35684 trainer.py:136] Epoch[278/1000] loss: 0.12247919240745447
I0424 14:33:46.149978 35684 trainer.py:136] Epoch[279/1000] loss: 0.12177064320293524
I0424 14:33:52.267841 35684 trainer.py:136] Epoch[280/1000] loss: 0.12187076814598956
I0424 14:33:58.445066 35684 trainer.py:136] Epoch[281/1000] loss: 0.1217575873863899
I0424 14:34:04.654234 35684 trainer.py:136] Epoch[282/1000] loss: 0.12241839882680926
I0424 14:34:10.927760 35684 trainer.py:136] Epoch[283/1000] loss: 0.12183812361652568
I0424 14:34:17.154541 35684 trainer.py:136] Epoch[284/1000] loss: 0.1223089043366707
I0424 14:34:23.388241 35684 trainer.py:136] Epoch[285/1000] loss: 0.12262478432917999
I0424 14:34:29.558011 35684 trainer.py:136] Epoch[286/1000] loss: 0.12256121243965828
I0424 14:34:35.816193 35684 trainer.py:136] Epoch[287/1000] loss: 0.12179389457076283
I0424 14:34:42.087569 35684 trainer.py:136] Epoch[288/1000] loss: 0.12187717728695627
I0424 14:34:48.453336 35684 trainer.py:136] Epoch[289/1000] loss: 0.12217474451004448
I0424 14:34:54.503153 35684 trainer.py:136] Epoch[290/1000] loss: 0.12224979673401784
I0424 14:35:00.924136 35684 trainer.py:136] Epoch[291/1000] loss: 0.12182416691113326
I0424 14:35:07.289949 35684 trainer.py:136] Epoch[292/1000] loss: 0.12226705707735934
I0424 14:35:13.861495 35684 trainer.py:136] Epoch[293/1000] loss: 0.12129905340024981
I0424 14:35:20.328858 35684 trainer.py:136] Epoch[294/1000] loss: 0.1222874701528226
I0424 14:35:26.731935 35684 trainer.py:136] Epoch[295/1000] loss: 0.12224410903655876
I0424 14:35:33.013426 35684 trainer.py:136] Epoch[296/1000] loss: 0.12198371768502866
I0424 14:35:39.480816 35684 trainer.py:136] Epoch[297/1000] loss: 0.12150971806150372
I0424 14:35:45.793968 35684 trainer.py:136] Epoch[298/1000] loss: 0.12186676087015766
I0424 14:35:52.040073 35684 trainer.py:136] Epoch[299/1000] loss: 0.1220274726718159
I0424 14:35:53.427582 35684 trainer.py:142] Test: [{'precision': 0.0167973204104903, 'recall': 0.080780259910762, 'hit_ratio': 0.23161345496009123, 'ndcg': 0.0526268359345781}]
I0424 14:35:59.452627 35684 trainer.py:136] Epoch[300/1000] loss: 0.12221829757346946
I0424 14:36:05.653803 35684 trainer.py:136] Epoch[301/1000] loss: 0.1209553113933337
I0424 14:36:11.994684 35684 trainer.py:136] Epoch[302/1000] loss: 0.12215184129900851
I0424 14:36:18.539856 35684 trainer.py:136] Epoch[303/1000] loss: 0.12168884630930626
I0424 14:36:24.675909 35684 trainer.py:136] Epoch[304/1000] loss: 0.12151792001421169
I0424 14:36:30.934727 35684 trainer.py:136] Epoch[305/1000] loss: 0.12139195835186263
I0424 14:36:37.098214 35684 trainer.py:136] Epoch[306/1000] loss: 0.12143758646512436
I0424 14:36:43.276975 35684 trainer.py:136] Epoch[307/1000] loss: 0.12257661771471218
I0424 14:36:49.404530 35684 trainer.py:136] Epoch[308/1000] loss: 0.12143413469953052
I0424 14:36:55.810623 35684 trainer.py:136] Epoch[309/1000] loss: 0.12136535283367512
I0424 14:37:02.115602 35684 trainer.py:136] Epoch[310/1000] loss: 0.1215056192319272
I0424 14:37:08.560104 35684 trainer.py:136] Epoch[311/1000] loss: 0.12095872211759373
I0424 14:37:14.708600 35684 trainer.py:136] Epoch[312/1000] loss: 0.12058897695298922
I0424 14:37:21.053355 35684 trainer.py:136] Epoch[313/1000] loss: 0.1220944377325349
I0424 14:37:27.322202 35684 trainer.py:136] Epoch[314/1000] loss: 0.12117903187113294
I0424 14:37:33.536389 35684 trainer.py:136] Epoch[315/1000] loss: 0.12119625736091097
I0424 14:37:39.986556 35684 trainer.py:136] Epoch[316/1000] loss: 0.12151195071006225
I0424 14:37:46.572168 35684 trainer.py:136] Epoch[317/1000] loss: 0.12116335206112619
I0424 14:37:52.777799 35684 trainer.py:136] Epoch[318/1000] loss: 0.12173492032087456
I0424 14:37:59.201462 35684 trainer.py:136] Epoch[319/1000] loss: 0.1219551323328988
I0424 14:38:05.396001 35684 trainer.py:136] Epoch[320/1000] loss: 0.1219883516935979
I0424 14:38:11.579205 35684 trainer.py:136] Epoch[321/1000] loss: 0.12116196486404386
I0424 14:38:18.010783 35684 trainer.py:136] Epoch[322/1000] loss: 0.12194848502591504
I0424 14:38:24.538519 35684 trainer.py:136] Epoch[323/1000] loss: 0.12107285756175801
I0424 14:38:30.799530 35684 trainer.py:136] Epoch[324/1000] loss: 0.12142411063788301
I0424 14:38:37.065809 35684 trainer.py:136] Epoch[325/1000] loss: 0.12239924603599613
I0424 14:38:43.198767 35684 trainer.py:136] Epoch[326/1000] loss: 0.12130845237081334
I0424 14:38:49.398284 35684 trainer.py:136] Epoch[327/1000] loss: 0.12092584005351793
I0424 14:38:55.569148 35684 trainer.py:136] Epoch[328/1000] loss: 0.1206597695916386
I0424 14:39:01.682642 35684 trainer.py:136] Epoch[329/1000] loss: 0.12107658588280112
I0424 14:39:07.945227 35684 trainer.py:136] Epoch[330/1000] loss: 0.12160295677387108
I0424 14:39:14.196911 35684 trainer.py:136] Epoch[331/1000] loss: 0.12059513555239823
I0424 14:39:20.453043 35684 trainer.py:136] Epoch[332/1000] loss: 0.1222475090269315
I0424 14:39:26.547403 35684 trainer.py:136] Epoch[333/1000] loss: 0.12196553650043779
I0424 14:39:32.783019 35684 trainer.py:136] Epoch[334/1000] loss: 0.12143768408035828
I0424 14:39:39.045853 35684 trainer.py:136] Epoch[335/1000] loss: 0.12172788558369976
I0424 14:39:45.472394 35684 trainer.py:136] Epoch[336/1000] loss: 0.1217937157568285
I0424 14:39:51.757654 35684 trainer.py:136] Epoch[337/1000] loss: 0.12216475366030709
I0424 14:39:58.054756 35684 trainer.py:136] Epoch[338/1000] loss: 0.12146062454429724
I0424 14:40:08.016670 35684 trainer.py:136] Epoch[339/1000] loss: 0.12112838093001964
I0424 14:40:23.822594 35684 trainer.py:136] Epoch[340/1000] loss: 0.12127032295121985
I0424 14:40:39.725111 35684 trainer.py:136] Epoch[341/1000] loss: 0.12188683020866524
I0424 14:40:55.421528 35684 trainer.py:136] Epoch[342/1000] loss: 0.12170581961587323
I0424 14:41:11.433547 35684 trainer.py:136] Epoch[343/1000] loss: 0.12079074120117446
I0424 14:41:27.224719 35684 trainer.py:136] Epoch[344/1000] loss: 0.12124287753792132
I0424 14:41:43.117607 35684 trainer.py:136] Epoch[345/1000] loss: 0.12079094602900037
I0424 14:41:58.851123 35684 trainer.py:136] Epoch[346/1000] loss: 0.12050255312252853
I0424 14:42:14.745692 35684 trainer.py:136] Epoch[347/1000] loss: 0.12079423855421907
I0424 14:42:31.107079 35684 trainer.py:136] Epoch[348/1000] loss: 0.11992462130926423
I0424 14:42:47.146075 35684 trainer.py:136] Epoch[349/1000] loss: 0.12106036836818113
I0424 14:42:49.465733 35684 trainer.py:142] Test: [{'precision': 0.01681157354618015, 'recall': 0.08065213472632081, 'hit_ratio': 0.23175598631698974, 'ndcg': 0.05288166617761025}]
I0424 14:43:04.240986 35684 trainer.py:136] Epoch[350/1000] loss: 0.12129218964758566
I0424 14:43:10.660976 35684 trainer.py:136] Epoch[351/1000] loss: 0.12061870224395041
I0424 14:43:17.145546 35684 trainer.py:136] Epoch[352/1000] loss: 0.12155729683779054
I0424 14:43:23.446938 35684 trainer.py:136] Epoch[353/1000] loss: 0.12102270025317952
I0424 14:43:29.563870 35684 trainer.py:136] Epoch[354/1000] loss: 0.12043505035719629
I0424 14:43:35.942230 35684 trainer.py:136] Epoch[355/1000] loss: 0.12102504125085928
I0424 14:43:42.233808 35684 trainer.py:136] Epoch[356/1000] loss: 0.12097191040293645
I0424 14:43:48.448649 35684 trainer.py:136] Epoch[357/1000] loss: 0.12143985914476847
I0424 14:43:54.864274 35684 trainer.py:136] Epoch[358/1000] loss: 0.12102089582358376
I0424 14:44:01.149881 35684 trainer.py:136] Epoch[359/1000] loss: 0.12072269138643298
I0424 14:44:07.523158 35684 trainer.py:136] Epoch[360/1000] loss: 0.121730121515565
I0424 14:44:13.701386 35684 trainer.py:136] Epoch[361/1000] loss: 0.12048897866980504
I0424 14:44:19.808392 35684 trainer.py:136] Epoch[362/1000] loss: 0.12080488606529721
I0424 14:44:26.220399 35684 trainer.py:136] Epoch[363/1000] loss: 0.12089409830711656
I0424 14:44:32.506598 35684 trainer.py:136] Epoch[364/1000] loss: 0.1206761224795196
I0424 14:44:38.606672 35684 trainer.py:136] Epoch[365/1000] loss: 0.1211640901737294
I0424 14:44:44.831518 35684 trainer.py:136] Epoch[366/1000] loss: 0.12089243720648653
I0424 14:44:50.907817 35684 trainer.py:136] Epoch[367/1000] loss: 0.12091098965729698
I0424 14:44:57.024773 35684 trainer.py:136] Epoch[368/1000] loss: 0.1212461223289118
I0424 14:45:03.059099 35684 trainer.py:136] Epoch[369/1000] loss: 0.12153022067021516
I0424 14:45:09.091882 35684 trainer.py:136] Epoch[370/1000] loss: 0.12103370829658994
I0424 14:45:15.237442 35684 trainer.py:136] Epoch[371/1000] loss: 0.12013761509778136
I0424 14:45:21.667014 35684 trainer.py:136] Epoch[372/1000] loss: 0.12087824359788733
I0424 14:45:27.840523 35684 trainer.py:136] Epoch[373/1000] loss: 0.12027978505623543
I0424 14:45:34.044987 35684 trainer.py:136] Epoch[374/1000] loss: 0.121122447994806
I0424 14:45:40.493187 35684 trainer.py:136] Epoch[375/1000] loss: 0.12001581123824846
I0424 14:45:46.884553 35684 trainer.py:136] Epoch[376/1000] loss: 0.12098801085504435
I0424 14:45:52.972729 35684 trainer.py:136] Epoch[377/1000] loss: 0.12081145166845644
I0424 14:45:59.413702 35684 trainer.py:136] Epoch[378/1000] loss: 0.12086463264994703
I0424 14:46:05.723945 35684 trainer.py:136] Epoch[379/1000] loss: 0.12096884139513565
I0424 14:46:12.018800 35684 trainer.py:136] Epoch[380/1000] loss: 0.12094683856782266
I0424 14:46:18.420876 35684 trainer.py:136] Epoch[381/1000] loss: 0.12133740128602012
I0424 14:46:24.641921 35684 trainer.py:136] Epoch[382/1000] loss: 0.12066922122139041
I0424 14:46:30.863254 35684 trainer.py:136] Epoch[383/1000] loss: 0.12062901157443806
I0424 14:46:37.193625 35684 trainer.py:136] Epoch[384/1000] loss: 0.1211458920674809
I0424 14:46:43.404917 35684 trainer.py:136] Epoch[385/1000] loss: 0.12069852763818482
I0424 14:46:49.570490 35684 trainer.py:136] Epoch[386/1000] loss: 0.1202355864442001
I0424 14:46:55.855003 35684 trainer.py:136] Epoch[387/1000] loss: 0.1200492104231301
I0424 14:47:02.019575 35684 trainer.py:136] Epoch[388/1000] loss: 0.12071908126443119
I0424 14:47:08.180596 35684 trainer.py:136] Epoch[389/1000] loss: 0.1209249184545824
I0424 14:47:14.319193 35684 trainer.py:136] Epoch[390/1000] loss: 0.12014432895486638
I0424 14:47:20.648555 35684 trainer.py:136] Epoch[391/1000] loss: 0.12073992255885722
I0424 14:47:26.987273 35684 trainer.py:136] Epoch[392/1000] loss: 0.1207958693474026
I0424 14:47:33.264609 35684 trainer.py:136] Epoch[393/1000] loss: 0.12014173602653762
I0424 14:47:39.593326 35684 trainer.py:136] Epoch[394/1000] loss: 0.12021138961032285
I0424 14:47:45.807418 35684 trainer.py:136] Epoch[395/1000] loss: 0.1207971570350356
I0424 14:47:51.843620 35684 trainer.py:136] Epoch[396/1000] loss: 0.12039274949643572
I0424 14:47:58.060985 35684 trainer.py:136] Epoch[397/1000] loss: 0.12129108001620083
I0424 14:48:04.358085 35684 trainer.py:136] Epoch[398/1000] loss: 0.12072790414094925
I0424 14:48:10.567374 35684 trainer.py:136] Epoch[399/1000] loss: 0.12107957242909125
I0424 14:48:11.992003 35684 trainer.py:142] Test: [{'precision': 0.017039623717217785, 'recall': 0.08204284756577464, 'hit_ratio': 0.23432155074116306, 'ndcg': 0.05355371219483774}]
I0424 14:48:18.164265 35684 trainer.py:136] Epoch[400/1000] loss: 0.1208457388615204
I0424 14:48:24.543481 35684 trainer.py:136] Epoch[401/1000] loss: 0.12067289726208832
I0424 14:48:30.726847 35684 trainer.py:136] Epoch[402/1000] loss: 0.12063352953074342
I0424 14:48:36.787033 35684 trainer.py:136] Epoch[403/1000] loss: 0.11982191644482694
I0424 14:48:43.004505 35684 trainer.py:136] Epoch[404/1000] loss: 0.12013873192718473
I0424 14:48:49.330102 35684 trainer.py:136] Epoch[405/1000] loss: 0.12068306604179285
I0424 14:48:55.427055 35684 trainer.py:136] Epoch[406/1000] loss: 0.12041323960332548
I0424 14:49:01.829088 35684 trainer.py:136] Epoch[407/1000] loss: 0.1207371170995599
I0424 14:49:08.001257 35684 trainer.py:136] Epoch[408/1000] loss: 0.12128095354064036
I0424 14:49:14.516628 35684 trainer.py:136] Epoch[409/1000] loss: 0.12124770576671018
I0424 14:49:20.918583 35684 trainer.py:136] Epoch[410/1000] loss: 0.12008610658221326
I0424 14:49:27.002816 35684 trainer.py:136] Epoch[411/1000] loss: 0.12034527351290493
I0424 14:49:33.390090 35684 trainer.py:136] Epoch[412/1000] loss: 0.12062179436117916
I0424 14:49:39.631587 35684 trainer.py:136] Epoch[413/1000] loss: 0.12088837499840785
I0424 14:49:45.838312 35684 trainer.py:136] Epoch[414/1000] loss: 0.11986472268225783
I0424 14:49:52.094151 35684 trainer.py:136] Epoch[415/1000] loss: 0.12025866821660834
I0424 14:49:58.562652 35684 trainer.py:136] Epoch[416/1000] loss: 0.12079136250382763
I0424 14:50:04.790191 35684 trainer.py:136] Epoch[417/1000] loss: 0.12069120952638529
I0424 14:50:10.946273 35684 trainer.py:136] Epoch[418/1000] loss: 0.12118308688119306
I0424 14:50:17.258808 35684 trainer.py:136] Epoch[419/1000] loss: 0.12028037617772312
I0424 14:50:23.532518 35684 trainer.py:136] Epoch[420/1000] loss: 0.12070363141217474
I0424 14:50:29.788866 35684 trainer.py:136] Epoch[421/1000] loss: 0.12073441102343091
I0424 14:50:36.309556 35684 trainer.py:136] Epoch[422/1000] loss: 0.12017466468831241
I0424 14:50:42.542945 35684 trainer.py:136] Epoch[423/1000] loss: 0.12007754750676074
I0424 14:50:48.871621 35684 trainer.py:136] Epoch[424/1000] loss: 0.12068866508997093
I0424 14:50:55.127071 35684 trainer.py:136] Epoch[425/1000] loss: 0.11931398700354463
I0424 14:51:01.564078 35684 trainer.py:136] Epoch[426/1000] loss: 0.1207237627546666
I0424 14:51:07.774835 35684 trainer.py:136] Epoch[427/1000] loss: 0.11972201767109208
I0424 14:51:14.174262 35684 trainer.py:136] Epoch[428/1000] loss: 0.12019449611336498
I0424 14:51:20.366450 35684 trainer.py:136] Epoch[429/1000] loss: 0.12000882133083829
I0424 14:51:26.560211 35684 trainer.py:136] Epoch[430/1000] loss: 0.1205105414077387
I0424 14:51:32.779382 35684 trainer.py:136] Epoch[431/1000] loss: 0.1193818692433632
I0424 14:51:39.186330 35684 trainer.py:136] Epoch[432/1000] loss: 0.11981657286316662
I0424 14:51:45.341523 35684 trainer.py:136] Epoch[433/1000] loss: 0.12099239002850096
I0424 14:51:51.655315 35684 trainer.py:136] Epoch[434/1000] loss: 0.12093695972935628
I0424 14:51:57.852045 35684 trainer.py:136] Epoch[435/1000] loss: 0.11986620610548278
I0424 14:52:04.317896 35684 trainer.py:136] Epoch[436/1000] loss: 0.12044551034094923
I0424 14:52:10.629466 35684 trainer.py:136] Epoch[437/1000] loss: 0.12070191361136355
I0424 14:52:16.902542 35684 trainer.py:136] Epoch[438/1000] loss: 0.11972422102245234
I0424 14:52:23.134451 35684 trainer.py:136] Epoch[439/1000] loss: 0.12000134738825136
I0424 14:52:29.455873 35684 trainer.py:136] Epoch[440/1000] loss: 0.12030076361813788
I0424 14:52:35.626307 35684 trainer.py:136] Epoch[441/1000] loss: 0.12005455918231253
I0424 14:52:41.810204 35684 trainer.py:136] Epoch[442/1000] loss: 0.12001843434774269
I0424 14:52:47.994063 35684 trainer.py:136] Epoch[443/1000] loss: 0.11977739480592436
I0424 14:52:54.327019 35684 trainer.py:136] Epoch[444/1000] loss: 0.12028704116405067
I0424 14:53:00.423279 35684 trainer.py:136] Epoch[445/1000] loss: 0.11994134609476995
I0424 14:53:06.684043 35684 trainer.py:136] Epoch[446/1000] loss: 0.11991566949981754
I0424 14:53:12.904036 35684 trainer.py:136] Epoch[447/1000] loss: 0.12005761088961261
I0424 14:53:19.215067 35684 trainer.py:136] Epoch[448/1000] loss: 0.12068705121844502
I0424 14:53:25.376739 35684 trainer.py:136] Epoch[449/1000] loss: 0.1206969697091539
I0424 14:53:26.756574 35684 trainer.py:142] Test: [{'precision': 0.017003990877993147, 'recall': 0.08153133316028094, 'hit_ratio': 0.23275370581527935, 'ndcg': 0.053437674890058184}]
I0424 14:53:33.135431 35684 trainer.py:136] Epoch[450/1000] loss: 0.11986115612721039
I0424 14:53:39.467378 35684 trainer.py:136] Epoch[451/1000] loss: 0.12060309264619472
I0424 14:53:45.841225 35684 trainer.py:136] Epoch[452/1000] loss: 0.11915811656390206
I0424 14:53:51.950183 35684 trainer.py:136] Epoch[453/1000] loss: 0.11982696718078549
I0424 14:53:58.211256 35684 trainer.py:136] Epoch[454/1000] loss: 0.12071688397456024
I0424 14:54:04.572230 35684 trainer.py:136] Epoch[455/1000] loss: 0.12073404064117851
I0424 14:54:10.816729 35684 trainer.py:136] Epoch[456/1000] loss: 0.12078732037443225
I0424 14:54:17.095532 35684 trainer.py:136] Epoch[457/1000] loss: 0.11966955308186805
I0424 14:54:23.514821 35684 trainer.py:136] Epoch[458/1000] loss: 0.12056047040022026
I0424 14:54:29.859982 35684 trainer.py:136] Epoch[459/1000] loss: 0.1210349562056994
I0424 14:54:36.083321 35684 trainer.py:136] Epoch[460/1000] loss: 0.1198810325083086
I0424 14:54:42.346835 35684 trainer.py:136] Epoch[461/1000] loss: 0.11997766666493173
I0424 14:54:48.553778 35684 trainer.py:136] Epoch[462/1000] loss: 0.11984674165309486
I0424 14:54:54.608991 35684 trainer.py:136] Epoch[463/1000] loss: 0.12057455022961407
I0424 14:55:00.737217 35684 trainer.py:136] Epoch[464/1000] loss: 0.11962490655102972
I0424 14:55:06.785181 35684 trainer.py:136] Epoch[465/1000] loss: 0.1207058548422183
I0424 14:55:13.080444 35684 trainer.py:136] Epoch[466/1000] loss: 0.12015392656548549
I0424 14:55:19.072733 35684 trainer.py:136] Epoch[467/1000] loss: 0.12085270843768524
I0424 14:55:25.407429 35684 trainer.py:136] Epoch[468/1000] loss: 0.12090109617023145
I0424 14:55:31.601368 35684 trainer.py:136] Epoch[469/1000] loss: 0.12044303005529662
I0424 14:55:38.046068 35684 trainer.py:136] Epoch[470/1000] loss: 0.11966561374522872
I0424 14:55:44.424446 35684 trainer.py:136] Epoch[471/1000] loss: 0.12050065473984864
I0424 14:55:50.803152 35684 trainer.py:136] Epoch[472/1000] loss: 0.12006234415506913
I0424 14:55:57.267355 35684 trainer.py:136] Epoch[473/1000] loss: 0.12026822339680235
I0424 14:56:03.820110 35684 trainer.py:136] Epoch[474/1000] loss: 0.12021336073087434
I0424 14:56:10.059199 35684 trainer.py:136] Epoch[475/1000] loss: 0.11954541870598066
I0424 14:56:16.317303 35684 trainer.py:136] Epoch[476/1000] loss: 0.11955236630924677
I0424 14:56:22.698214 35684 trainer.py:136] Epoch[477/1000] loss: 0.12053493991241616
I0424 14:56:28.908978 35684 trainer.py:136] Epoch[478/1000] loss: 0.12100441172971564
I0424 14:56:35.289928 35684 trainer.py:136] Epoch[479/1000] loss: 0.12001255091469167
I0424 14:56:41.520366 35684 trainer.py:136] Epoch[480/1000] loss: 0.12045675591897156
I0424 14:56:47.788032 35684 trainer.py:136] Epoch[481/1000] loss: 0.11990542899248964
I0424 14:56:54.192591 35684 trainer.py:136] Epoch[482/1000] loss: 0.12045422133247731
I0424 14:57:00.541431 35684 trainer.py:136] Epoch[483/1000] loss: 0.11989703799708415
I0424 14:57:06.881164 35684 trainer.py:136] Epoch[484/1000] loss: 0.11983517342704837
I0424 14:57:13.395568 35684 trainer.py:136] Epoch[485/1000] loss: 0.1193570067821923
I0424 14:57:19.759694 35684 trainer.py:136] Epoch[486/1000] loss: 0.11911237252465749
I0424 14:57:25.988546 35684 trainer.py:136] Epoch[487/1000] loss: 0.11965366351907536
I0424 14:57:32.201624 35684 trainer.py:136] Epoch[488/1000] loss: 0.11937925800428552
I0424 14:57:38.554981 35684 trainer.py:136] Epoch[489/1000] loss: 0.11962012504622088
I0424 14:57:44.823731 35684 trainer.py:136] Epoch[490/1000] loss: 0.11992336632841724
I0424 14:57:50.913555 35684 trainer.py:136] Epoch[491/1000] loss: 0.11986519093230619
I0424 14:57:57.133953 35684 trainer.py:136] Epoch[492/1000] loss: 0.12041440972332228
I0424 14:58:03.553865 35684 trainer.py:136] Epoch[493/1000] loss: 0.11975200663683779
I0424 14:58:10.156353 35684 trainer.py:136] Epoch[494/1000] loss: 0.12014500620001453
I0424 14:58:17.021770 35684 trainer.py:136] Epoch[495/1000] loss: 0.1200506007772381
I0424 14:58:23.375657 35684 trainer.py:136] Epoch[496/1000] loss: 0.1195864904735048
I0424 14:58:29.436443 35684 trainer.py:136] Epoch[497/1000] loss: 0.11959619479159177
I0424 14:58:35.704902 35684 trainer.py:136] Epoch[498/1000] loss: 0.11956677750005561
I0424 14:58:41.995382 35684 trainer.py:136] Epoch[499/1000] loss: 0.1193057358012361
I0424 14:58:43.383865 35684 trainer.py:142] Test: [{'precision': 0.017082383124287333, 'recall': 0.08207000245734186, 'hit_ratio': 0.23360889395667048, 'ndcg': 0.05375472923087191}]
I0424 14:58:49.629704 35684 trainer.py:136] Epoch[500/1000] loss: 0.11960490174212698
I0424 14:58:55.878585 35684 trainer.py:136] Epoch[501/1000] loss: 0.11963024141929918
I0424 14:59:02.095211 35684 trainer.py:136] Epoch[502/1000] loss: 0.1194651046041715
I0424 14:59:08.148550 35684 trainer.py:136] Epoch[503/1000] loss: 0.12034718515509266
I0424 14:59:14.379621 35684 trainer.py:136] Epoch[504/1000] loss: 0.12019359282517837
I0424 14:59:20.568586 35684 trainer.py:136] Epoch[505/1000] loss: 0.11969448764950542
I0424 14:59:26.763294 35684 trainer.py:136] Epoch[506/1000] loss: 0.11975548252210778
I0424 14:59:32.928084 35684 trainer.py:136] Epoch[507/1000] loss: 0.11899858713150024
I0424 14:59:39.246896 35684 trainer.py:136] Epoch[508/1000] loss: 0.12037321672601214
I0424 14:59:45.340135 35684 trainer.py:136] Epoch[509/1000] loss: 0.11981030338901584
I0424 14:59:51.441846 35684 trainer.py:136] Epoch[510/1000] loss: 0.12020941735324213
I0424 14:59:57.412394 35684 trainer.py:136] Epoch[511/1000] loss: 0.11992204618656029
I0424 15:00:03.993785 35684 trainer.py:136] Epoch[512/1000] loss: 0.12039163026769283
I0424 15:00:10.197628 35684 trainer.py:136] Epoch[513/1000] loss: 0.12031951723462445
I0424 15:00:16.739087 35684 trainer.py:136] Epoch[514/1000] loss: 0.11950824397095179
I0424 15:00:22.848142 35684 trainer.py:136] Epoch[515/1000] loss: 0.11929509195230775
I0424 15:00:29.313980 35684 trainer.py:136] Epoch[516/1000] loss: 0.11998605513471668
I0424 15:00:35.339397 35684 trainer.py:136] Epoch[517/1000] loss: 0.11982074556714398
I0424 15:00:41.579502 35684 trainer.py:136] Epoch[518/1000] loss: 0.11981205048702531
I0424 15:00:47.944367 35684 trainer.py:136] Epoch[519/1000] loss: 0.1188382569511058
I0424 15:00:54.191431 35684 trainer.py:136] Epoch[520/1000] loss: 0.11911924284393505
I0424 15:01:00.561379 35684 trainer.py:136] Epoch[521/1000] loss: 0.11962150365619337
I0424 15:01:06.999365 35684 trainer.py:136] Epoch[522/1000] loss: 0.12031895894620379
I0424 15:01:13.576907 35684 trainer.py:136] Epoch[523/1000] loss: 0.11905638355824907
I0424 15:01:20.077612 35684 trainer.py:136] Epoch[524/1000] loss: 0.12001962543038999
I0424 15:01:26.619667 35684 trainer.py:136] Epoch[525/1000] loss: 0.11948033889471474
I0424 15:01:32.951550 35684 trainer.py:136] Epoch[526/1000] loss: 0.11962517502449327
I0424 15:01:39.576340 35684 trainer.py:136] Epoch[527/1000] loss: 0.11991470332367946
I0424 15:01:46.059172 35684 trainer.py:136] Epoch[528/1000] loss: 0.12022341964608532
I0424 15:01:52.481366 35684 trainer.py:136] Epoch[529/1000] loss: 0.12029945294735796
I0424 15:01:58.750789 35684 trainer.py:136] Epoch[530/1000] loss: 0.11919817770436658
I0424 15:02:05.174720 35684 trainer.py:136] Epoch[531/1000] loss: 0.11968991425582919
I0424 15:02:11.599155 35684 trainer.py:136] Epoch[532/1000] loss: 0.1209291267698094
I0424 15:02:17.977979 35684 trainer.py:136] Epoch[533/1000] loss: 0.11930269508038537
I0424 15:02:24.147567 35684 trainer.py:136] Epoch[534/1000] loss: 0.12066161544141123
I0424 15:02:30.526990 35684 trainer.py:136] Epoch[535/1000] loss: 0.12076819031420401
I0424 15:02:36.800167 35684 trainer.py:136] Epoch[536/1000] loss: 0.11979936922000627
I0424 15:02:43.081327 35684 trainer.py:136] Epoch[537/1000] loss: 0.12004544598571325
I0424 15:02:49.478997 35684 trainer.py:136] Epoch[538/1000] loss: 0.11931632509676077
I0424 15:02:55.822520 35684 trainer.py:136] Epoch[539/1000] loss: 0.11906214361473666
I0424 15:03:02.049414 35684 trainer.py:136] Epoch[540/1000] loss: 0.11884654793193784
I0424 15:03:08.323446 35684 trainer.py:136] Epoch[541/1000] loss: 0.1189566032361176
I0424 15:03:14.548581 35684 trainer.py:136] Epoch[542/1000] loss: 0.11985877787662765
I0424 15:03:21.000483 35684 trainer.py:136] Epoch[543/1000] loss: 0.11951911752506839
I0424 15:03:27.816917 35684 trainer.py:136] Epoch[544/1000] loss: 0.12008917937844486
I0424 15:03:34.048790 35684 trainer.py:136] Epoch[545/1000] loss: 0.12024904598118895
I0424 15:03:40.277352 35684 trainer.py:136] Epoch[546/1000] loss: 0.11940466663089849
I0424 15:03:46.667363 35684 trainer.py:136] Epoch[547/1000] loss: 0.12084133645235481
I0424 15:03:53.111297 35684 trainer.py:136] Epoch[548/1000] loss: 0.11828955717511096
I0424 15:03:59.443323 35684 trainer.py:136] Epoch[549/1000] loss: 0.11966538744962822
I0424 15:04:00.877914 35684 trainer.py:142] Test: [{'precision': 0.01706100342075256, 'recall': 0.08149134722844109, 'hit_ratio': 0.23332383124287343, 'ndcg': 0.053875202538530606}]
I0424 15:04:07.120480 35684 trainer.py:136] Epoch[550/1000] loss: 0.12065173988625155
I0424 15:04:13.404835 35684 trainer.py:136] Epoch[551/1000] loss: 0.11989001071048995
I0424 15:04:27.428677 35684 trainer.py:136] Epoch[552/1000] loss: 0.11973347338074344
I0424 15:04:42.966948 35684 trainer.py:136] Epoch[553/1000] loss: 0.11948485445168058
I0424 15:04:58.566709 35684 trainer.py:136] Epoch[554/1000] loss: 0.11862450737064167
I0424 15:05:13.987676 35684 trainer.py:136] Epoch[555/1000] loss: 0.11964078096009917
I0424 15:05:29.634654 35684 trainer.py:136] Epoch[556/1000] loss: 0.11955724770234803
I0424 15:05:44.988519 35684 trainer.py:136] Epoch[557/1000] loss: 0.12024108901367349
I0424 15:06:00.604354 35684 trainer.py:136] Epoch[558/1000] loss: 0.11926843743708174
I0424 15:06:16.082055 35684 trainer.py:136] Epoch[559/1000] loss: 0.11975508688364998
I0424 15:06:31.678177 35684 trainer.py:136] Epoch[560/1000] loss: 0.11904014179767189
I0424 15:06:47.133621 35684 trainer.py:136] Epoch[561/1000] loss: 0.11836805005194777
I0424 15:07:02.538180 35684 trainer.py:136] Epoch[562/1000] loss: 0.11878807729078551
I0424 15:07:18.201309 35684 trainer.py:136] Epoch[563/1000] loss: 0.11964565212443723
I0424 15:07:33.573641 35684 trainer.py:136] Epoch[564/1000] loss: 0.12073409734135968
I0424 15:07:49.184116 35684 trainer.py:136] Epoch[565/1000] loss: 0.11983249841605202
I0424 15:08:04.601561 35684 trainer.py:136] Epoch[566/1000] loss: 0.11913802260059421
I0424 15:08:19.932786 35684 trainer.py:136] Epoch[567/1000] loss: 0.11910577118396759
I0424 15:08:35.529736 35684 trainer.py:136] Epoch[568/1000] loss: 0.11879740668050313
I0424 15:08:51.206989 35684 trainer.py:136] Epoch[569/1000] loss: 0.11969046597763644
I0424 15:09:06.656907 35684 trainer.py:136] Epoch[570/1000] loss: 0.12007495129512528
I0424 15:09:22.286736 35684 trainer.py:136] Epoch[571/1000] loss: 0.12012114880953804
I0424 15:09:38.264857 35684 trainer.py:136] Epoch[572/1000] loss: 0.11941301658497018
I0424 15:09:53.952383 35684 trainer.py:136] Epoch[573/1000] loss: 0.12000777231434644
I0424 15:10:09.518041 35684 trainer.py:136] Epoch[574/1000] loss: 0.11917823527829122
I0424 15:10:25.591380 35684 trainer.py:136] Epoch[575/1000] loss: 0.11947864521357973
I0424 15:10:36.625895 35684 trainer.py:136] Epoch[576/1000] loss: 0.1197252916329998
I0424 15:10:42.968740 35684 trainer.py:136] Epoch[577/1000] loss: 0.11846702091269574
I0424 15:10:49.311691 35684 trainer.py:136] Epoch[578/1000] loss: 0.12014118051629956
I0424 15:10:55.813804 35684 trainer.py:136] Epoch[579/1000] loss: 0.11859764954296209
I0424 15:11:02.092777 35684 trainer.py:136] Epoch[580/1000] loss: 0.11988123670472937
I0424 15:11:08.484150 35684 trainer.py:136] Epoch[581/1000] loss: 0.11949912130327547
I0424 15:11:14.657471 35684 trainer.py:136] Epoch[582/1000] loss: 0.11905156656847161
I0424 15:11:21.024880 35684 trainer.py:136] Epoch[583/1000] loss: 0.11968550881591894
I0424 15:11:27.165515 35684 trainer.py:136] Epoch[584/1000] loss: 0.11955007519257271
I0424 15:11:33.591000 35684 trainer.py:136] Epoch[585/1000] loss: 0.12007862923003859
I0424 15:11:39.911243 35684 trainer.py:136] Epoch[586/1000] loss: 0.1195666603112625
I0424 15:11:46.543943 35684 trainer.py:136] Epoch[587/1000] loss: 0.11965815230446347
I0424 15:11:52.938700 35684 trainer.py:136] Epoch[588/1000] loss: 0.11905905515965769
I0424 15:11:59.290599 35684 trainer.py:136] Epoch[589/1000] loss: 0.11946555353322272
I0424 15:12:05.673668 35684 trainer.py:136] Epoch[590/1000] loss: 0.1195446065926956
I0424 15:12:12.146397 35684 trainer.py:136] Epoch[591/1000] loss: 0.11950392149767633
I0424 15:12:18.542805 35684 trainer.py:136] Epoch[592/1000] loss: 0.11915521601499138
I0424 15:12:24.983479 35684 trainer.py:136] Epoch[593/1000] loss: 0.11973105724585259
I0424 15:12:31.208507 35684 trainer.py:136] Epoch[594/1000] loss: 0.11882963069414688
I0424 15:12:37.298884 35684 trainer.py:136] Epoch[595/1000] loss: 0.119939461476722
I0424 15:12:43.861948 35684 trainer.py:136] Epoch[596/1000] loss: 0.11959234031580263
I0424 15:12:50.124170 35684 trainer.py:136] Epoch[597/1000] loss: 0.1187986018041433
I0424 15:12:56.280991 35684 trainer.py:136] Epoch[598/1000] loss: 0.11988794879388001
I0424 15:13:03.021349 35684 trainer.py:136] Epoch[599/1000] loss: 0.11965641152050535
I0424 15:13:04.474720 35684 trainer.py:142] Test: [{'precision': 0.017146522234891663, 'recall': 0.08227054251166789, 'hit_ratio': 0.2347491448118586, 'ndcg': 0.0538167578425483}]
I0424 15:13:10.899324 35684 trainer.py:136] Epoch[600/1000] loss: 0.11878037894681348
I0424 15:13:17.450021 35684 trainer.py:136] Epoch[601/1000] loss: 0.11926831949060246
I0424 15:13:23.807197 35684 trainer.py:136] Epoch[602/1000] loss: 0.11916357708179344
I0424 15:13:30.385318 35684 trainer.py:136] Epoch[603/1000] loss: 0.11967904044915054
I0424 15:13:36.593618 35684 trainer.py:136] Epoch[604/1000] loss: 0.11966862415863296
I0424 15:13:43.143538 35684 trainer.py:136] Epoch[605/1000] loss: 0.1200457210257902
I0424 15:13:49.572082 35684 trainer.py:136] Epoch[606/1000] loss: 0.11967811897649604
I0424 15:13:55.821582 35684 trainer.py:136] Epoch[607/1000] loss: 0.11835255511736466
I0424 15:14:02.020993 35684 trainer.py:136] Epoch[608/1000] loss: 0.11965657480187335
I0424 15:14:08.341289 35684 trainer.py:136] Epoch[609/1000] loss: 0.11921977479073961
I0424 15:14:14.745889 35684 trainer.py:136] Epoch[610/1000] loss: 0.11972840471287906
I0424 15:14:21.075663 35684 trainer.py:136] Epoch[611/1000] loss: 0.11976745270066343
I0424 15:14:27.304619 35684 trainer.py:136] Epoch[612/1000] loss: 0.11985292664523851
I0424 15:14:33.541575 35684 trainer.py:136] Epoch[613/1000] loss: 0.11881236163741452
I0424 15:14:40.129302 35684 trainer.py:136] Epoch[614/1000] loss: 0.12016636373127922
I0424 15:14:46.560326 35684 trainer.py:136] Epoch[615/1000] loss: 0.11919553236941159
I0424 15:14:52.791234 35684 trainer.py:136] Epoch[616/1000] loss: 0.11906548033831484
I0424 15:14:59.094056 35684 trainer.py:136] Epoch[617/1000] loss: 0.12037065031669908
I0424 15:15:05.437566 35684 trainer.py:136] Epoch[618/1000] loss: 0.11942446989528203
I0424 15:15:11.721042 35684 trainer.py:136] Epoch[619/1000] loss: 0.11956576018010155
I0424 15:15:22.372424 35684 trainer.py:136] Epoch[620/1000] loss: 0.11881984214661485
I0424 15:15:38.034636 35684 trainer.py:136] Epoch[621/1000] loss: 0.11982133454185422
I0424 15:15:53.761619 35684 trainer.py:136] Epoch[622/1000] loss: 0.11967367451574842
I0424 15:16:09.321661 35684 trainer.py:136] Epoch[623/1000] loss: 0.11912218607583289
I0424 15:16:24.993545 35684 trainer.py:136] Epoch[624/1000] loss: 0.11922502037832293
I0424 15:16:40.775395 35684 trainer.py:136] Epoch[625/1000] loss: 0.11922877382929042
I0424 15:16:56.263667 35684 trainer.py:136] Epoch[626/1000] loss: 0.11872714164398485
I0424 15:17:11.829274 35684 trainer.py:136] Epoch[627/1000] loss: 0.11914520117185884
I0424 15:17:27.143996 35684 trainer.py:136] Epoch[628/1000] loss: 0.11949333510661529
I0424 15:17:42.796732 35684 trainer.py:136] Epoch[629/1000] loss: 0.12001627986713992
I0424 15:17:58.571824 35684 trainer.py:136] Epoch[630/1000] loss: 0.11900429326598927
I0424 15:18:14.395985 35684 trainer.py:136] Epoch[631/1000] loss: 0.11917581724918495
I0424 15:18:30.033365 35684 trainer.py:136] Epoch[632/1000] loss: 0.11966036916789362
I0424 15:18:45.953550 35684 trainer.py:136] Epoch[633/1000] loss: 0.11905457609790866
I0424 15:19:02.112459 35684 trainer.py:136] Epoch[634/1000] loss: 0.11908276694810997
I0424 15:19:18.164744 35684 trainer.py:136] Epoch[635/1000] loss: 0.11949317952838995
I0424 15:19:33.664750 35684 trainer.py:136] Epoch[636/1000] loss: 0.11977353022765305
I0424 15:19:49.250352 35684 trainer.py:136] Epoch[637/1000] loss: 0.11977721447661771
I0424 15:20:05.196352 35684 trainer.py:136] Epoch[638/1000] loss: 0.11866123191380905
I0424 15:20:20.515964 35684 trainer.py:136] Epoch[639/1000] loss: 0.11893011099201138
I0424 15:20:36.283431 35684 trainer.py:136] Epoch[640/1000] loss: 0.11892300137018753
I0424 15:20:52.183171 35684 trainer.py:136] Epoch[641/1000] loss: 0.11974274013507163
I0424 15:21:07.835375 35684 trainer.py:136] Epoch[642/1000] loss: 0.1188586493164806
I0424 15:21:23.523462 35684 trainer.py:136] Epoch[643/1000] loss: 0.11921471685676252
I0424 15:21:39.272539 35684 trainer.py:136] Epoch[644/1000] loss: 0.11924704164266586
I0424 15:21:54.860351 35684 trainer.py:136] Epoch[645/1000] loss: 0.11813249704191241
I0424 15:22:10.677452 35684 trainer.py:136] Epoch[646/1000] loss: 0.11986583004058418
I0424 15:22:26.283748 35684 trainer.py:136] Epoch[647/1000] loss: 0.11824400419906034
I0424 15:22:41.874342 35684 trainer.py:136] Epoch[648/1000] loss: 0.11916996462870452
I0424 15:22:57.466989 35684 trainer.py:136] Epoch[649/1000] loss: 0.1191371160291009
I0424 15:23:00.155678 35684 trainer.py:142] Test: [{'precision': 0.017146522234891663, 'recall': 0.08176361577956026, 'hit_ratio': 0.233751425313569, 'ndcg': 0.05391911190415304}]
I0424 15:23:15.787067 35684 trainer.py:136] Epoch[650/1000] loss: 0.11894138990822485
I0424 15:23:31.691973 35684 trainer.py:136] Epoch[651/1000] loss: 0.11896314964456073
I0424 15:23:47.722475 35684 trainer.py:136] Epoch[652/1000] loss: 0.11931280905412416
I0424 15:24:03.331910 35684 trainer.py:136] Epoch[653/1000] loss: 0.11916255736249988
I0424 15:24:19.085384 35684 trainer.py:136] Epoch[654/1000] loss: 0.11942624932123443
I0424 15:24:34.576357 35684 trainer.py:136] Epoch[655/1000] loss: 0.11942971838732898
I0424 15:24:50.127797 35684 trainer.py:136] Epoch[656/1000] loss: 0.11897542264501927
I0424 15:25:05.711873 35684 trainer.py:136] Epoch[657/1000] loss: 0.11953927841732058
I0424 15:25:21.946977 35684 trainer.py:136] Epoch[658/1000] loss: 0.11956662343720258
I0424 15:25:37.437702 35684 trainer.py:136] Epoch[659/1000] loss: 0.11905433540627108
I0424 15:25:53.148514 35684 trainer.py:136] Epoch[660/1000] loss: 0.1194317503753355
I0424 15:26:09.389005 35684 trainer.py:136] Epoch[661/1000] loss: 0.11956368134183398
I0424 15:26:23.247275 35684 trainer.py:136] Epoch[662/1000] loss: 0.11931164209115303
I0424 15:26:29.573856 35684 trainer.py:136] Epoch[663/1000] loss: 0.1184028544920986
I0424 15:26:36.119087 35684 trainer.py:136] Epoch[664/1000] loss: 0.11893292541726161
I0424 15:26:42.359394 35684 trainer.py:136] Epoch[665/1000] loss: 0.11929568244239032
I0424 15:26:48.638144 35684 trainer.py:136] Epoch[666/1000] loss: 0.11889637034323255
I0424 15:26:54.875190 35684 trainer.py:136] Epoch[667/1000] loss: 0.11884245175426289
I0424 15:27:00.954009 35684 trainer.py:136] Epoch[668/1000] loss: 0.11837599249714512
I0424 15:27:07.076006 35684 trainer.py:136] Epoch[669/1000] loss: 0.11863242203401307
I0424 15:27:13.168432 35684 trainer.py:136] Epoch[670/1000] loss: 0.11921265847602133
I0424 15:27:19.374788 35684 trainer.py:136] Epoch[671/1000] loss: 0.1208362714466402
I0424 15:27:25.435160 35684 trainer.py:136] Epoch[672/1000] loss: 0.11893807932481927
I0424 15:27:31.478887 35684 trainer.py:136] Epoch[673/1000] loss: 0.11923071249561795
I0424 15:27:37.656866 35684 trainer.py:136] Epoch[674/1000] loss: 0.11887158301927275
I0424 15:27:43.827662 35684 trainer.py:136] Epoch[675/1000] loss: 0.11931004754062426
I0424 15:27:50.291253 35684 trainer.py:136] Epoch[676/1000] loss: 0.11824937442601738
I0424 15:27:56.625058 35684 trainer.py:136] Epoch[677/1000] loss: 0.11847263372550576
I0424 15:28:03.159112 35684 trainer.py:136] Epoch[678/1000] loss: 0.11856567064079188
I0424 15:28:09.579275 35684 trainer.py:136] Epoch[679/1000] loss: 0.119483890548601
I0424 15:28:15.847751 35684 trainer.py:136] Epoch[680/1000] loss: 0.11944436041985527
I0424 15:28:22.106669 35684 trainer.py:136] Epoch[681/1000] loss: 0.11853111244864382
I0424 15:28:28.465628 35684 trainer.py:136] Epoch[682/1000] loss: 0.11842715790716268
I0424 15:28:34.708394 35684 trainer.py:136] Epoch[683/1000] loss: 0.11948047553078603
I0424 15:28:41.068540 35684 trainer.py:136] Epoch[684/1000] loss: 0.11885506419812218
I0424 15:28:47.337901 35684 trainer.py:136] Epoch[685/1000] loss: 0.11866263868445057
I0424 15:28:53.676262 35684 trainer.py:136] Epoch[686/1000] loss: 0.11925214440640756
I0424 15:29:00.173792 35684 trainer.py:136] Epoch[687/1000] loss: 0.11859260057493792
I0424 15:29:06.589625 35684 trainer.py:136] Epoch[688/1000] loss: 0.11940509396589409
I0424 15:29:12.866433 35684 trainer.py:136] Epoch[689/1000] loss: 0.11884887276564614
I0424 15:29:19.407052 35684 trainer.py:136] Epoch[690/1000] loss: 0.11838263412148266
I0424 15:29:25.524012 35684 trainer.py:136] Epoch[691/1000] loss: 0.11855144596706002
I0424 15:29:31.792742 35684 trainer.py:136] Epoch[692/1000] loss: 0.1186690997269194
I0424 15:29:37.885106 35684 trainer.py:136] Epoch[693/1000] loss: 0.11922705173492432
I0424 15:29:44.190353 35684 trainer.py:136] Epoch[694/1000] loss: 0.11891561797109701
I0424 15:29:50.196413 35684 trainer.py:136] Epoch[695/1000] loss: 0.11840415493411532
I0424 15:29:56.403367 35684 trainer.py:136] Epoch[696/1000] loss: 0.12001366016723342
I0424 15:30:02.767747 35684 trainer.py:136] Epoch[697/1000] loss: 0.11816923459202557
I0424 15:30:09.021482 35684 trainer.py:136] Epoch[698/1000] loss: 0.11850485761286848
I0424 15:30:15.181214 35684 trainer.py:136] Epoch[699/1000] loss: 0.11898601421360243
I0424 15:30:16.735796 35684 trainer.py:142] Test: [{'precision': 0.01717502850627137, 'recall': 0.0818083483930257, 'hit_ratio': 0.23531927023945268, 'ndcg': 0.053827781332556356}]
I0424 15:30:22.934966 35684 trainer.py:136] Epoch[700/1000] loss: 0.11943718601586455
I0424 15:30:29.170256 35684 trainer.py:136] Epoch[701/1000] loss: 0.11886641294774362
I0424 15:30:35.331292 35684 trainer.py:136] Epoch[702/1000] loss: 0.11883914723234662
I0424 15:30:41.493832 35684 trainer.py:136] Epoch[703/1000] loss: 0.12009217741630845
I0424 15:30:47.521360 35684 trainer.py:136] Epoch[704/1000] loss: 0.11872862014224973
I0424 15:30:53.665760 35684 trainer.py:136] Epoch[705/1000] loss: 0.11816094878871562
I0424 15:30:59.794723 35684 trainer.py:136] Epoch[706/1000] loss: 0.11971827697450832
I0424 15:31:05.861241 35684 trainer.py:136] Epoch[707/1000] loss: 0.11860202808501356
I0424 15:31:12.030213 35684 trainer.py:136] Epoch[708/1000] loss: 0.118944054690458
I0424 15:31:18.093177 35684 trainer.py:136] Epoch[709/1000] loss: 0.11912789650387683
I0424 15:31:24.387930 35684 trainer.py:136] Epoch[710/1000] loss: 0.11904495904001139
I0424 15:31:30.494467 35684 trainer.py:136] Epoch[711/1000] loss: 0.119184868694362
I0424 15:31:36.762069 35684 trainer.py:136] Epoch[712/1000] loss: 0.11835779211783813
I0424 15:31:43.054076 35684 trainer.py:136] Epoch[713/1000] loss: 0.12002361527944015
I0424 15:31:49.178508 35684 trainer.py:136] Epoch[714/1000] loss: 0.1198362858366158
I0424 15:31:55.124373 35684 trainer.py:136] Epoch[715/1000] loss: 0.11878619507207709
I0424 15:32:01.395384 35684 trainer.py:136] Epoch[716/1000] loss: 0.11866994113740274
I0424 15:32:07.736214 35684 trainer.py:136] Epoch[717/1000] loss: 0.11876696954339237
I0424 15:32:13.933828 35684 trainer.py:136] Epoch[718/1000] loss: 0.11859091598603685
I0424 15:32:20.087915 35684 trainer.py:136] Epoch[719/1000] loss: 0.11969445153313168
I0424 15:32:26.358246 35684 trainer.py:136] Epoch[720/1000] loss: 0.11942764359005427
I0424 15:32:32.635822 35684 trainer.py:136] Epoch[721/1000] loss: 0.11862422121783435
I0424 15:32:38.934772 35684 trainer.py:136] Epoch[722/1000] loss: 0.11890965498099892
I0424 15:32:45.182936 35684 trainer.py:136] Epoch[723/1000] loss: 0.11855338261289111
I0424 15:32:51.419596 35684 trainer.py:136] Epoch[724/1000] loss: 0.11868001886848677
I0424 15:32:57.672471 35684 trainer.py:136] Epoch[725/1000] loss: 0.11981741793579974
I0424 15:33:03.860358 35684 trainer.py:136] Epoch[726/1000] loss: 0.11870911212290748
I0424 15:33:10.089471 35684 trainer.py:136] Epoch[727/1000] loss: 0.11879964261236838
I0424 15:33:16.350815 35684 trainer.py:136] Epoch[728/1000] loss: 0.11941506195876558
I0424 15:33:22.623413 35684 trainer.py:136] Epoch[729/1000] loss: 0.11821253319918099
I0424 15:33:28.861280 35684 trainer.py:136] Epoch[730/1000] loss: 0.11867364849579537
I0424 15:33:34.976803 35684 trainer.py:136] Epoch[731/1000] loss: 0.11954814334542065
I0424 15:33:41.110626 35684 trainer.py:136] Epoch[732/1000] loss: 0.11906454813177303
I0424 15:33:47.161650 35684 trainer.py:136] Epoch[733/1000] loss: 0.11866780799829353
I0424 15:33:53.302293 35684 trainer.py:136] Epoch[734/1000] loss: 0.1183954012596001
I0424 15:33:59.318480 35684 trainer.py:136] Epoch[735/1000] loss: 0.11904448447591168
I0424 15:34:05.874816 35684 trainer.py:136] Epoch[736/1000] loss: 0.11889028094582639
I0424 15:34:12.028822 35684 trainer.py:136] Epoch[737/1000] loss: 0.11878319930727199
I0424 15:34:18.372081 35684 trainer.py:136] Epoch[738/1000] loss: 0.1183317239254208
I0424 15:34:24.560645 35684 trainer.py:136] Epoch[739/1000] loss: 0.11925587676844354
I0424 15:34:30.750918 35684 trainer.py:136] Epoch[740/1000] loss: 0.11945031696962098
I0424 15:34:36.914524 35684 trainer.py:136] Epoch[741/1000] loss: 0.11869362261840853
I0424 15:34:43.109004 35684 trainer.py:136] Epoch[742/1000] loss: 0.11804471152313685
I0424 15:34:49.254628 35684 trainer.py:136] Epoch[743/1000] loss: 0.1192717208700665
I0424 15:34:55.557671 35684 trainer.py:136] Epoch[744/1000] loss: 0.11885316291097868
I0424 15:35:01.735096 35684 trainer.py:136] Epoch[745/1000] loss: 0.11975651891049692
I0424 15:35:07.985895 35684 trainer.py:136] Epoch[746/1000] loss: 0.11887557627791065
I0424 15:35:14.115237 35684 trainer.py:136] Epoch[747/1000] loss: 0.11847354812642276
I0424 15:35:20.358779 35684 trainer.py:136] Epoch[748/1000] loss: 0.11858823087255833
I0424 15:35:26.503464 35684 trainer.py:136] Epoch[749/1000] loss: 0.11876835863469011
I0424 15:35:28.067467 35684 trainer.py:142] Test: [{'precision': 0.017203534777651068, 'recall': 0.08202320910441024, 'hit_ratio': 0.2346066134549601, 'ndcg': 0.05433317508772399}]
I0424 15:35:34.356512 35684 trainer.py:136] Epoch[750/1000] loss: 0.119792098968716
I0424 15:35:40.586633 35684 trainer.py:136] Epoch[751/1000] loss: 0.11925506440259642
I0424 15:35:46.758226 35684 trainer.py:136] Epoch[752/1000] loss: 0.11849156135724763
I0424 15:35:52.852939 35684 trainer.py:136] Epoch[753/1000] loss: 0.11871271226870811
I0424 15:35:59.179745 35684 trainer.py:136] Epoch[754/1000] loss: 0.11859233147006924
I0424 15:36:05.490486 35684 trainer.py:136] Epoch[755/1000] loss: 0.11853690382282613
I0424 15:36:11.760871 35684 trainer.py:136] Epoch[756/1000] loss: 0.11774808774560185
I0424 15:36:17.850123 35684 trainer.py:136] Epoch[757/1000] loss: 0.11908239997544531
I0424 15:36:24.039114 35684 trainer.py:136] Epoch[758/1000] loss: 0.11907649646371098
I0424 15:36:30.248826 35684 trainer.py:136] Epoch[759/1000] loss: 0.11925869157253685
I0424 15:36:36.502144 35684 trainer.py:136] Epoch[760/1000] loss: 0.11947449233572362
I0424 15:36:42.708762 35684 trainer.py:136] Epoch[761/1000] loss: 0.11855378885895519
I0424 15:36:49.026074 35684 trainer.py:136] Epoch[762/1000] loss: 0.1179900899276895
I0424 15:36:55.170377 35684 trainer.py:136] Epoch[763/1000] loss: 0.11988518134517184
I0424 15:37:01.455677 35684 trainer.py:136] Epoch[764/1000] loss: 0.11881850861896903
I0424 15:37:07.791544 35684 trainer.py:136] Epoch[765/1000] loss: 0.11864890271829347
I0424 15:37:13.876854 35684 trainer.py:136] Epoch[766/1000] loss: 0.11978935159869113
I0424 15:37:20.253784 35684 trainer.py:136] Epoch[767/1000] loss: 0.11909283369274462
I0424 15:37:26.514868 35684 trainer.py:136] Epoch[768/1000] loss: 0.11981011434631833
I0424 15:37:32.746097 35684 trainer.py:136] Epoch[769/1000] loss: 0.11900944995172953
I0424 15:37:38.865495 35684 trainer.py:136] Epoch[770/1000] loss: 0.11902720948397102
I0424 15:37:45.207219 35684 trainer.py:136] Epoch[771/1000] loss: 0.11822869628667831
I0424 15:37:51.347841 35684 trainer.py:136] Epoch[772/1000] loss: 0.118832855153892
I0424 15:37:57.510387 35684 trainer.py:136] Epoch[773/1000] loss: 0.1191224255046602
I0424 15:38:03.642375 35684 trainer.py:136] Epoch[774/1000] loss: 0.11922775486768303
I0424 15:38:09.872771 35684 trainer.py:136] Epoch[775/1000] loss: 0.11868948060072075
I0424 15:38:16.114689 35684 trainer.py:136] Epoch[776/1000] loss: 0.118931499578185
I0424 15:38:22.191135 35684 trainer.py:136] Epoch[777/1000] loss: 0.11816128987376973
I0424 15:38:28.270523 35684 trainer.py:136] Epoch[778/1000] loss: 0.1183008354599193
I0424 15:38:34.347082 35684 trainer.py:136] Epoch[779/1000] loss: 0.11856578719817985
I0424 15:38:40.501296 35684 trainer.py:136] Epoch[780/1000] loss: 0.11892995692915835
I0424 15:38:46.618097 35684 trainer.py:136] Epoch[781/1000] loss: 0.11796859285588991
I0424 15:38:52.689048 35684 trainer.py:136] Epoch[782/1000] loss: 0.11836284626338442
I0424 15:38:58.878871 35684 trainer.py:136] Epoch[783/1000] loss: 0.11920888721942902
I0424 15:39:04.959393 35684 trainer.py:136] Epoch[784/1000] loss: 0.11868824506715192
I0424 15:39:11.091697 35684 trainer.py:136] Epoch[785/1000] loss: 0.11992541511180037
I0424 15:39:17.239767 35684 trainer.py:136] Epoch[786/1000] loss: 0.11807488107075126
I0424 15:39:23.331995 35684 trainer.py:136] Epoch[787/1000] loss: 0.11924021438521853
I0424 15:39:29.651279 35684 trainer.py:136] Epoch[788/1000] loss: 0.12001088185835693
I0424 15:39:35.796273 35684 trainer.py:136] Epoch[789/1000] loss: 0.11927774725324017
I0424 15:39:41.783125 35684 trainer.py:136] Epoch[790/1000] loss: 0.11949677083451869
I0424 15:39:47.872149 35684 trainer.py:136] Epoch[791/1000] loss: 0.1194849025647519
I0424 15:39:54.003710 35684 trainer.py:136] Epoch[792/1000] loss: 0.11901499419394186
I0424 15:40:00.177540 35684 trainer.py:136] Epoch[793/1000] loss: 0.11946807814351583
I0424 15:40:06.296565 35684 trainer.py:136] Epoch[794/1000] loss: 0.11861802195593463
I0424 15:40:12.656236 35684 trainer.py:136] Epoch[795/1000] loss: 0.11873154847298638
I0424 15:40:18.699402 35684 trainer.py:136] Epoch[796/1000] loss: 0.11920052375328744
I0424 15:40:25.001113 35684 trainer.py:136] Epoch[797/1000] loss: 0.11955822170790979
I0424 15:40:31.240714 35684 trainer.py:136] Epoch[798/1000] loss: 0.11848418098890175
I0424 15:40:37.413094 35684 trainer.py:136] Epoch[799/1000] loss: 0.11901237626196974
I0424 15:40:38.795042 35684 trainer.py:142] Test: [{'precision': 0.017146522234891663, 'recall': 0.08344569798791103, 'hit_ratio': 0.24446408209806158, 'ndcg': 0.05729174719209034}]
I0424 15:40:45.004370 35684 trainer.py:136] Epoch[800/1000] loss: 0.11969297758098375
I0424 15:40:51.183727 35684 trainer.py:136] Epoch[801/1000] loss: 0.11898991061469257
I0424 15:40:57.462694 35684 trainer.py:136] Epoch[802/1000] loss: 0.11816411654827959
I0424 15:41:03.603846 35684 trainer.py:136] Epoch[803/1000] loss: 0.11905638128519058
I0424 15:41:09.687552 35684 trainer.py:136] Epoch[804/1000] loss: 0.11845033817877204
I0424 15:41:15.827618 35684 trainer.py:136] Epoch[805/1000] loss: 0.11884423686286151
I0424 15:41:21.995806 35684 trainer.py:136] Epoch[806/1000] loss: 0.11942230367054374
I0424 15:41:28.151887 35684 trainer.py:136] Epoch[807/1000] loss: 0.11904853355076353
I0424 15:41:34.362341 35684 trainer.py:136] Epoch[808/1000] loss: 0.11918496681472003
I0424 15:41:40.539547 35684 trainer.py:136] Epoch[809/1000] loss: 0.1193845346570015
I0424 15:41:46.689265 35684 trainer.py:136] Epoch[810/1000] loss: 0.11961732400675952
I0424 15:41:52.826875 35684 trainer.py:136] Epoch[811/1000] loss: 0.11863296074887454
I0424 15:41:59.137104 35684 trainer.py:136] Epoch[812/1000] loss: 0.1183885791796749
I0424 15:42:05.374808 35684 trainer.py:136] Epoch[813/1000] loss: 0.11904144463902813
I0424 15:42:11.336474 35684 trainer.py:136] Epoch[814/1000] loss: 0.1187572143340515
I0424 15:42:17.626670 35684 trainer.py:136] Epoch[815/1000] loss: 0.11849825576705447
I0424 15:42:23.770946 35684 trainer.py:136] Epoch[816/1000] loss: 0.11877533162044267
I0424 15:42:29.880761 35684 trainer.py:136] Epoch[817/1000] loss: 0.11841844186439353
I0424 15:42:36.020816 35684 trainer.py:136] Epoch[818/1000] loss: 0.1196223254931175
I0424 15:42:42.230285 35684 trainer.py:136] Epoch[819/1000] loss: 0.1185704641422983
I0424 15:42:48.250067 35684 trainer.py:136] Epoch[820/1000] loss: 0.11857671959925506
I0424 15:42:54.352958 35684 trainer.py:136] Epoch[821/1000] loss: 0.11893148455074277
I0424 15:43:00.398885 35684 trainer.py:136] Epoch[822/1000] loss: 0.11937105744066885
I0424 15:43:06.551924 35684 trainer.py:136] Epoch[823/1000] loss: 0.11828488995463161
I0424 15:43:12.700897 35684 trainer.py:136] Epoch[824/1000] loss: 0.11865916456711495
I0424 15:43:18.899744 35684 trainer.py:136] Epoch[825/1000] loss: 0.11774224787950516
I0424 15:43:25.006439 35684 trainer.py:136] Epoch[826/1000] loss: 0.11925390665814029
I0424 15:43:31.160325 35684 trainer.py:136] Epoch[827/1000] loss: 0.11931969831555576
I0424 15:43:37.655194 35684 trainer.py:136] Epoch[828/1000] loss: 0.11752757897316399
I0424 15:43:43.861967 35684 trainer.py:136] Epoch[829/1000] loss: 0.11840015624539327
I0424 15:43:49.870686 35684 trainer.py:136] Epoch[830/1000] loss: 0.11797731685436379
I0424 15:43:56.343596 35684 trainer.py:136] Epoch[831/1000] loss: 0.11831922690242024
I0424 15:44:02.742331 35684 trainer.py:136] Epoch[832/1000] loss: 0.11868327792923329
I0424 15:44:08.890365 35684 trainer.py:136] Epoch[833/1000] loss: 0.11849542227336916
I0424 15:44:15.113771 35684 trainer.py:136] Epoch[834/1000] loss: 0.11722101788904707
I0424 15:44:21.493812 35684 trainer.py:136] Epoch[835/1000] loss: 0.1179700959789551
I0424 15:44:27.746510 35684 trainer.py:136] Epoch[836/1000] loss: 0.11826308829299474
I0424 15:44:33.756045 35684 trainer.py:136] Epoch[837/1000] loss: 0.11934880988072541
I0424 15:44:39.774866 35684 trainer.py:136] Epoch[838/1000] loss: 0.11861217388157118
I0424 15:44:45.866230 35684 trainer.py:136] Epoch[839/1000] loss: 0.11830558160604057
I0424 15:44:52.114060 35684 trainer.py:136] Epoch[840/1000] loss: 0.11904087448019092
I0424 15:44:58.283180 35684 trainer.py:136] Epoch[841/1000] loss: 0.11786435418209787
I0424 15:45:04.483159 35684 trainer.py:136] Epoch[842/1000] loss: 0.11797010330325466
I0424 15:45:10.642997 35684 trainer.py:136] Epoch[843/1000] loss: 0.11890656943038358
I0424 15:45:16.830816 35684 trainer.py:136] Epoch[844/1000] loss: 0.11825555032592709
I0424 15:45:22.843780 35684 trainer.py:136] Epoch[845/1000] loss: 0.11788093121880192
I0424 15:45:29.043328 35684 trainer.py:136] Epoch[846/1000] loss: 0.11941207074007745
I0424 15:45:35.344928 35684 trainer.py:136] Epoch[847/1000] loss: 0.11893262310048282
I0424 15:45:41.377705 35684 trainer.py:136] Epoch[848/1000] loss: 0.11865606285252814
I0424 15:45:47.493367 35684 trainer.py:136] Epoch[849/1000] loss: 0.1178840099502418
I0424 15:45:48.872322 35684 trainer.py:142] Test: [{'precision': 0.017125142531356892, 'recall': 0.08581354609137487, 'hit_ratio': 0.2447491448118586, 'ndcg': 0.058123276591354644}]
I0424 15:45:55.094090 35684 trainer.py:136] Epoch[850/1000] loss: 0.11874507089792671
I0424 15:46:01.213527 35684 trainer.py:136] Epoch[851/1000] loss: 0.11890643582505694
I0424 15:46:07.367272 35684 trainer.py:136] Epoch[852/1000] loss: 0.11922710755113829
I0424 15:46:13.798329 35684 trainer.py:136] Epoch[853/1000] loss: 0.11961452776597718
I0424 15:46:19.978169 35684 trainer.py:136] Epoch[854/1000] loss: 0.11876716010146222
I0424 15:46:26.300427 35684 trainer.py:136] Epoch[855/1000] loss: 0.11914248537209074
I0424 15:46:32.527961 35684 trainer.py:136] Epoch[856/1000] loss: 0.11834921700469518
I0424 15:46:38.875880 35684 trainer.py:136] Epoch[857/1000] loss: 0.11937511876478034
I0424 15:46:44.892362 35684 trainer.py:136] Epoch[858/1000] loss: 0.11870968543877036
I0424 15:46:51.007458 35684 trainer.py:136] Epoch[859/1000] loss: 0.11903131702693842
I0424 15:46:57.108021 35684 trainer.py:136] Epoch[860/1000] loss: 0.118679082242109
I0424 15:47:03.129616 35684 trainer.py:136] Epoch[861/1000] loss: 0.11861255689192626
I0424 15:47:09.242852 35684 trainer.py:136] Epoch[862/1000] loss: 0.11887452776654292
I0424 15:47:15.402173 35684 trainer.py:136] Epoch[863/1000] loss: 0.11849650046077825
I0424 15:47:21.381806 35684 trainer.py:136] Epoch[864/1000] loss: 0.11863883799415524
I0424 15:47:27.613361 35684 trainer.py:136] Epoch[865/1000] loss: 0.11835222072520499
I0424 15:47:33.869473 35684 trainer.py:136] Epoch[866/1000] loss: 0.1182715584666042
I0424 15:47:40.029174 35684 trainer.py:136] Epoch[867/1000] loss: 0.11950372475183617
I0424 15:47:46.043068 35684 trainer.py:136] Epoch[868/1000] loss: 0.11854912807880821
I0424 15:47:52.176598 35684 trainer.py:136] Epoch[869/1000] loss: 0.11811025327039977
I0424 15:47:58.214980 35684 trainer.py:136] Epoch[870/1000] loss: 0.11956134476399018
I0424 15:48:04.390606 35684 trainer.py:136] Epoch[871/1000] loss: 0.11810436415470253
I0424 15:48:10.576885 35684 trainer.py:136] Epoch[872/1000] loss: 0.11990187304504847
I0424 15:48:16.785762 35684 trainer.py:136] Epoch[873/1000] loss: 0.11861197738829306
I0424 15:48:22.971487 35684 trainer.py:136] Epoch[874/1000] loss: 0.1197276379344827
I0424 15:48:29.092339 35684 trainer.py:136] Epoch[875/1000] loss: 0.1187470775034468
I0424 15:48:35.068592 35684 trainer.py:136] Epoch[876/1000] loss: 0.11830833061771878
I0424 15:48:41.183101 35684 trainer.py:136] Epoch[877/1000] loss: 0.11896447193319515
I0424 15:48:47.339613 35684 trainer.py:136] Epoch[878/1000] loss: 0.1184013405088651
I0424 15:48:53.560761 35684 trainer.py:136] Epoch[879/1000] loss: 0.11928438433146073
I0424 15:48:59.792438 35684 trainer.py:136] Epoch[880/1000] loss: 0.1183731281908892
I0424 15:49:05.971379 35684 trainer.py:136] Epoch[881/1000] loss: 0.1188663054825896
I0424 15:49:12.057651 35684 trainer.py:136] Epoch[882/1000] loss: 0.1182374912550894
I0424 15:49:18.353160 35684 trainer.py:136] Epoch[883/1000] loss: 0.11824634368136777
I0424 15:49:24.467139 35684 trainer.py:136] Epoch[884/1000] loss: 0.11866926780696642
I0424 15:49:30.607522 35684 trainer.py:136] Epoch[885/1000] loss: 0.11943860036336769
I0424 15:49:36.715796 35684 trainer.py:136] Epoch[886/1000] loss: 0.11867710531263029
I0424 15:49:42.988009 35684 trainer.py:136] Epoch[887/1000] loss: 0.1181523831466497
I0424 15:49:49.218027 35684 trainer.py:136] Epoch[888/1000] loss: 0.11861049876374713
I0424 15:49:55.273635 35684 trainer.py:136] Epoch[889/1000] loss: 0.11983966435921395
I0424 15:50:01.370531 35684 trainer.py:136] Epoch[890/1000] loss: 0.11867717716653468
I0424 15:50:07.435315 35684 trainer.py:136] Epoch[891/1000] loss: 0.11842175509970067
I0424 15:50:13.742990 35684 trainer.py:136] Epoch[892/1000] loss: 0.11856047998545534
I0424 15:50:19.940282 35684 trainer.py:136] Epoch[893/1000] loss: 0.11845429203772949
I0424 15:50:26.120997 35684 trainer.py:136] Epoch[894/1000] loss: 0.11865935815592944
I0424 15:50:32.250739 35684 trainer.py:136] Epoch[895/1000] loss: 0.11875114501532862
I0424 15:50:38.647607 35684 trainer.py:136] Epoch[896/1000] loss: 0.11773483341528197
I0424 15:50:44.680590 35684 trainer.py:136] Epoch[897/1000] loss: 0.11771196808855412
I0424 15:50:50.928065 35684 trainer.py:136] Epoch[898/1000] loss: 0.1179211960505631
I0424 15:50:57.160717 35684 trainer.py:136] Epoch[899/1000] loss: 0.11898128688335419
I0424 15:50:58.557194 35684 trainer.py:142] Test: [{'precision': 0.017153648802736596, 'recall': 0.08551416979466993, 'hit_ratio': 0.24503420752565565, 'ndcg': 0.05847488453986932}]
I0424 15:51:04.996138 35684 trainer.py:136] Epoch[900/1000] loss: 0.11826882208302869
I0424 15:51:11.155652 35684 trainer.py:136] Epoch[901/1000] loss: 0.1188641323123948
I0424 15:51:17.422206 35684 trainer.py:136] Epoch[902/1000] loss: 0.11831984580573389
I0424 15:51:23.705057 35684 trainer.py:136] Epoch[903/1000] loss: 0.11879599763680312
I0424 15:51:30.031515 35684 trainer.py:136] Epoch[904/1000] loss: 0.1183595909910687
I0424 15:51:36.017435 35684 trainer.py:136] Epoch[905/1000] loss: 0.11928070627026639
I0424 15:51:42.188808 35684 trainer.py:136] Epoch[906/1000] loss: 0.11817626162605771
I0424 15:51:48.369178 35684 trainer.py:136] Epoch[907/1000] loss: 0.11862017921472
I0424 15:51:54.591412 35684 trainer.py:136] Epoch[908/1000] loss: 0.11944796473292982
I0424 15:52:00.849788 35684 trainer.py:136] Epoch[909/1000] loss: 0.11857263819646027
I0424 15:52:07.157042 35684 trainer.py:136] Epoch[910/1000] loss: 0.11807914785409378
I0424 15:52:13.232621 35684 trainer.py:136] Epoch[911/1000] loss: 0.11901065593553802
I0424 15:52:19.535970 35684 trainer.py:136] Epoch[912/1000] loss: 0.11830089632737434
I0424 15:52:25.710925 35684 trainer.py:136] Epoch[913/1000] loss: 0.11815446110095008
I0424 15:52:32.005495 35684 trainer.py:136] Epoch[914/1000] loss: 0.11885022485660295
I0424 15:52:38.155074 35684 trainer.py:136] Epoch[915/1000] loss: 0.11835786851785951
I0424 15:52:44.424045 35684 trainer.py:136] Epoch[916/1000] loss: 0.11931072339668113
I0424 15:52:50.511533 35684 trainer.py:136] Epoch[917/1000] loss: 0.11838743482100761
I0424 15:52:56.985870 35684 trainer.py:136] Epoch[918/1000] loss: 0.11840252780308158
I0424 15:53:03.153044 35684 trainer.py:136] Epoch[919/1000] loss: 0.11815349138894324
I0424 15:53:09.368942 35684 trainer.py:136] Epoch[920/1000] loss: 0.11929103315381681
I0424 15:53:15.765045 35684 trainer.py:136] Epoch[921/1000] loss: 0.11911402655355001
I0424 15:53:21.878497 35684 trainer.py:136] Epoch[922/1000] loss: 0.11818478218579696
I0424 15:53:28.082695 35684 trainer.py:136] Epoch[923/1000] loss: 0.1188926315408642
I0424 15:53:34.208766 35684 trainer.py:136] Epoch[924/1000] loss: 0.1177775371125189
I0424 15:53:40.247960 35684 trainer.py:136] Epoch[925/1000] loss: 0.11842815375934213
I0424 15:53:46.448863 35684 trainer.py:136] Epoch[926/1000] loss: 0.1181473103115114
I0424 15:53:52.621757 35684 trainer.py:136] Epoch[927/1000] loss: 0.11845381406404204
I0424 15:53:58.749486 35684 trainer.py:136] Epoch[928/1000] loss: 0.11893170326948166
I0424 15:54:04.914036 35684 trainer.py:136] Epoch[929/1000] loss: 0.11883995025339773
I0424 15:54:11.212126 35684 trainer.py:136] Epoch[930/1000] loss: 0.1192731164016966
I0424 15:54:17.415541 35684 trainer.py:136] Epoch[931/1000] loss: 0.11846777253736884
I0424 15:54:23.641370 35684 trainer.py:136] Epoch[932/1000] loss: 0.11760459385686002
I0424 15:54:29.944483 35684 trainer.py:136] Epoch[933/1000] loss: 0.11901658142017106
I0424 15:54:36.233851 35684 trainer.py:136] Epoch[934/1000] loss: 0.11781728848562402
I0424 15:54:42.301751 35684 trainer.py:136] Epoch[935/1000] loss: 0.11779146679377152
I0424 15:54:48.584566 35684 trainer.py:136] Epoch[936/1000] loss: 0.11749244165622581
I0424 15:54:54.758126 35684 trainer.py:136] Epoch[937/1000] loss: 0.11862817431910563
I0424 15:55:01.074977 35684 trainer.py:136] Epoch[938/1000] loss: 0.11771771071825997
I0424 15:55:07.176367 35684 trainer.py:136] Epoch[939/1000] loss: 0.11837067050954043
I0424 15:55:13.430026 35684 trainer.py:136] Epoch[940/1000] loss: 0.11814300210799202
I0424 15:55:19.522294 35684 trainer.py:136] Epoch[941/1000] loss: 0.11902089985245365
I0424 15:55:25.683556 35684 trainer.py:136] Epoch[942/1000] loss: 0.11915263344170683
I0424 15:55:31.947002 35684 trainer.py:136] Epoch[943/1000] loss: 0.1181149973960246
I0424 15:55:38.017924 35684 trainer.py:136] Epoch[944/1000] loss: 0.11867820926136889
I0424 15:55:44.156464 35684 trainer.py:136] Epoch[945/1000] loss: 0.11992290830713208
I0424 15:55:50.295593 35684 trainer.py:136] Epoch[946/1000] loss: 0.11904815975892341
I0424 15:55:56.399775 35684 trainer.py:136] Epoch[947/1000] loss: 0.11854758164135076
I0424 15:56:02.488518 35684 trainer.py:136] Epoch[948/1000] loss: 0.11804351324247102
I0424 15:56:08.528549 35684 trainer.py:136] Epoch[949/1000] loss: 0.1184772924851563
I0424 15:56:09.948039 35684 trainer.py:142] Test: [{'precision': 0.017053876852907622, 'recall': 0.08635427126416107, 'hit_ratio': 0.2468939566704675, 'ndcg': 0.05926511337040184}]
I0424 15:56:16.321826 35684 trainer.py:136] Epoch[950/1000] loss: 0.11850157519013195
I0424 15:56:22.475091 35684 trainer.py:136] Epoch[951/1000] loss: 0.11838740476612318
I0424 15:56:28.715246 35684 trainer.py:136] Epoch[952/1000] loss: 0.11924063553244381
I0424 15:56:34.938021 35684 trainer.py:136] Epoch[953/1000] loss: 0.11894487059217389
I0424 15:56:41.276935 35684 trainer.py:136] Epoch[954/1000] loss: 0.11908630508992632
I0424 15:56:47.566032 35684 trainer.py:136] Epoch[955/1000] loss: 0.11844578890477196
I0424 15:56:53.887688 35684 trainer.py:136] Epoch[956/1000] loss: 0.11958826270143864
I0424 15:56:59.952953 35684 trainer.py:136] Epoch[957/1000] loss: 0.1188971790469299
I0424 15:57:06.013661 35684 trainer.py:136] Epoch[958/1000] loss: 0.1188876267711995
I0424 15:57:12.065101 35684 trainer.py:136] Epoch[959/1000] loss: 0.11833279100009951
I0424 15:57:18.283029 35684 trainer.py:136] Epoch[960/1000] loss: 0.11867093976776479
I0424 15:57:24.393633 35684 trainer.py:136] Epoch[961/1000] loss: 0.11749882794032662
I0424 15:57:30.661361 35684 trainer.py:136] Epoch[962/1000] loss: 0.11874331319231098
I0424 15:57:36.857343 35684 trainer.py:136] Epoch[963/1000] loss: 0.11860728806863396
I0424 15:57:43.024585 35684 trainer.py:136] Epoch[964/1000] loss: 0.11839364810010135
I0424 15:57:49.330821 35684 trainer.py:136] Epoch[965/1000] loss: 0.11785266813585314
I0424 15:57:55.676232 35684 trainer.py:136] Epoch[966/1000] loss: 0.1187640741720038
I0424 15:58:01.974637 35684 trainer.py:136] Epoch[967/1000] loss: 0.11876573110535993
I0424 15:58:08.308723 35684 trainer.py:136] Epoch[968/1000] loss: 0.11820289189532651
I0424 15:58:14.341380 35684 trainer.py:136] Epoch[969/1000] loss: 0.11836731471752716
I0424 15:58:20.630898 35684 trainer.py:136] Epoch[970/1000] loss: 0.11791205974453586
I0424 15:58:26.887978 35684 trainer.py:136] Epoch[971/1000] loss: 0.11880706137014647
I0424 15:58:33.034543 35684 trainer.py:136] Epoch[972/1000] loss: 0.11865236635430385
I0424 15:58:39.243804 35684 trainer.py:136] Epoch[973/1000] loss: 0.11859023659411123
I0424 15:58:45.563094 35684 trainer.py:136] Epoch[974/1000] loss: 0.11864011936773688
I0424 15:58:51.726797 35684 trainer.py:136] Epoch[975/1000] loss: 0.11838229770882655
I0424 15:58:57.996668 35684 trainer.py:136] Epoch[976/1000] loss: 0.11814349321490628
I0424 15:59:04.156485 35684 trainer.py:136] Epoch[977/1000] loss: 0.1193762299115375
I0424 15:59:10.359806 35684 trainer.py:136] Epoch[978/1000] loss: 0.1187556901220548
I0424 15:59:16.555635 35684 trainer.py:136] Epoch[979/1000] loss: 0.11876842455338624
I0424 15:59:22.639365 35684 trainer.py:136] Epoch[980/1000] loss: 0.11845456076375509
I0424 15:59:28.737162 35684 trainer.py:136] Epoch[981/1000] loss: 0.11829970802290965
I0424 15:59:35.200284 35684 trainer.py:136] Epoch[982/1000] loss: 0.11876324766268165
I0424 15:59:41.362809 35684 trainer.py:136] Epoch[983/1000] loss: 0.11824011651136107
I0424 15:59:47.605085 35684 trainer.py:136] Epoch[984/1000] loss: 0.11790063876216694
I0424 15:59:53.758929 35684 trainer.py:136] Epoch[985/1000] loss: 0.11826904080176757
I0424 16:00:00.138784 35684 trainer.py:136] Epoch[986/1000] loss: 0.11862529574309365
I0424 16:00:06.316589 35684 trainer.py:136] Epoch[987/1000] loss: 0.11879270321736901
I0424 16:00:12.518448 35684 trainer.py:136] Epoch[988/1000] loss: 0.11878120166770482
I0424 16:00:18.700350 35684 trainer.py:136] Epoch[989/1000] loss: 0.11874424426232354
I0424 16:00:24.993696 35684 trainer.py:136] Epoch[990/1000] loss: 0.11826274733422167
I0424 16:00:31.277076 35684 trainer.py:136] Epoch[991/1000] loss: 0.11872529465768297
I0424 16:00:37.108860 35684 trainer.py:136] Epoch[992/1000] loss: 0.1189885974182921
I0424 16:00:42.995414 35684 trainer.py:136] Epoch[993/1000] loss: 0.1174625235341363
I0424 16:00:49.047727 35684 trainer.py:136] Epoch[994/1000] loss: 0.11944693364834381
I0424 16:00:55.131685 35684 trainer.py:136] Epoch[995/1000] loss: 0.1187531007295948
I0424 16:01:01.287249 35684 trainer.py:136] Epoch[996/1000] loss: 0.11847472506559502
I0424 16:01:07.509978 35684 trainer.py:136] Epoch[997/1000] loss: 0.1184586390095242
I0424 16:01:13.634884 35684 trainer.py:136] Epoch[998/1000] loss: 0.11843498783596491
I0424 16:01:19.927229 35684 trainer.py:136] Epoch[999/1000] loss: 0.11901956001075648
I0424 16:01:21.227984 35684 trainer.py:142] Test: [{'precision': 0.01706812998859748, 'recall': 0.08688058993139965, 'hit_ratio': 0.2479981425313569, 'ndcg': 0.060095510805977584}]
