I0424 13:52:43.465171  5652 trainer.py:118] Test: [{'precision': 0.009093500570125429, 'recall': 0.03812504154875111, 'hit_ratio': 0.10989167616875713, 'ndcg': 0.025660653422671223}]
I0424 13:52:49.705913  5652 trainer.py:136] Epoch[0/1000] loss: 0.7073251453496642
I0424 13:52:56.014280  5652 trainer.py:136] Epoch[1/1000] loss: 0.6839060470209284
I0424 13:53:02.323645  5652 trainer.py:136] Epoch[2/1000] loss: 0.6587553327366457
I0424 13:53:08.490114  5652 trainer.py:136] Epoch[3/1000] loss: 0.6276623152070127
I0424 13:53:14.918058  5652 trainer.py:136] Epoch[4/1000] loss: 0.5901597293756776
I0424 13:53:21.242494  5652 trainer.py:136] Epoch[5/1000] loss: 0.5471543154474032
I0424 13:53:27.546335  5652 trainer.py:136] Epoch[6/1000] loss: 0.5043399788565555
I0424 13:53:33.846836  5652 trainer.py:136] Epoch[7/1000] loss: 0.4670132171299498
I0424 13:53:40.169253  5652 trainer.py:136] Epoch[8/1000] loss: 0.4306733436503653
I0424 13:53:46.430324  5652 trainer.py:136] Epoch[9/1000] loss: 0.40108191360861567
I0424 13:53:52.626616  5652 trainer.py:136] Epoch[10/1000] loss: 0.37504591426606904
I0424 13:53:59.016381  5652 trainer.py:136] Epoch[11/1000] loss: 0.35093332246198494
I0424 13:54:05.119546  5652 trainer.py:136] Epoch[12/1000] loss: 0.3309919430037676
I0424 13:54:11.372345  5652 trainer.py:136] Epoch[13/1000] loss: 0.3143243648238101
I0424 13:54:17.669057  5652 trainer.py:136] Epoch[14/1000] loss: 0.29912064035060043
I0424 13:54:23.911311  5652 trainer.py:136] Epoch[15/1000] loss: 0.2835736678818525
I0424 13:54:30.156502  5652 trainer.py:136] Epoch[16/1000] loss: 0.27191964120177897
I0424 13:54:36.417418  5652 trainer.py:136] Epoch[17/1000] loss: 0.2623189846842976
I0424 13:54:42.794466  5652 trainer.py:136] Epoch[18/1000] loss: 0.25253972234362265
I0424 13:54:49.069742  5652 trainer.py:136] Epoch[19/1000] loss: 0.24508404176113968
I0424 13:54:55.214830  5652 trainer.py:136] Epoch[20/1000] loss: 0.23505455204996012
I0424 13:55:01.315967  5652 trainer.py:136] Epoch[21/1000] loss: 0.23037783852068044
I0424 13:55:07.892570  5652 trainer.py:136] Epoch[22/1000] loss: 0.222271838683193
I0424 13:55:14.088949  5652 trainer.py:136] Epoch[23/1000] loss: 0.21873031556606293
I0424 13:55:20.217374  5652 trainer.py:136] Epoch[24/1000] loss: 0.21128016028363825
I0424 13:55:26.319506  5652 trainer.py:136] Epoch[25/1000] loss: 0.20823040453054137
I0424 13:55:32.599911  5652 trainer.py:136] Epoch[26/1000] loss: 0.20227229721465353
I0424 13:55:38.820022  5652 trainer.py:136] Epoch[27/1000] loss: 0.19902269921060337
I0424 13:55:44.997879  5652 trainer.py:136] Epoch[28/1000] loss: 0.19471904155561479
I0424 13:55:51.195393  5652 trainer.py:136] Epoch[29/1000] loss: 0.1927606253805807
I0424 13:55:57.323738  5652 trainer.py:136] Epoch[30/1000] loss: 0.1882117921012943
I0424 13:56:03.378376  5652 trainer.py:136] Epoch[31/1000] loss: 0.18424429681341528
I0424 13:56:09.617229  5652 trainer.py:136] Epoch[32/1000] loss: 0.18149094081531136
I0424 13:56:15.749866  5652 trainer.py:136] Epoch[33/1000] loss: 0.18012491575742173
I0424 13:56:21.850625  5652 trainer.py:136] Epoch[34/1000] loss: 0.17582466263892288
I0424 13:56:28.048712  5652 trainer.py:136] Epoch[35/1000] loss: 0.17481365951441102
I0424 13:56:34.210634  5652 trainer.py:136] Epoch[36/1000] loss: 0.17217853968426333
I0424 13:56:40.395710  5652 trainer.py:136] Epoch[37/1000] loss: 0.16878785849627803
I0424 13:56:46.590031  5652 trainer.py:136] Epoch[38/1000] loss: 0.1668785959482193
I0424 13:56:52.702281  5652 trainer.py:136] Epoch[39/1000] loss: 0.1664286667512635
I0424 13:56:59.048919  5652 trainer.py:136] Epoch[40/1000] loss: 0.16359894381741347
I0424 13:57:05.313454  5652 trainer.py:136] Epoch[41/1000] loss: 0.16360030992556426
I0424 13:57:11.501918  5652 trainer.py:136] Epoch[42/1000] loss: 0.16024961259405493
I0424 13:57:17.626821  5652 trainer.py:136] Epoch[43/1000] loss: 0.15875290713067783
I0424 13:57:23.521454  5652 trainer.py:136] Epoch[44/1000] loss: 0.15905141325320227
I0424 13:57:29.730960  5652 trainer.py:136] Epoch[45/1000] loss: 0.1566751212891886
I0424 13:57:35.823889  5652 trainer.py:136] Epoch[46/1000] loss: 0.15653196886434392
I0424 13:57:42.024975  5652 trainer.py:136] Epoch[47/1000] loss: 0.15295375807810638
I0424 13:57:48.228655  5652 trainer.py:136] Epoch[48/1000] loss: 0.15217587654873477
I0424 13:57:54.634326  5652 trainer.py:136] Epoch[49/1000] loss: 0.1509069459418119
I0424 13:57:56.042212  5652 trainer.py:142] Test: [{'precision': 0.015357753705815273, 'recall': 0.07287578445342642, 'hit_ratio': 0.21080387685290763, 'ndcg': 0.04820183698539275}]
I0424 13:58:02.136741  5652 trainer.py:136] Epoch[50/1000] loss: 0.14966087674690506
I0424 13:58:08.240880  5652 trainer.py:136] Epoch[51/1000] loss: 0.1489113538952197
I0424 13:58:14.359507  5652 trainer.py:136] Epoch[52/1000] loss: 0.14931457022489128
I0424 13:58:20.407412  5652 trainer.py:136] Epoch[53/1000] loss: 0.14694167294744717
I0424 13:58:26.516452  5652 trainer.py:136] Epoch[54/1000] loss: 0.146203012284586
I0424 13:58:32.735012  5652 trainer.py:136] Epoch[55/1000] loss: 0.14498747885227203
I0424 13:58:39.102730  5652 trainer.py:136] Epoch[56/1000] loss: 0.1447476719395589
I0424 13:58:45.223000  5652 trainer.py:136] Epoch[57/1000] loss: 0.1428030597961555
I0424 13:58:51.568571  5652 trainer.py:136] Epoch[58/1000] loss: 0.14287168671519068
I0424 13:58:57.694722  5652 trainer.py:136] Epoch[59/1000] loss: 0.1417553093978914
I0424 13:59:03.898104  5652 trainer.py:136] Epoch[60/1000] loss: 0.1418123553364964
I0424 13:59:10.064738  5652 trainer.py:136] Epoch[61/1000] loss: 0.13970832097328315
I0424 13:59:16.097209  5652 trainer.py:136] Epoch[62/1000] loss: 0.14092185916536945
I0424 13:59:22.213901  5652 trainer.py:136] Epoch[63/1000] loss: 0.1399655422921908
I0424 13:59:28.394042  5652 trainer.py:136] Epoch[64/1000] loss: 0.1390001771308608
I0424 13:59:34.641849  5652 trainer.py:136] Epoch[65/1000] loss: 0.13738810788776915
I0424 13:59:40.837935  5652 trainer.py:136] Epoch[66/1000] loss: 0.1384170856011116
I0424 13:59:46.992022  5652 trainer.py:136] Epoch[67/1000] loss: 0.13589878493951538
I0424 13:59:53.151043  5652 trainer.py:136] Epoch[68/1000] loss: 0.13564023779610457
I0424 13:59:59.298684  5652 trainer.py:136] Epoch[69/1000] loss: 0.1358736159942918
I0424 14:00:05.350091  5652 trainer.py:136] Epoch[70/1000] loss: 0.13525882817931095
I0424 14:00:11.603639  5652 trainer.py:136] Epoch[71/1000] loss: 0.1349756798501742
I0424 14:00:18.120527  5652 trainer.py:136] Epoch[72/1000] loss: 0.13475741067175137
I0424 14:00:24.224270  5652 trainer.py:136] Epoch[73/1000] loss: 0.13373588480181614
I0424 14:00:30.316593  5652 trainer.py:136] Epoch[74/1000] loss: 0.133656079486265
I0424 14:00:36.457173  5652 trainer.py:136] Epoch[75/1000] loss: 0.1332970314611823
I0424 14:00:42.574799  5652 trainer.py:136] Epoch[76/1000] loss: 0.13350253842644771
I0424 14:00:48.680542  5652 trainer.py:136] Epoch[77/1000] loss: 0.1327617953894502
I0424 14:00:54.913608  5652 trainer.py:136] Epoch[78/1000] loss: 0.13156202852220858
I0424 14:01:00.961800  5652 trainer.py:136] Epoch[79/1000] loss: 0.1303440595077256
I0424 14:01:07.176554  5652 trainer.py:136] Epoch[80/1000] loss: 0.13077426386081567
I0424 14:01:13.309199  5652 trainer.py:136] Epoch[81/1000] loss: 0.1299743096707231
I0424 14:01:19.375251  5652 trainer.py:136] Epoch[82/1000] loss: 0.1300215179384765
I0424 14:01:25.468353  5652 trainer.py:136] Epoch[83/1000] loss: 0.12951181955256705
I0424 14:01:31.635821  5652 trainer.py:136] Epoch[84/1000] loss: 0.12841627027018596
I0424 14:01:37.937962  5652 trainer.py:136] Epoch[85/1000] loss: 0.1293276659512924
I0424 14:01:44.146745  5652 trainer.py:136] Epoch[86/1000] loss: 0.1287067394893048
I0424 14:01:50.336020  5652 trainer.py:136] Epoch[87/1000] loss: 0.12828412715156198
I0424 14:01:56.634682  5652 trainer.py:136] Epoch[88/1000] loss: 0.12744784822403374
I0424 14:02:02.831510  5652 trainer.py:136] Epoch[89/1000] loss: 0.12691295222710755
I0424 14:02:08.980425  5652 trainer.py:136] Epoch[90/1000] loss: 0.1279206352971368
I0424 14:02:15.165882  5652 trainer.py:136] Epoch[91/1000] loss: 0.12653458080554414
I0424 14:02:21.263162  5652 trainer.py:136] Epoch[92/1000] loss: 0.12550386180311945
I0424 14:02:27.293793  5652 trainer.py:136] Epoch[93/1000] loss: 0.1275350831575313
I0424 14:02:33.529318  5652 trainer.py:136] Epoch[94/1000] loss: 0.12583436791674565
I0424 14:02:39.696863  5652 trainer.py:136] Epoch[95/1000] loss: 0.1261850052465827
I0424 14:02:46.043289  5652 trainer.py:136] Epoch[96/1000] loss: 0.1258067861199379
I0424 14:02:52.445198  5652 trainer.py:136] Epoch[97/1000] loss: 0.1256592855867693
I0424 14:02:58.946578  5652 trainer.py:136] Epoch[98/1000] loss: 0.1247791186985323
I0424 14:03:05.287933  5652 trainer.py:136] Epoch[99/1000] loss: 0.12580471069125806
I0424 14:03:06.697254  5652 trainer.py:142] Test: [{'precision': 0.015935005701254265, 'recall': 0.07572196267060932, 'hit_ratio': 0.2186431014823261, 'ndcg': 0.05020515157430927}]
I0424 14:03:12.682292  5652 trainer.py:136] Epoch[100/1000] loss: 0.12461718828496286
I0424 14:03:19.039195  5652 trainer.py:136] Epoch[101/1000] loss: 0.12427316542904256
I0424 14:03:25.178046  5652 trainer.py:136] Epoch[102/1000] loss: 0.12471569228475377
I0424 14:03:31.432864  5652 trainer.py:136] Epoch[103/1000] loss: 0.12390317452155937
I0424 14:03:37.543499  5652 trainer.py:136] Epoch[104/1000] loss: 0.12496210546311685
I0424 14:03:43.732527  5652 trainer.py:136] Epoch[105/1000] loss: 0.12430057952464638
I0424 14:03:49.825774  5652 trainer.py:136] Epoch[106/1000] loss: 0.12267670477345838
I0424 14:03:56.138720  5652 trainer.py:136] Epoch[107/1000] loss: 0.12369372291585147
I0424 14:04:02.479129  5652 trainer.py:136] Epoch[108/1000] loss: 0.12312167933431722
I0424 14:04:08.804758  5652 trainer.py:136] Epoch[109/1000] loss: 0.12220118699942605
I0424 14:04:15.168670  5652 trainer.py:136] Epoch[110/1000] loss: 0.1230906806254791
I0424 14:04:21.332812  5652 trainer.py:136] Epoch[111/1000] loss: 0.12324885480989844
I0424 14:04:27.541597  5652 trainer.py:136] Epoch[112/1000] loss: 0.12150959683171773
I0424 14:04:33.940782  5652 trainer.py:136] Epoch[113/1000] loss: 0.12305661972801564
I0424 14:04:40.198213  5652 trainer.py:136] Epoch[114/1000] loss: 0.12211018952272706
I0424 14:04:46.464524  5652 trainer.py:136] Epoch[115/1000] loss: 0.12213727617162769
I0424 14:04:52.746752  5652 trainer.py:136] Epoch[116/1000] loss: 0.12176150298219617
I0424 14:04:58.992552  5652 trainer.py:136] Epoch[117/1000] loss: 0.12225986032162682
I0424 14:05:05.229930  5652 trainer.py:136] Epoch[118/1000] loss: 0.12204652254359197
I0424 14:05:11.359052  5652 trainer.py:136] Epoch[119/1000] loss: 0.12081396440833302
I0424 14:05:17.431428  5652 trainer.py:136] Epoch[120/1000] loss: 0.12044243868124688
I0424 14:05:23.679754  5652 trainer.py:136] Epoch[121/1000] loss: 0.12114213154477588
I0424 14:05:29.925694  5652 trainer.py:136] Epoch[122/1000] loss: 0.12070948428521722
I0424 14:05:36.022978  5652 trainer.py:136] Epoch[123/1000] loss: 0.1208732494358289
I0424 14:05:42.144329  5652 trainer.py:136] Epoch[124/1000] loss: 0.12021879978099112
I0424 14:05:48.293342  5652 trainer.py:136] Epoch[125/1000] loss: 0.12012430987620758
I0424 14:05:54.413777  5652 trainer.py:136] Epoch[126/1000] loss: 0.12036250089689837
I0424 14:06:00.678396  5652 trainer.py:136] Epoch[127/1000] loss: 0.12095171781414646
I0424 14:06:06.901299  5652 trainer.py:136] Epoch[128/1000] loss: 0.12045013172141576
I0424 14:06:13.035259  5652 trainer.py:136] Epoch[129/1000] loss: 0.11994159979335332
I0424 14:06:19.213121  5652 trainer.py:136] Epoch[130/1000] loss: 0.11989325411238913
I0424 14:06:25.454629  5652 trainer.py:136] Epoch[131/1000] loss: 0.12089554195181798
I0424 14:06:31.511734  5652 trainer.py:136] Epoch[132/1000] loss: 0.11945586803100877
I0424 14:06:37.735253  5652 trainer.py:136] Epoch[133/1000] loss: 0.1191030460394035
I0424 14:06:43.942670  5652 trainer.py:136] Epoch[134/1000] loss: 0.11899561599149543
I0424 14:06:50.188406  5652 trainer.py:136] Epoch[135/1000] loss: 0.11983550908201832
I0424 14:06:56.429395  5652 trainer.py:136] Epoch[136/1000] loss: 0.11966562599448835
I0424 14:07:02.624868  5652 trainer.py:136] Epoch[137/1000] loss: 0.11800693834232072
I0424 14:07:08.912228  5652 trainer.py:136] Epoch[138/1000] loss: 0.11898265463315834
I0424 14:07:15.260696  5652 trainer.py:136] Epoch[139/1000] loss: 0.11919175126289917
I0424 14:07:21.400634  5652 trainer.py:136] Epoch[140/1000] loss: 0.11827024830094839
I0424 14:07:27.630236  5652 trainer.py:136] Epoch[141/1000] loss: 0.11835026715771627
I0424 14:07:33.762355  5652 trainer.py:136] Epoch[142/1000] loss: 0.11867481154405464
I0424 14:07:40.020184  5652 trainer.py:136] Epoch[143/1000] loss: 0.11911331205549887
I0424 14:07:46.168135  5652 trainer.py:136] Epoch[144/1000] loss: 0.11901953690132852
I0424 14:07:52.449035  5652 trainer.py:136] Epoch[145/1000] loss: 0.11870150975251602
I0424 14:07:58.554345  5652 trainer.py:136] Epoch[146/1000] loss: 0.11866599813861362
I0424 14:08:04.838210  5652 trainer.py:136] Epoch[147/1000] loss: 0.1182327081086272
I0424 14:08:10.897679  5652 trainer.py:136] Epoch[148/1000] loss: 0.11715300659001884
I0424 14:08:17.174859  5652 trainer.py:136] Epoch[149/1000] loss: 0.11739412909847195
I0424 14:08:18.543241  5652 trainer.py:142] Test: [{'precision': 0.016034777651083236, 'recall': 0.07740534302342075, 'hit_ratio': 0.22120866590649943, 'ndcg': 0.05129325829603567}]
I0424 14:08:24.729772  5652 trainer.py:136] Epoch[150/1000] loss: 0.11857856481762255
I0424 14:08:31.208193  5652 trainer.py:136] Epoch[151/1000] loss: 0.11750087419808922
I0424 14:08:37.447845  5652 trainer.py:136] Epoch[152/1000] loss: 0.11800058729062646
I0424 14:08:43.694532  5652 trainer.py:136] Epoch[153/1000] loss: 0.11755747335442042
I0424 14:08:49.880814  5652 trainer.py:136] Epoch[154/1000] loss: 0.11733493019463652
I0424 14:08:56.170949  5652 trainer.py:136] Epoch[155/1000] loss: 0.11677361759593931
I0424 14:09:02.252468  5652 trainer.py:136] Epoch[156/1000] loss: 0.1177393190436444
I0424 14:09:08.425538  5652 trainer.py:136] Epoch[157/1000] loss: 0.11742939661114903
I0424 14:09:15.870943  5652 trainer.py:136] Epoch[158/1000] loss: 0.11668953009076037
I0424 14:09:31.347734  5652 trainer.py:136] Epoch[159/1000] loss: 0.11710381558385946
I0424 14:09:47.071746  5652 trainer.py:136] Epoch[160/1000] loss: 0.11688155630382441
I0424 14:10:03.100434  5652 trainer.py:136] Epoch[161/1000] loss: 0.11772637081853414
I0424 14:10:11.957275  5652 trainer.py:136] Epoch[162/1000] loss: 0.11616356670856476
I0424 14:10:18.526894  5652 trainer.py:136] Epoch[163/1000] loss: 0.11721347916429325
I0424 14:10:25.063781  5652 trainer.py:136] Epoch[164/1000] loss: 0.11621470799890615
I0424 14:10:38.169196  5652 trainer.py:136] Epoch[165/1000] loss: 0.1168322214635752
I0424 14:10:54.275396  5652 trainer.py:136] Epoch[166/1000] loss: 0.11632189053600117
I0424 14:11:10.419695  5652 trainer.py:136] Epoch[167/1000] loss: 0.11720612708289745
I0424 14:11:25.207842  5652 trainer.py:136] Epoch[168/1000] loss: 0.11653398128889375
I0424 14:11:31.766182  5652 trainer.py:136] Epoch[169/1000] loss: 0.11721980748540264
I0424 14:11:38.157740  5652 trainer.py:136] Epoch[170/1000] loss: 0.11626176788645276
I0424 14:11:44.275880  5652 trainer.py:136] Epoch[171/1000] loss: 0.11591396821757495
I0424 14:11:50.605734  5652 trainer.py:136] Epoch[172/1000] loss: 0.11669079378499823
I0424 14:11:56.663422  5652 trainer.py:136] Epoch[173/1000] loss: 0.11622274439718763
I0424 14:12:02.925128  5652 trainer.py:136] Epoch[174/1000] loss: 0.11588398316654108
I0424 14:12:09.015578  5652 trainer.py:136] Epoch[175/1000] loss: 0.11590084067340624
I0424 14:12:15.438616  5652 trainer.py:136] Epoch[176/1000] loss: 0.11599918530654099
I0424 14:12:21.798239  5652 trainer.py:136] Epoch[177/1000] loss: 0.11647736344297054
I0424 14:12:28.104594  5652 trainer.py:136] Epoch[178/1000] loss: 0.11601715989537158
I0424 14:12:34.353264  5652 trainer.py:136] Epoch[179/1000] loss: 0.11555547582901131
I0424 14:12:40.470750  5652 trainer.py:136] Epoch[180/1000] loss: 0.11557135453163567
I0424 14:12:46.665564  5652 trainer.py:136] Epoch[181/1000] loss: 0.11515675270456378
I0424 14:12:52.737447  5652 trainer.py:136] Epoch[182/1000] loss: 0.11556286970942707
I0424 14:12:58.928345  5652 trainer.py:136] Epoch[183/1000] loss: 0.11498987864134676
I0424 14:13:05.083686  5652 trainer.py:136] Epoch[184/1000] loss: 0.11514260228407586
I0424 14:13:11.397755  5652 trainer.py:136] Epoch[185/1000] loss: 0.1151542408486544
I0424 14:13:17.738148  5652 trainer.py:136] Epoch[186/1000] loss: 0.11547498291326781
I0424 14:13:23.799122  5652 trainer.py:136] Epoch[187/1000] loss: 0.11549724171222267
I0424 14:13:29.831540  5652 trainer.py:136] Epoch[188/1000] loss: 0.11493432420795247
I0424 14:13:36.031193  5652 trainer.py:136] Epoch[189/1000] loss: 0.11556012663295713
I0424 14:13:42.258670  5652 trainer.py:136] Epoch[190/1000] loss: 0.11490222975864249
I0424 14:13:48.552783  5652 trainer.py:136] Epoch[191/1000] loss: 0.11486981607089608
I0424 14:13:54.689946  5652 trainer.py:136] Epoch[192/1000] loss: 0.11537884074752613
I0424 14:14:00.837249  5652 trainer.py:136] Epoch[193/1000] loss: 0.1147137915684005
I0424 14:14:06.901537  5652 trainer.py:136] Epoch[194/1000] loss: 0.11509646045959603
I0424 14:14:13.070729  5652 trainer.py:136] Epoch[195/1000] loss: 0.1147008735244557
I0424 14:14:19.317136  5652 trainer.py:136] Epoch[196/1000] loss: 0.1145572808839507
I0424 14:14:25.569982  5652 trainer.py:136] Epoch[197/1000] loss: 0.11478921202784878
I0424 14:14:31.758020  5652 trainer.py:136] Epoch[198/1000] loss: 0.11515647210812165
I0424 14:14:37.952561  5652 trainer.py:136] Epoch[199/1000] loss: 0.11548766493797302
I0424 14:14:39.373932  5652 trainer.py:142] Test: [{'precision': 0.016419612314709234, 'recall': 0.07908080010659671, 'hit_ratio': 0.22548460661345496, 'ndcg': 0.05241115974645176}]
I0424 14:14:45.380264  5652 trainer.py:136] Epoch[200/1000] loss: 0.11484695188069748
I0424 14:14:51.669559  5652 trainer.py:136] Epoch[201/1000] loss: 0.11503920994572721
I0424 14:14:57.997915  5652 trainer.py:136] Epoch[202/1000] loss: 0.11480343038752927
I0424 14:15:04.234695  5652 trainer.py:136] Epoch[203/1000] loss: 0.11542447151268943
I0424 14:15:10.327819  5652 trainer.py:136] Epoch[204/1000] loss: 0.11405304768833063
I0424 14:15:16.455904  5652 trainer.py:136] Epoch[205/1000] loss: 0.11450756113913099
I0424 14:15:22.574295  5652 trainer.py:136] Epoch[206/1000] loss: 0.11420824100910607
I0424 14:15:28.696723  5652 trainer.py:136] Epoch[207/1000] loss: 0.11468422223450774
I0424 14:15:35.281257  5652 trainer.py:136] Epoch[208/1000] loss: 0.1141634198316073
I0424 14:15:50.844433  5652 trainer.py:136] Epoch[209/1000] loss: 0.1148042600538771
I0424 14:16:06.388350  5652 trainer.py:136] Epoch[210/1000] loss: 0.11404497163780665
I0424 14:16:22.358197  5652 trainer.py:136] Epoch[211/1000] loss: 0.11442997003510846
I0424 14:16:38.187810  5652 trainer.py:136] Epoch[212/1000] loss: 0.11407187997789706
I0424 14:16:53.641731  5652 trainer.py:136] Epoch[213/1000] loss: 0.11544928017814281
I0424 14:17:09.523481  5652 trainer.py:136] Epoch[214/1000] loss: 0.11322143042491654
I0424 14:17:25.016069  5652 trainer.py:136] Epoch[215/1000] loss: 0.11420381094439555
I0424 14:17:40.872600  5652 trainer.py:136] Epoch[216/1000] loss: 0.11405176808268337
I0424 14:17:56.830020  5652 trainer.py:136] Epoch[217/1000] loss: 0.11367849210056208
I0424 14:18:12.552985  5652 trainer.py:136] Epoch[218/1000] loss: 0.11360727869353052
I0424 14:18:28.259641  5652 trainer.py:136] Epoch[219/1000] loss: 0.11495225712404412
I0424 14:18:44.144607  5652 trainer.py:136] Epoch[220/1000] loss: 0.11347260806014982
I0424 14:19:00.042245  5652 trainer.py:136] Epoch[221/1000] loss: 0.11425230235366499
I0424 14:19:16.081460  5652 trainer.py:136] Epoch[222/1000] loss: 0.11436889977273294
I0424 14:19:32.247400  5652 trainer.py:136] Epoch[223/1000] loss: 0.11419042401899726
I0424 14:19:48.088328  5652 trainer.py:136] Epoch[224/1000] loss: 0.11363440562607878
I0424 14:20:03.896386  5652 trainer.py:136] Epoch[225/1000] loss: 0.1148421454985263
I0424 14:20:19.496813  5652 trainer.py:136] Epoch[226/1000] loss: 0.11298231881553844
I0424 14:20:35.292129  5652 trainer.py:136] Epoch[227/1000] loss: 0.11343354214045961
I0424 14:20:51.232159  5652 trainer.py:136] Epoch[228/1000] loss: 0.11388861804695452
I0424 14:21:07.024783  5652 trainer.py:136] Epoch[229/1000] loss: 0.11315794011293831
I0424 14:21:22.805681  5652 trainer.py:136] Epoch[230/1000] loss: 0.11385506239988036
I0424 14:21:38.439079  5652 trainer.py:136] Epoch[231/1000] loss: 0.11286010668944504
I0424 14:21:54.058189  5652 trainer.py:136] Epoch[232/1000] loss: 0.11416950948157553
I0424 14:22:09.603552  5652 trainer.py:136] Epoch[233/1000] loss: 0.11384851434978388
I0424 14:22:25.785551  5652 trainer.py:136] Epoch[234/1000] loss: 0.11285976459414272
I0424 14:22:41.499201  5652 trainer.py:136] Epoch[235/1000] loss: 0.11311150695812905
I0424 14:22:57.061454  5652 trainer.py:136] Epoch[236/1000] loss: 0.11308628106016223
I0424 14:23:12.986588  5652 trainer.py:136] Epoch[237/1000] loss: 0.1131639157311391
I0424 14:23:28.845776  5652 trainer.py:136] Epoch[238/1000] loss: 0.11340271732059576
I0424 14:23:44.200329  5652 trainer.py:136] Epoch[239/1000] loss: 0.11356163694191787
I0424 14:23:59.948131  5652 trainer.py:136] Epoch[240/1000] loss: 0.11304698669809406
I0424 14:24:15.535485  5652 trainer.py:136] Epoch[241/1000] loss: 0.11388204638230598
I0424 14:24:31.135632  5652 trainer.py:136] Epoch[242/1000] loss: 0.11378153565071397
I0424 14:24:46.965980  5652 trainer.py:136] Epoch[243/1000] loss: 0.11364299930253272
I0424 14:25:03.074883  5652 trainer.py:136] Epoch[244/1000] loss: 0.11339367395740445
I0424 14:25:18.501845  5652 trainer.py:136] Epoch[245/1000] loss: 0.11398058283632084
I0424 14:25:34.083747  5652 trainer.py:136] Epoch[246/1000] loss: 0.11334292628502442
I0424 14:25:49.531863  5652 trainer.py:136] Epoch[247/1000] loss: 0.11345552413140313
I0424 14:26:05.224391  5652 trainer.py:136] Epoch[248/1000] loss: 0.11326782872616234
I0424 14:26:20.732906  5652 trainer.py:136] Epoch[249/1000] loss: 0.11292229643312551
I0424 14:26:23.183695  5652 trainer.py:142] Test: [{'precision': 0.016597776510832378, 'recall': 0.07951581397724733, 'hit_ratio': 0.22705245153933865, 'ndcg': 0.052886318002906246}]
I0424 14:26:39.095829  5652 trainer.py:136] Epoch[250/1000] loss: 0.1127892395449897
I0424 14:26:54.895187  5652 trainer.py:136] Epoch[251/1000] loss: 0.11276639555975543
I0424 14:27:10.464743  5652 trainer.py:136] Epoch[252/1000] loss: 0.11283309858734325
I0424 14:27:25.950037  5652 trainer.py:136] Epoch[253/1000] loss: 0.11203241967043634
I0424 14:27:41.403094  5652 trainer.py:136] Epoch[254/1000] loss: 0.11268247638718557
I0424 14:27:56.903934  5652 trainer.py:136] Epoch[255/1000] loss: 0.11327125321505434
I0424 14:28:12.878296  5652 trainer.py:136] Epoch[256/1000] loss: 0.11211133419962252
I0424 14:28:28.408715  5652 trainer.py:136] Epoch[257/1000] loss: 0.11287658724744441
I0424 14:28:43.904543  5652 trainer.py:136] Epoch[258/1000] loss: 0.11296919682773493
I0424 14:28:59.486549  5652 trainer.py:136] Epoch[259/1000] loss: 0.11171819913690373
I0424 14:29:15.367065  5652 trainer.py:136] Epoch[260/1000] loss: 0.11289655442460109
I0424 14:29:30.707149  5652 trainer.py:136] Epoch[261/1000] loss: 0.11253927572298858
I0424 14:29:46.337552  5652 trainer.py:136] Epoch[262/1000] loss: 0.11324916489548602
I0424 14:30:02.262033  5652 trainer.py:136] Epoch[263/1000] loss: 0.1123339724490198
I0424 14:30:17.986032  5652 trainer.py:136] Epoch[264/1000] loss: 0.11227079821845233
I0424 14:30:33.775640  5652 trainer.py:136] Epoch[265/1000] loss: 0.11261417211617454
I0424 14:30:49.364460  5652 trainer.py:136] Epoch[266/1000] loss: 0.11280249046572184
I0424 14:31:05.075658  5652 trainer.py:136] Epoch[267/1000] loss: 0.1114305826061863
I0424 14:31:20.812472  5652 trainer.py:136] Epoch[268/1000] loss: 0.11327100103184329
I0424 14:31:36.377636  5652 trainer.py:136] Epoch[269/1000] loss: 0.1128396996754711
I0424 14:31:51.972959  5652 trainer.py:136] Epoch[270/1000] loss: 0.11254387071072045
I0424 14:32:07.677063  5652 trainer.py:136] Epoch[271/1000] loss: 0.11280738612857916
I0424 14:32:23.593691  5652 trainer.py:136] Epoch[272/1000] loss: 0.11184819371013319
I0424 14:32:39.498805  5652 trainer.py:136] Epoch[273/1000] loss: 0.11260419351569677
I0424 14:32:55.172688  5652 trainer.py:136] Epoch[274/1000] loss: 0.11278883746619951
I0424 14:33:10.886961  5652 trainer.py:136] Epoch[275/1000] loss: 0.11353891608068499
I0424 14:33:18.145161  5652 trainer.py:136] Epoch[276/1000] loss: 0.11189092708341146
I0424 14:33:24.569365  5652 trainer.py:136] Epoch[277/1000] loss: 0.11173055447259192
I0424 14:33:31.226395  5652 trainer.py:136] Epoch[278/1000] loss: 0.11132560455698078
I0424 14:33:37.804246  5652 trainer.py:136] Epoch[279/1000] loss: 0.11264605706526061
I0424 14:33:44.244762  5652 trainer.py:136] Epoch[280/1000] loss: 0.11212283120316974
I0424 14:33:50.518136  5652 trainer.py:136] Epoch[281/1000] loss: 0.11239927628282774
I0424 14:33:56.716683  5652 trainer.py:136] Epoch[282/1000] loss: 0.11231261883246696
I0424 14:34:03.014639  5652 trainer.py:136] Epoch[283/1000] loss: 0.1125630203445079
I0424 14:34:09.239426  5652 trainer.py:136] Epoch[284/1000] loss: 0.11242426148915695
I0424 14:34:15.628988  5652 trainer.py:136] Epoch[285/1000] loss: 0.11317568158699294
I0424 14:34:21.787378  5652 trainer.py:136] Epoch[286/1000] loss: 0.1115829045489683
I0424 14:34:28.052819  5652 trainer.py:136] Epoch[287/1000] loss: 0.11193859008914334
I0424 14:34:34.217468  5652 trainer.py:136] Epoch[288/1000] loss: 0.11215543532270496
I0424 14:34:40.518239  5652 trainer.py:136] Epoch[289/1000] loss: 0.11234441020731199
I0424 14:34:46.817686  5652 trainer.py:136] Epoch[290/1000] loss: 0.11147428910105915
I0424 14:34:52.989000  5652 trainer.py:136] Epoch[291/1000] loss: 0.11171159350265891
I0424 14:34:59.343278  5652 trainer.py:136] Epoch[292/1000] loss: 0.1129448829313456
I0424 14:35:05.830284  5652 trainer.py:136] Epoch[293/1000] loss: 0.11250751844402086
I0424 14:35:12.293588  5652 trainer.py:136] Epoch[294/1000] loss: 0.11235048470355696
I0424 14:35:18.986771  5652 trainer.py:136] Epoch[295/1000] loss: 0.11239168881359747
I0424 14:35:25.472588  5652 trainer.py:136] Epoch[296/1000] loss: 0.11212582595772662
I0424 14:35:31.704205  5652 trainer.py:136] Epoch[297/1000] loss: 0.1117315435055959
I0424 14:35:38.192003  5652 trainer.py:136] Epoch[298/1000] loss: 0.11230524477817244
I0424 14:35:44.409819  5652 trainer.py:136] Epoch[299/1000] loss: 0.11174120160482698
I0424 14:35:45.822966  5652 trainer.py:142] Test: [{'precision': 0.016811573546180153, 'recall': 0.08075673172501122, 'hit_ratio': 0.22876282782212087, 'ndcg': 0.05361695447689988}]
I0424 14:35:51.954359  5652 trainer.py:136] Epoch[300/1000] loss: 0.11154279188584473
I0424 14:35:58.122861  5652 trainer.py:136] Epoch[301/1000] loss: 0.11159303418155443
I0424 14:36:04.332640  5652 trainer.py:136] Epoch[302/1000] loss: 0.11236063264689203
I0424 14:36:10.712674  5652 trainer.py:136] Epoch[303/1000] loss: 0.11287023101822805
I0424 14:36:17.092382  5652 trainer.py:136] Epoch[304/1000] loss: 0.11197586079775276
I0424 14:36:23.361219  5652 trainer.py:136] Epoch[305/1000] loss: 0.11227995144613719
I0424 14:36:29.540347  5652 trainer.py:136] Epoch[306/1000] loss: 0.111442753697856
I0424 14:36:35.642518  5652 trainer.py:136] Epoch[307/1000] loss: 0.11196311386459964
I0424 14:36:42.048535  5652 trainer.py:136] Epoch[308/1000] loss: 0.11211021863302942
I0424 14:36:48.168852  5652 trainer.py:136] Epoch[309/1000] loss: 0.11181920552152698
I0424 14:36:54.610993  5652 trainer.py:136] Epoch[310/1000] loss: 0.11138439228979208
I0424 14:37:01.028609  5652 trainer.py:136] Epoch[311/1000] loss: 0.11102159346564341
I0424 14:37:07.303148  5652 trainer.py:136] Epoch[312/1000] loss: 0.11210395964020389
I0424 14:37:13.485764  5652 trainer.py:136] Epoch[313/1000] loss: 0.11218986849663622
I0424 14:37:19.882620  5652 trainer.py:136] Epoch[314/1000] loss: 0.11145229081986315
I0424 14:37:26.060857  5652 trainer.py:136] Epoch[315/1000] loss: 0.11211711749181909
I0424 14:37:32.145311  5652 trainer.py:136] Epoch[316/1000] loss: 0.11223153555292194
I0424 14:37:38.450838  5652 trainer.py:136] Epoch[317/1000] loss: 0.11252310657400195
I0424 14:37:45.051443  5652 trainer.py:136] Epoch[318/1000] loss: 0.11144998265525043
I0424 14:37:51.302562  5652 trainer.py:136] Epoch[319/1000] loss: 0.1117322838912576
I0424 14:37:57.481920  5652 trainer.py:136] Epoch[320/1000] loss: 0.11195954516277475
I0424 14:38:03.725341  5652 trainer.py:136] Epoch[321/1000] loss: 0.11151655068842031
I0424 14:38:09.993075  5652 trainer.py:136] Epoch[322/1000] loss: 0.11220963147737212
I0424 14:38:16.392614  5652 trainer.py:136] Epoch[323/1000] loss: 0.11253802187867083
I0424 14:38:22.792181  5652 trainer.py:136] Epoch[324/1000] loss: 0.11160303159790524
I0424 14:38:29.031762  5652 trainer.py:136] Epoch[325/1000] loss: 0.1112525840684519
I0424 14:38:35.284180  5652 trainer.py:136] Epoch[326/1000] loss: 0.11192724626448194
I0424 14:38:41.646370  5652 trainer.py:136] Epoch[327/1000] loss: 0.11155689735028704
I0424 14:38:47.819423  5652 trainer.py:136] Epoch[328/1000] loss: 0.11150389076289484
I0424 14:38:54.042129  5652 trainer.py:136] Epoch[329/1000] loss: 0.1114699979454784
I0424 14:39:00.370349  5652 trainer.py:136] Epoch[330/1000] loss: 0.11176599435887094
I0424 14:39:06.674787  5652 trainer.py:136] Epoch[331/1000] loss: 0.11183369652194491
I0424 14:39:12.791149  5652 trainer.py:136] Epoch[332/1000] loss: 0.11192251274646339
I0424 14:39:19.044316  5652 trainer.py:136] Epoch[333/1000] loss: 0.11143223133127568
I0424 14:39:25.276852  5652 trainer.py:136] Epoch[334/1000] loss: 0.11132540970535601
I0424 14:39:31.554746  5652 trainer.py:136] Epoch[335/1000] loss: 0.11094290106478384
I0424 14:39:37.877202  5652 trainer.py:136] Epoch[336/1000] loss: 0.11184246901233318
I0424 14:39:44.271950  5652 trainer.py:136] Epoch[337/1000] loss: 0.11122014600846727
I0424 14:39:50.445619  5652 trainer.py:136] Epoch[338/1000] loss: 0.11193930686025297
I0424 14:39:56.943879  5652 trainer.py:136] Epoch[339/1000] loss: 0.11150778388067828
I0424 14:40:05.195494  5652 trainer.py:136] Epoch[340/1000] loss: 0.11197497392609967
I0424 14:40:21.595297  5652 trainer.py:136] Epoch[341/1000] loss: 0.11141593691151021
I0424 14:40:37.246538  5652 trainer.py:136] Epoch[342/1000] loss: 0.11094201154122918
I0424 14:40:53.503651  5652 trainer.py:136] Epoch[343/1000] loss: 0.11118647797127902
I0424 14:41:09.333364  5652 trainer.py:136] Epoch[344/1000] loss: 0.11112400914652873
I0424 14:41:25.273286  5652 trainer.py:136] Epoch[345/1000] loss: 0.11078842640933344
I0424 14:41:40.946252  5652 trainer.py:136] Epoch[346/1000] loss: 0.11150409230741404
I0424 14:41:56.914019  5652 trainer.py:136] Epoch[347/1000] loss: 0.1112212920087879
I0424 14:42:12.709589  5652 trainer.py:136] Epoch[348/1000] loss: 0.11181981002880355
I0424 14:42:29.187980  5652 trainer.py:136] Epoch[349/1000] loss: 0.11146580705703316
I0424 14:42:31.694662  5652 trainer.py:142] Test: [{'precision': 0.016832953249714927, 'recall': 0.08139498141381128, 'hit_ratio': 0.23004561003420754, 'ndcg': 0.053828714669645214}]
I0424 14:42:47.780528  5652 trainer.py:136] Epoch[350/1000] loss: 0.11191336886357453
I0424 14:43:03.657915  5652 trainer.py:136] Epoch[351/1000] loss: 0.11063121107675261
I0424 14:43:10.017555  5652 trainer.py:136] Epoch[352/1000] loss: 0.11103822871790094
I0424 14:43:16.521634  5652 trainer.py:136] Epoch[353/1000] loss: 0.11088873837458885
I0424 14:43:22.625086  5652 trainer.py:136] Epoch[354/1000] loss: 0.11082215821844037
I0424 14:43:28.960326  5652 trainer.py:136] Epoch[355/1000] loss: 0.11203943672826734
I0424 14:43:35.198145  5652 trainer.py:136] Epoch[356/1000] loss: 0.11044536770905479
I0424 14:43:41.541125  5652 trainer.py:136] Epoch[357/1000] loss: 0.11082678856485981
I0424 14:43:47.711061  5652 trainer.py:136] Epoch[358/1000] loss: 0.11090921105469688
I0424 14:43:54.215637  5652 trainer.py:136] Epoch[359/1000] loss: 0.110899521258928
I0424 14:44:00.423507  5652 trainer.py:136] Epoch[360/1000] loss: 0.11179907683093669
I0424 14:44:06.939691  5652 trainer.py:136] Epoch[361/1000] loss: 0.11069018267473932
I0424 14:44:13.030064  5652 trainer.py:136] Epoch[362/1000] loss: 0.11133920098260297
I0424 14:44:19.271597  5652 trainer.py:136] Epoch[363/1000] loss: 0.11122363186993842
I0424 14:44:25.678213  5652 trainer.py:136] Epoch[364/1000] loss: 0.11108897626399994
I0424 14:44:32.094433  5652 trainer.py:136] Epoch[365/1000] loss: 0.11120671185396486
I0424 14:44:38.310028  5652 trainer.py:136] Epoch[366/1000] loss: 0.111177361365092
I0424 14:44:44.605275  5652 trainer.py:136] Epoch[367/1000] loss: 0.11093101928294716
I0424 14:44:50.618783  5652 trainer.py:136] Epoch[368/1000] loss: 0.11066080743478517
I0424 14:44:56.840343  5652 trainer.py:136] Epoch[369/1000] loss: 0.11049798484575951
I0424 14:45:02.827872  5652 trainer.py:136] Epoch[370/1000] loss: 0.11094408507569362
I0424 14:45:08.962316  5652 trainer.py:136] Epoch[371/1000] loss: 0.11118301622948404
I0424 14:45:14.971258  5652 trainer.py:136] Epoch[372/1000] loss: 0.11067914457644447
I0424 14:45:21.522498  5652 trainer.py:136] Epoch[373/1000] loss: 0.11019117246239872
I0424 14:45:27.693016  5652 trainer.py:136] Epoch[374/1000] loss: 0.11099988222122192
I0424 14:45:33.903461  5652 trainer.py:136] Epoch[375/1000] loss: 0.11132899646536779
I0424 14:45:40.306729  5652 trainer.py:136] Epoch[376/1000] loss: 0.11100251227617264
I0424 14:45:46.669273  5652 trainer.py:136] Epoch[377/1000] loss: 0.11095241671901639
I0424 14:45:52.918909  5652 trainer.py:136] Epoch[378/1000] loss: 0.11112265478251344
I0424 14:45:59.219053  5652 trainer.py:136] Epoch[379/1000] loss: 0.1100377474548453
I0424 14:46:05.648118  5652 trainer.py:136] Epoch[380/1000] loss: 0.11083648947335906
I0424 14:46:11.908170  5652 trainer.py:136] Epoch[381/1000] loss: 0.11060311784178524
I0424 14:46:18.288739  5652 trainer.py:136] Epoch[382/1000] loss: 0.11136080728749097
I0424 14:46:24.487437  5652 trainer.py:136] Epoch[383/1000] loss: 0.11027674541129905
I0424 14:46:30.704784  5652 trainer.py:136] Epoch[384/1000] loss: 0.11123311633275727
I0424 14:46:36.974719  5652 trainer.py:136] Epoch[385/1000] loss: 0.10993504966214551
I0424 14:46:43.172112  5652 trainer.py:136] Epoch[386/1000] loss: 0.11080072340318713
I0424 14:46:49.516670  5652 trainer.py:136] Epoch[387/1000] loss: 0.110703884039895
I0424 14:46:55.772279  5652 trainer.py:136] Epoch[388/1000] loss: 0.11056958694579237
I0424 14:47:02.041501  5652 trainer.py:136] Epoch[389/1000] loss: 0.11133862551996264
I0424 14:47:08.267307  5652 trainer.py:136] Epoch[390/1000] loss: 0.11028904177374758
I0424 14:47:14.569823  5652 trainer.py:136] Epoch[391/1000] loss: 0.1115784787778127
I0424 14:47:20.864831  5652 trainer.py:136] Epoch[392/1000] loss: 0.1109141790765827
I0424 14:47:27.104881  5652 trainer.py:136] Epoch[393/1000] loss: 0.1106866185190314
I0424 14:47:33.298496  5652 trainer.py:136] Epoch[394/1000] loss: 0.11159707163855181
I0424 14:47:39.746812  5652 trainer.py:136] Epoch[395/1000] loss: 0.11179181731353371
I0424 14:47:45.869212  5652 trainer.py:136] Epoch[396/1000] loss: 0.11179954836429176
I0424 14:47:51.971257  5652 trainer.py:136] Epoch[397/1000] loss: 0.10975475104178413
I0424 14:47:58.155668  5652 trainer.py:136] Epoch[398/1000] loss: 0.11079521035238848
I0424 14:48:04.561998  5652 trainer.py:136] Epoch[399/1000] loss: 0.1107822522773581
I0424 14:48:05.992775  5652 trainer.py:142] Test: [{'precision': 0.016889965792474336, 'recall': 0.08189053008388726, 'hit_ratio': 0.23075826681870013, 'ndcg': 0.053611316087794014}]
I0424 14:48:12.390897  5652 trainer.py:136] Epoch[400/1000] loss: 0.11006757680137279
I0424 14:48:18.483854  5652 trainer.py:136] Epoch[401/1000] loss: 0.11078727257958913
I0424 14:48:24.783678  5652 trainer.py:136] Epoch[402/1000] loss: 0.110920590995732
I0424 14:48:30.988970  5652 trainer.py:136] Epoch[403/1000] loss: 0.1109537194340916
I0424 14:48:37.122354  5652 trainer.py:136] Epoch[404/1000] loss: 0.11114386923737445
I0424 14:48:43.259124  5652 trainer.py:136] Epoch[405/1000] loss: 0.11021209899651802
I0424 14:48:49.449305  5652 trainer.py:136] Epoch[406/1000] loss: 0.1104016881120407
I0424 14:48:55.600475  5652 trainer.py:136] Epoch[407/1000] loss: 0.10989514119544272
I0424 14:49:02.141193  5652 trainer.py:136] Epoch[408/1000] loss: 0.11026222940723775
I0424 14:49:08.374660  5652 trainer.py:136] Epoch[409/1000] loss: 0.11043473004789675
I0424 14:49:14.994354  5652 trainer.py:136] Epoch[410/1000] loss: 0.11018888323994006
I0424 14:49:21.327373  5652 trainer.py:136] Epoch[411/1000] loss: 0.11032544013302205
I0424 14:49:27.618812  5652 trainer.py:136] Epoch[412/1000] loss: 0.11099392125162028
I0424 14:49:34.033937  5652 trainer.py:136] Epoch[413/1000] loss: 0.11027501877081597
I0424 14:49:40.404839  5652 trainer.py:136] Epoch[414/1000] loss: 0.11039493346618394
I0424 14:49:46.514098  5652 trainer.py:136] Epoch[415/1000] loss: 0.11107906598155781
I0424 14:49:52.947370  5652 trainer.py:136] Epoch[416/1000] loss: 0.10999292349916394
I0424 14:49:59.390903  5652 trainer.py:136] Epoch[417/1000] loss: 0.11042948370262728
I0424 14:50:05.628251  5652 trainer.py:136] Epoch[418/1000] loss: 0.11052018454519369
I0424 14:50:11.728100  5652 trainer.py:136] Epoch[419/1000] loss: 0.1112153629882861
I0424 14:50:18.077667  5652 trainer.py:136] Epoch[420/1000] loss: 0.10987678586931551
I0424 14:50:24.369052  5652 trainer.py:136] Epoch[421/1000] loss: 0.11030895944874165
I0424 14:50:30.706536  5652 trainer.py:136] Epoch[422/1000] loss: 0.11014520856788602
I0424 14:50:37.217283  5652 trainer.py:136] Epoch[423/1000] loss: 0.11030315367852227
I0424 14:50:43.586211  5652 trainer.py:136] Epoch[424/1000] loss: 0.11101638790914568
I0424 14:50:49.648591  5652 trainer.py:136] Epoch[425/1000] loss: 0.11035941427541991
I0424 14:50:55.916601  5652 trainer.py:136] Epoch[426/1000] loss: 0.11100969501471115
I0424 14:51:02.284905  5652 trainer.py:136] Epoch[427/1000] loss: 0.11047069475812427
I0424 14:51:08.534386  5652 trainer.py:136] Epoch[428/1000] loss: 0.1104398521326356
I0424 14:51:14.872975  5652 trainer.py:136] Epoch[429/1000] loss: 0.11031123313863399
I0424 14:51:21.005885  5652 trainer.py:136] Epoch[430/1000] loss: 0.10998271241531533
I0424 14:51:27.078477  5652 trainer.py:136] Epoch[431/1000] loss: 0.10992098826978167
I0424 14:51:33.338451  5652 trainer.py:136] Epoch[432/1000] loss: 0.11069412617865255
I0424 14:51:39.565671  5652 trainer.py:136] Epoch[433/1000] loss: 0.11092294563176268
I0424 14:51:45.863710  5652 trainer.py:136] Epoch[434/1000] loss: 0.11045627409623841
I0424 14:51:52.083882  5652 trainer.py:136] Epoch[435/1000] loss: 0.11036428240901333
I0424 14:51:58.457431  5652 trainer.py:136] Epoch[436/1000] loss: 0.11056712825419539
I0424 14:52:04.875637  5652 trainer.py:136] Epoch[437/1000] loss: 0.11100010826426038
I0424 14:52:11.295586  5652 trainer.py:136] Epoch[438/1000] loss: 0.11111315731274879
I0424 14:52:17.575858  5652 trainer.py:136] Epoch[439/1000] loss: 0.11126605572841936
I0424 14:52:23.827217  5652 trainer.py:136] Epoch[440/1000] loss: 0.11013519044144679
I0424 14:52:30.011601  5652 trainer.py:136] Epoch[441/1000] loss: 0.11044052659960116
I0424 14:52:36.387245  5652 trainer.py:136] Epoch[442/1000] loss: 0.10980570240546081
I0424 14:52:42.617965  5652 trainer.py:136] Epoch[443/1000] loss: 0.11088245703002154
I0424 14:52:48.951026  5652 trainer.py:136] Epoch[444/1000] loss: 0.11044445444466704
I0424 14:52:55.367129  5652 trainer.py:136] Epoch[445/1000] loss: 0.10986490029904802
I0424 14:53:01.601519  5652 trainer.py:136] Epoch[446/1000] loss: 0.11175380988141238
I0424 14:53:07.907902  5652 trainer.py:136] Epoch[447/1000] loss: 0.11167739180185027
I0424 14:53:14.181228  5652 trainer.py:136] Epoch[448/1000] loss: 0.11052130983542588
I0424 14:53:20.325028  5652 trainer.py:136] Epoch[449/1000] loss: 0.11022510644742999
I0424 14:53:21.758840  5652 trainer.py:142] Test: [{'precision': 0.017103762827822108, 'recall': 0.08243870584957022, 'hit_ratio': 0.23189851767388825, 'ndcg': 0.05408825211846438}]
I0424 14:53:28.050841  5652 trainer.py:136] Epoch[450/1000] loss: 0.10927559687929639
I0424 14:53:34.235427  5652 trainer.py:136] Epoch[451/1000] loss: 0.11072619360382274
I0424 14:53:40.652180  5652 trainer.py:136] Epoch[452/1000] loss: 0.11001022816714594
I0424 14:53:46.808804  5652 trainer.py:136] Epoch[453/1000] loss: 0.11119609704967272
I0424 14:53:53.062840  5652 trainer.py:136] Epoch[454/1000] loss: 0.1101283960170665
I0424 14:53:59.252049  5652 trainer.py:136] Epoch[455/1000] loss: 0.10975549660496793
I0424 14:54:05.554067  5652 trainer.py:136] Epoch[456/1000] loss: 0.10993669169434046
I0424 14:54:11.974296  5652 trainer.py:136] Epoch[457/1000] loss: 0.11055009016546152
I0424 14:54:18.214585  5652 trainer.py:136] Epoch[458/1000] loss: 0.11028595281354452
I0424 14:54:24.689760  5652 trainer.py:136] Epoch[459/1000] loss: 0.10986563007710344
I0424 14:54:31.059545  5652 trainer.py:136] Epoch[460/1000] loss: 0.11116823377245563
I0424 14:54:37.238058  5652 trainer.py:136] Epoch[461/1000] loss: 0.11062657656305927
I0424 14:54:43.545069  5652 trainer.py:136] Epoch[462/1000] loss: 0.11037900475627285
I0424 14:54:49.630712  5652 trainer.py:136] Epoch[463/1000] loss: 0.11097210443626015
I0424 14:54:55.813530  5652 trainer.py:136] Epoch[464/1000] loss: 0.109715391644987
I0424 14:55:01.956714  5652 trainer.py:136] Epoch[465/1000] loss: 0.11044817544141058
I0424 14:55:08.053664  5652 trainer.py:136] Epoch[466/1000] loss: 0.11005953156341941
I0424 14:55:14.314692  5652 trainer.py:136] Epoch[467/1000] loss: 0.1092915182649079
I0424 14:55:20.481233  5652 trainer.py:136] Epoch[468/1000] loss: 0.11002284743018069
I0424 14:55:26.751289  5652 trainer.py:136] Epoch[469/1000] loss: 0.11106960791147362
I0424 14:55:33.130617  5652 trainer.py:136] Epoch[470/1000] loss: 0.11098147878202341
I0424 14:55:39.484049  5652 trainer.py:136] Epoch[471/1000] loss: 0.1114667660351527
I0424 14:55:45.980587  5652 trainer.py:136] Epoch[472/1000] loss: 0.11071964744794166
I0424 14:55:52.326561  5652 trainer.py:136] Epoch[473/1000] loss: 0.11034660357034813
I0424 14:55:58.751274  5652 trainer.py:136] Epoch[474/1000] loss: 0.11037110019538363
I0424 14:56:05.264246  5652 trainer.py:136] Epoch[475/1000] loss: 0.10981635446265592
I0424 14:56:11.632076  5652 trainer.py:136] Epoch[476/1000] loss: 0.1100316672759541
I0424 14:56:17.854347  5652 trainer.py:136] Epoch[477/1000] loss: 0.1104955372668929
I0424 14:56:24.302488  5652 trainer.py:136] Epoch[478/1000] loss: 0.11100686013193453
I0424 14:56:30.650266  5652 trainer.py:136] Epoch[479/1000] loss: 0.1097174411860563
I0424 14:56:36.929812  5652 trainer.py:136] Epoch[480/1000] loss: 0.1105841399501946
I0424 14:56:43.209293  5652 trainer.py:136] Epoch[481/1000] loss: 0.1096819967536603
I0424 14:56:49.463558  5652 trainer.py:136] Epoch[482/1000] loss: 0.11031252234163931
I0424 14:56:55.789376  5652 trainer.py:136] Epoch[483/1000] loss: 0.11060859098777932
I0424 14:57:02.100615  5652 trainer.py:136] Epoch[484/1000] loss: 0.10989739632202407
I0424 14:57:08.619145  5652 trainer.py:136] Epoch[485/1000] loss: 0.109816247502626
I0424 14:57:15.177179  5652 trainer.py:136] Epoch[486/1000] loss: 0.11112728677058624
I0424 14:57:21.483433  5652 trainer.py:136] Epoch[487/1000] loss: 0.11017043787544056
I0424 14:57:27.777924  5652 trainer.py:136] Epoch[488/1000] loss: 0.11039582602048324
I0424 14:57:34.061071  5652 trainer.py:136] Epoch[489/1000] loss: 0.11029947145005405
I0424 14:57:40.376185  5652 trainer.py:136] Epoch[490/1000] loss: 0.11036091499914558
I0424 14:57:46.667814  5652 trainer.py:136] Epoch[491/1000] loss: 0.11009543376453852
I0424 14:57:52.933774  5652 trainer.py:136] Epoch[492/1000] loss: 0.11022522010035433
I0424 14:57:59.290670  5652 trainer.py:136] Epoch[493/1000] loss: 0.10932978949809478
I0424 14:58:05.857279  5652 trainer.py:136] Epoch[494/1000] loss: 0.10949282449180797
I0424 14:58:12.634592  5652 trainer.py:136] Epoch[495/1000] loss: 0.11012650394843797
I0424 14:58:19.411504  5652 trainer.py:136] Epoch[496/1000] loss: 0.11065055947687666
I0424 14:58:25.531692  5652 trainer.py:136] Epoch[497/1000] loss: 0.10923744207721646
I0424 14:58:31.719886  5652 trainer.py:136] Epoch[498/1000] loss: 0.11003143895985716
I0424 14:58:37.992410  5652 trainer.py:136] Epoch[499/1000] loss: 0.11047442295288636
I0424 14:58:39.404888  5652 trainer.py:142] Test: [{'precision': 0.0169897377423033, 'recall': 0.08245225658871641, 'hit_ratio': 0.23161345496009123, 'ndcg': 0.05431652280739481}]
I0424 14:58:45.597290  5652 trainer.py:136] Epoch[500/1000] loss: 0.11060559055057623
I0424 14:58:51.887907  5652 trainer.py:136] Epoch[501/1000] loss: 0.11029349658953941
I0424 14:58:58.100289  5652 trainer.py:136] Epoch[502/1000] loss: 0.11071111324985149
I0424 14:59:04.288093  5652 trainer.py:136] Epoch[503/1000] loss: 0.10942846864967024
I0424 14:59:10.355287  5652 trainer.py:136] Epoch[504/1000] loss: 0.109172037849992
I0424 14:59:16.625164  5652 trainer.py:136] Epoch[505/1000] loss: 0.11002743004237191
I0424 14:59:22.975649  5652 trainer.py:136] Epoch[506/1000] loss: 0.10919688503115864
I0424 14:59:29.157973  5652 trainer.py:136] Epoch[507/1000] loss: 0.10952875573756331
I0424 14:59:35.469029  5652 trainer.py:136] Epoch[508/1000] loss: 0.11030119556491658
I0424 14:59:41.582358  5652 trainer.py:136] Epoch[509/1000] loss: 0.10973737047890485
I0424 14:59:47.782745  5652 trainer.py:136] Epoch[510/1000] loss: 0.10917955194994555
I0424 14:59:53.770202  5652 trainer.py:136] Epoch[511/1000] loss: 0.11003715292376987
I0424 15:00:00.090519  5652 trainer.py:136] Epoch[512/1000] loss: 0.11017494295108116
I0424 15:00:06.413480  5652 trainer.py:136] Epoch[513/1000] loss: 0.10948926349312572
I0424 15:00:12.647338  5652 trainer.py:136] Epoch[514/1000] loss: 0.10944076160253105
I0424 15:00:19.118257  5652 trainer.py:136] Epoch[515/1000] loss: 0.11038493819661059
I0424 15:00:25.471087  5652 trainer.py:136] Epoch[516/1000] loss: 0.11014818677962837
I0424 15:00:31.781798  5652 trainer.py:136] Epoch[517/1000] loss: 0.1107247106857219
I0424 15:00:37.976072  5652 trainer.py:136] Epoch[518/1000] loss: 0.11054821931204553
I0424 15:00:44.232808  5652 trainer.py:136] Epoch[519/1000] loss: 0.10966874507524199
I0424 15:00:50.587346  5652 trainer.py:136] Epoch[520/1000] loss: 0.11056097104387769
I0424 15:00:57.009751  5652 trainer.py:136] Epoch[521/1000] loss: 0.10984396745087736
I0424 15:01:03.405980  5652 trainer.py:136] Epoch[522/1000] loss: 0.109657953603793
I0424 15:01:09.736476  5652 trainer.py:136] Epoch[523/1000] loss: 0.10994610304044465
I0424 15:01:16.272086  5652 trainer.py:136] Epoch[524/1000] loss: 0.11038671193991677
I0424 15:01:22.845042  5652 trainer.py:136] Epoch[525/1000] loss: 0.10907063405897657
I0424 15:01:29.160261  5652 trainer.py:136] Epoch[526/1000] loss: 0.11028493069491144
I0424 15:01:35.639177  5652 trainer.py:136] Epoch[527/1000] loss: 0.11048033189470485
I0424 15:01:42.189719  5652 trainer.py:136] Epoch[528/1000] loss: 0.11042900282447621
I0424 15:01:48.711712  5652 trainer.py:136] Epoch[529/1000] loss: 0.11096680896767115
I0424 15:01:55.024991  5652 trainer.py:136] Epoch[530/1000] loss: 0.11072825451018446
I0424 15:02:01.419653  5652 trainer.py:136] Epoch[531/1000] loss: 0.1097287934715465
I0424 15:02:07.660989  5652 trainer.py:136] Epoch[532/1000] loss: 0.10964458524170569
I0424 15:02:14.121264  5652 trainer.py:136] Epoch[533/1000] loss: 0.10988524455135151
I0424 15:02:20.592047  5652 trainer.py:136] Epoch[534/1000] loss: 0.11082443152948962
I0424 15:02:26.672189  5652 trainer.py:136] Epoch[535/1000] loss: 0.10916330880027707
I0424 15:02:32.928707  5652 trainer.py:136] Epoch[536/1000] loss: 0.10881322483390064
I0424 15:02:39.201387  5652 trainer.py:136] Epoch[537/1000] loss: 0.11038977160292157
I0424 15:02:45.563715  5652 trainer.py:136] Epoch[538/1000] loss: 0.10956090322490465
I0424 15:02:52.044038  5652 trainer.py:136] Epoch[539/1000] loss: 0.10949937999248505
I0424 15:02:58.112324  5652 trainer.py:136] Epoch[540/1000] loss: 0.11057832925501516
I0424 15:03:04.369443  5652 trainer.py:136] Epoch[541/1000] loss: 0.11004601153781858
I0424 15:03:10.601624  5652 trainer.py:136] Epoch[542/1000] loss: 0.10993145785089266
I0424 15:03:16.882358  5652 trainer.py:136] Epoch[543/1000] loss: 0.10975501383260144
I0424 15:03:23.602063  5652 trainer.py:136] Epoch[544/1000] loss: 0.11011321539595975
I0424 15:03:30.284022  5652 trainer.py:136] Epoch[545/1000] loss: 0.11003466821828131
I0424 15:03:36.649763  5652 trainer.py:136] Epoch[546/1000] loss: 0.11023580750166359
I0424 15:03:43.071690  5652 trainer.py:136] Epoch[547/1000] loss: 0.1100312884328729
I0424 15:03:49.357518  5652 trainer.py:136] Epoch[548/1000] loss: 0.10976157766782631
I0424 15:03:55.812154  5652 trainer.py:136] Epoch[549/1000] loss: 0.10974489733324212
I0424 15:03:57.227018  5652 trainer.py:142] Test: [{'precision': 0.017110889395667038, 'recall': 0.08247049140246926, 'hit_ratio': 0.2330387685290764, 'ndcg': 0.05447835903906784}]
I0424 15:04:03.588344  5652 trainer.py:136] Epoch[550/1000] loss: 0.11023445010690366
I0424 15:04:10.058027  5652 trainer.py:136] Epoch[551/1000] loss: 0.10911215109340215
I0424 15:04:19.497941  5652 trainer.py:136] Epoch[552/1000] loss: 0.10969884655738281
I0424 15:04:35.401428  5652 trainer.py:136] Epoch[553/1000] loss: 0.11010219674494306
I0424 15:04:51.011129  5652 trainer.py:136] Epoch[554/1000] loss: 0.11039492955147209
I0424 15:05:06.603283  5652 trainer.py:136] Epoch[555/1000] loss: 0.1101834498724695
I0424 15:05:21.900605  5652 trainer.py:136] Epoch[556/1000] loss: 0.10981330932196924
I0424 15:05:37.570446  5652 trainer.py:136] Epoch[557/1000] loss: 0.1089417296698538
I0424 15:05:52.963774  5652 trainer.py:136] Epoch[558/1000] loss: 0.11014499654204159
I0424 15:06:09.036292  5652 trainer.py:136] Epoch[559/1000] loss: 0.10972582675137763
I0424 15:06:24.632021  5652 trainer.py:136] Epoch[560/1000] loss: 0.10980253123630912
I0424 15:06:40.466527  5652 trainer.py:136] Epoch[561/1000] loss: 0.10882773136688491
I0424 15:06:56.067905  5652 trainer.py:136] Epoch[562/1000] loss: 0.11012216291185152
I0424 15:07:11.759225  5652 trainer.py:136] Epoch[563/1000] loss: 0.10915913483348944
I0424 15:07:27.143062  5652 trainer.py:136] Epoch[564/1000] loss: 0.10970000821655079
I0424 15:07:42.657756  5652 trainer.py:136] Epoch[565/1000] loss: 0.1097028607786712
I0424 15:07:58.206539  5652 trainer.py:136] Epoch[566/1000] loss: 0.10987574834439714
I0424 15:08:13.549509  5652 trainer.py:136] Epoch[567/1000] loss: 0.10975480319584831
I0424 15:08:29.176640  5652 trainer.py:136] Epoch[568/1000] loss: 0.10980607809151634
I0424 15:08:44.883070  5652 trainer.py:136] Epoch[569/1000] loss: 0.10993601849018517
I0424 15:09:00.524057  5652 trainer.py:136] Epoch[570/1000] loss: 0.10945034506967512
I0424 15:09:16.268444  5652 trainer.py:136] Epoch[571/1000] loss: 0.10946689356686705
I0424 15:09:31.741403  5652 trainer.py:136] Epoch[572/1000] loss: 0.10958944298958374
I0424 15:09:47.798090  5652 trainer.py:136] Epoch[573/1000] loss: 0.10972436858435809
I0424 15:10:03.501750  5652 trainer.py:136] Epoch[574/1000] loss: 0.11010277991072606
I0424 15:10:19.517300  5652 trainer.py:136] Epoch[575/1000] loss: 0.10948036686848786
I0424 15:10:34.135653  5652 trainer.py:136] Epoch[576/1000] loss: 0.11035181152618538
I0424 15:10:40.407446  5652 trainer.py:136] Epoch[577/1000] loss: 0.10950302320011591
I0424 15:10:46.615119  5652 trainer.py:136] Epoch[578/1000] loss: 0.1104425045393281
I0424 15:10:53.040042  5652 trainer.py:136] Epoch[579/1000] loss: 0.10947753249083535
I0424 15:10:59.229502  5652 trainer.py:136] Epoch[580/1000] loss: 0.11025696513006243
I0424 15:11:05.661320  5652 trainer.py:136] Epoch[581/1000] loss: 0.10900584620944524
I0424 15:11:12.044440  5652 trainer.py:136] Epoch[582/1000] loss: 0.10946183929503975
I0424 15:11:18.210973  5652 trainer.py:136] Epoch[583/1000] loss: 0.10964234274322704
I0424 15:11:24.496372  5652 trainer.py:136] Epoch[584/1000] loss: 0.10946876265234866
I0424 15:11:30.854397  5652 trainer.py:136] Epoch[585/1000] loss: 0.10984969757876153
I0424 15:11:37.107920  5652 trainer.py:136] Epoch[586/1000] loss: 0.10938208411305637
I0424 15:11:43.608744  5652 trainer.py:136] Epoch[587/1000] loss: 0.10954679649765209
I0424 15:11:50.098577  5652 trainer.py:136] Epoch[588/1000] loss: 0.10876468051288088
I0424 15:11:56.633409  5652 trainer.py:136] Epoch[589/1000] loss: 0.10923617156380314
I0424 15:12:02.960417  5652 trainer.py:136] Epoch[590/1000] loss: 0.1097168481703532
I0424 15:12:09.453160  5652 trainer.py:136] Epoch[591/1000] loss: 0.11061737901073392
I0424 15:12:15.907139  5652 trainer.py:136] Epoch[592/1000] loss: 0.10934150307360342
I0424 15:12:22.513998  5652 trainer.py:136] Epoch[593/1000] loss: 0.10952601455530878
I0424 15:12:28.709206  5652 trainer.py:136] Epoch[594/1000] loss: 0.10962631540783381
I0424 15:12:34.986515  5652 trainer.py:136] Epoch[595/1000] loss: 0.11020310096821542
I0424 15:12:41.554524  5652 trainer.py:136] Epoch[596/1000] loss: 0.1101806906320281
I0424 15:12:48.061907  5652 trainer.py:136] Epoch[597/1000] loss: 0.11019934170832069
I0424 15:12:54.228761  5652 trainer.py:136] Epoch[598/1000] loss: 0.11019038547903805
I0424 15:13:00.630222  5652 trainer.py:136] Epoch[599/1000] loss: 0.1094056607808097
I0424 15:13:02.129751  5652 trainer.py:142] Test: [{'precision': 0.01710376282782211, 'recall': 0.08315833091327662, 'hit_ratio': 0.23275370581527935, 'ndcg': 0.054792769898433125}]
I0424 15:13:08.826222  5652 trainer.py:136] Epoch[600/1000] loss: 0.10849891337802854
I0424 15:13:15.348343  5652 trainer.py:136] Epoch[601/1000] loss: 0.10946187478000835
I0424 15:13:21.817686  5652 trainer.py:136] Epoch[602/1000] loss: 0.10895479495747615
I0424 15:13:28.236814  5652 trainer.py:136] Epoch[603/1000] loss: 0.11052591858778969
I0424 15:13:34.526586  5652 trainer.py:136] Epoch[604/1000] loss: 0.10851501332501233
I0424 15:13:40.922194  5652 trainer.py:136] Epoch[605/1000] loss: 0.10908650897317014
I0424 15:13:47.427068  5652 trainer.py:136] Epoch[606/1000] loss: 0.10957776047920777
I0424 15:13:53.817154  5652 trainer.py:136] Epoch[607/1000] loss: 0.10901625706987866
I0424 15:13:59.944061  5652 trainer.py:136] Epoch[608/1000] loss: 0.10941187986883066
I0424 15:14:06.169454  5652 trainer.py:136] Epoch[609/1000] loss: 0.10983141650587826
I0424 15:14:12.608883  5652 trainer.py:136] Epoch[610/1000] loss: 0.10944682473348359
I0424 15:14:19.013412  5652 trainer.py:136] Epoch[611/1000] loss: 0.10943323032835782
I0424 15:14:25.340557  5652 trainer.py:136] Epoch[612/1000] loss: 0.11003561646251356
I0424 15:14:31.760465  5652 trainer.py:136] Epoch[613/1000] loss: 0.10937632153094826
I0424 15:14:38.448436  5652 trainer.py:136] Epoch[614/1000] loss: 0.10931188600548243
I0424 15:14:44.794453  5652 trainer.py:136] Epoch[615/1000] loss: 0.1098000770908291
I0424 15:14:51.167495  5652 trainer.py:136] Epoch[616/1000] loss: 0.1092967306405811
I0424 15:14:57.439136  5652 trainer.py:136] Epoch[617/1000] loss: 0.10987172844046253
I0424 15:15:03.787285  5652 trainer.py:136] Epoch[618/1000] loss: 0.10916421840251503
I0424 15:15:10.149743  5652 trainer.py:136] Epoch[619/1000] loss: 0.10992183776225074
I0424 15:15:18.729970  5652 trainer.py:136] Epoch[620/1000] loss: 0.11015257201457428
I0424 15:15:34.483371  5652 trainer.py:136] Epoch[621/1000] loss: 0.10887315907215668
I0424 15:15:50.366178  5652 trainer.py:136] Epoch[622/1000] loss: 0.10945855207362418
I0424 15:16:06.228611  5652 trainer.py:136] Epoch[623/1000] loss: 0.10960750521744712
I0424 15:16:21.853956  5652 trainer.py:136] Epoch[624/1000] loss: 0.10948994301133237
I0424 15:16:37.779221  5652 trainer.py:136] Epoch[625/1000] loss: 0.10964528534371974
I0424 15:16:53.313893  5652 trainer.py:136] Epoch[626/1000] loss: 0.10907839276527954
I0424 15:17:09.156579  5652 trainer.py:136] Epoch[627/1000] loss: 0.10943521874941002
I0424 15:17:24.666525  5652 trainer.py:136] Epoch[628/1000] loss: 0.10936678983902527
I0424 15:17:40.403611  5652 trainer.py:136] Epoch[629/1000] loss: 0.11016994739993144
I0424 15:17:56.382060  5652 trainer.py:136] Epoch[630/1000] loss: 0.10857814853474246
I0424 15:18:12.064490  5652 trainer.py:136] Epoch[631/1000] loss: 0.10859825159028424
I0424 15:18:27.842296  5652 trainer.py:136] Epoch[632/1000] loss: 0.10951531337479413
I0424 15:18:43.725354  5652 trainer.py:136] Epoch[633/1000] loss: 0.11009353437161042
I0424 15:19:00.162833  5652 trainer.py:136] Epoch[634/1000] loss: 0.1098506729734146
I0424 15:19:16.195921  5652 trainer.py:136] Epoch[635/1000] loss: 0.10928118127887532
I0424 15:19:31.722565  5652 trainer.py:136] Epoch[636/1000] loss: 0.10958896968829429
I0424 15:19:47.317622  5652 trainer.py:136] Epoch[637/1000] loss: 0.10908229333364357
I0424 15:20:03.315496  5652 trainer.py:136] Epoch[638/1000] loss: 0.10939872037556211
I0424 15:20:18.982401  5652 trainer.py:136] Epoch[639/1000] loss: 0.10925522989640801
I0424 15:20:34.885562  5652 trainer.py:136] Epoch[640/1000] loss: 0.10959732052633318
I0424 15:20:50.997536  5652 trainer.py:136] Epoch[641/1000] loss: 0.10903723916764986
I0424 15:21:06.623873  5652 trainer.py:136] Epoch[642/1000] loss: 0.10936340045625881
I0424 15:21:22.257251  5652 trainer.py:136] Epoch[643/1000] loss: 0.10937296801199348
I0424 15:21:38.040130  5652 trainer.py:136] Epoch[644/1000] loss: 0.10967189982786017
I0424 15:21:53.924801  5652 trainer.py:136] Epoch[645/1000] loss: 0.10916980520143348
I0424 15:22:09.752254  5652 trainer.py:136] Epoch[646/1000] loss: 0.10822111014592445
I0424 15:22:25.293993  5652 trainer.py:136] Epoch[647/1000] loss: 0.10900879967010628
I0424 15:22:40.888093  5652 trainer.py:136] Epoch[648/1000] loss: 0.10870134653681415
I0424 15:22:56.624241  5652 trainer.py:136] Epoch[649/1000] loss: 0.10915229520050146
I0424 15:22:59.116607  5652 trainer.py:142] Test: [{'precision': 0.017039623717217782, 'recall': 0.0832328245062703, 'hit_ratio': 0.23360889395667048, 'ndcg': 0.05454067968473134}]
I0424 15:23:14.776916  5652 trainer.py:136] Epoch[650/1000] loss: 0.10942544687097355
I0424 15:23:31.085461  5652 trainer.py:136] Epoch[651/1000] loss: 0.10910742616249343
I0424 15:23:47.003518  5652 trainer.py:136] Epoch[652/1000] loss: 0.10968888071128878
I0424 15:24:02.603276  5652 trainer.py:136] Epoch[653/1000] loss: 0.10998451659234904
I0424 15:24:18.516182  5652 trainer.py:136] Epoch[654/1000] loss: 0.10889081366486468
I0424 15:24:34.127310  5652 trainer.py:136] Epoch[655/1000] loss: 0.1088582815255149
I0424 15:24:49.801887  5652 trainer.py:136] Epoch[656/1000] loss: 0.1081670367364156
I0424 15:25:05.302973  5652 trainer.py:136] Epoch[657/1000] loss: 0.10948256668397936
I0424 15:25:21.444657  5652 trainer.py:136] Epoch[658/1000] loss: 0.11022696290480888
I0424 15:25:36.959712  5652 trainer.py:136] Epoch[659/1000] loss: 0.10987603032993058
I0424 15:25:52.875428  5652 trainer.py:136] Epoch[660/1000] loss: 0.10901641706793995
I0424 15:26:09.016708  5652 trainer.py:136] Epoch[661/1000] loss: 0.10890531893503869
I0424 15:26:23.259235  5652 trainer.py:136] Epoch[662/1000] loss: 0.11002030349889044
I0424 15:26:29.703014  5652 trainer.py:136] Epoch[663/1000] loss: 0.10876928673962415
I0424 15:26:36.180085  5652 trainer.py:136] Epoch[664/1000] loss: 0.10982828120053825
I0424 15:26:42.374929  5652 trainer.py:136] Epoch[665/1000] loss: 0.10967566237106162
I0424 15:26:48.616218  5652 trainer.py:136] Epoch[666/1000] loss: 0.1099879530779386
I0424 15:26:54.883163  5652 trainer.py:136] Epoch[667/1000] loss: 0.10948637860306239
I0424 15:27:01.041716  5652 trainer.py:136] Epoch[668/1000] loss: 0.10950390022184889
I0424 15:27:07.177666  5652 trainer.py:136] Epoch[669/1000] loss: 0.1091628526732073
I0424 15:27:13.208298  5652 trainer.py:136] Epoch[670/1000] loss: 0.10936784693750284
I0424 15:27:19.449823  5652 trainer.py:136] Epoch[671/1000] loss: 0.10947122942593138
I0424 15:27:25.583664  5652 trainer.py:136] Epoch[672/1000] loss: 0.11001069477554094
I0424 15:27:31.672785  5652 trainer.py:136] Epoch[673/1000] loss: 0.10948483039767055
I0424 15:27:37.774472  5652 trainer.py:136] Epoch[674/1000] loss: 0.10943101194955535
I0424 15:27:43.968192  5652 trainer.py:136] Epoch[675/1000] loss: 0.10904437429824118
I0424 15:27:50.459275  5652 trainer.py:136] Epoch[676/1000] loss: 0.1089543552469399
I0424 15:27:56.716751  5652 trainer.py:136] Epoch[677/1000] loss: 0.10965996664964546
I0424 15:28:03.317582  5652 trainer.py:136] Epoch[678/1000] loss: 0.11015866545297331
I0424 15:28:09.682929  5652 trainer.py:136] Epoch[679/1000] loss: 0.1097694577301963
I0424 15:28:15.944427  5652 trainer.py:136] Epoch[680/1000] loss: 0.10874091581267825
I0424 15:28:22.256169  5652 trainer.py:136] Epoch[681/1000] loss: 0.10908309509188442
I0424 15:28:28.582238  5652 trainer.py:136] Epoch[682/1000] loss: 0.10997344515586303
I0424 15:28:34.856897  5652 trainer.py:136] Epoch[683/1000] loss: 0.10915602958303387
I0424 15:28:41.256911  5652 trainer.py:136] Epoch[684/1000] loss: 0.10877965592731864
I0424 15:28:47.483963  5652 trainer.py:136] Epoch[685/1000] loss: 0.10942923681715787
I0424 15:28:53.711145  5652 trainer.py:136] Epoch[686/1000] loss: 0.10888439568422609
I0424 15:29:00.179772  5652 trainer.py:136] Epoch[687/1000] loss: 0.10923256927122504
I0424 15:29:06.477912  5652 trainer.py:136] Epoch[688/1000] loss: 0.1098351030279014
I0424 15:29:12.823454  5652 trainer.py:136] Epoch[689/1000] loss: 0.10929066271094953
I0424 15:29:19.223119  5652 trainer.py:136] Epoch[690/1000] loss: 0.10987382116964307
I0424 15:29:25.335211  5652 trainer.py:136] Epoch[691/1000] loss: 0.10889799867646169
I0424 15:29:31.642246  5652 trainer.py:136] Epoch[692/1000] loss: 0.10906904998977306
I0424 15:29:37.871155  5652 trainer.py:136] Epoch[693/1000] loss: 0.10898192984572912
I0424 15:29:44.293010  5652 trainer.py:136] Epoch[694/1000] loss: 0.10932610082929417
I0424 15:29:50.319002  5652 trainer.py:136] Epoch[695/1000] loss: 0.10973675751079948
I0424 15:29:56.530940  5652 trainer.py:136] Epoch[696/1000] loss: 0.10897098607936148
I0424 15:30:03.044819  5652 trainer.py:136] Epoch[697/1000] loss: 0.10896681211257385
I0424 15:30:09.266662  5652 trainer.py:136] Epoch[698/1000] loss: 0.10872680378162254
I0424 15:30:15.462896  5652 trainer.py:136] Epoch[699/1000] loss: 0.10947311050811057
I0424 15:30:17.020844  5652 trainer.py:142] Test: [{'precision': 0.017224914481185852, 'recall': 0.08364076286612278, 'hit_ratio': 0.2347491448118586, 'ndcg': 0.05457611718579008}]
I0424 15:30:23.365191  5652 trainer.py:136] Epoch[700/1000] loss: 0.10891574305497993
I0424 15:30:29.539659  5652 trainer.py:136] Epoch[701/1000] loss: 0.10941743976989035
I0424 15:30:35.592969  5652 trainer.py:136] Epoch[702/1000] loss: 0.10972855189594172
I0424 15:30:41.796817  5652 trainer.py:136] Epoch[703/1000] loss: 0.10852679408202737
I0424 15:30:47.842286  5652 trainer.py:136] Epoch[704/1000] loss: 0.10876071288929147
I0424 15:30:53.846156  5652 trainer.py:136] Epoch[705/1000] loss: 0.10968107565984887
I0424 15:31:00.120253  5652 trainer.py:136] Epoch[706/1000] loss: 0.1095353882696669
I0424 15:31:06.220041  5652 trainer.py:136] Epoch[707/1000] loss: 0.10899098924661087
I0424 15:31:12.343167  5652 trainer.py:136] Epoch[708/1000] loss: 0.10912790831367848
I0424 15:31:18.432629  5652 trainer.py:136] Epoch[709/1000] loss: 0.10831930917703499
I0424 15:31:24.804090  5652 trainer.py:136] Epoch[710/1000] loss: 0.10915081708107964
I0424 15:31:30.938980  5652 trainer.py:136] Epoch[711/1000] loss: 0.1084841881263054
I0424 15:31:37.156703  5652 trainer.py:136] Epoch[712/1000] loss: 0.10921705905663764
I0424 15:31:43.365427  5652 trainer.py:136] Epoch[713/1000] loss: 0.10894726595636141
I0424 15:31:49.535921  5652 trainer.py:136] Epoch[714/1000] loss: 0.10904636979103088
I0424 15:31:55.732216  5652 trainer.py:136] Epoch[715/1000] loss: 0.10882236265530021
I0424 15:32:02.087730  5652 trainer.py:136] Epoch[716/1000] loss: 0.1096679925666017
I0424 15:32:08.295344  5652 trainer.py:136] Epoch[717/1000] loss: 0.10925709456205368
I0424 15:32:14.477615  5652 trainer.py:136] Epoch[718/1000] loss: 0.10925536451198287
I0424 15:32:20.626681  5652 trainer.py:136] Epoch[719/1000] loss: 0.10861047811932482
I0424 15:32:26.927742  5652 trainer.py:136] Epoch[720/1000] loss: 0.10841574229426303
I0424 15:32:33.173639  5652 trainer.py:136] Epoch[721/1000] loss: 0.10908119178424447
I0424 15:32:39.504439  5652 trainer.py:136] Epoch[722/1000] loss: 0.10894763128737271
I0424 15:32:45.545304  5652 trainer.py:136] Epoch[723/1000] loss: 0.10941898368172727
I0424 15:32:51.903518  5652 trainer.py:136] Epoch[724/1000] loss: 0.10901149021366895
I0424 15:32:58.039244  5652 trainer.py:136] Epoch[725/1000] loss: 0.1090321202399367
I0424 15:33:04.243434  5652 trainer.py:136] Epoch[726/1000] loss: 0.10979453878382504
I0424 15:33:10.520807  5652 trainer.py:136] Epoch[727/1000] loss: 0.1083516529050924
I0424 15:33:16.700143  5652 trainer.py:136] Epoch[728/1000] loss: 0.10929640332015894
I0424 15:33:23.141679  5652 trainer.py:136] Epoch[729/1000] loss: 0.10867428021915888
I0424 15:33:29.378550  5652 trainer.py:136] Epoch[730/1000] loss: 0.10897373332310531
I0424 15:33:35.404990  5652 trainer.py:136] Epoch[731/1000] loss: 0.10879360455072533
I0424 15:33:41.603578  5652 trainer.py:136] Epoch[732/1000] loss: 0.10862597684233875
I0424 15:33:47.691463  5652 trainer.py:136] Epoch[733/1000] loss: 0.10915042901948346
I0424 15:33:53.978316  5652 trainer.py:136] Epoch[734/1000] loss: 0.10898138039698035
I0424 15:34:00.143052  5652 trainer.py:136] Epoch[735/1000] loss: 0.10941041374610642
I0424 15:34:06.583612  5652 trainer.py:136] Epoch[736/1000] loss: 0.10896912734892408
I0424 15:34:12.750945  5652 trainer.py:136] Epoch[737/1000] loss: 0.10864889419684975
I0424 15:34:19.116219  5652 trainer.py:136] Epoch[738/1000] loss: 0.10853144539109731
I0424 15:34:25.345695  5652 trainer.py:136] Epoch[739/1000] loss: 0.10850489467887556
I0424 15:34:31.430248  5652 trainer.py:136] Epoch[740/1000] loss: 0.10893419195534819
I0424 15:34:37.576888  5652 trainer.py:136] Epoch[741/1000] loss: 0.10921020224943
I0424 15:34:43.839969  5652 trainer.py:136] Epoch[742/1000] loss: 0.10874280939667912
I0424 15:34:50.041643  5652 trainer.py:136] Epoch[743/1000] loss: 0.109982169659461
I0424 15:34:56.383076  5652 trainer.py:136] Epoch[744/1000] loss: 0.10935922042798188
I0424 15:35:02.583956  5652 trainer.py:136] Epoch[745/1000] loss: 0.1093288252161721
I0424 15:35:08.792785  5652 trainer.py:136] Epoch[746/1000] loss: 0.10984131277112638
I0424 15:35:14.904139  5652 trainer.py:136] Epoch[747/1000] loss: 0.108720633311797
I0424 15:35:21.117448  5652 trainer.py:136] Epoch[748/1000] loss: 0.108723600663371
I0424 15:35:27.342586  5652 trainer.py:136] Epoch[749/1000] loss: 0.10865959941835726
I0424 15:35:28.824203  5652 trainer.py:142] Test: [{'precision': 0.017175028506271367, 'recall': 0.0837711313073723, 'hit_ratio': 0.23517673888255416, 'ndcg': 0.054529636834570044}]
I0424 15:35:35.062700  5652 trainer.py:136] Epoch[750/1000] loss: 0.1087580316905248
I0424 15:35:41.188341  5652 trainer.py:136] Epoch[751/1000] loss: 0.10890099418870473
I0424 15:35:47.365195  5652 trainer.py:136] Epoch[752/1000] loss: 0.10851671710862952
I0424 15:35:53.486832  5652 trainer.py:136] Epoch[753/1000] loss: 0.10965301563679161
I0424 15:35:59.894970  5652 trainer.py:136] Epoch[754/1000] loss: 0.11016742392616757
I0424 15:36:06.158667  5652 trainer.py:136] Epoch[755/1000] loss: 0.10985129654912626
I0424 15:36:12.473104  5652 trainer.py:136] Epoch[756/1000] loss: 0.10934625174534524
I0424 15:36:18.788551  5652 trainer.py:136] Epoch[757/1000] loss: 0.10935272364798239
I0424 15:36:25.013870  5652 trainer.py:136] Epoch[758/1000] loss: 0.1089786376993535
I0424 15:36:31.212476  5652 trainer.py:136] Epoch[759/1000] loss: 0.10865448794122469
I0424 15:36:37.393909  5652 trainer.py:136] Epoch[760/1000] loss: 0.10942055903753992
I0424 15:36:43.496678  5652 trainer.py:136] Epoch[761/1000] loss: 0.1090163435723822
I0424 15:36:49.887778  5652 trainer.py:136] Epoch[762/1000] loss: 0.1086335745403322
I0424 15:36:55.897536  5652 trainer.py:136] Epoch[763/1000] loss: 0.1089119940238484
I0424 15:37:02.171283  5652 trainer.py:136] Epoch[764/1000] loss: 0.10905029485791416
I0424 15:37:08.411072  5652 trainer.py:136] Epoch[765/1000] loss: 0.10921284164917672
I0424 15:37:14.596031  5652 trainer.py:136] Epoch[766/1000] loss: 0.10848238091852705
I0424 15:37:20.856350  5652 trainer.py:136] Epoch[767/1000] loss: 0.10922966480760252
I0424 15:37:27.147039  5652 trainer.py:136] Epoch[768/1000] loss: 0.1092244243975413
I0424 15:37:33.370090  5652 trainer.py:136] Epoch[769/1000] loss: 0.10792082712306815
I0424 15:37:39.651441  5652 trainer.py:136] Epoch[770/1000] loss: 0.10855814359955869
I0424 15:37:45.985296  5652 trainer.py:136] Epoch[771/1000] loss: 0.1091850804070295
I0424 15:37:52.164704  5652 trainer.py:136] Epoch[772/1000] loss: 0.1097767836714195
I0424 15:37:58.445823  5652 trainer.py:136] Epoch[773/1000] loss: 0.10908875462867446
I0424 15:38:04.532958  5652 trainer.py:136] Epoch[774/1000] loss: 0.10925295658535876
I0424 15:38:10.780306  5652 trainer.py:136] Epoch[775/1000] loss: 0.10910936861725176
I0424 15:38:16.951431  5652 trainer.py:136] Epoch[776/1000] loss: 0.10888751773005825
I0424 15:38:23.008977  5652 trainer.py:136] Epoch[777/1000] loss: 0.10950462166535652
I0424 15:38:29.109309  5652 trainer.py:136] Epoch[778/1000] loss: 0.1093710879400625
I0424 15:38:35.233541  5652 trainer.py:136] Epoch[779/1000] loss: 0.10875333795102976
I0424 15:38:41.560386  5652 trainer.py:136] Epoch[780/1000] loss: 0.10948908770993604
I0424 15:38:47.562580  5652 trainer.py:136] Epoch[781/1000] loss: 0.10879689429776143
I0424 15:38:53.730176  5652 trainer.py:136] Epoch[782/1000] loss: 0.10879603836495998
I0424 15:38:59.913014  5652 trainer.py:136] Epoch[783/1000] loss: 0.10805354810367196
I0424 15:39:06.113178  5652 trainer.py:136] Epoch[784/1000] loss: 0.10922569049111867
I0424 15:39:12.326230  5652 trainer.py:136] Epoch[785/1000] loss: 0.10958360362861116
I0424 15:39:18.473842  5652 trainer.py:136] Epoch[786/1000] loss: 0.10969625375533508
I0424 15:39:24.750504  5652 trainer.py:136] Epoch[787/1000] loss: 0.10939647295212342
I0424 15:39:31.133063  5652 trainer.py:136] Epoch[788/1000] loss: 0.10860624707351296
I0424 15:39:37.383541  5652 trainer.py:136] Epoch[789/1000] loss: 0.10890332041150433
I0424 15:39:43.388921  5652 trainer.py:136] Epoch[790/1000] loss: 0.10994984234793712
I0424 15:39:49.462032  5652 trainer.py:136] Epoch[791/1000] loss: 0.10934367510726896
I0424 15:39:55.630322  5652 trainer.py:136] Epoch[792/1000] loss: 0.10878042712555093
I0424 15:40:01.945837  5652 trainer.py:136] Epoch[793/1000] loss: 0.10980716524487835
I0424 15:40:08.252055  5652 trainer.py:136] Epoch[794/1000] loss: 0.10953684921486903
I0424 15:40:14.513412  5652 trainer.py:136] Epoch[795/1000] loss: 0.10952730438971923
I0424 15:40:20.635127  5652 trainer.py:136] Epoch[796/1000] loss: 0.1094754196829715
I0424 15:40:26.867037  5652 trainer.py:136] Epoch[797/1000] loss: 0.1089245920716706
I0424 15:40:32.992302  5652 trainer.py:136] Epoch[798/1000] loss: 0.10875412000943038
I0424 15:40:39.265468  5652 trainer.py:136] Epoch[799/1000] loss: 0.10852104475942709
I0424 15:40:40.662548  5652 trainer.py:142] Test: [{'precision': 0.017324686431014816, 'recall': 0.08383665007284814, 'hit_ratio': 0.23617445838084378, 'ndcg': 0.05506364304626951}]
I0424 15:40:46.936536  5652 trainer.py:136] Epoch[800/1000] loss: 0.10979250187085847
I0424 15:40:53.067579  5652 trainer.py:136] Epoch[801/1000] loss: 0.10965476260852006
I0424 15:40:59.276982  5652 trainer.py:136] Epoch[802/1000] loss: 0.1091642309043367
I0424 15:41:05.273837  5652 trainer.py:136] Epoch[803/1000] loss: 0.10849310280913013
I0424 15:41:11.336604  5652 trainer.py:136] Epoch[804/1000] loss: 0.10909751891079596
I0424 15:41:17.420525  5652 trainer.py:136] Epoch[805/1000] loss: 0.10917858716289876
I0424 15:41:23.600565  5652 trainer.py:136] Epoch[806/1000] loss: 0.1085374312380613
I0424 15:41:29.794140  5652 trainer.py:136] Epoch[807/1000] loss: 0.10900013287693767
I0424 15:41:35.857520  5652 trainer.py:136] Epoch[808/1000] loss: 0.10954455993438171
I0424 15:41:41.981322  5652 trainer.py:136] Epoch[809/1000] loss: 0.1085979308364755
I0424 15:41:48.097175  5652 trainer.py:136] Epoch[810/1000] loss: 0.10914773506633306
I0424 15:41:54.406884  5652 trainer.py:136] Epoch[811/1000] loss: 0.109510362527128
I0424 15:42:00.512458  5652 trainer.py:136] Epoch[812/1000] loss: 0.109225547414715
I0424 15:42:06.743528  5652 trainer.py:136] Epoch[813/1000] loss: 0.108846804726932
I0424 15:42:12.843633  5652 trainer.py:136] Epoch[814/1000] loss: 0.1089733371795234
I0424 15:42:19.206933  5652 trainer.py:136] Epoch[815/1000] loss: 0.10905753341266665
I0424 15:42:25.238935  5652 trainer.py:136] Epoch[816/1000] loss: 0.10865129227355375
I0424 15:42:31.408699  5652 trainer.py:136] Epoch[817/1000] loss: 0.10897426357713796
I0424 15:42:37.488673  5652 trainer.py:136] Epoch[818/1000] loss: 0.10896996939081256
I0424 15:42:43.647390  5652 trainer.py:136] Epoch[819/1000] loss: 0.10964638474634138
I0424 15:42:49.746317  5652 trainer.py:136] Epoch[820/1000] loss: 0.10894577685049024
I0424 15:42:55.845082  5652 trainer.py:136] Epoch[821/1000] loss: 0.10814014493913973
I0424 15:43:01.930354  5652 trainer.py:136] Epoch[822/1000] loss: 0.10912598454851215
I0424 15:43:08.114251  5652 trainer.py:136] Epoch[823/1000] loss: 0.10853858721458305
I0424 15:43:14.372899  5652 trainer.py:136] Epoch[824/1000] loss: 0.10945587150626264
I0424 15:43:20.471678  5652 trainer.py:136] Epoch[825/1000] loss: 0.10848403532626265
I0424 15:43:26.473583  5652 trainer.py:136] Epoch[826/1000] loss: 0.10910504412347988
I0424 15:43:32.736778  5652 trainer.py:136] Epoch[827/1000] loss: 0.10953103081654694
I0424 15:43:39.100934  5652 trainer.py:136] Epoch[828/1000] loss: 0.10892217290603508
I0424 15:43:45.315682  5652 trainer.py:136] Epoch[829/1000] loss: 0.10941738294342816
I0424 15:43:51.259617  5652 trainer.py:136] Epoch[830/1000] loss: 0.10809761273153758
I0424 15:43:57.729260  5652 trainer.py:136] Epoch[831/1000] loss: 0.10875833564895694
I0424 15:44:04.066483  5652 trainer.py:136] Epoch[832/1000] loss: 0.108763682640205
I0424 15:44:10.251394  5652 trainer.py:136] Epoch[833/1000] loss: 0.10809489478499203
I0424 15:44:16.472605  5652 trainer.py:136] Epoch[834/1000] loss: 0.10903716062085103
I0424 15:44:22.756233  5652 trainer.py:136] Epoch[835/1000] loss: 0.10923385796910626
I0424 15:44:28.881296  5652 trainer.py:136] Epoch[836/1000] loss: 0.10873201300027006
I0424 15:44:35.017411  5652 trainer.py:136] Epoch[837/1000] loss: 0.10825668237471985
I0424 15:44:41.108322  5652 trainer.py:136] Epoch[838/1000] loss: 0.10873573614379108
I0424 15:44:47.275149  5652 trainer.py:136] Epoch[839/1000] loss: 0.10885498723236181
I0424 15:44:53.508752  5652 trainer.py:136] Epoch[840/1000] loss: 0.1096891500687195
I0424 15:44:59.840150  5652 trainer.py:136] Epoch[841/1000] loss: 0.10945748512522649
I0424 15:45:05.963759  5652 trainer.py:136] Epoch[842/1000] loss: 0.10935660110691846
I0424 15:45:12.161466  5652 trainer.py:136] Epoch[843/1000] loss: 0.10922744125127792
I0424 15:45:18.305851  5652 trainer.py:136] Epoch[844/1000] loss: 0.1093574392340951
I0424 15:45:24.302490  5652 trainer.py:136] Epoch[845/1000] loss: 0.10881237761449006
I0424 15:45:30.638794  5652 trainer.py:136] Epoch[846/1000] loss: 0.10919225380077201
I0424 15:45:36.920150  5652 trainer.py:136] Epoch[847/1000] loss: 0.10920863762750464
I0424 15:45:43.059076  5652 trainer.py:136] Epoch[848/1000] loss: 0.10796907190549171
I0424 15:45:49.322813  5652 trainer.py:136] Epoch[849/1000] loss: 0.10947395987429862
I0424 15:45:50.703392  5652 trainer.py:142] Test: [{'precision': 0.017175028506271374, 'recall': 0.08485233410523237, 'hit_ratio': 0.24517673888255416, 'ndcg': 0.05695891959170363}]
I0424 15:45:56.816080  5652 trainer.py:136] Epoch[850/1000] loss: 0.10890332710439876
I0424 15:46:03.105286  5652 trainer.py:136] Epoch[851/1000] loss: 0.10845345271340871
I0424 15:46:09.294316  5652 trainer.py:136] Epoch[852/1000] loss: 0.10833602360749649
I0424 15:46:15.540668  5652 trainer.py:136] Epoch[853/1000] loss: 0.10906091382948019
I0424 15:46:21.694514  5652 trainer.py:136] Epoch[854/1000] loss: 0.10916847205263074
I0424 15:46:27.997987  5652 trainer.py:136] Epoch[855/1000] loss: 0.1093884634517007
I0424 15:46:34.178712  5652 trainer.py:136] Epoch[856/1000] loss: 0.10798023969440138
I0424 15:46:40.379085  5652 trainer.py:136] Epoch[857/1000] loss: 0.1090381225034342
I0424 15:46:46.585875  5652 trainer.py:136] Epoch[858/1000] loss: 0.1100975840778674
I0424 15:46:52.799458  5652 trainer.py:136] Epoch[859/1000] loss: 0.1094851740083452
I0424 15:46:58.743409  5652 trainer.py:136] Epoch[860/1000] loss: 0.10907401056107828
I0424 15:47:04.835501  5652 trainer.py:136] Epoch[861/1000] loss: 0.10881820548388918
I0424 15:47:10.976224  5652 trainer.py:136] Epoch[862/1000] loss: 0.10893244839320748
I0424 15:47:17.161839  5652 trainer.py:136] Epoch[863/1000] loss: 0.10924506654678764
I0424 15:47:23.208015  5652 trainer.py:136] Epoch[864/1000] loss: 0.10907024523969423
I0424 15:47:29.474092  5652 trainer.py:136] Epoch[865/1000] loss: 0.10940704204268374
I0424 15:47:35.707526  5652 trainer.py:136] Epoch[866/1000] loss: 0.10960117361303102
I0424 15:47:41.850759  5652 trainer.py:136] Epoch[867/1000] loss: 0.10783334783578323
I0424 15:47:47.809806  5652 trainer.py:136] Epoch[868/1000] loss: 0.10791521052182731
I0424 15:47:53.929912  5652 trainer.py:136] Epoch[869/1000] loss: 0.10904476766364049
I0424 15:47:59.982597  5652 trainer.py:136] Epoch[870/1000] loss: 0.10883801708282051
I0424 15:48:06.149300  5652 trainer.py:136] Epoch[871/1000] loss: 0.10908749585939666
I0424 15:48:12.178098  5652 trainer.py:136] Epoch[872/1000] loss: 0.10887300993426371
I0424 15:48:18.333116  5652 trainer.py:136] Epoch[873/1000] loss: 0.108618345048468
I0424 15:48:24.433789  5652 trainer.py:136] Epoch[874/1000] loss: 0.10877970138848839
I0424 15:48:30.517752  5652 trainer.py:136] Epoch[875/1000] loss: 0.10911408432964552
I0424 15:48:36.746757  5652 trainer.py:136] Epoch[876/1000] loss: 0.10819909506935184
I0424 15:48:42.735070  5652 trainer.py:136] Epoch[877/1000] loss: 0.1087232232093811
I0424 15:48:48.792973  5652 trainer.py:136] Epoch[878/1000] loss: 0.10982633192660445
I0424 15:48:55.060095  5652 trainer.py:136] Epoch[879/1000] loss: 0.10879786691423189
I0424 15:49:01.371329  5652 trainer.py:136] Epoch[880/1000] loss: 0.10924729212360867
I0424 15:49:07.554354  5652 trainer.py:136] Epoch[881/1000] loss: 0.11006150293653294
I0424 15:49:13.671455  5652 trainer.py:136] Epoch[882/1000] loss: 0.10867053308224274
I0424 15:49:19.896465  5652 trainer.py:136] Epoch[883/1000] loss: 0.10836921758570914
I0424 15:49:26.171925  5652 trainer.py:136] Epoch[884/1000] loss: 0.10880583486819671
I0424 15:49:32.502380  5652 trainer.py:136] Epoch[885/1000] loss: 0.11005589353331065
I0424 15:49:38.590924  5652 trainer.py:136] Epoch[886/1000] loss: 0.10885574668645859
I0424 15:49:44.793848  5652 trainer.py:136] Epoch[887/1000] loss: 0.10889475274894198
I0424 15:49:51.166806  5652 trainer.py:136] Epoch[888/1000] loss: 0.10866939150175806
I0424 15:49:57.305021  5652 trainer.py:136] Epoch[889/1000] loss: 0.10885764671079183
I0424 15:50:03.445842  5652 trainer.py:136] Epoch[890/1000] loss: 0.10875318161511825
I0424 15:50:09.629365  5652 trainer.py:136] Epoch[891/1000] loss: 0.10874736788919416
I0424 15:50:15.788389  5652 trainer.py:136] Epoch[892/1000] loss: 0.10850600784612914
I0424 15:50:21.936052  5652 trainer.py:136] Epoch[893/1000] loss: 0.10868332194069684
I0424 15:50:28.119581  5652 trainer.py:136] Epoch[894/1000] loss: 0.10921281740321952
I0424 15:50:34.279133  5652 trainer.py:136] Epoch[895/1000] loss: 0.109557727509636
I0424 15:50:40.570399  5652 trainer.py:136] Epoch[896/1000] loss: 0.1089457542461864
I0424 15:50:46.690241  5652 trainer.py:136] Epoch[897/1000] loss: 0.10975571784932735
I0424 15:50:52.836804  5652 trainer.py:136] Epoch[898/1000] loss: 0.1086330113269515
I0424 15:50:59.054531  5652 trainer.py:136] Epoch[899/1000] loss: 0.10882578209295111
I0424 15:51:00.451000  5652 trainer.py:142] Test: [{'precision': 0.017175028506271374, 'recall': 0.08562605200820028, 'hit_ratio': 0.24517673888255416, 'ndcg': 0.05803806683621681}]
I0424 15:51:06.663653  5652 trainer.py:136] Epoch[900/1000] loss: 0.10995339627488185
I0424 15:51:12.783217  5652 trainer.py:136] Epoch[901/1000] loss: 0.1092711968694703
I0424 15:51:19.057723  5652 trainer.py:136] Epoch[902/1000] loss: 0.10923753097905951
I0424 15:51:25.422612  5652 trainer.py:136] Epoch[903/1000] loss: 0.10839747586997889
I0424 15:51:31.689140  5652 trainer.py:136] Epoch[904/1000] loss: 0.10893608692844035
I0424 15:51:37.788761  5652 trainer.py:136] Epoch[905/1000] loss: 0.10853599580162662
I0424 15:51:43.993701  5652 trainer.py:136] Epoch[906/1000] loss: 0.10988888851666855
I0424 15:51:50.178289  5652 trainer.py:136] Epoch[907/1000] loss: 0.1081437135146836
I0424 15:51:56.626776  5652 trainer.py:136] Epoch[908/1000] loss: 0.10862253682088044
I0424 15:52:02.836359  5652 trainer.py:136] Epoch[909/1000] loss: 0.10814986125392428
I0424 15:52:09.174694  5652 trainer.py:136] Epoch[910/1000] loss: 0.1089497419484591
I0424 15:52:15.301918  5652 trainer.py:136] Epoch[911/1000] loss: 0.10837939596277173
I0424 15:52:21.399338  5652 trainer.py:136] Epoch[912/1000] loss: 0.10976318042662184
I0424 15:52:27.558539  5652 trainer.py:136] Epoch[913/1000] loss: 0.109559215857821
I0424 15:52:33.778856  5652 trainer.py:136] Epoch[914/1000] loss: 0.10862955110052884
I0424 15:52:39.850150  5652 trainer.py:136] Epoch[915/1000] loss: 0.10884071166737605
I0424 15:52:46.023289  5652 trainer.py:136] Epoch[916/1000] loss: 0.10835734009742737
I0424 15:52:52.304165  5652 trainer.py:136] Epoch[917/1000] loss: 0.10861702604314029
I0424 15:52:58.546754  5652 trainer.py:136] Epoch[918/1000] loss: 0.10880493498959784
I0424 15:53:04.648080  5652 trainer.py:136] Epoch[919/1000] loss: 0.10936528204356209
I0424 15:53:10.988386  5652 trainer.py:136] Epoch[920/1000] loss: 0.10889232019751759
I0424 15:53:17.140285  5652 trainer.py:136] Epoch[921/1000] loss: 0.10905219740786795
I0424 15:53:23.180696  5652 trainer.py:136] Epoch[922/1000] loss: 0.10861613841380104
I0424 15:53:29.318187  5652 trainer.py:136] Epoch[923/1000] loss: 0.10835744390043162
I0424 15:53:35.422908  5652 trainer.py:136] Epoch[924/1000] loss: 0.10835937978857654
I0424 15:53:41.607365  5652 trainer.py:136] Epoch[925/1000] loss: 0.1094337737156173
I0424 15:53:47.845734  5652 trainer.py:136] Epoch[926/1000] loss: 0.1088833124455759
I0424 15:53:54.030568  5652 trainer.py:136] Epoch[927/1000] loss: 0.10849122021157863
I0424 15:54:00.215913  5652 trainer.py:136] Epoch[928/1000] loss: 0.10956527911505456
I0424 15:54:06.331159  5652 trainer.py:136] Epoch[929/1000] loss: 0.10854475957862401
I0424 15:54:12.662555  5652 trainer.py:136] Epoch[930/1000] loss: 0.10891672236434484
I0424 15:54:18.860391  5652 trainer.py:136] Epoch[931/1000] loss: 0.10930347063783873
I0424 15:54:25.023290  5652 trainer.py:136] Epoch[932/1000] loss: 0.10879982565924273
I0424 15:54:31.225752  5652 trainer.py:136] Epoch[933/1000] loss: 0.10835452150490324
I0424 15:54:37.605244  5652 trainer.py:136] Epoch[934/1000] loss: 0.1085029162340245
I0424 15:54:43.759396  5652 trainer.py:136] Epoch[935/1000] loss: 0.10899028043120594
I0424 15:54:49.905654  5652 trainer.py:136] Epoch[936/1000] loss: 0.10786586103297896
I0424 15:54:56.200103  5652 trainer.py:136] Epoch[937/1000] loss: 0.10828433248956325
I0424 15:55:02.483451  5652 trainer.py:136] Epoch[938/1000] loss: 0.10849608518814637
I0424 15:55:08.631145  5652 trainer.py:136] Epoch[939/1000] loss: 0.10910090425256956
I0424 15:55:14.985470  5652 trainer.py:136] Epoch[940/1000] loss: 0.10889519523766081
I0424 15:55:21.190324  5652 trainer.py:136] Epoch[941/1000] loss: 0.10857721632820065
I0424 15:55:27.448776  5652 trainer.py:136] Epoch[942/1000] loss: 0.10840628321393062
I0424 15:55:33.635858  5652 trainer.py:136] Epoch[943/1000] loss: 0.10912411975658547
I0424 15:55:39.763863  5652 trainer.py:136] Epoch[944/1000] loss: 0.10901673807431075
I0424 15:55:45.811105  5652 trainer.py:136] Epoch[945/1000] loss: 0.10928338399883043
I0424 15:55:52.032095  5652 trainer.py:136] Epoch[946/1000] loss: 0.109477022315486
I0424 15:55:58.103109  5652 trainer.py:136] Epoch[947/1000] loss: 0.10797687481015415
I0424 15:56:04.258089  5652 trainer.py:136] Epoch[948/1000] loss: 0.10928845329809997
I0424 15:56:10.477149  5652 trainer.py:136] Epoch[949/1000] loss: 0.10905174708972543
I0424 15:56:11.928052  5652 trainer.py:142] Test: [{'precision': 0.017118015963511965, 'recall': 0.08610380639865075, 'hit_ratio': 0.24360889395667048, 'ndcg': 0.05937512598363198}]
I0424 15:56:18.138283  5652 trainer.py:136] Epoch[950/1000] loss: 0.10854133395320278
I0424 15:56:24.417270  5652 trainer.py:136] Epoch[951/1000] loss: 0.1078474097332712
I0424 15:56:30.622518  5652 trainer.py:136] Epoch[952/1000] loss: 0.10903864619085345
I0424 15:56:36.846769  5652 trainer.py:136] Epoch[953/1000] loss: 0.10903190846665431
I0424 15:56:43.100004  5652 trainer.py:136] Epoch[954/1000] loss: 0.10835078042947639
I0424 15:56:49.401656  5652 trainer.py:136] Epoch[955/1000] loss: 0.10858214848627479
I0424 15:56:55.608054  5652 trainer.py:136] Epoch[956/1000] loss: 0.10817003439543611
I0424 15:57:01.722256  5652 trainer.py:136] Epoch[957/1000] loss: 0.10869073135367895
I0424 15:57:07.851765  5652 trainer.py:136] Epoch[958/1000] loss: 0.10874640019768375
I0424 15:57:13.833434  5652 trainer.py:136] Epoch[959/1000] loss: 0.10766188434119951
I0424 15:57:20.044824  5652 trainer.py:136] Epoch[960/1000] loss: 0.10858293231260979
I0424 15:57:26.106142  5652 trainer.py:136] Epoch[961/1000] loss: 0.10894617539341167
I0424 15:57:32.526496  5652 trainer.py:136] Epoch[962/1000] loss: 0.10882458494881452
I0424 15:57:38.537895  5652 trainer.py:136] Epoch[963/1000] loss: 0.1081070312756603
I0424 15:57:44.808645  5652 trainer.py:136] Epoch[964/1000] loss: 0.10830322362608828
I0424 15:57:50.964589  5652 trainer.py:136] Epoch[965/1000] loss: 0.10888669778734951
I0424 15:57:57.338233  5652 trainer.py:136] Epoch[966/1000] loss: 0.1087901705907563
I0424 15:58:03.670886  5652 trainer.py:136] Epoch[967/1000] loss: 0.10785414366903952
I0424 15:58:09.867063  5652 trainer.py:136] Epoch[968/1000] loss: 0.10927750738495487
I0424 15:58:15.924316  5652 trainer.py:136] Epoch[969/1000] loss: 0.10865727685770746
I0424 15:58:22.218843  5652 trainer.py:136] Epoch[970/1000] loss: 0.1078815152079372
I0424 15:58:28.401184  5652 trainer.py:136] Epoch[971/1000] loss: 0.10878196762780011
I0424 15:58:34.559218  5652 trainer.py:136] Epoch[972/1000] loss: 0.1090777641383268
I0424 15:58:40.780895  5652 trainer.py:136] Epoch[973/1000] loss: 0.10842136672492754
I0424 15:58:46.978924  5652 trainer.py:136] Epoch[974/1000] loss: 0.10957959913096185
I0424 15:58:53.139491  5652 trainer.py:136] Epoch[975/1000] loss: 0.10967948679196632
I0424 15:58:59.376595  5652 trainer.py:136] Epoch[976/1000] loss: 0.10832717459080583
I0424 15:59:05.497179  5652 trainer.py:136] Epoch[977/1000] loss: 0.10896741321026268
I0424 15:59:11.718256  5652 trainer.py:136] Epoch[978/1000] loss: 0.10901940778150397
I0424 15:59:17.878751  5652 trainer.py:136] Epoch[979/1000] loss: 0.108791260901144
I0424 15:59:23.985432  5652 trainer.py:136] Epoch[980/1000] loss: 0.10829026416196662
I0424 15:59:30.196352  5652 trainer.py:136] Epoch[981/1000] loss: 0.10880909834877919
I0424 15:59:36.528287  5652 trainer.py:136] Epoch[982/1000] loss: 0.10912923211768522
I0424 15:59:42.677573  5652 trainer.py:136] Epoch[983/1000] loss: 0.10924992280996453
I0424 15:59:49.045831  5652 trainer.py:136] Epoch[984/1000] loss: 0.10908076343900067
I0424 15:59:55.250564  5652 trainer.py:136] Epoch[985/1000] loss: 0.10922698272486865
I0424 16:00:01.604012  5652 trainer.py:136] Epoch[986/1000] loss: 0.10847243111012346
I0424 16:00:07.706189  5652 trainer.py:136] Epoch[987/1000] loss: 0.10876257338766325
I0424 16:00:13.812725  5652 trainer.py:136] Epoch[988/1000] loss: 0.10841115993463386
I0424 16:00:19.971702  5652 trainer.py:136] Epoch[989/1000] loss: 0.1094908814056445
I0424 16:00:26.307786  5652 trainer.py:136] Epoch[990/1000] loss: 0.10835227509171276
I0424 16:00:32.553931  5652 trainer.py:136] Epoch[991/1000] loss: 0.10903706603636176
I0424 16:00:38.391706  5652 trainer.py:136] Epoch[992/1000] loss: 0.10874641307834852
I0424 16:00:44.373431  5652 trainer.py:136] Epoch[993/1000] loss: 0.10871914610014123
I0424 16:00:50.466117  5652 trainer.py:136] Epoch[994/1000] loss: 0.10859330339451968
I0424 16:00:56.515219  5652 trainer.py:136] Epoch[995/1000] loss: 0.10879727591902523
I0424 16:01:02.754771  5652 trainer.py:136] Epoch[996/1000] loss: 0.10903199736849736
I0424 16:01:08.839145  5652 trainer.py:136] Epoch[997/1000] loss: 0.10946425782927012
I0424 16:01:15.036453  5652 trainer.py:136] Epoch[998/1000] loss: 0.10897332404629659
I0424 16:01:21.327651  5652 trainer.py:136] Epoch[999/1000] loss: 0.10877679806139509
I0424 16:01:22.652069  5652 trainer.py:142] Test: [{'precision': 0.01700399087799315, 'recall': 0.08675956142677836, 'hit_ratio': 0.24819851767388825, 'ndcg': 0.06011015151546729}]
