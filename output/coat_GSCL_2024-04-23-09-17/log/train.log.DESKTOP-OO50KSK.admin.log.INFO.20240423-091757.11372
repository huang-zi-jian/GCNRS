I0423 09:17:58.776407 12780 trainer.py:118] Test: [{'precision': 0.014978902953586495, 'recall': 0.06536982707868783, 'hit_ratio': 0.23628691983122363, 'ndcg': 0.03775881918796425}]
I0423 09:17:59.776062 12780 trainer.py:136] Epoch[0/200] loss: 0.6739881753921508
I0423 09:18:00.821089 12780 trainer.py:136] Epoch[1/200] loss: 0.6345806578795116
I0423 09:18:01.855208 12780 trainer.py:136] Epoch[2/200] loss: 0.6011582016944885
I0423 09:18:02.866375 12780 trainer.py:136] Epoch[3/200] loss: 0.5581892967224121
I0423 09:18:03.900511 12780 trainer.py:136] Epoch[4/200] loss: 0.5242492308219274
I0423 09:18:04.886811 12780 trainer.py:136] Epoch[5/200] loss: 0.4956712285677592
I0423 09:18:05.899075 12780 trainer.py:136] Epoch[6/200] loss: 0.45897423624992373
I0423 09:18:06.914237 12780 trainer.py:136] Epoch[7/200] loss: 0.42509160935878754
I0423 09:18:07.965364 12780 trainer.py:136] Epoch[8/200] loss: 0.41353238026301065
I0423 09:18:09.036365 12780 trainer.py:136] Epoch[9/200] loss: 0.39009103874365486
I0423 09:18:10.098410 12780 trainer.py:136] Epoch[10/200] loss: 0.3537940949201584
I0423 09:18:11.155529 12780 trainer.py:136] Epoch[11/200] loss: 0.3651436597108841
I0423 09:18:12.152743 12780 trainer.py:136] Epoch[12/200] loss: 0.34167210658391317
I0423 09:18:13.146975 12780 trainer.py:136] Epoch[13/200] loss: 0.35401564886172615
I0423 09:18:14.153224 12780 trainer.py:136] Epoch[14/200] loss: 0.3189134468634923
I0423 09:18:15.153464 12780 trainer.py:136] Epoch[15/200] loss: 0.32988762060801186
I0423 09:18:16.141737 12780 trainer.py:136] Epoch[16/200] loss: 0.3191612516840299
I0423 09:18:17.153024 12780 trainer.py:136] Epoch[17/200] loss: 0.31450065523386
I0423 09:18:18.161501 12780 trainer.py:136] Epoch[18/200] loss: 0.30047351072231926
I0423 09:18:19.196751 12780 trainer.py:136] Epoch[19/200] loss: 0.29942701011896133
I0423 09:18:20.269417 12780 trainer.py:136] Epoch[20/200] loss: 0.3026336635152499
I0423 09:18:21.307505 12780 trainer.py:136] Epoch[21/200] loss: 0.2906819567084312
I0423 09:18:22.378527 12780 trainer.py:136] Epoch[22/200] loss: 0.2656071146329244
I0423 09:18:23.436564 12780 trainer.py:136] Epoch[23/200] loss: 0.297659661869208
I0423 09:18:24.447805 12780 trainer.py:136] Epoch[24/200] loss: 0.2642928640047709
I0423 09:18:25.477540 12780 trainer.py:136] Epoch[25/200] loss: 0.25229750325282413
I0423 09:18:26.549584 12780 trainer.py:136] Epoch[26/200] loss: 0.27145256797472633
I0423 09:18:27.612630 12780 trainer.py:136] Epoch[27/200] loss: 0.2570820887883504
I0423 09:18:28.692567 12780 trainer.py:136] Epoch[28/200] loss: 0.265020077675581
I0423 09:18:29.702870 12780 trainer.py:136] Epoch[29/200] loss: 0.25061478912830354
I0423 09:18:30.756923 12780 trainer.py:136] Epoch[30/200] loss: 0.258326847354571
I0423 09:18:31.859446 12780 trainer.py:136] Epoch[31/200] loss: 0.25315289745728176
I0423 09:18:32.928403 12780 trainer.py:136] Epoch[32/200] loss: 0.2564442525307337
I0423 09:18:34.022291 12780 trainer.py:136] Epoch[33/200] loss: 0.24259970784187318
I0423 09:18:35.066365 12780 trainer.py:136] Epoch[34/200] loss: 0.2597591112057368
I0423 09:18:36.092590 12780 trainer.py:136] Epoch[35/200] loss: 0.22675427049398422
I0423 09:18:37.117792 12780 trainer.py:136] Epoch[36/200] loss: 0.24463934501012166
I0423 09:18:38.136964 12780 trainer.py:136] Epoch[37/200] loss: 0.24603528281052908
I0423 09:18:39.130275 12780 trainer.py:136] Epoch[38/200] loss: 0.2463770588239034
I0423 09:18:40.113565 12780 trainer.py:136] Epoch[39/200] loss: 0.23626350462436677
I0423 09:18:41.113526 12780 trainer.py:136] Epoch[40/200] loss: 0.23120991090933482
I0423 09:18:42.116767 12780 trainer.py:136] Epoch[41/200] loss: 0.23396055996418
I0423 09:18:43.099048 12780 trainer.py:136] Epoch[42/200] loss: 0.23731084565321606
I0423 09:18:44.096538 12780 trainer.py:136] Epoch[43/200] loss: 0.21414868781963983
I0423 09:18:45.097313 12780 trainer.py:136] Epoch[44/200] loss: 0.23340277125438055
I0423 09:18:46.104498 12780 trainer.py:136] Epoch[45/200] loss: 0.22023597608009973
I0423 09:18:47.095731 12780 trainer.py:136] Epoch[46/200] loss: 0.22189225355784098
I0423 09:18:48.097977 12780 trainer.py:136] Epoch[47/200] loss: 0.21215852399667104
I0423 09:18:49.104192 12780 trainer.py:136] Epoch[48/200] loss: 0.22028159846862158
I0423 09:18:50.107430 12780 trainer.py:136] Epoch[49/200] loss: 0.2252812961737315
I0423 09:18:50.129356 12780 trainer.py:142] Test: [{'precision': 0.02362869198312235, 'recall': 0.16459281459281458, 'hit_ratio': 0.3755274261603376, 'ndcg': 0.07614538896101694}]
I0423 09:18:51.129576 12780 trainer.py:136] Epoch[50/200] loss: 0.20917554398377736
I0423 09:18:52.127929 12780 trainer.py:136] Epoch[51/200] loss: 0.22671019981304805
I0423 09:18:53.168019 12780 trainer.py:136] Epoch[52/200] loss: 0.2118606557448705
I0423 09:18:54.161349 12780 trainer.py:136] Epoch[53/200] loss: 0.20807052701711654
I0423 09:18:55.150695 12780 trainer.py:136] Epoch[54/200] loss: 0.19631590098142623
I0423 09:18:56.159039 12780 trainer.py:136] Epoch[55/200] loss: 0.21761732101440429
I0423 09:18:57.191159 12780 trainer.py:136] Epoch[56/200] loss: 0.21400487770636875
I0423 09:18:58.180462 12780 trainer.py:136] Epoch[57/200] loss: 0.20388011584679286
I0423 09:18:59.176776 12780 trainer.py:136] Epoch[58/200] loss: 0.2012011428674062
I0423 09:19:00.188995 12780 trainer.py:136] Epoch[59/200] loss: 0.21157779941956203
I0423 09:19:01.213151 12780 trainer.py:136] Epoch[60/200] loss: 0.20619209011395773
I0423 09:19:02.204450 12780 trainer.py:136] Epoch[61/200] loss: 0.20638233820597332
I0423 09:19:03.207675 12780 trainer.py:136] Epoch[62/200] loss: 0.198634106417497
I0423 09:19:04.231791 12780 trainer.py:136] Epoch[63/200] loss: 0.1891012931863467
I0423 09:19:05.234706 12780 trainer.py:136] Epoch[64/200] loss: 0.1848203122615814
I0423 09:19:06.228985 12780 trainer.py:136] Epoch[65/200] loss: 0.19320965160926182
I0423 09:19:07.243165 12780 trainer.py:136] Epoch[66/200] loss: 0.19704670583208403
I0423 09:19:08.245137 12780 trainer.py:136] Epoch[67/200] loss: 0.20107107733686766
I0423 09:19:09.232979 12780 trainer.py:136] Epoch[68/200] loss: 0.1839526265859604
I0423 09:19:10.231106 12780 trainer.py:136] Epoch[69/200] loss: 0.1875592922170957
I0423 09:19:11.250346 12780 trainer.py:136] Epoch[70/200] loss: 0.196775687734286
I0423 09:19:12.254626 12780 trainer.py:136] Epoch[71/200] loss: 0.19513955761988958
I0423 09:19:13.260864 12780 trainer.py:136] Epoch[72/200] loss: 0.19021751657128333
I0423 09:19:14.256690 12780 trainer.py:136] Epoch[73/200] loss: 0.19706296771764756
I0423 09:19:15.263895 12780 trainer.py:136] Epoch[74/200] loss: 0.19609841754039128
I0423 09:19:16.254223 12780 trainer.py:136] Epoch[75/200] loss: 0.18797586212555567
I0423 09:19:17.275409 12780 trainer.py:136] Epoch[76/200] loss: 0.1797338972489039
I0423 09:19:18.287597 12780 trainer.py:136] Epoch[77/200] loss: 0.17737869570652645
I0423 09:19:19.286874 12780 trainer.py:136] Epoch[78/200] loss: 0.18261535391211509
I0423 09:19:20.297093 12780 trainer.py:136] Epoch[79/200] loss: 0.19096999640266102
I0423 09:19:21.308275 12780 trainer.py:136] Epoch[80/200] loss: 0.1757079005241394
I0423 09:19:22.324476 12780 trainer.py:136] Epoch[81/200] loss: 0.18153631140788395
I0423 09:19:23.352603 12780 trainer.py:136] Epoch[82/200] loss: 0.188091575105985
I0423 09:19:24.423598 12780 trainer.py:136] Epoch[83/200] loss: 0.1771025463938713
I0423 09:19:25.516526 12780 trainer.py:136] Epoch[84/200] loss: 0.17668760518232982
I0423 09:19:26.591466 12780 trainer.py:136] Epoch[85/200] loss: 0.175893617918094
I0423 09:19:27.615637 12780 trainer.py:136] Epoch[86/200] loss: 0.17254779736200967
I0423 09:19:28.614853 12780 trainer.py:136] Epoch[87/200] loss: 0.1856730669736862
I0423 09:19:29.636012 12780 trainer.py:136] Epoch[88/200] loss: 0.18537597060203553
I0423 09:19:30.633314 12780 trainer.py:136] Epoch[89/200] loss: 0.17695225775241852
I0423 09:19:31.638584 12780 trainer.py:136] Epoch[90/200] loss: 0.18036798611283303
I0423 09:19:32.645762 12780 trainer.py:136] Epoch[91/200] loss: 0.17690511147181193
I0423 09:19:33.667809 12780 trainer.py:136] Epoch[92/200] loss: 0.17989163796106974
I0423 09:19:34.692375 12780 trainer.py:136] Epoch[93/200] loss: 0.18183474093675614
I0423 09:19:35.715796 12780 trainer.py:136] Epoch[94/200] loss: 0.17186757028102875
I0423 09:19:36.723045 12780 trainer.py:136] Epoch[95/200] loss: 0.1712715076903502
I0423 09:19:37.741856 12780 trainer.py:136] Epoch[96/200] loss: 0.1758760223786036
I0423 09:19:38.761139 12780 trainer.py:136] Epoch[97/200] loss: 0.18277751356363298
I0423 09:19:39.759653 12780 trainer.py:136] Epoch[98/200] loss: 0.16765630791584651
I0423 09:19:40.771512 12780 trainer.py:136] Epoch[99/200] loss: 0.1863405908147494
I0423 09:19:40.793432 12780 trainer.py:142] Test: [{'precision': 0.024683544303797444, 'recall': 0.16788681313997766, 'hit_ratio': 0.4008438818565401, 'ndcg': 0.08107993385168416}]
I0423 09:19:41.792281 12780 trainer.py:136] Epoch[100/200] loss: 0.16850492358207703
I0423 09:19:42.821889 12780 trainer.py:136] Epoch[101/200] loss: 0.17599319765965143
I0423 09:19:43.821123 12780 trainer.py:136] Epoch[102/200] loss: 0.16977260957161586
I0423 09:19:44.808393 12780 trainer.py:136] Epoch[103/200] loss: 0.17412364333868027
I0423 09:19:45.802706 12780 trainer.py:136] Epoch[104/200] loss: 0.1737202872832616
I0423 09:19:46.780003 12780 trainer.py:136] Epoch[105/200] loss: 0.172933558622996
I0423 09:19:47.786848 12780 trainer.py:136] Epoch[106/200] loss: 0.17073413307468097
I0423 09:19:48.746637 12780 trainer.py:136] Epoch[107/200] loss: 0.17017002974947293
I0423 09:19:49.746994 12780 trainer.py:136] Epoch[108/200] loss: 0.16237722237904867
I0423 09:19:50.767178 12780 trainer.py:136] Epoch[109/200] loss: 0.16039536197980245
I0423 09:19:51.767535 12780 trainer.py:136] Epoch[110/200] loss: 0.1586512344578902
I0423 09:19:52.786234 12780 trainer.py:136] Epoch[111/200] loss: 0.17599278191725412
I0423 09:19:53.796441 12780 trainer.py:136] Epoch[112/200] loss: 0.16392793208360673
I0423 09:19:54.814596 12780 trainer.py:136] Epoch[113/200] loss: 0.17474002291758856
I0423 09:19:55.888590 12780 trainer.py:136] Epoch[114/200] loss: 0.17177998026212057
I0423 09:19:56.960624 12780 trainer.py:136] Epoch[115/200] loss: 0.1613526999950409
I0423 09:19:57.993727 12780 trainer.py:136] Epoch[116/200] loss: 0.1661570337911447
I0423 09:19:59.067410 12780 trainer.py:136] Epoch[117/200] loss: 0.16380899821718534
I0423 09:20:00.112483 12780 trainer.py:136] Epoch[118/200] loss: 0.1649105797211329
I0423 09:20:01.117075 12780 trainer.py:136] Epoch[119/200] loss: 0.16123297611872356
I0423 09:20:02.127301 12780 trainer.py:136] Epoch[120/200] loss: 0.16455588539441426
I0423 09:20:03.142480 12780 trainer.py:136] Epoch[121/200] loss: 0.1574823039273421
I0423 09:20:04.133796 12780 trainer.py:136] Epoch[122/200] loss: 0.15763823091983795
I0423 09:20:05.127124 12780 trainer.py:136] Epoch[123/200] loss: 0.15649844706058502
I0423 09:20:06.150288 12780 trainer.py:136] Epoch[124/200] loss: 0.16483233521382015
I0423 09:20:07.161480 12780 trainer.py:136] Epoch[125/200] loss: 0.1596160148580869
I0423 09:20:08.162021 12780 trainer.py:136] Epoch[126/200] loss: 0.15972436616818111
I0423 09:20:09.171350 12780 trainer.py:136] Epoch[127/200] loss: 0.16372398808598518
I0423 09:20:10.181521 12780 trainer.py:136] Epoch[128/200] loss: 0.16236620669563612
I0423 09:20:11.206663 12780 trainer.py:136] Epoch[129/200] loss: 0.1604498642186324
I0423 09:20:12.187982 12780 trainer.py:136] Epoch[130/200] loss: 0.15575822268923123
I0423 09:20:13.200190 12780 trainer.py:136] Epoch[131/200] loss: 0.16360867073138555
I0423 09:20:14.191428 12780 trainer.py:136] Epoch[132/200] loss: 0.15649468700091043
I0423 09:20:15.191668 12780 trainer.py:136] Epoch[133/200] loss: 0.18524373695254326
I0423 09:20:16.188904 12780 trainer.py:136] Epoch[134/200] loss: 0.15504494508107503
I0423 09:20:17.191163 12780 trainer.py:136] Epoch[135/200] loss: 0.16718768452604613
I0423 09:20:18.175558 12780 trainer.py:136] Epoch[136/200] loss: 0.16991340816020967
I0423 09:20:19.175765 12780 trainer.py:136] Epoch[137/200] loss: 0.16418075263500215
I0423 09:20:20.177060 12780 trainer.py:136] Epoch[138/200] loss: 0.15896823902924856
I0423 09:20:21.215253 12780 trainer.py:136] Epoch[139/200] loss: 0.15871668408314388
I0423 09:20:22.212494 12780 trainer.py:136] Epoch[140/200] loss: 0.16014852076768876
I0423 09:20:23.219000 12780 trainer.py:136] Epoch[141/200] loss: 0.15348076994220416
I0423 09:20:24.225615 12780 trainer.py:136] Epoch[142/200] loss: 0.15492887025078136
I0423 09:20:25.238817 12780 trainer.py:136] Epoch[143/200] loss: 0.1634527454773585
I0423 09:20:26.257781 12780 trainer.py:136] Epoch[144/200] loss: 0.1553034690519174
I0423 09:20:27.305835 12780 trainer.py:136] Epoch[145/200] loss: 0.1484958790242672
I0423 09:20:28.387251 12780 trainer.py:136] Epoch[146/200] loss: 0.15832258487741152
I0423 09:20:29.400432 12780 trainer.py:136] Epoch[147/200] loss: 0.15487602824966112
I0423 09:20:30.435560 12780 trainer.py:136] Epoch[148/200] loss: 0.1576609363158544
I0423 09:20:31.436793 12780 trainer.py:136] Epoch[149/200] loss: 0.16095997939507167
I0423 09:20:31.456726 12780 trainer.py:142] Test: [{'precision': 0.024683544303797444, 'recall': 0.16958361844437793, 'hit_ratio': 0.3881856540084388, 'ndcg': 0.08054474827663103}]
I0423 09:20:32.460022 12780 trainer.py:136] Epoch[150/200] loss: 0.16401350299517314
I0423 09:20:33.467208 12780 trainer.py:136] Epoch[151/200] loss: 0.1675812490284443
I0423 09:20:34.477457 12780 trainer.py:136] Epoch[152/200] loss: 0.1605099231004715
I0423 09:20:35.477324 12780 trainer.py:136] Epoch[153/200] loss: 0.15794355149070421
I0423 09:20:36.473126 12780 trainer.py:136] Epoch[154/200] loss: 0.15475168252984683
I0423 09:20:37.454433 12780 trainer.py:136] Epoch[155/200] loss: 0.16671953350305557
I0423 09:20:38.455311 12780 trainer.py:136] Epoch[156/200] loss: 0.15631536146004996
I0423 09:20:39.463555 12780 trainer.py:136] Epoch[157/200] loss: 0.16373296802242596
I0423 09:20:40.507089 12780 trainer.py:136] Epoch[158/200] loss: 0.1580473800500234
I0423 09:20:41.545172 12780 trainer.py:136] Epoch[159/200] loss: 0.16164835219581922
I0423 09:20:42.574322 12780 trainer.py:136] Epoch[160/200] loss: 0.15913173258304597
I0423 09:20:43.583549 12780 trainer.py:136] Epoch[161/200] loss: 0.1575530268251896
I0423 09:20:44.586342 12780 trainer.py:136] Epoch[162/200] loss: 0.1522564840813478
I0423 09:20:45.586541 12780 trainer.py:136] Epoch[163/200] loss: 0.15802639921506245
I0423 09:20:46.598765 12780 trainer.py:136] Epoch[164/200] loss: 0.15165638451774915
I0423 09:20:47.637870 12780 trainer.py:136] Epoch[165/200] loss: 0.15673722177743912
I0423 09:20:48.696520 12780 trainer.py:136] Epoch[166/200] loss: 0.16131354222695032
I0423 09:20:49.714691 12780 trainer.py:136] Epoch[167/200] loss: 0.16768596520026524
I0423 09:20:50.702923 12780 trainer.py:136] Epoch[168/200] loss: 0.15017722845077514
I0423 09:20:51.712002 12780 trainer.py:136] Epoch[169/200] loss: 0.16072903275489808
I0423 09:20:52.743101 12780 trainer.py:136] Epoch[170/200] loss: 0.15678716227412223
I0423 09:20:53.774211 12780 trainer.py:136] Epoch[171/200] loss: 0.16107572813828785
I0423 09:20:54.895580 12780 trainer.py:136] Epoch[172/200] loss: 0.1578166700899601
I0423 09:20:56.273563 12780 trainer.py:136] Epoch[173/200] loss: 0.14841946959495544
I0423 09:20:57.858421 12780 trainer.py:136] Epoch[174/200] loss: 0.1617390272517999
I0423 09:20:59.530382 12780 trainer.py:136] Epoch[175/200] loss: 0.15554286912083626
I0423 09:21:01.218913 12780 trainer.py:136] Epoch[176/200] loss: 0.15497797255714735
I0423 09:21:02.915397 12780 trainer.py:136] Epoch[177/200] loss: 0.15509897048274676
I0423 09:21:04.568463 12780 trainer.py:136] Epoch[178/200] loss: 0.15870311881105106
I0423 09:21:06.280878 12780 trainer.py:136] Epoch[179/200] loss: 0.1641968088845412
I0423 09:21:07.989300 12780 trainer.py:136] Epoch[180/200] loss: 0.17389527186751366
I0423 09:21:09.656286 12780 trainer.py:136] Epoch[181/200] loss: 0.14717781022191048
I0423 09:21:11.328849 12780 trainer.py:136] Epoch[182/200] loss: 0.15616985857486726
I0423 09:21:13.012346 12780 trainer.py:136] Epoch[183/200] loss: 0.14854609792431195
I0423 09:21:14.679630 12780 trainer.py:136] Epoch[184/200] loss: 0.15671648904681207
I0423 09:21:16.350939 12780 trainer.py:136] Epoch[185/200] loss: 0.15110743989547093
I0423 09:21:18.008659 12780 trainer.py:136] Epoch[186/200] loss: 0.1505217877527078
I0423 09:21:19.672666 12780 trainer.py:136] Epoch[187/200] loss: 0.15506662676731744
I0423 09:21:21.350315 12780 trainer.py:136] Epoch[188/200] loss: 0.16383264710505804
I0423 09:21:23.017882 12780 trainer.py:136] Epoch[189/200] loss: 0.15555979559818903
I0423 09:21:24.674901 12780 trainer.py:136] Epoch[190/200] loss: 0.15230774854620296
I0423 09:21:26.344507 12780 trainer.py:136] Epoch[191/200] loss: 0.15406893814603487
I0423 09:21:28.012038 12780 trainer.py:136] Epoch[192/200] loss: 0.1458881730834643
I0423 09:21:29.678061 12780 trainer.py:136] Epoch[193/200] loss: 0.15448789298534393
I0423 09:21:31.363546 12780 trainer.py:136] Epoch[194/200] loss: 0.15262011662125588
I0423 09:21:33.038141 12780 trainer.py:136] Epoch[195/200] loss: 0.16539221679170926
I0423 09:21:34.389173 12780 trainer.py:136] Epoch[196/200] loss: 0.1469952307641506
I0423 09:21:35.712384 12780 trainer.py:136] Epoch[197/200] loss: 0.15068388655781745
I0423 09:21:36.985265 12780 trainer.py:136] Epoch[198/200] loss: 0.15059076646963757
I0423 09:21:37.984519 12780 trainer.py:136] Epoch[199/200] loss: 0.16249362776676815
I0423 09:21:38.004452 12780 trainer.py:142] Test: [{'precision': 0.025105485232067484, 'recall': 0.16963143841624847, 'hit_ratio': 0.4008438818565401, 'ndcg': 0.080167945012142694}]
