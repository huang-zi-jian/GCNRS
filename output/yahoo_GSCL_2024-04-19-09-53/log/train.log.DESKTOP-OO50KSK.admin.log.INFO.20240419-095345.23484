I0419 09:53:50.383343 20188 trainer.py:121] Test: [{'precision': 0.007091900965169954, 'recall': 0.08479873975048123, 'hit_ratio': 0.1351237935375577, 'ndcg': 0.038579494007350716}]
I0419 09:53:56.848598 20188 trainer.py:139] Epoch[0/1000] loss: 0.5444302438728271
I0419 09:54:03.505856 20188 trainer.py:139] Epoch[1/1000] loss: 0.4988032358307992
I0419 09:54:09.992536 20188 trainer.py:139] Epoch[2/1000] loss: 0.4559118454494784
I0419 09:54:16.680711 20188 trainer.py:139] Epoch[3/1000] loss: 0.40797582653261
I0419 09:54:23.190936 20188 trainer.py:139] Epoch[4/1000] loss: 0.3755537382056636
I0419 09:54:29.612010 20188 trainer.py:139] Epoch[5/1000] loss: 0.34477979569665845
I0419 09:54:36.444765 20188 trainer.py:139] Epoch[6/1000] loss: 0.3245269718670076
I0419 09:54:43.072641 20188 trainer.py:139] Epoch[7/1000] loss: 0.3085069031484665
I0419 09:54:50.082189 20188 trainer.py:139] Epoch[8/1000] loss: 0.2933859272349265
I0419 09:54:57.730648 20188 trainer.py:139] Epoch[9/1000] loss: 0.28201191607982884
I0419 09:55:05.253162 20188 trainer.py:139] Epoch[10/1000] loss: 0.27291959379949876
I0419 09:55:12.304945 20188 trainer.py:139] Epoch[11/1000] loss: 0.26358226566545423
I0419 09:55:19.636484 20188 trainer.py:139] Epoch[12/1000] loss: 0.25207921742431577
I0419 09:55:26.656980 20188 trainer.py:139] Epoch[13/1000] loss: 0.24429603353623422
I0419 09:55:33.660422 20188 trainer.py:139] Epoch[14/1000] loss: 0.23648016755619355
I0419 09:55:40.758471 20188 trainer.py:139] Epoch[15/1000] loss: 0.23158695212294977
I0419 09:55:47.646507 20188 trainer.py:139] Epoch[16/1000] loss: 0.2229193504298887
I0419 09:55:54.509628 20188 trainer.py:139] Epoch[17/1000] loss: 0.21985527079912923
I0419 09:56:01.778628 20188 trainer.py:139] Epoch[18/1000] loss: 0.21494249855318376
I0419 09:56:08.944011 20188 trainer.py:139] Epoch[19/1000] loss: 0.21014579529723815
I0419 09:56:16.080252 20188 trainer.py:139] Epoch[20/1000] loss: 0.2067562702202028
I0419 09:56:23.430331 20188 trainer.py:139] Epoch[21/1000] loss: 0.20372623637799295
I0419 09:56:30.457886 20188 trainer.py:139] Epoch[22/1000] loss: 0.19860477673430596
I0419 09:56:37.625960 20188 trainer.py:139] Epoch[23/1000] loss: 0.1964696710628848
I0419 09:56:44.883816 20188 trainer.py:139] Epoch[24/1000] loss: 0.1930965706706047
I0419 09:56:52.269812 20188 trainer.py:139] Epoch[25/1000] loss: 0.19073046791938045
I0419 09:56:59.328227 20188 trainer.py:139] Epoch[26/1000] loss: 0.18976779786809797
I0419 09:57:06.711020 20188 trainer.py:139] Epoch[27/1000] loss: 0.1868343199453046
I0419 09:57:14.082420 20188 trainer.py:139] Epoch[28/1000] loss: 0.18414954961307586
I0419 09:57:21.428255 20188 trainer.py:139] Epoch[29/1000] loss: 0.18021300915748842
I0419 09:57:28.528987 20188 trainer.py:139] Epoch[30/1000] loss: 0.1787068425647674
I0419 09:57:35.467221 20188 trainer.py:139] Epoch[31/1000] loss: 0.1784444547468616
I0419 09:57:42.322432 20188 trainer.py:139] Epoch[32/1000] loss: 0.17793642633384274
I0419 09:57:49.325755 20188 trainer.py:139] Epoch[33/1000] loss: 0.17293988793127
I0419 09:57:56.218717 20188 trainer.py:139] Epoch[34/1000] loss: 0.1728191503113316
I0419 09:58:03.476166 20188 trainer.py:139] Epoch[35/1000] loss: 0.16969939345313656
I0419 09:58:10.640230 20188 trainer.py:139] Epoch[36/1000] loss: 0.16835295096520456
I0419 09:58:17.843904 20188 trainer.py:139] Epoch[37/1000] loss: 0.16727409127258486
I0419 09:58:24.989898 20188 trainer.py:139] Epoch[38/1000] loss: 0.16644550787825738
I0419 09:58:32.338009 20188 trainer.py:139] Epoch[39/1000] loss: 0.16630685617846827
I0419 09:58:39.870579 20188 trainer.py:139] Epoch[40/1000] loss: 0.16450308479609027
I0419 09:58:46.954806 20188 trainer.py:139] Epoch[41/1000] loss: 0.16055358874221
I0419 09:58:54.093707 20188 trainer.py:139] Epoch[42/1000] loss: 0.16073362048595183
I0419 09:59:00.896686 20188 trainer.py:139] Epoch[43/1000] loss: 0.15732208639383316
I0419 09:59:07.993311 20188 trainer.py:139] Epoch[44/1000] loss: 0.15717443847848522
I0419 09:59:14.851887 20188 trainer.py:139] Epoch[45/1000] loss: 0.15654344376056425
I0419 09:59:22.000216 20188 trainer.py:139] Epoch[46/1000] loss: 0.15451830385192747
I0419 09:59:29.272511 20188 trainer.py:139] Epoch[47/1000] loss: 0.15212692632790534
I0419 09:59:36.510007 20188 trainer.py:139] Epoch[48/1000] loss: 0.15317644226935603
I0419 09:59:43.749394 20188 trainer.py:139] Epoch[49/1000] loss: 0.1513612782282214
I0419 09:59:44.324066 20188 trainer.py:145] Test: [{'precision': 0.011644985312631143, 'recall': 0.14719258104696628, 'hit_ratio': 0.2224087284934956, 'ndcg': 0.06902397027927144}]
I0419 09:59:51.665397 20188 trainer.py:139] Epoch[50/1000] loss: 0.14931944156846694
I0419 09:59:58.904459 20188 trainer.py:139] Epoch[51/1000] loss: 0.14947295982030132
I0419 10:00:05.855164 20188 trainer.py:139] Epoch[52/1000] loss: 0.14831210648821247
I0419 10:00:13.099013 20188 trainer.py:139] Epoch[53/1000] loss: 0.14679710014212516
I0419 10:00:20.167340 20188 trainer.py:139] Epoch[54/1000] loss: 0.14646507318942778
I0419 10:00:27.473229 20188 trainer.py:139] Epoch[55/1000] loss: 0.1442558188592234
I0419 10:00:34.774277 20188 trainer.py:139] Epoch[56/1000] loss: 0.14556902887359743
I0419 10:00:41.817716 20188 trainer.py:139] Epoch[57/1000] loss: 0.14132902206432435
I0419 10:00:48.589025 20188 trainer.py:139] Epoch[58/1000] loss: 0.14320639677105412
I0419 10:00:56.072160 20188 trainer.py:139] Epoch[59/1000] loss: 0.14164352633299365
I0419 10:01:03.177362 20188 trainer.py:139] Epoch[60/1000] loss: 0.14012596575963882
I0419 10:01:10.234558 20188 trainer.py:139] Epoch[61/1000] loss: 0.14071448519825935
I0419 10:01:17.173692 20188 trainer.py:139] Epoch[62/1000] loss: 0.13793511460385016
I0419 10:01:24.265602 20188 trainer.py:139] Epoch[63/1000] loss: 0.13635842514134222
I0419 10:01:31.288687 20188 trainer.py:139] Epoch[64/1000] loss: 0.13764713416176458
I0419 10:01:38.255357 20188 trainer.py:139] Epoch[65/1000] loss: 0.13384409248828888
I0419 10:01:45.111153 20188 trainer.py:139] Epoch[66/1000] loss: 0.13451909382016428
I0419 10:01:52.188314 20188 trainer.py:139] Epoch[67/1000] loss: 0.13171448402347102
I0419 10:01:59.188798 20188 trainer.py:139] Epoch[68/1000] loss: 0.13086832555071
I0419 10:02:06.560186 20188 trainer.py:139] Epoch[69/1000] loss: 0.1322238757725685
I0419 10:02:13.549878 20188 trainer.py:139] Epoch[70/1000] loss: 0.1320761865185153
I0419 10:02:20.804792 20188 trainer.py:139] Epoch[71/1000] loss: 0.1303401671109661
I0419 10:02:27.987023 20188 trainer.py:139] Epoch[72/1000] loss: 0.12765027150031058
I0419 10:02:35.054807 20188 trainer.py:139] Epoch[73/1000] loss: 0.12746631053666915
I0419 10:02:42.054357 20188 trainer.py:139] Epoch[74/1000] loss: 0.1286449854172045
I0419 10:02:49.109707 20188 trainer.py:139] Epoch[75/1000] loss: 0.12747216537114112
I0419 10:02:56.093426 20188 trainer.py:139] Epoch[76/1000] loss: 0.12593337833400695
I0419 10:03:03.345783 20188 trainer.py:139] Epoch[77/1000] loss: 0.12572726871698134
I0419 10:03:10.621354 20188 trainer.py:139] Epoch[78/1000] loss: 0.12547695228169042
I0419 10:03:17.713602 20188 trainer.py:139] Epoch[79/1000] loss: 0.12415794391305215
I0419 10:03:25.150130 20188 trainer.py:139] Epoch[80/1000] loss: 0.12434179948702935
I0419 10:03:32.718961 20188 trainer.py:139] Epoch[81/1000] loss: 0.12295191518722041
I0419 10:03:40.002143 20188 trainer.py:139] Epoch[82/1000] loss: 0.121536705162256
I0419 10:03:47.398361 20188 trainer.py:139] Epoch[83/1000] loss: 0.12093927458890023
I0419 10:03:55.100741 20188 trainer.py:139] Epoch[84/1000] loss: 0.12191705850343551
I0419 10:04:02.703096 20188 trainer.py:139] Epoch[85/1000] loss: 0.11924594652748877
I0419 10:04:10.610891 20188 trainer.py:139] Epoch[86/1000] loss: 0.11872188302297745
I0419 10:04:18.300929 20188 trainer.py:139] Epoch[87/1000] loss: 0.11817175522446632
I0419 10:04:26.115376 20188 trainer.py:139] Epoch[88/1000] loss: 0.11865120597424046
I0419 10:04:34.461568 20188 trainer.py:139] Epoch[89/1000] loss: 0.11658763705242065
I0419 10:04:44.944238 20188 trainer.py:139] Epoch[90/1000] loss: 0.11895195310634951
I0419 10:04:53.180901 20188 trainer.py:139] Epoch[91/1000] loss: 0.11815597549561531
I0419 10:05:03.748073 20188 trainer.py:139] Epoch[92/1000] loss: 0.11442644870088946
I0419 10:05:11.852586 20188 trainer.py:139] Epoch[93/1000] loss: 0.11536970338033091
I0419 10:05:19.876128 20188 trainer.py:139] Epoch[94/1000] loss: 0.11599733512247762
I0419 10:05:28.883107 20188 trainer.py:139] Epoch[95/1000] loss: 0.11413636154705478
I0419 10:05:37.702198 20188 trainer.py:139] Epoch[96/1000] loss: 0.11338716288728098
I0419 10:05:45.543416 20188 trainer.py:139] Epoch[97/1000] loss: 0.11321467762031863
I0419 10:05:53.623823 20188 trainer.py:139] Epoch[98/1000] loss: 0.11388389393687248
I0419 10:06:03.606998 20188 trainer.py:139] Epoch[99/1000] loss: 0.11101748217498103
I0419 10:06:04.258381 20188 trainer.py:145] Test: [{'precision': 0.012106588334032739, 'recall': 0.1552862871264046, 'hit_ratio': 0.22912295425933696, 'ndcg': 0.07364728761102785}]
I0419 10:06:13.026577 20188 trainer.py:139] Epoch[100/1000] loss: 0.10961949428723704
I0419 10:06:22.854409 20188 trainer.py:139] Epoch[101/1000] loss: 0.11251706497803811
I0419 10:06:31.092965 20188 trainer.py:139] Epoch[102/1000] loss: 0.10997951307123707
I0419 10:06:38.997520 20188 trainer.py:139] Epoch[103/1000] loss: 0.10985620536150471
I0419 10:06:46.865605 20188 trainer.py:139] Epoch[104/1000] loss: 0.11050966442112
I0419 10:06:57.130158 20188 trainer.py:139] Epoch[105/1000] loss: 0.10901632171965414
I0419 10:07:05.134105 20188 trainer.py:139] Epoch[106/1000] loss: 0.10857424548556728
I0419 10:07:14.874704 20188 trainer.py:139] Epoch[107/1000] loss: 0.10824522856743105
I0419 10:07:24.214176 20188 trainer.py:139] Epoch[108/1000] loss: 0.10697923468485955
I0419 10:07:33.485949 20188 trainer.py:139] Epoch[109/1000] loss: 0.10827534393437448
I0419 10:07:44.703546 20188 trainer.py:139] Epoch[110/1000] loss: 0.10580471025839928
I0419 10:07:55.728962 20188 trainer.py:139] Epoch[111/1000] loss: 0.10456608247853094
I0419 10:08:03.858332 20188 trainer.py:139] Epoch[112/1000] loss: 0.10656135469194382
I0419 10:08:14.405806 20188 trainer.py:139] Epoch[113/1000] loss: 0.10456548114457438
I0419 10:08:22.594929 20188 trainer.py:139] Epoch[114/1000] loss: 0.10380569857455069
I0419 10:08:33.965358 20188 trainer.py:139] Epoch[115/1000] loss: 0.1050047974192327
I0419 10:08:43.809232 20188 trainer.py:139] Epoch[116/1000] loss: 0.10465673681709074
I0419 10:08:52.948574 20188 trainer.py:139] Epoch[117/1000] loss: 0.10347629470690604
I0419 10:09:02.070489 20188 trainer.py:139] Epoch[118/1000] loss: 0.10250268071409195
I0419 10:09:11.824573 20188 trainer.py:139] Epoch[119/1000] loss: 0.10189038755432252
I0419 10:09:20.740860 20188 trainer.py:139] Epoch[120/1000] loss: 0.10219339894190911
I0419 10:09:30.764497 20188 trainer.py:139] Epoch[121/1000] loss: 0.10124958979506646
I0419 10:09:39.917022 20188 trainer.py:139] Epoch[122/1000] loss: 0.10069922718309587
I0419 10:09:49.976479 20188 trainer.py:139] Epoch[123/1000] loss: 0.10081420117808927
I0419 10:09:59.884329 20188 trainer.py:139] Epoch[124/1000] loss: 0.10139377715606843
I0419 10:10:09.909646 20188 trainer.py:139] Epoch[125/1000] loss: 0.09958104993547162
I0419 10:10:20.518856 20188 trainer.py:139] Epoch[126/1000] loss: 0.0986151022295798
I0419 10:10:28.861435 20188 trainer.py:139] Epoch[127/1000] loss: 0.10029678575454219
I0419 10:10:39.614449 20188 trainer.py:139] Epoch[128/1000] loss: 0.09863965465657172
I0419 10:10:48.064685 20188 trainer.py:139] Epoch[129/1000] loss: 0.09984477357037606
I0419 10:10:58.854099 20188 trainer.py:139] Epoch[130/1000] loss: 0.09852222906004998
I0419 10:11:07.287255 20188 trainer.py:139] Epoch[131/1000] loss: 0.09721439475974729
I0419 10:11:17.948055 20188 trainer.py:139] Epoch[132/1000] loss: 0.09815323665257424
I0419 10:11:26.571027 20188 trainer.py:139] Epoch[133/1000] loss: 0.0960071894430345
I0419 10:11:37.391961 20188 trainer.py:139] Epoch[134/1000] loss: 0.09730791036159761
I0419 10:11:48.160687 20188 trainer.py:139] Epoch[135/1000] loss: 0.09701804263937858
I0419 10:11:56.859228 20188 trainer.py:139] Epoch[136/1000] loss: 0.09571665525436401
I0419 10:12:07.682040 20188 trainer.py:139] Epoch[137/1000] loss: 0.09472463532320914
I0419 10:12:16.121716 20188 trainer.py:139] Epoch[138/1000] loss: 0.09671339909395864
I0419 10:12:26.715567 20188 trainer.py:139] Epoch[139/1000] loss: 0.09737988633494224
I0419 10:12:35.295949 20188 trainer.py:139] Epoch[140/1000] loss: 0.09438028955651868
I0419 10:12:46.508439 20188 trainer.py:139] Epoch[141/1000] loss: 0.09363804685492669
I0419 10:12:54.880685 20188 trainer.py:139] Epoch[142/1000] loss: 0.09513397082205742
I0419 10:13:05.746830 20188 trainer.py:139] Epoch[143/1000] loss: 0.09438737361661849
I0419 10:13:14.435353 20188 trainer.py:139] Epoch[144/1000] loss: 0.09619109380629755
I0419 10:13:25.014708 20188 trainer.py:139] Epoch[145/1000] loss: 0.09481763899807007
I0419 10:13:33.101256 20188 trainer.py:139] Epoch[146/1000] loss: 0.09206590200624158
I0419 10:13:43.751478 20188 trainer.py:139] Epoch[147/1000] loss: 0.09440340125753034
I0419 10:13:52.791452 20188 trainer.py:139] Epoch[148/1000] loss: 0.09231522811516639
I0419 10:14:03.196452 20188 trainer.py:139] Epoch[149/1000] loss: 0.09237855384426732
I0419 10:14:03.922025 20188 trainer.py:145] Test: [{'precision': 0.01261015526647084, 'recall': 0.16402160808371466, 'hit_ratio': 0.23835501468736886, 'ndcg': 0.07752007905191051}]
I0419 10:14:14.955385 20188 trainer.py:139] Epoch[150/1000] loss: 0.09117058568423794
I0419 10:14:23.261596 20188 trainer.py:139] Epoch[151/1000] loss: 0.09299956226060467
I0419 10:14:33.832229 20188 trainer.py:139] Epoch[152/1000] loss: 0.09073184178240838
I0419 10:14:41.926624 20188 trainer.py:139] Epoch[153/1000] loss: 0.0915109992267624
I0419 10:14:52.425981 20188 trainer.py:139] Epoch[154/1000] loss: 0.09012533844478669
I0419 10:15:00.873869 20188 trainer.py:139] Epoch[155/1000] loss: 0.09127151172968649
I0419 10:15:11.565547 20188 trainer.py:139] Epoch[156/1000] loss: 0.09023227037922028
I0419 10:15:19.663863 20188 trainer.py:139] Epoch[157/1000] loss: 0.08893951569353381
I0419 10:15:29.965357 20188 trainer.py:139] Epoch[158/1000] loss: 0.08924760320974935
I0419 10:15:38.207100 20188 trainer.py:139] Epoch[159/1000] loss: 0.08829130484692511
I0419 10:15:48.669148 20188 trainer.py:139] Epoch[160/1000] loss: 0.08949312615779138
I0419 10:15:56.910691 20188 trainer.py:139] Epoch[161/1000] loss: 0.09085552778936201
I0419 10:16:07.508778 20188 trainer.py:139] Epoch[162/1000] loss: 0.08891103332561831
I0419 10:16:15.809036 20188 trainer.py:139] Epoch[163/1000] loss: 0.0891352738103559
I0419 10:16:26.258162 20188 trainer.py:139] Epoch[164/1000] loss: 0.0887006708691197
I0419 10:16:35.178436 20188 trainer.py:139] Epoch[165/1000] loss: 0.08843389862487393
I0419 10:16:45.553455 20188 trainer.py:139] Epoch[166/1000] loss: 0.08732469223680035
I0419 10:16:54.784757 20188 trainer.py:139] Epoch[167/1000] loss: 0.08778092229077893
I0419 10:17:04.873274 20188 trainer.py:139] Epoch[168/1000] loss: 0.08709949134818969
I0419 10:17:13.573334 20188 trainer.py:139] Epoch[169/1000] loss: 0.08723681948838695
I0419 10:17:24.078876 20188 trainer.py:139] Epoch[170/1000] loss: 0.08640673384070396
I0419 10:17:33.628224 20188 trainer.py:139] Epoch[171/1000] loss: 0.08635716885328293
I0419 10:17:43.437726 20188 trainer.py:139] Epoch[172/1000] loss: 0.0871235313675096
I0419 10:17:54.090010 20188 trainer.py:139] Epoch[173/1000] loss: 0.08608612970959756
I0419 10:18:02.973405 20188 trainer.py:139] Epoch[174/1000] loss: 0.08557211944172459
I0419 10:18:13.885935 20188 trainer.py:139] Epoch[175/1000] loss: 0.08565810803444154
I0419 10:18:22.800879 20188 trainer.py:139] Epoch[176/1000] loss: 0.08712040765150901
I0419 10:18:33.564272 20188 trainer.py:139] Epoch[177/1000] loss: 0.08537519590989236
I0419 10:18:41.602478 20188 trainer.py:139] Epoch[178/1000] loss: 0.08486104816679031
I0419 10:18:52.098151 20188 trainer.py:139] Epoch[179/1000] loss: 0.08556169271469116
I0419 10:19:00.162123 20188 trainer.py:139] Epoch[180/1000] loss: 0.08361235753663125
I0419 10:19:10.863883 20188 trainer.py:139] Epoch[181/1000] loss: 0.08453715592622757
I0419 10:19:19.193261 20188 trainer.py:139] Epoch[182/1000] loss: 0.08439690066922095
I0419 10:19:29.895192 20188 trainer.py:139] Epoch[183/1000] loss: 0.08459558578268174
I0419 10:19:38.128225 20188 trainer.py:139] Epoch[184/1000] loss: 0.08435101771066265
I0419 10:19:49.351974 20188 trainer.py:139] Epoch[185/1000] loss: 0.08481409544906308
I0419 10:19:57.506521 20188 trainer.py:139] Epoch[186/1000] loss: 0.08418133614524718
I0419 10:20:07.817021 20188 trainer.py:139] Epoch[187/1000] loss: 0.0839922201008566
I0419 10:20:16.351293 20188 trainer.py:139] Epoch[188/1000] loss: 0.08285666713791509
I0419 10:20:26.790256 20188 trainer.py:139] Epoch[189/1000] loss: 0.08372177736413094
I0419 10:20:35.178855 20188 trainer.py:139] Epoch[190/1000] loss: 0.08298328026167807
I0419 10:20:46.127770 20188 trainer.py:139] Epoch[191/1000] loss: 0.08315855769380447
I0419 10:20:54.311100 20188 trainer.py:139] Epoch[192/1000] loss: 0.08271219244887752
I0419 10:21:05.094838 20188 trainer.py:139] Epoch[193/1000] loss: 0.08212325157177064
I0419 10:21:14.178917 20188 trainer.py:139] Epoch[194/1000] loss: 0.08274449420071417
I0419 10:21:24.012503 20188 trainer.py:139] Epoch[195/1000] loss: 0.08253405807960418
I0419 10:21:32.148028 20188 trainer.py:139] Epoch[196/1000] loss: 0.0814949655004086
I0419 10:21:42.745221 20188 trainer.py:139] Epoch[197/1000] loss: 0.08160168653534304
I0419 10:21:50.977819 20188 trainer.py:139] Epoch[198/1000] loss: 0.08170006388137417
I0419 10:22:01.345773 20188 trainer.py:139] Epoch[199/1000] loss: 0.08186135597286685
I0419 10:22:02.089285 20188 trainer.py:145] Test: [{'precision': 0.012421317666806549, 'recall': 0.16123100799978682, 'hit_ratio': 0.23373898447335292, 'ndcg': 0.07680802248624277}]
I0419 10:22:10.677641 20188 trainer.py:139] Epoch[200/1000] loss: 0.08132512530972881
I0419 10:22:20.986373 20188 trainer.py:139] Epoch[201/1000] loss: 0.08087390721324951
I0419 10:22:29.390563 20188 trainer.py:139] Epoch[202/1000] loss: 0.07961775338457476
I0419 10:22:39.880359 20188 trainer.py:139] Epoch[203/1000] loss: 0.0803806573873566
I0419 10:22:49.392849 20188 trainer.py:139] Epoch[204/1000] loss: 0.08086419177632179
I0419 10:22:58.474043 20188 trainer.py:139] Epoch[205/1000] loss: 0.08058091409264072
I0419 10:23:07.583659 20188 trainer.py:139] Epoch[206/1000] loss: 0.08007637964140984
I0419 10:23:16.934879 20188 trainer.py:139] Epoch[207/1000] loss: 0.08056841430164152
I0419 10:23:24.922740 20188 trainer.py:139] Epoch[208/1000] loss: 0.0795651089039541
I0419 10:23:35.557708 20188 trainer.py:139] Epoch[209/1000] loss: 0.0805259206362309
I0419 10:23:43.851667 20188 trainer.py:139] Epoch[210/1000] loss: 0.07918487188796844
I0419 10:23:54.578637 20188 trainer.py:139] Epoch[211/1000] loss: 0.08033227127405905
I0419 10:24:02.695848 20188 trainer.py:139] Epoch[212/1000] loss: 0.07923246643716289
I0419 10:24:13.288463 20188 trainer.py:139] Epoch[213/1000] loss: 0.07879214974180344
I0419 10:24:21.539950 20188 trainer.py:139] Epoch[214/1000] loss: 0.07935621192859064
I0419 10:24:32.239114 20188 trainer.py:139] Epoch[215/1000] loss: 0.07941722317088035
I0419 10:24:40.551265 20188 trainer.py:139] Epoch[216/1000] loss: 0.07824062772335545
I0419 10:24:50.754935 20188 trainer.py:139] Epoch[217/1000] loss: 0.07950741473224855
I0419 10:24:58.908184 20188 trainer.py:139] Epoch[218/1000] loss: 0.07859274973311732
I0419 10:25:09.730021 20188 trainer.py:139] Epoch[219/1000] loss: 0.07928944186818215
I0419 10:25:17.882499 20188 trainer.py:139] Epoch[220/1000] loss: 0.07953765579769688
I0419 10:25:28.638791 20188 trainer.py:139] Epoch[221/1000] loss: 0.07870624971485907
I0419 10:25:36.967751 20188 trainer.py:139] Epoch[222/1000] loss: 0.07823965902770719
I0419 10:25:47.395150 20188 trainer.py:139] Epoch[223/1000] loss: 0.07780801264509078
I0419 10:25:55.670060 20188 trainer.py:139] Epoch[224/1000] loss: 0.0779552108818485
I0419 10:26:06.162437 20188 trainer.py:139] Epoch[225/1000] loss: 0.07669135074942343
I0419 10:26:14.313827 20188 trainer.py:139] Epoch[226/1000] loss: 0.0775726335423608
I0419 10:26:24.654539 20188 trainer.py:139] Epoch[227/1000] loss: 0.07824725140967677
I0419 10:26:33.099740 20188 trainer.py:139] Epoch[228/1000] loss: 0.07660320281021056
I0419 10:26:43.742433 20188 trainer.py:139] Epoch[229/1000] loss: 0.07687615981746104
I0419 10:26:51.961763 20188 trainer.py:139] Epoch[230/1000] loss: 0.07619673338147902
I0419 10:27:02.550448 20188 trainer.py:139] Epoch[231/1000] loss: 0.07742863460894554
I0419 10:27:11.037577 20188 trainer.py:139] Epoch[232/1000] loss: 0.07745094981885725
I0419 10:27:22.386559 20188 trainer.py:139] Epoch[233/1000] loss: 0.07707154919062892
I0419 10:27:30.719812 20188 trainer.py:139] Epoch[234/1000] loss: 0.07580415712248895
I0419 10:27:41.705026 20188 trainer.py:139] Epoch[235/1000] loss: 0.07646064123799724
I0419 10:27:52.190039 20188 trainer.py:139] Epoch[236/1000] loss: 0.07692371549144868
I0419 10:28:00.421961 20188 trainer.py:139] Epoch[237/1000] loss: 0.07674946065150923
I0419 10:28:11.006180 20188 trainer.py:139] Epoch[238/1000] loss: 0.07573248133543999
I0419 10:28:19.530319 20188 trainer.py:139] Epoch[239/1000] loss: 0.0760249050874864
I0419 10:28:30.120142 20188 trainer.py:139] Epoch[240/1000] loss: 0.07586634291275855
I0419 10:28:38.314308 20188 trainer.py:139] Epoch[241/1000] loss: 0.07484502423434489
I0419 10:28:48.194153 20188 trainer.py:139] Epoch[242/1000] loss: 0.07592248916625977
I0419 10:28:56.664408 20188 trainer.py:139] Epoch[243/1000] loss: 0.07460233028377256
I0419 10:29:05.340743 20188 trainer.py:139] Epoch[244/1000] loss: 0.07537242842297401
I0419 10:29:15.028527 20188 trainer.py:139] Epoch[245/1000] loss: 0.07527517311034664
I0419 10:29:23.422178 20188 trainer.py:139] Epoch[246/1000] loss: 0.07511632072348748
I0419 10:29:33.876477 20188 trainer.py:139] Epoch[247/1000] loss: 0.0747009888291359
I0419 10:29:42.431312 20188 trainer.py:139] Epoch[248/1000] loss: 0.07592700650134394
I0419 10:29:53.341377 20188 trainer.py:139] Epoch[249/1000] loss: 0.07458022645404262
I0419 10:29:53.999637 20188 trainer.py:145] Test: [{'precision': 0.012526227444397823, 'recall': 0.16138137868100105, 'hit_ratio': 0.23667645824590852, 'ndcg': 0.07780039477617501}]
I0419 10:30:02.504478 20188 trainer.py:139] Epoch[250/1000] loss: 0.07379225713591422
I0419 10:30:12.934783 20188 trainer.py:139] Epoch[251/1000] loss: 0.07592240360475355
I0419 10:30:20.965467 20188 trainer.py:139] Epoch[252/1000] loss: 0.07342302258456906
I0419 10:30:31.487709 20188 trainer.py:139] Epoch[253/1000] loss: 0.0744224813195967
I0419 10:30:39.834415 20188 trainer.py:139] Epoch[254/1000] loss: 0.0746572792770401
I0419 10:30:50.405674 20188 trainer.py:139] Epoch[255/1000] loss: 0.07576233569172121
I0419 10:30:58.706505 20188 trainer.py:139] Epoch[256/1000] loss: 0.07439643180658741
I0419 10:31:09.332634 20188 trainer.py:139] Epoch[257/1000] loss: 0.07541916495369326
I0419 10:31:17.775796 20188 trainer.py:139] Epoch[258/1000] loss: 0.07448967606309921
I0419 10:31:28.136093 20188 trainer.py:139] Epoch[259/1000] loss: 0.07443757535469148
I0419 10:31:36.315417 20188 trainer.py:139] Epoch[260/1000] loss: 0.07447151995954975
I0419 10:31:44.999834 20188 trainer.py:139] Epoch[261/1000] loss: 0.07356695482327093
I0419 10:31:55.043059 20188 trainer.py:139] Epoch[262/1000] loss: 0.07360757719124517
I0419 10:32:03.453688 20188 trainer.py:139] Epoch[263/1000] loss: 0.07407932440119405
I0419 10:32:14.114722 20188 trainer.py:139] Epoch[264/1000] loss: 0.0729216460979754
I0419 10:32:22.400316 20188 trainer.py:139] Epoch[265/1000] loss: 0.07356373268750406
I0419 10:32:33.039396 20188 trainer.py:139] Epoch[266/1000] loss: 0.07390405514067219
I0419 10:32:41.401386 20188 trainer.py:139] Epoch[267/1000] loss: 0.07433044345628831
I0419 10:32:52.198355 20188 trainer.py:139] Epoch[268/1000] loss: 0.0734854321325979
I0419 10:33:00.577842 20188 trainer.py:139] Epoch[269/1000] loss: 0.07320741972615642
I0419 10:33:11.195761 20188 trainer.py:139] Epoch[270/1000] loss: 0.0744021500070249
I0419 10:33:19.645612 20188 trainer.py:139] Epoch[271/1000] loss: 0.07324467971920967
I0419 10:33:30.126540 20188 trainer.py:139] Epoch[272/1000] loss: 0.07290056726384547
I0419 10:33:38.500157 20188 trainer.py:139] Epoch[273/1000] loss: 0.07371129456066317
I0419 10:33:49.114569 20188 trainer.py:139] Epoch[274/1000] loss: 0.07331788245468371
I0419 10:33:57.527533 20188 trainer.py:139] Epoch[275/1000] loss: 0.07341323264183537
I0419 10:34:08.364284 20188 trainer.py:139] Epoch[276/1000] loss: 0.07211508637955112
I0419 10:34:16.657095 20188 trainer.py:139] Epoch[277/1000] loss: 0.07234561551482446
I0419 10:34:27.082935 20188 trainer.py:139] Epoch[278/1000] loss: 0.0726177227352896
I0419 10:34:35.654583 20188 trainer.py:139] Epoch[279/1000] loss: 0.07152998579605933
I0419 10:34:45.891079 20188 trainer.py:139] Epoch[280/1000] loss: 0.07175040893977688
I0419 10:34:54.788490 20188 trainer.py:139] Epoch[281/1000] loss: 0.07196412926479694
I0419 10:35:04.419248 20188 trainer.py:139] Epoch[282/1000] loss: 0.07225515993852769
I0419 10:35:13.632808 20188 trainer.py:139] Epoch[283/1000] loss: 0.07156134547004776
I0419 10:35:23.206382 20188 trainer.py:139] Epoch[284/1000] loss: 0.07175924052153865
I0419 10:35:32.652842 20188 trainer.py:139] Epoch[285/1000] loss: 0.07247740468911586
I0419 10:35:40.757537 20188 trainer.py:139] Epoch[286/1000] loss: 0.0718712225075691
I0419 10:35:51.378992 20188 trainer.py:139] Epoch[287/1000] loss: 0.07106604336971237
I0419 10:35:59.591968 20188 trainer.py:139] Epoch[288/1000] loss: 0.07223712088119599
I0419 10:36:10.276585 20188 trainer.py:139] Epoch[289/1000] loss: 0.07132586590465038
I0419 10:36:18.681263 20188 trainer.py:139] Epoch[290/1000] loss: 0.07287527080024442
I0419 10:36:29.274861 20188 trainer.py:139] Epoch[291/1000] loss: 0.07124640215789119
I0419 10:36:37.380317 20188 trainer.py:139] Epoch[292/1000] loss: 0.07194615443868022
I0419 10:36:47.858037 20188 trainer.py:139] Epoch[293/1000] loss: 0.07151817782751975
I0419 10:36:56.232026 20188 trainer.py:139] Epoch[294/1000] loss: 0.07185762892327001
I0419 10:37:06.790727 20188 trainer.py:139] Epoch[295/1000] loss: 0.07114796833165231
I0419 10:37:15.098260 20188 trainer.py:139] Epoch[296/1000] loss: 0.07197477590412862
I0419 10:37:25.670854 20188 trainer.py:139] Epoch[297/1000] loss: 0.07083489397360433
I0419 10:37:33.942572 20188 trainer.py:139] Epoch[298/1000] loss: 0.07029271029656933
I0419 10:37:44.173753 20188 trainer.py:139] Epoch[299/1000] loss: 0.07118269236337754
I0419 10:37:44.921251 20188 trainer.py:145] Test: [{'precision': 0.012547209399916078, 'recall': 0.1620453077020429, 'hit_ratio': 0.23667645824590852, 'ndcg': 0.07751897983895564}]
I0419 10:37:53.286283 20188 trainer.py:139] Epoch[300/1000] loss: 0.07102769078506578
I0419 10:38:03.805145 20188 trainer.py:139] Epoch[301/1000] loss: 0.07101380055950533
I0419 10:38:12.099815 20188 trainer.py:139] Epoch[302/1000] loss: 0.07060673892978699
I0419 10:38:22.778867 20188 trainer.py:139] Epoch[303/1000] loss: 0.07011292466232853
I0419 10:38:31.248681 20188 trainer.py:139] Epoch[304/1000] loss: 0.0715665674257663
I0419 10:38:41.466701 20188 trainer.py:139] Epoch[305/1000] loss: 0.07102503435265634
I0419 10:38:49.805695 20188 trainer.py:139] Epoch[306/1000] loss: 0.0706582085620011
I0419 10:38:59.200987 20188 trainer.py:139] Epoch[307/1000] loss: 0.07029089073259984
I0419 10:39:08.393162 20188 trainer.py:139] Epoch[308/1000] loss: 0.0712180632737375
I0419 10:39:16.884236 20188 trainer.py:139] Epoch[309/1000] loss: 0.06982056051492691
I0419 10:39:27.060445 20188 trainer.py:139] Epoch[310/1000] loss: 0.07062112816399144
I0419 10:39:35.103096 20188 trainer.py:139] Epoch[311/1000] loss: 0.07090696824654456
I0419 10:39:45.908864 20188 trainer.py:139] Epoch[312/1000] loss: 0.07102598994970322
I0419 10:39:54.078077 20188 trainer.py:139] Epoch[313/1000] loss: 0.0706554988939916
I0419 10:40:04.545932 20188 trainer.py:139] Epoch[314/1000] loss: 0.07110120127758672
I0419 10:40:12.802993 20188 trainer.py:139] Epoch[315/1000] loss: 0.07093242015088758
I0419 10:40:23.198563 20188 trainer.py:139] Epoch[316/1000] loss: 0.06938970389385377
I0419 10:40:31.636761 20188 trainer.py:139] Epoch[317/1000] loss: 0.07011775305915263
I0419 10:40:42.137423 20188 trainer.py:139] Epoch[318/1000] loss: 0.07001501069434228
I0419 10:40:50.416677 20188 trainer.py:139] Epoch[319/1000] loss: 0.06916942843987096
I0419 10:41:00.803317 20188 trainer.py:139] Epoch[320/1000] loss: 0.07037397474050522
I0419 10:41:08.907815 20188 trainer.py:139] Epoch[321/1000] loss: 0.06989236260133405
I0419 10:41:19.516065 20188 trainer.py:139] Epoch[322/1000] loss: 0.06989051738092976
I0419 10:41:28.002419 20188 trainer.py:139] Epoch[323/1000] loss: 0.07014914055264765
I0419 10:41:38.425370 20188 trainer.py:139] Epoch[324/1000] loss: 0.0698638662936226
I0419 10:41:46.953732 20188 trainer.py:139] Epoch[325/1000] loss: 0.06832782407441447
I0419 10:41:57.320333 20188 trainer.py:139] Epoch[326/1000] loss: 0.06889519089412305
I0419 10:42:05.780823 20188 trainer.py:139] Epoch[327/1000] loss: 0.06899259131281607
I0419 10:42:16.288800 20188 trainer.py:139] Epoch[328/1000] loss: 0.06865358364678198
I0419 10:42:24.418198 20188 trainer.py:139] Epoch[329/1000] loss: 0.06903794780373573
I0419 10:42:35.248821 20188 trainer.py:139] Epoch[330/1000] loss: 0.0690759421596604
I0419 10:42:43.571487 20188 trainer.py:139] Epoch[331/1000] loss: 0.06952937632318466
I0419 10:42:53.956621 20188 trainer.py:139] Epoch[332/1000] loss: 0.06902004315728141
I0419 10:43:02.307867 20188 trainer.py:139] Epoch[333/1000] loss: 0.06932228539259203
I0419 10:43:12.938821 20188 trainer.py:139] Epoch[334/1000] loss: 0.06904013040325334
I0419 10:43:21.102126 20188 trainer.py:139] Epoch[335/1000] loss: 0.06864735273824583
I0419 10:43:31.530088 20188 trainer.py:139] Epoch[336/1000] loss: 0.06918535874255242
I0419 10:43:39.631457 20188 trainer.py:139] Epoch[337/1000] loss: 0.06790196559121532
I0419 10:43:49.672608 20188 trainer.py:139] Epoch[338/1000] loss: 0.06856547368149604
I0419 10:43:58.138325 20188 trainer.py:139] Epoch[339/1000] loss: 0.06918170513404955
I0419 10:44:08.257017 20188 trainer.py:139] Epoch[340/1000] loss: 0.06962529509778946
I0419 10:44:16.806100 20188 trainer.py:139] Epoch[341/1000] loss: 0.06894923530278667
I0419 10:44:26.296149 20188 trainer.py:139] Epoch[342/1000] loss: 0.0685859615163457
I0419 10:44:35.749353 20188 trainer.py:139] Epoch[343/1000] loss: 0.06852850564304859
I0419 10:44:45.695365 20188 trainer.py:139] Epoch[344/1000] loss: 0.06897845335545079
I0419 10:44:54.322943 20188 trainer.py:139] Epoch[345/1000] loss: 0.06839860963725275
I0419 10:45:03.507598 20188 trainer.py:139] Epoch[346/1000] loss: 0.0696020285568891
I0419 10:45:13.255742 20188 trainer.py:139] Epoch[347/1000] loss: 0.06902911093446516
I0419 10:45:21.561845 20188 trainer.py:139] Epoch[348/1000] loss: 0.06904677463875662
I0419 10:45:31.984198 20188 trainer.py:139] Epoch[349/1000] loss: 0.06822508573532104
I0419 10:45:32.637625 20188 trainer.py:145] Test: [{'precision': 0.012589173310952585, 'recall': 0.1632725855764043, 'hit_ratio': 0.23835501468736886, 'ndcg': 0.07755861207186475}]
I0419 10:45:40.903640 20188 trainer.py:139] Epoch[350/1000] loss: 0.06749637785457796
I0419 10:45:51.275864 20188 trainer.py:139] Epoch[351/1000] loss: 0.06908378077130164
I0419 10:45:59.563198 20188 trainer.py:139] Epoch[352/1000] loss: 0.06918088316677078
I0419 10:46:10.010523 20188 trainer.py:139] Epoch[353/1000] loss: 0.06940846866176974
I0419 10:46:18.238382 20188 trainer.py:139] Epoch[354/1000] loss: 0.06840642806022398
I0419 10:46:28.930994 20188 trainer.py:139] Epoch[355/1000] loss: 0.06785123464801619
I0419 10:46:37.213513 20188 trainer.py:139] Epoch[356/1000] loss: 0.06891450315954224
I0419 10:46:47.674708 20188 trainer.py:139] Epoch[357/1000] loss: 0.06856308691203594
I0419 10:46:55.760164 20188 trainer.py:139] Epoch[358/1000] loss: 0.06847202411342052
I0419 10:47:06.189774 20188 trainer.py:139] Epoch[359/1000] loss: 0.0688253950567976
I0419 10:47:14.507490 20188 trainer.py:139] Epoch[360/1000] loss: 0.06879073375415418
I0419 10:47:25.152962 20188 trainer.py:139] Epoch[361/1000] loss: 0.06876919334453921
I0419 10:47:33.300590 20188 trainer.py:139] Epoch[362/1000] loss: 0.0677827860439016
I0419 10:47:43.712820 20188 trainer.py:139] Epoch[363/1000] loss: 0.06893312570548826
I0419 10:47:51.826123 20188 trainer.py:139] Epoch[364/1000] loss: 0.06776503966219964
I0419 10:48:02.181258 20188 trainer.py:139] Epoch[365/1000] loss: 0.06782965896831404
I0419 10:48:10.908218 20188 trainer.py:139] Epoch[366/1000] loss: 0.067788248761527
I0419 10:48:20.962183 20188 trainer.py:139] Epoch[367/1000] loss: 0.0677519059109111
I0419 10:48:29.854549 20188 trainer.py:139] Epoch[368/1000] loss: 0.06756858924223531
I0419 10:48:39.003847 20188 trainer.py:139] Epoch[369/1000] loss: 0.0672882744261334
I0419 10:48:48.636404 20188 trainer.py:139] Epoch[370/1000] loss: 0.06694248565022022
I0419 10:48:56.928184 20188 trainer.py:139] Epoch[371/1000] loss: 0.06753864313565916
I0419 10:49:07.531141 20188 trainer.py:139] Epoch[372/1000] loss: 0.06631978414952755
I0419 10:49:15.921733 20188 trainer.py:139] Epoch[373/1000] loss: 0.0672396774133367
I0419 10:49:26.587717 20188 trainer.py:139] Epoch[374/1000] loss: 0.06792211622720765
I0419 10:49:35.036934 20188 trainer.py:139] Epoch[375/1000] loss: 0.06816067053906379
I0419 10:49:45.901133 20188 trainer.py:139] Epoch[376/1000] loss: 0.06777510677854862
I0419 10:49:54.389931 20188 trainer.py:139] Epoch[377/1000] loss: 0.06782727766661875
I0419 10:50:04.954229 20188 trainer.py:139] Epoch[378/1000] loss: 0.06775369687426475
I0419 10:50:13.312770 20188 trainer.py:139] Epoch[379/1000] loss: 0.06807965250505556
I0419 10:50:23.886085 20188 trainer.py:139] Epoch[380/1000] loss: 0.06730771767756631
I0419 10:50:32.174465 20188 trainer.py:139] Epoch[381/1000] loss: 0.06704870959924113
I0419 10:50:42.749030 20188 trainer.py:139] Epoch[382/1000] loss: 0.06686243523032434
I0419 10:50:51.004343 20188 trainer.py:139] Epoch[383/1000] loss: 0.06677190857308526
I0419 10:51:01.685431 20188 trainer.py:139] Epoch[384/1000] loss: 0.06738755365292873
I0419 10:51:10.140193 20188 trainer.py:139] Epoch[385/1000] loss: 0.06781814253378299
I0419 10:51:20.986509 20188 trainer.py:139] Epoch[386/1000] loss: 0.06758836500587002
I0419 10:51:29.345971 20188 trainer.py:139] Epoch[387/1000] loss: 0.067486448754226
I0419 10:51:39.952227 20188 trainer.py:139] Epoch[388/1000] loss: 0.06749930971812818
I0419 10:51:48.241461 20188 trainer.py:139] Epoch[389/1000] loss: 0.06665566473478271
I0419 10:51:58.790257 20188 trainer.py:139] Epoch[390/1000] loss: 0.06745623190316462
I0419 10:52:07.447016 20188 trainer.py:139] Epoch[391/1000] loss: 0.06753195383616033
I0419 10:52:17.509003 20188 trainer.py:139] Epoch[392/1000] loss: 0.06738684740999053
I0419 10:52:26.403263 20188 trainer.py:139] Epoch[393/1000] loss: 0.06593473309711102
I0419 10:52:36.737750 20188 trainer.py:139] Epoch[394/1000] loss: 0.06639032456423005
I0419 10:52:45.245493 20188 trainer.py:139] Epoch[395/1000] loss: 0.06673103408707727
I0419 10:52:55.528048 20188 trainer.py:139] Epoch[396/1000] loss: 0.06718096527601441
I0419 10:53:04.357534 20188 trainer.py:139] Epoch[397/1000] loss: 0.06655152190116144
I0419 10:53:13.780435 20188 trainer.py:139] Epoch[398/1000] loss: 0.06640716570038949
I0419 10:53:23.127321 20188 trainer.py:139] Epoch[399/1000] loss: 0.06702987795635577
I0419 10:53:23.839546 20188 trainer.py:145] Test: [{'precision': 0.012400335711288298, 'recall': 0.16197636699105436, 'hit_ratio': 0.23541754091481326, 'ndcg': 0.07726356596209807}]
I0419 10:53:33.723697 20188 trainer.py:139] Epoch[400/1000] loss: 0.06651932860334073
I0419 10:53:42.564259 20188 trainer.py:139] Epoch[401/1000] loss: 0.06652134963341298
I0419 10:53:51.885667 20188 trainer.py:139] Epoch[402/1000] loss: 0.06664397213007173
I0419 10:54:01.238212 20188 trainer.py:139] Epoch[403/1000] loss: 0.06710941729045683
I0419 10:54:10.407744 20188 trainer.py:139] Epoch[404/1000] loss: 0.0675052609294653
I0419 10:54:20.378659 20188 trainer.py:139] Epoch[405/1000] loss: 0.06644507822009825
I0419 10:54:28.794090 20188 trainer.py:139] Epoch[406/1000] loss: 0.06695730275204105
I0419 10:54:39.295447 20188 trainer.py:139] Epoch[407/1000] loss: 0.06616905932464907
I0419 10:54:47.645205 20188 trainer.py:139] Epoch[408/1000] loss: 0.06629651316231297
I0419 10:54:58.157690 20188 trainer.py:139] Epoch[409/1000] loss: 0.06672333829825924
I0419 10:55:06.675361 20188 trainer.py:139] Epoch[410/1000] loss: 0.06564286231033263
I0419 10:55:17.358280 20188 trainer.py:139] Epoch[411/1000] loss: 0.06614819631701516
I0419 10:55:25.740042 20188 trainer.py:139] Epoch[412/1000] loss: 0.06658671279588053
I0419 10:55:36.490275 20188 trainer.py:139] Epoch[413/1000] loss: 0.06659182239203684
I0419 10:55:44.840398 20188 trainer.py:139] Epoch[414/1000] loss: 0.06770775154713661
I0419 10:55:55.735363 20188 trainer.py:139] Epoch[415/1000] loss: 0.06687175837014953
I0419 10:56:03.881329 20188 trainer.py:139] Epoch[416/1000] loss: 0.06645278206035014
I0419 10:56:14.656713 20188 trainer.py:139] Epoch[417/1000] loss: 0.06615734232529517
I0419 10:56:22.884869 20188 trainer.py:139] Epoch[418/1000] loss: 0.06568547746827526
I0419 10:56:33.265959 20188 trainer.py:139] Epoch[419/1000] loss: 0.0667472255806769
I0419 10:56:41.347121 20188 trainer.py:139] Epoch[420/1000] loss: 0.06653594544097301
I0419 10:56:51.886550 20188 trainer.py:139] Epoch[421/1000] loss: 0.06648950477040583
I0419 10:57:00.102624 20188 trainer.py:139] Epoch[422/1000] loss: 0.06571685234385152
I0419 10:57:10.747833 20188 trainer.py:139] Epoch[423/1000] loss: 0.0658342102242093
I0419 10:57:19.031804 20188 trainer.py:139] Epoch[424/1000] loss: 0.06593626677509278
I0419 10:57:29.529429 20188 trainer.py:139] Epoch[425/1000] loss: 0.06556528458191503
I0419 10:57:37.899777 20188 trainer.py:139] Epoch[426/1000] loss: 0.06530165233679357
I0419 10:57:48.608052 20188 trainer.py:139] Epoch[427/1000] loss: 0.06683534197509289
I0419 10:57:56.915796 20188 trainer.py:139] Epoch[428/1000] loss: 0.0661341761869769
I0419 10:58:07.390045 20188 trainer.py:139] Epoch[429/1000] loss: 0.06547598396578143
I0419 10:58:15.793426 20188 trainer.py:139] Epoch[430/1000] loss: 0.06679461013165212
I0419 10:58:25.570879 20188 trainer.py:139] Epoch[431/1000] loss: 0.06661056985537853
I0419 10:58:34.760197 20188 trainer.py:139] Epoch[432/1000] loss: 0.06599154497586912
I0419 10:58:44.004365 20188 trainer.py:139] Epoch[433/1000] loss: 0.06555294557925194
I0419 10:58:53.181397 20188 trainer.py:139] Epoch[434/1000] loss: 0.06577233098928005
I0419 10:59:02.270176 20188 trainer.py:139] Epoch[435/1000] loss: 0.06560998277798775
I0419 10:59:11.935994 20188 trainer.py:139] Epoch[436/1000] loss: 0.06569628549679633
I0419 10:59:20.214054 20188 trainer.py:139] Epoch[437/1000] loss: 0.06546605077962722
I0419 10:59:30.796481 20188 trainer.py:139] Epoch[438/1000] loss: 0.06546496485750522
I0419 10:59:39.027172 20188 trainer.py:139] Epoch[439/1000] loss: 0.06543141206906687
I0419 10:59:49.479824 20188 trainer.py:139] Epoch[440/1000] loss: 0.06578867720259775
I0419 10:59:57.776632 20188 trainer.py:139] Epoch[441/1000] loss: 0.06563103018749145
I0419 11:00:08.632673 20188 trainer.py:139] Epoch[442/1000] loss: 0.06600721522925361
I0419 11:00:16.877682 20188 trainer.py:139] Epoch[443/1000] loss: 0.06641505256054862
I0419 11:00:27.595810 20188 trainer.py:139] Epoch[444/1000] loss: 0.06575571523318367
I0419 11:00:35.661421 20188 trainer.py:139] Epoch[445/1000] loss: 0.06605081037888604
I0419 11:00:46.307421 20188 trainer.py:139] Epoch[446/1000] loss: 0.06540480334191554
I0419 11:00:54.530414 20188 trainer.py:139] Epoch[447/1000] loss: 0.06455117121579186
I0419 11:01:05.225100 20188 trainer.py:139] Epoch[448/1000] loss: 0.0654692874560433
I0419 11:01:13.315607 20188 trainer.py:139] Epoch[449/1000] loss: 0.06503501888965407
I0419 11:01:13.967427 20188 trainer.py:145] Test: [{'precision': 0.012631137221989094, 'recall': 0.16478794903050045, 'hit_ratio': 0.23961393201846412, 'ndcg': 0.07802557303922804}]
I0419 11:01:24.478726 20188 trainer.py:139] Epoch[450/1000] loss: 0.06588345189248362
I0419 11:01:32.700700 20188 trainer.py:139] Epoch[451/1000] loss: 0.0656638581065401
I0419 11:01:43.384046 20188 trainer.py:139] Epoch[452/1000] loss: 0.06511514375527058
I0419 11:01:51.748203 20188 trainer.py:139] Epoch[453/1000] loss: 0.06493755856588963
I0419 11:02:02.288119 20188 trainer.py:139] Epoch[454/1000] loss: 0.06553242656011735
I0419 11:02:10.689512 20188 trainer.py:139] Epoch[455/1000] loss: 0.06486685910532551
I0419 11:02:21.339732 20188 trainer.py:139] Epoch[456/1000] loss: 0.06567288412442131
I0419 11:02:29.525547 20188 trainer.py:139] Epoch[457/1000] loss: 0.06488614673576047
I0419 11:02:40.256860 20188 trainer.py:139] Epoch[458/1000] loss: 0.0637525237736202
I0419 11:02:48.531601 20188 trainer.py:139] Epoch[459/1000] loss: 0.0645885318517685
I0419 11:02:59.216248 20188 trainer.py:139] Epoch[460/1000] loss: 0.06587827926681887
I0419 11:03:07.461199 20188 trainer.py:139] Epoch[461/1000] loss: 0.06552578142333415
I0419 11:03:18.271128 20188 trainer.py:139] Epoch[462/1000] loss: 0.06532194988141136
I0419 11:03:26.486613 20188 trainer.py:139] Epoch[463/1000] loss: 0.06527582982615117
I0419 11:03:37.151655 20188 trainer.py:139] Epoch[464/1000] loss: 0.06558715540074533
I0419 11:03:45.074114 20188 trainer.py:139] Epoch[465/1000] loss: 0.06518514322177056
I0419 11:03:55.732227 20188 trainer.py:139] Epoch[466/1000] loss: 0.06411723594271368
I0419 11:04:03.889108 20188 trainer.py:139] Epoch[467/1000] loss: 0.06559552702932589
I0419 11:04:14.592796 20188 trainer.py:139] Epoch[468/1000] loss: 0.065595799035603
I0419 11:04:23.192848 20188 trainer.py:139] Epoch[469/1000] loss: 0.06454977146800488
I0419 11:04:33.745526 20188 trainer.py:139] Epoch[470/1000] loss: 0.06519123989968531
I0419 11:04:41.941235 20188 trainer.py:139] Epoch[471/1000] loss: 0.06437928313689847
I0419 11:04:52.521295 20188 trainer.py:139] Epoch[472/1000] loss: 0.06475385014087923
I0419 11:05:01.063313 20188 trainer.py:139] Epoch[473/1000] loss: 0.06554260411329808
I0419 11:05:11.629969 20188 trainer.py:139] Epoch[474/1000] loss: 0.06546775197550174
I0419 11:05:19.960493 20188 trainer.py:139] Epoch[475/1000] loss: 0.06508929096162319
I0419 11:05:30.484288 20188 trainer.py:139] Epoch[476/1000] loss: 0.0645607998294215
I0419 11:05:38.900369 20188 trainer.py:139] Epoch[477/1000] loss: 0.06565229564664825
I0419 11:05:49.622449 20188 trainer.py:139] Epoch[478/1000] loss: 0.06434893079342381
I0419 11:05:57.934257 20188 trainer.py:139] Epoch[479/1000] loss: 0.06492116584652854
I0419 11:06:08.343678 20188 trainer.py:139] Epoch[480/1000] loss: 0.06472295330416772
I0419 11:06:16.727281 20188 trainer.py:139] Epoch[481/1000] loss: 0.06498932586081567
I0419 11:06:27.210940 20188 trainer.py:139] Epoch[482/1000] loss: 0.06534561352624048
I0419 11:06:35.680733 20188 trainer.py:139] Epoch[483/1000] loss: 0.065440826778931
I0419 11:06:46.410305 20188 trainer.py:139] Epoch[484/1000] loss: 0.0651537569299821
I0419 11:06:54.740995 20188 trainer.py:139] Epoch[485/1000] loss: 0.06439643665667504
I0419 11:07:05.025411 20188 trainer.py:139] Epoch[486/1000] loss: 0.06388639953107603
I0419 11:07:13.858163 20188 trainer.py:139] Epoch[487/1000] loss: 0.06554613466705045
I0419 11:07:23.404401 20188 trainer.py:139] Epoch[488/1000] loss: 0.06550105276607698
I0419 11:07:32.770448 20188 trainer.py:139] Epoch[489/1000] loss: 0.06492802308451745
I0419 11:07:41.670950 20188 trainer.py:139] Epoch[490/1000] loss: 0.0637911926474302
I0419 11:07:51.473500 20188 trainer.py:139] Epoch[491/1000] loss: 0.06489462225187209
I0419 11:08:00.073219 20188 trainer.py:139] Epoch[492/1000] loss: 0.06428831280960191
I0419 11:08:10.133882 20188 trainer.py:139] Epoch[493/1000] loss: 0.06501792881998324
I0419 11:08:18.209406 20188 trainer.py:139] Epoch[494/1000] loss: 0.0642726116122738
I0419 11:08:28.687075 20188 trainer.py:139] Epoch[495/1000] loss: 0.06418825457653692
I0419 11:08:36.546148 20188 trainer.py:139] Epoch[496/1000] loss: 0.06436968787062552
I0419 11:08:46.985445 20188 trainer.py:139] Epoch[497/1000] loss: 0.06469813722275919
I0419 11:08:55.324627 20188 trainer.py:139] Epoch[498/1000] loss: 0.06389535122340725
I0419 11:09:05.997951 20188 trainer.py:139] Epoch[499/1000] loss: 0.06419187916382667
I0419 11:09:06.676245 20188 trainer.py:145] Test: [{'precision': 0.012694083088543858, 'recall': 0.1659969093246475, 'hit_ratio': 0.24129248845992446, 'ndcg': 0.07877929221939922}]
I0419 11:09:14.891376 20188 trainer.py:139] Epoch[500/1000] loss: 0.06445557702212565
I0419 11:09:25.332738 20188 trainer.py:139] Epoch[501/1000] loss: 0.063890463702621
I0419 11:09:33.600035 20188 trainer.py:139] Epoch[502/1000] loss: 0.06496147625148296
I0419 11:09:44.160150 20188 trainer.py:139] Epoch[503/1000] loss: 0.06447963939318734
I0419 11:09:52.158635 20188 trainer.py:139] Epoch[504/1000] loss: 0.0649964492167196
I0419 11:10:02.978373 20188 trainer.py:139] Epoch[505/1000] loss: 0.06555777043104172
I0419 11:10:11.391291 20188 trainer.py:139] Epoch[506/1000] loss: 0.0642612685839976
I0419 11:10:21.881233 20188 trainer.py:139] Epoch[507/1000] loss: 0.06373238461392541
I0419 11:10:30.057902 20188 trainer.py:139] Epoch[508/1000] loss: 0.06445184926832875
I0419 11:10:40.462440 20188 trainer.py:139] Epoch[509/1000] loss: 0.06488254149594615
I0419 11:10:48.920156 20188 trainer.py:139] Epoch[510/1000] loss: 0.06398072075699607
I0419 11:10:59.491878 20188 trainer.py:139] Epoch[511/1000] loss: 0.06379686241909381
I0419 11:11:07.741540 20188 trainer.py:139] Epoch[512/1000] loss: 0.06386581441808131
I0419 11:11:17.929694 20188 trainer.py:139] Epoch[513/1000] loss: 0.06417183355698662
I0419 11:11:26.590917 20188 trainer.py:139] Epoch[514/1000] loss: 0.06586123083627993
I0419 11:11:36.535247 20188 trainer.py:139] Epoch[515/1000] loss: 0.06386910817555842
I0419 11:11:45.235242 20188 trainer.py:139] Epoch[516/1000] loss: 0.06400588521313283
I0419 11:11:54.129726 20188 trainer.py:139] Epoch[517/1000] loss: 0.06476541987109569
I0419 11:12:04.230077 20188 trainer.py:139] Epoch[518/1000] loss: 0.06382779242290605
I0419 11:12:13.607119 20188 trainer.py:139] Epoch[519/1000] loss: 0.06353244389737805
I0419 11:12:23.123091 20188 trainer.py:139] Epoch[520/1000] loss: 0.06468592079416398
I0419 11:12:31.443299 20188 trainer.py:139] Epoch[521/1000] loss: 0.06486807973875154
I0419 11:12:42.246877 20188 trainer.py:139] Epoch[522/1000] loss: 0.0640019169978557
I0419 11:12:50.474580 20188 trainer.py:139] Epoch[523/1000] loss: 0.06456960004664236
I0419 11:13:01.048258 20188 trainer.py:139] Epoch[524/1000] loss: 0.0641145456822649
I0419 11:13:09.316843 20188 trainer.py:139] Epoch[525/1000] loss: 0.06398795803468074
I0419 11:13:19.989624 20188 trainer.py:139] Epoch[526/1000] loss: 0.06359115327077527
I0419 11:13:28.061259 20188 trainer.py:139] Epoch[527/1000] loss: 0.06388129402072198
I0419 11:13:38.721045 20188 trainer.py:139] Epoch[528/1000] loss: 0.06275730231596578
I0419 11:13:46.993394 20188 trainer.py:139] Epoch[529/1000] loss: 0.06353798508644104
I0419 11:13:57.572474 20188 trainer.py:139] Epoch[530/1000] loss: 0.06401913000210639
I0419 11:14:05.710717 20188 trainer.py:139] Epoch[531/1000] loss: 0.06373139921455614
I0419 11:14:16.172187 20188 trainer.py:139] Epoch[532/1000] loss: 0.06382465536796278
I0419 11:14:24.429107 20188 trainer.py:139] Epoch[533/1000] loss: 0.06376494299019536
I0419 11:14:34.841144 20188 trainer.py:139] Epoch[534/1000] loss: 0.06464778541797592
I0419 11:14:43.035990 20188 trainer.py:139] Epoch[535/1000] loss: 0.06373304963832901
I0419 11:14:53.626337 20188 trainer.py:139] Epoch[536/1000] loss: 0.06426677354160816
I0419 11:15:01.638365 20188 trainer.py:139] Epoch[537/1000] loss: 0.06326813749488323
I0419 11:15:12.216976 20188 trainer.py:139] Epoch[538/1000] loss: 0.06297103219455288
I0419 11:15:20.410452 20188 trainer.py:139] Epoch[539/1000] loss: 0.0633242586327176
I0419 11:15:30.925902 20188 trainer.py:139] Epoch[540/1000] loss: 0.06387646033638908
I0419 11:15:39.380755 20188 trainer.py:139] Epoch[541/1000] loss: 0.06361718656074616
I0419 11:15:49.426977 20188 trainer.py:139] Epoch[542/1000] loss: 0.06431175209581852
I0419 11:15:58.444886 20188 trainer.py:139] Epoch[543/1000] loss: 0.06298318535329835
I0419 11:16:07.551690 20188 trainer.py:139] Epoch[544/1000] loss: 0.06351269385026347
I0419 11:16:17.372374 20188 trainer.py:139] Epoch[545/1000] loss: 0.06408199235316246
I0419 11:16:26.204942 20188 trainer.py:139] Epoch[546/1000] loss: 0.06409028136441784
I0419 11:16:36.648836 20188 trainer.py:139] Epoch[547/1000] loss: 0.06419584563662929
I0419 11:16:46.685888 20188 trainer.py:139] Epoch[548/1000] loss: 0.06333566577203813
I0419 11:16:55.768986 20188 trainer.py:139] Epoch[549/1000] loss: 0.06365216733707536
I0419 11:16:56.447287 20188 trainer.py:145] Test: [{'precision': 0.012673101133025605, 'recall': 0.16588600470262244, 'hit_ratio': 0.2400335711288292, 'ndcg': 0.07905439105272485}]
I0419 11:17:05.752348 20188 trainer.py:139] Epoch[550/1000] loss: 0.063251769891189
I0419 11:17:15.284355 20188 trainer.py:139] Epoch[551/1000] loss: 0.06438920454632852
I0419 11:17:24.829061 20188 trainer.py:139] Epoch[552/1000] loss: 0.06411400809884071
I0419 11:17:34.369998 20188 trainer.py:139] Epoch[553/1000] loss: 0.06325358849379324
I0419 11:17:43.774856 20188 trainer.py:139] Epoch[554/1000] loss: 0.06355818991939868
I0419 11:17:52.923557 20188 trainer.py:139] Epoch[555/1000] loss: 0.06463987626616031
I0419 11:18:02.183423 20188 trainer.py:139] Epoch[556/1000] loss: 0.06415191983744022
I0419 11:18:11.762766 20188 trainer.py:139] Epoch[557/1000] loss: 0.06390736967084869
I0419 11:18:20.597151 20188 trainer.py:139] Epoch[558/1000] loss: 0.06325319463447217
I0419 11:18:30.561652 20188 trainer.py:139] Epoch[559/1000] loss: 0.06345965370776192
I0419 11:18:40.571170 20188 trainer.py:139] Epoch[560/1000] loss: 0.06378873972402464
I0419 11:18:49.563648 20188 trainer.py:139] Epoch[561/1000] loss: 0.06422210652982036
I0419 11:18:58.680540 20188 trainer.py:139] Epoch[562/1000] loss: 0.06306886913314942
I0419 11:19:07.863705 20188 trainer.py:139] Epoch[563/1000] loss: 0.06403619778012076
I0419 11:19:17.071220 20188 trainer.py:139] Epoch[564/1000] loss: 0.06359088829448147
I0419 11:19:26.454442 20188 trainer.py:139] Epoch[565/1000] loss: 0.06307943742121419
I0419 11:19:35.527509 20188 trainer.py:139] Epoch[566/1000] loss: 0.06368910965900268
I0419 11:19:45.528969 20188 trainer.py:139] Epoch[567/1000] loss: 0.06288919051087671
I0419 11:19:54.296382 20188 trainer.py:139] Epoch[568/1000] loss: 0.06296283583487233
I0419 11:20:04.650722 20188 trainer.py:139] Epoch[569/1000] loss: 0.06289834120581227
I0419 11:20:12.670565 20188 trainer.py:139] Epoch[570/1000] loss: 0.06435345011132379
I0419 11:20:23.077132 20188 trainer.py:139] Epoch[571/1000] loss: 0.06374294430978837
I0419 11:20:31.390448 20188 trainer.py:139] Epoch[572/1000] loss: 0.06316072313535598
I0419 11:20:42.110103 20188 trainer.py:139] Epoch[573/1000] loss: 0.06325009543328516
I0419 11:20:50.395617 20188 trainer.py:139] Epoch[574/1000] loss: 0.06350886329047141
I0419 11:21:00.999635 20188 trainer.py:139] Epoch[575/1000] loss: 0.06416021665978816
I0419 11:21:09.151514 20188 trainer.py:139] Epoch[576/1000] loss: 0.06366384167584681
I0419 11:21:19.740293 20188 trainer.py:139] Epoch[577/1000] loss: 0.06383017570741716
I0419 11:21:28.041677 20188 trainer.py:139] Epoch[578/1000] loss: 0.06381187942479888
I0419 11:21:38.731761 20188 trainer.py:139] Epoch[579/1000] loss: 0.06364134332585719
I0419 11:21:46.987336 20188 trainer.py:139] Epoch[580/1000] loss: 0.06292984989141265
I0419 11:21:57.585241 20188 trainer.py:139] Epoch[581/1000] loss: 0.06326050197164859
I0419 11:22:05.882922 20188 trainer.py:139] Epoch[582/1000] loss: 0.06304184449536185
I0419 11:22:16.611173 20188 trainer.py:139] Epoch[583/1000] loss: 0.06331446856981324
I0419 11:22:24.928396 20188 trainer.py:139] Epoch[584/1000] loss: 0.063410482038894
I0419 11:22:35.465903 20188 trainer.py:139] Epoch[585/1000] loss: 0.06406411738885988
I0419 11:22:43.781137 20188 trainer.py:139] Epoch[586/1000] loss: 0.06402504167729808
I0419 11:22:54.439435 20188 trainer.py:139] Epoch[587/1000] loss: 0.06343991934291777
I0419 11:23:02.566477 20188 trainer.py:139] Epoch[588/1000] loss: 0.06380851428595281
I0419 11:23:13.086181 20188 trainer.py:139] Epoch[589/1000] loss: 0.0637523511484746
I0419 11:23:21.155683 20188 trainer.py:139] Epoch[590/1000] loss: 0.06368866232374022
I0419 11:23:31.404546 20188 trainer.py:139] Epoch[591/1000] loss: 0.06412409954974728
I0419 11:23:40.186140 20188 trainer.py:139] Epoch[592/1000] loss: 0.0627392198770277
I0419 11:23:50.057566 20188 trainer.py:139] Epoch[593/1000] loss: 0.06334162473438247
I0419 11:23:59.017322 20188 trainer.py:139] Epoch[594/1000] loss: 0.06318432110692224
I0419 11:24:09.165255 20188 trainer.py:139] Epoch[595/1000] loss: 0.06294364019507362
I0419 11:24:17.838165 20188 trainer.py:139] Epoch[596/1000] loss: 0.06232565647411731
I0419 11:24:27.611306 20188 trainer.py:139] Epoch[597/1000] loss: 0.06320294653696398
I0419 11:24:36.834919 20188 trainer.py:139] Epoch[598/1000] loss: 0.06262901389310437
I0419 11:24:45.735833 20188 trainer.py:139] Epoch[599/1000] loss: 0.06255079499415812
I0419 11:24:46.486891 20188 trainer.py:145] Test: [{'precision': 0.012736046999580367, 'recall': 0.1658090708657222, 'hit_ratio': 0.2404532102391943, 'ndcg': 0.07869806101610664}]
I0419 11:24:56.217351 20188 trainer.py:139] Epoch[600/1000] loss: 0.06331126415921796
I0419 11:25:04.999797 20188 trainer.py:139] Epoch[601/1000] loss: 0.06312578928566748
I0419 11:25:15.131171 20188 trainer.py:139] Epoch[602/1000] loss: 0.0629899729523928
I0419 11:25:23.521381 20188 trainer.py:139] Epoch[603/1000] loss: 0.06226011714146983
I0419 11:25:33.648697 20188 trainer.py:139] Epoch[604/1000] loss: 0.0633779386839559
I0419 11:25:41.983078 20188 trainer.py:139] Epoch[605/1000] loss: 0.06245730625044915
I0419 11:25:52.498970 20188 trainer.py:139] Epoch[606/1000] loss: 0.06341128189477228
I0419 11:26:00.783797 20188 trainer.py:139] Epoch[607/1000] loss: 0.06324920046233362
I0419 11:26:11.609029 20188 trainer.py:139] Epoch[608/1000] loss: 0.0631023426089556
I0419 11:26:19.872658 20188 trainer.py:139] Epoch[609/1000] loss: 0.062835770989618
I0419 11:26:30.277200 20188 trainer.py:139] Epoch[610/1000] loss: 0.06321160290991107
I0419 11:26:38.655687 20188 trainer.py:139] Epoch[611/1000] loss: 0.06315123998830395
I0419 11:26:49.624160 20188 trainer.py:139] Epoch[612/1000] loss: 0.06294572311303308
I0419 11:26:58.005641 20188 trainer.py:139] Epoch[613/1000] loss: 0.06292797829354962
I0419 11:27:08.856443 20188 trainer.py:139] Epoch[614/1000] loss: 0.06275462899957934
I0419 11:27:17.157946 20188 trainer.py:139] Epoch[615/1000] loss: 0.061916650122692506
I0419 11:27:27.972055 20188 trainer.py:139] Epoch[616/1000] loss: 0.06287456165638662
I0419 11:27:36.377064 20188 trainer.py:139] Epoch[617/1000] loss: 0.06247961935737441
I0419 11:27:47.038949 20188 trainer.py:139] Epoch[618/1000] loss: 0.06269725604403403
I0419 11:27:55.460905 20188 trainer.py:139] Epoch[619/1000] loss: 0.06262137674756589
I0419 11:28:06.385345 20188 trainer.py:139] Epoch[620/1000] loss: 0.06348970153879735
I0419 11:28:14.588961 20188 trainer.py:139] Epoch[621/1000] loss: 0.06232921238387785
I0419 11:28:25.357817 20188 trainer.py:139] Epoch[622/1000] loss: 0.0631896450875267
I0419 11:28:33.554995 20188 trainer.py:139] Epoch[623/1000] loss: 0.06348605453968048
I0419 11:28:44.221580 20188 trainer.py:139] Epoch[624/1000] loss: 0.06291282465381007
I0419 11:28:52.333884 20188 trainer.py:139] Epoch[625/1000] loss: 0.06339092204166998
I0419 11:29:02.858144 20188 trainer.py:139] Epoch[626/1000] loss: 0.06332934245226844
I0419 11:29:11.083137 20188 trainer.py:139] Epoch[627/1000] loss: 0.062213463228075735
I0419 11:29:21.685429 20188 trainer.py:139] Epoch[628/1000] loss: 0.06378008305065093
I0419 11:29:30.157194 20188 trainer.py:139] Epoch[629/1000] loss: 0.06243766856289679
I0419 11:29:40.684157 20188 trainer.py:139] Epoch[630/1000] loss: 0.06342015583668986
I0419 11:29:49.174168 20188 trainer.py:139] Epoch[631/1000] loss: 0.06277341137249623
I0419 11:29:59.613115 20188 trainer.py:139] Epoch[632/1000] loss: 0.06378472986961564
I0419 11:30:07.927722 20188 trainer.py:139] Epoch[633/1000] loss: 0.06253436808624575
I0419 11:30:18.422659 20188 trainer.py:139] Epoch[634/1000] loss: 0.0635073948050699
I0419 11:30:26.638681 20188 trainer.py:139] Epoch[635/1000] loss: 0.06265366101457227
I0419 11:30:36.226140 20188 trainer.py:139] Epoch[636/1000] loss: 0.0629370070753559
I0419 11:30:45.164371 20188 trainer.py:139] Epoch[637/1000] loss: 0.06279173247035473
I0419 11:30:54.643014 20188 trainer.py:139] Epoch[638/1000] loss: 0.06283211479744603
I0419 11:31:04.226328 20188 trainer.py:139] Epoch[639/1000] loss: 0.06272181988723817
I0419 11:31:12.902309 20188 trainer.py:139] Epoch[640/1000] loss: 0.06289267774310804
I0419 11:31:23.180816 20188 trainer.py:139] Epoch[641/1000] loss: 0.06279562527854596
I0419 11:31:31.324089 20188 trainer.py:139] Epoch[642/1000] loss: 0.06326604418216213
I0419 11:31:41.729335 20188 trainer.py:139] Epoch[643/1000] loss: 0.06308281752130677
I0419 11:31:50.098860 20188 trainer.py:139] Epoch[644/1000] loss: 0.06331401216166635
I0419 11:32:00.648026 20188 trainer.py:139] Epoch[645/1000] loss: 0.06269319091112383
I0419 11:32:08.951115 20188 trainer.py:139] Epoch[646/1000] loss: 0.06328438931415158
I0419 11:32:19.703136 20188 trainer.py:139] Epoch[647/1000] loss: 0.06251714420655081
I0419 11:32:27.864567 20188 trainer.py:139] Epoch[648/1000] loss: 0.06319440967373309
I0419 11:32:38.376650 20188 trainer.py:139] Epoch[649/1000] loss: 0.0635408238177338
I0419 11:32:39.027473 20188 trainer.py:145] Test: [{'precision': 0.01265211917750735, 'recall': 0.1641724783352983, 'hit_ratio': 0.23919429290809904, 'ndcg': 0.07884358409810209}]
I0419 11:32:47.533205 20188 trainer.py:139] Epoch[650/1000] loss: 0.06236810627723894
I0419 11:32:58.055182 20188 trainer.py:139] Epoch[651/1000] loss: 0.06222071895195592
I0419 11:33:06.140085 20188 trainer.py:139] Epoch[652/1000] loss: 0.06286708523909892
I0419 11:33:16.643850 20188 trainer.py:139] Epoch[653/1000] loss: 0.06291443530109621
I0419 11:33:25.046268 20188 trainer.py:139] Epoch[654/1000] loss: 0.06390187636979165
I0419 11:33:35.752585 20188 trainer.py:139] Epoch[655/1000] loss: 0.06261701539399163
I0419 11:33:43.777257 20188 trainer.py:139] Epoch[656/1000] loss: 0.06299113770646433
I0419 11:33:54.396676 20188 trainer.py:139] Epoch[657/1000] loss: 0.06243515254989747
I0419 11:34:02.581877 20188 trainer.py:139] Epoch[658/1000] loss: 0.06387086266711835
I0419 11:34:13.277875 20188 trainer.py:139] Epoch[659/1000] loss: 0.06268252095868511
I0419 11:34:21.486441 20188 trainer.py:139] Epoch[660/1000] loss: 0.06204600265670207
I0419 11:34:32.056284 20188 trainer.py:139] Epoch[661/1000] loss: 0.06211481832208172
I0419 11:34:40.172288 20188 trainer.py:139] Epoch[662/1000] loss: 0.06198493950068951
I0419 11:34:50.700723 20188 trainer.py:139] Epoch[663/1000] loss: 0.061737079593923785
I0419 11:34:58.884962 20188 trainer.py:139] Epoch[664/1000] loss: 0.0631314963703194
I0419 11:35:09.426452 20188 trainer.py:139] Epoch[665/1000] loss: 0.06287373530287896
I0419 11:35:17.674404 20188 trainer.py:139] Epoch[666/1000] loss: 0.06297239949626307
I0419 11:35:28.242587 20188 trainer.py:139] Epoch[667/1000] loss: 0.06249503214513102
I0419 11:35:36.206182 20188 trainer.py:139] Epoch[668/1000] loss: 0.0631601717923918
I0419 11:35:46.934863 20188 trainer.py:139] Epoch[669/1000] loss: 0.061645162381952806
I0419 11:35:55.323860 20188 trainer.py:139] Epoch[670/1000] loss: 0.06273674051607808
I0419 11:36:06.259126 20188 trainer.py:139] Epoch[671/1000] loss: 0.06185811289375828
I0419 11:36:14.549556 20188 trainer.py:139] Epoch[672/1000] loss: 0.06269361577447384
I0419 11:36:24.519187 20188 trainer.py:139] Epoch[673/1000] loss: 0.061767720346969944
I0419 11:36:33.266616 20188 trainer.py:139] Epoch[674/1000] loss: 0.06248274115064452
I0419 11:36:42.294586 20188 trainer.py:139] Epoch[675/1000] loss: 0.06273857239753969
I0419 11:36:52.388482 20188 trainer.py:139] Epoch[676/1000] loss: 0.06292367744590005
I0419 11:37:01.560386 20188 trainer.py:139] Epoch[677/1000] loss: 0.06216802291812435
I0419 11:37:11.503325 20188 trainer.py:139] Epoch[678/1000] loss: 0.06248866195880597
I0419 11:37:21.670020 20188 trainer.py:139] Epoch[679/1000] loss: 0.06207544614951457
I0419 11:37:30.573067 20188 trainer.py:139] Epoch[680/1000] loss: 0.06261191625268228
I0419 11:37:40.891609 20188 trainer.py:139] Epoch[681/1000] loss: 0.062216666016367175
I0419 11:37:49.209994 20188 trainer.py:139] Epoch[682/1000] loss: 0.062209637835621834
I0419 11:37:59.929123 20188 trainer.py:139] Epoch[683/1000] loss: 0.061800274817693616
I0419 11:38:08.385294 20188 trainer.py:139] Epoch[684/1000] loss: 0.0625986073526644
I0419 11:38:18.796212 20188 trainer.py:139] Epoch[685/1000] loss: 0.06260360585105035
I0419 11:38:27.242997 20188 trainer.py:139] Epoch[686/1000] loss: 0.061703619457060294
I0419 11:38:36.927176 20188 trainer.py:139] Epoch[687/1000] loss: 0.06250043081179742
I0419 11:38:46.096431 20188 trainer.py:139] Epoch[688/1000] loss: 0.06207531017641867
I0419 11:38:55.940562 20188 trainer.py:139] Epoch[689/1000] loss: 0.0626803789167635
I0419 11:39:05.001513 20188 trainer.py:139] Epoch[690/1000] loss: 0.062429159459087155
I0419 11:39:14.900401 20188 trainer.py:139] Epoch[691/1000] loss: 0.06278260424733162
I0419 11:39:23.926545 20188 trainer.py:139] Epoch[692/1000] loss: 0.062369147796303995
I0419 11:39:33.757479 20188 trainer.py:139] Epoch[693/1000] loss: 0.06337946088564012
I0419 11:39:42.695724 20188 trainer.py:139] Epoch[694/1000] loss: 0.062153363960885236
I0419 11:39:51.989850 20188 trainer.py:139] Epoch[695/1000] loss: 0.062478761579240524
I0419 11:40:01.510894 20188 trainer.py:139] Epoch[696/1000] loss: 0.06248864363278112
I0419 11:40:11.106731 20188 trainer.py:139] Epoch[697/1000] loss: 0.06268362478623467
I0419 11:40:20.818508 20188 trainer.py:139] Epoch[698/1000] loss: 0.06241907053176434
I0419 11:40:30.003343 20188 trainer.py:139] Epoch[699/1000] loss: 0.0631580475357271
I0419 11:40:30.803219 20188 trainer.py:145] Test: [{'precision': 0.012966848510281166, 'recall': 0.16828793903909303, 'hit_ratio': 0.24716743600503566, 'ndcg': 0.07991942742490088}]
I0419 11:40:40.364860 20188 trainer.py:139] Epoch[700/1000] loss: 0.06180727866388137
I0419 11:40:49.370896 20188 trainer.py:139] Epoch[701/1000] loss: 0.06190048146151727
I0419 11:40:59.105252 20188 trainer.py:139] Epoch[702/1000] loss: 0.06191881337473469
I0419 11:41:07.987499 20188 trainer.py:139] Epoch[703/1000] loss: 0.06211878203095928
I0419 11:41:18.004207 20188 trainer.py:139] Epoch[704/1000] loss: 0.06163477735413659
I0419 11:41:27.186180 20188 trainer.py:139] Epoch[705/1000] loss: 0.06218306984632246
I0419 11:41:36.903778 20188 trainer.py:139] Epoch[706/1000] loss: 0.06161828567424128
I0419 11:41:46.501528 20188 trainer.py:139] Epoch[707/1000] loss: 0.06199437902579384
I0419 11:41:56.009011 20188 trainer.py:139] Epoch[708/1000] loss: 0.062405540217314995
I0419 11:42:05.222842 20188 trainer.py:139] Epoch[709/1000] loss: 0.061618552933777535
I0419 11:42:14.929815 20188 trainer.py:139] Epoch[710/1000] loss: 0.06224166235375789
I0419 11:42:24.059477 20188 trainer.py:139] Epoch[711/1000] loss: 0.06195447263458083
I0419 11:42:33.964233 20188 trainer.py:139] Epoch[712/1000] loss: 0.06236718739232709
I0419 11:42:43.314954 20188 trainer.py:139] Epoch[713/1000] loss: 0.06225289500528766
I0419 11:42:52.948124 20188 trainer.py:139] Epoch[714/1000] loss: 0.06201234327689294
I0419 11:43:01.892399 20188 trainer.py:139] Epoch[715/1000] loss: 0.061854718192931146
I0419 11:43:11.728808 20188 trainer.py:139] Epoch[716/1000] loss: 0.06267988249178856
I0419 11:43:20.404000 20188 trainer.py:139] Epoch[717/1000] loss: 0.06295821136764941
I0419 11:43:30.710288 20188 trainer.py:139] Epoch[718/1000] loss: 0.06203452239353811
I0419 11:43:38.911390 20188 trainer.py:139] Epoch[719/1000] loss: 0.0620370221234137
I0419 11:43:49.536124 20188 trainer.py:139] Epoch[720/1000] loss: 0.06193596749536453
I0419 11:43:57.977732 20188 trainer.py:139] Epoch[721/1000] loss: 0.06223322943814339
I0419 11:44:08.688418 20188 trainer.py:139] Epoch[722/1000] loss: 0.06220461914856588
I0419 11:44:17.145628 20188 trainer.py:139] Epoch[723/1000] loss: 0.06270605962603323
I0419 11:44:27.786230 20188 trainer.py:139] Epoch[724/1000] loss: 0.06204929611375255
I0419 11:44:36.074394 20188 trainer.py:139] Epoch[725/1000] loss: 0.0626308853107114
I0419 11:44:46.744499 20188 trainer.py:139] Epoch[726/1000] loss: 0.06309136435870201
I0419 11:44:54.938200 20188 trainer.py:139] Epoch[727/1000] loss: 0.061523972920352415
I0419 11:45:05.580140 20188 trainer.py:139] Epoch[728/1000] loss: 0.06157799744077267
I0419 11:45:14.070386 20188 trainer.py:139] Epoch[729/1000] loss: 0.06224642910303608
I0419 11:45:24.325211 20188 trainer.py:139] Epoch[730/1000] loss: 0.06236046841067652
I0419 11:45:33.720664 20188 trainer.py:139] Epoch[731/1000] loss: 0.06210634593040713
I0419 11:45:42.958848 20188 trainer.py:139] Epoch[732/1000] loss: 0.062139910735910936
I0419 11:45:53.444477 20188 trainer.py:139] Epoch[733/1000] loss: 0.061879636599652225
I0419 11:46:02.146543 20188 trainer.py:139] Epoch[734/1000] loss: 0.06178610171041181
I0419 11:46:12.683928 20188 trainer.py:139] Epoch[735/1000] loss: 0.061986439050205296
I0419 11:46:21.021600 20188 trainer.py:139] Epoch[736/1000] loss: 0.06244982124095963
I0419 11:46:29.023574 20188 trainer.py:139] Epoch[737/1000] loss: 0.06154113419113621
I0419 11:46:39.224067 20188 trainer.py:139] Epoch[738/1000] loss: 0.06228908085294308
I0419 11:46:47.061958 20188 trainer.py:139] Epoch[739/1000] loss: 0.06205011892222589
I0419 11:46:55.056216 20188 trainer.py:139] Epoch[740/1000] loss: 0.061844461627544894
I0419 11:47:02.469416 20188 trainer.py:139] Epoch[741/1000] loss: 0.06160580505046152
I0419 11:47:09.729095 20188 trainer.py:139] Epoch[742/1000] loss: 0.06301061136107292
I0419 11:47:17.133307 20188 trainer.py:139] Epoch[743/1000] loss: 0.06218798176175164
I0419 11:47:24.432850 20188 trainer.py:139] Epoch[744/1000] loss: 0.062058469761283166
I0419 11:47:31.648363 20188 trainer.py:139] Epoch[745/1000] loss: 0.06166480127121172
I0419 11:47:39.143264 20188 trainer.py:139] Epoch[746/1000] loss: 0.06176890276612774
I0419 11:47:46.601567 20188 trainer.py:139] Epoch[747/1000] loss: 0.06224963231192481
I0419 11:47:53.984169 20188 trainer.py:139] Epoch[748/1000] loss: 0.0628057528407343
I0419 11:48:01.498827 20188 trainer.py:139] Epoch[749/1000] loss: 0.06256726624504212
I0419 11:48:02.078047 20188 trainer.py:145] Test: [{'precision': 0.012966848510281166, 'recall': 0.16860266837186685, 'hit_ratio': 0.2463281577843055, 'ndcg': 0.07945495817951319}]
I0419 11:48:09.525478 20188 trainer.py:139] Epoch[750/1000] loss: 0.062364718426139124
I0419 11:48:16.961619 20188 trainer.py:139] Epoch[751/1000] loss: 0.062431623558363604
I0419 11:48:24.256442 20188 trainer.py:139] Epoch[752/1000] loss: 0.0629939439916803
I0419 11:48:31.684720 20188 trainer.py:139] Epoch[753/1000] loss: 0.0622528376238
I0419 11:48:39.101723 20188 trainer.py:139] Epoch[754/1000] loss: 0.06207870716048825
I0419 11:48:46.611182 20188 trainer.py:139] Epoch[755/1000] loss: 0.06192487382119702
I0419 11:48:54.021409 20188 trainer.py:139] Epoch[756/1000] loss: 0.06228652187893467
I0419 11:49:01.724980 20188 trainer.py:139] Epoch[757/1000] loss: 0.061197309123892936
I0419 11:49:09.121184 20188 trainer.py:139] Epoch[758/1000] loss: 0.06145207289486162
I0419 11:49:16.347513 20188 trainer.py:139] Epoch[759/1000] loss: 0.061318838848702366
I0419 11:49:23.866774 20188 trainer.py:139] Epoch[760/1000] loss: 0.06181246967565629
I0419 11:49:31.265639 20188 trainer.py:139] Epoch[761/1000] loss: 0.06182283493539979
I0419 11:49:38.684031 20188 trainer.py:139] Epoch[762/1000] loss: 0.06177285181418542
I0419 11:49:46.182228 20188 trainer.py:139] Epoch[763/1000] loss: 0.0627038576790402
I0419 11:49:53.662954 20188 trainer.py:139] Epoch[764/1000] loss: 0.061710661337260275
I0419 11:50:01.098834 20188 trainer.py:139] Epoch[765/1000] loss: 0.06161943192203199
I0419 11:50:08.665054 20188 trainer.py:139] Epoch[766/1000] loss: 0.062187561344715855
I0419 11:50:16.084621 20188 trainer.py:139] Epoch[767/1000] loss: 0.06184150891438607
I0419 11:50:25.381802 20188 trainer.py:139] Epoch[768/1000] loss: 0.062125443270610224
I0419 11:50:33.069836 20188 trainer.py:139] Epoch[769/1000] loss: 0.062359051057888616
I0419 11:50:40.607837 20188 trainer.py:139] Epoch[770/1000] loss: 0.06180503357562327
I0419 11:50:48.237394 20188 trainer.py:139] Epoch[771/1000] loss: 0.061100119544613744
I0419 11:50:55.766252 20188 trainer.py:139] Epoch[772/1000] loss: 0.061449672786458846
I0419 11:51:03.211966 20188 trainer.py:139] Epoch[773/1000] loss: 0.06145224804359098
I0419 11:51:12.858112 20188 trainer.py:139] Epoch[774/1000] loss: 0.06175526610064891
I0419 11:51:20.475898 20188 trainer.py:139] Epoch[775/1000] loss: 0.061760286410008705
I0419 11:51:27.719080 20188 trainer.py:139] Epoch[776/1000] loss: 0.06164126332488752
I0419 11:51:35.257346 20188 trainer.py:139] Epoch[777/1000] loss: 0.061683615789778774
I0419 11:51:42.713625 20188 trainer.py:139] Epoch[778/1000] loss: 0.06187358594709827
I0419 11:51:50.166268 20188 trainer.py:139] Epoch[779/1000] loss: 0.06222888893417774
I0419 11:51:57.490325 20188 trainer.py:139] Epoch[780/1000] loss: 0.06229983774885055
I0419 11:52:05.046091 20188 trainer.py:139] Epoch[781/1000] loss: 0.06148863595820243
I0419 11:52:12.594254 20188 trainer.py:139] Epoch[782/1000] loss: 0.06136720273042879
I0419 11:52:20.248769 20188 trainer.py:139] Epoch[783/1000] loss: 0.06208999749393233
I0419 11:52:29.916700 20188 trainer.py:139] Epoch[784/1000] loss: 0.06165608577430248
I0419 11:52:37.584302 20188 trainer.py:139] Epoch[785/1000] loss: 0.06181890859959587
I0419 11:52:45.099172 20188 trainer.py:139] Epoch[786/1000] loss: 0.062031883746385574
I0419 11:52:52.512042 20188 trainer.py:139] Epoch[787/1000] loss: 0.06186442551833968
I0419 11:53:00.025275 20188 trainer.py:139] Epoch[788/1000] loss: 0.06231037689553153
I0419 11:53:07.443275 20188 trainer.py:139] Epoch[789/1000] loss: 0.06220708907611908
I0419 11:53:14.709471 20188 trainer.py:139] Epoch[790/1000] loss: 0.06184900888512211
I0419 11:53:22.280147 20188 trainer.py:139] Epoch[791/1000] loss: 0.06220635909947657
I0419 11:53:29.619244 20188 trainer.py:139] Epoch[792/1000] loss: 0.061637293847818526
I0419 11:53:39.199603 20188 trainer.py:139] Epoch[793/1000] loss: 0.061216771602630615
I0419 11:53:46.218371 20188 trainer.py:139] Epoch[794/1000] loss: 0.06223091501141748
I0419 11:53:53.360449 20188 trainer.py:139] Epoch[795/1000] loss: 0.06255726227837224
I0419 11:54:00.377130 20188 trainer.py:139] Epoch[796/1000] loss: 0.061609302557283835
I0419 11:54:07.278614 20188 trainer.py:139] Epoch[797/1000] loss: 0.06049086057370709
I0419 11:54:14.344476 20188 trainer.py:139] Epoch[798/1000] loss: 0.06210842848785462
I0419 11:54:21.401888 20188 trainer.py:139] Epoch[799/1000] loss: 0.062122112560656764
I0419 11:54:21.951052 20188 trainer.py:145] Test: [{'precision': 0.012924884599244657, 'recall': 0.1677354142104457, 'hit_ratio': 0.24464960134284516, 'ndcg': 0.0797253003970289}]
I0419 11:54:29.162584 20188 trainer.py:139] Epoch[800/1000] loss: 0.061671032900771784
I0419 11:54:36.097874 20188 trainer.py:139] Epoch[801/1000] loss: 0.06222222114522611
I0419 11:54:43.291107 20188 trainer.py:139] Epoch[802/1000] loss: 0.062086633917304776
I0419 11:54:50.367036 20188 trainer.py:139] Epoch[803/1000] loss: 0.06146508689609266
I0419 11:54:57.429516 20188 trainer.py:139] Epoch[804/1000] loss: 0.06173168573408357
I0419 11:55:04.439597 20188 trainer.py:139] Epoch[805/1000] loss: 0.06131319425279094
I0419 11:55:11.405243 20188 trainer.py:139] Epoch[806/1000] loss: 0.06138018458600967
I0419 11:55:18.341232 20188 trainer.py:139] Epoch[807/1000] loss: 0.061004989329845674
I0419 11:55:25.501156 20188 trainer.py:139] Epoch[808/1000] loss: 0.062049725243160804
I0419 11:55:32.549654 20188 trainer.py:139] Epoch[809/1000] loss: 0.06227665965355212
I0419 11:55:39.691703 20188 trainer.py:139] Epoch[810/1000] loss: 0.062275213099295096
I0419 11:55:46.846189 20188 trainer.py:139] Epoch[811/1000] loss: 0.06132483085797679
I0419 11:55:53.768579 20188 trainer.py:139] Epoch[812/1000] loss: 0.06186643314938391
I0419 11:56:00.806956 20188 trainer.py:139] Epoch[813/1000] loss: 0.06154506629513156
I0419 11:56:08.058306 20188 trainer.py:139] Epoch[814/1000] loss: 0.06119686130794787
I0419 11:56:15.039156 20188 trainer.py:139] Epoch[815/1000] loss: 0.06250423769797048
I0419 11:56:21.340357 20188 trainer.py:139] Epoch[816/1000] loss: 0.06183263473212719
I0419 11:56:27.622397 20188 trainer.py:139] Epoch[817/1000] loss: 0.061428150342356776
I0419 11:56:33.933519 20188 trainer.py:139] Epoch[818/1000] loss: 0.060869003495862405
I0419 11:56:40.293724 20188 trainer.py:139] Epoch[819/1000] loss: 0.06270970097712932
I0419 11:56:46.604096 20188 trainer.py:139] Epoch[820/1000] loss: 0.0614819455771677
I0419 11:56:53.092958 20188 trainer.py:139] Epoch[821/1000] loss: 0.06234693935801906
I0419 11:56:59.574836 20188 trainer.py:139] Epoch[822/1000] loss: 0.06207477169171456
I0419 11:57:06.077458 20188 trainer.py:139] Epoch[823/1000] loss: 0.062182109382364056
I0419 11:57:12.415922 20188 trainer.py:139] Epoch[824/1000] loss: 0.06266064851755096
I0419 11:57:18.859995 20188 trainer.py:139] Epoch[825/1000] loss: 0.062274240498100555
I0419 11:57:25.226454 20188 trainer.py:139] Epoch[826/1000] loss: 0.06205535349586318
I0419 11:57:31.526951 20188 trainer.py:139] Epoch[827/1000] loss: 0.06146008905864531
I0419 11:57:37.785104 20188 trainer.py:139] Epoch[828/1000] loss: 0.06077341741371539
I0419 11:57:44.295127 20188 trainer.py:139] Epoch[829/1000] loss: 0.06132170269566198
I0419 11:57:50.706998 20188 trainer.py:139] Epoch[830/1000] loss: 0.06155884295942322
I0419 11:57:57.065883 20188 trainer.py:139] Epoch[831/1000] loss: 0.06145747624818356
I0419 11:58:03.449618 20188 trainer.py:139] Epoch[832/1000] loss: 0.06137915790802048
I0419 11:58:09.807960 20188 trainer.py:139] Epoch[833/1000] loss: 0.06164843066325111
I0419 11:58:16.113964 20188 trainer.py:139] Epoch[834/1000] loss: 0.061081488226209915
I0419 11:58:22.565510 20188 trainer.py:139] Epoch[835/1000] loss: 0.060532282316877
I0419 11:58:28.885059 20188 trainer.py:139] Epoch[836/1000] loss: 0.0615470835999135
I0419 11:58:35.296871 20188 trainer.py:139] Epoch[837/1000] loss: 0.06113472430696411
I0419 11:58:41.721111 20188 trainer.py:139] Epoch[838/1000] loss: 0.06082859965822389
I0419 11:58:48.271758 20188 trainer.py:139] Epoch[839/1000] loss: 0.06191233383311379
I0419 11:58:54.569189 20188 trainer.py:139] Epoch[840/1000] loss: 0.060914948762905215
I0419 11:59:01.068831 20188 trainer.py:139] Epoch[841/1000] loss: 0.06226210025770049
I0419 11:59:07.375500 20188 trainer.py:139] Epoch[842/1000] loss: 0.06064554658387938
I0419 11:59:13.860721 20188 trainer.py:139] Epoch[843/1000] loss: 0.0610930428750092
I0419 11:59:20.218849 20188 trainer.py:139] Epoch[844/1000] loss: 0.06198638263008287
I0419 11:59:26.577599 20188 trainer.py:139] Epoch[845/1000] loss: 0.06056435940967452
I0419 11:59:32.980438 20188 trainer.py:139] Epoch[846/1000] loss: 0.06200236478640187
I0419 11:59:39.347084 20188 trainer.py:139] Epoch[847/1000] loss: 0.061415171190615625
I0419 11:59:45.782391 20188 trainer.py:139] Epoch[848/1000] loss: 0.061357165055890235
I0419 11:59:52.113563 20188 trainer.py:139] Epoch[849/1000] loss: 0.061563025679319136
I0419 11:59:52.563582 20188 trainer.py:145] Test: [{'precision': 0.012757028955098624, 'recall': 0.1637558366471501, 'hit_ratio': 0.24213176668065464, 'ndcg': 0.0778411055385135}]
I0419 11:59:59.050366 20188 trainer.py:139] Epoch[850/1000] loss: 0.06062668015158946
I0419 12:00:05.507872 20188 trainer.py:139] Epoch[851/1000] loss: 0.06105719530774701
I0419 12:00:11.989434 20188 trainer.py:139] Epoch[852/1000] loss: 0.06102596067132488
I0419 12:00:18.254393 20188 trainer.py:139] Epoch[853/1000] loss: 0.060823422105562304
I0419 12:00:24.660822 20188 trainer.py:139] Epoch[854/1000] loss: 0.06086198030219924
I0419 12:00:31.093789 20188 trainer.py:139] Epoch[855/1000] loss: 0.06172081233272629
I0419 12:00:37.560134 20188 trainer.py:139] Epoch[856/1000] loss: 0.06100336119772926
I0419 12:00:43.940336 20188 trainer.py:139] Epoch[857/1000] loss: 0.06195495277643204
I0419 12:00:50.280129 20188 trainer.py:139] Epoch[858/1000] loss: 0.06133456924749959
I0419 12:00:56.648391 20188 trainer.py:139] Epoch[859/1000] loss: 0.06133726022897228
I0419 12:01:03.072701 20188 trainer.py:139] Epoch[860/1000] loss: 0.06131396220336037
I0419 12:01:09.451511 20188 trainer.py:139] Epoch[861/1000] loss: 0.06146454192217319
I0419 12:01:15.880440 20188 trainer.py:139] Epoch[862/1000] loss: 0.0624090903588841
I0419 12:01:22.383586 20188 trainer.py:139] Epoch[863/1000] loss: 0.06226129835892108
I0419 12:01:28.704337 20188 trainer.py:139] Epoch[864/1000] loss: 0.06031083423764475
I0419 12:01:35.159257 20188 trainer.py:139] Epoch[865/1000] loss: 0.06015604271763755
I0419 12:01:41.681341 20188 trainer.py:139] Epoch[866/1000] loss: 0.06143348153320051
I0419 12:01:47.989194 20188 trainer.py:139] Epoch[867/1000] loss: 0.06165958556436723
I0419 12:01:54.337449 20188 trainer.py:139] Epoch[868/1000] loss: 0.06208666365954184
I0419 12:02:00.651437 20188 trainer.py:139] Epoch[869/1000] loss: 0.06125890697923399
I0419 12:02:07.210107 20188 trainer.py:139] Epoch[870/1000] loss: 0.061221751053967786
I0419 12:02:13.744013 20188 trainer.py:139] Epoch[871/1000] loss: 0.061021181123871955
I0419 12:02:20.166018 20188 trainer.py:139] Epoch[872/1000] loss: 0.06204799244240407
I0419 12:02:26.835284 20188 trainer.py:139] Epoch[873/1000] loss: 0.06239540346207157
I0419 12:02:33.223486 20188 trainer.py:139] Epoch[874/1000] loss: 0.06181226911083344
I0419 12:02:39.570761 20188 trainer.py:139] Epoch[875/1000] loss: 0.06153900146244034
I0419 12:02:45.928982 20188 trainer.py:139] Epoch[876/1000] loss: 0.06223122162684318
I0419 12:02:52.435844 20188 trainer.py:139] Epoch[877/1000] loss: 0.06153193350520826
I0419 12:02:58.778892 20188 trainer.py:139] Epoch[878/1000] loss: 0.061959078174925616
I0419 12:03:05.204867 20188 trainer.py:139] Epoch[879/1000] loss: 0.061999314795097994
I0419 12:03:11.561898 20188 trainer.py:139] Epoch[880/1000] loss: 0.06227298717825643
I0419 12:03:18.200005 20188 trainer.py:139] Epoch[881/1000] loss: 0.06182273056718611
I0419 12:03:24.561570 20188 trainer.py:139] Epoch[882/1000] loss: 0.061633612900491686
I0419 12:03:31.098010 20188 trainer.py:139] Epoch[883/1000] loss: 0.061134039394317136
I0419 12:03:37.450924 20188 trainer.py:139] Epoch[884/1000] loss: 0.06147747552923618
I0419 12:03:43.916214 20188 trainer.py:139] Epoch[885/1000] loss: 0.06065449292861646
I0419 12:03:50.325056 20188 trainer.py:139] Epoch[886/1000] loss: 0.061663528483721516
I0419 12:03:56.861688 20188 trainer.py:139] Epoch[887/1000] loss: 0.06120770472672678
I0419 12:04:03.269938 20188 trainer.py:139] Epoch[888/1000] loss: 0.06180310333448072
I0419 12:04:09.715411 20188 trainer.py:139] Epoch[889/1000] loss: 0.06192981049178108
I0419 12:04:16.133375 20188 trainer.py:139] Epoch[890/1000] loss: 0.061059431443291325
I0419 12:04:22.558310 20188 trainer.py:139] Epoch[891/1000] loss: 0.06129158913127838
I0419 12:04:28.936970 20188 trainer.py:139] Epoch[892/1000] loss: 0.06087754889120979
I0419 12:04:35.374164 20188 trainer.py:139] Epoch[893/1000] loss: 0.06152424162193652
I0419 12:04:41.760761 20188 trainer.py:139] Epoch[894/1000] loss: 0.06027998661081637
I0419 12:04:48.118471 20188 trainer.py:139] Epoch[895/1000] loss: 0.060885626402112744
I0419 12:04:54.502080 20188 trainer.py:139] Epoch[896/1000] loss: 0.06056237040508178
I0419 12:05:00.818774 20188 trainer.py:139] Epoch[897/1000] loss: 0.06091985286724183
I0419 12:05:07.257803 20188 trainer.py:139] Epoch[898/1000] loss: 0.06176269649257583
I0419 12:05:13.532746 20188 trainer.py:139] Epoch[899/1000] loss: 0.06129873592045999
I0419 12:05:13.991212 20188 trainer.py:145] Test: [{'precision': 0.012736046999580366, 'recall': 0.1639866381578509, 'hit_ratio': 0.24213176668065464, 'ndcg': 0.07824080560576918}]
I0419 12:05:20.279846 20188 trainer.py:139] Epoch[900/1000] loss: 0.060983169102861036
I0419 12:05:26.470226 20188 trainer.py:139] Epoch[901/1000] loss: 0.061301373425991304
I0419 12:05:32.771037 20188 trainer.py:139] Epoch[902/1000] loss: 0.06077364279377845
I0419 12:05:39.028466 20188 trainer.py:139] Epoch[903/1000] loss: 0.061168831202291676
I0419 12:05:45.528110 20188 trainer.py:139] Epoch[904/1000] loss: 0.06094719607743525
I0419 12:05:51.789158 20188 trainer.py:139] Epoch[905/1000] loss: 0.06186578879433294
I0419 12:05:58.217350 20188 trainer.py:139] Epoch[906/1000] loss: 0.061215237984734196
I0419 12:06:04.462934 20188 trainer.py:139] Epoch[907/1000] loss: 0.06133070167514586
I0419 12:06:10.780055 20188 trainer.py:139] Epoch[908/1000] loss: 0.061646001653805856
I0419 12:06:17.217191 20188 trainer.py:139] Epoch[909/1000] loss: 0.062096048927595536
I0419 12:06:23.765135 20188 trainer.py:139] Epoch[910/1000] loss: 0.06121559975849044
I0419 12:06:30.267022 20188 trainer.py:139] Epoch[911/1000] loss: 0.06137588259673888
I0419 12:06:36.678366 20188 trainer.py:139] Epoch[912/1000] loss: 0.06077653157614892
I0419 12:06:42.996539 20188 trainer.py:139] Epoch[913/1000] loss: 0.0616007671361008
I0419 12:06:49.311074 20188 trainer.py:139] Epoch[914/1000] loss: 0.06087626937416292
I0419 12:06:55.620434 20188 trainer.py:139] Epoch[915/1000] loss: 0.061515485627516624
I0419 12:07:02.258767 20188 trainer.py:139] Epoch[916/1000] loss: 0.061553467605863846
I0419 12:07:08.710862 20188 trainer.py:139] Epoch[917/1000] loss: 0.06227556724221476
I0419 12:07:14.984058 20188 trainer.py:139] Epoch[918/1000] loss: 0.06154779825479754
I0419 12:07:21.452893 20188 trainer.py:139] Epoch[919/1000] loss: 0.05949885722610258
I0419 12:07:27.673877 20188 trainer.py:139] Epoch[920/1000] loss: 0.06134836243525628
I0419 12:07:33.880379 20188 trainer.py:139] Epoch[921/1000] loss: 0.061233450929003376
I0419 12:07:40.046919 20188 trainer.py:139] Epoch[922/1000] loss: 0.061088276245901664
I0419 12:07:46.084093 20188 trainer.py:139] Epoch[923/1000] loss: 0.06115453365829683
I0419 12:07:52.164326 20188 trainer.py:139] Epoch[924/1000] loss: 0.061277493834495544
I0419 12:07:58.246735 20188 trainer.py:139] Epoch[925/1000] loss: 0.0606796610499582
I0419 12:08:04.294998 20188 trainer.py:139] Epoch[926/1000] loss: 0.06119023125258184
I0419 12:08:10.399149 20188 trainer.py:139] Epoch[927/1000] loss: 0.06018652592695529
I0419 12:08:16.397752 20188 trainer.py:139] Epoch[928/1000] loss: 0.061040749472956506
I0419 12:08:22.563726 20188 trainer.py:139] Epoch[929/1000] loss: 0.06064359423133635
I0419 12:08:28.620360 20188 trainer.py:139] Epoch[930/1000] loss: 0.06023701346449314
I0419 12:08:34.763627 20188 trainer.py:139] Epoch[931/1000] loss: 0.06163996872642348
I0419 12:08:40.985841 20188 trainer.py:139] Epoch[932/1000] loss: 0.061488246124598286
I0419 12:08:47.076329 20188 trainer.py:139] Epoch[933/1000] loss: 0.061498486406860814
I0419 12:08:53.062532 20188 trainer.py:139] Epoch[934/1000] loss: 0.06144584132538688
I0419 12:08:59.384104 20188 trainer.py:139] Epoch[935/1000] loss: 0.06162611761641118
I0419 12:09:05.522039 20188 trainer.py:139] Epoch[936/1000] loss: 0.061325168777858055
I0419 12:09:11.802778 20188 trainer.py:139] Epoch[937/1000] loss: 0.06065852092879434
I0419 12:09:18.103059 20188 trainer.py:139] Epoch[938/1000] loss: 0.06039527040575781
I0419 12:09:24.357040 20188 trainer.py:139] Epoch[939/1000] loss: 0.06112136661766037
I0419 12:09:30.742611 20188 trainer.py:139] Epoch[940/1000] loss: 0.06144912865373396
I0419 12:09:36.835383 20188 trainer.py:139] Epoch[941/1000] loss: 0.06153780450263331
I0419 12:09:42.891154 20188 trainer.py:139] Epoch[942/1000] loss: 0.060720665620700005
I0419 12:09:48.775381 20188 trainer.py:139] Epoch[943/1000] loss: 0.061781426531172565
I0419 12:09:54.956198 20188 trainer.py:139] Epoch[944/1000] loss: 0.06120917471426149
I0419 12:10:01.229702 20188 trainer.py:139] Epoch[945/1000] loss: 0.0615305291909364
I0419 12:10:07.457177 20188 trainer.py:139] Epoch[946/1000] loss: 0.06155839826791517
I0419 12:10:13.749004 20188 trainer.py:139] Epoch[947/1000] loss: 0.06209044140433111
I0419 12:10:19.913627 20188 trainer.py:139] Epoch[948/1000] loss: 0.06181229969426509
I0419 12:10:26.079266 20188 trainer.py:139] Epoch[949/1000] loss: 0.06088722497224808
I0419 12:10:26.469421 20188 trainer.py:145] Test: [{'precision': 0.012861938732689891, 'recall': 0.16571415249552052, 'hit_ratio': 0.2433906840117499, 'ndcg': 0.07909602238577854}]
I0419 12:10:32.456151 20188 trainer.py:139] Epoch[950/1000] loss: 0.06110768026161578
I0419 12:10:38.487264 20188 trainer.py:139] Epoch[951/1000] loss: 0.06146319426836506
I0419 12:10:44.908617 20188 trainer.py:139] Epoch[952/1000] loss: 0.061276611781889395
I0419 12:10:51.012759 20188 trainer.py:139] Epoch[953/1000] loss: 0.06093029924217732
I0419 12:10:56.981293 20188 trainer.py:139] Epoch[954/1000] loss: 0.06138180995420102
I0419 12:11:03.047138 20188 trainer.py:139] Epoch[955/1000] loss: 0.06176061567760283
I0419 12:11:09.275640 20188 trainer.py:139] Epoch[956/1000] loss: 0.061279119322857546
I0419 12:11:15.424980 20188 trainer.py:139] Epoch[957/1000] loss: 0.060892907842513055
I0419 12:11:21.600611 20188 trainer.py:139] Epoch[958/1000] loss: 0.06122307004707475
I0419 12:11:27.823134 20188 trainer.py:139] Epoch[959/1000] loss: 0.06111177207241135
I0419 12:11:33.988781 20188 trainer.py:139] Epoch[960/1000] loss: 0.06121700359207968
I0419 12:11:40.039646 20188 trainer.py:139] Epoch[961/1000] loss: 0.06092712613603761
I0419 12:11:46.272742 20188 trainer.py:139] Epoch[962/1000] loss: 0.060505622817624
I0419 12:11:52.217290 20188 trainer.py:139] Epoch[963/1000] loss: 0.061014110162373514
I0419 12:11:58.553476 20188 trainer.py:139] Epoch[964/1000] loss: 0.06093167940214757
I0419 12:12:04.672193 20188 trainer.py:139] Epoch[965/1000] loss: 0.060395231650721644
I0419 12:12:10.915715 20188 trainer.py:139] Epoch[966/1000] loss: 0.06081454533963434
I0419 12:12:17.156019 20188 trainer.py:139] Epoch[967/1000] loss: 0.06132644625200379
I0419 12:12:23.643396 20188 trainer.py:139] Epoch[968/1000] loss: 0.06076087646426693
I0419 12:12:29.968261 20188 trainer.py:139] Epoch[969/1000] loss: 0.06018807366490364
I0419 12:12:36.283363 20188 trainer.py:139] Epoch[970/1000] loss: 0.06080361822199437
I0419 12:12:42.766778 20188 trainer.py:139] Epoch[971/1000] loss: 0.06111732852314749
I0419 12:12:49.248494 20188 trainer.py:139] Epoch[972/1000] loss: 0.0603379737585783
I0419 12:12:55.665614 20188 trainer.py:139] Epoch[973/1000] loss: 0.061110269879141164
I0419 12:13:01.960715 20188 trainer.py:139] Epoch[974/1000] loss: 0.061228381890443065
I0419 12:13:08.281260 20188 trainer.py:139] Epoch[975/1000] loss: 0.06126121251333144
I0419 12:13:14.739917 20188 trainer.py:139] Epoch[976/1000] loss: 0.06093990418218797
I0419 12:13:21.059070 20188 trainer.py:139] Epoch[977/1000] loss: 0.061506909768908255
I0419 12:13:27.324106 20188 trainer.py:139] Epoch[978/1000] loss: 0.06163986796332944
I0419 12:13:33.490985 20188 trainer.py:139] Epoch[979/1000] loss: 0.06066342299022982
I0419 12:13:39.846183 20188 trainer.py:139] Epoch[980/1000] loss: 0.060826106417563655
I0419 12:13:46.168133 20188 trainer.py:139] Epoch[981/1000] loss: 0.06070256209181201
I0419 12:13:52.360276 20188 trainer.py:139] Epoch[982/1000] loss: 0.06122626862939327
I0419 12:13:58.478979 20188 trainer.py:139] Epoch[983/1000] loss: 0.06040409453693898
I0419 12:14:04.608926 20188 trainer.py:139] Epoch[984/1000] loss: 0.060979480885209575
I0419 12:14:10.818497 20188 trainer.py:139] Epoch[985/1000] loss: 0.060682697401892756
I0419 12:14:17.025841 20188 trainer.py:139] Epoch[986/1000] loss: 0.06085374392569065
I0419 12:14:23.289878 20188 trainer.py:139] Epoch[987/1000] loss: 0.061537055418856686
I0419 12:14:29.639641 20188 trainer.py:139] Epoch[988/1000] loss: 0.06070998863827798
I0419 12:14:36.000217 20188 trainer.py:139] Epoch[989/1000] loss: 0.061350755754017064
I0419 12:14:42.364508 20188 trainer.py:139] Epoch[990/1000] loss: 0.060899683724968665
I0419 12:14:48.547192 20188 trainer.py:139] Epoch[991/1000] loss: 0.0609568091289651
I0419 12:14:54.871436 20188 trainer.py:139] Epoch[992/1000] loss: 0.06129126388940119
I0419 12:15:01.195161 20188 trainer.py:139] Epoch[993/1000] loss: 0.06052048258002727
I0419 12:15:07.234526 20188 trainer.py:139] Epoch[994/1000] loss: 0.061190572296900135
I0419 12:15:13.524921 20188 trainer.py:139] Epoch[995/1000] loss: 0.060482662351381396
I0419 12:15:19.816489 20188 trainer.py:139] Epoch[996/1000] loss: 0.060509846936310493
I0419 12:15:26.251249 20188 trainer.py:139] Epoch[997/1000] loss: 0.06078194328133137
I0419 12:15:32.924226 20188 trainer.py:139] Epoch[998/1000] loss: 0.0601175845029854
I0419 12:15:39.231004 20188 trainer.py:139] Epoch[999/1000] loss: 0.061143178432699175
I0419 12:15:39.632660 20188 trainer.py:145] Test: [{'precision': 0.012778010910616875, 'recall': 0.1647979404378901, 'hit_ratio': 0.2433906840117499, 'ndcg': 0.07980097968783897}]
