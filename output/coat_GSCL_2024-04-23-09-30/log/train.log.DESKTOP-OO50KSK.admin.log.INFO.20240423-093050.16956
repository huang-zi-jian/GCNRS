I0423 09:30:51.796826 19172 trainer.py:118] Test: [{'precision': 0.016877637130801676, 'recall': 0.10538389177629681, 'hit_ratio': 0.29535864978902954, 'ndcg': 0.05469991283215165}]
I0423 09:30:53.174972 19172 trainer.py:136] Epoch[0/200] loss: 0.6686500747998555
I0423 09:30:54.682108 19172 trainer.py:136] Epoch[1/200] loss: 0.6304746866226196
I0423 09:30:56.423848 19172 trainer.py:136] Epoch[2/200] loss: 0.6048426330089569
I0423 09:30:58.211962 19172 trainer.py:136] Epoch[3/200] loss: 0.5592183689276378
I0423 09:30:59.886949 19172 trainer.py:136] Epoch[4/200] loss: 0.5278614302476247
I0423 09:31:01.584239 19172 trainer.py:136] Epoch[5/200] loss: 0.48235957622528075
I0423 09:31:03.262756 19172 trainer.py:136] Epoch[6/200] loss: 0.46565167705217997
I0423 09:31:04.959802 19172 trainer.py:136] Epoch[7/200] loss: 0.4241593321164449
I0423 09:31:06.668757 19172 trainer.py:136] Epoch[8/200] loss: 0.41035374701023103
I0423 09:31:08.354298 19172 trainer.py:136] Epoch[9/200] loss: 0.38893812596797944
I0423 09:31:10.042768 19172 trainer.py:136] Epoch[10/200] loss: 0.36000003218650817
I0423 09:31:11.736660 19172 trainer.py:136] Epoch[11/200] loss: 0.34819549818833667
I0423 09:31:13.410239 19172 trainer.py:136] Epoch[12/200] loss: 0.3474060297012329
I0423 09:31:15.121654 19172 trainer.py:136] Epoch[13/200] loss: 0.33151494562625883
I0423 09:31:16.806398 19172 trainer.py:136] Epoch[14/200] loss: 0.3380879670381546
I0423 09:31:18.484346 19172 trainer.py:136] Epoch[15/200] loss: 0.3176834916075071
I0423 09:31:20.157876 19172 trainer.py:136] Epoch[16/200] loss: 0.3025976702570915
I0423 09:31:21.832833 19172 trainer.py:136] Epoch[17/200] loss: 0.29200595021247866
I0423 09:31:23.537683 19172 trainer.py:136] Epoch[18/200] loss: 0.3040422429641088
I0423 09:31:25.213231 19172 trainer.py:136] Epoch[19/200] loss: 0.2979820435245832
I0423 09:31:26.910703 19172 trainer.py:136] Epoch[20/200] loss: 0.29112101793289186
I0423 09:31:28.660394 19172 trainer.py:136] Epoch[21/200] loss: 0.2757944797476133
I0423 09:31:30.433587 19172 trainer.py:136] Epoch[22/200] loss: 0.29824173798163733
I0423 09:31:32.226777 19172 trainer.py:136] Epoch[23/200] loss: 0.2703120852510134
I0423 09:31:33.915743 19172 trainer.py:136] Epoch[24/200] loss: 0.27197752048571905
I0423 09:31:35.583742 19172 trainer.py:136] Epoch[25/200] loss: 0.27620256145795186
I0423 09:31:37.259401 19172 trainer.py:136] Epoch[26/200] loss: 0.2662898247440656
I0423 09:31:38.957904 19172 trainer.py:136] Epoch[27/200] loss: 0.2608974456787109
I0423 09:31:40.640844 19172 trainer.py:136] Epoch[28/200] loss: 0.24512207607428232
I0423 09:31:42.345500 19172 trainer.py:136] Epoch[29/200] loss: 0.2638119921088219
I0423 09:31:44.028052 19172 trainer.py:136] Epoch[30/200] loss: 0.2711499884724617
I0423 09:31:45.722959 19172 trainer.py:136] Epoch[31/200] loss: 0.25343819161256154
I0423 09:31:47.454370 19172 trainer.py:136] Epoch[32/200] loss: 0.26246216893196106
I0423 09:31:49.154055 19172 trainer.py:136] Epoch[33/200] loss: 0.251896836857001
I0423 09:31:50.836496 19172 trainer.py:136] Epoch[34/200] loss: 0.23503274818261463
I0423 09:31:52.538152 19172 trainer.py:136] Epoch[35/200] loss: 0.24407522926727931
I0423 09:31:54.256462 19172 trainer.py:136] Epoch[36/200] loss: 0.24313698212305704
I0423 09:31:55.933980 19172 trainer.py:136] Epoch[37/200] loss: 0.2379961575071017
I0423 09:31:57.630835 19172 trainer.py:136] Epoch[38/200] loss: 0.2487976670265198
I0423 09:31:59.335339 19172 trainer.py:136] Epoch[39/200] loss: 0.2370816687742869
I0423 09:32:01.115525 19172 trainer.py:136] Epoch[40/200] loss: 0.22853145052989324
I0423 09:32:02.897691 19172 trainer.py:136] Epoch[41/200] loss: 0.23198296278715133
I0423 09:32:04.697234 19172 trainer.py:136] Epoch[42/200] loss: 0.23614410658677418
I0423 09:32:06.424747 19172 trainer.py:136] Epoch[43/200] loss: 0.23128031889597575
I0423 09:32:08.102979 19172 trainer.py:136] Epoch[44/200] loss: 0.23376685877641043
I0423 09:32:09.789446 19172 trainer.py:136] Epoch[45/200] loss: 0.2295438970128695
I0423 09:32:11.513234 19172 trainer.py:136] Epoch[46/200] loss: 0.22058541129032772
I0423 09:32:13.194422 19172 trainer.py:136] Epoch[47/200] loss: 0.21951706906159718
I0423 09:32:14.929739 19172 trainer.py:136] Epoch[48/200] loss: 0.21728338897228242
I0423 09:32:16.615666 19172 trainer.py:136] Epoch[49/200] loss: 0.2366649717092514
I0423 09:32:16.644569 19172 trainer.py:142] Test: [{'precision': 0.02299578059071728, 'recall': 0.1579742924679633, 'hit_ratio': 0.379746835443038, 'ndcg': 0.0768705665308676}]
I0423 09:32:18.337055 19172 trainer.py:136] Epoch[50/200] loss: 0.21805816640456518
I0423 09:32:20.052454 19172 trainer.py:136] Epoch[51/200] loss: 0.2009764994184176
I0423 09:32:21.735386 19172 trainer.py:136] Epoch[52/200] loss: 0.2006820797920227
I0423 09:32:23.412885 19172 trainer.py:136] Epoch[53/200] loss: 0.21155795454978943
I0423 09:32:25.084324 19172 trainer.py:136] Epoch[54/200] loss: 0.20902366985877355
I0423 09:32:26.793792 19172 trainer.py:136] Epoch[55/200] loss: 0.20909927984078724
I0423 09:32:28.490234 19172 trainer.py:136] Epoch[56/200] loss: 0.20286685973405838
I0423 09:32:30.258449 19172 trainer.py:136] Epoch[57/200] loss: 0.20446057319641114
I0423 09:32:32.021068 19172 trainer.py:136] Epoch[58/200] loss: 0.207090034087499
I0423 09:32:33.786333 19172 trainer.py:136] Epoch[59/200] loss: 0.21764737914005916
I0423 09:32:35.456274 19172 trainer.py:136] Epoch[60/200] loss: 0.19779072950283685
I0423 09:32:37.112862 19172 trainer.py:136] Epoch[61/200] loss: 0.20784728328386942
I0423 09:32:38.816263 19172 trainer.py:136] Epoch[62/200] loss: 0.20329642792542776
I0423 09:32:40.498226 19172 trainer.py:136] Epoch[63/200] loss: 0.19898727387189866
I0423 09:32:42.170831 19172 trainer.py:136] Epoch[64/200] loss: 0.19642528345187504
I0423 09:32:43.867285 19172 trainer.py:136] Epoch[65/200] loss: 0.1973889966805776
I0423 09:32:45.574144 19172 trainer.py:136] Epoch[66/200] loss: 0.18516039475798607
I0423 09:32:47.245717 19172 trainer.py:136] Epoch[67/200] loss: 0.19369987746079761
I0423 09:32:48.917497 19172 trainer.py:136] Epoch[68/200] loss: 0.1961549128095309
I0423 09:32:50.632329 19172 trainer.py:136] Epoch[69/200] loss: 0.18733494381109875
I0423 09:32:52.311866 19172 trainer.py:136] Epoch[70/200] loss: 0.20076449712117514
I0423 09:32:53.980406 19172 trainer.py:136] Epoch[71/200] loss: 0.18045753464102746
I0423 09:32:55.660397 19172 trainer.py:136] Epoch[72/200] loss: 0.20015816316008567
I0423 09:32:57.366260 19172 trainer.py:136] Epoch[73/200] loss: 0.18713526129722596
I0423 09:32:59.054782 19172 trainer.py:136] Epoch[74/200] loss: 0.19672651092211405
I0423 09:33:00.826973 19172 trainer.py:136] Epoch[75/200] loss: 0.18770459443330764
I0423 09:33:02.576689 19172 trainer.py:136] Epoch[76/200] loss: 0.18955999314785005
I0423 09:33:04.299128 19172 trainer.py:136] Epoch[77/200] loss: 0.197157055636247
I0423 09:33:05.978670 19172 trainer.py:136] Epoch[78/200] loss: 0.19880414605140687
I0423 09:33:07.661151 19172 trainer.py:136] Epoch[79/200] loss: 0.1758532116810481
I0423 09:33:09.360652 19172 trainer.py:136] Epoch[80/200] loss: 0.18259537518024443
I0423 09:33:11.046127 19172 trainer.py:136] Epoch[81/200] loss: 0.17322256391247112
I0423 09:33:12.730589 19172 trainer.py:136] Epoch[82/200] loss: 0.17090320885181426
I0423 09:33:14.451601 19172 trainer.py:136] Epoch[83/200] loss: 0.18452997331817944
I0423 09:33:16.125643 19172 trainer.py:136] Epoch[84/200] loss: 0.1951922113696734
I0423 09:33:17.832096 19172 trainer.py:136] Epoch[85/200] loss: 0.18405796686808268
I0423 09:33:19.524984 19172 trainer.py:136] Epoch[86/200] loss: 0.18524250735839207
I0423 09:33:21.235361 19172 trainer.py:136] Epoch[87/200] loss: 0.18402660191059111
I0423 09:33:22.915192 19172 trainer.py:136] Epoch[88/200] loss: 0.17885731781522432
I0423 09:33:24.648951 19172 trainer.py:136] Epoch[89/200] loss: 0.1835060767829418
I0423 09:33:26.333155 19172 trainer.py:136] Epoch[90/200] loss: 0.19368702198068302
I0423 09:33:28.016308 19172 trainer.py:136] Epoch[91/200] loss: 0.16881874601046246
I0423 09:33:29.686281 19172 trainer.py:136] Epoch[92/200] loss: 0.1860758659740289
I0423 09:33:31.384333 19172 trainer.py:136] Epoch[93/200] loss: 0.17729032884041468
I0423 09:33:33.094084 19172 trainer.py:136] Epoch[94/200] loss: 0.17224651674429575
I0423 09:33:34.782894 19172 trainer.py:136] Epoch[95/200] loss: 0.17394904717803
I0423 09:33:36.551067 19172 trainer.py:136] Epoch[96/200] loss: 0.17368918309609097
I0423 09:33:38.287362 19172 trainer.py:136] Epoch[97/200] loss: 0.16779931187629699
I0423 09:33:39.976118 19172 trainer.py:136] Epoch[98/200] loss: 0.1611062119404475
I0423 09:33:41.639118 19172 trainer.py:136] Epoch[99/200] loss: 0.1827521617213885
I0423 09:33:41.670014 19172 trainer.py:142] Test: [{'precision': 0.024050632911392384, 'recall': 0.1725271587296903, 'hit_ratio': 0.4081856540084388, 'ndcg': 0.081689964805663775}]
I0423 09:33:43.349582 19172 trainer.py:136] Epoch[100/200] loss: 0.1695345123608907
I0423 09:33:45.041471 19172 trainer.py:136] Epoch[101/200] loss: 0.1659615822136402
I0423 09:33:46.715067 19172 trainer.py:136] Epoch[102/200] loss: 0.16979905640085538
I0423 09:33:48.409580 19172 trainer.py:136] Epoch[103/200] loss: 0.16707404603560766
I0423 09:33:50.088046 19172 trainer.py:136] Epoch[104/200] loss: 0.17123345881700516
I0423 09:33:51.761030 19172 trainer.py:136] Epoch[105/200] loss: 0.17830020412802697
I0423 09:33:53.438599 19172 trainer.py:136] Epoch[106/200] loss: 0.1734192629655202
I0423 09:33:55.111174 19172 trainer.py:136] Epoch[107/200] loss: 0.1668765552341938
I0423 09:33:56.782722 19172 trainer.py:136] Epoch[108/200] loss: 0.17205404018362364
I0423 09:33:58.462681 19172 trainer.py:136] Epoch[109/200] loss: 0.1698798899849256
I0423 09:34:00.146205 19172 trainer.py:136] Epoch[110/200] loss: 0.1654462806880474
I0423 09:34:01.830678 19172 trainer.py:136] Epoch[111/200] loss: 0.16398469309012095
I0423 09:34:03.522432 19172 trainer.py:136] Epoch[112/200] loss: 0.16827908009290696
I0423 09:34:05.210204 19172 trainer.py:136] Epoch[113/200] loss: 0.1708248198032379
I0423 09:34:06.869820 19172 trainer.py:136] Epoch[114/200] loss: 0.1598645361761252
I0423 09:34:08.541829 19172 trainer.py:136] Epoch[115/200] loss: 0.15999611765146254
I0423 09:34:10.217430 19172 trainer.py:136] Epoch[116/200] loss: 0.17311227396130563
I0423 09:34:11.901124 19172 trainer.py:136] Epoch[117/200] loss: 0.17177124718825024
I0423 09:34:13.585094 19172 trainer.py:136] Epoch[118/200] loss: 0.17279429584741593
I0423 09:34:15.255676 19172 trainer.py:136] Epoch[119/200] loss: 0.1802870233853658
I0423 09:34:16.937165 19172 trainer.py:136] Epoch[120/200] loss: 0.16245205228527387
I0423 09:34:18.612114 19172 trainer.py:136] Epoch[121/200] loss: 0.15378679235776266
I0423 09:34:20.281701 19172 trainer.py:136] Epoch[122/200] loss: 0.15622731844584148
I0423 09:34:21.958251 19172 trainer.py:136] Epoch[123/200] loss: 0.1606782006720702
I0423 09:34:23.643651 19172 trainer.py:136] Epoch[124/200] loss: 0.1724938953916232
I0423 09:34:25.316916 19172 trainer.py:136] Epoch[125/200] loss: 0.16933927138646443
I0423 09:34:26.995345 19172 trainer.py:136] Epoch[126/200] loss: 0.18498901749650637
I0423 09:34:28.675312 19172 trainer.py:136] Epoch[127/200] loss: 0.15926123932003974
I0423 09:34:30.355570 19172 trainer.py:136] Epoch[128/200] loss: 0.1645221784710884
I0423 09:34:32.032695 19172 trainer.py:136] Epoch[129/200] loss: 0.17116678034265836
I0423 09:34:33.706655 19172 trainer.py:136] Epoch[130/200] loss: 0.16561042740941048
I0423 09:34:35.486921 19172 trainer.py:136] Epoch[131/200] loss: 0.16359495371580124
I0423 09:34:37.165594 19172 trainer.py:136] Epoch[132/200] loss: 0.16496196016669273
I0423 09:34:38.838201 19172 trainer.py:136] Epoch[133/200] loss: 0.15895895386735598
I0423 09:34:40.505192 19172 trainer.py:136] Epoch[134/200] loss: 0.15759901677568752
I0423 09:34:42.182691 19172 trainer.py:136] Epoch[135/200] loss: 0.15347146540880202
I0423 09:34:43.947946 19172 trainer.py:136] Epoch[136/200] loss: 0.149047206590573
I0423 09:34:45.633932 19172 trainer.py:136] Epoch[137/200] loss: 0.162626792738835
I0423 09:34:47.344340 19172 trainer.py:136] Epoch[138/200] loss: 0.161403967688481
I0423 09:34:49.010806 19172 trainer.py:136] Epoch[139/200] loss: 0.1591261774301529
I0423 09:34:50.683219 19172 trainer.py:136] Epoch[140/200] loss: 0.1578082635998726
I0423 09:34:52.433022 19172 trainer.py:136] Epoch[141/200] loss: 0.16756953472892444
I0423 09:34:54.115486 19172 trainer.py:136] Epoch[142/200] loss: 0.1593086582918962
I0423 09:34:55.798218 19172 trainer.py:136] Epoch[143/200] loss: 0.15554283758004506
I0423 09:34:57.464100 19172 trainer.py:136] Epoch[144/200] loss: 0.1635345975557963
I0423 09:34:59.151988 19172 trainer.py:136] Epoch[145/200] loss: 0.16573021734754245
I0423 09:35:00.821493 19172 trainer.py:136] Epoch[146/200] loss: 0.15573651269078254
I0423 09:35:02.491784 19172 trainer.py:136] Epoch[147/200] loss: 0.15835848475495976
I0423 09:35:04.170025 19172 trainer.py:136] Epoch[148/200] loss: 0.15843926469484965
I0423 09:35:05.852642 19172 trainer.py:136] Epoch[149/200] loss: 0.17243372201919555
I0423 09:35:05.882543 19172 trainer.py:142] Test: [{'precision': 0.023628691983122337, 'recall': 0.17481068251953276, 'hit_ratio': 0.399746835443038, 'ndcg': 0.08143881921715158}]
I0423 09:35:07.566451 19172 trainer.py:136] Epoch[150/200] loss: 0.15802985007564227
I0423 09:35:09.242983 19172 trainer.py:136] Epoch[151/200] loss: 0.1485369771718979
I0423 09:35:10.900590 19172 trainer.py:136] Epoch[152/200] loss: 0.1591387666761875
I0423 09:35:12.574923 19172 trainer.py:136] Epoch[153/200] loss: 0.14848172217607497
I0423 09:35:14.245529 19172 trainer.py:136] Epoch[154/200] loss: 0.16818661590417225
I0423 09:35:15.914787 19172 trainer.py:136] Epoch[155/200] loss: 0.16972281088431676
I0423 09:35:17.589691 19172 trainer.py:136] Epoch[156/200] loss: 0.1550859292348226
I0423 09:35:19.277205 19172 trainer.py:136] Epoch[157/200] loss: 0.1617533338566621
I0423 09:35:20.979694 19172 trainer.py:136] Epoch[158/200] loss: 0.15383518586556116
I0423 09:35:22.661177 19172 trainer.py:136] Epoch[159/200] loss: 0.15399994924664498
I0423 09:35:24.347654 19172 trainer.py:136] Epoch[160/200] loss: 0.16673666437466939
I0423 09:35:26.025189 19172 trainer.py:136] Epoch[161/200] loss: 0.1665973462164402
I0423 09:35:27.700269 19172 trainer.py:136] Epoch[162/200] loss: 0.14907127966483433
I0423 09:35:29.376807 19172 trainer.py:136] Epoch[163/200] loss: 0.16606198623776436
I0423 09:35:31.038470 19172 trainer.py:136] Epoch[164/200] loss: 0.16008921811978022
I0423 09:35:32.709447 19172 trainer.py:136] Epoch[165/200] loss: 0.1534862478574117
I0423 09:35:34.386984 19172 trainer.py:136] Epoch[166/200] loss: 0.15225597818692524
I0423 09:35:36.071507 19172 trainer.py:136] Epoch[167/200] loss: 0.1611859713991483
I0423 09:35:37.745599 19172 trainer.py:136] Epoch[168/200] loss: 0.15553382237752278
I0423 09:35:39.444124 19172 trainer.py:136] Epoch[169/200] loss: 0.15021274238824844
I0423 09:35:41.207383 19172 trainer.py:136] Epoch[170/200] loss: 0.1557778167227904
I0423 09:35:42.916907 19172 trainer.py:136] Epoch[171/200] loss: 0.1554788514971733
I0423 09:35:44.604827 19172 trainer.py:136] Epoch[172/200] loss: 0.16644049038489658
I0423 09:35:46.291915 19172 trainer.py:136] Epoch[173/200] loss: 0.15725715607404708
I0423 09:35:47.968412 19172 trainer.py:136] Epoch[174/200] loss: 0.1540172559519609
I0423 09:35:49.643364 19172 trainer.py:136] Epoch[175/200] loss: 0.15031540219982464
I0423 09:35:51.313891 19172 trainer.py:136] Epoch[176/200] loss: 0.16154272109270096
I0423 09:35:52.983849 19172 trainer.py:136] Epoch[177/200] loss: 0.15333497549096745
I0423 09:35:54.661865 19172 trainer.py:136] Epoch[178/200] loss: 0.1490822084248066
I0423 09:35:56.335451 19172 trainer.py:136] Epoch[179/200] loss: 0.14935514579216638
I0423 09:35:57.827371 19172 trainer.py:136] Epoch[180/200] loss: 0.1530718612174193
I0423 09:35:59.231294 19172 trainer.py:136] Epoch[181/200] loss: 0.15567999035120011
I0423 09:36:00.387876 19172 trainer.py:136] Epoch[182/200] loss: 0.14894085029760998
I0423 09:36:01.423705 19172 trainer.py:136] Epoch[183/200] loss: 0.15708400731285413
I0423 09:36:02.409976 19172 trainer.py:136] Epoch[184/200] loss: 0.14839746082822483
I0423 09:36:03.419704 19172 trainer.py:136] Epoch[185/200] loss: 0.14688220943013827
I0423 09:36:04.449853 19172 trainer.py:136] Epoch[186/200] loss: 0.15506245667735735
I0423 09:36:05.444058 19172 trainer.py:136] Epoch[187/200] loss: 0.1531530742843946
I0423 09:36:06.446249 19172 trainer.py:136] Epoch[188/200] loss: 0.15789848392208417
I0423 09:36:07.441551 19172 trainer.py:136] Epoch[189/200] loss: 0.15905682692925135
I0423 09:36:08.438383 19172 trainer.py:136] Epoch[190/200] loss: 0.15357562899589539
I0423 09:36:09.440601 19172 trainer.py:136] Epoch[191/200] loss: 0.15649105509122213
I0423 09:36:10.442800 19172 trainer.py:136] Epoch[192/200] loss: 0.146167620519797
I0423 09:36:11.446716 19172 trainer.py:136] Epoch[193/200] loss: 0.15093707169095674
I0423 09:36:12.469490 19172 trainer.py:136] Epoch[194/200] loss: 0.15915785903731983
I0423 09:36:13.251441 19172 trainer.py:136] Epoch[195/200] loss: 0.15407806783914565
I0423 09:36:13.864952 19172 trainer.py:136] Epoch[196/200] loss: 0.15988687351346015
I0423 09:36:14.529728 19172 trainer.py:136] Epoch[197/200] loss: 0.1523104727268219
I0423 09:36:15.161195 19172 trainer.py:136] Epoch[198/200] loss: 0.16031122704346976
I0423 09:36:15.773149 19172 trainer.py:136] Epoch[199/200] loss: 0.15730679656068483
I0423 09:36:15.792662 19172 trainer.py:142] Test: [{'precision': 0.0232067510548523, 'recall': 0.17427419509697987, 'hit_ratio': 0.39130801687763715, 'ndcg': 0.81774297227649814}]
