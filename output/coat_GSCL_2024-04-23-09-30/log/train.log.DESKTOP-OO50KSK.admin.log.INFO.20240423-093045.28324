I0423 09:30:47.003746 34280 trainer.py:118] Test: [{'precision': 0.017510548523206743, 'recall': 0.1081277372416613, 'hit_ratio': 0.3080168776371308, 'ndcg': 0.05794940570242472}]
I0423 09:30:48.062772 34280 trainer.py:136] Epoch[0/200] loss: 0.6786239385604859
I0423 09:30:49.067411 34280 trainer.py:136] Epoch[1/200] loss: 0.6364594082037608
I0423 09:30:50.073729 34280 trainer.py:136] Epoch[2/200] loss: 0.6055898129940033
I0423 09:30:51.167289 34280 trainer.py:136] Epoch[3/200] loss: 0.5661737322807312
I0423 09:30:52.409776 34280 trainer.py:136] Epoch[4/200] loss: 0.5246400584777197
I0423 09:30:53.829324 34280 trainer.py:136] Epoch[5/200] loss: 0.4939572185277939
I0423 09:30:55.442591 34280 trainer.py:136] Epoch[6/200] loss: 0.4765824943780899
I0423 09:30:57.206776 34280 trainer.py:136] Epoch[7/200] loss: 0.42636574705441793
I0423 09:30:58.963996 34280 trainer.py:136] Epoch[8/200] loss: 0.4028452525536219
I0423 09:31:00.652388 34280 trainer.py:136] Epoch[9/200] loss: 0.3871491352717082
I0423 09:31:02.335280 34280 trainer.py:136] Epoch[10/200] loss: 0.37147727608680725
I0423 09:31:04.004836 34280 trainer.py:136] Epoch[11/200] loss: 0.3661884993314743
I0423 09:31:05.727234 34280 trainer.py:136] Epoch[12/200] loss: 0.34145024716854094
I0423 09:31:07.411841 34280 trainer.py:136] Epoch[13/200] loss: 0.31641230434179307
I0423 09:31:09.081417 34280 trainer.py:136] Epoch[14/200] loss: 0.3353484849135081
I0423 09:31:10.791821 34280 trainer.py:136] Epoch[15/200] loss: 0.30017591317494713
I0423 09:31:12.467800 34280 trainer.py:136] Epoch[16/200] loss: 0.30747785568237307
I0423 09:31:14.147326 34280 trainer.py:136] Epoch[17/200] loss: 0.31350683768590293
I0423 09:31:15.853743 34280 trainer.py:136] Epoch[18/200] loss: 0.2966963325937589
I0423 09:31:17.541936 34280 trainer.py:136] Epoch[19/200] loss: 0.2975869655609131
I0423 09:31:19.215459 34280 trainer.py:136] Epoch[20/200] loss: 0.3067763462662697
I0423 09:31:20.884445 34280 trainer.py:136] Epoch[21/200] loss: 0.2702688838044802
I0423 09:31:22.576345 34280 trainer.py:136] Epoch[22/200] loss: 0.27105689495801927
I0423 09:31:24.293727 34280 trainer.py:136] Epoch[23/200] loss: 0.27979312241077425
I0423 09:31:25.959315 34280 trainer.py:136] Epoch[24/200] loss: 0.28162762920061746
I0423 09:31:27.673152 34280 trainer.py:136] Epoch[25/200] loss: 0.2778361886739731
I0423 09:31:29.464266 34280 trainer.py:136] Epoch[26/200] loss: 0.27923481315374377
I0423 09:31:31.221551 34280 trainer.py:136] Epoch[27/200] loss: 0.25790607134501137
I0423 09:31:32.962888 34280 trainer.py:136] Epoch[28/200] loss: 0.2577118754386902
I0423 09:31:34.645303 34280 trainer.py:136] Epoch[29/200] loss: 0.2562819967667262
I0423 09:31:36.319922 34280 trainer.py:136] Epoch[30/200] loss: 0.24111031343539555
I0423 09:31:38.044340 34280 trainer.py:136] Epoch[31/200] loss: 0.2534157559275627
I0423 09:31:39.721350 34280 trainer.py:136] Epoch[32/200] loss: 0.25910016944011055
I0423 09:31:41.399120 34280 trainer.py:136] Epoch[33/200] loss: 0.25105369786421455
I0423 09:31:43.114526 34280 trainer.py:136] Epoch[34/200] loss: 0.2486715818444888
I0423 09:31:44.791075 34280 trainer.py:136] Epoch[35/200] loss: 0.2329113408923149
I0423 09:31:46.518900 34280 trainer.py:136] Epoch[36/200] loss: 0.24088795036077498
I0423 09:31:48.217389 34280 trainer.py:136] Epoch[37/200] loss: 0.24115616331497827
I0423 09:31:49.899145 34280 trainer.py:136] Epoch[38/200] loss: 0.2358225146929423
I0423 09:31:51.581006 34280 trainer.py:136] Epoch[39/200] loss: 0.21972231020530064
I0423 09:31:53.304664 34280 trainer.py:136] Epoch[40/200] loss: 0.2383533443013827
I0423 09:31:54.995562 34280 trainer.py:136] Epoch[41/200] loss: 0.2183430736263593
I0423 09:31:56.693440 34280 trainer.py:136] Epoch[42/200] loss: 0.22981378734111785
I0423 09:31:58.388408 34280 trainer.py:136] Epoch[43/200] loss: 0.2274786298473676
I0423 09:32:00.091372 34280 trainer.py:136] Epoch[44/200] loss: 0.23390778799851736
I0423 09:32:01.878548 34280 trainer.py:136] Epoch[45/200] loss: 0.22419953991969427
I0423 09:32:03.649177 34280 trainer.py:136] Epoch[46/200] loss: 0.21744351436694462
I0423 09:32:05.450284 34280 trainer.py:136] Epoch[47/200] loss: 0.2118893027305603
I0423 09:32:07.161970 34280 trainer.py:136] Epoch[48/200] loss: 0.2030664342145125
I0423 09:32:08.835076 34280 trainer.py:136] Epoch[49/200] loss: 0.20752158711353938
I0423 09:32:08.865972 34280 trainer.py:142] Test: [{'precision': 0.02341772151898733, 'recall': 0.1576929985157833, 'hit_ratio': 0.38396624472573837, 'ndcg': 0.07728669867314852}]
I0423 09:32:10.569836 34280 trainer.py:136] Epoch[50/200] loss: 0.21408990571896236
I0423 09:32:12.280864 34280 trainer.py:136] Epoch[51/200] loss: 0.2149882932504018
I0423 09:32:13.964410 34280 trainer.py:136] Epoch[52/200] loss: 0.20418013681968053
I0423 09:32:15.664281 34280 trainer.py:136] Epoch[53/200] loss: 0.20807594110568364
I0423 09:32:17.348802 34280 trainer.py:136] Epoch[54/200] loss: 0.2055073618888855
I0423 09:32:19.072164 34280 trainer.py:136] Epoch[55/200] loss: 0.21838208337624868
I0423 09:32:20.747130 34280 trainer.py:136] Epoch[56/200] loss: 0.21489151219526928
I0423 09:32:22.440621 34280 trainer.py:136] Epoch[57/200] loss: 0.1927476704120636
I0423 09:32:24.131957 34280 trainer.py:136] Epoch[58/200] loss: 0.20961855004231136
I0423 09:32:25.846389 34280 trainer.py:136] Epoch[59/200] loss: 0.21748690729339917
I0423 09:32:27.542288 34280 trainer.py:136] Epoch[60/200] loss: 0.18974259843428928
I0423 09:32:29.261219 34280 trainer.py:136] Epoch[61/200] loss: 0.20937232275803883
I0423 09:32:31.026452 34280 trainer.py:136] Epoch[62/200] loss: 0.20760899633169175
I0423 09:32:32.808057 34280 trainer.py:136] Epoch[63/200] loss: 0.1950154369076093
I0423 09:32:34.504930 34280 trainer.py:136] Epoch[64/200] loss: 0.1872093565762043
I0423 09:32:36.187383 34280 trainer.py:136] Epoch[65/200] loss: 0.19804893831412
I0423 09:32:37.865898 34280 trainer.py:136] Epoch[66/200] loss: 0.1874243254462878
I0423 09:32:39.578712 34280 trainer.py:136] Epoch[67/200] loss: 0.18576255788405735
I0423 09:32:41.261268 34280 trainer.py:136] Epoch[68/200] loss: 0.19688382744789124
I0423 09:32:42.920878 34280 trainer.py:136] Epoch[69/200] loss: 0.1920294200380643
I0423 09:32:44.628737 34280 trainer.py:136] Epoch[70/200] loss: 0.18546094944079716
I0423 09:32:46.306287 34280 trainer.py:136] Epoch[71/200] loss: 0.1906104808052381
I0423 09:32:47.980804 34280 trainer.py:136] Epoch[72/200] loss: 0.17030880401531856
I0423 09:32:49.701873 34280 trainer.py:136] Epoch[73/200] loss: 0.19541160116593043
I0423 09:32:51.389371 34280 trainer.py:136] Epoch[74/200] loss: 0.17485707600911457
I0423 09:32:53.069901 34280 trainer.py:136] Epoch[75/200] loss: 0.19347935716311138
I0423 09:32:54.741858 34280 trainer.py:136] Epoch[76/200] loss: 0.1974474218984445
I0423 09:32:56.444795 34280 trainer.py:136] Epoch[77/200] loss: 0.18161851118008296
I0423 09:32:58.129268 34280 trainer.py:136] Epoch[78/200] loss: 0.1819254423181216
I0423 09:32:59.852672 34280 trainer.py:136] Epoch[79/200] loss: 0.18438362578550974
I0423 09:33:01.624306 34280 trainer.py:136] Epoch[80/200] loss: 0.19078501015901567
I0423 09:33:03.397556 34280 trainer.py:136] Epoch[81/200] loss: 0.1893142287929853
I0423 09:33:05.092034 34280 trainer.py:136] Epoch[82/200] loss: 0.1854880854487419
I0423 09:33:06.764630 34280 trainer.py:136] Epoch[83/200] loss: 0.18103335797786713
I0423 09:33:08.455110 34280 trainer.py:136] Epoch[84/200] loss: 0.1897339125474294
I0423 09:33:10.154554 34280 trainer.py:136] Epoch[85/200] loss: 0.18478277921676636
I0423 09:33:11.825617 34280 trainer.py:136] Epoch[86/200] loss: 0.16298113092780114
I0423 09:33:13.538465 34280 trainer.py:136] Epoch[87/200] loss: 0.18243787288665772
I0423 09:33:15.228550 34280 trainer.py:136] Epoch[88/200] loss: 0.17850980336467426
I0423 09:33:16.909607 34280 trainer.py:136] Epoch[89/200] loss: 0.16795230011145273
I0423 09:33:18.630425 34280 trainer.py:136] Epoch[90/200] loss: 0.18038161794344584
I0423 09:33:20.331828 34280 trainer.py:136] Epoch[91/200] loss: 0.17777560998996098
I0423 09:33:22.014663 34280 trainer.py:136] Epoch[92/200] loss: 0.17104228834311166
I0423 09:33:23.679635 34280 trainer.py:136] Epoch[93/200] loss: 0.16903609335422515
I0423 09:33:25.379782 34280 trainer.py:136] Epoch[94/200] loss: 0.18514051189025243
I0423 09:33:27.057291 34280 trainer.py:136] Epoch[95/200] loss: 0.17438808927933375
I0423 09:33:28.750850 34280 trainer.py:136] Epoch[96/200] loss: 0.17192931150396665
I0423 09:33:30.439482 34280 trainer.py:136] Epoch[97/200] loss: 0.1757631331682205
I0423 09:33:32.130936 34280 trainer.py:136] Epoch[98/200] loss: 0.17121634036302566
I0423 09:33:33.860100 34280 trainer.py:136] Epoch[99/200] loss: 0.18088896175225574
I0423 09:33:33.889003 34280 trainer.py:142] Test: [{'precision': 0.024472573839662434, 'recall': 0.16622725610067376, 'hit_ratio': 0.3881856540084388, 'ndcg': 0.0832642020670723}]
I0423 09:33:35.604689 34280 trainer.py:136] Epoch[100/200] loss: 0.17242436508337658
I0423 09:33:37.363908 34280 trainer.py:136] Epoch[101/200] loss: 0.17427720427513121
I0423 09:33:39.086253 34280 trainer.py:136] Epoch[102/200] loss: 0.16377371400594712
I0423 09:33:40.776441 34280 trainer.py:136] Epoch[103/200] loss: 0.1722702704370022
I0423 09:33:42.461963 34280 trainer.py:136] Epoch[104/200] loss: 0.17153890480597814
I0423 09:33:44.139938 34280 trainer.py:136] Epoch[105/200] loss: 0.17118337377905846
I0423 09:33:45.824414 34280 trainer.py:136] Epoch[106/200] loss: 0.17483169411619504
I0423 09:33:47.490046 34280 trainer.py:136] Epoch[107/200] loss: 0.17038353085517882
I0423 09:33:49.149640 34280 trainer.py:136] Epoch[108/200] loss: 0.17462635338306426
I0423 09:33:50.816191 34280 trainer.py:136] Epoch[109/200] loss: 0.1700089323023955
I0423 09:33:52.485175 34280 trainer.py:136] Epoch[110/200] loss: 0.1741405427455902
I0423 09:33:54.159754 34280 trainer.py:136] Epoch[111/200] loss: 0.17030666420857113
I0423 09:33:55.838312 34280 trainer.py:136] Epoch[112/200] loss: 0.16049236555894217
I0423 09:33:57.517265 34280 trainer.py:136] Epoch[113/200] loss: 0.16739118645588558
I0423 09:33:59.195795 34280 trainer.py:136] Epoch[114/200] loss: 0.1630367989341418
I0423 09:34:00.878302 34280 trainer.py:136] Epoch[115/200] loss: 0.15443042268355686
I0423 09:34:02.560055 34280 trainer.py:136] Epoch[116/200] loss: 0.16880276203155517
I0423 09:34:04.229640 34280 trainer.py:136] Epoch[117/200] loss: 0.15370479623476666
I0423 09:34:05.901470 34280 trainer.py:136] Epoch[118/200] loss: 0.16645699739456177
I0423 09:34:07.569479 34280 trainer.py:136] Epoch[119/200] loss: 0.15400127669175465
I0423 09:34:09.248069 34280 trainer.py:136] Epoch[120/200] loss: 0.1731994517147541
I0423 09:34:10.929593 34280 trainer.py:136] Epoch[121/200] loss: 0.15420340572794278
I0423 09:34:12.592811 34280 trainer.py:136] Epoch[122/200] loss: 0.15896080434322357
I0423 09:34:14.274401 34280 trainer.py:136] Epoch[123/200] loss: 0.1652910793821017
I0423 09:34:15.949923 34280 trainer.py:136] Epoch[124/200] loss: 0.1670695630212625
I0423 09:34:17.633833 34280 trainer.py:136] Epoch[125/200] loss: 0.16490727042158446
I0423 09:34:19.314374 34280 trainer.py:136] Epoch[126/200] loss: 0.17534376084804534
I0423 09:34:20.990934 34280 trainer.py:136] Epoch[127/200] loss: 0.16549459422628085
I0423 09:34:22.655178 34280 trainer.py:136] Epoch[128/200] loss: 0.16122098738948504
I0423 09:34:24.331970 34280 trainer.py:136] Epoch[129/200] loss: 0.15940283512075742
I0423 09:34:25.999203 34280 trainer.py:136] Epoch[130/200] loss: 0.17500376800696055
I0423 09:34:27.674075 34280 trainer.py:136] Epoch[131/200] loss: 0.17166017691294352
I0423 09:34:29.349670 34280 trainer.py:136] Epoch[132/200] loss: 0.1625824101269245
I0423 09:34:31.017940 34280 trainer.py:136] Epoch[133/200] loss: 0.1566083920498689
I0423 09:34:32.683517 34280 trainer.py:136] Epoch[134/200] loss: 0.15910822103420894
I0423 09:34:34.395979 34280 trainer.py:136] Epoch[135/200] loss: 0.168023494631052
I0423 09:34:36.145314 34280 trainer.py:136] Epoch[136/200] loss: 0.16692050024867058
I0423 09:34:37.827999 34280 trainer.py:136] Epoch[137/200] loss: 0.1579585999250412
I0423 09:34:39.531881 34280 trainer.py:136] Epoch[138/200] loss: 0.17328096603353818
I0423 09:34:41.217368 34280 trainer.py:136] Epoch[139/200] loss: 0.15611919934550922
I0423 09:34:42.946732 34280 trainer.py:136] Epoch[140/200] loss: 0.1626741774380207
I0423 09:34:44.660561 34280 trainer.py:136] Epoch[141/200] loss: 0.17476611683766047
I0423 09:34:46.376051 34280 trainer.py:136] Epoch[142/200] loss: 0.17005598694086074
I0423 09:34:48.058010 34280 trainer.py:136] Epoch[143/200] loss: 0.18126181314388912
I0423 09:34:49.736265 34280 trainer.py:136] Epoch[144/200] loss: 0.1714445506532987
I0423 09:34:51.437729 34280 trainer.py:136] Epoch[145/200] loss: 0.15833176920811334
I0423 09:34:53.194392 34280 trainer.py:136] Epoch[146/200] loss: 0.16382236704230307
I0423 09:34:54.870057 34280 trainer.py:136] Epoch[147/200] loss: 0.16193602830171586
I0423 09:34:56.550478 34280 trainer.py:136] Epoch[148/200] loss: 0.15990266998608907
I0423 09:34:58.226416 34280 trainer.py:136] Epoch[149/200] loss: 0.1556959201892217
I0423 09:34:58.256316 34280 trainer.py:142] Test: [{'precision': 0.024050632911392388, 'recall': 0.1762272561006738, 'hit_ratio': 0.4081856540084388, 'ndcg': 0.080971538765416253}]
I0423 09:34:59.925336 34280 trainer.py:136] Epoch[150/200] loss: 0.1582499198615551
I0423 09:35:01.597163 34280 trainer.py:136] Epoch[151/200] loss: 0.16676008154948552
I0423 09:35:03.284345 34280 trainer.py:136] Epoch[152/200] loss: 0.16210172325372696
I0423 09:35:04.962027 34280 trainer.py:136] Epoch[153/200] loss: 0.16309702346722285
I0423 09:35:06.631039 34280 trainer.py:136] Epoch[154/200] loss: 0.1534180539349715
I0423 09:35:08.300558 34280 trainer.py:136] Epoch[155/200] loss: 0.15875257402658463
I0423 09:35:09.972132 34280 trainer.py:136] Epoch[156/200] loss: 0.15105006769299506
I0423 09:35:11.626535 34280 trainer.py:136] Epoch[157/200] loss: 0.17884504894415537
I0423 09:35:13.299064 34280 trainer.py:136] Epoch[158/200] loss: 0.15211366787552832
I0423 09:35:14.982310 34280 trainer.py:136] Epoch[159/200] loss: 0.16988616635402043
I0423 09:35:16.676821 34280 trainer.py:136] Epoch[160/200] loss: 0.15324931144714354
I0423 09:35:18.348696 34280 trainer.py:136] Epoch[161/200] loss: 0.1520600770910581
I0423 09:35:20.021269 34280 trainer.py:136] Epoch[162/200] loss: 0.1527877410252889
I0423 09:35:21.710815 34280 trainer.py:136] Epoch[163/200] loss: 0.1542875883479913
I0423 09:35:23.394313 34280 trainer.py:136] Epoch[164/200] loss: 0.1622354616721471
I0423 09:35:25.066845 34280 trainer.py:136] Epoch[165/200] loss: 0.15838611821333567
I0423 09:35:26.733932 34280 trainer.py:136] Epoch[166/200] loss: 0.1502002276480198
I0423 09:35:28.401490 34280 trainer.py:136] Epoch[167/200] loss: 0.14893542726834616
I0423 09:35:30.062159 34280 trainer.py:136] Epoch[168/200] loss: 0.1605165533721447
I0423 09:35:31.738130 34280 trainer.py:136] Epoch[169/200] loss: 0.15522318904598553
I0423 09:35:33.409699 34280 trainer.py:136] Epoch[170/200] loss: 0.16251461679736773
I0423 09:35:35.078228 34280 trainer.py:136] Epoch[171/200] loss: 0.16533826167384783
I0423 09:35:36.764190 34280 trainer.py:136] Epoch[172/200] loss: 0.16427527144551277
I0423 09:35:38.435887 34280 trainer.py:136] Epoch[173/200] loss: 0.15289001713196437
I0423 09:35:40.156318 34280 trainer.py:136] Epoch[174/200] loss: 0.14698414330681164
I0423 09:35:41.952502 34280 trainer.py:136] Epoch[175/200] loss: 0.1541712780793508
I0423 09:35:43.635504 34280 trainer.py:136] Epoch[176/200] loss: 0.1573825178047021
I0423 09:35:45.319036 34280 trainer.py:136] Epoch[177/200] loss: 0.17261898765961328
I0423 09:35:46.992133 34280 trainer.py:136] Epoch[178/200] loss: 0.15516088232398034
I0423 09:35:48.665081 34280 trainer.py:136] Epoch[179/200] loss: 0.15486620093385378
I0423 09:35:50.334614 34280 trainer.py:136] Epoch[180/200] loss: 0.15938027426600457
I0423 09:35:52.000725 34280 trainer.py:136] Epoch[181/200] loss: 0.16999309758345285
I0423 09:35:53.677528 34280 trainer.py:136] Epoch[182/200] loss: 0.15903662691513698
I0423 09:35:55.367115 34280 trainer.py:136] Epoch[183/200] loss: 0.1632639805475871
I0423 09:35:57.055663 34280 trainer.py:136] Epoch[184/200] loss: 0.15143304218848547
I0423 09:35:58.451284 34280 trainer.py:136] Epoch[185/200] loss: 0.14584887847304345
I0423 09:35:59.786886 34280 trainer.py:136] Epoch[186/200] loss: 0.17059347853064538
I0423 09:36:00.814054 34280 trainer.py:136] Epoch[187/200] loss: 0.16060739755630493
I0423 09:36:01.864799 34280 trainer.py:136] Epoch[188/200] loss: 0.15141426771879196
I0423 09:36:02.850608 34280 trainer.py:136] Epoch[189/200] loss: 0.15023478617270788
I0423 09:36:03.833914 34280 trainer.py:136] Epoch[190/200] loss: 0.1430566591521104
I0423 09:36:04.815162 34280 trainer.py:136] Epoch[191/200] loss: 0.1655605912208557
I0423 09:36:05.805394 34280 trainer.py:136] Epoch[192/200] loss: 0.14958424965540568
I0423 09:36:06.796336 34280 trainer.py:136] Epoch[193/200] loss: 0.16734661608934404
I0423 09:36:07.810483 34280 trainer.py:136] Epoch[194/200] loss: 0.15546320353945095
I0423 09:36:08.828649 34280 trainer.py:136] Epoch[195/200] loss: 0.15029261857271195
I0423 09:36:09.831844 34280 trainer.py:136] Epoch[196/200] loss: 0.15009302174051603
I0423 09:36:10.832770 34280 trainer.py:136] Epoch[197/200] loss: 0.14614877725640932
I0423 09:36:11.831624 34280 trainer.py:136] Epoch[198/200] loss: 0.15094252278407413
I0423 09:36:12.819884 34280 trainer.py:136] Epoch[199/200] loss: 0.1761639580130577
I0423 09:36:12.840815 34280 trainer.py:142] Test: [{'precision': 0.024261603375527404, 'recall': 0.17619711746294022, 'hit_ratio': 0.399746835443038, 'ndcg': 0.0816051905906188}]
