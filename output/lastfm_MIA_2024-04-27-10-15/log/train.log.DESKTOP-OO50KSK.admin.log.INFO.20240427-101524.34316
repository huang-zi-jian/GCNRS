I0427 10:15:26.253754 11084 trainer.py:118] Test: [{'precision': 0.055764075067024174, 'recall': 0.12589074328744723, 'hit_ratio': 0.5404825737265415, 'ndcg': 0.11038300757361978}]
I0427 10:15:28.285243 11084 trainer.py:136] Epoch[0/1000] loss: 0.5508133909281563
I0427 10:15:30.270854 11084 trainer.py:136] Epoch[1/1000] loss: 0.48109408687142763
I0427 10:15:32.341527 11084 trainer.py:136] Epoch[2/1000] loss: 0.4542467524023617
I0427 10:15:34.501653 11084 trainer.py:136] Epoch[3/1000] loss: 0.44061894451870637
I0427 10:15:36.704698 11084 trainer.py:136] Epoch[4/1000] loss: 0.4255998204736149
I0427 10:15:38.818043 11084 trainer.py:136] Epoch[5/1000] loss: 0.4195154589765212
I0427 10:15:41.039299 11084 trainer.py:136] Epoch[6/1000] loss: 0.4028017398189096
I0427 10:15:43.031728 11084 trainer.py:136] Epoch[7/1000] loss: 0.39483728478936586
I0427 10:15:45.228725 11084 trainer.py:136] Epoch[8/1000] loss: 0.38706596108043895
I0427 10:15:47.537283 11084 trainer.py:136] Epoch[9/1000] loss: 0.38173769502078786
I0427 10:15:49.672261 11084 trainer.py:136] Epoch[10/1000] loss: 0.36749560342115517
I0427 10:15:51.761403 11084 trainer.py:136] Epoch[11/1000] loss: 0.3584260642528534
I0427 10:15:53.867959 11084 trainer.py:136] Epoch[12/1000] loss: 0.3501322690178366
I0427 10:15:56.166353 11084 trainer.py:136] Epoch[13/1000] loss: 0.3484135901226717
I0427 10:15:58.251535 11084 trainer.py:136] Epoch[14/1000] loss: 0.335449697340236
I0427 10:16:00.588383 11084 trainer.py:136] Epoch[15/1000] loss: 0.3234072012059829
I0427 10:16:02.846920 11084 trainer.py:136] Epoch[16/1000] loss: 0.324880905011121
I0427 10:16:05.112668 11084 trainer.py:136] Epoch[17/1000] loss: 0.31020068421083336
I0427 10:16:07.400602 11084 trainer.py:136] Epoch[18/1000] loss: 0.30294684276861306
I0427 10:16:09.631851 11084 trainer.py:136] Epoch[19/1000] loss: 0.29975613075144153
I0427 10:16:12.081801 11084 trainer.py:136] Epoch[20/1000] loss: 0.2926487747360678
I0427 10:16:14.644543 11084 trainer.py:136] Epoch[21/1000] loss: 0.2859071466852637
I0427 10:16:17.094499 11084 trainer.py:136] Epoch[22/1000] loss: 0.28561491826001334
I0427 10:16:19.356107 11084 trainer.py:136] Epoch[23/1000] loss: 0.2812974347787745
I0427 10:16:21.583418 11084 trainer.py:136] Epoch[24/1000] loss: 0.27521759271621704
I0427 10:16:24.154961 11084 trainer.py:136] Epoch[25/1000] loss: 0.2654917143723544
I0427 10:16:26.345786 11084 trainer.py:136] Epoch[26/1000] loss: 0.27216290025150075
I0427 10:16:28.498851 11084 trainer.py:136] Epoch[27/1000] loss: 0.26000818347229676
I0427 10:16:30.696886 11084 trainer.py:136] Epoch[28/1000] loss: 0.2524472702951992
I0427 10:16:33.168700 11084 trainer.py:136] Epoch[29/1000] loss: 0.24799591653487263
I0427 10:16:35.593394 11084 trainer.py:136] Epoch[30/1000] loss: 0.24993065174888163
I0427 10:16:38.019418 11084 trainer.py:136] Epoch[31/1000] loss: 0.2454772214679157
I0427 10:16:40.320897 11084 trainer.py:136] Epoch[32/1000] loss: 0.24124517247957342
I0427 10:16:42.841575 11084 trainer.py:136] Epoch[33/1000] loss: 0.2364744272302179
I0427 10:16:44.928725 11084 trainer.py:136] Epoch[34/1000] loss: 0.2338830819901298
I0427 10:16:47.200003 11084 trainer.py:136] Epoch[35/1000] loss: 0.2285464072928709
I0427 10:16:49.431714 11084 trainer.py:136] Epoch[36/1000] loss: 0.22390612609246197
I0427 10:16:51.782598 11084 trainer.py:136] Epoch[37/1000] loss: 0.22882724071250243
I0427 10:16:54.293360 11084 trainer.py:136] Epoch[38/1000] loss: 0.22939924895763397
I0427 10:16:56.571462 11084 trainer.py:136] Epoch[39/1000] loss: 0.21575602713753195
I0427 10:16:58.940644 11084 trainer.py:136] Epoch[40/1000] loss: 0.21990463488242207
I0427 10:17:01.196660 11084 trainer.py:136] Epoch[41/1000] loss: 0.2180527124334784
I0427 10:17:03.562534 11084 trainer.py:136] Epoch[42/1000] loss: 0.21369163166074193
I0427 10:17:05.755243 11084 trainer.py:136] Epoch[43/1000] loss: 0.20358386723434224
I0427 10:17:08.060017 11084 trainer.py:136] Epoch[44/1000] loss: 0.20725886348415823
I0427 10:17:10.268783 11084 trainer.py:136] Epoch[45/1000] loss: 0.2095501431647469
I0427 10:17:12.483288 11084 trainer.py:136] Epoch[46/1000] loss: 0.2046631048707401
I0427 10:17:14.759774 11084 trainer.py:136] Epoch[47/1000] loss: 0.20133577462504892
I0427 10:17:17.082136 11084 trainer.py:136] Epoch[48/1000] loss: 0.20058166279512293
I0427 10:17:19.392544 11084 trainer.py:136] Epoch[49/1000] loss: 0.19315364693894105
I0427 10:17:19.566502 11084 trainer.py:142] Test: [{'precision': 0.11214477211796255, 'recall': 0.26149182656870734, 'hit_ratio': 0.8241286863270777, 'ndcg': 0.2470875322577256}]
I0427 10:17:21.727474 11084 trainer.py:136] Epoch[50/1000] loss: 0.19298053576665766
I0427 10:17:23.885449 11084 trainer.py:136] Epoch[51/1000] loss: 0.1896847705630695
I0427 10:17:26.198296 11084 trainer.py:136] Epoch[52/1000] loss: 0.1870254751513986
I0427 10:17:28.460955 11084 trainer.py:136] Epoch[53/1000] loss: 0.18880555471953223
I0427 10:17:30.871551 11084 trainer.py:136] Epoch[54/1000] loss: 0.18365857268080993
I0427 10:17:33.186312 11084 trainer.py:136] Epoch[55/1000] loss: 0.18516453048762152
I0427 10:17:35.377673 11084 trainer.py:136] Epoch[56/1000] loss: 0.1868389020947849
I0427 10:17:37.553588 11084 trainer.py:136] Epoch[57/1000] loss: 0.18367644881500916
I0427 10:17:39.814190 11084 trainer.py:136] Epoch[58/1000] loss: 0.1763095093124053
I0427 10:17:41.969102 11084 trainer.py:136] Epoch[59/1000] loss: 0.17917613685131073
I0427 10:17:44.263383 11084 trainer.py:136] Epoch[60/1000] loss: 0.17576358160551855
I0427 10:17:46.639471 11084 trainer.py:136] Epoch[61/1000] loss: 0.1766156703233719
I0427 10:17:48.881910 11084 trainer.py:136] Epoch[62/1000] loss: 0.17831001386922948
I0427 10:17:51.178182 11084 trainer.py:136] Epoch[63/1000] loss: 0.17387187130310955
I0427 10:17:53.486738 11084 trainer.py:136] Epoch[64/1000] loss: 0.17499612447093515
I0427 10:17:55.709653 11084 trainer.py:136] Epoch[65/1000] loss: 0.17171797156333923
I0427 10:17:58.037964 11084 trainer.py:136] Epoch[66/1000] loss: 0.1694809855783687
I0427 10:18:00.281611 11084 trainer.py:136] Epoch[67/1000] loss: 0.16704248943749597
I0427 10:18:02.687051 11084 trainer.py:136] Epoch[68/1000] loss: 0.1649878664928324
I0427 10:18:05.038198 11084 trainer.py:136] Epoch[69/1000] loss: 0.1634350778425441
I0427 10:18:07.245991 11084 trainer.py:136] Epoch[70/1000] loss: 0.16231682808960185
I0427 10:18:09.531574 11084 trainer.py:136] Epoch[71/1000] loss: 0.16459138077848098
I0427 10:18:11.721997 11084 trainer.py:136] Epoch[72/1000] loss: 0.1641481413560755
I0427 10:18:13.953271 11084 trainer.py:136] Epoch[73/1000] loss: 0.16265581022290623
I0427 10:18:16.279583 11084 trainer.py:136] Epoch[74/1000] loss: 0.16167983588050394
I0427 10:18:18.588143 11084 trainer.py:136] Epoch[75/1000] loss: 0.15919636628207037
I0427 10:18:20.733108 11084 trainer.py:136] Epoch[76/1000] loss: 0.15721294108559103
I0427 10:18:23.044522 11084 trainer.py:136] Epoch[77/1000] loss: 0.15731508854557485
I0427 10:18:25.334999 11084 trainer.py:136] Epoch[78/1000] loss: 0.15485706487122705
I0427 10:18:27.668002 11084 trainer.py:136] Epoch[79/1000] loss: 0.15633870836566477
I0427 10:18:29.884636 11084 trainer.py:136] Epoch[80/1000] loss: 0.1500810897525619
I0427 10:18:32.199250 11084 trainer.py:136] Epoch[81/1000] loss: 0.1507595190230538
I0427 10:18:34.463137 11084 trainer.py:136] Epoch[82/1000] loss: 0.1523200825733297
I0427 10:18:36.789443 11084 trainer.py:136] Epoch[83/1000] loss: 0.15111409653635585
I0427 10:18:39.031121 11084 trainer.py:136] Epoch[84/1000] loss: 0.15014392400489135
I0427 10:18:41.239059 11084 trainer.py:136] Epoch[85/1000] loss: 0.15043124556541443
I0427 10:18:43.441886 11084 trainer.py:136] Epoch[86/1000] loss: 0.14981341361999512
I0427 10:18:45.740925 11084 trainer.py:136] Epoch[87/1000] loss: 0.14933687536155477
I0427 10:18:47.966593 11084 trainer.py:136] Epoch[88/1000] loss: 0.14861542950658238
I0427 10:18:50.281005 11084 trainer.py:136] Epoch[89/1000] loss: 0.14794494737597072
I0427 10:18:52.520861 11084 trainer.py:136] Epoch[90/1000] loss: 0.1483486154500176
I0427 10:18:54.827346 11084 trainer.py:136] Epoch[91/1000] loss: 0.14141707166152842
I0427 10:18:57.124881 11084 trainer.py:136] Epoch[92/1000] loss: 0.14426189310410442
I0427 10:18:59.329675 11084 trainer.py:136] Epoch[93/1000] loss: 0.14429750512627995
I0427 10:19:01.622674 11084 trainer.py:136] Epoch[94/1000] loss: 0.13845742406213984
I0427 10:19:03.855336 11084 trainer.py:136] Epoch[95/1000] loss: 0.14473470519570744
I0427 10:19:06.018599 11084 trainer.py:136] Epoch[96/1000] loss: 0.14094644653446534
I0427 10:19:08.234010 11084 trainer.py:136] Epoch[97/1000] loss: 0.14092967703061945
I0427 10:19:10.626691 11084 trainer.py:136] Epoch[98/1000] loss: 0.1401957177063998
I0427 10:19:12.864553 11084 trainer.py:136] Epoch[99/1000] loss: 0.14000117778778076
I0427 10:19:13.026012 11084 trainer.py:142] Test: [{'precision': 0.12262734584450412, 'recall': 0.28866001054614854, 'hit_ratio': 0.8648793565683646, 'ndcg': 0.2698256697721046}]
I0427 10:19:15.215799 11084 trainer.py:136] Epoch[100/1000] loss: 0.1379773397656048
I0427 10:19:17.606507 11084 trainer.py:136] Epoch[101/1000] loss: 0.13652164357550003
I0427 10:19:19.846181 11084 trainer.py:136] Epoch[102/1000] loss: 0.1377149084035088
I0427 10:19:22.134640 11084 trainer.py:136] Epoch[103/1000] loss: 0.1380825888584642
I0427 10:19:24.335471 11084 trainer.py:136] Epoch[104/1000] loss: 0.13550875861855113
I0427 10:19:26.556797 11084 trainer.py:136] Epoch[105/1000] loss: 0.1377229532774757
I0427 10:19:28.944676 11084 trainer.py:136] Epoch[106/1000] loss: 0.13283908454810872
I0427 10:19:31.208863 11084 trainer.py:136] Epoch[107/1000] loss: 0.13339263814337113
I0427 10:19:33.462996 11084 trainer.py:136] Epoch[108/1000] loss: 0.13381096896003275
I0427 10:19:35.787101 11084 trainer.py:136] Epoch[109/1000] loss: 0.13276095556862214
I0427 10:19:38.107937 11084 trainer.py:136] Epoch[110/1000] loss: 0.13119417691932006
I0427 10:19:40.272788 11084 trainer.py:136] Epoch[111/1000] loss: 0.13231173990403905
I0427 10:19:42.600142 11084 trainer.py:136] Epoch[112/1000] loss: 0.13125322934459238
I0427 10:19:45.020753 11084 trainer.py:136] Epoch[113/1000] loss: 0.13158779109225555
I0427 10:19:47.330141 11084 trainer.py:136] Epoch[114/1000] loss: 0.13094197520438364
I0427 10:19:49.579300 11084 trainer.py:136] Epoch[115/1000] loss: 0.13249598355854258
I0427 10:19:51.895682 11084 trainer.py:136] Epoch[116/1000] loss: 0.12843379948069067
I0427 10:19:54.284774 11084 trainer.py:136] Epoch[117/1000] loss: 0.12774980725610957
I0427 10:19:56.506226 11084 trainer.py:136] Epoch[118/1000] loss: 0.13046689901281805
I0427 10:19:58.787696 11084 trainer.py:136] Epoch[119/1000] loss: 0.12564532239647472
I0427 10:20:01.033315 11084 trainer.py:136] Epoch[120/1000] loss: 0.1251975302310551
I0427 10:20:03.240938 11084 trainer.py:136] Epoch[121/1000] loss: 0.12596897167318008
I0427 10:20:05.538344 11084 trainer.py:136] Epoch[122/1000] loss: 0.12696277656975916
I0427 10:20:07.733517 11084 trainer.py:136] Epoch[123/1000] loss: 0.12178891678066815
I0427 10:20:09.849400 11084 trainer.py:136] Epoch[124/1000] loss: 0.12320163407746483
I0427 10:20:12.108011 11084 trainer.py:136] Epoch[125/1000] loss: 0.12467984110116959
I0427 10:20:14.316766 11084 trainer.py:136] Epoch[126/1000] loss: 0.12652285046437206
I0427 10:20:16.519247 11084 trainer.py:136] Epoch[127/1000] loss: 0.12299008492161245
I0427 10:20:18.756914 11084 trainer.py:136] Epoch[128/1000] loss: 0.12344737044152092
I0427 10:20:21.187765 11084 trainer.py:136] Epoch[129/1000] loss: 0.1183842915822478
I0427 10:20:23.401035 11084 trainer.py:136] Epoch[130/1000] loss: 0.11908530093291227
I0427 10:20:25.587485 11084 trainer.py:136] Epoch[131/1000] loss: 0.12289465218782425
I0427 10:20:27.812239 11084 trainer.py:136] Epoch[132/1000] loss: 0.1210022814133588
I0427 10:20:30.082553 11084 trainer.py:136] Epoch[133/1000] loss: 0.12075410651810028
I0427 10:20:32.252658 11084 trainer.py:136] Epoch[134/1000] loss: 0.11708296090364456
I0427 10:20:34.592834 11084 trainer.py:136] Epoch[135/1000] loss: 0.12009732249905081
I0427 10:20:36.794609 11084 trainer.py:136] Epoch[136/1000] loss: 0.11755057643441592
I0427 10:20:39.035295 11084 trainer.py:136] Epoch[137/1000] loss: 0.11852609322351568
I0427 10:20:41.169312 11084 trainer.py:136] Epoch[138/1000] loss: 0.12032042969675626
I0427 10:20:43.389000 11084 trainer.py:136] Epoch[139/1000] loss: 0.11786242618280299
I0427 10:20:45.694022 11084 trainer.py:136] Epoch[140/1000] loss: 0.11583498207961812
I0427 10:20:48.016322 11084 trainer.py:136] Epoch[141/1000] loss: 0.1141410215812571
I0427 10:20:50.157280 11084 trainer.py:136] Epoch[142/1000] loss: 0.117482309394023
I0427 10:20:52.503178 11084 trainer.py:136] Epoch[143/1000] loss: 0.11759742261732326
I0427 10:20:54.691998 11084 trainer.py:136] Epoch[144/1000] loss: 0.11536959996994804
I0427 10:20:56.953758 11084 trainer.py:136] Epoch[145/1000] loss: 0.11689035725944183
I0427 10:20:59.176441 11084 trainer.py:136] Epoch[146/1000] loss: 0.11271246566491969
I0427 10:21:01.364244 11084 trainer.py:136] Epoch[147/1000] loss: 0.11879391135538325
I0427 10:21:03.694142 11084 trainer.py:136] Epoch[148/1000] loss: 0.11444268901558484
I0427 10:21:05.974615 11084 trainer.py:136] Epoch[149/1000] loss: 0.11366214603185654
I0427 10:21:06.124114 11084 trainer.py:142] Test: [{'precision': 0.12707774798927624, 'recall': 0.30012256497116946, 'hit_ratio': 0.8723860589812332, 'ndcg': 0.28106577220677936}]
I0427 10:21:08.466014 11084 trainer.py:136] Epoch[150/1000] loss: 0.1129318217144293
I0427 10:21:10.658881 11084 trainer.py:136] Epoch[151/1000] loss: 0.11127722811172991
I0427 10:21:13.044237 11084 trainer.py:136] Epoch[152/1000] loss: 0.11091083594981362
I0427 10:21:15.340638 11084 trainer.py:136] Epoch[153/1000] loss: 0.1107441138695268
I0427 10:21:17.636654 11084 trainer.py:136] Epoch[154/1000] loss: 0.1135572909432299
I0427 10:21:19.800634 11084 trainer.py:136] Epoch[155/1000] loss: 0.11067644243731219
I0427 10:21:22.108503 11084 trainer.py:136] Epoch[156/1000] loss: 0.11319617225843318
I0427 10:21:24.502191 11084 trainer.py:136] Epoch[157/1000] loss: 0.11211809866568621
I0427 10:21:26.694051 11084 trainer.py:136] Epoch[158/1000] loss: 0.1091847555602298
I0427 10:21:29.101856 11084 trainer.py:136] Epoch[159/1000] loss: 0.11150970704415265
I0427 10:21:31.319692 11084 trainer.py:136] Epoch[160/1000] loss: 0.11049247270121294
I0427 10:21:33.480913 11084 trainer.py:136] Epoch[161/1000] loss: 0.10908441902960048
I0427 10:21:35.757227 11084 trainer.py:136] Epoch[162/1000] loss: 0.10875288090285133
I0427 10:21:38.171478 11084 trainer.py:136] Epoch[163/1000] loss: 0.11052765390452217
I0427 10:21:40.443052 11084 trainer.py:136] Epoch[164/1000] loss: 0.10876645629896838
I0427 10:21:42.744723 11084 trainer.py:136] Epoch[165/1000] loss: 0.11017003217164208
I0427 10:21:44.924612 11084 trainer.py:136] Epoch[166/1000] loss: 0.10881557184107163
I0427 10:21:47.108934 11084 trainer.py:136] Epoch[167/1000] loss: 0.10681436780621023
I0427 10:21:49.188113 11084 trainer.py:136] Epoch[168/1000] loss: 0.10816387350068372
I0427 10:21:51.398902 11084 trainer.py:136] Epoch[169/1000] loss: 0.10556889895130606
I0427 10:21:53.549438 11084 trainer.py:136] Epoch[170/1000] loss: 0.10851707397138372
I0427 10:21:55.786146 11084 trainer.py:136] Epoch[171/1000] loss: 0.10667587378445793
I0427 10:21:57.975398 11084 trainer.py:136] Epoch[172/1000] loss: 0.10782240944750168
I0427 10:22:00.140751 11084 trainer.py:136] Epoch[173/1000] loss: 0.10606788975350998
I0427 10:22:02.246734 11084 trainer.py:136] Epoch[174/1000] loss: 0.10259132174884572
I0427 10:22:04.481691 11084 trainer.py:136] Epoch[175/1000] loss: 0.1062746245194884
I0427 10:22:06.699284 11084 trainer.py:136] Epoch[176/1000] loss: 0.106487916672931
I0427 10:22:08.976583 11084 trainer.py:136] Epoch[177/1000] loss: 0.11040734762654585
I0427 10:22:11.123600 11084 trainer.py:136] Epoch[178/1000] loss: 0.10385995533536463
I0427 10:22:13.519755 11084 trainer.py:136] Epoch[179/1000] loss: 0.10332890117869657
I0427 10:22:15.799044 11084 trainer.py:136] Epoch[180/1000] loss: 0.10140341476482503
I0427 10:22:18.128370 11084 trainer.py:136] Epoch[181/1000] loss: 0.10754095456179451
I0427 10:22:20.307765 11084 trainer.py:136] Epoch[182/1000] loss: 0.10486390923752505
I0427 10:22:22.621753 11084 trainer.py:136] Epoch[183/1000] loss: 0.10367832639638115
I0427 10:22:24.836534 11084 trainer.py:136] Epoch[184/1000] loss: 0.10040301873403437
I0427 10:22:26.999532 11084 trainer.py:136] Epoch[185/1000] loss: 0.104999481316875
I0427 10:22:29.202817 11084 trainer.py:136] Epoch[186/1000] loss: 0.10475379842169144
I0427 10:22:31.533092 11084 trainer.py:136] Epoch[187/1000] loss: 0.1021643110057887
I0427 10:22:33.699633 11084 trainer.py:136] Epoch[188/1000] loss: 0.102346291875138
I0427 10:22:35.974751 11084 trainer.py:136] Epoch[189/1000] loss: 0.10271641042302637
I0427 10:22:38.195910 11084 trainer.py:136] Epoch[190/1000] loss: 0.10165350226794972
I0427 10:22:40.400556 11084 trainer.py:136] Epoch[191/1000] loss: 0.09943544645519818
I0427 10:22:42.858769 11084 trainer.py:136] Epoch[192/1000] loss: 0.10212546937605914
I0427 10:22:45.168040 11084 trainer.py:136] Epoch[193/1000] loss: 0.09956664504373774
I0427 10:22:47.631580 11084 trainer.py:136] Epoch[194/1000] loss: 0.10078455902197782
I0427 10:22:49.979377 11084 trainer.py:136] Epoch[195/1000] loss: 0.1011913975372034
I0427 10:22:52.484818 11084 trainer.py:136] Epoch[196/1000] loss: 0.09598212382372688
I0427 10:22:54.729701 11084 trainer.py:136] Epoch[197/1000] loss: 0.09953504143392339
I0427 10:22:57.020196 11084 trainer.py:136] Epoch[198/1000] loss: 0.09967521797208224
I0427 10:22:59.588860 11084 trainer.py:136] Epoch[199/1000] loss: 0.09862020524109111
I0427 10:22:59.765270 11084 trainer.py:142] Test: [{'precision': 0.13024128686327086, 'recall': 0.30778924093306703, 'hit_ratio': 0.87828418230563, 'ndcg': 0.28950712489955244}]
I0427 10:23:02.249138 11084 trainer.py:136] Epoch[200/1000] loss: 0.0997372716665268
I0427 10:23:04.492997 11084 trainer.py:136] Epoch[201/1000] loss: 0.10048177706844666
I0427 10:23:06.791513 11084 trainer.py:136] Epoch[202/1000] loss: 0.10053576134583529
I0427 10:23:09.042147 11084 trainer.py:136] Epoch[203/1000] loss: 0.10015555602662704
I0427 10:23:11.516551 11084 trainer.py:136] Epoch[204/1000] loss: 0.09460072657641243
I0427 10:23:13.856846 11084 trainer.py:136] Epoch[205/1000] loss: 0.09769624866106931
I0427 10:23:16.219081 11084 trainer.py:136] Epoch[206/1000] loss: 0.09728946799741071
I0427 10:23:18.775877 11084 trainer.py:136] Epoch[207/1000] loss: 0.09746645040371839
I0427 10:23:21.082324 11084 trainer.py:136] Epoch[208/1000] loss: 0.09638683147290174
I0427 10:23:23.365841 11084 trainer.py:136] Epoch[209/1000] loss: 0.09432671482072157
I0427 10:23:25.864173 11084 trainer.py:136] Epoch[210/1000] loss: 0.0971741952440318
I0427 10:23:28.127611 11084 trainer.py:136] Epoch[211/1000] loss: 0.09584660784286611
I0427 10:23:30.358842 11084 trainer.py:136] Epoch[212/1000] loss: 0.09496969861142776
I0427 10:23:32.752932 11084 trainer.py:136] Epoch[213/1000] loss: 0.09524352059644811
I0427 10:23:34.949408 11084 trainer.py:136] Epoch[214/1000] loss: 0.09336559014285312
I0427 10:23:37.471692 11084 trainer.py:136] Epoch[215/1000] loss: 0.0930637200089062
I0427 10:23:39.867851 11084 trainer.py:136] Epoch[216/1000] loss: 0.09428240008213941
I0427 10:23:42.451350 11084 trainer.py:136] Epoch[217/1000] loss: 0.09589560461394928
I0427 10:23:44.960085 11084 trainer.py:136] Epoch[218/1000] loss: 0.09319087030256495
I0427 10:23:47.178770 11084 trainer.py:136] Epoch[219/1000] loss: 0.09369191658847473
I0427 10:23:49.508653 11084 trainer.py:136] Epoch[220/1000] loss: 0.09171866691287826
I0427 10:23:51.695255 11084 trainer.py:136] Epoch[221/1000] loss: 0.09320789444095948
I0427 10:23:53.848215 11084 trainer.py:136] Epoch[222/1000] loss: 0.09350942382041146
I0427 10:23:55.982857 11084 trainer.py:136] Epoch[223/1000] loss: 0.09313499182462692
I0427 10:23:58.164994 11084 trainer.py:136] Epoch[224/1000] loss: 0.09294011400026433
I0427 10:24:00.477299 11084 trainer.py:136] Epoch[225/1000] loss: 0.09459791858406628
I0427 10:24:02.641295 11084 trainer.py:136] Epoch[226/1000] loss: 0.09361019642914042
I0427 10:24:04.891984 11084 trainer.py:136] Epoch[227/1000] loss: 0.09238462763674118
I0427 10:24:07.059889 11084 trainer.py:136] Epoch[228/1000] loss: 0.09134696949930753
I0427 10:24:09.331852 11084 trainer.py:136] Epoch[229/1000] loss: 0.09293690148521871
I0427 10:24:11.616864 11084 trainer.py:136] Epoch[230/1000] loss: 0.0912074823589886
I0427 10:24:13.860464 11084 trainer.py:136] Epoch[231/1000] loss: 0.09202988840201322
I0427 10:24:16.004477 11084 trainer.py:136] Epoch[232/1000] loss: 0.09261336265241399
I0427 10:24:18.272350 11084 trainer.py:136] Epoch[233/1000] loss: 0.08908864855766296
I0427 10:24:20.458713 11084 trainer.py:136] Epoch[234/1000] loss: 0.09307555810493581
I0427 10:24:22.651526 11084 trainer.py:136] Epoch[235/1000] loss: 0.09350555390119553
I0427 10:24:24.806591 11084 trainer.py:136] Epoch[236/1000] loss: 0.09365350884549759
I0427 10:24:26.976459 11084 trainer.py:136] Epoch[237/1000] loss: 0.09038454776301104
I0427 10:24:29.188556 11084 trainer.py:136] Epoch[238/1000] loss: 0.0901653503670412
I0427 10:24:31.413126 11084 trainer.py:136] Epoch[239/1000] loss: 0.08854264941285639
I0427 10:24:33.659917 11084 trainer.py:136] Epoch[240/1000] loss: 0.09176652747042038
I0427 10:24:35.917249 11084 trainer.py:136] Epoch[241/1000] loss: 0.08851428592906278
I0427 10:24:38.063763 11084 trainer.py:136] Epoch[242/1000] loss: 0.09319499880075455
I0427 10:24:40.321391 11084 trainer.py:136] Epoch[243/1000] loss: 0.0914427581078866
I0427 10:24:42.392833 11084 trainer.py:136] Epoch[244/1000] loss: 0.09038686664665446
I0427 10:24:44.609341 11084 trainer.py:136] Epoch[245/1000] loss: 0.08896741095711203
I0427 10:24:46.712519 11084 trainer.py:136] Epoch[246/1000] loss: 0.08899392801172593
I0427 10:24:48.905920 11084 trainer.py:136] Epoch[247/1000] loss: 0.08800443130380967
I0427 10:24:51.207426 11084 trainer.py:136] Epoch[248/1000] loss: 0.09263416423517115
I0427 10:24:53.314566 11084 trainer.py:136] Epoch[249/1000] loss: 0.08649097952772589
I0427 10:24:53.470592 11084 trainer.py:142] Test: [{'precision': 0.13230563002680973, 'recall': 0.31206780940064355, 'hit_ratio': 0.8772117962466488, 'ndcg': 0.29471048152589074}]
I0427 10:24:55.618611 11084 trainer.py:136] Epoch[250/1000] loss: 0.09695905885275673
I0427 10:24:57.802469 11084 trainer.py:136] Epoch[251/1000] loss: 0.08626102393164355
I0427 10:25:00.028911 11084 trainer.py:136] Epoch[252/1000] loss: 0.08676643231335808
I0427 10:25:02.283237 11084 trainer.py:136] Epoch[253/1000] loss: 0.08852233562399359
I0427 10:25:04.553424 11084 trainer.py:136] Epoch[254/1000] loss: 0.08730076034279431
I0427 10:25:06.697161 11084 trainer.py:136] Epoch[255/1000] loss: 0.08828446137554505
I0427 10:25:08.880058 11084 trainer.py:136] Epoch[256/1000] loss: 0.088001008857699
I0427 10:25:10.908466 11084 trainer.py:136] Epoch[257/1000] loss: 0.08574889644103892
I0427 10:25:13.006623 11084 trainer.py:136] Epoch[258/1000] loss: 0.08665798516834483
I0427 10:25:15.193506 11084 trainer.py:136] Epoch[259/1000] loss: 0.08727514437016319
I0427 10:25:17.367333 11084 trainer.py:136] Epoch[260/1000] loss: 0.08579547878573923
I0427 10:25:19.547818 11084 trainer.py:136] Epoch[261/1000] loss: 0.08833176642656326
I0427 10:25:21.881229 11084 trainer.py:136] Epoch[262/1000] loss: 0.08457943315015119
I0427 10:25:24.064142 11084 trainer.py:136] Epoch[263/1000] loss: 0.08806556901511024
I0427 10:25:26.205588 11084 trainer.py:136] Epoch[264/1000] loss: 0.08807818591594696
I0427 10:25:28.298609 11084 trainer.py:136] Epoch[265/1000] loss: 0.08491875844843247
I0427 10:25:30.486744 11084 trainer.py:136] Epoch[266/1000] loss: 0.08937640400493846
I0427 10:25:32.618218 11084 trainer.py:136] Epoch[267/1000] loss: 0.083888899315806
I0427 10:25:34.877169 11084 trainer.py:136] Epoch[268/1000] loss: 0.08486700123723816
I0427 10:25:36.992234 11084 trainer.py:136] Epoch[269/1000] loss: 0.08577603802961462
I0427 10:25:39.260549 11084 trainer.py:136] Epoch[270/1000] loss: 0.08411792008315816
I0427 10:25:41.402506 11084 trainer.py:136] Epoch[271/1000] loss: 0.08404100072734497
I0427 10:25:43.853066 11084 trainer.py:136] Epoch[272/1000] loss: 0.08775074560852612
I0427 10:25:46.133587 11084 trainer.py:136] Epoch[273/1000] loss: 0.0834712118786924
I0427 10:25:48.409126 11084 trainer.py:136] Epoch[274/1000] loss: 0.08442418277263641
I0427 10:25:50.728320 11084 trainer.py:136] Epoch[275/1000] loss: 0.08454204460277277
I0427 10:25:52.998841 11084 trainer.py:136] Epoch[276/1000] loss: 0.08382194839856204
I0427 10:25:55.300253 11084 trainer.py:136] Epoch[277/1000] loss: 0.08173000505741905
I0427 10:25:57.428442 11084 trainer.py:136] Epoch[278/1000] loss: 0.08691149117315516
I0427 10:25:59.708749 11084 trainer.py:136] Epoch[279/1000] loss: 0.08355620284290875
I0427 10:26:01.928912 11084 trainer.py:136] Epoch[280/1000] loss: 0.08303635282551541
I0427 10:26:04.230267 11084 trainer.py:136] Epoch[281/1000] loss: 0.0816262138678747
I0427 10:26:06.626440 11084 trainer.py:136] Epoch[282/1000] loss: 0.08637107601937126
I0427 10:26:08.941917 11084 trainer.py:136] Epoch[283/1000] loss: 0.08146000083755045
I0427 10:26:11.217120 11084 trainer.py:136] Epoch[284/1000] loss: 0.08213119800476466
I0427 10:26:13.457778 11084 trainer.py:136] Epoch[285/1000] loss: 0.08962517144048915
I0427 10:26:15.637787 11084 trainer.py:136] Epoch[286/1000] loss: 0.08220961843343343
I0427 10:26:17.910988 11084 trainer.py:136] Epoch[287/1000] loss: 0.08422952539780561
I0427 10:26:20.162584 11084 trainer.py:136] Epoch[288/1000] loss: 0.08305658794501249
I0427 10:26:22.537793 11084 trainer.py:136] Epoch[289/1000] loss: 0.08212091532700203
I0427 10:26:24.898896 11084 trainer.py:136] Epoch[290/1000] loss: 0.08344157785177231
I0427 10:26:27.154888 11084 trainer.py:136] Epoch[291/1000] loss: 0.0798283469151048
I0427 10:26:29.397471 11084 trainer.py:136] Epoch[292/1000] loss: 0.08548986736465902
I0427 10:26:31.580941 11084 trainer.py:136] Epoch[293/1000] loss: 0.08199938123717028
I0427 10:26:33.765820 11084 trainer.py:136] Epoch[294/1000] loss: 0.08140061751884572
I0427 10:26:36.090166 11084 trainer.py:136] Epoch[295/1000] loss: 0.08054979583796333
I0427 10:26:38.271163 11084 trainer.py:136] Epoch[296/1000] loss: 0.08148857951164246
I0427 10:26:40.442211 11084 trainer.py:136] Epoch[297/1000] loss: 0.08049933919135262
I0427 10:26:42.679463 11084 trainer.py:136] Epoch[298/1000] loss: 0.08186231860343147
I0427 10:26:44.915138 11084 trainer.py:136] Epoch[299/1000] loss: 0.08122165194329094
I0427 10:26:45.067629 11084 trainer.py:142] Test: [{'precision': 0.13372654155495986, 'recall': 0.3153570097742942, 'hit_ratio': 0.8809651474530831, 'ndcg': 0.29777830223498386}]
I0427 10:26:47.297432 11084 trainer.py:136] Epoch[300/1000] loss: 0.08033742361208972
I0427 10:26:49.568211 11084 trainer.py:136] Epoch[301/1000] loss: 0.08020558120573268
I0427 10:26:51.893156 11084 trainer.py:136] Epoch[302/1000] loss: 0.08074149007306379
I0427 10:26:54.076003 11084 trainer.py:136] Epoch[303/1000] loss: 0.08183702081441879
I0427 10:26:56.282720 11084 trainer.py:136] Epoch[304/1000] loss: 0.0826545585604275
I0427 10:26:58.475092 11084 trainer.py:136] Epoch[305/1000] loss: 0.08185780223678141
I0427 10:27:00.724683 11084 trainer.py:136] Epoch[306/1000] loss: 0.07752131517319118
I0427 10:27:02.993214 11084 trainer.py:136] Epoch[307/1000] loss: 0.08113171554663602
I0427 10:27:05.235867 11084 trainer.py:136] Epoch[308/1000] loss: 0.07766988939222168
I0427 10:27:07.349706 11084 trainer.py:136] Epoch[309/1000] loss: 0.07753042285056676
I0427 10:27:09.584014 11084 trainer.py:136] Epoch[310/1000] loss: 0.08033016236389384
I0427 10:27:11.840346 11084 trainer.py:136] Epoch[311/1000] loss: 0.07877538309377782
I0427 10:27:14.125234 11084 trainer.py:136] Epoch[312/1000] loss: 0.07909582686774871
I0427 10:27:16.268074 11084 trainer.py:136] Epoch[313/1000] loss: 0.08141613269553465
I0427 10:27:18.818010 11084 trainer.py:136] Epoch[314/1000] loss: 0.07842322570436142
I0427 10:27:21.023545 11084 trainer.py:136] Epoch[315/1000] loss: 0.08069034972611595
I0427 10:27:23.233890 11084 trainer.py:136] Epoch[316/1000] loss: 0.07787585609099444
I0427 10:27:25.323055 11084 trainer.py:136] Epoch[317/1000] loss: 0.07937097461784587
I0427 10:27:27.428387 11084 trainer.py:136] Epoch[318/1000] loss: 0.07856656961581286
I0427 10:27:29.560949 11084 trainer.py:136] Epoch[319/1000] loss: 0.08179622055853114
I0427 10:27:31.839323 11084 trainer.py:136] Epoch[320/1000] loss: 0.08053845386294757
I0427 10:27:34.073036 11084 trainer.py:136] Epoch[321/1000] loss: 0.07846121928271126
I0427 10:27:36.303712 11084 trainer.py:136] Epoch[322/1000] loss: 0.077280921751962
I0427 10:27:38.394140 11084 trainer.py:136] Epoch[323/1000] loss: 0.07895433946567423
I0427 10:27:40.636273 11084 trainer.py:136] Epoch[324/1000] loss: 0.07929899412042954
I0427 10:27:42.816926 11084 trainer.py:136] Epoch[325/1000] loss: 0.07943965713767444
I0427 10:27:45.097334 11084 trainer.py:136] Epoch[326/1000] loss: 0.07761304365361438
I0427 10:27:47.224363 11084 trainer.py:136] Epoch[327/1000] loss: 0.07746677495100919
I0427 10:27:49.462635 11084 trainer.py:136] Epoch[328/1000] loss: 0.07788412579718758
I0427 10:27:51.753646 11084 trainer.py:136] Epoch[329/1000] loss: 0.07930538321242613
I0427 10:27:54.019202 11084 trainer.py:136] Epoch[330/1000] loss: 0.07768493277185104
I0427 10:27:56.220950 11084 trainer.py:136] Epoch[331/1000] loss: 0.0790994645041578
I0427 10:27:58.369105 11084 trainer.py:136] Epoch[332/1000] loss: 0.07781335492344464
I0427 10:28:00.688715 11084 trainer.py:136] Epoch[333/1000] loss: 0.07744643398944069
I0427 10:28:02.986794 11084 trainer.py:136] Epoch[334/1000] loss: 0.07855634347480886
I0427 10:28:05.305977 11084 trainer.py:136] Epoch[335/1000] loss: 0.07761638041804819
I0427 10:28:07.448924 11084 trainer.py:136] Epoch[336/1000] loss: 0.07504137495861334
I0427 10:28:09.670189 11084 trainer.py:136] Epoch[337/1000] loss: 0.07767638695590637
I0427 10:28:11.878974 11084 trainer.py:136] Epoch[338/1000] loss: 0.07532047809046857
I0427 10:28:14.107696 11084 trainer.py:136] Epoch[339/1000] loss: 0.0766467224149143
I0427 10:28:16.287627 11084 trainer.py:136] Epoch[340/1000] loss: 0.0811831096515936
I0427 10:28:18.519933 11084 trainer.py:136] Epoch[341/1000] loss: 0.07457261839333702
I0427 10:28:20.733677 11084 trainer.py:136] Epoch[342/1000] loss: 0.07949454249704585
I0427 10:28:22.999285 11084 trainer.py:136] Epoch[343/1000] loss: 0.07691493235966738
I0427 10:28:25.261539 11084 trainer.py:136] Epoch[344/1000] loss: 0.0753931363715845
I0427 10:28:27.528874 11084 trainer.py:136] Epoch[345/1000] loss: 0.07592575208229177
I0427 10:28:29.662806 11084 trainer.py:136] Epoch[346/1000] loss: 0.07437293976545334
I0427 10:28:31.960278 11084 trainer.py:136] Epoch[347/1000] loss: 0.07494703439228675
I0427 10:28:34.223726 11084 trainer.py:136] Epoch[348/1000] loss: 0.07456617955775822
I0427 10:28:36.475005 11084 trainer.py:136] Epoch[349/1000] loss: 0.07601648919722613
I0427 10:28:36.623507 11084 trainer.py:142] Test: [{'precision': 0.13504021447721185, 'recall': 0.31901388983197854, 'hit_ratio': 0.8809651474530831, 'ndcg': 0.3006581285505657}]
I0427 10:28:38.871193 11084 trainer.py:136] Epoch[350/1000] loss: 0.07809235506197985
I0427 10:28:41.078051 11084 trainer.py:136] Epoch[351/1000] loss: 0.07762673979296404
I0427 10:28:43.203046 11084 trainer.py:136] Epoch[352/1000] loss: 0.07462263852357864
I0427 10:28:45.390873 11084 trainer.py:136] Epoch[353/1000] loss: 0.07703939474680845
I0427 10:28:47.601251 11084 trainer.py:136] Epoch[354/1000] loss: 0.07693629273596932
I0427 10:28:49.748244 11084 trainer.py:136] Epoch[355/1000] loss: 0.07683111683410757
I0427 10:28:52.047010 11084 trainer.py:136] Epoch[356/1000] loss: 0.07625507870141197
I0427 10:28:54.249889 11084 trainer.py:136] Epoch[357/1000] loss: 0.07629008152905632
I0427 10:28:56.619657 11084 trainer.py:136] Epoch[358/1000] loss: 0.07530741897575996
I0427 10:28:58.825965 11084 trainer.py:136] Epoch[359/1000] loss: 0.07645654371556114
I0427 10:29:01.072839 11084 trainer.py:136] Epoch[360/1000] loss: 0.08034406120286268
I0427 10:29:03.273997 11084 trainer.py:136] Epoch[361/1000] loss: 0.07668212231467753
I0427 10:29:05.453964 11084 trainer.py:136] Epoch[362/1000] loss: 0.07598721893394694
I0427 10:29:07.589521 11084 trainer.py:136] Epoch[363/1000] loss: 0.07449936559971641
I0427 10:29:09.772155 11084 trainer.py:136] Epoch[364/1000] loss: 0.0731453562484068
I0427 10:29:11.904465 11084 trainer.py:136] Epoch[365/1000] loss: 0.07484959416529711
I0427 10:29:14.166071 11084 trainer.py:136] Epoch[366/1000] loss: 0.07454576343297958
I0427 10:29:16.372821 11084 trainer.py:136] Epoch[367/1000] loss: 0.07512860043960459
I0427 10:29:18.635071 11084 trainer.py:136] Epoch[368/1000] loss: 0.07329911037402995
I0427 10:29:20.852372 11084 trainer.py:136] Epoch[369/1000] loss: 0.07484704431365519
I0427 10:29:23.091871 11084 trainer.py:136] Epoch[370/1000] loss: 0.07424366561805501
I0427 10:29:25.212921 11084 trainer.py:136] Epoch[371/1000] loss: 0.07410660123123843
I0427 10:29:27.468621 11084 trainer.py:136] Epoch[372/1000] loss: 0.07516666983856875
I0427 10:29:29.633638 11084 trainer.py:136] Epoch[373/1000] loss: 0.07234178264351453
I0427 10:29:31.807849 11084 trainer.py:136] Epoch[374/1000] loss: 0.07345103560125127
I0427 10:29:33.989683 11084 trainer.py:136] Epoch[375/1000] loss: 0.07555906343109467
I0427 10:29:36.179466 11084 trainer.py:136] Epoch[376/1000] loss: 0.07467970558825661
I0427 10:29:38.400499 11084 trainer.py:136] Epoch[377/1000] loss: 0.07284073969897102
I0427 10:29:40.626966 11084 trainer.py:136] Epoch[378/1000] loss: 0.0732405019157073
I0427 10:29:42.817012 11084 trainer.py:136] Epoch[379/1000] loss: 0.07249510463546305
I0427 10:29:45.073511 11084 trainer.py:136] Epoch[380/1000] loss: 0.07375254525857813
I0427 10:29:47.305179 11084 trainer.py:136] Epoch[381/1000] loss: 0.07267185453982915
I0427 10:29:49.439180 11084 trainer.py:136] Epoch[382/1000] loss: 0.07175526373526629
I0427 10:29:51.780230 11084 trainer.py:136] Epoch[383/1000] loss: 0.06892146542668343
I0427 10:29:54.005019 11084 trainer.py:136] Epoch[384/1000] loss: 0.07438413053750992
I0427 10:29:56.119132 11084 trainer.py:136] Epoch[385/1000] loss: 0.07433842473170336
I0427 10:29:58.287122 11084 trainer.py:136] Epoch[386/1000] loss: 0.07587904088637408
I0427 10:30:00.511398 11084 trainer.py:136] Epoch[387/1000] loss: 0.07133315810385872
I0427 10:30:02.671342 11084 trainer.py:136] Epoch[388/1000] loss: 0.07245099456871257
I0427 10:30:04.910025 11084 trainer.py:136] Epoch[389/1000] loss: 0.07313825628336738
I0427 10:30:06.999235 11084 trainer.py:136] Epoch[390/1000] loss: 0.07519870864994385
I0427 10:30:09.344866 11084 trainer.py:136] Epoch[391/1000] loss: 0.0746453781338299
I0427 10:30:11.551751 11084 trainer.py:136] Epoch[392/1000] loss: 0.07352232144159429
I0427 10:30:13.767736 11084 trainer.py:136] Epoch[393/1000] loss: 0.07260822373278
I0427 10:30:16.012780 11084 trainer.py:136] Epoch[394/1000] loss: 0.07104911107350798
I0427 10:30:18.180660 11084 trainer.py:136] Epoch[395/1000] loss: 0.0742933395154336
I0427 10:30:20.415285 11084 trainer.py:136] Epoch[396/1000] loss: 0.07216612381093643
I0427 10:30:22.625639 11084 trainer.py:136] Epoch[397/1000] loss: 0.07279576448833242
I0427 10:30:24.761650 11084 trainer.py:136] Epoch[398/1000] loss: 0.07413941227337893
I0427 10:30:27.059688 11084 trainer.py:136] Epoch[399/1000] loss: 0.07198773149181814
I0427 10:30:27.201213 11084 trainer.py:142] Test: [{'precision': 0.13646112600536203, 'recall': 0.3226216627561054, 'hit_ratio': 0.882573726541555, 'ndcg': 0.30394588838509223}]
I0427 10:30:29.428109 11084 trainer.py:136] Epoch[400/1000] loss: 0.07320206568521612
I0427 10:30:31.678075 11084 trainer.py:136] Epoch[401/1000] loss: 0.0726562251939493
I0427 10:30:33.913408 11084 trainer.py:136] Epoch[402/1000] loss: 0.07049877525252454
I0427 10:30:36.164236 11084 trainer.py:136] Epoch[403/1000] loss: 0.07426136403399355
I0427 10:30:38.281478 11084 trainer.py:136] Epoch[404/1000] loss: 0.07186127673177158
I0427 10:30:40.575491 11084 trainer.py:136] Epoch[405/1000] loss: 0.06905956785468494
I0427 10:30:42.737959 11084 trainer.py:136] Epoch[406/1000] loss: 0.07182426553438692
I0427 10:30:45.001713 11084 trainer.py:136] Epoch[407/1000] loss: 0.07139802110545776
I0427 10:30:47.194712 11084 trainer.py:136] Epoch[408/1000] loss: 0.07039543789099245
I0427 10:30:49.386916 11084 trainer.py:136] Epoch[409/1000] loss: 0.06906764625626452
I0427 10:30:51.772431 11084 trainer.py:136] Epoch[410/1000] loss: 0.06960190898355316
I0427 10:30:53.993453 11084 trainer.py:136] Epoch[411/1000] loss: 0.07360325008630753
I0427 10:30:56.241800 11084 trainer.py:136] Epoch[412/1000] loss: 0.06909541259793674
I0427 10:30:58.441711 11084 trainer.py:136] Epoch[413/1000] loss: 0.07208584380500457
I0427 10:31:00.706831 11084 trainer.py:136] Epoch[414/1000] loss: 0.07093813445638208
I0427 10:31:02.960404 11084 trainer.py:136] Epoch[415/1000] loss: 0.07002410993856542
I0427 10:31:05.177006 11084 trainer.py:136] Epoch[416/1000] loss: 0.07328826758791418
I0427 10:31:07.358879 11084 trainer.py:136] Epoch[417/1000] loss: 0.06938973858075984
I0427 10:31:09.612081 11084 trainer.py:136] Epoch[418/1000] loss: 0.07087111297775717
I0427 10:31:11.927339 11084 trainer.py:136] Epoch[419/1000] loss: 0.07194277205887963
I0427 10:31:14.110732 11084 trainer.py:136] Epoch[420/1000] loss: 0.07038040152367424
I0427 10:31:16.260553 11084 trainer.py:136] Epoch[421/1000] loss: 0.06869685737525716
I0427 10:31:18.527679 11084 trainer.py:136] Epoch[422/1000] loss: 0.06985669276293587
I0427 10:31:20.674645 11084 trainer.py:136] Epoch[423/1000] loss: 0.06818255650646546
I0427 10:31:22.919808 11084 trainer.py:136] Epoch[424/1000] loss: 0.06995752497630961
I0427 10:31:25.142505 11084 trainer.py:136] Epoch[425/1000] loss: 0.07446912500788183
I0427 10:31:27.405166 11084 trainer.py:136] Epoch[426/1000] loss: 0.07044548979576896
I0427 10:31:29.599866 11084 trainer.py:136] Epoch[427/1000] loss: 0.07409605559180765
I0427 10:31:31.933716 11084 trainer.py:136] Epoch[428/1000] loss: 0.06910132792066126
I0427 10:31:34.064769 11084 trainer.py:136] Epoch[429/1000] loss: 0.06850936548674808
I0427 10:31:36.281473 11084 trainer.py:136] Epoch[430/1000] loss: 0.0690171979367733
I0427 10:31:38.533611 11084 trainer.py:136] Epoch[431/1000] loss: 0.06987204753300723
I0427 10:31:40.728429 11084 trainer.py:136] Epoch[432/1000] loss: 0.06681661943302435
I0427 10:31:42.936176 11084 trainer.py:136] Epoch[433/1000] loss: 0.06861346806673442
I0427 10:31:45.170726 11084 trainer.py:136] Epoch[434/1000] loss: 0.06891547121545848
I0427 10:31:47.370129 11084 trainer.py:136] Epoch[435/1000] loss: 0.0688927145126988
I0427 10:31:49.606956 11084 trainer.py:136] Epoch[436/1000] loss: 0.06835274091538261
I0427 10:31:51.936873 11084 trainer.py:136] Epoch[437/1000] loss: 0.06674393025391243
I0427 10:31:54.137223 11084 trainer.py:136] Epoch[438/1000] loss: 0.0692525755833177
I0427 10:31:56.328118 11084 trainer.py:136] Epoch[439/1000] loss: 0.06871321468668826
I0427 10:31:58.562373 11084 trainer.py:136] Epoch[440/1000] loss: 0.06850715595133164
I0427 10:32:00.735275 11084 trainer.py:136] Epoch[441/1000] loss: 0.06693717903074096
I0427 10:32:02.921093 11084 trainer.py:136] Epoch[442/1000] loss: 0.06822945769218837
I0427 10:32:05.178676 11084 trainer.py:136] Epoch[443/1000] loss: 0.06666555343305364
I0427 10:32:07.316175 11084 trainer.py:136] Epoch[444/1000] loss: 0.06924897848683245
I0427 10:32:09.577490 11084 trainer.py:136] Epoch[445/1000] loss: 0.06745881302391782
I0427 10:32:11.807581 11084 trainer.py:136] Epoch[446/1000] loss: 0.06686936932451584
I0427 10:32:14.050297 11084 trainer.py:136] Epoch[447/1000] loss: 0.06919541604378644
I0427 10:32:16.255070 11084 trainer.py:136] Epoch[448/1000] loss: 0.06640043832799968
I0427 10:32:18.403006 11084 trainer.py:136] Epoch[449/1000] loss: 0.06693834154044881
I0427 10:32:18.549112 11084 trainer.py:142] Test: [{'precision': 0.13603217158176953, 'recall': 0.3215968507302683, 'hit_ratio': 0.882573726541555, 'ndcg': 0.3037783383890825}]
I0427 10:32:20.701960 11084 trainer.py:136] Epoch[450/1000] loss: 0.0700410354663344
I0427 10:32:22.914795 11084 trainer.py:136] Epoch[451/1000] loss: 0.0679925572784508
I0427 10:32:25.150461 11084 trainer.py:136] Epoch[452/1000] loss: 0.07051239863914602
I0427 10:32:27.292442 11084 trainer.py:136] Epoch[453/1000] loss: 0.06881024513174505
I0427 10:32:29.447125 11084 trainer.py:136] Epoch[454/1000] loss: 0.07059854225200765
I0427 10:32:31.613510 11084 trainer.py:136] Epoch[455/1000] loss: 0.06944662201053955
I0427 10:32:33.767978 11084 trainer.py:136] Epoch[456/1000] loss: 0.06545598279027377
I0427 10:32:35.880616 11084 trainer.py:136] Epoch[457/1000] loss: 0.06513780026751406
I0427 10:32:38.011688 11084 trainer.py:136] Epoch[458/1000] loss: 0.06810323521494865
I0427 10:32:40.284554 11084 trainer.py:136] Epoch[459/1000] loss: 0.06629439070820808
I0427 10:32:42.485932 11084 trainer.py:136] Epoch[460/1000] loss: 0.06882394236676834
I0427 10:32:44.731165 11084 trainer.py:136] Epoch[461/1000] loss: 0.06729456190677251
I0427 10:32:46.922233 11084 trainer.py:136] Epoch[462/1000] loss: 0.06583600885727826
I0427 10:32:49.043012 11084 trainer.py:136] Epoch[463/1000] loss: 0.06693540929871447
I0427 10:32:51.229272 11084 trainer.py:136] Epoch[464/1000] loss: 0.0668424058924703
I0427 10:32:53.463739 11084 trainer.py:136] Epoch[465/1000] loss: 0.06495032021228005
I0427 10:32:55.680156 11084 trainer.py:136] Epoch[466/1000] loss: 0.06720391967717339
I0427 10:32:57.780995 11084 trainer.py:136] Epoch[467/1000] loss: 0.06843500102267545
I0427 10:33:00.005917 11084 trainer.py:136] Epoch[468/1000] loss: 0.06685249901869718
I0427 10:33:02.217262 11084 trainer.py:136] Epoch[469/1000] loss: 0.06651350395644412
I0427 10:33:04.436609 11084 trainer.py:136] Epoch[470/1000] loss: 0.06721372266902643
I0427 10:33:06.656986 11084 trainer.py:136] Epoch[471/1000] loss: 0.0660057631047333
I0427 10:33:08.659611 11084 trainer.py:136] Epoch[472/1000] loss: 0.06653913461110171
I0427 10:33:10.910303 11084 trainer.py:136] Epoch[473/1000] loss: 0.06947898382649702
I0427 10:33:13.146945 11084 trainer.py:136] Epoch[474/1000] loss: 0.0654569441343055
I0427 10:33:15.340820 11084 trainer.py:136] Epoch[475/1000] loss: 0.06754473443416988
I0427 10:33:17.587198 11084 trainer.py:136] Epoch[476/1000] loss: 0.06550207602627137
I0427 10:33:19.688549 11084 trainer.py:136] Epoch[477/1000] loss: 0.06727853724185158
I0427 10:33:21.872794 11084 trainer.py:136] Epoch[478/1000] loss: 0.06535937549436793
I0427 10:33:23.988591 11084 trainer.py:136] Epoch[479/1000] loss: 0.06604261652511709
I0427 10:33:26.247549 11084 trainer.py:136] Epoch[480/1000] loss: 0.06588938766542603
I0427 10:33:28.340959 11084 trainer.py:136] Epoch[481/1000] loss: 0.06732844868127037
I0427 10:33:30.628025 11084 trainer.py:136] Epoch[482/1000] loss: 0.06569472853751744
I0427 10:33:32.866873 11084 trainer.py:136] Epoch[483/1000] loss: 0.0667318995384609
I0427 10:33:35.052120 11084 trainer.py:136] Epoch[484/1000] loss: 0.06572553120991763
I0427 10:33:37.204212 11084 trainer.py:136] Epoch[485/1000] loss: 0.06517715248114922
I0427 10:33:39.366094 11084 trainer.py:136] Epoch[486/1000] loss: 0.06900456986006569
I0427 10:33:41.639264 11084 trainer.py:136] Epoch[487/1000] loss: 0.06745154520168024
I0427 10:33:43.774050 11084 trainer.py:136] Epoch[488/1000] loss: 0.06552406312788234
I0427 10:33:45.937017 11084 trainer.py:136] Epoch[489/1000] loss: 0.06487947110744084
I0427 10:33:48.063059 11084 trainer.py:136] Epoch[490/1000] loss: 0.0672135204076767
I0427 10:33:50.235519 11084 trainer.py:136] Epoch[491/1000] loss: 0.06573476160273832
I0427 10:33:52.376527 11084 trainer.py:136] Epoch[492/1000] loss: 0.06455408716026474
I0427 10:33:54.621327 11084 trainer.py:136] Epoch[493/1000] loss: 0.06723150238394737
I0427 10:33:56.742216 11084 trainer.py:136] Epoch[494/1000] loss: 0.06650629223269575
I0427 10:33:58.995623 11084 trainer.py:136] Epoch[495/1000] loss: 0.06447461817194433
I0427 10:34:01.222027 11084 trainer.py:136] Epoch[496/1000] loss: 0.06495656489449389
I0427 10:34:03.458105 11084 trainer.py:136] Epoch[497/1000] loss: 0.06520238124272403
I0427 10:34:05.661470 11084 trainer.py:136] Epoch[498/1000] loss: 0.06567558229846113
I0427 10:34:07.922125 11084 trainer.py:136] Epoch[499/1000] loss: 0.0659440996892312
I0427 10:34:08.092555 11084 trainer.py:142] Test: [{'precision': 0.13702412868632716, 'recall': 0.3233080945058552, 'hit_ratio': 0.8847184986595175, 'ndcg': 0.3051762964415168}]
I0427 10:34:10.313290 11084 trainer.py:136] Epoch[500/1000] loss: 0.06569358991349444
I0427 10:34:12.574450 11084 trainer.py:136] Epoch[501/1000] loss: 0.06489120182745597
I0427 10:34:14.781670 11084 trainer.py:136] Epoch[502/1000] loss: 0.06453901638879496
I0427 10:34:17.020935 11084 trainer.py:136] Epoch[503/1000] loss: 0.06897829911288093
I0427 10:34:19.206803 11084 trainer.py:136] Epoch[504/1000] loss: 0.06491969635381419
I0427 10:34:21.472004 11084 trainer.py:136] Epoch[505/1000] loss: 0.06498176823644077
I0427 10:34:23.723407 11084 trainer.py:136] Epoch[506/1000] loss: 0.0644548368804595
I0427 10:34:25.928225 11084 trainer.py:136] Epoch[507/1000] loss: 0.0642779121065841
I0427 10:34:28.055850 11084 trainer.py:136] Epoch[508/1000] loss: 0.06271584090941093
I0427 10:34:30.259567 11084 trainer.py:136] Epoch[509/1000] loss: 0.06546315244015526
I0427 10:34:32.511101 11084 trainer.py:136] Epoch[510/1000] loss: 0.06363459216321216
I0427 10:34:34.765697 11084 trainer.py:136] Epoch[511/1000] loss: 0.06411146438297104
I0427 10:34:36.912685 11084 trainer.py:136] Epoch[512/1000] loss: 0.06567288847530589
I0427 10:34:39.018774 11084 trainer.py:136] Epoch[513/1000] loss: 0.06415679481099634
I0427 10:34:41.269815 11084 trainer.py:136] Epoch[514/1000] loss: 0.06471470852985102
I0427 10:34:43.500466 11084 trainer.py:136] Epoch[515/1000] loss: 0.06484748094397433
I0427 10:34:45.822252 11084 trainer.py:136] Epoch[516/1000] loss: 0.06469266730196335
I0427 10:34:48.031049 11084 trainer.py:136] Epoch[517/1000] loss: 0.06431500810910673
I0427 10:34:50.336250 11084 trainer.py:136] Epoch[518/1000] loss: 0.06362160514382754
I0427 10:34:52.611361 11084 trainer.py:136] Epoch[519/1000] loss: 0.064929237260538
I0427 10:34:54.806250 11084 trainer.py:136] Epoch[520/1000] loss: 0.06796354077318136
I0427 10:34:57.017326 11084 trainer.py:136] Epoch[521/1000] loss: 0.06375967382508166
I0427 10:34:59.231399 11084 trainer.py:136] Epoch[522/1000] loss: 0.06511262344086871
I0427 10:35:01.461755 11084 trainer.py:136] Epoch[523/1000] loss: 0.06343578503412359
I0427 10:35:03.714006 11084 trainer.py:136] Epoch[524/1000] loss: 0.06517329242299585
I0427 10:35:05.893516 11084 trainer.py:136] Epoch[525/1000] loss: 0.06408371710601975
I0427 10:35:08.108319 11084 trainer.py:136] Epoch[526/1000] loss: 0.061721923158449286
I0427 10:35:10.309776 11084 trainer.py:136] Epoch[527/1000] loss: 0.06490804430316477
I0427 10:35:12.545976 11084 trainer.py:136] Epoch[528/1000] loss: 0.06479261662153636
I0427 10:35:14.757711 11084 trainer.py:136] Epoch[529/1000] loss: 0.06418554068488233
I0427 10:35:17.005231 11084 trainer.py:136] Epoch[530/1000] loss: 0.06479323808761205
I0427 10:35:19.160587 11084 trainer.py:136] Epoch[531/1000] loss: 0.06253188804668539
I0427 10:35:21.348078 11084 trainer.py:136] Epoch[532/1000] loss: 0.06454088911414146
I0427 10:35:23.514233 11084 trainer.py:136] Epoch[533/1000] loss: 0.06422127257375156
I0427 10:35:25.671825 11084 trainer.py:136] Epoch[534/1000] loss: 0.0637845037614598
I0427 10:35:27.873054 11084 trainer.py:136] Epoch[535/1000] loss: 0.06380210334763807
I0427 10:35:30.105016 11084 trainer.py:136] Epoch[536/1000] loss: 0.06374493175569702
I0427 10:35:32.416325 11084 trainer.py:136] Epoch[537/1000] loss: 0.06395431629875127
I0427 10:35:34.550019 11084 trainer.py:136] Epoch[538/1000] loss: 0.06508176313603625
I0427 10:35:36.772800 11084 trainer.py:136] Epoch[539/1000] loss: 0.06460161682437449
I0427 10:35:39.069555 11084 trainer.py:136] Epoch[540/1000] loss: 0.0622427200569826
I0427 10:35:41.348549 11084 trainer.py:136] Epoch[541/1000] loss: 0.06165192079018144
I0427 10:35:43.690879 11084 trainer.py:136] Epoch[542/1000] loss: 0.062256190487567115
I0427 10:35:45.964416 11084 trainer.py:136] Epoch[543/1000] loss: 0.06277506404063281
I0427 10:35:48.073950 11084 trainer.py:136] Epoch[544/1000] loss: 0.06660060847506803
I0427 10:35:50.203984 11084 trainer.py:136] Epoch[545/1000] loss: 0.06401011457338053
I0427 10:35:52.289720 11084 trainer.py:136] Epoch[546/1000] loss: 0.06440569328911164
I0427 10:35:54.433744 11084 trainer.py:136] Epoch[547/1000] loss: 0.06487581922727473
I0427 10:35:56.529956 11084 trainer.py:136] Epoch[548/1000] loss: 0.0635397844016552
I0427 10:35:58.704883 11084 trainer.py:136] Epoch[549/1000] loss: 0.06360701887923129
I0427 10:35:58.865348 11084 trainer.py:142] Test: [{'precision': 0.13804289544235931, 'recall': 0.3264579681651122, 'hit_ratio': 0.8847184986595175, 'ndcg': 0.3072995552595154}]
I0427 10:36:01.051247 11084 trainer.py:136] Epoch[550/1000] loss: 0.06539806000450078
I0427 10:36:03.217160 11084 trainer.py:136] Epoch[551/1000] loss: 0.06355480170425247
I0427 10:36:05.384597 11084 trainer.py:136] Epoch[552/1000] loss: 0.0628705592278172
I0427 10:36:07.601109 11084 trainer.py:136] Epoch[553/1000] loss: 0.06396051079911344
I0427 10:36:09.893050 11084 trainer.py:136] Epoch[554/1000] loss: 0.06293178021031268
I0427 10:36:12.181094 11084 trainer.py:136] Epoch[555/1000] loss: 0.06444399825790349
I0427 10:36:14.404837 11084 trainer.py:136] Epoch[556/1000] loss: 0.06433283340405016
I0427 10:36:16.663035 11084 trainer.py:136] Epoch[557/1000] loss: 0.06475378770162077
I0427 10:36:18.796048 11084 trainer.py:136] Epoch[558/1000] loss: 0.0648230559685651
I0427 10:36:20.947636 11084 trainer.py:136] Epoch[559/1000] loss: 0.06568024154095088
I0427 10:36:23.138986 11084 trainer.py:136] Epoch[560/1000] loss: 0.0628282999729409
I0427 10:36:25.440166 11084 trainer.py:136] Epoch[561/1000] loss: 0.0629819958087276
I0427 10:36:27.565595 11084 trainer.py:136] Epoch[562/1000] loss: 0.06800337924676783
I0427 10:36:29.693960 11084 trainer.py:136] Epoch[563/1000] loss: 0.06385491766473826
I0427 10:36:31.875599 11084 trainer.py:136] Epoch[564/1000] loss: 0.06293849252602633
I0427 10:36:34.154319 11084 trainer.py:136] Epoch[565/1000] loss: 0.06260590299087412
I0427 10:36:36.329555 11084 trainer.py:136] Epoch[566/1000] loss: 0.06264270009363399
I0427 10:36:38.530960 11084 trainer.py:136] Epoch[567/1000] loss: 0.06080976457280271
I0427 10:36:40.753685 11084 trainer.py:136] Epoch[568/1000] loss: 0.060856300022672206
I0427 10:36:42.894719 11084 trainer.py:136] Epoch[569/1000] loss: 0.06535484247347888
I0427 10:36:45.129386 11084 trainer.py:136] Epoch[570/1000] loss: 0.06076726865242509
I0427 10:36:47.292187 11084 trainer.py:136] Epoch[571/1000] loss: 0.06111252132584067
I0427 10:36:49.537863 11084 trainer.py:136] Epoch[572/1000] loss: 0.06010840592138907
I0427 10:36:51.698797 11084 trainer.py:136] Epoch[573/1000] loss: 0.06273732093327186
I0427 10:36:53.989840 11084 trainer.py:136] Epoch[574/1000] loss: 0.06241701587158091
I0427 10:36:56.083232 11084 trainer.py:136] Epoch[575/1000] loss: 0.06311185153968193
I0427 10:36:58.194398 11084 trainer.py:136] Epoch[576/1000] loss: 0.06414365834173034
I0427 10:37:00.420670 11084 trainer.py:136] Epoch[577/1000] loss: 0.06270595924819217
I0427 10:37:02.640009 11084 trainer.py:136] Epoch[578/1000] loss: 0.06292296989875681
I0427 10:37:04.937449 11084 trainer.py:136] Epoch[579/1000] loss: 0.06174268113339648
I0427 10:37:07.200922 11084 trainer.py:136] Epoch[580/1000] loss: 0.06491906984763987
I0427 10:37:09.350775 11084 trainer.py:136] Epoch[581/1000] loss: 0.06402250927160769
I0427 10:37:11.590812 11084 trainer.py:136] Epoch[582/1000] loss: 0.060478228199131345
I0427 10:37:13.753533 11084 trainer.py:136] Epoch[583/1000] loss: 0.06076654200168217
I0427 10:37:16.013730 11084 trainer.py:136] Epoch[584/1000] loss: 0.06164532877943095
I0427 10:37:18.242482 11084 trainer.py:136] Epoch[585/1000] loss: 0.06316719313754755
I0427 10:37:20.393979 11084 trainer.py:136] Epoch[586/1000] loss: 0.06308657632154577
I0427 10:37:22.599377 11084 trainer.py:136] Epoch[587/1000] loss: 0.06363233836258159
I0427 10:37:24.736415 11084 trainer.py:136] Epoch[588/1000] loss: 0.0631030854933402
I0427 10:37:26.953537 11084 trainer.py:136] Epoch[589/1000] loss: 0.06223184177104164
I0427 10:37:29.252052 11084 trainer.py:136] Epoch[590/1000] loss: 0.06057747387710739
I0427 10:37:31.504024 11084 trainer.py:136] Epoch[591/1000] loss: 0.06648745519273422
I0427 10:37:33.733733 11084 trainer.py:136] Epoch[592/1000] loss: 0.06194472247186829
I0427 10:37:35.848954 11084 trainer.py:136] Epoch[593/1000] loss: 0.06276922431938789
I0427 10:37:37.956019 11084 trainer.py:136] Epoch[594/1000] loss: 0.0632008048979675
I0427 10:37:40.318506 11084 trainer.py:136] Epoch[595/1000] loss: 0.06150645894162795
I0427 10:37:42.452672 11084 trainer.py:136] Epoch[596/1000] loss: 0.06350126709131633
I0427 10:37:44.671967 11084 trainer.py:136] Epoch[597/1000] loss: 0.06144773039747687
I0427 10:37:46.800040 11084 trainer.py:136] Epoch[598/1000] loss: 0.061218224904116464
I0427 10:37:49.139328 11084 trainer.py:136] Epoch[599/1000] loss: 0.061618312535917055
I0427 10:37:49.291819 11084 trainer.py:142] Test: [{'precision': 0.1383646112600537, 'recall': 0.32685795394043315, 'hit_ratio': 0.8847184986595175, 'ndcg': 0.30855801807878197}]
I0427 10:37:51.531696 11084 trainer.py:136] Epoch[600/1000] loss: 0.0627328093875857
I0427 10:37:53.704095 11084 trainer.py:136] Epoch[601/1000] loss: 0.05967436687034719
I0427 10:37:55.861890 11084 trainer.py:136] Epoch[602/1000] loss: 0.05999173771809129
I0427 10:37:58.090565 11084 trainer.py:136] Epoch[603/1000] loss: 0.06203817115987048
I0427 10:38:00.326265 11084 trainer.py:136] Epoch[604/1000] loss: 0.061738941599341
I0427 10:38:02.479635 11084 trainer.py:136] Epoch[605/1000] loss: 0.062089338022119855
I0427 10:38:04.691450 11084 trainer.py:136] Epoch[606/1000] loss: 0.06264580106910538
I0427 10:38:06.832230 11084 trainer.py:136] Epoch[607/1000] loss: 0.06312805260805522
I0427 10:38:08.916694 11084 trainer.py:136] Epoch[608/1000] loss: 0.0611019756864099
I0427 10:38:11.159373 11084 trainer.py:136] Epoch[609/1000] loss: 0.061547654735691404
I0427 10:38:13.388089 11084 trainer.py:136] Epoch[610/1000] loss: 0.06116733634296585
I0427 10:38:15.488772 11084 trainer.py:136] Epoch[611/1000] loss: 0.05783219306784518
I0427 10:38:17.589869 11084 trainer.py:136] Epoch[612/1000] loss: 0.062362850150641275
I0427 10:38:19.829538 11084 trainer.py:136] Epoch[613/1000] loss: 0.06312959794612492
I0427 10:38:21.982645 11084 trainer.py:136] Epoch[614/1000] loss: 0.06032473550123327
I0427 10:38:24.271129 11084 trainer.py:136] Epoch[615/1000] loss: 0.059963158824864554
I0427 10:38:26.473469 11084 trainer.py:136] Epoch[616/1000] loss: 0.060287645853617615
I0427 10:38:28.762615 11084 trainer.py:136] Epoch[617/1000] loss: 0.060560148428468144
I0427 10:38:31.054430 11084 trainer.py:136] Epoch[618/1000] loss: 0.06056641984511824
I0427 10:38:33.254219 11084 trainer.py:136] Epoch[619/1000] loss: 0.06192381701925222
I0427 10:38:35.541308 11084 trainer.py:136] Epoch[620/1000] loss: 0.0629024203209316
I0427 10:38:37.843328 11084 trainer.py:136] Epoch[621/1000] loss: 0.06029533288058113
I0427 10:38:40.143234 11084 trainer.py:136] Epoch[622/1000] loss: 0.06098451903637718
I0427 10:38:42.340064 11084 trainer.py:136] Epoch[623/1000] loss: 0.060926690259400534
I0427 10:38:44.606181 11084 trainer.py:136] Epoch[624/1000] loss: 0.0616622223135303
I0427 10:38:46.882703 11084 trainer.py:136] Epoch[625/1000] loss: 0.05859174228766385
I0427 10:38:49.326368 11084 trainer.py:136] Epoch[626/1000] loss: 0.0632645213866935
I0427 10:38:51.523806 11084 trainer.py:136] Epoch[627/1000] loss: 0.06126172007883296
I0427 10:38:53.769784 11084 trainer.py:136] Epoch[628/1000] loss: 0.0613936120096375
I0427 10:38:56.012421 11084 trainer.py:136] Epoch[629/1000] loss: 0.06131580997915829
I0427 10:38:58.302923 11084 trainer.py:136] Epoch[630/1000] loss: 0.060473413370987945
I0427 10:39:00.602578 11084 trainer.py:136] Epoch[631/1000] loss: 0.060311623136786854
I0427 10:39:02.874114 11084 trainer.py:136] Epoch[632/1000] loss: 0.06029382216579774
I0427 10:39:05.143692 11084 trainer.py:136] Epoch[633/1000] loss: 0.06230435257448869
I0427 10:39:07.404565 11084 trainer.py:136] Epoch[634/1000] loss: 0.061655972372083104
I0427 10:39:09.582979 11084 trainer.py:136] Epoch[635/1000] loss: 0.06003003852332339
I0427 10:39:11.788742 11084 trainer.py:136] Epoch[636/1000] loss: 0.060813552316497356
I0427 10:39:13.985599 11084 trainer.py:136] Epoch[637/1000] loss: 0.061124827931909
I0427 10:39:16.215260 11084 trainer.py:136] Epoch[638/1000] loss: 0.05983730011126574
I0427 10:39:18.418181 11084 trainer.py:136] Epoch[639/1000] loss: 0.060881087446914
I0427 10:39:20.570705 11084 trainer.py:136] Epoch[640/1000] loss: 0.06056221508804489
I0427 10:39:22.772501 11084 trainer.py:136] Epoch[641/1000] loss: 0.06067271662109038
I0427 10:39:25.103523 11084 trainer.py:136] Epoch[642/1000] loss: 0.06019091759534443
I0427 10:39:27.318043 11084 trainer.py:136] Epoch[643/1000] loss: 0.0628864903222112
I0427 10:39:29.570740 11084 trainer.py:136] Epoch[644/1000] loss: 0.06098658175152891
I0427 10:39:31.715031 11084 trainer.py:136] Epoch[645/1000] loss: 0.060624274918261695
I0427 10:39:33.895840 11084 trainer.py:136] Epoch[646/1000] loss: 0.060607598108403826
I0427 10:39:36.060717 11084 trainer.py:136] Epoch[647/1000] loss: 0.0595964706119369
I0427 10:39:38.237782 11084 trainer.py:136] Epoch[648/1000] loss: 0.06043517173213117
I0427 10:39:40.532941 11084 trainer.py:136] Epoch[649/1000] loss: 0.06265327816500384
I0427 10:39:40.684435 11084 trainer.py:142] Test: [{'precision': 0.13801608579088476, 'recall': 0.3262798732484114, 'hit_ratio': 0.8847184986595175, 'ndcg': 0.30862107450792087}]
I0427 10:39:42.891809 11084 trainer.py:136] Epoch[650/1000] loss: 0.05772725120186806
I0427 10:39:45.080977 11084 trainer.py:136] Epoch[651/1000] loss: 0.0616530171212028
I0427 10:39:47.165225 11084 trainer.py:136] Epoch[652/1000] loss: 0.05882624164223671
I0427 10:39:49.350685 11084 trainer.py:136] Epoch[653/1000] loss: 0.06371039809549556
I0427 10:39:51.572916 11084 trainer.py:136] Epoch[654/1000] loss: 0.059042201760937184
I0427 10:39:53.693016 11084 trainer.py:136] Epoch[655/1000] loss: 0.0630028155796668
I0427 10:39:55.887275 11084 trainer.py:136] Epoch[656/1000] loss: 0.06118799483074861
I0427 10:39:58.043194 11084 trainer.py:136] Epoch[657/1000] loss: 0.0614980012178421
I0427 10:40:00.265933 11084 trainer.py:136] Epoch[658/1000] loss: 0.05863711259820882
I0427 10:40:02.542013 11084 trainer.py:136] Epoch[659/1000] loss: 0.058806603664861005
I0427 10:40:04.784296 11084 trainer.py:136] Epoch[660/1000] loss: 0.05910914566586999
I0427 10:40:07.095999 11084 trainer.py:136] Epoch[661/1000] loss: 0.059352667454411
I0427 10:40:09.199594 11084 trainer.py:136] Epoch[662/1000] loss: 0.05897786862709943
I0427 10:40:11.398457 11084 trainer.py:136] Epoch[663/1000] loss: 0.060652031179736644
I0427 10:40:13.556906 11084 trainer.py:136] Epoch[664/1000] loss: 0.05920643578557407
I0427 10:40:15.877944 11084 trainer.py:136] Epoch[665/1000] loss: 0.06192030428963549
I0427 10:40:18.076859 11084 trainer.py:136] Epoch[666/1000] loss: 0.06095883272149984
I0427 10:40:20.361594 11084 trainer.py:136] Epoch[667/1000] loss: 0.059821348199073004
I0427 10:40:22.628608 11084 trainer.py:136] Epoch[668/1000] loss: 0.060004825539448685
I0427 10:40:24.770251 11084 trainer.py:136] Epoch[669/1000] loss: 0.059801959377877856
I0427 10:40:27.074678 11084 trainer.py:136] Epoch[670/1000] loss: 0.05965401977300644
I0427 10:40:29.257511 11084 trainer.py:136] Epoch[671/1000] loss: 0.05851581605041728
I0427 10:40:31.611436 11084 trainer.py:136] Epoch[672/1000] loss: 0.060993111089748496
I0427 10:40:33.805892 11084 trainer.py:136] Epoch[673/1000] loss: 0.05956388615510043
I0427 10:40:36.124647 11084 trainer.py:136] Epoch[674/1000] loss: 0.06009605899453163
I0427 10:40:38.297629 11084 trainer.py:136] Epoch[675/1000] loss: 0.059453719240777636
I0427 10:40:40.574733 11084 trainer.py:136] Epoch[676/1000] loss: 0.05993057392975863
I0427 10:40:42.800098 11084 trainer.py:136] Epoch[677/1000] loss: 0.059010401368141174
I0427 10:40:45.021798 11084 trainer.py:136] Epoch[678/1000] loss: 0.05977417440975413
I0427 10:40:47.130926 11084 trainer.py:136] Epoch[679/1000] loss: 0.058832730878801906
I0427 10:40:49.392190 11084 trainer.py:136] Epoch[680/1000] loss: 0.05948331338517806
I0427 10:40:51.664314 11084 trainer.py:136] Epoch[681/1000] loss: 0.058944553355960286
I0427 10:40:53.924898 11084 trainer.py:136] Epoch[682/1000] loss: 0.058638711843420475
I0427 10:40:56.140682 11084 trainer.py:136] Epoch[683/1000] loss: 0.060341131818645144
I0427 10:40:58.313410 11084 trainer.py:136] Epoch[684/1000] loss: 0.057887302602038664
I0427 10:41:00.556573 11084 trainer.py:136] Epoch[685/1000] loss: 0.05820828807704589
I0427 10:41:02.813996 11084 trainer.py:136] Epoch[686/1000] loss: 0.05945391733856762
I0427 10:41:04.961874 11084 trainer.py:136] Epoch[687/1000] loss: 0.059223958455464416
I0427 10:41:07.207771 11084 trainer.py:136] Epoch[688/1000] loss: 0.058021012474508846
I0427 10:41:09.410500 11084 trainer.py:136] Epoch[689/1000] loss: 0.057832707596175814
I0427 10:41:11.625445 11084 trainer.py:136] Epoch[690/1000] loss: 0.06098303374122171
I0427 10:41:13.941457 11084 trainer.py:136] Epoch[691/1000] loss: 0.06055718024863916
I0427 10:41:16.250984 11084 trainer.py:136] Epoch[692/1000] loss: 0.05883207851473023
I0427 10:41:18.534100 11084 trainer.py:136] Epoch[693/1000] loss: 0.06176245497430072
I0427 10:41:20.823546 11084 trainer.py:136] Epoch[694/1000] loss: 0.05973564811489161
I0427 10:41:22.934766 11084 trainer.py:136] Epoch[695/1000] loss: 0.057642926188076246
I0427 10:41:25.133795 11084 trainer.py:136] Epoch[696/1000] loss: 0.0565711989560548
I0427 10:41:27.360116 11084 trainer.py:136] Epoch[697/1000] loss: 0.059615988941753614
I0427 10:41:29.578090 11084 trainer.py:136] Epoch[698/1000] loss: 0.06006190925836563
I0427 10:41:31.830007 11084 trainer.py:136] Epoch[699/1000] loss: 0.05964123786372297
I0427 10:41:31.993233 11084 trainer.py:142] Test: [{'precision': 0.1383109919571046, 'recall': 0.3270713536669222, 'hit_ratio': 0.885254691689008, 'ndcg': 0.3099516039841195}]
I0427 10:41:34.210234 11084 trainer.py:136] Epoch[700/1000] loss: 0.06001645567662576
I0427 10:41:36.470403 11084 trainer.py:136] Epoch[701/1000] loss: 0.060573901104576444
I0427 10:41:38.640515 11084 trainer.py:136] Epoch[702/1000] loss: 0.05903110499767696
I0427 10:41:40.864594 11084 trainer.py:136] Epoch[703/1000] loss: 0.05832778509048855
I0427 10:41:43.193996 11084 trainer.py:136] Epoch[704/1000] loss: 0.060060431413790756
I0427 10:41:45.421671 11084 trainer.py:136] Epoch[705/1000] loss: 0.05873247126446051
I0427 10:41:47.638319 11084 trainer.py:136] Epoch[706/1000] loss: 0.05813319981098175
I0427 10:41:49.879977 11084 trainer.py:136] Epoch[707/1000] loss: 0.06074790766133981
I0427 10:41:52.094353 11084 trainer.py:136] Epoch[708/1000] loss: 0.05924129310776206
I0427 10:41:54.281071 11084 trainer.py:136] Epoch[709/1000] loss: 0.057503646568340415
I0427 10:41:56.465952 11084 trainer.py:136] Epoch[710/1000] loss: 0.059053244178786
I0427 10:41:58.773969 11084 trainer.py:136] Epoch[711/1000] loss: 0.05671824887394905
I0427 10:42:00.959748 11084 trainer.py:136] Epoch[712/1000] loss: 0.05855280358125182
I0427 10:42:03.400896 11084 trainer.py:136] Epoch[713/1000] loss: 0.05741306503905969
I0427 10:42:05.634110 11084 trainer.py:136] Epoch[714/1000] loss: 0.057364963433321786
I0427 10:42:07.990412 11084 trainer.py:136] Epoch[715/1000] loss: 0.058697818833238935
I0427 10:42:10.215049 11084 trainer.py:136] Epoch[716/1000] loss: 0.06019119677298209
I0427 10:42:12.461164 11084 trainer.py:136] Epoch[717/1000] loss: 0.056679413160857034
I0427 10:42:14.651271 11084 trainer.py:136] Epoch[718/1000] loss: 0.05878149367430631
I0427 10:42:16.906121 11084 trainer.py:136] Epoch[719/1000] loss: 0.05987322155167075
I0427 10:42:19.168694 11084 trainer.py:136] Epoch[720/1000] loss: 0.057136373484835905
I0427 10:42:21.320617 11084 trainer.py:136] Epoch[721/1000] loss: 0.05728358863031163
I0427 10:42:23.567815 11084 trainer.py:136] Epoch[722/1000] loss: 0.0576762256815153
I0427 10:42:25.836339 11084 trainer.py:136] Epoch[723/1000] loss: 0.0587923564016819
I0427 10:42:28.012035 11084 trainer.py:136] Epoch[724/1000] loss: 0.05605622556279687
I0427 10:42:30.249157 11084 trainer.py:136] Epoch[725/1000] loss: 0.05699357499971109
I0427 10:42:32.583096 11084 trainer.py:136] Epoch[726/1000] loss: 0.05772994524415802
I0427 10:42:34.840331 11084 trainer.py:136] Epoch[727/1000] loss: 0.056760278475635195
I0427 10:42:37.003707 11084 trainer.py:136] Epoch[728/1000] loss: 0.058384764939546585
I0427 10:42:39.179578 11084 trainer.py:136] Epoch[729/1000] loss: 0.05707043628482258
I0427 10:42:41.412203 11084 trainer.py:136] Epoch[730/1000] loss: 0.05793442620950587
I0427 10:42:43.664659 11084 trainer.py:136] Epoch[731/1000] loss: 0.058212593855226744
I0427 10:42:45.722963 11084 trainer.py:136] Epoch[732/1000] loss: 0.05904355623266276
I0427 10:42:47.969613 11084 trainer.py:136] Epoch[733/1000] loss: 0.05607263897271717
I0427 10:42:50.219969 11084 trainer.py:136] Epoch[734/1000] loss: 0.058526753502733564
I0427 10:42:52.536973 11084 trainer.py:136] Epoch[735/1000] loss: 0.058043091174434215
I0427 10:42:54.772363 11084 trainer.py:136] Epoch[736/1000] loss: 0.059088826179504395
I0427 10:42:57.014068 11084 trainer.py:136] Epoch[737/1000] loss: 0.058343041907338536
I0427 10:42:59.307518 11084 trainer.py:136] Epoch[738/1000] loss: 0.058265009127995544
I0427 10:43:01.537828 11084 trainer.py:136] Epoch[739/1000] loss: 0.05832913079682518
I0427 10:43:03.875126 11084 trainer.py:136] Epoch[740/1000] loss: 0.056608814746141434
I0427 10:43:06.037323 11084 trainer.py:136] Epoch[741/1000] loss: 0.05648180513697512
I0427 10:43:08.324541 11084 trainer.py:136] Epoch[742/1000] loss: 0.05568950930062462
I0427 10:43:10.504177 11084 trainer.py:136] Epoch[743/1000] loss: 0.05672138337703312
I0427 10:43:12.680038 11084 trainer.py:136] Epoch[744/1000] loss: 0.06021511773852741
I0427 10:43:14.922281 11084 trainer.py:136] Epoch[745/1000] loss: 0.058071834856972974
I0427 10:43:17.150850 11084 trainer.py:136] Epoch[746/1000] loss: 0.057533551226643956
I0427 10:43:19.340658 11084 trainer.py:136] Epoch[747/1000] loss: 0.05759404687320485
I0427 10:43:21.620821 11084 trainer.py:136] Epoch[748/1000] loss: 0.05766933783888817
I0427 10:43:23.948260 11084 trainer.py:136] Epoch[749/1000] loss: 0.05811513412524672
I0427 10:43:24.104736 11084 trainer.py:142] Test: [{'precision': 0.13908847184986603, 'recall': 0.32890640497248297, 'hit_ratio': 0.8879356568364611, 'ndcg': 0.31081114403449056}]
I0427 10:43:26.343163 11084 trainer.py:136] Epoch[750/1000] loss: 0.05885120700387394
I0427 10:43:28.534646 11084 trainer.py:136] Epoch[751/1000] loss: 0.056763299028663075
I0427 10:43:30.731891 11084 trainer.py:136] Epoch[752/1000] loss: 0.0580635423607686
I0427 10:43:33.044237 11084 trainer.py:136] Epoch[753/1000] loss: 0.05732386624988388
I0427 10:43:35.249171 11084 trainer.py:136] Epoch[754/1000] loss: 0.05677588568890796
I0427 10:43:37.500270 11084 trainer.py:136] Epoch[755/1000] loss: 0.05760907009243965
I0427 10:43:39.684142 11084 trainer.py:136] Epoch[756/1000] loss: 0.057305375442785376
I0427 10:43:41.900438 11084 trainer.py:136] Epoch[757/1000] loss: 0.05711189197266803
I0427 10:43:44.120959 11084 trainer.py:136] Epoch[758/1000] loss: 0.05913400978726499
I0427 10:43:46.365437 11084 trainer.py:136] Epoch[759/1000] loss: 0.05788774021408137
I0427 10:43:48.566816 11084 trainer.py:136] Epoch[760/1000] loss: 0.05731349504169296
I0427 10:43:50.796520 11084 trainer.py:136] Epoch[761/1000] loss: 0.057540639796677756
I0427 10:43:53.052390 11084 trainer.py:136] Epoch[762/1000] loss: 0.05740594447535627
I0427 10:43:55.384574 11084 trainer.py:136] Epoch[763/1000] loss: 0.05687976146445555
I0427 10:43:57.534077 11084 trainer.py:136] Epoch[764/1000] loss: 0.058642198276870394
I0427 10:43:59.731814 11084 trainer.py:136] Epoch[765/1000] loss: 0.05681250310119461
I0427 10:44:01.962569 11084 trainer.py:136] Epoch[766/1000] loss: 0.05586574599146843
I0427 10:44:04.172320 11084 trainer.py:136] Epoch[767/1000] loss: 0.05802804801393958
I0427 10:44:06.380043 11084 trainer.py:136] Epoch[768/1000] loss: 0.05696728277732344
I0427 10:44:08.620626 11084 trainer.py:136] Epoch[769/1000] loss: 0.05725470623549293
I0427 10:44:10.846326 11084 trainer.py:136] Epoch[770/1000] loss: 0.05722389589337742
I0427 10:44:12.988346 11084 trainer.py:136] Epoch[771/1000] loss: 0.05766232925302842
I0427 10:44:15.182223 11084 trainer.py:136] Epoch[772/1000] loss: 0.05419474358067793
I0427 10:44:17.462851 11084 trainer.py:136] Epoch[773/1000] loss: 0.05838013199322364
I0427 10:44:19.643524 11084 trainer.py:136] Epoch[774/1000] loss: 0.056737391168580335
I0427 10:44:21.860091 11084 trainer.py:136] Epoch[775/1000] loss: 0.05730385201818803
I0427 10:44:24.082294 11084 trainer.py:136] Epoch[776/1000] loss: 0.05794434753410956
I0427 10:44:26.343830 11084 trainer.py:136] Epoch[777/1000] loss: 0.05926439757732784
I0427 10:44:28.473349 11084 trainer.py:136] Epoch[778/1000] loss: 0.05612817209433107
I0427 10:44:30.676435 11084 trainer.py:136] Epoch[779/1000] loss: 0.05691572191084132
I0427 10:44:32.944030 11084 trainer.py:136] Epoch[780/1000] loss: 0.05585465361090267
I0427 10:44:35.214556 11084 trainer.py:136] Epoch[781/1000] loss: 0.056366939974181796
I0427 10:44:37.539687 11084 trainer.py:136] Epoch[782/1000] loss: 0.055721045197809446
I0427 10:44:39.837129 11084 trainer.py:136] Epoch[783/1000] loss: 0.0579592364237589
I0427 10:44:42.150104 11084 trainer.py:136] Epoch[784/1000] loss: 0.05802688440855812
I0427 10:44:44.411093 11084 trainer.py:136] Epoch[785/1000] loss: 0.05580293409088079
I0427 10:44:46.746631 11084 trainer.py:136] Epoch[786/1000] loss: 0.056358705986948573
I0427 10:44:48.893225 11084 trainer.py:136] Epoch[787/1000] loss: 0.05779795830740648
I0427 10:44:51.146821 11084 trainer.py:136] Epoch[788/1000] loss: 0.05726365394452039
I0427 10:44:53.360545 11084 trainer.py:136] Epoch[789/1000] loss: 0.05592390631928163
I0427 10:44:55.529184 11084 trainer.py:136] Epoch[790/1000] loss: 0.05622056236161905
I0427 10:44:57.840881 11084 trainer.py:136] Epoch[791/1000] loss: 0.05539732601712732
I0427 10:45:00.092477 11084 trainer.py:136] Epoch[792/1000] loss: 0.059606799307991475
I0427 10:45:02.265403 11084 trainer.py:136] Epoch[793/1000] loss: 0.05746525569873698
I0427 10:45:04.489867 11084 trainer.py:136] Epoch[794/1000] loss: 0.05702116603360457
I0427 10:45:06.624391 11084 trainer.py:136] Epoch[795/1000] loss: 0.05606997210313292
I0427 10:45:08.787412 11084 trainer.py:136] Epoch[796/1000] loss: 0.05877153224804822
I0427 10:45:11.028809 11084 trainer.py:136] Epoch[797/1000] loss: 0.0568716721061398
I0427 10:45:13.230575 11084 trainer.py:136] Epoch[798/1000] loss: 0.05604890624389929
I0427 10:45:15.354643 11084 trainer.py:136] Epoch[799/1000] loss: 0.05586847903973916
I0427 10:45:15.498719 11084 trainer.py:142] Test: [{'precision': 0.13806970509383387, 'recall': 0.3259287970173478, 'hit_ratio': 0.8879356568364611, 'ndcg': 0.30946240910459577}]
I0427 10:45:17.739398 11084 trainer.py:136] Epoch[800/1000] loss: 0.057909364209455604
I0427 10:45:19.938213 11084 trainer.py:136] Epoch[801/1000] loss: 0.05758522976847256
I0427 10:45:22.071275 11084 trainer.py:136] Epoch[802/1000] loss: 0.05577929405605092
I0427 10:45:24.182357 11084 trainer.py:136] Epoch[803/1000] loss: 0.05582185221068999
I0427 10:45:26.380015 11084 trainer.py:136] Epoch[804/1000] loss: 0.054676431066849655
I0427 10:45:28.629459 11084 trainer.py:136] Epoch[805/1000] loss: 0.05712525217848666
I0427 10:45:30.879716 11084 trainer.py:136] Epoch[806/1000] loss: 0.05495235718348447
I0427 10:45:33.125555 11084 trainer.py:136] Epoch[807/1000] loss: 0.05768379240351565
I0427 10:45:35.444592 11084 trainer.py:136] Epoch[808/1000] loss: 0.057691607624292374
I0427 10:45:37.615934 11084 trainer.py:136] Epoch[809/1000] loss: 0.055263610447154325
I0427 10:45:39.838609 11084 trainer.py:136] Epoch[810/1000] loss: 0.055757385842940384
I0427 10:45:42.113181 11084 trainer.py:136] Epoch[811/1000] loss: 0.056719990118461495
I0427 10:45:44.250153 11084 trainer.py:136] Epoch[812/1000] loss: 0.05569812282919884
I0427 10:45:46.398116 11084 trainer.py:136] Epoch[813/1000] loss: 0.05595350659945432
I0427 10:45:48.596475 11084 trainer.py:136] Epoch[814/1000] loss: 0.05649423533502747
I0427 10:45:50.824186 11084 trainer.py:136] Epoch[815/1000] loss: 0.05562581735498765
I0427 10:45:53.047842 11084 trainer.py:136] Epoch[816/1000] loss: 0.05431319970418425
I0427 10:45:55.245719 11084 trainer.py:136] Epoch[817/1000] loss: 0.05541840962627355
I0427 10:45:57.462898 11084 trainer.py:136] Epoch[818/1000] loss: 0.05506091674461084
I0427 10:45:59.700556 11084 trainer.py:136] Epoch[819/1000] loss: 0.05502853717874078
I0427 10:46:01.916221 11084 trainer.py:136] Epoch[820/1000] loss: 0.05615939287578359
I0427 10:46:04.107913 11084 trainer.py:136] Epoch[821/1000] loss: 0.05631203533095472
I0427 10:46:06.244181 11084 trainer.py:136] Epoch[822/1000] loss: 0.05435029296752285
I0427 10:46:08.572160 11084 trainer.py:136] Epoch[823/1000] loss: 0.05724657195455888
I0427 10:46:10.755020 11084 trainer.py:136] Epoch[824/1000] loss: 0.05642299375989858
I0427 10:46:12.962667 11084 trainer.py:136] Epoch[825/1000] loss: 0.0556151064879754
I0427 10:46:15.201297 11084 trainer.py:136] Epoch[826/1000] loss: 0.057293130632709056
I0427 10:46:17.515281 11084 trainer.py:136] Epoch[827/1000] loss: 0.05623809445430251
I0427 10:46:19.706366 11084 trainer.py:136] Epoch[828/1000] loss: 0.05789712641169043
I0427 10:46:22.011419 11084 trainer.py:136] Epoch[829/1000] loss: 0.05500865048345398
I0427 10:46:24.275069 11084 trainer.py:136] Epoch[830/1000] loss: 0.05629541111343047
I0427 10:46:26.479686 11084 trainer.py:136] Epoch[831/1000] loss: 0.05702162555911962
I0427 10:46:28.748802 11084 trainer.py:136] Epoch[832/1000] loss: 0.05535947750596439
I0427 10:46:31.013353 11084 trainer.py:136] Epoch[833/1000] loss: 0.05612571055398268
I0427 10:46:33.242133 11084 trainer.py:136] Epoch[834/1000] loss: 0.05674757172956186
I0427 10:46:35.478617 11084 trainer.py:136] Epoch[835/1000] loss: 0.05669495266150026
I0427 10:46:37.672427 11084 trainer.py:136] Epoch[836/1000] loss: 0.05588460450663286
I0427 10:46:39.901122 11084 trainer.py:136] Epoch[837/1000] loss: 0.05544999658184893
I0427 10:46:42.162380 11084 trainer.py:136] Epoch[838/1000] loss: 0.054860702551463074
I0427 10:46:44.405990 11084 trainer.py:136] Epoch[839/1000] loss: 0.056843077873482424
I0427 10:46:46.660123 11084 trainer.py:136] Epoch[840/1000] loss: 0.05787376270574682
I0427 10:46:48.840670 11084 trainer.py:136] Epoch[841/1000] loss: 0.054944158696076446
I0427 10:46:50.978104 11084 trainer.py:136] Epoch[842/1000] loss: 0.055179664755568784
I0427 10:46:53.243982 11084 trainer.py:136] Epoch[843/1000] loss: 0.05481384300133761
I0427 10:46:55.485055 11084 trainer.py:136] Epoch[844/1000] loss: 0.05702543499715188
I0427 10:46:57.617033 11084 trainer.py:136] Epoch[845/1000] loss: 0.05600402153590146
I0427 10:46:59.926765 11084 trainer.py:136] Epoch[846/1000] loss: 0.0562530773527482
I0427 10:47:02.255237 11084 trainer.py:136] Epoch[847/1000] loss: 0.056139450082007575
I0427 10:47:04.452280 11084 trainer.py:136] Epoch[848/1000] loss: 0.05628199875354767
I0427 10:47:06.570900 11084 trainer.py:136] Epoch[849/1000] loss: 0.05828438502024202
I0427 10:47:06.717410 11084 trainer.py:142] Test: [{'precision': 0.13919571045576412, 'recall': 0.32899420591149037, 'hit_ratio': 0.8900804289544236, 'ndcg': 0.31165266325510493}]
I0427 10:47:08.998992 11084 trainer.py:136] Epoch[850/1000] loss: 0.0573330894112587
I0427 10:47:11.246608 11084 trainer.py:136] Epoch[851/1000] loss: 0.05454528616631732
I0427 10:47:13.491971 11084 trainer.py:136] Epoch[852/1000] loss: 0.055212880977812934
I0427 10:47:15.726192 11084 trainer.py:136] Epoch[853/1000] loss: 0.056167784640017676
I0427 10:47:17.931460 11084 trainer.py:136] Epoch[854/1000] loss: 0.05512719667133163
I0427 10:47:20.151462 11084 trainer.py:136] Epoch[855/1000] loss: 0.053962635643341965
I0427 10:47:22.374174 11084 trainer.py:136] Epoch[856/1000] loss: 0.057048575404812306
I0427 10:47:24.549176 11084 trainer.py:136] Epoch[857/1000] loss: 0.054549978279015594
I0427 10:47:26.644343 11084 trainer.py:136] Epoch[858/1000] loss: 0.05623042473898215
I0427 10:47:28.894748 11084 trainer.py:136] Epoch[859/1000] loss: 0.05543733322445084
I0427 10:47:31.162342 11084 trainer.py:136] Epoch[860/1000] loss: 0.05617605763323167
I0427 10:47:33.366976 11084 trainer.py:136] Epoch[861/1000] loss: 0.05602778823060148
I0427 10:47:35.625086 11084 trainer.py:136] Epoch[862/1000] loss: 0.057987788582549375
I0427 10:47:37.938396 11084 trainer.py:136] Epoch[863/1000] loss: 0.056389743571772295
I0427 10:47:40.138214 11084 trainer.py:136] Epoch[864/1000] loss: 0.053441654014236784
I0427 10:47:42.378768 11084 trainer.py:136] Epoch[865/1000] loss: 0.055280779433601046
I0427 10:47:44.668988 11084 trainer.py:136] Epoch[866/1000] loss: 0.0565542591845288
I0427 10:47:46.951486 11084 trainer.py:136] Epoch[867/1000] loss: 0.055972420993973225
I0427 10:47:49.109381 11084 trainer.py:136] Epoch[868/1000] loss: 0.054857038618887174
I0427 10:47:51.414598 11084 trainer.py:136] Epoch[869/1000] loss: 0.054706527029766756
I0427 10:47:53.604533 11084 trainer.py:136] Epoch[870/1000] loss: 0.054574703468995935
I0427 10:47:55.782718 11084 trainer.py:136] Epoch[871/1000] loss: 0.05477673209765378
I0427 10:47:58.043904 11084 trainer.py:136] Epoch[872/1000] loss: 0.056747969459084904
I0427 10:48:00.318220 11084 trainer.py:136] Epoch[873/1000] loss: 0.05995867050745908
I0427 10:48:02.553447 11084 trainer.py:136] Epoch[874/1000] loss: 0.056581922752015734
I0427 10:48:04.839927 11084 trainer.py:136] Epoch[875/1000] loss: 0.05448675791130347
I0427 10:48:07.083151 11084 trainer.py:136] Epoch[876/1000] loss: 0.05443086584701257
I0427 10:48:09.265644 11084 trainer.py:136] Epoch[877/1000] loss: 0.05674529491978533
I0427 10:48:11.388282 11084 trainer.py:136] Epoch[878/1000] loss: 0.055786735432989454
I0427 10:48:13.705254 11084 trainer.py:136] Epoch[879/1000] loss: 0.055250766522744126
I0427 10:48:15.921538 11084 trainer.py:136] Epoch[880/1000] loss: 0.05301420785048429
I0427 10:48:18.266068 11084 trainer.py:136] Epoch[881/1000] loss: 0.055803752997342276
I0427 10:48:20.400076 11084 trainer.py:136] Epoch[882/1000] loss: 0.05515783981365316
I0427 10:48:22.575407 11084 trainer.py:136] Epoch[883/1000] loss: 0.05515889428994235
I0427 10:48:24.851086 11084 trainer.py:136] Epoch[884/1000] loss: 0.05647254012086812
I0427 10:48:27.033293 11084 trainer.py:136] Epoch[885/1000] loss: 0.053744428517187345
I0427 10:48:29.322156 11084 trainer.py:136] Epoch[886/1000] loss: 0.05519379302859306
I0427 10:48:31.630346 11084 trainer.py:136] Epoch[887/1000] loss: 0.05451946048175588
I0427 10:48:33.862656 11084 trainer.py:136] Epoch[888/1000] loss: 0.05453129463336047
I0427 10:48:36.173087 11084 trainer.py:136] Epoch[889/1000] loss: 0.05625619498245856
I0427 10:48:38.358906 11084 trainer.py:136] Epoch[890/1000] loss: 0.054828181862831116
I0427 10:48:40.470563 11084 trainer.py:136] Epoch[891/1000] loss: 0.05476328686756246
I0427 10:48:42.590643 11084 trainer.py:136] Epoch[892/1000] loss: 0.05244650801315027
I0427 10:48:44.710714 11084 trainer.py:136] Epoch[893/1000] loss: 0.055347978630486655
I0427 10:48:46.888606 11084 trainer.py:136] Epoch[894/1000] loss: 0.055545941214351094
I0427 10:48:49.065534 11084 trainer.py:136] Epoch[895/1000] loss: 0.05597798219498466
I0427 10:48:51.224244 11084 trainer.py:136] Epoch[896/1000] loss: 0.05539300380384221
I0427 10:48:53.399935 11084 trainer.py:136] Epoch[897/1000] loss: 0.0560103223166045
I0427 10:48:55.585856 11084 trainer.py:136] Epoch[898/1000] loss: 0.055425557800952124
I0427 10:48:57.785106 11084 trainer.py:136] Epoch[899/1000] loss: 0.05404135058907902
I0427 10:48:57.958526 11084 trainer.py:142] Test: [{'precision': 0.13890080428954427, 'recall': 0.327986782225467, 'hit_ratio': 0.8895442359249329, 'ndcg': 0.3108077324889945}]
I0427 10:49:00.226582 11084 trainer.py:136] Epoch[900/1000] loss: 0.05351370573043823
I0427 10:49:02.435032 11084 trainer.py:136] Epoch[901/1000] loss: 0.05402543045142118
I0427 10:49:04.697815 11084 trainer.py:136] Epoch[902/1000] loss: 0.05570000234772177
I0427 10:49:06.921532 11084 trainer.py:136] Epoch[903/1000] loss: 0.05436113739714903
I0427 10:49:09.122345 11084 trainer.py:136] Epoch[904/1000] loss: 0.05643298279713182
I0427 10:49:11.360067 11084 trainer.py:136] Epoch[905/1000] loss: 0.05386706551208215
I0427 10:49:13.550464 11084 trainer.py:136] Epoch[906/1000] loss: 0.05516159446800456
I0427 10:49:15.819994 11084 trainer.py:136] Epoch[907/1000] loss: 0.053433564655921036
I0427 10:49:17.999644 11084 trainer.py:136] Epoch[908/1000] loss: 0.05408513304941794
I0427 10:49:20.222365 11084 trainer.py:136] Epoch[909/1000] loss: 0.05505781116731027
I0427 10:49:22.458569 11084 trainer.py:136] Epoch[910/1000] loss: 0.055088322828797734
I0427 10:49:24.624032 11084 trainer.py:136] Epoch[911/1000] loss: 0.0526256618254325
I0427 10:49:26.841774 11084 trainer.py:136] Epoch[912/1000] loss: 0.05598213435972438
I0427 10:49:29.146243 11084 trainer.py:136] Epoch[913/1000] loss: 0.05419639760957045
I0427 10:49:31.272237 11084 trainer.py:136] Epoch[914/1000] loss: 0.05353650516446899
I0427 10:49:33.409784 11084 trainer.py:136] Epoch[915/1000] loss: 0.053918364293435043
I0427 10:49:35.566285 11084 trainer.py:136] Epoch[916/1000] loss: 0.05679853961748235
I0427 10:49:37.671396 11084 trainer.py:136] Epoch[917/1000] loss: 0.053831155028413326
I0427 10:49:39.857269 11084 trainer.py:136] Epoch[918/1000] loss: 0.05343062518274083
I0427 10:49:42.201698 11084 trainer.py:136] Epoch[919/1000] loss: 0.05328627390896573
I0427 10:49:44.291247 11084 trainer.py:136] Epoch[920/1000] loss: 0.05684122202150962
I0427 10:49:46.517577 11084 trainer.py:136] Epoch[921/1000] loss: 0.05360174967962153
I0427 10:49:48.754258 11084 trainer.py:136] Epoch[922/1000] loss: 0.053977917660685146
I0427 10:49:51.008804 11084 trainer.py:136] Epoch[923/1000] loss: 0.05502563123317326
I0427 10:49:53.153739 11084 trainer.py:136] Epoch[924/1000] loss: 0.05315785570179715
I0427 10:49:55.359527 11084 trainer.py:136] Epoch[925/1000] loss: 0.055780814412762135
I0427 10:49:57.579272 11084 trainer.py:136] Epoch[926/1000] loss: 0.057114638607291615
I0427 10:49:59.897913 11084 trainer.py:136] Epoch[927/1000] loss: 0.05320228395216605
I0427 10:50:02.066900 11084 trainer.py:136] Epoch[928/1000] loss: 0.05415624051409609
I0427 10:50:04.183546 11084 trainer.py:136] Epoch[929/1000] loss: 0.056469805976923776
I0427 10:50:06.406588 11084 trainer.py:136] Epoch[930/1000] loss: 0.05460301194997395
I0427 10:50:08.639375 11084 trainer.py:136] Epoch[931/1000] loss: 0.05544746579492793
I0427 10:50:10.760572 11084 trainer.py:136] Epoch[932/1000] loss: 0.05419568662696025
I0427 10:50:12.971369 11084 trainer.py:136] Epoch[933/1000] loss: 0.054536271621199214
I0427 10:50:15.157825 11084 trainer.py:136] Epoch[934/1000] loss: 0.05369256327257437
I0427 10:50:17.436421 11084 trainer.py:136] Epoch[935/1000] loss: 0.0551434667671428
I0427 10:50:19.653822 11084 trainer.py:136] Epoch[936/1000] loss: 0.056377487804959804
I0427 10:50:21.829653 11084 trainer.py:136] Epoch[937/1000] loss: 0.05451034031370107
I0427 10:50:23.966686 11084 trainer.py:136] Epoch[938/1000] loss: 0.05497857774881756
I0427 10:50:26.196426 11084 trainer.py:136] Epoch[939/1000] loss: 0.0555922822917209
I0427 10:50:28.713222 11084 trainer.py:136] Epoch[940/1000] loss: 0.05364277235725347
I0427 10:50:30.986814 11084 trainer.py:136] Epoch[941/1000] loss: 0.05391115914372837
I0427 10:50:33.244912 11084 trainer.py:136] Epoch[942/1000] loss: 0.054979710017933565
I0427 10:50:35.537011 11084 trainer.py:136] Epoch[943/1000] loss: 0.052151104764026755
I0427 10:50:37.764810 11084 trainer.py:136] Epoch[944/1000] loss: 0.05395228108939003
I0427 10:50:40.063889 11084 trainer.py:136] Epoch[945/1000] loss: 0.05231082286028301
I0427 10:50:42.287616 11084 trainer.py:136] Epoch[946/1000] loss: 0.05342606433174189
I0427 10:50:44.436620 11084 trainer.py:136] Epoch[947/1000] loss: 0.0551646108574727
I0427 10:50:46.675887 11084 trainer.py:136] Epoch[948/1000] loss: 0.054582178154412436
I0427 10:50:48.920581 11084 trainer.py:136] Epoch[949/1000] loss: 0.05333532962728949
I0427 10:50:49.073070 11084 trainer.py:142] Test: [{'precision': 0.13938337801608588, 'recall': 0.3292975657925983, 'hit_ratio': 0.8890080428954423, 'ndcg': 0.31189793582345343}]
I0427 10:50:51.468199 11084 trainer.py:136] Epoch[950/1000] loss: 0.05310208635295138
I0427 10:50:53.677550 11084 trainer.py:136] Epoch[951/1000] loss: 0.05343606936580995
I0427 10:50:55.910222 11084 trainer.py:136] Epoch[952/1000] loss: 0.054667788831626665
I0427 10:50:58.167728 11084 trainer.py:136] Epoch[953/1000] loss: 0.05562319036792306
I0427 10:51:00.581689 11084 trainer.py:136] Epoch[954/1000] loss: 0.05616619394106023
I0427 10:51:02.786420 11084 trainer.py:136] Epoch[955/1000] loss: 0.05448733620783862
I0427 10:51:05.163032 11084 trainer.py:136] Epoch[956/1000] loss: 0.05268429044414969
I0427 10:51:07.425544 11084 trainer.py:136] Epoch[957/1000] loss: 0.05475451030275401
I0427 10:51:09.723306 11084 trainer.py:136] Epoch[958/1000] loss: 0.05620152875781059
I0427 10:51:11.969923 11084 trainer.py:136] Epoch[959/1000] loss: 0.053986014688716215
I0427 10:51:14.219044 11084 trainer.py:136] Epoch[960/1000] loss: 0.05586521239841685
I0427 10:51:16.464697 11084 trainer.py:136] Epoch[961/1000] loss: 0.05415647389257655
I0427 10:51:18.685025 11084 trainer.py:136] Epoch[962/1000] loss: 0.05250818150884965
I0427 10:51:20.860927 11084 trainer.py:136] Epoch[963/1000] loss: 0.05393637848251006
I0427 10:51:22.922416 11084 trainer.py:136] Epoch[964/1000] loss: 0.053381891373325795
I0427 10:51:25.037534 11084 trainer.py:136] Epoch[965/1000] loss: 0.05387665375190623
I0427 10:51:27.164877 11084 trainer.py:136] Epoch[966/1000] loss: 0.05534610064590678
I0427 10:51:29.492849 11084 trainer.py:136] Epoch[967/1000] loss: 0.0543148035512251
I0427 10:51:31.612134 11084 trainer.py:136] Epoch[968/1000] loss: 0.0525728764341158
I0427 10:51:33.756139 11084 trainer.py:136] Epoch[969/1000] loss: 0.05504909924724523
I0427 10:51:36.035232 11084 trainer.py:136] Epoch[970/1000] loss: 0.05461269836215412
I0427 10:51:38.250016 11084 trainer.py:136] Epoch[971/1000] loss: 0.05371461479979403
I0427 10:51:40.446801 11084 trainer.py:136] Epoch[972/1000] loss: 0.053216515656779796
I0427 10:51:42.596328 11084 trainer.py:136] Epoch[973/1000] loss: 0.055177603355225396
I0427 10:51:44.900727 11084 trainer.py:136] Epoch[974/1000] loss: 0.054456705994465775
I0427 10:51:47.036297 11084 trainer.py:136] Epoch[975/1000] loss: 0.05295976799200563
I0427 10:51:49.315743 11084 trainer.py:136] Epoch[976/1000] loss: 0.052340317955788446
I0427 10:51:51.469897 11084 trainer.py:136] Epoch[977/1000] loss: 0.05173842269269859
I0427 10:51:53.647505 11084 trainer.py:136] Epoch[978/1000] loss: 0.05343694502816481
I0427 10:51:55.775063 11084 trainer.py:136] Epoch[979/1000] loss: 0.05475621254128568
I0427 10:51:57.969857 11084 trainer.py:136] Epoch[980/1000] loss: 0.05229895079837126
I0427 10:52:00.118810 11084 trainer.py:136] Epoch[981/1000] loss: 0.053032297202769446
I0427 10:52:02.201004 11084 trainer.py:136] Epoch[982/1000] loss: 0.05239627072039772
I0427 10:52:04.392410 11084 trainer.py:136] Epoch[983/1000] loss: 0.05414692531613743
I0427 10:52:06.545477 11084 trainer.py:136] Epoch[984/1000] loss: 0.05450325262020616
I0427 10:52:08.713435 11084 trainer.py:136] Epoch[985/1000] loss: 0.053057747290414924
I0427 10:52:10.862334 11084 trainer.py:136] Epoch[986/1000] loss: 0.0537090910708203
I0427 10:52:12.927170 11084 trainer.py:136] Epoch[987/1000] loss: 0.05350462566403782
I0427 10:52:15.270683 11084 trainer.py:136] Epoch[988/1000] loss: 0.053475191926254946
I0427 10:52:17.470061 11084 trainer.py:136] Epoch[989/1000] loss: 0.05255912222406443
I0427 10:52:19.597360 11084 trainer.py:136] Epoch[990/1000] loss: 0.05556346015895114
I0427 10:52:21.724414 11084 trainer.py:136] Epoch[991/1000] loss: 0.053119521807221806
I0427 10:52:23.875976 11084 trainer.py:136] Epoch[992/1000] loss: 0.0524590493125074
I0427 10:52:26.093742 11084 trainer.py:136] Epoch[993/1000] loss: 0.05407451728687567
I0427 10:52:28.266558 11084 trainer.py:136] Epoch[994/1000] loss: 0.053950637140694785
I0427 10:52:30.393325 11084 trainer.py:136] Epoch[995/1000] loss: 0.053393468699034524
I0427 10:52:32.507718 11084 trainer.py:136] Epoch[996/1000] loss: 0.05485552176833153
I0427 10:52:34.611850 11084 trainer.py:136] Epoch[997/1000] loss: 0.05341225446147077
I0427 10:52:36.880722 11084 trainer.py:136] Epoch[998/1000] loss: 0.05337302737376269
I0427 10:52:38.932797 11084 trainer.py:136] Epoch[999/1000] loss: 0.05265353159869418
I0427 10:52:39.088276 11084 trainer.py:142] Test: [{'precision': 0.13965147453083115, 'recall': 0.33001015250147886, 'hit_ratio': 0.8916890080428954, 'ndcg': 0.3125267270937071}]
