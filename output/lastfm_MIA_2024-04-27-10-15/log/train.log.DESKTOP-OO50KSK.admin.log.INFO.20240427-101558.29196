I0427 10:16:00.498683 19076 trainer.py:118] Test: [{'precision': 0.026782841823056278, 'recall': 0.058440257284288186, 'hit_ratio': 0.2949061662198391, 'ndcg': 0.05269272512775716}]
I0427 10:16:02.672504 19076 trainer.py:136] Epoch[0/1000] loss: 0.6744602819283804
I0427 10:16:04.752871 19076 trainer.py:136] Epoch[1/1000] loss: 0.5900135437647501
I0427 10:16:06.873821 19076 trainer.py:136] Epoch[2/1000] loss: 0.54689888159434
I0427 10:16:08.969613 19076 trainer.py:136] Epoch[3/1000] loss: 0.5184974471728007
I0427 10:16:11.260972 19076 trainer.py:136] Epoch[4/1000] loss: 0.4980587561925252
I0427 10:16:13.590503 19076 trainer.py:136] Epoch[5/1000] loss: 0.4848786989847819
I0427 10:16:15.774342 19076 trainer.py:136] Epoch[6/1000] loss: 0.4748886028925578
I0427 10:16:17.913333 19076 trainer.py:136] Epoch[7/1000] loss: 0.46289599935213727
I0427 10:16:20.093258 19076 trainer.py:136] Epoch[8/1000] loss: 0.4570991098880768
I0427 10:16:22.212314 19076 trainer.py:136] Epoch[9/1000] loss: 0.44780775407950085
I0427 10:16:24.704684 19076 trainer.py:136] Epoch[10/1000] loss: 0.4384462932745616
I0427 10:16:26.782875 19076 trainer.py:136] Epoch[11/1000] loss: 0.437109371026357
I0427 10:16:28.926344 19076 trainer.py:136] Epoch[12/1000] loss: 0.4265955885251363
I0427 10:16:30.978942 19076 trainer.py:136] Epoch[13/1000] loss: 0.42004166046778363
I0427 10:16:33.206573 19076 trainer.py:136] Epoch[14/1000] loss: 0.4188055793444316
I0427 10:16:35.442361 19076 trainer.py:136] Epoch[15/1000] loss: 0.41124628980954486
I0427 10:16:37.661614 19076 trainer.py:136] Epoch[16/1000] loss: 0.40430497129758197
I0427 10:16:39.731867 19076 trainer.py:136] Epoch[17/1000] loss: 0.4016801317532857
I0427 10:16:41.985532 19076 trainer.py:136] Epoch[18/1000] loss: 0.3945288509130478
I0427 10:16:44.076998 19076 trainer.py:136] Epoch[19/1000] loss: 0.3876325289408366
I0427 10:16:46.240618 19076 trainer.py:136] Epoch[20/1000] loss: 0.38418303430080414
I0427 10:16:48.251106 19076 trainer.py:136] Epoch[21/1000] loss: 0.38043659428755444
I0427 10:16:50.378125 19076 trainer.py:136] Epoch[22/1000] loss: 0.37266799807548523
I0427 10:16:52.463896 19076 trainer.py:136] Epoch[23/1000] loss: 0.37029945850372314
I0427 10:16:54.897911 19076 trainer.py:136] Epoch[24/1000] loss: 0.360758180419604
I0427 10:16:57.008002 19076 trainer.py:136] Epoch[25/1000] loss: 0.36458422740300495
I0427 10:16:59.242634 19076 trainer.py:136] Epoch[26/1000] loss: 0.35584798951943714
I0427 10:17:01.319249 19076 trainer.py:136] Epoch[27/1000] loss: 0.35051784416039783
I0427 10:17:03.564527 19076 trainer.py:136] Epoch[28/1000] loss: 0.3447356124718984
I0427 10:17:05.710393 19076 trainer.py:136] Epoch[29/1000] loss: 0.3412221471468608
I0427 10:17:07.769985 19076 trainer.py:136] Epoch[30/1000] loss: 0.3320644944906235
I0427 10:17:09.874103 19076 trainer.py:136] Epoch[31/1000] loss: 0.3380834509929021
I0427 10:17:12.022263 19076 trainer.py:136] Epoch[32/1000] loss: 0.3271445681651433
I0427 10:17:14.172195 19076 trainer.py:136] Epoch[33/1000] loss: 0.3266933411359787
I0427 10:17:16.302152 19076 trainer.py:136] Epoch[34/1000] loss: 0.32311418652534485
I0427 10:17:18.527438 19076 trainer.py:136] Epoch[35/1000] loss: 0.3178288092215856
I0427 10:17:20.626569 19076 trainer.py:136] Epoch[36/1000] loss: 0.30775466561317444
I0427 10:17:22.793473 19076 trainer.py:136] Epoch[37/1000] loss: 0.3098020752271016
I0427 10:17:24.924574 19076 trainer.py:136] Epoch[38/1000] loss: 0.3059310217698415
I0427 10:17:27.171600 19076 trainer.py:136] Epoch[39/1000] loss: 0.30248317619164783
I0427 10:17:29.452638 19076 trainer.py:136] Epoch[40/1000] loss: 0.2981177568435669
I0427 10:17:31.625584 19076 trainer.py:136] Epoch[41/1000] loss: 0.29546744128068286
I0427 10:17:33.663296 19076 trainer.py:136] Epoch[42/1000] loss: 0.28771963715553284
I0427 10:17:35.802823 19076 trainer.py:136] Epoch[43/1000] loss: 0.2913895746072133
I0427 10:17:37.869533 19076 trainer.py:136] Epoch[44/1000] loss: 0.2826916078726451
I0427 10:17:40.008540 19076 trainer.py:136] Epoch[45/1000] loss: 0.28646179536978406
I0427 10:17:42.130562 19076 trainer.py:136] Epoch[46/1000] loss: 0.28405096133550006
I0427 10:17:44.292286 19076 trainer.py:136] Epoch[47/1000] loss: 0.27574995656808216
I0427 10:17:46.498941 19076 trainer.py:136] Epoch[48/1000] loss: 0.27612373729546863
I0427 10:17:48.699521 19076 trainer.py:136] Epoch[49/1000] loss: 0.2715192635854085
I0427 10:17:48.887891 19076 trainer.py:142] Test: [{'precision': 0.1036729222520108, 'recall': 0.24229528860107646, 'hit_ratio': 0.7941018766756032, 'ndcg': 0.2284165919974782}]
I0427 10:17:51.030676 19076 trainer.py:136] Epoch[50/1000] loss: 0.26705344021320343
I0427 10:17:53.267894 19076 trainer.py:136] Epoch[51/1000] loss: 0.2644331951936086
I0427 10:17:55.400115 19076 trainer.py:136] Epoch[52/1000] loss: 0.26461417973041534
I0427 10:17:57.671191 19076 trainer.py:136] Epoch[53/1000] loss: 0.25949673851331073
I0427 10:17:59.863013 19076 trainer.py:136] Epoch[54/1000] loss: 0.2602628916501999
I0427 10:18:02.125336 19076 trainer.py:136] Epoch[55/1000] loss: 0.25864346077044803
I0427 10:18:04.234339 19076 trainer.py:136] Epoch[56/1000] loss: 0.2561437636613846
I0427 10:18:06.377302 19076 trainer.py:136] Epoch[57/1000] loss: 0.25453394403060275
I0427 10:18:08.516936 19076 trainer.py:136] Epoch[58/1000] loss: 0.25231264034907025
I0427 10:18:10.636315 19076 trainer.py:136] Epoch[59/1000] loss: 0.24790544311205545
I0427 10:18:12.862307 19076 trainer.py:136] Epoch[60/1000] loss: 0.24364284425973892
I0427 10:18:14.991445 19076 trainer.py:136] Epoch[61/1000] loss: 0.2436674932638804
I0427 10:18:17.079496 19076 trainer.py:136] Epoch[62/1000] loss: 0.24158856521050134
I0427 10:18:19.189133 19076 trainer.py:136] Epoch[63/1000] loss: 0.23919280618429184
I0427 10:18:21.275293 19076 trainer.py:136] Epoch[64/1000] loss: 0.23917466898759207
I0427 10:18:23.288705 19076 trainer.py:136] Epoch[65/1000] loss: 0.23513484497865042
I0427 10:18:25.449615 19076 trainer.py:136] Epoch[66/1000] loss: 0.23556152979532877
I0427 10:18:27.520495 19076 trainer.py:136] Epoch[67/1000] loss: 0.2332096869746844
I0427 10:18:29.656399 19076 trainer.py:136] Epoch[68/1000] loss: 0.23318112889925638
I0427 10:18:31.798591 19076 trainer.py:136] Epoch[69/1000] loss: 0.2297667091091474
I0427 10:18:33.962247 19076 trainer.py:136] Epoch[70/1000] loss: 0.22847426186005274
I0427 10:18:36.065312 19076 trainer.py:136] Epoch[71/1000] loss: 0.2299608662724495
I0427 10:18:38.127556 19076 trainer.py:136] Epoch[72/1000] loss: 0.2246221825480461
I0427 10:18:40.279513 19076 trainer.py:136] Epoch[73/1000] loss: 0.22308815022309622
I0427 10:18:42.406781 19076 trainer.py:136] Epoch[74/1000] loss: 0.2200476105014483
I0427 10:18:44.426187 19076 trainer.py:136] Epoch[75/1000] loss: 0.22067038218180338
I0427 10:18:46.602600 19076 trainer.py:136] Epoch[76/1000] loss: 0.21624206751585007
I0427 10:18:48.680782 19076 trainer.py:136] Epoch[77/1000] loss: 0.21814076602458954
I0427 10:18:50.845531 19076 trainer.py:136] Epoch[78/1000] loss: 0.213696817557017
I0427 10:18:52.926503 19076 trainer.py:136] Epoch[79/1000] loss: 0.2154954398671786
I0427 10:18:54.978840 19076 trainer.py:136] Epoch[80/1000] loss: 0.21132935335238776
I0427 10:18:57.127871 19076 trainer.py:136] Epoch[81/1000] loss: 0.20984392364819845
I0427 10:18:59.264892 19076 trainer.py:136] Epoch[82/1000] loss: 0.20887601375579834
I0427 10:19:01.341073 19076 trainer.py:136] Epoch[83/1000] loss: 0.20747412741184235
I0427 10:19:03.474610 19076 trainer.py:136] Epoch[84/1000] loss: 0.20432392259438834
I0427 10:19:05.522944 19076 trainer.py:136] Epoch[85/1000] loss: 0.20237225045760474
I0427 10:19:07.637007 19076 trainer.py:136] Epoch[86/1000] loss: 0.2058039034406344
I0427 10:19:09.820827 19076 trainer.py:136] Epoch[87/1000] loss: 0.20116571833690008
I0427 10:19:11.963961 19076 trainer.py:136] Epoch[88/1000] loss: 0.1994318589568138
I0427 10:19:14.117915 19076 trainer.py:136] Epoch[89/1000] loss: 0.20118725299835205
I0427 10:19:16.422909 19076 trainer.py:136] Epoch[90/1000] loss: 0.19936115046342215
I0427 10:19:18.490132 19076 trainer.py:136] Epoch[91/1000] loss: 0.19583859543005624
I0427 10:19:20.623129 19076 trainer.py:136] Epoch[92/1000] loss: 0.19694925844669342
I0427 10:19:22.713329 19076 trainer.py:136] Epoch[93/1000] loss: 0.19548017283280691
I0427 10:19:24.789560 19076 trainer.py:136] Epoch[94/1000] loss: 0.1933592880765597
I0427 10:19:26.957457 19076 trainer.py:136] Epoch[95/1000] loss: 0.19030361622571945
I0427 10:19:29.046336 19076 trainer.py:136] Epoch[96/1000] loss: 0.19260805348555246
I0427 10:19:31.228797 19076 trainer.py:136] Epoch[97/1000] loss: 0.194380392630895
I0427 10:19:33.361791 19076 trainer.py:136] Epoch[98/1000] loss: 0.1894200543562571
I0427 10:19:35.621655 19076 trainer.py:136] Epoch[99/1000] loss: 0.19055878619352976
I0427 10:19:35.782118 19076 trainer.py:142] Test: [{'precision': 0.1137533512064344, 'recall': 0.2670505959809699, 'hit_ratio': 0.839142091152815, 'ndcg': 0.2500179500424248}]
I0427 10:19:37.898637 19076 trainer.py:136] Epoch[100/1000] loss: 0.1900439312060674
I0427 10:19:40.016853 19076 trainer.py:136] Epoch[101/1000] loss: 0.1895081326365471
I0427 10:19:42.111213 19076 trainer.py:136] Epoch[102/1000] loss: 0.18449017902215323
I0427 10:19:44.333456 19076 trainer.py:136] Epoch[103/1000] loss: 0.18542191634575525
I0427 10:19:46.439584 19076 trainer.py:136] Epoch[104/1000] loss: 0.184121643503507
I0427 10:19:48.607952 19076 trainer.py:136] Epoch[105/1000] loss: 0.18475897858540216
I0427 10:19:50.665225 19076 trainer.py:136] Epoch[106/1000] loss: 0.18673126896222433
I0427 10:19:52.900856 19076 trainer.py:136] Epoch[107/1000] loss: 0.18387105564276376
I0427 10:19:55.008897 19076 trainer.py:136] Epoch[108/1000] loss: 0.17950416604677835
I0427 10:19:57.101235 19076 trainer.py:136] Epoch[109/1000] loss: 0.18037337064743042
I0427 10:19:59.298302 19076 trainer.py:136] Epoch[110/1000] loss: 0.18019171307484308
I0427 10:20:01.447789 19076 trainer.py:136] Epoch[111/1000] loss: 0.17601239184538522
I0427 10:20:03.536280 19076 trainer.py:136] Epoch[112/1000] loss: 0.17729347944259644
I0427 10:20:05.764588 19076 trainer.py:136] Epoch[113/1000] loss: 0.1749887689948082
I0427 10:20:07.731523 19076 trainer.py:136] Epoch[114/1000] loss: 0.17407184342543283
I0427 10:20:09.841425 19076 trainer.py:136] Epoch[115/1000] loss: 0.17280860245227814
I0427 10:20:11.860838 19076 trainer.py:136] Epoch[116/1000] loss: 0.17165407290061316
I0427 10:20:13.943017 19076 trainer.py:136] Epoch[117/1000] loss: 0.1704480176170667
I0427 10:20:15.974455 19076 trainer.py:136] Epoch[118/1000] loss: 0.16941208144028982
I0427 10:20:18.023827 19076 trainer.py:136] Epoch[119/1000] loss: 0.1696675568819046
I0427 10:20:20.311135 19076 trainer.py:136] Epoch[120/1000] loss: 0.17155821124712625
I0427 10:20:22.369935 19076 trainer.py:136] Epoch[121/1000] loss: 0.16788226614395776
I0427 10:20:24.563345 19076 trainer.py:136] Epoch[122/1000] loss: 0.17082655926545462
I0427 10:20:26.643573 19076 trainer.py:136] Epoch[123/1000] loss: 0.16877949237823486
I0427 10:20:28.761452 19076 trainer.py:136] Epoch[124/1000] loss: 0.16767890254656473
I0427 10:20:30.813623 19076 trainer.py:136] Epoch[125/1000] loss: 0.1648786241809527
I0427 10:20:32.973784 19076 trainer.py:136] Epoch[126/1000] loss: 0.1669099529584249
I0427 10:20:35.052298 19076 trainer.py:136] Epoch[127/1000] loss: 0.16345961391925812
I0427 10:20:37.165369 19076 trainer.py:136] Epoch[128/1000] loss: 0.16199805090824762
I0427 10:20:39.193764 19076 trainer.py:136] Epoch[129/1000] loss: 0.16051909079154333
I0427 10:20:41.343729 19076 trainer.py:136] Epoch[130/1000] loss: 0.1632363200187683
I0427 10:20:43.437836 19076 trainer.py:136] Epoch[131/1000] loss: 0.16469738632440567
I0427 10:20:45.640202 19076 trainer.py:136] Epoch[132/1000] loss: 0.16351337234179178
I0427 10:20:47.706359 19076 trainer.py:136] Epoch[133/1000] loss: 0.16360478848218918
I0427 10:20:49.832367 19076 trainer.py:136] Epoch[134/1000] loss: 0.1577324519554774
I0427 10:20:52.086003 19076 trainer.py:136] Epoch[135/1000] loss: 0.15819887816905975
I0427 10:20:54.193073 19076 trainer.py:136] Epoch[136/1000] loss: 0.1582907090584437
I0427 10:20:56.270372 19076 trainer.py:136] Epoch[137/1000] loss: 0.15978275487820306
I0427 10:20:58.426405 19076 trainer.py:136] Epoch[138/1000] loss: 0.15863297382990518
I0427 10:21:00.493158 19076 trainer.py:136] Epoch[139/1000] loss: 0.15785163144270578
I0427 10:21:02.565357 19076 trainer.py:136] Epoch[140/1000] loss: 0.1560549462834994
I0427 10:21:04.703329 19076 trainer.py:136] Epoch[141/1000] loss: 0.15484360108772913
I0427 10:21:06.866185 19076 trainer.py:136] Epoch[142/1000] loss: 0.15527248630921045
I0427 10:21:08.961357 19076 trainer.py:136] Epoch[143/1000] loss: 0.15648004412651062
I0427 10:21:11.111366 19076 trainer.py:136] Epoch[144/1000] loss: 0.15228567520777384
I0427 10:21:13.401043 19076 trainer.py:136] Epoch[145/1000] loss: 0.15252615263064703
I0427 10:21:15.610284 19076 trainer.py:136] Epoch[146/1000] loss: 0.15180177489916483
I0427 10:21:17.738313 19076 trainer.py:136] Epoch[147/1000] loss: 0.15338812520106634
I0427 10:21:19.903290 19076 trainer.py:136] Epoch[148/1000] loss: 0.15164571007092795
I0427 10:21:22.094550 19076 trainer.py:136] Epoch[149/1000] loss: 0.15084722389777502
I0427 10:21:22.279930 19076 trainer.py:142] Test: [{'precision': 0.12000000000000009, 'recall': 0.28239932796706196, 'hit_ratio': 0.8563002680965147, 'ndcg': 0.2649646972755933}]
I0427 10:21:24.485248 19076 trainer.py:136] Epoch[150/1000] loss: 0.14900398006041846
I0427 10:21:26.613322 19076 trainer.py:136] Epoch[151/1000] loss: 0.14992993573347727
I0427 10:21:28.798869 19076 trainer.py:136] Epoch[152/1000] loss: 0.15142164379358292
I0427 10:21:30.965877 19076 trainer.py:136] Epoch[153/1000] loss: 0.1477141777674357
I0427 10:21:33.091637 19076 trainer.py:136] Epoch[154/1000] loss: 0.14923533300558725
I0427 10:21:35.304125 19076 trainer.py:136] Epoch[155/1000] loss: 0.1488544245560964
I0427 10:21:37.587432 19076 trainer.py:136] Epoch[156/1000] loss: 0.1478941192229589
I0427 10:21:39.794223 19076 trainer.py:136] Epoch[157/1000] loss: 0.14667967955271402
I0427 10:21:41.845135 19076 trainer.py:136] Epoch[158/1000] loss: 0.14563547323147455
I0427 10:21:43.914433 19076 trainer.py:136] Epoch[159/1000] loss: 0.1441799153884252
I0427 10:21:46.003547 19076 trainer.py:136] Epoch[160/1000] loss: 0.14693164577086767
I0427 10:21:48.121115 19076 trainer.py:136] Epoch[161/1000] loss: 0.14335090418656668
I0427 10:21:50.147475 19076 trainer.py:136] Epoch[162/1000] loss: 0.1429242044687271
I0427 10:21:52.285549 19076 trainer.py:136] Epoch[163/1000] loss: 0.14526950319608053
I0427 10:21:54.245109 19076 trainer.py:136] Epoch[164/1000] loss: 0.1449855367342631
I0427 10:21:56.427999 19076 trainer.py:136] Epoch[165/1000] loss: 0.1420135796070099
I0427 10:21:58.533771 19076 trainer.py:136] Epoch[166/1000] loss: 0.14129478732744852
I0427 10:22:00.624187 19076 trainer.py:136] Epoch[167/1000] loss: 0.14018492648998895
I0427 10:22:02.711457 19076 trainer.py:136] Epoch[168/1000] loss: 0.1391606703400612
I0427 10:22:04.849461 19076 trainer.py:136] Epoch[169/1000] loss: 0.140770914653937
I0427 10:22:07.009247 19076 trainer.py:136] Epoch[170/1000] loss: 0.13913400967915854
I0427 10:22:09.159971 19076 trainer.py:136] Epoch[171/1000] loss: 0.14036581913630167
I0427 10:22:11.289046 19076 trainer.py:136] Epoch[172/1000] loss: 0.14192263533671698
I0427 10:22:13.525735 19076 trainer.py:136] Epoch[173/1000] loss: 0.13715292265017828
I0427 10:22:15.700374 19076 trainer.py:136] Epoch[174/1000] loss: 0.13866193095842996
I0427 10:22:17.724720 19076 trainer.py:136] Epoch[175/1000] loss: 0.13971735537052155
I0427 10:22:19.805445 19076 trainer.py:136] Epoch[176/1000] loss: 0.13792086889346442
I0427 10:22:21.927510 19076 trainer.py:136] Epoch[177/1000] loss: 0.13537402947743735
I0427 10:22:24.026635 19076 trainer.py:136] Epoch[178/1000] loss: 0.13996276011069617
I0427 10:22:26.076996 19076 trainer.py:136] Epoch[179/1000] loss: 0.13535229365030924
I0427 10:22:28.293296 19076 trainer.py:136] Epoch[180/1000] loss: 0.13533238569895426
I0427 10:22:30.297091 19076 trainer.py:136] Epoch[181/1000] loss: 0.1342740406592687
I0427 10:22:32.352338 19076 trainer.py:136] Epoch[182/1000] loss: 0.13230452686548233
I0427 10:22:34.342483 19076 trainer.py:136] Epoch[183/1000] loss: 0.13594753543535867
I0427 10:22:36.505312 19076 trainer.py:136] Epoch[184/1000] loss: 0.13472511619329453
I0427 10:22:38.570112 19076 trainer.py:136] Epoch[185/1000] loss: 0.13324463615814844
I0427 10:22:40.718075 19076 trainer.py:136] Epoch[186/1000] loss: 0.13217680901288986
I0427 10:22:43.023154 19076 trainer.py:136] Epoch[187/1000] loss: 0.13051437586545944
I0427 10:22:45.178006 19076 trainer.py:136] Epoch[188/1000] loss: 0.13224805891513824
I0427 10:22:47.404717 19076 trainer.py:136] Epoch[189/1000] loss: 0.13176269829273224
I0427 10:22:49.564764 19076 trainer.py:136] Epoch[190/1000] loss: 0.13030471776922545
I0427 10:22:51.768645 19076 trainer.py:136] Epoch[191/1000] loss: 0.13090516130129495
I0427 10:22:53.967684 19076 trainer.py:136] Epoch[192/1000] loss: 0.1319826419154803
I0427 10:22:56.024928 19076 trainer.py:136] Epoch[193/1000] loss: 0.13279273609320322
I0427 10:22:58.209777 19076 trainer.py:136] Epoch[194/1000] loss: 0.1296235273281733
I0427 10:23:00.545214 19076 trainer.py:136] Epoch[195/1000] loss: 0.13075446089108786
I0427 10:23:02.871631 19076 trainer.py:136] Epoch[196/1000] loss: 0.12831699227293333
I0427 10:23:04.988958 19076 trainer.py:136] Epoch[197/1000] loss: 0.12762890135248503
I0427 10:23:07.087522 19076 trainer.py:136] Epoch[198/1000] loss: 0.12990892181793848
I0427 10:23:09.131847 19076 trainer.py:136] Epoch[199/1000] loss: 0.1278140110274156
I0427 10:23:09.422874 19076 trainer.py:142] Test: [{'precision': 0.12343163538874005, 'recall': 0.2915718618762304, 'hit_ratio': 0.8680965147453084, 'ndcg': 0.2742823242103305}]
I0427 10:23:11.575355 19076 trainer.py:136] Epoch[200/1000] loss: 0.1282252719004949
I0427 10:23:13.798042 19076 trainer.py:136] Epoch[201/1000] loss: 0.12598675737778345
I0427 10:23:15.957955 19076 trainer.py:136] Epoch[202/1000] loss: 0.12531316156188646
I0427 10:23:18.395534 19076 trainer.py:136] Epoch[203/1000] loss: 0.12618054449558258
I0427 10:23:20.524191 19076 trainer.py:136] Epoch[204/1000] loss: 0.12849080810944238
I0427 10:23:22.812691 19076 trainer.py:136] Epoch[205/1000] loss: 0.12569242964188257
I0427 10:23:25.124087 19076 trainer.py:136] Epoch[206/1000] loss: 0.12794595708449683
I0427 10:23:27.271603 19076 trainer.py:136] Epoch[207/1000] loss: 0.12630726769566536
I0427 10:23:29.407900 19076 trainer.py:136] Epoch[208/1000] loss: 0.12723951786756516
I0427 10:23:31.776758 19076 trainer.py:136] Epoch[209/1000] loss: 0.12628190964460373
I0427 10:23:33.785740 19076 trainer.py:136] Epoch[210/1000] loss: 0.12473473573724429
I0427 10:23:36.036363 19076 trainer.py:136] Epoch[211/1000] loss: 0.1264723725616932
I0427 10:23:38.325834 19076 trainer.py:136] Epoch[212/1000] loss: 0.1276040400067965
I0427 10:23:40.567078 19076 trainer.py:136] Epoch[213/1000] loss: 0.12524084374308586
I0427 10:23:43.131646 19076 trainer.py:136] Epoch[214/1000] loss: 0.12249638388554256
I0427 10:23:45.251112 19076 trainer.py:136] Epoch[215/1000] loss: 0.12402510891358058
I0427 10:23:47.346247 19076 trainer.py:136] Epoch[216/1000] loss: 0.12538565571109453
I0427 10:23:49.609317 19076 trainer.py:136] Epoch[217/1000] loss: 0.1240758274992307
I0427 10:23:51.640439 19076 trainer.py:136] Epoch[218/1000] loss: 0.12428233027458191
I0427 10:23:53.700708 19076 trainer.py:136] Epoch[219/1000] loss: 0.12437240406870842
I0427 10:23:55.743657 19076 trainer.py:136] Epoch[220/1000] loss: 0.12218980118632317
I0427 10:23:57.793235 19076 trainer.py:136] Epoch[221/1000] loss: 0.12170944114526112
I0427 10:23:59.929525 19076 trainer.py:136] Epoch[222/1000] loss: 0.11903028935194016
I0427 10:24:02.060621 19076 trainer.py:136] Epoch[223/1000] loss: 0.11658703908324242
I0427 10:24:04.164748 19076 trainer.py:136] Epoch[224/1000] loss: 0.12073626990119617
I0427 10:24:06.280929 19076 trainer.py:136] Epoch[225/1000] loss: 0.121660977602005
I0427 10:24:08.407971 19076 trainer.py:136] Epoch[226/1000] loss: 0.11997699861725171
I0427 10:24:10.540918 19076 trainer.py:136] Epoch[227/1000] loss: 0.12245778491099675
I0427 10:24:12.631021 19076 trainer.py:136] Epoch[228/1000] loss: 0.11702256401379903
I0427 10:24:14.714199 19076 trainer.py:136] Epoch[229/1000] loss: 0.11908679828047752
I0427 10:24:16.745754 19076 trainer.py:136] Epoch[230/1000] loss: 0.11802974591652553
I0427 10:24:18.805116 19076 trainer.py:136] Epoch[231/1000] loss: 0.12067321687936783
I0427 10:24:20.934123 19076 trainer.py:136] Epoch[232/1000] loss: 0.12152551114559174
I0427 10:24:22.984412 19076 trainer.py:136] Epoch[233/1000] loss: 0.11910427485903104
I0427 10:24:25.081669 19076 trainer.py:136] Epoch[234/1000] loss: 0.11749562869469325
I0427 10:24:27.064167 19076 trainer.py:136] Epoch[235/1000] loss: 0.11836092794934909
I0427 10:24:29.069954 19076 trainer.py:136] Epoch[236/1000] loss: 0.1167427363495032
I0427 10:24:31.127083 19076 trainer.py:136] Epoch[237/1000] loss: 0.11444465070962906
I0427 10:24:33.193856 19076 trainer.py:136] Epoch[238/1000] loss: 0.11539923399686813
I0427 10:24:35.231970 19076 trainer.py:136] Epoch[239/1000] loss: 0.11439750467737515
I0427 10:24:37.280822 19076 trainer.py:136] Epoch[240/1000] loss: 0.11563634872436523
I0427 10:24:39.379943 19076 trainer.py:136] Epoch[241/1000] loss: 0.1136154942214489
I0427 10:24:41.372476 19076 trainer.py:136] Epoch[242/1000] loss: 0.11511282498637836
I0427 10:24:43.410745 19076 trainer.py:136] Epoch[243/1000] loss: 0.11459706102808316
I0427 10:24:45.494973 19076 trainer.py:136] Epoch[244/1000] loss: 0.11455752824743588
I0427 10:24:47.478529 19076 trainer.py:136] Epoch[245/1000] loss: 0.11597975964347522
I0427 10:24:49.563267 19076 trainer.py:136] Epoch[246/1000] loss: 0.11585365484158199
I0427 10:24:51.647552 19076 trainer.py:136] Epoch[247/1000] loss: 0.11337048560380936
I0427 10:24:53.799492 19076 trainer.py:136] Epoch[248/1000] loss: 0.11507475127776463
I0427 10:24:55.878741 19076 trainer.py:136] Epoch[249/1000] loss: 0.11255806932846706
I0427 10:24:56.058141 19076 trainer.py:142] Test: [{'precision': 0.1266219839142092, 'recall': 0.29877114947293165, 'hit_ratio': 0.8729222520107238, 'ndcg': 0.2818314068000739}]
I0427 10:24:58.105457 19076 trainer.py:136] Epoch[250/1000] loss: 0.11421362186471622
I0427 10:25:00.203327 19076 trainer.py:136] Epoch[251/1000] loss: 0.11413724472125371
I0427 10:25:02.345030 19076 trainer.py:136] Epoch[252/1000] loss: 0.11286928008000056
I0427 10:25:04.369446 19076 trainer.py:136] Epoch[253/1000] loss: 0.11368661373853683
I0427 10:25:06.478890 19076 trainer.py:136] Epoch[254/1000] loss: 0.11311720311641693
I0427 10:25:08.508301 19076 trainer.py:136] Epoch[255/1000] loss: 0.11249410485227902
I0427 10:25:10.586543 19076 trainer.py:136] Epoch[256/1000] loss: 0.11173291380206744
I0427 10:25:12.618920 19076 trainer.py:136] Epoch[257/1000] loss: 0.11071588719884555
I0427 10:25:14.768925 19076 trainer.py:136] Epoch[258/1000] loss: 0.10999685525894165
I0427 10:25:16.714517 19076 trainer.py:136] Epoch[259/1000] loss: 0.11280536403258641
I0427 10:25:18.859535 19076 trainer.py:136] Epoch[260/1000] loss: 0.11425651237368584
I0427 10:25:20.940773 19076 trainer.py:136] Epoch[261/1000] loss: 0.1108864148457845
I0427 10:25:22.991115 19076 trainer.py:136] Epoch[262/1000] loss: 0.10835849245389302
I0427 10:25:25.065769 19076 trainer.py:136] Epoch[263/1000] loss: 0.1100990263124307
I0427 10:25:27.043359 19076 trainer.py:136] Epoch[264/1000] loss: 0.10938617214560509
I0427 10:25:29.123877 19076 trainer.py:136] Epoch[265/1000] loss: 0.10970425481597583
I0427 10:25:31.154298 19076 trainer.py:136] Epoch[266/1000] loss: 0.10884832963347435
I0427 10:25:33.223393 19076 trainer.py:136] Epoch[267/1000] loss: 0.11106857160727183
I0427 10:25:35.318690 19076 trainer.py:136] Epoch[268/1000] loss: 0.10780886560678482
I0427 10:25:37.383924 19076 trainer.py:136] Epoch[269/1000] loss: 0.10869468127687772
I0427 10:25:39.439949 19076 trainer.py:136] Epoch[270/1000] loss: 0.10638872534036636
I0427 10:25:41.487815 19076 trainer.py:136] Epoch[271/1000] loss: 0.10615634297331174
I0427 10:25:43.631807 19076 trainer.py:136] Epoch[272/1000] loss: 0.11099511881669362
I0427 10:25:45.717977 19076 trainer.py:136] Epoch[273/1000] loss: 0.10830546543002129
I0427 10:25:47.791194 19076 trainer.py:136] Epoch[274/1000] loss: 0.1070476087431113
I0427 10:25:49.985241 19076 trainer.py:136] Epoch[275/1000] loss: 0.10752232372760773
I0427 10:25:52.063413 19076 trainer.py:136] Epoch[276/1000] loss: 0.10852235804001491
I0427 10:25:54.190413 19076 trainer.py:136] Epoch[277/1000] loss: 0.10421327253182729
I0427 10:25:56.283511 19076 trainer.py:136] Epoch[278/1000] loss: 0.10693889359633128
I0427 10:25:58.385060 19076 trainer.py:136] Epoch[279/1000] loss: 0.10533711190025012
I0427 10:26:00.444290 19076 trainer.py:136] Epoch[280/1000] loss: 0.1080573337773482
I0427 10:26:02.484765 19076 trainer.py:136] Epoch[281/1000] loss: 0.10430620610713959
I0427 10:26:04.714212 19076 trainer.py:136] Epoch[282/1000] loss: 0.1062802883485953
I0427 10:26:06.869627 19076 trainer.py:136] Epoch[283/1000] loss: 0.10570944969852765
I0427 10:26:08.922980 19076 trainer.py:136] Epoch[284/1000] loss: 0.10523665323853493
I0427 10:26:11.037720 19076 trainer.py:136] Epoch[285/1000] loss: 0.1076543815433979
I0427 10:26:13.138844 19076 trainer.py:136] Epoch[286/1000] loss: 0.10660129288832347
I0427 10:26:15.280399 19076 trainer.py:136] Epoch[287/1000] loss: 0.10371348386009534
I0427 10:26:17.325382 19076 trainer.py:136] Epoch[288/1000] loss: 0.10320636505881946
I0427 10:26:19.426476 19076 trainer.py:136] Epoch[289/1000] loss: 0.10451900710662206
I0427 10:26:21.576126 19076 trainer.py:136] Epoch[290/1000] loss: 0.10322399561603864
I0427 10:26:23.849955 19076 trainer.py:136] Epoch[291/1000] loss: 0.10496921588977177
I0427 10:26:25.949978 19076 trainer.py:136] Epoch[292/1000] loss: 0.10615784923235576
I0427 10:26:28.004649 19076 trainer.py:136] Epoch[293/1000] loss: 0.10392833625276883
I0427 10:26:30.081768 19076 trainer.py:136] Epoch[294/1000] loss: 0.10145055378476779
I0427 10:26:32.097214 19076 trainer.py:136] Epoch[295/1000] loss: 0.10472949221730232
I0427 10:26:34.256179 19076 trainer.py:136] Epoch[296/1000] loss: 0.10513890286286671
I0427 10:26:36.269566 19076 trainer.py:136] Epoch[297/1000] loss: 0.10454076652725537
I0427 10:26:38.354882 19076 trainer.py:136] Epoch[298/1000] loss: 0.10109696288903554
I0427 10:26:40.430251 19076 trainer.py:136] Epoch[299/1000] loss: 0.1022426684697469
I0427 10:26:40.605219 19076 trainer.py:142] Test: [{'precision': 0.12868632707774807, 'recall': 0.30342759870279207, 'hit_ratio': 0.8723860589812332, 'ndcg': 0.28624301305832134}]
I0427 10:26:42.737269 19076 trainer.py:136] Epoch[300/1000] loss: 0.10426470264792442
I0427 10:26:44.809492 19076 trainer.py:136] Epoch[301/1000] loss: 0.10360289985934894
I0427 10:26:46.969529 19076 trainer.py:136] Epoch[302/1000] loss: 0.10063327476382256
I0427 10:26:49.108891 19076 trainer.py:136] Epoch[303/1000] loss: 0.10386630271871884
I0427 10:26:51.204876 19076 trainer.py:136] Epoch[304/1000] loss: 0.10193546737233798
I0427 10:26:53.274163 19076 trainer.py:136] Epoch[305/1000] loss: 0.10204785689711571
I0427 10:26:55.343304 19076 trainer.py:136] Epoch[306/1000] loss: 0.10298079997301102
I0427 10:26:57.462904 19076 trainer.py:136] Epoch[307/1000] loss: 0.10260973870754242
I0427 10:26:59.485275 19076 trainer.py:136] Epoch[308/1000] loss: 0.1026140662531058
I0427 10:27:01.578400 19076 trainer.py:136] Epoch[309/1000] loss: 0.10093194246292114
I0427 10:27:03.687476 19076 trainer.py:136] Epoch[310/1000] loss: 0.10045682390530904
I0427 10:27:05.796350 19076 trainer.py:136] Epoch[311/1000] loss: 0.10013696427146594
I0427 10:27:07.909424 19076 trainer.py:136] Epoch[312/1000] loss: 0.0996146413187186
I0427 10:27:10.037497 19076 trainer.py:136] Epoch[313/1000] loss: 0.10043439144889514
I0427 10:27:12.148589 19076 trainer.py:136] Epoch[314/1000] loss: 0.10144802555441856
I0427 10:27:14.257791 19076 trainer.py:136] Epoch[315/1000] loss: 0.10120571777224541
I0427 10:27:16.362757 19076 trainer.py:136] Epoch[316/1000] loss: 0.09977750852704048
I0427 10:27:18.688443 19076 trainer.py:136] Epoch[317/1000] loss: 0.09960310036937396
I0427 10:27:20.762398 19076 trainer.py:136] Epoch[318/1000] loss: 0.0986425851782163
I0427 10:27:22.893031 19076 trainer.py:136] Epoch[319/1000] loss: 0.09887279570102692
I0427 10:27:24.857604 19076 trainer.py:136] Epoch[320/1000] loss: 0.09942919264237086
I0427 10:27:26.934041 19076 trainer.py:136] Epoch[321/1000] loss: 0.10054251675804456
I0427 10:27:28.923522 19076 trainer.py:136] Epoch[322/1000] loss: 0.10063833246628444
I0427 10:27:31.035573 19076 trainer.py:136] Epoch[323/1000] loss: 0.09703029816349347
I0427 10:27:33.058859 19076 trainer.py:136] Epoch[324/1000] loss: 0.09687888746460278
I0427 10:27:35.101177 19076 trainer.py:136] Epoch[325/1000] loss: 0.09738074739774068
I0427 10:27:37.128355 19076 trainer.py:136] Epoch[326/1000] loss: 0.09999759991963704
I0427 10:27:39.247599 19076 trainer.py:136] Epoch[327/1000] loss: 0.09766923760374387
I0427 10:27:41.340747 19076 trainer.py:136] Epoch[328/1000] loss: 0.09853612755735715
I0427 10:27:43.495216 19076 trainer.py:136] Epoch[329/1000] loss: 0.0965676022072633
I0427 10:27:45.560357 19076 trainer.py:136] Epoch[330/1000] loss: 0.09742107366522153
I0427 10:27:47.694343 19076 trainer.py:136] Epoch[331/1000] loss: 0.09686773146192233
I0427 10:27:49.758219 19076 trainer.py:136] Epoch[332/1000] loss: 0.0955978458126386
I0427 10:27:51.910123 19076 trainer.py:136] Epoch[333/1000] loss: 0.09639920915166537
I0427 10:27:53.995282 19076 trainer.py:136] Epoch[334/1000] loss: 0.09607357655962308
I0427 10:27:56.131249 19076 trainer.py:136] Epoch[335/1000] loss: 0.09826542064547539
I0427 10:27:58.242488 19076 trainer.py:136] Epoch[336/1000] loss: 0.09933063512047131
I0427 10:28:00.302409 19076 trainer.py:136] Epoch[337/1000] loss: 0.0957392156124115
I0427 10:28:02.346993 19076 trainer.py:136] Epoch[338/1000] loss: 0.09497392550110817
I0427 10:28:04.461234 19076 trainer.py:136] Epoch[339/1000] loss: 0.09606671457489331
I0427 10:28:06.512058 19076 trainer.py:136] Epoch[340/1000] loss: 0.0971271110077699
I0427 10:28:08.609165 19076 trainer.py:136] Epoch[341/1000] loss: 0.09313128391901652
I0427 10:28:10.697341 19076 trainer.py:136] Epoch[342/1000] loss: 0.09471853077411652
I0427 10:28:12.784525 19076 trainer.py:136] Epoch[343/1000] loss: 0.09571763997276624
I0427 10:28:14.923581 19076 trainer.py:136] Epoch[344/1000] loss: 0.09507314239939053
I0427 10:28:16.994831 19076 trainer.py:136] Epoch[345/1000] loss: 0.09412696088353793
I0427 10:28:19.127900 19076 trainer.py:136] Epoch[346/1000] loss: 0.093544186403354
I0427 10:28:21.224029 19076 trainer.py:136] Epoch[347/1000] loss: 0.0952956626812617
I0427 10:28:23.320946 19076 trainer.py:136] Epoch[348/1000] loss: 0.09393598511815071
I0427 10:28:25.401072 19076 trainer.py:136] Epoch[349/1000] loss: 0.09492659444610278
I0427 10:28:25.553151 19076 trainer.py:142] Test: [{'precision': 0.129892761394102, 'recall': 0.306673796423836, 'hit_ratio': 0.8745308310991957, 'ndcg': 0.2901495501190133}]
I0427 10:28:27.634521 19076 trainer.py:136] Epoch[350/1000] loss: 0.0939118725558122
I0427 10:28:29.700679 19076 trainer.py:136] Epoch[351/1000] loss: 0.09543620546658833
I0427 10:28:31.765928 19076 trainer.py:136] Epoch[352/1000] loss: 0.09445461134115855
I0427 10:28:33.770243 19076 trainer.py:136] Epoch[353/1000] loss: 0.09437706818183263
I0427 10:28:35.785744 19076 trainer.py:136] Epoch[354/1000] loss: 0.0925850768884023
I0427 10:28:37.872912 19076 trainer.py:136] Epoch[355/1000] loss: 0.09227660670876503
I0427 10:28:39.981055 19076 trainer.py:136] Epoch[356/1000] loss: 0.0935182012617588
I0427 10:28:42.009476 19076 trainer.py:136] Epoch[357/1000] loss: 0.09253678470849991
I0427 10:28:44.109607 19076 trainer.py:136] Epoch[358/1000] loss: 0.09439449136455853
I0427 10:28:46.140930 19076 trainer.py:136] Epoch[359/1000] loss: 0.09316127747297287
I0427 10:28:48.218187 19076 trainer.py:136] Epoch[360/1000] loss: 0.09272138650218646
I0427 10:28:50.165847 19076 trainer.py:136] Epoch[361/1000] loss: 0.09244754537940025
I0427 10:28:52.349996 19076 trainer.py:136] Epoch[362/1000] loss: 0.09315456698338191
I0427 10:28:54.442244 19076 trainer.py:136] Epoch[363/1000] loss: 0.09426083167394002
I0427 10:28:56.605704 19076 trainer.py:136] Epoch[364/1000] loss: 0.09462917844454448
I0427 10:28:58.645570 19076 trainer.py:136] Epoch[365/1000] loss: 0.09244520465532939
I0427 10:29:00.740813 19076 trainer.py:136] Epoch[366/1000] loss: 0.09405005102356274
I0427 10:29:02.763704 19076 trainer.py:136] Epoch[367/1000] loss: 0.09198438500364621
I0427 10:29:04.894835 19076 trainer.py:136] Epoch[368/1000] loss: 0.09182537098725636
I0427 10:29:06.904233 19076 trainer.py:136] Epoch[369/1000] loss: 0.09353202084700267
I0427 10:29:08.980252 19076 trainer.py:136] Epoch[370/1000] loss: 0.09050642823179562
I0427 10:29:10.962743 19076 trainer.py:136] Epoch[371/1000] loss: 0.09243659550944965
I0427 10:29:13.060214 19076 trainer.py:136] Epoch[372/1000] loss: 0.092410359531641
I0427 10:29:15.143338 19076 trainer.py:136] Epoch[373/1000] loss: 0.09039375558495522
I0427 10:29:17.257495 19076 trainer.py:136] Epoch[374/1000] loss: 0.09158944586912791
I0427 10:29:19.306823 19076 trainer.py:136] Epoch[375/1000] loss: 0.09211904183030128
I0427 10:29:21.371635 19076 trainer.py:136] Epoch[376/1000] loss: 0.09028865769505501
I0427 10:29:23.434694 19076 trainer.py:136] Epoch[377/1000] loss: 0.08988882352908452
I0427 10:29:25.515466 19076 trainer.py:136] Epoch[378/1000] loss: 0.08970676238338153
I0427 10:29:27.628591 19076 trainer.py:136] Epoch[379/1000] loss: 0.09042566890517871
I0427 10:29:29.781144 19076 trainer.py:136] Epoch[380/1000] loss: 0.09088267758488655
I0427 10:29:31.855689 19076 trainer.py:136] Epoch[381/1000] loss: 0.08872472991545995
I0427 10:29:33.954800 19076 trainer.py:136] Epoch[382/1000] loss: 0.09063189352552097
I0427 10:29:36.134617 19076 trainer.py:136] Epoch[383/1000] loss: 0.09017371013760567
I0427 10:29:38.136548 19076 trainer.py:136] Epoch[384/1000] loss: 0.08739025394121806
I0427 10:29:40.243612 19076 trainer.py:136] Epoch[385/1000] loss: 0.09076982239882152
I0427 10:29:42.269280 19076 trainer.py:136] Epoch[386/1000] loss: 0.09013713772098224
I0427 10:29:44.357946 19076 trainer.py:136] Epoch[387/1000] loss: 0.0889161800344785
I0427 10:29:46.450472 19076 trainer.py:136] Epoch[388/1000] loss: 0.08925754204392433
I0427 10:29:48.524241 19076 trainer.py:136] Epoch[389/1000] loss: 0.08996463442842166
I0427 10:29:50.542201 19076 trainer.py:136] Epoch[390/1000] loss: 0.08938946202397346
I0427 10:29:52.687814 19076 trainer.py:136] Epoch[391/1000] loss: 0.09030478571852048
I0427 10:29:54.755094 19076 trainer.py:136] Epoch[392/1000] loss: 0.08931106825669606
I0427 10:29:56.860263 19076 trainer.py:136] Epoch[393/1000] loss: 0.08524546027183533
I0427 10:29:58.824864 19076 trainer.py:136] Epoch[394/1000] loss: 0.08860880881547928
I0427 10:30:01.012767 19076 trainer.py:136] Epoch[395/1000] loss: 0.08654264857371648
I0427 10:30:03.028148 19076 trainer.py:136] Epoch[396/1000] loss: 0.08650521064798038
I0427 10:30:05.148228 19076 trainer.py:136] Epoch[397/1000] loss: 0.08733566105365753
I0427 10:30:07.236443 19076 trainer.py:136] Epoch[398/1000] loss: 0.08948470776279767
I0427 10:30:09.402672 19076 trainer.py:136] Epoch[399/1000] loss: 0.09010312085350354
I0427 10:30:09.552741 19076 trainer.py:142] Test: [{'precision': 0.1312332439678285, 'recall': 0.31010845254379404, 'hit_ratio': 0.8772117962466488, 'ndcg': 0.2933584832939485}]
I0427 10:30:11.591619 19076 trainer.py:136] Epoch[400/1000] loss: 0.08731139575441678
I0427 10:30:13.661093 19076 trainer.py:136] Epoch[401/1000] loss: 0.08822263777256012
I0427 10:30:15.683880 19076 trainer.py:136] Epoch[402/1000] loss: 0.08638489246368408
I0427 10:30:17.757076 19076 trainer.py:136] Epoch[403/1000] loss: 0.08893057083090146
I0427 10:30:19.764461 19076 trainer.py:136] Epoch[404/1000] loss: 0.08586568882067998
I0427 10:30:21.819341 19076 trainer.py:136] Epoch[405/1000] loss: 0.08594706902901332
I0427 10:30:23.901963 19076 trainer.py:136] Epoch[406/1000] loss: 0.08734836926062901
I0427 10:30:25.916927 19076 trainer.py:136] Epoch[407/1000] loss: 0.08707271764675777
I0427 10:30:28.047677 19076 trainer.py:136] Epoch[408/1000] loss: 0.08751797179381053
I0427 10:30:30.101459 19076 trainer.py:136] Epoch[409/1000] loss: 0.08463912333051364
I0427 10:30:32.257149 19076 trainer.py:136] Epoch[410/1000] loss: 0.08562818790475528
I0427 10:30:34.397789 19076 trainer.py:136] Epoch[411/1000] loss: 0.08496496453881264
I0427 10:30:36.472782 19076 trainer.py:136] Epoch[412/1000] loss: 0.08582697808742523
I0427 10:30:38.603960 19076 trainer.py:136] Epoch[413/1000] loss: 0.08611529072125752
I0427 10:30:40.766850 19076 trainer.py:136] Epoch[414/1000] loss: 0.08602886646986008
I0427 10:30:42.811713 19076 trainer.py:136] Epoch[415/1000] loss: 0.08645790939529736
I0427 10:30:44.941913 19076 trainer.py:136] Epoch[416/1000] loss: 0.08766951163609822
I0427 10:30:47.019907 19076 trainer.py:136] Epoch[417/1000] loss: 0.08658035472035408
I0427 10:30:49.174626 19076 trainer.py:136] Epoch[418/1000] loss: 0.08701382577419281
I0427 10:30:51.228697 19076 trainer.py:136] Epoch[419/1000] loss: 0.08540877203146617
I0427 10:30:53.383921 19076 trainer.py:136] Epoch[420/1000] loss: 0.084576732168595
I0427 10:30:55.371848 19076 trainer.py:136] Epoch[421/1000] loss: 0.08569099009037018
I0427 10:30:57.569628 19076 trainer.py:136] Epoch[422/1000] loss: 0.08754438906908035
I0427 10:30:59.644812 19076 trainer.py:136] Epoch[423/1000] loss: 0.08592075730363528
I0427 10:31:01.800719 19076 trainer.py:136] Epoch[424/1000] loss: 0.08519076431790988
I0427 10:31:03.912662 19076 trainer.py:136] Epoch[425/1000] loss: 0.08391559248169263
I0427 10:31:06.006799 19076 trainer.py:136] Epoch[426/1000] loss: 0.08514462659756343
I0427 10:31:08.102992 19076 trainer.py:136] Epoch[427/1000] loss: 0.08277338619033496
I0427 10:31:10.210507 19076 trainer.py:136] Epoch[428/1000] loss: 0.0851798305908839
I0427 10:31:12.229328 19076 trainer.py:136] Epoch[429/1000] loss: 0.08513661349813144
I0427 10:31:14.324019 19076 trainer.py:136] Epoch[430/1000] loss: 0.08447742834687233
I0427 10:31:16.371183 19076 trainer.py:136] Epoch[431/1000] loss: 0.08472172419230144
I0427 10:31:18.468876 19076 trainer.py:136] Epoch[432/1000] loss: 0.08644499629735947
I0427 10:31:20.532122 19076 trainer.py:136] Epoch[433/1000] loss: 0.08400075758496921
I0427 10:31:22.702534 19076 trainer.py:136] Epoch[434/1000] loss: 0.08393766731023788
I0427 10:31:24.844502 19076 trainer.py:136] Epoch[435/1000] loss: 0.08567425111929576
I0427 10:31:26.931749 19076 trainer.py:136] Epoch[436/1000] loss: 0.08424939215183258
I0427 10:31:29.032221 19076 trainer.py:136] Epoch[437/1000] loss: 0.08340773483117421
I0427 10:31:30.984770 19076 trainer.py:136] Epoch[438/1000] loss: 0.08449740956226985
I0427 10:31:33.080472 19076 trainer.py:136] Epoch[439/1000] loss: 0.08360311016440392
I0427 10:31:35.157666 19076 trainer.py:136] Epoch[440/1000] loss: 0.08456989005208015
I0427 10:31:37.281669 19076 trainer.py:136] Epoch[441/1000] loss: 0.08375013122955959
I0427 10:31:39.395725 19076 trainer.py:136] Epoch[442/1000] loss: 0.08438868323961894
I0427 10:31:41.480477 19076 trainer.py:136] Epoch[443/1000] loss: 0.08311199272672336
I0427 10:31:43.600040 19076 trainer.py:136] Epoch[444/1000] loss: 0.08273633693655331
I0427 10:31:45.719929 19076 trainer.py:136] Epoch[445/1000] loss: 0.08439387132724126
I0427 10:31:47.735070 19076 trainer.py:136] Epoch[446/1000] loss: 0.083069143195947
I0427 10:31:49.819246 19076 trainer.py:136] Epoch[447/1000] loss: 0.08257383604844411
I0427 10:31:51.873087 19076 trainer.py:136] Epoch[448/1000] loss: 0.08322786043087642
I0427 10:31:53.971776 19076 trainer.py:136] Epoch[449/1000] loss: 0.08152862886587779
I0427 10:31:54.134232 19076 trainer.py:142] Test: [{'precision': 0.13198391420911537, 'recall': 0.3122283882337503, 'hit_ratio': 0.87828418230563, 'ndcg': 0.29590798834802123}]
I0427 10:31:56.138751 19076 trainer.py:136] Epoch[450/1000] loss: 0.08247728894154231
I0427 10:31:58.268734 19076 trainer.py:136] Epoch[451/1000] loss: 0.08390522251526515
I0427 10:32:00.318074 19076 trainer.py:136] Epoch[452/1000] loss: 0.08355732137958209
I0427 10:32:02.401252 19076 trainer.py:136] Epoch[453/1000] loss: 0.08193814009428024
I0427 10:32:04.434573 19076 trainer.py:136] Epoch[454/1000] loss: 0.08455724890033404
I0427 10:32:06.593309 19076 trainer.py:136] Epoch[455/1000] loss: 0.08439347520470619
I0427 10:32:08.624109 19076 trainer.py:136] Epoch[456/1000] loss: 0.08192753046751022
I0427 10:32:10.745718 19076 trainer.py:136] Epoch[457/1000] loss: 0.0805689146121343
I0427 10:32:12.797872 19076 trainer.py:136] Epoch[458/1000] loss: 0.08250718315442403
I0427 10:32:14.926950 19076 trainer.py:136] Epoch[459/1000] loss: 0.08168370028336842
I0427 10:32:16.961260 19076 trainer.py:136] Epoch[460/1000] loss: 0.08244398236274719
I0427 10:32:19.095235 19076 trainer.py:136] Epoch[461/1000] loss: 0.08222319558262825
I0427 10:32:21.128534 19076 trainer.py:136] Epoch[462/1000] loss: 0.08241996169090271
I0427 10:32:23.202832 19076 trainer.py:136] Epoch[463/1000] loss: 0.08171614507834117
I0427 10:32:25.226207 19076 trainer.py:136] Epoch[464/1000] loss: 0.08114535858233769
I0427 10:32:27.246594 19076 trainer.py:136] Epoch[465/1000] loss: 0.08088763306538264
I0427 10:32:29.376360 19076 trainer.py:136] Epoch[466/1000] loss: 0.08325506746768951
I0427 10:32:31.317938 19076 trainer.py:136] Epoch[467/1000] loss: 0.08281502624352773
I0427 10:32:33.440733 19076 trainer.py:136] Epoch[468/1000] loss: 0.08203382169206937
I0427 10:32:35.405638 19076 trainer.py:136] Epoch[469/1000] loss: 0.08220067868630092
I0427 10:32:37.514351 19076 trainer.py:136] Epoch[470/1000] loss: 0.08176696300506592
I0427 10:32:39.542036 19076 trainer.py:136] Epoch[471/1000] loss: 0.07985797276099522
I0427 10:32:41.644122 19076 trainer.py:136] Epoch[472/1000] loss: 0.08180424571037292
I0427 10:32:43.701436 19076 trainer.py:136] Epoch[473/1000] loss: 0.0820283330976963
I0427 10:32:45.817102 19076 trainer.py:136] Epoch[474/1000] loss: 0.08223651473720868
I0427 10:32:47.844732 19076 trainer.py:136] Epoch[475/1000] loss: 0.07991824299097061
I0427 10:32:49.900804 19076 trainer.py:136] Epoch[476/1000] loss: 0.08281470959385236
I0427 10:32:51.983709 19076 trainer.py:136] Epoch[477/1000] loss: 0.07992105682690938
I0427 10:32:54.072273 19076 trainer.py:136] Epoch[478/1000] loss: 0.0806046687066555
I0427 10:32:56.134636 19076 trainer.py:136] Epoch[479/1000] loss: 0.07966845606764157
I0427 10:32:58.211555 19076 trainer.py:136] Epoch[480/1000] loss: 0.07977860669294994
I0427 10:33:00.264054 19076 trainer.py:136] Epoch[481/1000] loss: 0.07799556603034337
I0427 10:33:02.416647 19076 trainer.py:136] Epoch[482/1000] loss: 0.07898045207063357
I0427 10:33:04.475021 19076 trainer.py:136] Epoch[483/1000] loss: 0.08040036881963412
I0427 10:33:06.631073 19076 trainer.py:136] Epoch[484/1000] loss: 0.07964927578965823
I0427 10:33:08.621738 19076 trainer.py:136] Epoch[485/1000] loss: 0.08081913118561108
I0427 10:33:10.678080 19076 trainer.py:136] Epoch[486/1000] loss: 0.07801452651619911
I0427 10:33:12.682498 19076 trainer.py:136] Epoch[487/1000] loss: 0.07872400432825089
I0427 10:33:14.807604 19076 trainer.py:136] Epoch[488/1000] loss: 0.08077131708463033
I0427 10:33:16.843134 19076 trainer.py:136] Epoch[489/1000] loss: 0.07743473102649052
I0427 10:33:18.945478 19076 trainer.py:136] Epoch[490/1000] loss: 0.0798281158010165
I0427 10:33:20.981857 19076 trainer.py:136] Epoch[491/1000] loss: 0.08003699158628781
I0427 10:33:23.008737 19076 trainer.py:136] Epoch[492/1000] loss: 0.07790582502881686
I0427 10:33:25.036691 19076 trainer.py:136] Epoch[493/1000] loss: 0.08012220760186513
I0427 10:33:27.072635 19076 trainer.py:136] Epoch[494/1000] loss: 0.07924381146828334
I0427 10:33:29.066092 19076 trainer.py:136] Epoch[495/1000] loss: 0.07767493277788162
I0427 10:33:31.131342 19076 trainer.py:136] Epoch[496/1000] loss: 0.07790596534808476
I0427 10:33:33.294442 19076 trainer.py:136] Epoch[497/1000] loss: 0.07880076517661412
I0427 10:33:35.372050 19076 trainer.py:136] Epoch[498/1000] loss: 0.07781338443358739
I0427 10:33:37.498789 19076 trainer.py:136] Epoch[499/1000] loss: 0.07741735751430194
I0427 10:33:37.692143 19076 trainer.py:142] Test: [{'precision': 0.13348525469168906, 'recall': 0.3150570791944394, 'hit_ratio': 0.8820375335120644, 'ndcg': 0.29802695337701374}]
I0427 10:33:39.746404 19076 trainer.py:136] Epoch[500/1000] loss: 0.07698788866400719
I0427 10:33:41.824644 19076 trainer.py:136] Epoch[501/1000] loss: 0.07996819292505582
I0427 10:33:43.806940 19076 trainer.py:136] Epoch[502/1000] loss: 0.07899466529488564
I0427 10:33:45.855290 19076 trainer.py:136] Epoch[503/1000] loss: 0.07839606205622356
I0427 10:33:47.837813 19076 trainer.py:136] Epoch[504/1000] loss: 0.07845498373111089
I0427 10:33:49.905622 19076 trainer.py:136] Epoch[505/1000] loss: 0.07759819303949674
I0427 10:33:51.841318 19076 trainer.py:136] Epoch[506/1000] loss: 0.07671728978554408
I0427 10:33:53.950962 19076 trainer.py:136] Epoch[507/1000] loss: 0.07800778498252232
I0427 10:33:55.952156 19076 trainer.py:136] Epoch[508/1000] loss: 0.07899463549256325
I0427 10:33:58.092641 19076 trainer.py:136] Epoch[509/1000] loss: 0.07872177412112553
I0427 10:34:00.133933 19076 trainer.py:136] Epoch[510/1000] loss: 0.07671048243840535
I0427 10:34:02.246768 19076 trainer.py:136] Epoch[511/1000] loss: 0.07881270100673039
I0427 10:34:04.342704 19076 trainer.py:136] Epoch[512/1000] loss: 0.07984352732698123
I0427 10:34:06.481316 19076 trainer.py:136] Epoch[513/1000] loss: 0.07540980602304141
I0427 10:34:08.557596 19076 trainer.py:136] Epoch[514/1000] loss: 0.07734913130601247
I0427 10:34:10.640753 19076 trainer.py:136] Epoch[515/1000] loss: 0.07781698182225227
I0427 10:34:12.680097 19076 trainer.py:136] Epoch[516/1000] loss: 0.07724632943669955
I0427 10:34:14.702934 19076 trainer.py:136] Epoch[517/1000] loss: 0.0771985724568367
I0427 10:34:16.723928 19076 trainer.py:136] Epoch[518/1000] loss: 0.07649702082077663
I0427 10:34:18.935710 19076 trainer.py:136] Epoch[519/1000] loss: 0.07782469938198726
I0427 10:34:21.014952 19076 trainer.py:136] Epoch[520/1000] loss: 0.07558969408273697
I0427 10:34:23.173894 19076 trainer.py:136] Epoch[521/1000] loss: 0.07695504898826282
I0427 10:34:25.287725 19076 trainer.py:136] Epoch[522/1000] loss: 0.07594495266675949
I0427 10:34:27.359565 19076 trainer.py:136] Epoch[523/1000] loss: 0.07483469943205516
I0427 10:34:29.422812 19076 trainer.py:136] Epoch[524/1000] loss: 0.0753948986530304
I0427 10:34:31.513800 19076 trainer.py:136] Epoch[525/1000] loss: 0.07771318530042966
I0427 10:34:33.702687 19076 trainer.py:136] Epoch[526/1000] loss: 0.07713361456990242
I0427 10:34:35.736052 19076 trainer.py:136] Epoch[527/1000] loss: 0.07627161095539729
I0427 10:34:37.818196 19076 trainer.py:136] Epoch[528/1000] loss: 0.07789146651824315
I0427 10:34:39.836258 19076 trainer.py:136] Epoch[529/1000] loss: 0.07507375379403432
I0427 10:34:42.021934 19076 trainer.py:136] Epoch[530/1000] loss: 0.07470921675364177
I0427 10:34:44.043394 19076 trainer.py:136] Epoch[531/1000] loss: 0.07718770702679952
I0427 10:34:46.149158 19076 trainer.py:136] Epoch[532/1000] loss: 0.07750303422411282
I0427 10:34:48.270905 19076 trainer.py:136] Epoch[533/1000] loss: 0.07692759608229001
I0427 10:34:50.359174 19076 trainer.py:136] Epoch[534/1000] loss: 0.07577129205067952
I0427 10:34:52.428387 19076 trainer.py:136] Epoch[535/1000] loss: 0.07680413747827212
I0427 10:34:54.504259 19076 trainer.py:136] Epoch[536/1000] loss: 0.07631839190920194
I0427 10:34:56.579790 19076 trainer.py:136] Epoch[537/1000] loss: 0.07568743452429771
I0427 10:34:58.699179 19076 trainer.py:136] Epoch[538/1000] loss: 0.07614294812083244
I0427 10:35:00.834891 19076 trainer.py:136] Epoch[539/1000] loss: 0.07547321543097496
I0427 10:35:02.987143 19076 trainer.py:136] Epoch[540/1000] loss: 0.07586028178532918
I0427 10:35:05.029451 19076 trainer.py:136] Epoch[541/1000] loss: 0.07335654273629189
I0427 10:35:07.053277 19076 trainer.py:136] Epoch[542/1000] loss: 0.07385250677665074
I0427 10:35:09.100616 19076 trainer.py:136] Epoch[543/1000] loss: 0.07459958394368489
I0427 10:35:11.219294 19076 trainer.py:136] Epoch[544/1000] loss: 0.07534347226222356
I0427 10:35:13.273543 19076 trainer.py:136] Epoch[545/1000] loss: 0.07431825002034505
I0427 10:35:15.341755 19076 trainer.py:136] Epoch[546/1000] loss: 0.07538563137253125
I0427 10:35:17.398915 19076 trainer.py:136] Epoch[547/1000] loss: 0.07778566206494968
I0427 10:35:19.485042 19076 trainer.py:136] Epoch[548/1000] loss: 0.07475172852476437
I0427 10:35:21.519665 19076 trainer.py:136] Epoch[549/1000] loss: 0.07401979714632034
I0427 10:35:21.669479 19076 trainer.py:142] Test: [{'precision': 0.1341823056300269, 'recall': 0.3167990339926945, 'hit_ratio': 0.885254691689008, 'ndcg': 0.2990899989559373}]
I0427 10:35:23.721539 19076 trainer.py:136] Epoch[550/1000] loss: 0.07512759044766426
I0427 10:35:25.865560 19076 trainer.py:136] Epoch[551/1000] loss: 0.07552859683831532
I0427 10:35:27.908933 19076 trainer.py:136] Epoch[552/1000] loss: 0.07445168246825536
I0427 10:35:29.953523 19076 trainer.py:136] Epoch[553/1000] loss: 0.07539939135313034
I0427 10:35:31.996730 19076 trainer.py:136] Epoch[554/1000] loss: 0.0729176364839077
I0427 10:35:34.077023 19076 trainer.py:136] Epoch[555/1000] loss: 0.07551136737068494
I0427 10:35:36.081479 19076 trainer.py:136] Epoch[556/1000] loss: 0.07435595368345578
I0427 10:35:38.317270 19076 trainer.py:136] Epoch[557/1000] loss: 0.07429262374838193
I0427 10:35:40.440303 19076 trainer.py:136] Epoch[558/1000] loss: 0.0737772894402345
I0427 10:35:42.568747 19076 trainer.py:136] Epoch[559/1000] loss: 0.07323041682442029
I0427 10:35:44.640291 19076 trainer.py:136] Epoch[560/1000] loss: 0.07511123642325401
I0427 10:35:46.724249 19076 trainer.py:136] Epoch[561/1000] loss: 0.072978592167298
I0427 10:35:48.727330 19076 trainer.py:136] Epoch[562/1000] loss: 0.07582239682475726
I0427 10:35:50.740753 19076 trainer.py:136] Epoch[563/1000] loss: 0.07321415096521378
I0427 10:35:52.792583 19076 trainer.py:136] Epoch[564/1000] loss: 0.07427714268366496
I0427 10:35:54.822043 19076 trainer.py:136] Epoch[565/1000] loss: 0.07246782133976619
I0427 10:35:56.820688 19076 trainer.py:136] Epoch[566/1000] loss: 0.07430940742293994
I0427 10:35:58.877307 19076 trainer.py:136] Epoch[567/1000] loss: 0.07139477630456288
I0427 10:36:00.911714 19076 trainer.py:136] Epoch[568/1000] loss: 0.07501999785502751
I0427 10:36:03.019821 19076 trainer.py:136] Epoch[569/1000] loss: 0.07455291971564293
I0427 10:36:05.074633 19076 trainer.py:136] Epoch[570/1000] loss: 0.0736146333316962
I0427 10:36:07.162967 19076 trainer.py:136] Epoch[571/1000] loss: 0.0748867429792881
I0427 10:36:09.246647 19076 trainer.py:136] Epoch[572/1000] loss: 0.07380011553565662
I0427 10:36:11.327380 19076 trainer.py:136] Epoch[573/1000] loss: 0.0750576841334502
I0427 10:36:13.386623 19076 trainer.py:136] Epoch[574/1000] loss: 0.07432872677842776
I0427 10:36:15.593035 19076 trainer.py:136] Epoch[575/1000] loss: 0.0746789202094078
I0427 10:36:17.635370 19076 trainer.py:136] Epoch[576/1000] loss: 0.07371681556105614
I0427 10:36:19.765372 19076 trainer.py:136] Epoch[577/1000] loss: 0.07210593049724896
I0427 10:36:21.798862 19076 trainer.py:136] Epoch[578/1000] loss: 0.07286012421051662
I0427 10:36:23.903002 19076 trainer.py:136] Epoch[579/1000] loss: 0.07201226303974788
I0427 10:36:26.006332 19076 trainer.py:136] Epoch[580/1000] loss: 0.07318469882011414
I0427 10:36:28.042998 19076 trainer.py:136] Epoch[581/1000] loss: 0.07396381845076878
I0427 10:36:30.148358 19076 trainer.py:136] Epoch[582/1000] loss: 0.07166651636362076
I0427 10:36:32.274945 19076 trainer.py:136] Epoch[583/1000] loss: 0.07295052831371625
I0427 10:36:34.331725 19076 trainer.py:136] Epoch[584/1000] loss: 0.0728086419403553
I0427 10:36:36.363442 19076 trainer.py:136] Epoch[585/1000] loss: 0.0725731688241164
I0427 10:36:38.438679 19076 trainer.py:136] Epoch[586/1000] loss: 0.07241914048790932
I0427 10:36:40.493555 19076 trainer.py:136] Epoch[587/1000] loss: 0.07335349793235461
I0427 10:36:42.592730 19076 trainer.py:136] Epoch[588/1000] loss: 0.07078831394513448
I0427 10:36:44.732712 19076 trainer.py:136] Epoch[589/1000] loss: 0.07335296769936879
I0427 10:36:46.873588 19076 trainer.py:136] Epoch[590/1000] loss: 0.073527658979098
I0427 10:36:48.947226 19076 trainer.py:136] Epoch[591/1000] loss: 0.07221658652027448
I0427 10:36:50.962649 19076 trainer.py:136] Epoch[592/1000] loss: 0.07294321432709694
I0427 10:36:53.007980 19076 trainer.py:136] Epoch[593/1000] loss: 0.07193629071116447
I0427 10:36:55.038202 19076 trainer.py:136] Epoch[594/1000] loss: 0.07253874465823174
I0427 10:36:57.131331 19076 trainer.py:136] Epoch[595/1000] loss: 0.07312655821442604
I0427 10:36:59.251438 19076 trainer.py:136] Epoch[596/1000] loss: 0.07123846684892972
I0427 10:37:01.332189 19076 trainer.py:136] Epoch[597/1000] loss: 0.07034968088070552
I0427 10:37:03.484749 19076 trainer.py:136] Epoch[598/1000] loss: 0.07291494185725848
I0427 10:37:05.573941 19076 trainer.py:136] Epoch[599/1000] loss: 0.0715687945485115
I0427 10:37:05.745367 19076 trainer.py:142] Test: [{'precision': 0.1352278820375336, 'recall': 0.3189744419924992, 'hit_ratio': 0.8847184986595175, 'ndcg': 0.30155992202192494}]
I0427 10:37:07.876957 19076 trainer.py:136] Epoch[600/1000] loss: 0.07184240842858951
I0427 10:37:09.926416 19076 trainer.py:136] Epoch[601/1000] loss: 0.07184293741981189
I0427 10:37:12.069249 19076 trainer.py:136] Epoch[602/1000] loss: 0.07141686727603276
I0427 10:37:14.118313 19076 trainer.py:136] Epoch[603/1000] loss: 0.07285457849502563
I0427 10:37:16.322696 19076 trainer.py:136] Epoch[604/1000] loss: 0.07210912679632504
I0427 10:37:18.416616 19076 trainer.py:136] Epoch[605/1000] loss: 0.07280791054169337
I0427 10:37:20.494212 19076 trainer.py:136] Epoch[606/1000] loss: 0.07247245560089748
I0427 10:37:22.540574 19076 trainer.py:136] Epoch[607/1000] loss: 0.07159570852915446
I0427 10:37:24.635751 19076 trainer.py:136] Epoch[608/1000] loss: 0.07047974566618602
I0427 10:37:26.695401 19076 trainer.py:136] Epoch[609/1000] loss: 0.07201745361089706
I0427 10:37:28.718835 19076 trainer.py:136] Epoch[610/1000] loss: 0.07012949883937836
I0427 10:37:30.772392 19076 trainer.py:136] Epoch[611/1000] loss: 0.07156752794981003
I0427 10:37:32.811205 19076 trainer.py:136] Epoch[612/1000] loss: 0.07180776322881381
I0427 10:37:34.881574 19076 trainer.py:136] Epoch[613/1000] loss: 0.07230817526578903
I0427 10:37:36.967756 19076 trainer.py:136] Epoch[614/1000] loss: 0.06986373662948608
I0427 10:37:39.078818 19076 trainer.py:136] Epoch[615/1000] loss: 0.07025006661812465
I0427 10:37:41.075654 19076 trainer.py:136] Epoch[616/1000] loss: 0.0711346132059892
I0427 10:37:43.091121 19076 trainer.py:136] Epoch[617/1000] loss: 0.06909816960493724
I0427 10:37:45.137450 19076 trainer.py:136] Epoch[618/1000] loss: 0.06999009971817334
I0427 10:37:47.273457 19076 trainer.py:136] Epoch[619/1000] loss: 0.0710460605720679
I0427 10:37:49.391485 19076 trainer.py:136] Epoch[620/1000] loss: 0.07153348500529925
I0427 10:37:51.510766 19076 trainer.py:136] Epoch[621/1000] loss: 0.06982795769969623
I0427 10:37:53.592467 19076 trainer.py:136] Epoch[622/1000] loss: 0.06968098382155101
I0427 10:37:55.729333 19076 trainer.py:136] Epoch[623/1000] loss: 0.0733172136048476
I0427 10:37:57.810502 19076 trainer.py:136] Epoch[624/1000] loss: 0.07196451351046562
I0427 10:37:59.917631 19076 trainer.py:136] Epoch[625/1000] loss: 0.07079401984810829
I0427 10:38:01.906981 19076 trainer.py:136] Epoch[626/1000] loss: 0.06834513073166211
I0427 10:38:04.009139 19076 trainer.py:136] Epoch[627/1000] loss: 0.07135867699980736
I0427 10:38:06.098120 19076 trainer.py:136] Epoch[628/1000] loss: 0.0701791283984979
I0427 10:38:08.245386 19076 trainer.py:136] Epoch[629/1000] loss: 0.0704965131978194
I0427 10:38:10.283214 19076 trainer.py:136] Epoch[630/1000] loss: 0.07120249668757121
I0427 10:38:12.415759 19076 trainer.py:136] Epoch[631/1000] loss: 0.07276203483343124
I0427 10:38:14.419218 19076 trainer.py:136] Epoch[632/1000] loss: 0.06949803108970325
I0427 10:38:16.447565 19076 trainer.py:136] Epoch[633/1000] loss: 0.07138000552852948
I0427 10:38:18.481456 19076 trainer.py:136] Epoch[634/1000] loss: 0.0715930958588918
I0427 10:38:20.621603 19076 trainer.py:136] Epoch[635/1000] loss: 0.06969658906261127
I0427 10:38:22.733695 19076 trainer.py:136] Epoch[636/1000] loss: 0.06904972717165947
I0427 10:38:24.838787 19076 trainer.py:136] Epoch[637/1000] loss: 0.07000526537497838
I0427 10:38:26.915476 19076 trainer.py:136] Epoch[638/1000] loss: 0.06992742791771889
I0427 10:38:28.950984 19076 trainer.py:136] Epoch[639/1000] loss: 0.07141147305568059
I0427 10:38:31.131173 19076 trainer.py:136] Epoch[640/1000] loss: 0.07171538223822911
I0427 10:38:33.201396 19076 trainer.py:136] Epoch[641/1000] loss: 0.07051438589890797
I0427 10:38:35.373293 19076 trainer.py:136] Epoch[642/1000] loss: 0.07130518679817517
I0427 10:38:37.415648 19076 trainer.py:136] Epoch[643/1000] loss: 0.06961873422066371
I0427 10:38:39.566164 19076 trainer.py:136] Epoch[644/1000] loss: 0.07046953588724136
I0427 10:38:41.605521 19076 trainer.py:136] Epoch[645/1000] loss: 0.07003066688776016
I0427 10:38:43.707643 19076 trainer.py:136] Epoch[646/1000] loss: 0.06841575726866722
I0427 10:38:45.786790 19076 trainer.py:136] Epoch[647/1000] loss: 0.06967468187212944
I0427 10:38:47.901893 19076 trainer.py:136] Epoch[648/1000] loss: 0.07062810038526852
I0427 10:38:50.064544 19076 trainer.py:136] Epoch[649/1000] loss: 0.07109543184439342
I0427 10:38:50.224010 19076 trainer.py:142] Test: [{'precision': 0.1361126005361931, 'recall': 0.3207315456976395, 'hit_ratio': 0.8847184986595175, 'ndcg': 0.3032601429625688}]
I0427 10:38:52.258610 19076 trainer.py:136] Epoch[650/1000] loss: 0.0693549948434035
I0427 10:38:54.279081 19076 trainer.py:136] Epoch[651/1000] loss: 0.07015162582198779
I0427 10:38:56.387166 19076 trainer.py:136] Epoch[652/1000] loss: 0.06833417092760403
I0427 10:38:58.465380 19076 trainer.py:136] Epoch[653/1000] loss: 0.06878155469894409
I0427 10:39:00.654405 19076 trainer.py:136] Epoch[654/1000] loss: 0.07029777268568675
I0427 10:39:02.745544 19076 trainer.py:136] Epoch[655/1000] loss: 0.0698810505370299
I0427 10:39:04.859643 19076 trainer.py:136] Epoch[656/1000] loss: 0.06896456455190976
I0427 10:39:06.897818 19076 trainer.py:136] Epoch[657/1000] loss: 0.06979180872440338
I0427 10:39:08.924641 19076 trainer.py:136] Epoch[658/1000] loss: 0.06917353595296542
I0427 10:39:10.972897 19076 trainer.py:136] Epoch[659/1000] loss: 0.0700511522591114
I0427 10:39:13.110295 19076 trainer.py:136] Epoch[660/1000] loss: 0.06892046084006627
I0427 10:39:15.104411 19076 trainer.py:136] Epoch[661/1000] loss: 0.06979534650842349
I0427 10:39:17.214534 19076 trainer.py:136] Epoch[662/1000] loss: 0.06867876648902893
I0427 10:39:19.192155 19076 trainer.py:136] Epoch[663/1000] loss: 0.07018901159365971
I0427 10:39:21.326122 19076 trainer.py:136] Epoch[664/1000] loss: 0.0684957926472028
I0427 10:39:23.375484 19076 trainer.py:136] Epoch[665/1000] loss: 0.07020824526747067
I0427 10:39:25.541602 19076 trainer.py:136] Epoch[666/1000] loss: 0.06818189720312755
I0427 10:39:27.646554 19076 trainer.py:136] Epoch[667/1000] loss: 0.06832488998770714
I0427 10:39:29.743163 19076 trainer.py:136] Epoch[668/1000] loss: 0.06942787518103917
I0427 10:39:31.776825 19076 trainer.py:136] Epoch[669/1000] loss: 0.0690369742612044
I0427 10:39:33.841022 19076 trainer.py:136] Epoch[670/1000] loss: 0.06935759882132213
I0427 10:39:35.883311 19076 trainer.py:136] Epoch[671/1000] loss: 0.06725981210668881
I0427 10:39:37.996591 19076 trainer.py:136] Epoch[672/1000] loss: 0.06895509734749794
I0427 10:39:40.119735 19076 trainer.py:136] Epoch[673/1000] loss: 0.06912895912925403
I0427 10:39:42.208526 19076 trainer.py:136] Epoch[674/1000] loss: 0.06784188002347946
I0427 10:39:44.318937 19076 trainer.py:136] Epoch[675/1000] loss: 0.06617072224617004
I0427 10:39:46.421068 19076 trainer.py:136] Epoch[676/1000] loss: 0.06769888351360957
I0427 10:39:48.461053 19076 trainer.py:136] Epoch[677/1000] loss: 0.06809114043911298
I0427 10:39:50.464505 19076 trainer.py:136] Epoch[678/1000] loss: 0.06996215259035428
I0427 10:39:52.580114 19076 trainer.py:136] Epoch[679/1000] loss: 0.06907661134998004
I0427 10:39:54.592606 19076 trainer.py:136] Epoch[680/1000] loss: 0.06650662049651146
I0427 10:39:56.655268 19076 trainer.py:136] Epoch[681/1000] loss: 0.06846970071395238
I0427 10:39:58.683675 19076 trainer.py:136] Epoch[682/1000] loss: 0.06600237203141053
I0427 10:40:00.768824 19076 trainer.py:136] Epoch[683/1000] loss: 0.06825351590911548
I0427 10:40:02.919747 19076 trainer.py:136] Epoch[684/1000] loss: 0.06780781596899033
I0427 10:40:05.033463 19076 trainer.py:136] Epoch[685/1000] loss: 0.06842352077364922
I0427 10:40:07.083043 19076 trainer.py:136] Epoch[686/1000] loss: 0.06847536315520604
I0427 10:40:09.122849 19076 trainer.py:136] Epoch[687/1000] loss: 0.06945473452409108
I0427 10:40:11.209091 19076 trainer.py:136] Epoch[688/1000] loss: 0.06775498266021411
I0427 10:40:13.349021 19076 trainer.py:136] Epoch[689/1000] loss: 0.06555604375898838
I0427 10:40:15.398989 19076 trainer.py:136] Epoch[690/1000] loss: 0.07072758302092552
I0427 10:40:17.509756 19076 trainer.py:136] Epoch[691/1000] loss: 0.06817565485835075
I0427 10:40:19.572986 19076 trainer.py:136] Epoch[692/1000] loss: 0.06732876971364021
I0427 10:40:21.675210 19076 trainer.py:136] Epoch[693/1000] loss: 0.0671512819826603
I0427 10:40:23.774001 19076 trainer.py:136] Epoch[694/1000] loss: 0.06648306424419086
I0427 10:40:25.912009 19076 trainer.py:136] Epoch[695/1000] loss: 0.06820101166764896
I0427 10:40:27.999154 19076 trainer.py:136] Epoch[696/1000] loss: 0.06743352611859639
I0427 10:40:30.088723 19076 trainer.py:136] Epoch[697/1000] loss: 0.06746878599127133
I0427 10:40:32.177616 19076 trainer.py:136] Epoch[698/1000] loss: 0.06686371192336082
I0427 10:40:34.218512 19076 trainer.py:136] Epoch[699/1000] loss: 0.06755527233084042
I0427 10:40:34.385952 19076 trainer.py:142] Test: [{'precision': 0.13654155495978562, 'recall': 0.3223154733874653, 'hit_ratio': 0.8884718498659517, 'ndcg': 0.30413798216271576}]
I0427 10:40:36.421653 19076 trainer.py:136] Epoch[700/1000] loss: 0.06711145117878914
I0427 10:40:38.482573 19076 trainer.py:136] Epoch[701/1000] loss: 0.06746762121717136
I0427 10:40:40.603637 19076 trainer.py:136] Epoch[702/1000] loss: 0.06611050168673198
I0427 10:40:42.678505 19076 trainer.py:136] Epoch[703/1000] loss: 0.0658152736723423
I0427 10:40:44.792565 19076 trainer.py:136] Epoch[704/1000] loss: 0.06788670147458713
I0427 10:40:46.817973 19076 trainer.py:136] Epoch[705/1000] loss: 0.06764020770788193
I0427 10:40:48.965617 19076 trainer.py:136] Epoch[706/1000] loss: 0.06758587683240573
I0427 10:40:51.018869 19076 trainer.py:136] Epoch[707/1000] loss: 0.066946675380071
I0427 10:40:53.130958 19076 trainer.py:136] Epoch[708/1000] loss: 0.06756284708778064
I0427 10:40:55.251037 19076 trainer.py:136] Epoch[709/1000] loss: 0.06686358526349068
I0427 10:40:57.370886 19076 trainer.py:136] Epoch[710/1000] loss: 0.06609249425431092
I0427 10:40:59.397359 19076 trainer.py:136] Epoch[711/1000] loss: 0.0681475115319093
I0427 10:41:01.512945 19076 trainer.py:136] Epoch[712/1000] loss: 0.06620324154694875
I0427 10:41:03.661718 19076 trainer.py:136] Epoch[713/1000] loss: 0.06484347954392433
I0427 10:41:05.841231 19076 trainer.py:136] Epoch[714/1000] loss: 0.06663920109470685
I0427 10:41:07.926923 19076 trainer.py:136] Epoch[715/1000] loss: 0.06636112183332443
I0427 10:41:10.014592 19076 trainer.py:136] Epoch[716/1000] loss: 0.06716981157660484
I0427 10:41:12.072757 19076 trainer.py:136] Epoch[717/1000] loss: 0.06782995909452438
I0427 10:41:14.107900 19076 trainer.py:136] Epoch[718/1000] loss: 0.06629682332277298
I0427 10:41:16.191184 19076 trainer.py:136] Epoch[719/1000] loss: 0.06674689675370853
I0427 10:41:18.289322 19076 trainer.py:136] Epoch[720/1000] loss: 0.06665568550427754
I0427 10:41:20.258874 19076 trainer.py:136] Epoch[721/1000] loss: 0.06714026381572087
I0427 10:41:22.275358 19076 trainer.py:136] Epoch[722/1000] loss: 0.0671003262201945
I0427 10:41:24.370779 19076 trainer.py:136] Epoch[723/1000] loss: 0.06679781650503476
I0427 10:41:26.545840 19076 trainer.py:136] Epoch[724/1000] loss: 0.06684439008434613
I0427 10:41:28.652869 19076 trainer.py:136] Epoch[725/1000] loss: 0.06652821972966194
I0427 10:41:30.692905 19076 trainer.py:136] Epoch[726/1000] loss: 0.06554726262887318
I0427 10:41:32.865859 19076 trainer.py:136] Epoch[727/1000] loss: 0.06624638972183068
I0427 10:41:34.907533 19076 trainer.py:136] Epoch[728/1000] loss: 0.0646682692070802
I0427 10:41:37.017573 19076 trainer.py:136] Epoch[729/1000] loss: 0.06616699323058128
I0427 10:41:39.063703 19076 trainer.py:136] Epoch[730/1000] loss: 0.0663134182492892
I0427 10:41:41.156832 19076 trainer.py:136] Epoch[731/1000] loss: 0.06439712767799695
I0427 10:41:43.203963 19076 trainer.py:136] Epoch[732/1000] loss: 0.06811701878905296
I0427 10:41:45.295094 19076 trainer.py:136] Epoch[733/1000] loss: 0.06613984704017639
I0427 10:41:47.396525 19076 trainer.py:136] Epoch[734/1000] loss: 0.06542982285221417
I0427 10:41:49.415939 19076 trainer.py:136] Epoch[735/1000] loss: 0.06574670970439911
I0427 10:41:51.493744 19076 trainer.py:136] Epoch[736/1000] loss: 0.06559617320696513
I0427 10:41:53.574423 19076 trainer.py:136] Epoch[737/1000] loss: 0.06649105375011762
I0427 10:41:55.612972 19076 trainer.py:136] Epoch[738/1000] loss: 0.06419158602754275
I0427 10:41:57.741262 19076 trainer.py:136] Epoch[739/1000] loss: 0.06544575095176697
I0427 10:41:59.843932 19076 trainer.py:136] Epoch[740/1000] loss: 0.06503476140399773
I0427 10:42:02.125992 19076 trainer.py:136] Epoch[741/1000] loss: 0.06509946597119172
I0427 10:42:04.182814 19076 trainer.py:136] Epoch[742/1000] loss: 0.06519730451206367
I0427 10:42:06.241078 19076 trainer.py:136] Epoch[743/1000] loss: 0.06503080266217391
I0427 10:42:08.335259 19076 trainer.py:136] Epoch[744/1000] loss: 0.0656993892043829
I0427 10:42:10.509654 19076 trainer.py:136] Epoch[745/1000] loss: 0.0641814178476731
I0427 10:42:12.643121 19076 trainer.py:136] Epoch[746/1000] loss: 0.06525781999031703
I0427 10:42:14.773861 19076 trainer.py:136] Epoch[747/1000] loss: 0.06582956636945407
I0427 10:42:16.868247 19076 trainer.py:136] Epoch[748/1000] loss: 0.06494791929920514
I0427 10:42:18.965374 19076 trainer.py:136] Epoch[749/1000] loss: 0.064813365538915
I0427 10:42:19.108894 19076 trainer.py:142] Test: [{'precision': 0.13723860589812342, 'recall': 0.32382802823348494, 'hit_ratio': 0.8916890080428954, 'ndcg': 0.3057963094022319}]
I0427 10:42:21.141217 19076 trainer.py:136] Epoch[750/1000] loss: 0.06451657973229885
I0427 10:42:23.260223 19076 trainer.py:136] Epoch[751/1000] loss: 0.06580476711193721
I0427 10:42:25.306532 19076 trainer.py:136] Epoch[752/1000] loss: 0.06644220153490703
I0427 10:42:27.464864 19076 trainer.py:136] Epoch[753/1000] loss: 0.06505565345287323
I0427 10:42:29.631788 19076 trainer.py:136] Epoch[754/1000] loss: 0.06732096647222836
I0427 10:42:31.759515 19076 trainer.py:136] Epoch[755/1000] loss: 0.06562521557013194
I0427 10:42:33.899650 19076 trainer.py:136] Epoch[756/1000] loss: 0.06685130794843037
I0427 10:42:35.973048 19076 trainer.py:136] Epoch[757/1000] loss: 0.0658491247644027
I0427 10:42:38.071670 19076 trainer.py:136] Epoch[758/1000] loss: 0.06377274232606094
I0427 10:42:40.155271 19076 trainer.py:136] Epoch[759/1000] loss: 0.06590478867292404
I0427 10:42:42.236026 19076 trainer.py:136] Epoch[760/1000] loss: 0.06557718416055043
I0427 10:42:44.287574 19076 trainer.py:136] Epoch[761/1000] loss: 0.06485656276345253
I0427 10:42:46.410663 19076 trainer.py:136] Epoch[762/1000] loss: 0.06421319333215554
I0427 10:42:48.493416 19076 trainer.py:136] Epoch[763/1000] loss: 0.06501561589539051
I0427 10:42:50.691011 19076 trainer.py:136] Epoch[764/1000] loss: 0.06547083333134651
I0427 10:42:52.781156 19076 trainer.py:136] Epoch[765/1000] loss: 0.06403232862552007
I0427 10:42:54.936813 19076 trainer.py:136] Epoch[766/1000] loss: 0.06368885127206643
I0427 10:42:57.030014 19076 trainer.py:136] Epoch[767/1000] loss: 0.06405187460283439
I0427 10:42:59.173964 19076 trainer.py:136] Epoch[768/1000] loss: 0.06485764247675736
I0427 10:43:01.212374 19076 trainer.py:136] Epoch[769/1000] loss: 0.06362833206852277
I0427 10:43:03.360276 19076 trainer.py:136] Epoch[770/1000] loss: 0.06453919721146424
I0427 10:43:05.350035 19076 trainer.py:136] Epoch[771/1000] loss: 0.06482593963543574
I0427 10:43:07.462425 19076 trainer.py:136] Epoch[772/1000] loss: 0.06455256169040997
I0427 10:43:09.537869 19076 trainer.py:136] Epoch[773/1000] loss: 0.06395945387581985
I0427 10:43:11.604458 19076 trainer.py:136] Epoch[774/1000] loss: 0.06561086823542912
I0427 10:43:13.718635 19076 trainer.py:136] Epoch[775/1000] loss: 0.06527812406420708
I0427 10:43:15.851775 19076 trainer.py:136] Epoch[776/1000] loss: 0.06453301012516022
I0427 10:43:17.894936 19076 trainer.py:136] Epoch[777/1000] loss: 0.06424460684259732
I0427 10:43:19.951196 19076 trainer.py:136] Epoch[778/1000] loss: 0.06528215358654658
I0427 10:43:22.066598 19076 trainer.py:136] Epoch[779/1000] loss: 0.06457953775922458
I0427 10:43:24.197426 19076 trainer.py:136] Epoch[780/1000] loss: 0.06329437717795372
I0427 10:43:26.208533 19076 trainer.py:136] Epoch[781/1000] loss: 0.06378054494659106
I0427 10:43:28.353051 19076 trainer.py:136] Epoch[782/1000] loss: 0.0637151226401329
I0427 10:43:30.467776 19076 trainer.py:136] Epoch[783/1000] loss: 0.06597422311703365
I0427 10:43:32.522980 19076 trainer.py:136] Epoch[784/1000] loss: 0.06389240299661954
I0427 10:43:34.630049 19076 trainer.py:136] Epoch[785/1000] loss: 0.06375419658919175
I0427 10:43:36.630638 19076 trainer.py:136] Epoch[786/1000] loss: 0.0641498863697052
I0427 10:43:38.684931 19076 trainer.py:136] Epoch[787/1000] loss: 0.06409727906187375
I0427 10:43:40.768243 19076 trainer.py:136] Epoch[788/1000] loss: 0.06530143879354
I0427 10:43:42.929558 19076 trainer.py:136] Epoch[789/1000] loss: 0.06524361049135526
I0427 10:43:45.008628 19076 trainer.py:136] Epoch[790/1000] loss: 0.06310602029164632
I0427 10:43:47.083650 19076 trainer.py:136] Epoch[791/1000] loss: 0.06595787157615025
I0427 10:43:49.179764 19076 trainer.py:136] Epoch[792/1000] loss: 0.06591246152917545
I0427 10:43:51.283890 19076 trainer.py:136] Epoch[793/1000] loss: 0.06500714396437009
I0427 10:43:53.412187 19076 trainer.py:136] Epoch[794/1000] loss: 0.06302619973818462
I0427 10:43:55.598417 19076 trainer.py:136] Epoch[795/1000] loss: 0.06385752434531848
I0427 10:43:57.742380 19076 trainer.py:136] Epoch[796/1000] loss: 0.0622755978256464
I0427 10:43:59.860384 19076 trainer.py:136] Epoch[797/1000] loss: 0.06291127949953079
I0427 10:44:01.894795 19076 trainer.py:136] Epoch[798/1000] loss: 0.06395222619175911
I0427 10:44:03.985943 19076 trainer.py:136] Epoch[799/1000] loss: 0.06340846233069897
I0427 10:44:04.133450 19076 trainer.py:142] Test: [{'precision': 0.13718498659517436, 'recall': 0.3239927460700999, 'hit_ratio': 0.8895442359249329, 'ndcg': 0.3063444365272252}]
I0427 10:44:06.127887 19076 trainer.py:136] Epoch[800/1000] loss: 0.06323876169820626
I0427 10:44:08.207437 19076 trainer.py:136] Epoch[801/1000] loss: 0.06242461812992891
I0427 10:44:10.195957 19076 trainer.py:136] Epoch[802/1000] loss: 0.06415897731979688
I0427 10:44:12.277129 19076 trainer.py:136] Epoch[803/1000] loss: 0.0648129532734553
I0427 10:44:14.292569 19076 trainer.py:136] Epoch[804/1000] loss: 0.0639239785571893
I0427 10:44:16.432644 19076 trainer.py:136] Epoch[805/1000] loss: 0.06312624116738637
I0427 10:44:18.467305 19076 trainer.py:136] Epoch[806/1000] loss: 0.06396802514791489
I0427 10:44:20.563868 19076 trainer.py:136] Epoch[807/1000] loss: 0.06309578008949757
I0427 10:44:22.551378 19076 trainer.py:136] Epoch[808/1000] loss: 0.06355977741380532
I0427 10:44:24.660909 19076 trainer.py:136] Epoch[809/1000] loss: 0.06259651171664397
I0427 10:44:26.682249 19076 trainer.py:136] Epoch[810/1000] loss: 0.06599613403280576
I0427 10:44:28.760389 19076 trainer.py:136] Epoch[811/1000] loss: 0.06373178648451965
I0427 10:44:30.846864 19076 trainer.py:136] Epoch[812/1000] loss: 0.06518039852380753
I0427 10:44:32.969943 19076 trainer.py:136] Epoch[813/1000] loss: 0.06261893175542355
I0427 10:44:35.073028 19076 trainer.py:136] Epoch[814/1000] loss: 0.06458231930931409
I0427 10:44:37.136468 19076 trainer.py:136] Epoch[815/1000] loss: 0.06411374174058437
I0427 10:44:39.234597 19076 trainer.py:136] Epoch[816/1000] loss: 0.06286958294610183
I0427 10:44:41.269948 19076 trainer.py:136] Epoch[817/1000] loss: 0.0628899068882068
I0427 10:44:43.388845 19076 trainer.py:136] Epoch[818/1000] loss: 0.06551031271616618
I0427 10:44:45.504183 19076 trainer.py:136] Epoch[819/1000] loss: 0.06309789046645164
I0427 10:44:47.665129 19076 trainer.py:136] Epoch[820/1000] loss: 0.06286234719057877
I0427 10:44:49.742946 19076 trainer.py:136] Epoch[821/1000] loss: 0.06420158098141353
I0427 10:44:51.808195 19076 trainer.py:136] Epoch[822/1000] loss: 0.06315104477107525
I0427 10:44:53.931385 19076 trainer.py:136] Epoch[823/1000] loss: 0.06349020699659984
I0427 10:44:56.119514 19076 trainer.py:136] Epoch[824/1000] loss: 0.06378493954737981
I0427 10:44:58.162804 19076 trainer.py:136] Epoch[825/1000] loss: 0.06336855702102184
I0427 10:45:00.358586 19076 trainer.py:136] Epoch[826/1000] loss: 0.06297789079447587
I0427 10:45:02.448790 19076 trainer.py:136] Epoch[827/1000] loss: 0.06219377430776755
I0427 10:45:04.531727 19076 trainer.py:136] Epoch[828/1000] loss: 0.06287937425076962
I0427 10:45:06.564592 19076 trainer.py:136] Epoch[829/1000] loss: 0.06307704808811347
I0427 10:45:08.642895 19076 trainer.py:136] Epoch[830/1000] loss: 0.06305318946639697
I0427 10:45:10.694926 19076 trainer.py:136] Epoch[831/1000] loss: 0.06259690225124359
I0427 10:45:12.811975 19076 trainer.py:136] Epoch[832/1000] loss: 0.06334942765533924
I0427 10:45:14.841360 19076 trainer.py:136] Epoch[833/1000] loss: 0.06248963251709938
I0427 10:45:16.946422 19076 trainer.py:136] Epoch[834/1000] loss: 0.0623113177716732
I0427 10:45:18.986791 19076 trainer.py:136] Epoch[835/1000] loss: 0.06338176193336646
I0427 10:45:21.077989 19076 trainer.py:136] Epoch[836/1000] loss: 0.06425253301858902
I0427 10:45:23.101372 19076 trainer.py:136] Epoch[837/1000] loss: 0.06259510417779286
I0427 10:45:25.182077 19076 trainer.py:136] Epoch[838/1000] loss: 0.06270343251526356
I0427 10:45:27.265197 19076 trainer.py:136] Epoch[839/1000] loss: 0.06281354154149692
I0427 10:45:29.321270 19076 trainer.py:136] Epoch[840/1000] loss: 0.06293554914494355
I0427 10:45:31.463883 19076 trainer.py:136] Epoch[841/1000] loss: 0.06322440753380458
I0427 10:45:33.579638 19076 trainer.py:136] Epoch[842/1000] loss: 0.06376468203961849
I0427 10:45:35.707293 19076 trainer.py:136] Epoch[843/1000] loss: 0.061245363826553025
I0427 10:45:37.737527 19076 trainer.py:136] Epoch[844/1000] loss: 0.06326196963588397
I0427 10:45:39.879474 19076 trainer.py:136] Epoch[845/1000] loss: 0.06360858120024204
I0427 10:45:41.976638 19076 trainer.py:136] Epoch[846/1000] loss: 0.062335298086206116
I0427 10:45:44.051817 19076 trainer.py:136] Epoch[847/1000] loss: 0.06292733177542686
I0427 10:45:46.058253 19076 trainer.py:136] Epoch[848/1000] loss: 0.06190465266505877
I0427 10:45:48.187268 19076 trainer.py:136] Epoch[849/1000] loss: 0.061799572159846626
I0427 10:45:48.342747 19076 trainer.py:142] Test: [{'precision': 0.1375871313672923, 'recall': 0.3245642022471388, 'hit_ratio': 0.8906166219839142, 'ndcg': 0.307069404653585}]
I0427 10:45:50.377091 19076 trainer.py:136] Epoch[850/1000] loss: 0.06317955193420251
I0427 10:45:52.490705 19076 trainer.py:136] Epoch[851/1000] loss: 0.06127313959101836
I0427 10:45:54.592087 19076 trainer.py:136] Epoch[852/1000] loss: 0.06131204590201378
I0427 10:45:56.675045 19076 trainer.py:136] Epoch[853/1000] loss: 0.06047027868529161
I0427 10:45:58.743211 19076 trainer.py:136] Epoch[854/1000] loss: 0.0614255511512359
I0427 10:46:00.918039 19076 trainer.py:136] Epoch[855/1000] loss: 0.0626313096533219
I0427 10:46:03.050015 19076 trainer.py:136] Epoch[856/1000] loss: 0.06225130955378214
I0427 10:46:05.130351 19076 trainer.py:136] Epoch[857/1000] loss: 0.06209968154629072
I0427 10:46:07.147746 19076 trainer.py:136] Epoch[858/1000] loss: 0.0625783372670412
I0427 10:46:09.262848 19076 trainer.py:136] Epoch[859/1000] loss: 0.06104068271815777
I0427 10:46:11.360137 19076 trainer.py:136] Epoch[860/1000] loss: 0.0636076567073663
I0427 10:46:13.472520 19076 trainer.py:136] Epoch[861/1000] loss: 0.06179920583963394
I0427 10:46:15.544715 19076 trainer.py:136] Epoch[862/1000] loss: 0.06075716701646646
I0427 10:46:17.684715 19076 trainer.py:136] Epoch[863/1000] loss: 0.06309020519256592
I0427 10:46:19.766165 19076 trainer.py:136] Epoch[864/1000] loss: 0.061625080183148384
I0427 10:46:21.893901 19076 trainer.py:136] Epoch[865/1000] loss: 0.06103299061457316
I0427 10:46:23.928229 19076 trainer.py:136] Epoch[866/1000] loss: 0.06186811812222004
I0427 10:46:26.017493 19076 trainer.py:136] Epoch[867/1000] loss: 0.061219872906804085
I0427 10:46:28.171595 19076 trainer.py:136] Epoch[868/1000] loss: 0.059798398365577064
I0427 10:46:30.276248 19076 trainer.py:136] Epoch[869/1000] loss: 0.062057926009098686
I0427 10:46:32.472707 19076 trainer.py:136] Epoch[870/1000] loss: 0.06125721583763758
I0427 10:46:34.594574 19076 trainer.py:136] Epoch[871/1000] loss: 0.06030230472485224
I0427 10:46:36.731004 19076 trainer.py:136] Epoch[872/1000] loss: 0.061816208685437836
I0427 10:46:38.880931 19076 trainer.py:136] Epoch[873/1000] loss: 0.061867990220586457
I0427 10:46:40.920973 19076 trainer.py:136] Epoch[874/1000] loss: 0.06259677559137344
I0427 10:46:42.960273 19076 trainer.py:136] Epoch[875/1000] loss: 0.061165926357110344
I0427 10:46:45.057357 19076 trainer.py:136] Epoch[876/1000] loss: 0.06246298489471277
I0427 10:46:47.144260 19076 trainer.py:136] Epoch[877/1000] loss: 0.06076421091953913
I0427 10:46:49.334020 19076 trainer.py:136] Epoch[878/1000] loss: 0.06169056768218676
I0427 10:46:51.408204 19076 trainer.py:136] Epoch[879/1000] loss: 0.061952811355392136
I0427 10:46:53.474783 19076 trainer.py:136] Epoch[880/1000] loss: 0.06133523148794969
I0427 10:46:55.529904 19076 trainer.py:136] Epoch[881/1000] loss: 0.06139651002983252
I0427 10:46:57.648926 19076 trainer.py:136] Epoch[882/1000] loss: 0.062207174797852836
I0427 10:46:59.811152 19076 trainer.py:136] Epoch[883/1000] loss: 0.061611625055472054
I0427 10:47:01.999093 19076 trainer.py:136] Epoch[884/1000] loss: 0.062172784159580864
I0427 10:47:04.048630 19076 trainer.py:136] Epoch[885/1000] loss: 0.061721651504437126
I0427 10:47:06.132794 19076 trainer.py:136] Epoch[886/1000] loss: 0.061578513433535896
I0427 10:47:08.116286 19076 trainer.py:136] Epoch[887/1000] loss: 0.061036162078380585
I0427 10:47:10.251379 19076 trainer.py:136] Epoch[888/1000] loss: 0.061635044092933335
I0427 10:47:12.232075 19076 trainer.py:136] Epoch[889/1000] loss: 0.061259943371017776
I0427 10:47:14.371329 19076 trainer.py:136] Epoch[890/1000] loss: 0.06025979667901993
I0427 10:47:16.383470 19076 trainer.py:136] Epoch[891/1000] loss: 0.060876072073976197
I0427 10:47:18.439034 19076 trainer.py:136] Epoch[892/1000] loss: 0.06013272516429424
I0427 10:47:20.466994 19076 trainer.py:136] Epoch[893/1000] loss: 0.061484917998313904
I0427 10:47:22.535254 19076 trainer.py:136] Epoch[894/1000] loss: 0.060386533538500466
I0427 10:47:24.578079 19076 trainer.py:136] Epoch[895/1000] loss: 0.06268999228874843
I0427 10:47:26.656303 19076 trainer.py:136] Epoch[896/1000] loss: 0.06087563373148441
I0427 10:47:28.712359 19076 trainer.py:136] Epoch[897/1000] loss: 0.061258394892017044
I0427 10:47:30.878293 19076 trainer.py:136] Epoch[898/1000] loss: 0.05960312175254027
I0427 10:47:32.956350 19076 trainer.py:136] Epoch[899/1000] loss: 0.060150522738695145
I0427 10:47:33.114819 19076 trainer.py:142] Test: [{'precision': 0.13772117962466499, 'recall': 0.3250259398646878, 'hit_ratio': 0.8932975871313673, 'ndcg': 0.3078763149787194}]
I0427 10:47:35.165073 19076 trainer.py:136] Epoch[900/1000] loss: 0.061748254423340164
I0427 10:47:37.381622 19076 trainer.py:136] Epoch[901/1000] loss: 0.0629392396658659
I0427 10:47:39.439996 19076 trainer.py:136] Epoch[902/1000] loss: 0.06143303029239178
I0427 10:47:41.610403 19076 trainer.py:136] Epoch[903/1000] loss: 0.06032363511621952
I0427 10:47:43.665340 19076 trainer.py:136] Epoch[904/1000] loss: 0.06103372201323509
I0427 10:47:45.761907 19076 trainer.py:136] Epoch[905/1000] loss: 0.06102265045046806
I0427 10:47:47.757350 19076 trainer.py:136] Epoch[906/1000] loss: 0.06106948790450891
I0427 10:47:49.851495 19076 trainer.py:136] Epoch[907/1000] loss: 0.05952357438703378
I0427 10:47:51.884583 19076 trainer.py:136] Epoch[908/1000] loss: 0.0611242080728213
I0427 10:47:54.039042 19076 trainer.py:136] Epoch[909/1000] loss: 0.061556645358602204
I0427 10:47:56.023672 19076 trainer.py:136] Epoch[910/1000] loss: 0.05991834526260694
I0427 10:47:58.126627 19076 trainer.py:136] Epoch[911/1000] loss: 0.06187329130868117
I0427 10:48:00.202607 19076 trainer.py:136] Epoch[912/1000] loss: 0.06112913725276788
I0427 10:48:02.353551 19076 trainer.py:136] Epoch[913/1000] loss: 0.06187366073330244
I0427 10:48:04.378887 19076 trainer.py:136] Epoch[914/1000] loss: 0.06079608636597792
I0427 10:48:06.498108 19076 trainer.py:136] Epoch[915/1000] loss: 0.05942752088109652
I0427 10:48:08.475289 19076 trainer.py:136] Epoch[916/1000] loss: 0.06193068064749241
I0427 10:48:10.620849 19076 trainer.py:136] Epoch[917/1000] loss: 0.061480470622579254
I0427 10:48:12.775806 19076 trainer.py:136] Epoch[918/1000] loss: 0.06141825268665949
I0427 10:48:14.881855 19076 trainer.py:136] Epoch[919/1000] loss: 0.059862238044540085
I0427 10:48:16.981520 19076 trainer.py:136] Epoch[920/1000] loss: 0.06100606173276901
I0427 10:48:19.110804 19076 trainer.py:136] Epoch[921/1000] loss: 0.0622772133598725
I0427 10:48:21.203956 19076 trainer.py:136] Epoch[922/1000] loss: 0.06272235574821632
I0427 10:48:23.283831 19076 trainer.py:136] Epoch[923/1000] loss: 0.059768332789341606
I0427 10:48:25.342287 19076 trainer.py:136] Epoch[924/1000] loss: 0.061305684968829155
I0427 10:48:27.492696 19076 trainer.py:136] Epoch[925/1000] loss: 0.06185130029916763
I0427 10:48:29.596815 19076 trainer.py:136] Epoch[926/1000] loss: 0.06066284887492657
I0427 10:48:31.692139 19076 trainer.py:136] Epoch[927/1000] loss: 0.060652974992990494
I0427 10:48:33.750034 19076 trainer.py:136] Epoch[928/1000] loss: 0.05960056371986866
I0427 10:48:35.888041 19076 trainer.py:136] Epoch[929/1000] loss: 0.060971579824884735
I0427 10:48:37.967217 19076 trainer.py:136] Epoch[930/1000] loss: 0.05977115469674269
I0427 10:48:40.034410 19076 trainer.py:136] Epoch[931/1000] loss: 0.06068275993069013
I0427 10:48:42.074806 19076 trainer.py:136] Epoch[932/1000] loss: 0.06070973599950472
I0427 10:48:44.104194 19076 trainer.py:136] Epoch[933/1000] loss: 0.060469950859745346
I0427 10:48:46.222232 19076 trainer.py:136] Epoch[934/1000] loss: 0.05994455267985662
I0427 10:48:48.208812 19076 trainer.py:136] Epoch[935/1000] loss: 0.06179158575832844
I0427 10:48:50.309983 19076 trainer.py:136] Epoch[936/1000] loss: 0.06072048656642437
I0427 10:48:52.296060 19076 trainer.py:136] Epoch[937/1000] loss: 0.05972231552004814
I0427 10:48:54.426155 19076 trainer.py:136] Epoch[938/1000] loss: 0.06135507673025131
I0427 10:48:56.495058 19076 trainer.py:136] Epoch[939/1000] loss: 0.060606539249420166
I0427 10:48:58.565621 19076 trainer.py:136] Epoch[940/1000] loss: 0.06071909020344416
I0427 10:49:00.676697 19076 trainer.py:136] Epoch[941/1000] loss: 0.060139093548059464
I0427 10:49:02.818339 19076 trainer.py:136] Epoch[942/1000] loss: 0.061221920574704804
I0427 10:49:04.921068 19076 trainer.py:136] Epoch[943/1000] loss: 0.06018745402495066
I0427 10:49:07.031165 19076 trainer.py:136] Epoch[944/1000] loss: 0.06022763376434644
I0427 10:49:09.063581 19076 trainer.py:136] Epoch[945/1000] loss: 0.05997824793060621
I0427 10:49:11.196614 19076 trainer.py:136] Epoch[946/1000] loss: 0.06013137040038904
I0427 10:49:13.264833 19076 trainer.py:136] Epoch[947/1000] loss: 0.05955447691182295
I0427 10:49:15.332082 19076 trainer.py:136] Epoch[948/1000] loss: 0.06047673150897026
I0427 10:49:17.341278 19076 trainer.py:136] Epoch[949/1000] loss: 0.059349107866485916
I0427 10:49:17.497324 19076 trainer.py:142] Test: [{'precision': 0.13839142091152826, 'recall': 0.32687495918019505, 'hit_ratio': 0.8949061662198391, 'ndcg': 0.3086182909032014}]
I0427 10:49:19.544633 19076 trainer.py:136] Epoch[950/1000] loss: 0.0616251261283954
I0427 10:49:21.574961 19076 trainer.py:136] Epoch[951/1000] loss: 0.05905779389043649
I0427 10:49:23.639710 19076 trainer.py:136] Epoch[952/1000] loss: 0.05882133170962334
I0427 10:49:25.684075 19076 trainer.py:136] Epoch[953/1000] loss: 0.061280506973465286
I0427 10:49:27.777209 19076 trainer.py:136] Epoch[954/1000] loss: 0.06057221256196499
I0427 10:49:29.869364 19076 trainer.py:136] Epoch[955/1000] loss: 0.06055968999862671
I0427 10:49:31.978040 19076 trainer.py:136] Epoch[956/1000] loss: 0.060252598176399864
I0427 10:49:34.105018 19076 trainer.py:136] Epoch[957/1000] loss: 0.05946884428461393
I0427 10:49:36.019768 19076 trainer.py:136] Epoch[958/1000] loss: 0.060024707267681755
I0427 10:49:38.051127 19076 trainer.py:136] Epoch[959/1000] loss: 0.06005700553456942
I0427 10:49:40.061585 19076 trainer.py:136] Epoch[960/1000] loss: 0.05862160647908846
I0427 10:49:42.158841 19076 trainer.py:136] Epoch[961/1000] loss: 0.06063104296724001
I0427 10:49:44.188591 19076 trainer.py:136] Epoch[962/1000] loss: 0.059284295265873276
I0427 10:49:46.248870 19076 trainer.py:136] Epoch[963/1000] loss: 0.05948072858154774
I0427 10:49:48.302187 19076 trainer.py:136] Epoch[964/1000] loss: 0.059500359619657196
I0427 10:49:50.337508 19076 trainer.py:136] Epoch[965/1000] loss: 0.05932727890710036
I0427 10:49:52.324982 19076 trainer.py:136] Epoch[966/1000] loss: 0.06196000054478645
I0427 10:49:54.400172 19076 trainer.py:136] Epoch[967/1000] loss: 0.06012085204323133
I0427 10:49:56.456857 19076 trainer.py:136] Epoch[968/1000] loss: 0.05822649225592613
I0427 10:49:58.578438 19076 trainer.py:136] Epoch[969/1000] loss: 0.06049389081696669
I0427 10:50:00.629054 19076 trainer.py:136] Epoch[970/1000] loss: 0.06021086437006792
I0427 10:50:02.772082 19076 trainer.py:136] Epoch[971/1000] loss: 0.06115008952716986
I0427 10:50:04.784106 19076 trainer.py:136] Epoch[972/1000] loss: 0.05897760080794493
I0427 10:50:06.880839 19076 trainer.py:136] Epoch[973/1000] loss: 0.05908720505734285
I0427 10:50:08.881564 19076 trainer.py:136] Epoch[974/1000] loss: 0.05903547195096811
I0427 10:50:10.919041 19076 trainer.py:136] Epoch[975/1000] loss: 0.05919277295470238
I0427 10:50:13.033163 19076 trainer.py:136] Epoch[976/1000] loss: 0.058871286610762276
I0427 10:50:15.111979 19076 trainer.py:136] Epoch[977/1000] loss: 0.05882298822204272
I0427 10:50:17.198219 19076 trainer.py:136] Epoch[978/1000] loss: 0.05937223881483078
I0427 10:50:19.258573 19076 trainer.py:136] Epoch[979/1000] loss: 0.06030235749979814
I0427 10:50:21.331776 19076 trainer.py:136] Epoch[980/1000] loss: 0.0604000190893809
I0427 10:50:23.406992 19076 trainer.py:136] Epoch[981/1000] loss: 0.06032868350545565
I0427 10:50:25.481817 19076 trainer.py:136] Epoch[982/1000] loss: 0.0606257418791453
I0427 10:50:27.566001 19076 trainer.py:136] Epoch[983/1000] loss: 0.06004838397105535
I0427 10:50:30.014456 19076 trainer.py:136] Epoch[984/1000] loss: 0.05963096581399441
I0427 10:50:32.102081 19076 trainer.py:136] Epoch[985/1000] loss: 0.05995612094799677
I0427 10:50:34.304964 19076 trainer.py:136] Epoch[986/1000] loss: 0.06033908575773239
I0427 10:50:36.397133 19076 trainer.py:136] Epoch[987/1000] loss: 0.06006514964004358
I0427 10:50:38.527837 19076 trainer.py:136] Epoch[988/1000] loss: 0.05780647632976373
I0427 10:50:40.597702 19076 trainer.py:136] Epoch[989/1000] loss: 0.05850451439619064
I0427 10:50:42.682908 19076 trainer.py:136] Epoch[990/1000] loss: 0.059069400653243065
I0427 10:50:44.750125 19076 trainer.py:136] Epoch[991/1000] loss: 0.057185026506582894
I0427 10:50:46.815420 19076 trainer.py:136] Epoch[992/1000] loss: 0.05957290343940258
I0427 10:50:48.825897 19076 trainer.py:136] Epoch[993/1000] loss: 0.058927382032076515
I0427 10:50:51.044615 19076 trainer.py:136] Epoch[994/1000] loss: 0.05862591229379177
I0427 10:50:53.143743 19076 trainer.py:136] Epoch[995/1000] loss: 0.05972011387348175
I0427 10:50:55.214960 19076 trainer.py:136] Epoch[996/1000] loss: 0.05948935511211554
I0427 10:50:57.335945 19076 trainer.py:136] Epoch[997/1000] loss: 0.05995818041265011
I0427 10:50:59.647232 19076 trainer.py:136] Epoch[998/1000] loss: 0.05878315679728985
I0427 10:51:01.803144 19076 trainer.py:136] Epoch[999/1000] loss: 0.06123793808122476
I0427 10:51:01.951647 19076 trainer.py:142] Test: [{'precision': 0.1383646112600537, 'recall': 0.32713355127761384, 'hit_ratio': 0.8954423592493298, 'ndcg': 0.3086529936706675}]
