I0803 10:50:34.636679 14832 trainer.py:119] Test: [{'precision': 0.05913188647746247, 'recall': 0.056718464665997684, 'hit_ratio': 0.4721202003338898, 'ndcg': 0.07775564885268987}]
I0803 10:50:50.230571 14832 trainer.py:139] Epoch[0/1000] loss: 0.5652656182646751
I0803 10:51:05.643800 14832 trainer.py:139] Epoch[1/1000] loss: 0.4574991185218096
I0803 10:51:21.550398 14832 trainer.py:139] Epoch[2/1000] loss: 0.42963901720941067
I0803 10:51:37.580018 14832 trainer.py:139] Epoch[3/1000] loss: 0.4254154469817877
I0803 10:51:53.617442 14832 trainer.py:139] Epoch[4/1000] loss: 0.4246191829442978
I0803 10:52:09.267735 14832 trainer.py:139] Epoch[5/1000] loss: 0.4228103645145893
I0803 10:52:25.558075 14832 trainer.py:139] Epoch[6/1000] loss: 0.41945398040115833
I0803 10:52:41.584252 14832 trainer.py:139] Epoch[7/1000] loss: 0.41383164562284946
I0803 10:52:57.351395 14832 trainer.py:139] Epoch[8/1000] loss: 0.4143731128424406
I0803 10:53:13.370178 14832 trainer.py:139] Epoch[9/1000] loss: 0.4068464059382677
I0803 10:53:29.729055 14832 trainer.py:139] Epoch[10/1000] loss: 0.4035140462219715
I0803 10:53:46.737159 14832 trainer.py:139] Epoch[11/1000] loss: 0.3982483558356762
I0803 10:54:02.730301 14832 trainer.py:139] Epoch[12/1000] loss: 0.39154442958533764
I0803 10:54:18.972406 14832 trainer.py:139] Epoch[13/1000] loss: 0.387147881090641
I0803 10:54:35.377396 14832 trainer.py:139] Epoch[14/1000] loss: 0.38435520604252815
I0803 10:54:51.962813 14832 trainer.py:139] Epoch[15/1000] loss: 0.3824655693024397
I0803 10:55:09.021281 14832 trainer.py:139] Epoch[16/1000] loss: 0.38062312081456184
I0803 10:55:25.396903 14832 trainer.py:139] Epoch[17/1000] loss: 0.3782010618597269
I0803 10:55:41.893238 14832 trainer.py:139] Epoch[18/1000] loss: 0.37765851244330406
I0803 10:55:58.305262 14832 trainer.py:139] Epoch[19/1000] loss: 0.3721122369170189
I0803 10:56:14.333588 14832 trainer.py:139] Epoch[20/1000] loss: 0.370513416826725
I0803 10:56:31.075052 14832 trainer.py:139] Epoch[21/1000] loss: 0.37082567624747753
I0803 10:56:47.518709 14832 trainer.py:139] Epoch[22/1000] loss: 0.36972582153975964
I0803 10:57:04.095598 14832 trainer.py:139] Epoch[23/1000] loss: 0.3673107586801052
I0803 10:57:20.100437 14832 trainer.py:139] Epoch[24/1000] loss: 0.36362770199775696
I0803 10:57:36.309941 14832 trainer.py:139] Epoch[25/1000] loss: 0.36460681073367596
I0803 10:57:52.398161 14832 trainer.py:139] Epoch[26/1000] loss: 0.3613896742463112
I0803 10:58:08.754472 14832 trainer.py:139] Epoch[27/1000] loss: 0.3587226439267397
I0803 10:58:24.868103 14832 trainer.py:139] Epoch[28/1000] loss: 0.35896385461091995
I0803 10:58:40.958747 14832 trainer.py:139] Epoch[29/1000] loss: 0.35870698653161526
I0803 10:58:56.601813 14832 trainer.py:139] Epoch[30/1000] loss: 0.35491846688091755
I0803 10:59:12.653146 14832 trainer.py:139] Epoch[31/1000] loss: 0.3545229472219944
I0803 10:59:28.943075 14832 trainer.py:139] Epoch[32/1000] loss: 0.35147557966411114
I0803 10:59:45.185496 14832 trainer.py:139] Epoch[33/1000] loss: 0.3500287290662527
I0803 11:00:01.140057 14832 trainer.py:139] Epoch[34/1000] loss: 0.34948817640542984
I0803 11:00:17.224090 14832 trainer.py:139] Epoch[35/1000] loss: 0.34821514040231705
I0803 11:00:33.576072 14832 trainer.py:139] Epoch[36/1000] loss: 0.3474808856844902
I0803 11:00:49.296909 14832 trainer.py:139] Epoch[37/1000] loss: 0.3427587263286114
I0803 11:01:05.318144 14832 trainer.py:139] Epoch[38/1000] loss: 0.34468622505664825
I0803 11:01:21.306752 14832 trainer.py:139] Epoch[39/1000] loss: 0.3413462210446596
I0803 11:01:37.032011 14832 trainer.py:139] Epoch[40/1000] loss: 0.33985722810029984
I0803 11:01:53.655560 14832 trainer.py:139] Epoch[41/1000] loss: 0.336614765226841
I0803 11:02:09.763014 14832 trainer.py:139] Epoch[42/1000] loss: 0.3362199179828167
I0803 11:02:26.414415 14832 trainer.py:139] Epoch[43/1000] loss: 0.33737885020673275
I0803 11:02:42.674743 14832 trainer.py:139] Epoch[44/1000] loss: 0.33224955946207047
I0803 11:02:59.150038 14832 trainer.py:139] Epoch[45/1000] loss: 0.3317537512630224
I0803 11:03:15.410874 14832 trainer.py:139] Epoch[46/1000] loss: 0.3307427242398262
I0803 11:03:31.686645 14832 trainer.py:139] Epoch[47/1000] loss: 0.3294023685157299
I0803 11:03:47.818488 14832 trainer.py:139] Epoch[48/1000] loss: 0.32792431116104126
I0803 11:04:03.893699 14832 trainer.py:139] Epoch[49/1000] loss: 0.3260754216462374
I0803 11:04:04.604322 14832 trainer.py:145] Test: [{'precision': 0.16200333889816365, 'recall': 0.21589274055458887, 'hit_ratio': 0.8495826377295492, 'ndcg': 0.24722305258134625}]
I0803 11:04:20.774483 14832 trainer.py:139] Epoch[50/1000] loss: 0.3267837781459093
I0803 11:04:36.658586 14832 trainer.py:139] Epoch[51/1000] loss: 0.32328906282782555
I0803 11:04:53.129253 14832 trainer.py:139] Epoch[52/1000] loss: 0.323242275044322
I0803 11:05:09.680843 14832 trainer.py:139] Epoch[53/1000] loss: 0.32281454280018806
I0803 11:05:25.834687 14832 trainer.py:139] Epoch[54/1000] loss: 0.32087581045925617
I0803 11:05:42.327702 14832 trainer.py:139] Epoch[55/1000] loss: 0.3183116465806961
I0803 11:05:58.393338 14832 trainer.py:139] Epoch[56/1000] loss: 0.31631679832935333
I0803 11:06:14.523617 14832 trainer.py:139] Epoch[57/1000] loss: 0.318259684368968
I0803 11:06:30.546855 14832 trainer.py:139] Epoch[58/1000] loss: 0.3156976029276848
I0803 11:06:46.610656 14832 trainer.py:139] Epoch[59/1000] loss: 0.31317093409597874
I0803 11:07:02.448148 14832 trainer.py:139] Epoch[60/1000] loss: 0.31273212283849716
I0803 11:07:18.405762 14832 trainer.py:139] Epoch[61/1000] loss: 0.3123537451028824
I0803 11:07:34.383023 14832 trainer.py:139] Epoch[62/1000] loss: 0.31151795759797096
I0803 11:07:50.254399 14832 trainer.py:139] Epoch[63/1000] loss: 0.3091730419546366
I0803 11:08:06.302740 14832 trainer.py:139] Epoch[64/1000] loss: 0.30862200632691383
I0803 11:08:22.604103 14832 trainer.py:139] Epoch[65/1000] loss: 0.30828974582254887
I0803 11:08:38.804278 14832 trainer.py:139] Epoch[66/1000] loss: 0.3076443374156952
I0803 11:08:55.078836 14832 trainer.py:139] Epoch[67/1000] loss: 0.30538562685251236
I0803 11:09:11.353220 14832 trainer.py:139] Epoch[68/1000] loss: 0.30503263510763645
I0803 11:09:27.629801 14832 trainer.py:139] Epoch[69/1000] loss: 0.3045377004891634
I0803 11:09:44.104530 14832 trainer.py:139] Epoch[70/1000] loss: 0.3027347791939974
I0803 11:10:00.182149 14832 trainer.py:139] Epoch[71/1000] loss: 0.30380188673734665
I0803 11:10:16.200039 14832 trainer.py:139] Epoch[72/1000] loss: 0.30225467309355736
I0803 11:10:32.304728 14832 trainer.py:139] Epoch[73/1000] loss: 0.3003492224961519
I0803 11:10:48.285277 14832 trainer.py:139] Epoch[74/1000] loss: 0.2990196570754051
I0803 11:11:04.472646 14832 trainer.py:139] Epoch[75/1000] loss: 0.2977685425430536
I0803 11:11:20.847972 14832 trainer.py:139] Epoch[76/1000] loss: 0.2980576455593109
I0803 11:11:37.514818 14832 trainer.py:139] Epoch[77/1000] loss: 0.29586294665932655
I0803 11:11:53.773018 14832 trainer.py:139] Epoch[78/1000] loss: 0.2941345665603876
I0803 11:12:09.914857 14832 trainer.py:139] Epoch[79/1000] loss: 0.2935927286744118
I0803 11:12:25.896346 14832 trainer.py:139] Epoch[80/1000] loss: 0.29485533758997917
I0803 11:12:41.836071 14832 trainer.py:139] Epoch[81/1000] loss: 0.2926169503480196
I0803 11:12:58.053408 14832 trainer.py:139] Epoch[82/1000] loss: 0.2911083698272705
I0803 11:13:14.028973 14832 trainer.py:139] Epoch[83/1000] loss: 0.29249830543994904
I0803 11:13:29.817760 14832 trainer.py:139] Epoch[84/1000] loss: 0.2909447532147169
I0803 11:13:45.880793 14832 trainer.py:139] Epoch[85/1000] loss: 0.28842115215957165
I0803 11:14:02.035760 14832 trainer.py:139] Epoch[86/1000] loss: 0.28932845033705235
I0803 11:14:18.479083 14832 trainer.py:139] Epoch[87/1000] loss: 0.28921340592205524
I0803 11:14:34.457842 14832 trainer.py:139] Epoch[88/1000] loss: 0.28733838349580765
I0803 11:14:50.725172 14832 trainer.py:139] Epoch[89/1000] loss: 0.2849129196256399
I0803 11:15:06.665176 14832 trainer.py:139] Epoch[90/1000] loss: 0.28572792559862137
I0803 11:15:22.940890 14832 trainer.py:139] Epoch[91/1000] loss: 0.28491769172251225
I0803 11:15:38.989960 14832 trainer.py:139] Epoch[92/1000] loss: 0.2834362592548132
I0803 11:15:54.980431 14832 trainer.py:139] Epoch[93/1000] loss: 0.28345091827213764
I0803 11:16:10.911193 14832 trainer.py:139] Epoch[94/1000] loss: 0.283348610624671
I0803 11:16:27.334767 14832 trainer.py:139] Epoch[95/1000] loss: 0.2810326647013426
I0803 11:16:43.493649 14832 trainer.py:139] Epoch[96/1000] loss: 0.28161579743027687
I0803 11:16:59.414426 14832 trainer.py:139] Epoch[97/1000] loss: 0.2792826443910599
I0803 11:17:15.304299 14832 trainer.py:139] Epoch[98/1000] loss: 0.27857195772230625
I0803 11:17:31.648192 14832 trainer.py:139] Epoch[99/1000] loss: 0.2799903657287359
I0803 11:17:32.236753 14832 trainer.py:145] Test: [{'precision': 0.17383138564273787, 'recall': 0.23936700256427373, 'hit_ratio': 0.8754590984974958, 'ndcg': 0.26915417334239794}]
I0803 11:17:48.098911 14832 trainer.py:139] Epoch[100/1000] loss: 0.2782493680715561
I0803 11:18:04.183651 14832 trainer.py:139] Epoch[101/1000] loss: 0.27688009291887283
I0803 11:18:20.137094 14832 trainer.py:139] Epoch[102/1000] loss: 0.27599187567830086
I0803 11:18:36.282301 14832 trainer.py:139] Epoch[103/1000] loss: 0.2752568330615759
I0803 11:18:52.152560 14832 trainer.py:139] Epoch[104/1000] loss: 0.27592264488339424
I0803 11:19:08.336299 14832 trainer.py:139] Epoch[105/1000] loss: 0.27488114684820175
I0803 11:19:25.192698 14832 trainer.py:139] Epoch[106/1000] loss: 0.27309285663068295
I0803 11:19:41.770323 14832 trainer.py:139] Epoch[107/1000] loss: 0.2734387870877981
I0803 11:19:58.562671 14832 trainer.py:139] Epoch[108/1000] loss: 0.2726935688406229
I0803 11:20:14.862575 14832 trainer.py:139] Epoch[109/1000] loss: 0.27086166478693485
I0803 11:20:30.913142 14832 trainer.py:139] Epoch[110/1000] loss: 0.2704992610961199
I0803 11:20:46.803808 14832 trainer.py:139] Epoch[111/1000] loss: 0.2699870467185974
I0803 11:21:02.794314 14832 trainer.py:139] Epoch[112/1000] loss: 0.2702781781554222
I0803 11:21:19.055416 14832 trainer.py:139] Epoch[113/1000] loss: 0.27005356922745705
I0803 11:21:34.906275 14832 trainer.py:139] Epoch[114/1000] loss: 0.27065110206604004
I0803 11:21:51.004979 14832 trainer.py:139] Epoch[115/1000] loss: 0.26897388882935047
I0803 11:22:07.309181 14832 trainer.py:139] Epoch[116/1000] loss: 0.2690794635564089
I0803 11:22:23.130934 14832 trainer.py:139] Epoch[117/1000] loss: 0.2681300025433302
I0803 11:22:39.433145 14832 trainer.py:139] Epoch[118/1000] loss: 0.2664890792220831
I0803 11:22:55.507200 14832 trainer.py:139] Epoch[119/1000] loss: 0.2659242805093527
I0803 11:23:11.476852 14832 trainer.py:139] Epoch[120/1000] loss: 0.26611123979091644
I0803 11:23:27.754256 14832 trainer.py:139] Epoch[121/1000] loss: 0.26516885869205
I0803 11:23:43.926984 14832 trainer.py:139] Epoch[122/1000] loss: 0.26557685248553753
I0803 11:24:00.036189 14832 trainer.py:139] Epoch[123/1000] loss: 0.26373534835875034
I0803 11:24:16.333786 14832 trainer.py:139] Epoch[124/1000] loss: 0.26454671286046505
I0803 11:24:32.360078 14832 trainer.py:139] Epoch[125/1000] loss: 0.26316003128886223
I0803 11:24:48.368265 14832 trainer.py:139] Epoch[126/1000] loss: 0.2623969800770283
I0803 11:25:04.206216 14832 trainer.py:139] Epoch[127/1000] loss: 0.2622227165848017
I0803 11:25:20.313331 14832 trainer.py:139] Epoch[128/1000] loss: 0.26130547374486923
I0803 11:25:36.480063 14832 trainer.py:139] Epoch[129/1000] loss: 0.2615924123674631
I0803 11:25:52.483321 14832 trainer.py:139] Epoch[130/1000] loss: 0.2604299560189247
I0803 11:26:08.786154 14832 trainer.py:139] Epoch[131/1000] loss: 0.2604193054139614
I0803 11:26:25.312816 14832 trainer.py:139] Epoch[132/1000] loss: 0.25937157683074474
I0803 11:26:41.474217 14832 trainer.py:139] Epoch[133/1000] loss: 0.25976050458848476
I0803 11:26:57.796260 14832 trainer.py:139] Epoch[134/1000] loss: 0.25869494304060936
I0803 11:27:14.039940 14832 trainer.py:139] Epoch[135/1000] loss: 0.2566225007176399
I0803 11:27:30.299148 14832 trainer.py:139] Epoch[136/1000] loss: 0.25778712145984173
I0803 11:27:46.625062 14832 trainer.py:139] Epoch[137/1000] loss: 0.25619927421212196
I0803 11:28:02.974940 14832 trainer.py:139] Epoch[138/1000] loss: 0.2568097375333309
I0803 11:28:19.117595 14832 trainer.py:139] Epoch[139/1000] loss: 0.2563587389886379
I0803 11:28:35.009663 14832 trainer.py:139] Epoch[140/1000] loss: 0.2564317751675844
I0803 11:28:51.149278 14832 trainer.py:139] Epoch[141/1000] loss: 0.2569059291854501
I0803 11:29:06.944108 14832 trainer.py:139] Epoch[142/1000] loss: 0.2548152431845665
I0803 11:29:23.283345 14832 trainer.py:139] Epoch[143/1000] loss: 0.2553466809913516
I0803 11:29:39.935907 14832 trainer.py:139] Epoch[144/1000] loss: 0.255199009552598
I0803 11:29:55.914748 14832 trainer.py:139] Epoch[145/1000] loss: 0.2544298190623522
I0803 11:30:11.649738 14832 trainer.py:139] Epoch[146/1000] loss: 0.25263097137212753
I0803 11:30:27.900526 14832 trainer.py:139] Epoch[147/1000] loss: 0.2540200548246503
I0803 11:30:44.279672 14832 trainer.py:139] Epoch[148/1000] loss: 0.2538698064163327
I0803 11:31:00.254078 14832 trainer.py:139] Epoch[149/1000] loss: 0.25259396992623806
I0803 11:31:00.845636 14832 trainer.py:145] Test: [{'precision': 0.1813439065108514, 'recall': 0.2522179296456537, 'hit_ratio': 0.887813021702838, 'ndcg': 0.2816374747489838}]
I0803 11:31:16.571455 14832 trainer.py:139] Epoch[150/1000] loss: 0.25150170736014843
I0803 11:31:32.535973 14832 trainer.py:139] Epoch[151/1000] loss: 0.251521329395473
I0803 11:31:48.409104 14832 trainer.py:139] Epoch[152/1000] loss: 0.25020432844758034
I0803 11:32:04.659200 14832 trainer.py:139] Epoch[153/1000] loss: 0.2502248249948025
I0803 11:32:20.994195 14832 trainer.py:139] Epoch[154/1000] loss: 0.24821666907519102
I0803 11:32:37.467317 14832 trainer.py:139] Epoch[155/1000] loss: 0.2488444959744811
I0803 11:32:53.654129 14832 trainer.py:139] Epoch[156/1000] loss: 0.25092096347361803
I0803 11:33:10.166552 14832 trainer.py:139] Epoch[157/1000] loss: 0.24922970961779356
I0803 11:33:26.469918 14832 trainer.py:139] Epoch[158/1000] loss: 0.24846226442605257
I0803 11:33:42.463467 14832 trainer.py:139] Epoch[159/1000] loss: 0.24935252498835325
I0803 11:33:58.539694 14832 trainer.py:139] Epoch[160/1000] loss: 0.24802707601338625
I0803 11:34:14.649803 14832 trainer.py:139] Epoch[161/1000] loss: 0.24816524889320135
I0803 11:34:30.507851 14832 trainer.py:139] Epoch[162/1000] loss: 0.24725221190601587
I0803 11:34:46.597805 14832 trainer.py:139] Epoch[163/1000] loss: 0.24687875900417566
I0803 11:35:02.735598 14832 trainer.py:139] Epoch[164/1000] loss: 0.24722816981375217
I0803 11:35:18.648597 14832 trainer.py:139] Epoch[165/1000] loss: 0.24628022965043783
I0803 11:35:34.863800 14832 trainer.py:139] Epoch[166/1000] loss: 0.24718215316534042
I0803 11:35:50.922246 14832 trainer.py:139] Epoch[167/1000] loss: 0.24661434441804886
I0803 11:36:07.250448 14832 trainer.py:139] Epoch[168/1000] loss: 0.2443051440641284
I0803 11:36:23.113131 14832 trainer.py:139] Epoch[169/1000] loss: 0.24452538508921862
I0803 11:36:39.106482 14832 trainer.py:139] Epoch[170/1000] loss: 0.2447439832612872
I0803 11:36:55.127750 14832 trainer.py:139] Epoch[171/1000] loss: 0.2440392915159464
I0803 11:37:11.434374 14832 trainer.py:139] Epoch[172/1000] loss: 0.24347671307623386
I0803 11:37:27.451801 14832 trainer.py:139] Epoch[173/1000] loss: 0.24423544574528933
I0803 11:37:43.417851 14832 trainer.py:139] Epoch[174/1000] loss: 0.24400413315743208
I0803 11:37:59.353176 14832 trainer.py:139] Epoch[175/1000] loss: 0.24347535613924265
I0803 11:38:15.393298 14832 trainer.py:139] Epoch[176/1000] loss: 0.24394055921584368
I0803 11:38:31.593110 14832 trainer.py:139] Epoch[177/1000] loss: 0.24374839290976524
I0803 11:38:47.701921 14832 trainer.py:139] Epoch[178/1000] loss: 0.24234487395733595
I0803 11:39:03.779198 14832 trainer.py:139] Epoch[179/1000] loss: 0.24111684132367373
I0803 11:39:19.605685 14832 trainer.py:139] Epoch[180/1000] loss: 0.24235748872160912
I0803 11:39:35.799179 14832 trainer.py:139] Epoch[181/1000] loss: 0.2431031772866845
I0803 11:39:51.898840 14832 trainer.py:139] Epoch[182/1000] loss: 0.24095965083688498
I0803 11:40:08.042816 14832 trainer.py:139] Epoch[183/1000] loss: 0.24237962067127228
I0803 11:40:23.894582 14832 trainer.py:139] Epoch[184/1000] loss: 0.24149600323289633
I0803 11:40:39.784261 14832 trainer.py:139] Epoch[185/1000] loss: 0.2416423289105296
I0803 11:40:55.865288 14832 trainer.py:139] Epoch[186/1000] loss: 0.24059669114649296
I0803 11:41:11.858601 14832 trainer.py:139] Epoch[187/1000] loss: 0.24001183826476336
I0803 11:41:28.247791 14832 trainer.py:139] Epoch[188/1000] loss: 0.23947300482541323
I0803 11:41:44.507072 14832 trainer.py:139] Epoch[189/1000] loss: 0.2381077092140913
I0803 11:42:00.450283 14832 trainer.py:139] Epoch[190/1000] loss: 0.23936170805245638
I0803 11:42:16.588864 14832 trainer.py:139] Epoch[191/1000] loss: 0.23886561021208763
I0803 11:42:32.825304 14832 trainer.py:139] Epoch[192/1000] loss: 0.23933312110602856
I0803 11:42:48.887601 14832 trainer.py:139] Epoch[193/1000] loss: 0.2378137744963169
I0803 11:43:04.951468 14832 trainer.py:139] Epoch[194/1000] loss: 0.23785518668591976
I0803 11:43:20.833585 14832 trainer.py:139] Epoch[195/1000] loss: 0.23902789875864983
I0803 11:43:36.564897 14832 trainer.py:139] Epoch[196/1000] loss: 0.23879283294081688
I0803 11:43:52.239141 14832 trainer.py:139] Epoch[197/1000] loss: 0.23873525485396385
I0803 11:44:08.164677 14832 trainer.py:139] Epoch[198/1000] loss: 0.23710610903799534
I0803 11:44:23.825712 14832 trainer.py:139] Epoch[199/1000] loss: 0.23742521740496159
I0803 11:44:24.410755 14832 trainer.py:145] Test: [{'precision': 0.18636060100166943, 'recall': 0.26078692831872624, 'hit_ratio': 0.8948247078464107, 'ndcg': 0.29039734492689384}]
I0803 11:44:40.423609 14832 trainer.py:139] Epoch[200/1000] loss: 0.23668985813856125
I0803 11:44:56.303753 14832 trainer.py:139] Epoch[201/1000] loss: 0.2358130430802703
I0803 11:45:12.493088 14832 trainer.py:139] Epoch[202/1000] loss: 0.23683077841997147
I0803 11:45:28.621915 14832 trainer.py:139] Epoch[203/1000] loss: 0.23593353386968374
I0803 11:45:44.465368 14832 trainer.py:139] Epoch[204/1000] loss: 0.23642989806830883
I0803 11:46:00.734910 14832 trainer.py:139] Epoch[205/1000] loss: 0.2362388875335455
I0803 11:46:16.649430 14832 trainer.py:139] Epoch[206/1000] loss: 0.23554061353206635
I0803 11:46:32.856387 14832 trainer.py:139] Epoch[207/1000] loss: 0.2370928581804037
I0803 11:46:48.518375 14832 trainer.py:139] Epoch[208/1000] loss: 0.23553407285362482
I0803 11:47:04.181182 14832 trainer.py:139] Epoch[209/1000] loss: 0.23496688716113567
I0803 11:47:19.726876 14832 trainer.py:139] Epoch[210/1000] loss: 0.23435398656874895
I0803 11:47:35.323935 14832 trainer.py:139] Epoch[211/1000] loss: 0.23489974066615105
I0803 11:47:51.145806 14832 trainer.py:139] Epoch[212/1000] loss: 0.2349340384826064
I0803 11:48:07.192441 14832 trainer.py:139] Epoch[213/1000] loss: 0.23500410933047533
I0803 11:48:23.025997 14832 trainer.py:139] Epoch[214/1000] loss: 0.23412007186561823
I0803 11:48:39.245363 14832 trainer.py:139] Epoch[215/1000] loss: 0.23378606513142586
I0803 11:48:54.893554 14832 trainer.py:139] Epoch[216/1000] loss: 0.23402484972029924
I0803 11:49:10.714757 14832 trainer.py:139] Epoch[217/1000] loss: 0.23483359068632126
I0803 11:49:26.466768 14832 trainer.py:139] Epoch[218/1000] loss: 0.2329890364781022
I0803 11:49:42.385523 14832 trainer.py:139] Epoch[219/1000] loss: 0.2340438524261117
I0803 11:49:58.426096 14832 trainer.py:139] Epoch[220/1000] loss: 0.23231387231498957
I0803 11:50:14.384910 14832 trainer.py:139] Epoch[221/1000] loss: 0.23238687962293625
I0803 11:50:30.121695 14832 trainer.py:139] Epoch[222/1000] loss: 0.2337413066998124
I0803 11:50:45.833793 14832 trainer.py:139] Epoch[223/1000] loss: 0.2323039025068283
I0803 11:51:02.102251 14832 trainer.py:139] Epoch[224/1000] loss: 0.2326122634112835
I0803 11:51:18.247252 14832 trainer.py:139] Epoch[225/1000] loss: 0.23275916278362274
I0803 11:51:34.005272 14832 trainer.py:139] Epoch[226/1000] loss: 0.23231139406561852
I0803 11:51:50.150193 14832 trainer.py:139] Epoch[227/1000] loss: 0.23217365331947803
I0803 11:52:05.781434 14832 trainer.py:139] Epoch[228/1000] loss: 0.23233055416494608
I0803 11:52:21.162885 14832 trainer.py:139] Epoch[229/1000] loss: 0.23120790347456932
I0803 11:52:37.241570 14832 trainer.py:139] Epoch[230/1000] loss: 0.23095936607569456
I0803 11:52:52.990705 14832 trainer.py:139] Epoch[231/1000] loss: 0.2314883777871728
I0803 11:53:08.618802 14832 trainer.py:139] Epoch[232/1000] loss: 0.2318391464650631
I0803 11:53:24.254831 14832 trainer.py:139] Epoch[233/1000] loss: 0.23140562418848276
I0803 11:53:40.106938 14832 trainer.py:139] Epoch[234/1000] loss: 0.2312356075271964
I0803 11:53:56.014444 14832 trainer.py:139] Epoch[235/1000] loss: 0.23087870422750711
I0803 11:54:12.023180 14832 trainer.py:139] Epoch[236/1000] loss: 0.23059682920575142
I0803 11:54:27.753787 14832 trainer.py:139] Epoch[237/1000] loss: 0.23034274391829967
I0803 11:54:43.205261 14832 trainer.py:139] Epoch[238/1000] loss: 0.22961960546672344
I0803 11:54:59.116149 14832 trainer.py:139] Epoch[239/1000] loss: 0.2300664195790887
I0803 11:55:14.871936 14832 trainer.py:139] Epoch[240/1000] loss: 0.23042013589292765
I0803 11:55:30.603433 14832 trainer.py:139] Epoch[241/1000] loss: 0.22850335761904716
I0803 11:55:46.426396 14832 trainer.py:139] Epoch[242/1000] loss: 0.22924779169261456
I0803 11:56:02.131011 14832 trainer.py:139] Epoch[243/1000] loss: 0.23075008764863014
I0803 11:56:17.882367 14832 trainer.py:139] Epoch[244/1000] loss: 0.229684354737401
I0803 11:56:33.815693 14832 trainer.py:139] Epoch[245/1000] loss: 0.22870384715497494
I0803 11:56:49.778406 14832 trainer.py:139] Epoch[246/1000] loss: 0.23010325152426958
I0803 11:57:05.742045 14832 trainer.py:139] Epoch[247/1000] loss: 0.22770087607204914
I0803 11:57:21.593235 14832 trainer.py:139] Epoch[248/1000] loss: 0.23010984435677528
I0803 11:57:37.697443 14832 trainer.py:139] Epoch[249/1000] loss: 0.2288781739771366
I0803 11:57:38.235177 14832 trainer.py:145] Test: [{'precision': 0.18934056761268778, 'recall': 0.2658803834406334, 'hit_ratio': 0.8993322203672788, 'ndcg': 0.2964875116838654}]
I0803 11:57:54.266771 14832 trainer.py:139] Epoch[250/1000] loss: 0.22868031077086926
I0803 11:58:10.500881 14832 trainer.py:139] Epoch[251/1000] loss: 0.22845971770584583
I0803 11:58:26.370181 14832 trainer.py:139] Epoch[252/1000] loss: 0.22965209372341633
I0803 11:58:42.459689 14832 trainer.py:139] Epoch[253/1000] loss: 0.22799593582749367
I0803 11:58:58.142239 14832 trainer.py:139] Epoch[254/1000] loss: 0.22853962797671556
I0803 11:59:14.106095 14832 trainer.py:139] Epoch[255/1000] loss: 0.2288857465609908
I0803 11:59:29.893938 14832 trainer.py:139] Epoch[256/1000] loss: 0.22916754893958569
I0803 11:59:45.722252 14832 trainer.py:139] Epoch[257/1000] loss: 0.22803805582225323
I0803 12:00:01.352169 14832 trainer.py:139] Epoch[258/1000] loss: 0.22861016541719437
I0803 12:00:16.962348 14832 trainer.py:139] Epoch[259/1000] loss: 0.2273863209411502
I0803 12:00:32.601006 14832 trainer.py:139] Epoch[260/1000] loss: 0.22788576874881983
I0803 12:00:48.432212 14832 trainer.py:139] Epoch[261/1000] loss: 0.22664577513933182
I0803 12:01:04.282509 14832 trainer.py:139] Epoch[262/1000] loss: 0.22598464414477348
I0803 12:01:19.938385 14832 trainer.py:139] Epoch[263/1000] loss: 0.22786005958914757
I0803 12:01:35.451009 14832 trainer.py:139] Epoch[264/1000] loss: 0.2267446257174015
I0803 12:01:51.186110 14832 trainer.py:139] Epoch[265/1000] loss: 0.22789815813302994
I0803 12:02:06.936794 14832 trainer.py:139] Epoch[266/1000] loss: 0.22700400464236736
I0803 12:02:22.580189 14832 trainer.py:139] Epoch[267/1000] loss: 0.22706814389675856
I0803 12:02:38.412189 14832 trainer.py:139] Epoch[268/1000] loss: 0.22693579457700253
I0803 12:02:54.287271 14832 trainer.py:139] Epoch[269/1000] loss: 0.22723469976335764
I0803 12:03:10.039028 14832 trainer.py:139] Epoch[270/1000] loss: 0.22632905188947916
I0803 12:03:26.244132 14832 trainer.py:139] Epoch[271/1000] loss: 0.22616417706012726
I0803 12:03:42.079165 14832 trainer.py:139] Epoch[272/1000] loss: 0.22586297243833542
I0803 12:03:57.876850 14832 trainer.py:139] Epoch[273/1000] loss: 0.2268026750534773
I0803 12:04:13.711658 14832 trainer.py:139] Epoch[274/1000] loss: 0.22544299345463514
I0803 12:04:29.933120 14832 trainer.py:139] Epoch[275/1000] loss: 0.22594805248081684
I0803 12:04:45.596215 14832 trainer.py:139] Epoch[276/1000] loss: 0.22592273354530334
I0803 12:05:01.111533 14832 trainer.py:139] Epoch[277/1000] loss: 0.2252722317352891
I0803 12:05:16.618183 14832 trainer.py:139] Epoch[278/1000] loss: 0.2261236971244216
I0803 12:05:32.427501 14832 trainer.py:139] Epoch[279/1000] loss: 0.2261181054636836
I0803 12:05:48.097510 14832 trainer.py:139] Epoch[280/1000] loss: 0.22359695006161928
I0803 12:06:03.729821 14832 trainer.py:139] Epoch[281/1000] loss: 0.2261252086609602
I0803 12:06:19.549457 14832 trainer.py:139] Epoch[282/1000] loss: 0.22628745716065168
I0803 12:06:35.358191 14832 trainer.py:139] Epoch[283/1000] loss: 0.22547513991594315
I0803 12:06:51.284393 14832 trainer.py:139] Epoch[284/1000] loss: 0.2250860622152686
I0803 12:07:07.154746 14832 trainer.py:139] Epoch[285/1000] loss: 0.22478500939905643
I0803 12:07:22.767050 14832 trainer.py:139] Epoch[286/1000] loss: 0.2247567642480135
I0803 12:07:38.650367 14832 trainer.py:139] Epoch[287/1000] loss: 0.2259180909022689
I0803 12:07:54.370747 14832 trainer.py:139] Epoch[288/1000] loss: 0.22447561472654343
I0803 12:08:10.336821 14832 trainer.py:139] Epoch[289/1000] loss: 0.22457043174654245
I0803 12:08:26.146953 14832 trainer.py:139] Epoch[290/1000] loss: 0.22336804121732712
I0803 12:08:42.295636 14832 trainer.py:139] Epoch[291/1000] loss: 0.22364460863173008
I0803 12:08:58.256592 14832 trainer.py:139] Epoch[292/1000] loss: 0.2238376084715128
I0803 12:09:14.015404 14832 trainer.py:139] Epoch[293/1000] loss: 0.2244408642873168
I0803 12:09:29.994431 14832 trainer.py:139] Epoch[294/1000] loss: 0.22347782459110022
I0803 12:09:46.073828 14832 trainer.py:139] Epoch[295/1000] loss: 0.22454395983368158
I0803 12:10:02.133021 14832 trainer.py:139] Epoch[296/1000] loss: 0.22273735236376524
I0803 12:10:17.717712 14832 trainer.py:139] Epoch[297/1000] loss: 0.22427720203995705
I0803 12:10:33.495308 14832 trainer.py:139] Epoch[298/1000] loss: 0.2237371141090989
I0803 12:10:49.298650 14832 trainer.py:139] Epoch[299/1000] loss: 0.22253092471510172
I0803 12:10:49.915151 14832 trainer.py:145] Test: [{'precision': 0.1912938230383973, 'recall': 0.26870953924971613, 'hit_ratio': 0.9015025041736227, 'ndcg': 0.2992343519274569}]
I0803 12:11:05.747627 14832 trainer.py:139] Epoch[300/1000] loss: 0.2227637590840459
I0803 12:11:21.466976 14832 trainer.py:139] Epoch[301/1000] loss: 0.22268865536898375
I0803 12:11:37.502705 14832 trainer.py:139] Epoch[302/1000] loss: 0.22248141560703516
I0803 12:11:53.213484 14832 trainer.py:139] Epoch[303/1000] loss: 0.2217991203069687
I0803 12:12:08.762662 14832 trainer.py:139] Epoch[304/1000] loss: 0.222660506144166
I0803 12:12:24.753517 14832 trainer.py:139] Epoch[305/1000] loss: 0.2224858133122325
I0803 12:12:40.480960 14832 trainer.py:139] Epoch[306/1000] loss: 0.22209202218800783
I0803 12:12:56.244096 14832 trainer.py:139] Epoch[307/1000] loss: 0.22331296931952238
I0803 12:13:12.085069 14832 trainer.py:139] Epoch[308/1000] loss: 0.22271283902227879
I0803 12:13:27.859382 14832 trainer.py:139] Epoch[309/1000] loss: 0.22389692813158035
I0803 12:13:43.619463 14832 trainer.py:139] Epoch[310/1000] loss: 0.2229371126741171
I0803 12:13:59.420272 14832 trainer.py:139] Epoch[311/1000] loss: 0.22318393550813198
I0803 12:14:15.046128 14832 trainer.py:139] Epoch[312/1000] loss: 0.22226181626319885
I0803 12:14:31.261040 14832 trainer.py:139] Epoch[313/1000] loss: 0.22225934639573097
I0803 12:14:47.293636 14832 trainer.py:139] Epoch[314/1000] loss: 0.22227562125772238
I0803 12:15:03.081770 14832 trainer.py:139] Epoch[315/1000] loss: 0.2216158490628004
I0803 12:15:19.044396 14832 trainer.py:139] Epoch[316/1000] loss: 0.2217645486816764
I0803 12:15:35.180337 14832 trainer.py:139] Epoch[317/1000] loss: 0.22224640380591154
I0803 12:15:51.048836 14832 trainer.py:139] Epoch[318/1000] loss: 0.22197147272527218
I0803 12:16:06.954033 14832 trainer.py:139] Epoch[319/1000] loss: 0.22201306000351906
I0803 12:16:22.793102 14832 trainer.py:139] Epoch[320/1000] loss: 0.22152932826429605
I0803 12:16:39.039028 14832 trainer.py:139] Epoch[321/1000] loss: 0.22171791922301054
I0803 12:16:54.982812 14832 trainer.py:139] Epoch[322/1000] loss: 0.22037431318312883
I0803 12:17:10.764791 14832 trainer.py:139] Epoch[323/1000] loss: 0.22067073546350002
I0803 12:17:26.604465 14832 trainer.py:139] Epoch[324/1000] loss: 0.2219996014609933
I0803 12:17:42.378684 14832 trainer.py:139] Epoch[325/1000] loss: 0.22097128070890903
I0803 12:17:58.149042 14832 trainer.py:139] Epoch[326/1000] loss: 0.2212669374421239
I0803 12:18:13.896917 14832 trainer.py:139] Epoch[327/1000] loss: 0.2212739009410143
I0803 12:18:29.888803 14832 trainer.py:139] Epoch[328/1000] loss: 0.221194957382977
I0803 12:18:45.855533 14832 trainer.py:139] Epoch[329/1000] loss: 0.22113343700766563
I0803 12:19:01.633678 14832 trainer.py:139] Epoch[330/1000] loss: 0.22081665974110365
I0803 12:19:17.377636 14832 trainer.py:139] Epoch[331/1000] loss: 0.22091556806117296
I0803 12:19:32.989320 14832 trainer.py:139] Epoch[332/1000] loss: 0.22039509937167168
I0803 12:19:48.629627 14832 trainer.py:139] Epoch[333/1000] loss: 0.2203020602464676
I0803 12:20:04.451333 14832 trainer.py:139] Epoch[334/1000] loss: 0.22079542744904757
I0803 12:20:20.201272 14832 trainer.py:139] Epoch[335/1000] loss: 0.21949158050119877
I0803 12:20:36.064954 14832 trainer.py:139] Epoch[336/1000] loss: 0.22048385627567768
I0803 12:20:52.022377 14832 trainer.py:139] Epoch[337/1000] loss: 0.22135269083082676
I0803 12:21:07.947149 14832 trainer.py:139] Epoch[338/1000] loss: 0.2202068055048585
I0803 12:21:24.000935 14832 trainer.py:139] Epoch[339/1000] loss: 0.22098850551992655
I0803 12:21:39.802859 14832 trainer.py:139] Epoch[340/1000] loss: 0.22037655673921108
I0803 12:21:55.650066 14832 trainer.py:139] Epoch[341/1000] loss: 0.22019603662192822
I0803 12:22:11.291468 14832 trainer.py:139] Epoch[342/1000] loss: 0.22049695439636707
I0803 12:22:27.295367 14832 trainer.py:139] Epoch[343/1000] loss: 0.22026241477578878
I0803 12:22:42.799618 14832 trainer.py:139] Epoch[344/1000] loss: 0.21966376155614853
I0803 12:22:58.411544 14832 trainer.py:139] Epoch[345/1000] loss: 0.2191300317645073
I0803 12:23:14.239119 14832 trainer.py:139] Epoch[346/1000] loss: 0.219658805988729
I0803 12:23:30.191357 14832 trainer.py:139] Epoch[347/1000] loss: 0.2196070710197091
I0803 12:23:45.977552 14832 trainer.py:139] Epoch[348/1000] loss: 0.21995330974459648
I0803 12:24:01.665400 14832 trainer.py:139] Epoch[349/1000] loss: 0.22023856360465288
I0803 12:24:02.285912 14832 trainer.py:145] Test: [{'precision': 0.19332220367278793, 'recall': 0.27315532424456723, 'hit_ratio': 0.9056761268781303, 'ndcg': 0.30305579649421444}]
I0803 12:24:17.968928 14832 trainer.py:139] Epoch[350/1000] loss: 0.22081908490508795
I0803 12:24:33.611887 14832 trainer.py:139] Epoch[351/1000] loss: 0.21990452893078327
I0803 12:24:49.571660 14832 trainer.py:139] Epoch[352/1000] loss: 0.21922115702182055
I0803 12:25:05.474751 14832 trainer.py:139] Epoch[353/1000] loss: 0.2194711547344923
I0803 12:25:21.144959 14832 trainer.py:139] Epoch[354/1000] loss: 0.21892283484339714
I0803 12:25:36.954479 14832 trainer.py:139] Epoch[355/1000] loss: 0.21928153466433287
I0803 12:25:52.750237 14832 trainer.py:139] Epoch[356/1000] loss: 0.2191833397373557
I0803 12:26:08.834714 14832 trainer.py:139] Epoch[357/1000] loss: 0.218080579303205
I0803 12:26:24.564197 14832 trainer.py:139] Epoch[358/1000] loss: 0.21934418193995953
I0803 12:26:40.543581 14832 trainer.py:139] Epoch[359/1000] loss: 0.21875833999365568
I0803 12:26:56.761322 14832 trainer.py:139] Epoch[360/1000] loss: 0.21908741910010576
I0803 12:27:12.869726 14832 trainer.py:139] Epoch[361/1000] loss: 0.21883095987141132
I0803 12:27:29.200844 14832 trainer.py:139] Epoch[362/1000] loss: 0.21943633444607258
I0803 12:27:45.131853 14832 trainer.py:139] Epoch[363/1000] loss: 0.21802398283034563
I0803 12:28:00.910277 14832 trainer.py:139] Epoch[364/1000] loss: 0.2179350759834051
I0803 12:28:16.910884 14832 trainer.py:139] Epoch[365/1000] loss: 0.2196380728855729
I0803 12:28:32.708032 14832 trainer.py:139] Epoch[366/1000] loss: 0.21751528792083263
I0803 12:28:48.546844 14832 trainer.py:139] Epoch[367/1000] loss: 0.2188493050634861
I0803 12:29:04.597221 14832 trainer.py:139] Epoch[368/1000] loss: 0.2185094328597188
I0803 12:29:20.253580 14832 trainer.py:139] Epoch[369/1000] loss: 0.21781618986278772
I0803 12:29:36.388459 14832 trainer.py:139] Epoch[370/1000] loss: 0.21921849437057972
I0803 12:29:51.987140 14832 trainer.py:139] Epoch[371/1000] loss: 0.21713987458497286
I0803 12:30:07.659973 14832 trainer.py:139] Epoch[372/1000] loss: 0.2179687200114131
I0803 12:30:23.919029 14832 trainer.py:139] Epoch[373/1000] loss: 0.21758805494755507
I0803 12:30:39.380280 14832 trainer.py:139] Epoch[374/1000] loss: 0.21740682423114777
I0803 12:30:55.043529 14832 trainer.py:139] Epoch[375/1000] loss: 0.21694188471883535
I0803 12:31:10.717087 14832 trainer.py:139] Epoch[376/1000] loss: 0.21884869784116745
I0803 12:31:26.124680 14832 trainer.py:139] Epoch[377/1000] loss: 0.2168762944638729
I0803 12:31:41.593068 14832 trainer.py:139] Epoch[378/1000] loss: 0.2172304168343544
I0803 12:31:57.539958 14832 trainer.py:139] Epoch[379/1000] loss: 0.21794526185840368
I0803 12:32:13.624771 14832 trainer.py:139] Epoch[380/1000] loss: 0.21744078118354082
I0803 12:32:29.545986 14832 trainer.py:139] Epoch[381/1000] loss: 0.218474299646914
I0803 12:32:45.340006 14832 trainer.py:139] Epoch[382/1000] loss: 0.21846413612365723
I0803 12:33:01.495226 14832 trainer.py:139] Epoch[383/1000] loss: 0.21716191060841084
I0803 12:33:17.557089 14832 trainer.py:139] Epoch[384/1000] loss: 0.2168440418317914
I0803 12:33:33.550053 14832 trainer.py:139] Epoch[385/1000] loss: 0.21734407637268305
I0803 12:33:49.477393 14832 trainer.py:139] Epoch[386/1000] loss: 0.21792794112116098
I0803 12:34:05.362460 14832 trainer.py:139] Epoch[387/1000] loss: 0.21673715487122536
I0803 12:34:21.130409 14832 trainer.py:139] Epoch[388/1000] loss: 0.2177291689440608
I0803 12:34:37.254879 14832 trainer.py:139] Epoch[389/1000] loss: 0.21775812190026045
I0803 12:34:52.973355 14832 trainer.py:139] Epoch[390/1000] loss: 0.21702109929174185
I0803 12:35:08.837614 14832 trainer.py:139] Epoch[391/1000] loss: 0.21703207027167082
I0803 12:35:24.770469 14832 trainer.py:139] Epoch[392/1000] loss: 0.21724928356707096
I0803 12:35:40.755708 14832 trainer.py:139] Epoch[393/1000] loss: 0.21665743086487055
I0803 12:35:56.688881 14832 trainer.py:139] Epoch[394/1000] loss: 0.21654612757265568
I0803 12:36:12.934276 14832 trainer.py:139] Epoch[395/1000] loss: 0.21709250938147306
I0803 12:36:30.172695 14832 trainer.py:139] Epoch[396/1000] loss: 0.21716667525470257
I0803 12:36:46.769997 14832 trainer.py:139] Epoch[397/1000] loss: 0.2180466167628765
I0803 12:37:03.533900 14832 trainer.py:139] Epoch[398/1000] loss: 0.21640963107347488
I0803 12:37:20.087083 14832 trainer.py:139] Epoch[399/1000] loss: 0.2179774921387434
I0803 12:37:20.667141 14832 trainer.py:145] Test: [{'precision': 0.19469115191986644, 'recall': 0.27458341384427337, 'hit_ratio': 0.906677796327212, 'ndcg': 0.30556770327805477}]
I0803 12:37:36.921476 14832 trainer.py:139] Epoch[400/1000] loss: 0.21596332266926765
I0803 12:37:53.432612 14832 trainer.py:139] Epoch[401/1000] loss: 0.21669129934161901
I0803 12:38:10.262351 14832 trainer.py:139] Epoch[402/1000] loss: 0.21697653364390135
I0803 12:38:26.903960 14832 trainer.py:139] Epoch[403/1000] loss: 0.21766699478030205
I0803 12:38:43.445467 14832 trainer.py:139] Epoch[404/1000] loss: 0.2160941194742918
I0803 12:38:59.588219 14832 trainer.py:139] Epoch[405/1000] loss: 0.21623660624027252
I0803 12:39:15.902101 14832 trainer.py:139] Epoch[406/1000] loss: 0.21623404417186975
I0803 12:39:32.343948 14832 trainer.py:139] Epoch[407/1000] loss: 0.2164308661594987
I0803 12:39:48.910208 14832 trainer.py:139] Epoch[408/1000] loss: 0.21453821007162333
I0803 12:40:04.988760 14832 trainer.py:139] Epoch[409/1000] loss: 0.21684387791901827
I0803 12:40:21.296391 14832 trainer.py:139] Epoch[410/1000] loss: 0.21539333369582891
I0803 12:40:37.378264 14832 trainer.py:139] Epoch[411/1000] loss: 0.21548260189592838
I0803 12:40:53.438405 14832 trainer.py:139] Epoch[412/1000] loss: 0.21581794321537018
I0803 12:41:09.431184 14832 trainer.py:139] Epoch[413/1000] loss: 0.2159086288884282
I0803 12:41:25.994605 14832 trainer.py:139] Epoch[414/1000] loss: 0.21577261202037334
I0803 12:41:42.293936 14832 trainer.py:139] Epoch[415/1000] loss: 0.2156884614378214
I0803 12:41:58.634869 14832 trainer.py:139] Epoch[416/1000] loss: 0.21552851516753435
I0803 12:42:14.575705 14832 trainer.py:139] Epoch[417/1000] loss: 0.21609095484018326
I0803 12:42:30.859896 14832 trainer.py:139] Epoch[418/1000] loss: 0.21748609375208616
I0803 12:42:46.902546 14832 trainer.py:139] Epoch[419/1000] loss: 0.216185811907053
I0803 12:43:03.357037 14832 trainer.py:139] Epoch[420/1000] loss: 0.21568778064101934
I0803 12:43:19.948521 14832 trainer.py:139] Epoch[421/1000] loss: 0.21560615487396717
I0803 12:43:36.296944 14832 trainer.py:139] Epoch[422/1000] loss: 0.21645168121904135
I0803 12:43:52.362102 14832 trainer.py:139] Epoch[423/1000] loss: 0.21556782070547342
I0803 12:44:08.499298 14832 trainer.py:139] Epoch[424/1000] loss: 0.21531297825276852
I0803 12:44:24.749348 14832 trainer.py:139] Epoch[425/1000] loss: 0.21438862849026918
I0803 12:44:41.227027 14832 trainer.py:139] Epoch[426/1000] loss: 0.21581415086984634
I0803 12:44:57.686856 14832 trainer.py:139] Epoch[427/1000] loss: 0.21556357573717833
I0803 12:45:14.710173 14832 trainer.py:139] Epoch[428/1000] loss: 0.21514862217009068
I0803 12:45:31.404510 14832 trainer.py:139] Epoch[429/1000] loss: 0.2154328152537346
I0803 12:45:47.642940 14832 trainer.py:139] Epoch[430/1000] loss: 0.215341467410326
I0803 12:46:04.023773 14832 trainer.py:139] Epoch[431/1000] loss: 0.21532143000513315
I0803 12:46:20.423954 14832 trainer.py:139] Epoch[432/1000] loss: 0.21465942356735468
I0803 12:46:36.392802 14832 trainer.py:139] Epoch[433/1000] loss: 0.21507053822278976
I0803 12:46:52.254822 14832 trainer.py:139] Epoch[434/1000] loss: 0.21492373198270798
I0803 12:47:08.197407 14832 trainer.py:139] Epoch[435/1000] loss: 0.2151194652542472
I0803 12:47:24.330314 14832 trainer.py:139] Epoch[436/1000] loss: 0.2143848454579711
I0803 12:47:41.192125 14832 trainer.py:139] Epoch[437/1000] loss: 0.21393143944442272
I0803 12:47:57.223634 14832 trainer.py:139] Epoch[438/1000] loss: 0.21524026431143284
I0803 12:48:13.649767 14832 trainer.py:139] Epoch[439/1000] loss: 0.2146862344816327
I0803 12:48:30.012444 14832 trainer.py:139] Epoch[440/1000] loss: 0.2148589175194502
I0803 12:48:46.593903 14832 trainer.py:139] Epoch[441/1000] loss: 0.2144095404073596
I0803 12:49:03.015752 14832 trainer.py:139] Epoch[442/1000] loss: 0.21398042142391205
I0803 12:49:19.231472 14832 trainer.py:139] Epoch[443/1000] loss: 0.21387754008173943
I0803 12:49:35.376912 14832 trainer.py:139] Epoch[444/1000] loss: 0.21453071106225252
I0803 12:49:51.790368 14832 trainer.py:139] Epoch[445/1000] loss: 0.21379986312240362
I0803 12:50:07.857289 14832 trainer.py:139] Epoch[446/1000] loss: 0.21372018288820982
I0803 12:50:24.180867 14832 trainer.py:139] Epoch[447/1000] loss: 0.21453901659697294
I0803 12:50:40.628606 14832 trainer.py:139] Epoch[448/1000] loss: 0.2139128828421235
I0803 12:50:56.846758 14832 trainer.py:139] Epoch[449/1000] loss: 0.21400013659149408
I0803 12:50:57.431801 14832 trainer.py:145] Test: [{'precision': 0.19510851419031713, 'recall': 0.2751317187548328, 'hit_ratio': 0.9055091819699499, 'ndcg': 0.3070239040664371}]
I0803 12:51:13.930082 14832 trainer.py:139] Epoch[450/1000] loss: 0.214892846532166
I0803 12:51:30.723926 14832 trainer.py:139] Epoch[451/1000] loss: 0.2137143248692155
I0803 12:51:47.102284 14832 trainer.py:139] Epoch[452/1000] loss: 0.21395131014287472
I0803 12:52:03.633990 14832 trainer.py:139] Epoch[453/1000] loss: 0.21410944871604443
I0803 12:52:19.761171 14832 trainer.py:139] Epoch[454/1000] loss: 0.21392790973186493
I0803 12:52:35.657923 14832 trainer.py:139] Epoch[455/1000] loss: 0.21487207151949406
I0803 12:52:51.612413 14832 trainer.py:139] Epoch[456/1000] loss: 0.2139812046661973
I0803 12:53:07.828629 14832 trainer.py:139] Epoch[457/1000] loss: 0.21387555822730064
I0803 12:53:24.586235 14832 trainer.py:139] Epoch[458/1000] loss: 0.21368875727057457
I0803 12:53:41.031285 14832 trainer.py:139] Epoch[459/1000] loss: 0.2138830916956067
I0803 12:53:57.658969 14832 trainer.py:139] Epoch[460/1000] loss: 0.21416352409869432
I0803 12:54:13.630349 14832 trainer.py:139] Epoch[461/1000] loss: 0.21382038854062557
I0803 12:54:29.633276 14832 trainer.py:139] Epoch[462/1000] loss: 0.21395384520292282
I0803 12:54:46.095414 14832 trainer.py:139] Epoch[463/1000] loss: 0.214296106249094
I0803 12:55:02.339282 14832 trainer.py:139] Epoch[464/1000] loss: 0.2145013092085719
I0803 12:55:18.604989 14832 trainer.py:139] Epoch[465/1000] loss: 0.21340663358569145
I0803 12:55:34.509873 14832 trainer.py:139] Epoch[466/1000] loss: 0.21334529388695955
I0803 12:55:50.350742 14832 trainer.py:139] Epoch[467/1000] loss: 0.21329421550035477
I0803 12:56:06.434093 14832 trainer.py:139] Epoch[468/1000] loss: 0.2129229810088873
I0803 12:56:23.027762 14832 trainer.py:139] Epoch[469/1000] loss: 0.21300395857542753
I0803 12:56:39.658143 14832 trainer.py:139] Epoch[470/1000] loss: 0.21385898161679506
I0803 12:56:56.058481 14832 trainer.py:139] Epoch[471/1000] loss: 0.2132980478927493
I0803 12:57:12.560415 14832 trainer.py:139] Epoch[472/1000] loss: 0.21333498787134886
I0803 12:57:28.544013 14832 trainer.py:139] Epoch[473/1000] loss: 0.21349434833973646
I0803 12:57:45.160633 14832 trainer.py:139] Epoch[474/1000] loss: 0.21288765221834183
I0803 12:58:01.406381 14832 trainer.py:139] Epoch[475/1000] loss: 0.21281893737614155
I0803 12:58:17.794138 14832 trainer.py:139] Epoch[476/1000] loss: 0.21252825018018484
I0803 12:58:34.285935 14832 trainer.py:139] Epoch[477/1000] loss: 0.21219829097390175
I0803 12:58:50.481783 14832 trainer.py:139] Epoch[478/1000] loss: 0.21256388258188963
I0803 12:59:06.538051 14832 trainer.py:139] Epoch[479/1000] loss: 0.212562738917768
I0803 12:59:23.009143 14832 trainer.py:139] Epoch[480/1000] loss: 0.213197473436594
I0803 12:59:39.597117 14832 trainer.py:139] Epoch[481/1000] loss: 0.2135549420490861
I0803 12:59:56.080711 14832 trainer.py:139] Epoch[482/1000] loss: 0.2135023521259427
I0803 13:00:12.558282 14832 trainer.py:139] Epoch[483/1000] loss: 0.2122452761977911
I0803 13:00:28.770876 14832 trainer.py:139] Epoch[484/1000] loss: 0.21298777032643557
I0803 13:00:45.409755 14832 trainer.py:139] Epoch[485/1000] loss: 0.21314414031803608
I0803 13:01:01.716541 14832 trainer.py:139] Epoch[486/1000] loss: 0.2128992835059762
I0803 13:01:17.804210 14832 trainer.py:139] Epoch[487/1000] loss: 0.21197129413485527
I0803 13:01:33.778176 14832 trainer.py:139] Epoch[488/1000] loss: 0.21272421441972256
I0803 13:01:50.061319 14832 trainer.py:139] Epoch[489/1000] loss: 0.21294535789638758
I0803 13:02:05.997159 14832 trainer.py:139] Epoch[490/1000] loss: 0.2117595737800002
I0803 13:02:22.172974 14832 trainer.py:139] Epoch[491/1000] loss: 0.21225161757320166
I0803 13:02:38.607127 14832 trainer.py:139] Epoch[492/1000] loss: 0.21204930264502764
I0803 13:02:54.877397 14832 trainer.py:139] Epoch[493/1000] loss: 0.21302889939397573
I0803 13:03:11.182894 14832 trainer.py:139] Epoch[494/1000] loss: 0.21252804715186357
I0803 13:03:27.508309 14832 trainer.py:139] Epoch[495/1000] loss: 0.2122012758627534
I0803 13:03:43.693855 14832 trainer.py:139] Epoch[496/1000] loss: 0.21194316912442446
I0803 13:03:59.803395 14832 trainer.py:139] Epoch[497/1000] loss: 0.2119162054732442
I0803 13:04:16.080118 14832 trainer.py:139] Epoch[498/1000] loss: 0.21200569905340672
I0803 13:04:32.424369 14832 trainer.py:139] Epoch[499/1000] loss: 0.2125175204128027
I0803 13:04:32.973122 14832 trainer.py:145] Test: [{'precision': 0.1970200333889816, 'recall': 0.2774048955242693, 'hit_ratio': 0.9075125208681135, 'ndcg': 0.30919553995233645}]
I0803 13:04:49.340567 14832 trainer.py:139] Epoch[500/1000] loss: 0.21317789144814014
I0803 13:05:05.810942 14832 trainer.py:139] Epoch[501/1000] loss: 0.21188540384173393
I0803 13:05:22.379804 14832 trainer.py:139] Epoch[502/1000] loss: 0.21213030628859997
I0803 13:05:38.827231 14832 trainer.py:139] Epoch[503/1000] loss: 0.21168604865670204
I0803 13:05:54.701604 14832 trainer.py:139] Epoch[504/1000] loss: 0.21218355745077133
I0803 13:06:10.806259 14832 trainer.py:139] Epoch[505/1000] loss: 0.21183036547154188
I0803 13:06:27.306064 14832 trainer.py:139] Epoch[506/1000] loss: 0.2121806414797902
I0803 13:06:43.570452 14832 trainer.py:139] Epoch[507/1000] loss: 0.21113296318799257
I0803 13:06:59.515484 14832 trainer.py:139] Epoch[508/1000] loss: 0.21136122476309538
I0803 13:07:15.497915 14832 trainer.py:139] Epoch[509/1000] loss: 0.21137838531285524
I0803 13:07:31.501436 14832 trainer.py:139] Epoch[510/1000] loss: 0.21220892202109098
I0803 13:07:47.735580 14832 trainer.py:139] Epoch[511/1000] loss: 0.2109166644513607
I0803 13:08:03.886076 14832 trainer.py:139] Epoch[512/1000] loss: 0.21142212394624949
I0803 13:08:20.047058 14832 trainer.py:139] Epoch[513/1000] loss: 0.2114624734967947
I0803 13:08:36.383091 14832 trainer.py:139] Epoch[514/1000] loss: 0.21113789826631546
I0803 13:08:53.287043 14832 trainer.py:139] Epoch[515/1000] loss: 0.21130192000418901
I0803 13:09:09.581562 14832 trainer.py:139] Epoch[516/1000] loss: 0.2112856674939394
I0803 13:09:25.727120 14832 trainer.py:139] Epoch[517/1000] loss: 0.21051370538771152
I0803 13:09:42.192710 14832 trainer.py:139] Epoch[518/1000] loss: 0.21183255314826965
I0803 13:09:58.526775 14832 trainer.py:139] Epoch[519/1000] loss: 0.21189888752996922
I0803 13:10:14.736483 14832 trainer.py:139] Epoch[520/1000] loss: 0.21119681932032108
I0803 13:10:31.343629 14832 trainer.py:139] Epoch[521/1000] loss: 0.21184555441141129
I0803 13:10:47.701968 14832 trainer.py:139] Epoch[522/1000] loss: 0.21220618579536676
I0803 13:11:03.614620 14832 trainer.py:139] Epoch[523/1000] loss: 0.21169529017060995
I0803 13:11:20.224148 14832 trainer.py:139] Epoch[524/1000] loss: 0.21102589461952448
I0803 13:11:36.585355 14832 trainer.py:139] Epoch[525/1000] loss: 0.21128253173083067
I0803 13:11:52.865575 14832 trainer.py:139] Epoch[526/1000] loss: 0.21067995205521584
I0803 13:12:09.054653 14832 trainer.py:139] Epoch[527/1000] loss: 0.2108883187174797
I0803 13:12:25.137944 14832 trainer.py:139] Epoch[528/1000] loss: 0.21012694761157036
I0803 13:12:41.183072 14832 trainer.py:139] Epoch[529/1000] loss: 0.21153283957391977
I0803 13:12:57.347551 14832 trainer.py:139] Epoch[530/1000] loss: 0.21097028441727161
I0803 13:13:13.484508 14832 trainer.py:139] Epoch[531/1000] loss: 0.2107162745669484
I0803 13:13:29.754312 14832 trainer.py:139] Epoch[532/1000] loss: 0.2099188230931759
I0803 13:13:46.007833 14832 trainer.py:139] Epoch[533/1000] loss: 0.21137208212167025
I0803 13:14:01.863273 14832 trainer.py:139] Epoch[534/1000] loss: 0.2106572613120079
I0803 13:14:18.170010 14832 trainer.py:139] Epoch[535/1000] loss: 0.21236415300518274
I0803 13:14:34.175535 14832 trainer.py:139] Epoch[536/1000] loss: 0.2104999078437686
I0803 13:14:50.404371 14832 trainer.py:139] Epoch[537/1000] loss: 0.21131523046642542
I0803 13:15:06.530102 14832 trainer.py:139] Epoch[538/1000] loss: 0.21160709578543901
I0803 13:15:22.885842 14832 trainer.py:139] Epoch[539/1000] loss: 0.20991676021367311
I0803 13:15:39.163060 14832 trainer.py:139] Epoch[540/1000] loss: 0.21112642623484135
I0803 13:15:55.766730 14832 trainer.py:139] Epoch[541/1000] loss: 0.21110268216580153
I0803 13:16:12.504363 14832 trainer.py:139] Epoch[542/1000] loss: 0.21151853632181883
I0803 13:16:28.827027 14832 trainer.py:139] Epoch[543/1000] loss: 0.21098991483449936
I0803 13:16:45.128026 14832 trainer.py:139] Epoch[544/1000] loss: 0.20978280808776617
I0803 13:17:01.321716 14832 trainer.py:139] Epoch[545/1000] loss: 0.21060716453939676
I0803 13:17:17.558791 14832 trainer.py:139] Epoch[546/1000] loss: 0.2095679109916091
I0803 13:17:33.872790 14832 trainer.py:139] Epoch[547/1000] loss: 0.21054033562541008
I0803 13:17:50.151787 14832 trainer.py:139] Epoch[548/1000] loss: 0.21202360466122627
I0803 13:18:05.949169 14832 trainer.py:139] Epoch[549/1000] loss: 0.21136786043643951
I0803 13:18:06.550158 14832 trainer.py:145] Test: [{'precision': 0.19728714524207008, 'recall': 0.2785657439088265, 'hit_ratio': 0.9088480801335559, 'ndcg': 0.3108073111527538}]
I0803 13:18:22.544662 14832 trainer.py:139] Epoch[550/1000] loss: 0.2105144038796425
I0803 13:18:38.845726 14832 trainer.py:139] Epoch[551/1000] loss: 0.21075536776334047
I0803 13:18:54.865184 14832 trainer.py:139] Epoch[552/1000] loss: 0.2105212053284049
I0803 13:19:11.003257 14832 trainer.py:139] Epoch[553/1000] loss: 0.21111377235502005
I0803 13:19:27.234863 14832 trainer.py:139] Epoch[554/1000] loss: 0.2098683938384056
I0803 13:19:43.060701 14832 trainer.py:139] Epoch[555/1000] loss: 0.211003040894866
I0803 13:19:59.024971 14832 trainer.py:139] Epoch[556/1000] loss: 0.20987625792622566
I0803 13:20:15.425378 14832 trainer.py:139] Epoch[557/1000] loss: 0.20944481249898672
I0803 13:20:31.230912 14832 trainer.py:139] Epoch[558/1000] loss: 0.20986810512840748
I0803 13:20:47.364091 14832 trainer.py:139] Epoch[559/1000] loss: 0.2107008546590805
I0803 13:21:03.806525 14832 trainer.py:139] Epoch[560/1000] loss: 0.21011970844119787
I0803 13:21:20.467284 14832 trainer.py:139] Epoch[561/1000] loss: 0.2091148542240262
I0803 13:21:36.762737 14832 trainer.py:139] Epoch[562/1000] loss: 0.21064609102904797
I0803 13:21:53.053799 14832 trainer.py:139] Epoch[563/1000] loss: 0.21059683989733458
I0803 13:22:09.155001 14832 trainer.py:139] Epoch[564/1000] loss: 0.20957211777567863
I0803 13:22:25.199304 14832 trainer.py:139] Epoch[565/1000] loss: 0.2099046465009451
I0803 13:22:41.546713 14832 trainer.py:139] Epoch[566/1000] loss: 0.21110556181520224
I0803 13:22:57.598801 14832 trainer.py:139] Epoch[567/1000] loss: 0.21015654504299164
I0803 13:23:13.607439 14832 trainer.py:139] Epoch[568/1000] loss: 0.2107037715613842
I0803 13:23:29.737451 14832 trainer.py:139] Epoch[569/1000] loss: 0.20952741242945194
I0803 13:23:45.894431 14832 trainer.py:139] Epoch[570/1000] loss: 0.2096210941672325
I0803 13:24:01.800115 14832 trainer.py:139] Epoch[571/1000] loss: 0.2099265716969967
I0803 13:24:17.908033 14832 trainer.py:139] Epoch[572/1000] loss: 0.2110207388177514
I0803 13:24:34.180574 14832 trainer.py:139] Epoch[573/1000] loss: 0.20940516330301762
I0803 13:24:50.507097 14832 trainer.py:139] Epoch[574/1000] loss: 0.20900608878582716
I0803 13:25:06.424108 14832 trainer.py:139] Epoch[575/1000] loss: 0.21012057736516
I0803 13:25:22.314953 14832 trainer.py:139] Epoch[576/1000] loss: 0.2097666822373867
I0803 13:25:38.194764 14832 trainer.py:139] Epoch[577/1000] loss: 0.209873435087502
I0803 13:25:54.183225 14832 trainer.py:139] Epoch[578/1000] loss: 0.20999203715473413
I0803 13:26:10.323313 14832 trainer.py:139] Epoch[579/1000] loss: 0.2091717440634966
I0803 13:26:26.811017 14832 trainer.py:139] Epoch[580/1000] loss: 0.2103322921320796
I0803 13:26:42.783319 14832 trainer.py:139] Epoch[581/1000] loss: 0.2100655473768711
I0803 13:26:59.148542 14832 trainer.py:139] Epoch[582/1000] loss: 0.20852914545685053
I0803 13:27:15.321341 14832 trainer.py:139] Epoch[583/1000] loss: 0.20956034120172262
I0803 13:27:31.447250 14832 trainer.py:139] Epoch[584/1000] loss: 0.21021925285458565
I0803 13:27:47.691791 14832 trainer.py:139] Epoch[585/1000] loss: 0.2090254444628954
I0803 13:28:03.881229 14832 trainer.py:139] Epoch[586/1000] loss: 0.20983857102692127
I0803 13:28:19.799130 14832 trainer.py:139] Epoch[587/1000] loss: 0.20821773633360863
I0803 13:28:35.853212 14832 trainer.py:139] Epoch[588/1000] loss: 0.2087161261588335
I0803 13:28:52.024214 14832 trainer.py:139] Epoch[589/1000] loss: 0.2098953053355217
I0803 13:29:07.899891 14832 trainer.py:139] Epoch[590/1000] loss: 0.20929586328566074
I0803 13:29:24.137095 14832 trainer.py:139] Epoch[591/1000] loss: 0.20884813088923693
I0803 13:29:40.562057 14832 trainer.py:139] Epoch[592/1000] loss: 0.208316289819777
I0803 13:29:56.587353 14832 trainer.py:139] Epoch[593/1000] loss: 0.20909378863871098
I0803 13:30:13.249410 14832 trainer.py:139] Epoch[594/1000] loss: 0.20855992939323187
I0803 13:30:29.305440 14832 trainer.py:139] Epoch[595/1000] loss: 0.20972815062850714
I0803 13:30:45.565044 14832 trainer.py:139] Epoch[596/1000] loss: 0.2088120486587286
I0803 13:31:01.451623 14832 trainer.py:139] Epoch[597/1000] loss: 0.2086016582325101
I0803 13:31:17.763955 14832 trainer.py:139] Epoch[598/1000] loss: 0.20950044505298138
I0803 13:31:33.760665 14832 trainer.py:139] Epoch[599/1000] loss: 0.20835303235799074
I0803 13:31:34.318381 14832 trainer.py:145] Test: [{'precision': 0.1982303839732887, 'recall': 0.28000521479635054, 'hit_ratio': 0.9095158597662771, 'ndcg': 0.3124341392478493}]
I0803 13:31:50.898991 14832 trainer.py:139] Epoch[600/1000] loss: 0.21072026062756777
I0803 13:32:07.339535 14832 trainer.py:139] Epoch[601/1000] loss: 0.20876572746783495
I0803 13:32:23.215374 14832 trainer.py:139] Epoch[602/1000] loss: 0.20960963517427444
I0803 13:32:39.481838 14832 trainer.py:139] Epoch[603/1000] loss: 0.20945575647056103
I0803 13:32:55.820803 14832 trainer.py:139] Epoch[604/1000] loss: 0.20817818772047758
I0803 13:33:12.514129 14832 trainer.py:139] Epoch[605/1000] loss: 0.20889534149318933
I0803 13:33:28.769349 14832 trainer.py:139] Epoch[606/1000] loss: 0.20912912674248219
I0803 13:33:45.495814 14832 trainer.py:139] Epoch[607/1000] loss: 0.20951288752257824
I0803 13:34:01.405524 14832 trainer.py:139] Epoch[608/1000] loss: 0.2089263303205371
I0803 13:34:18.013423 14832 trainer.py:139] Epoch[609/1000] loss: 0.20888982992619276
I0803 13:34:34.656491 14832 trainer.py:139] Epoch[610/1000] loss: 0.20970969460904598
I0803 13:34:51.131430 14832 trainer.py:139] Epoch[611/1000] loss: 0.20808405242860317
I0803 13:35:07.503584 14832 trainer.py:139] Epoch[612/1000] loss: 0.20889289863407612
I0803 13:35:24.031383 14832 trainer.py:139] Epoch[613/1000] loss: 0.20870678406208754
I0803 13:35:40.766421 14832 trainer.py:139] Epoch[614/1000] loss: 0.20822774060070515
I0803 13:35:56.892354 14832 trainer.py:139] Epoch[615/1000] loss: 0.2073040585964918
I0803 13:36:12.977026 14832 trainer.py:139] Epoch[616/1000] loss: 0.20925626251846552
I0803 13:36:29.194421 14832 trainer.py:139] Epoch[617/1000] loss: 0.2093735970556736
I0803 13:36:45.531826 14832 trainer.py:139] Epoch[618/1000] loss: 0.20820810832083225
I0803 13:37:01.629227 14832 trainer.py:139] Epoch[619/1000] loss: 0.20947027578949928
I0803 13:37:17.566304 14832 trainer.py:139] Epoch[620/1000] loss: 0.2079789573326707
I0803 13:37:34.019145 14832 trainer.py:139] Epoch[621/1000] loss: 0.20881590899080038
I0803 13:37:50.268119 14832 trainer.py:139] Epoch[622/1000] loss: 0.2092636227607727
I0803 13:38:06.218544 14832 trainer.py:139] Epoch[623/1000] loss: 0.2089638477191329
I0803 13:38:22.240653 14832 trainer.py:139] Epoch[624/1000] loss: 0.2078087367117405
I0803 13:38:38.109394 14832 trainer.py:139] Epoch[625/1000] loss: 0.20880115870386362
I0803 13:38:54.006109 14832 trainer.py:139] Epoch[626/1000] loss: 0.20810219086706638
I0803 13:39:10.593322 14832 trainer.py:139] Epoch[627/1000] loss: 0.2090866845101118
I0803 13:39:26.726099 14832 trainer.py:139] Epoch[628/1000] loss: 0.20806699339300394
I0803 13:39:42.920230 14832 trainer.py:139] Epoch[629/1000] loss: 0.20873175002634525
I0803 13:39:59.266766 14832 trainer.py:139] Epoch[630/1000] loss: 0.2072238912805915
I0803 13:40:15.607976 14832 trainer.py:139] Epoch[631/1000] loss: 0.208224942907691
I0803 13:40:31.872967 14832 trainer.py:139] Epoch[632/1000] loss: 0.20806829538196325
I0803 13:40:48.092573 14832 trainer.py:139] Epoch[633/1000] loss: 0.20691567193716764
I0803 13:41:04.461298 14832 trainer.py:139] Epoch[634/1000] loss: 0.20693791843950748
I0803 13:41:20.975497 14832 trainer.py:139] Epoch[635/1000] loss: 0.2070294776931405
I0803 13:41:37.440374 14832 trainer.py:139] Epoch[636/1000] loss: 0.20917032845318317
I0803 13:41:53.759007 14832 trainer.py:139] Epoch[637/1000] loss: 0.2087136171758175
I0803 13:42:09.949127 14832 trainer.py:139] Epoch[638/1000] loss: 0.2089247452095151
I0803 13:42:25.890574 14832 trainer.py:139] Epoch[639/1000] loss: 0.2085403073579073
I0803 13:42:42.165230 14832 trainer.py:139] Epoch[640/1000] loss: 0.20873000100255013
I0803 13:42:58.639165 14832 trainer.py:139] Epoch[641/1000] loss: 0.20776843558996916
I0803 13:43:14.460948 14832 trainer.py:139] Epoch[642/1000] loss: 0.20807196851819754
I0803 13:43:30.604138 14832 trainer.py:139] Epoch[643/1000] loss: 0.20759176183491945
I0803 13:43:46.899262 14832 trainer.py:139] Epoch[644/1000] loss: 0.20765176601707935
I0803 13:44:03.006919 14832 trainer.py:139] Epoch[645/1000] loss: 0.20743804145604372
I0803 13:44:19.454256 14832 trainer.py:139] Epoch[646/1000] loss: 0.20784268341958523
I0803 13:44:35.795521 14832 trainer.py:139] Epoch[647/1000] loss: 0.2083807112649083
I0803 13:44:52.346974 14832 trainer.py:139] Epoch[648/1000] loss: 0.20886264648288488
I0803 13:45:08.761003 14832 trainer.py:139] Epoch[649/1000] loss: 0.2080465406179428
I0803 13:45:09.380463 14832 trainer.py:145] Test: [{'precision': 0.19859766277128543, 'recall': 0.28065401878977153, 'hit_ratio': 0.9101836393989984, 'ndcg': 0.3129682212648088}]
I0803 13:45:25.671846 14832 trainer.py:139] Epoch[650/1000] loss: 0.2079272223636508
I0803 13:45:41.770087 14832 trainer.py:139] Epoch[651/1000] loss: 0.20736308861523867
I0803 13:45:58.038568 14832 trainer.py:139] Epoch[652/1000] loss: 0.20744693838059902
I0803 13:46:14.435688 14832 trainer.py:139] Epoch[653/1000] loss: 0.20749066397547722
I0803 13:46:30.482959 14832 trainer.py:139] Epoch[654/1000] loss: 0.20778368320316076
I0803 13:46:46.375449 14832 trainer.py:139] Epoch[655/1000] loss: 0.20744549203664064
I0803 13:47:02.169776 14832 trainer.py:139] Epoch[656/1000] loss: 0.20775625482201576
I0803 13:47:18.743282 14832 trainer.py:139] Epoch[657/1000] loss: 0.20719614438712597
I0803 13:47:35.122429 14832 trainer.py:139] Epoch[658/1000] loss: 0.207337262108922
I0803 13:47:51.560462 14832 trainer.py:139] Epoch[659/1000] loss: 0.20711703039705753
I0803 13:48:07.681692 14832 trainer.py:139] Epoch[660/1000] loss: 0.20644503086805344
I0803 13:48:24.154153 14832 trainer.py:139] Epoch[661/1000] loss: 0.20688421465456486
I0803 13:48:40.163547 14832 trainer.py:139] Epoch[662/1000] loss: 0.20783608499914408
I0803 13:48:56.591707 14832 trainer.py:139] Epoch[663/1000] loss: 0.20690902322530746
I0803 13:49:12.708709 14832 trainer.py:139] Epoch[664/1000] loss: 0.20674417074769735
I0803 13:49:29.047410 14832 trainer.py:139] Epoch[665/1000] loss: 0.20742276683449745
I0803 13:49:44.952005 14832 trainer.py:139] Epoch[666/1000] loss: 0.20699814520776272
I0803 13:50:01.112549 14832 trainer.py:139] Epoch[667/1000] loss: 0.20762625709176064
I0803 13:50:17.397002 14832 trainer.py:139] Epoch[668/1000] loss: 0.20629967376589775
I0803 13:50:33.597588 14832 trainer.py:139] Epoch[669/1000] loss: 0.20798291079699993
I0803 13:50:50.204583 14832 trainer.py:139] Epoch[670/1000] loss: 0.2080351309850812
I0803 13:51:06.470070 14832 trainer.py:139] Epoch[671/1000] loss: 0.20781801734119654
I0803 13:51:23.004086 14832 trainer.py:139] Epoch[672/1000] loss: 0.20695137791335583
I0803 13:51:39.729555 14832 trainer.py:139] Epoch[673/1000] loss: 0.20571751706302166
I0803 13:51:55.994635 14832 trainer.py:139] Epoch[674/1000] loss: 0.2070068996399641
I0803 13:52:12.905466 14832 trainer.py:139] Epoch[675/1000] loss: 0.2067705737426877
I0803 13:52:29.085396 14832 trainer.py:139] Epoch[676/1000] loss: 0.20782369188964367
I0803 13:52:45.117525 14832 trainer.py:139] Epoch[677/1000] loss: 0.20723890233784914
I0803 13:53:01.249345 14832 trainer.py:139] Epoch[678/1000] loss: 0.20819262135773897
I0803 13:53:17.959841 14832 trainer.py:139] Epoch[679/1000] loss: 0.2070109359920025
I0803 13:53:34.505294 14832 trainer.py:139] Epoch[680/1000] loss: 0.20744065009057522
I0803 13:53:50.749889 14832 trainer.py:139] Epoch[681/1000] loss: 0.207269667647779
I0803 13:54:07.111419 14832 trainer.py:139] Epoch[682/1000] loss: 0.20752210170030594
I0803 13:54:23.469723 14832 trainer.py:139] Epoch[683/1000] loss: 0.20696500968188047
I0803 13:54:39.616247 14832 trainer.py:139] Epoch[684/1000] loss: 0.20677501056343317
I0803 13:54:55.865587 14832 trainer.py:139] Epoch[685/1000] loss: 0.20620178151875734
I0803 13:55:11.922324 14832 trainer.py:139] Epoch[686/1000] loss: 0.2075028195977211
I0803 13:55:28.466725 14832 trainer.py:139] Epoch[687/1000] loss: 0.20611300226300955
I0803 13:55:44.911112 14832 trainer.py:139] Epoch[688/1000] loss: 0.2066987408325076
I0803 13:56:01.226238 14832 trainer.py:139] Epoch[689/1000] loss: 0.20744162052869797
I0803 13:56:17.582519 14832 trainer.py:139] Epoch[690/1000] loss: 0.20720528718084097
I0803 13:56:33.805389 14832 trainer.py:139] Epoch[691/1000] loss: 0.20737645030021667
I0803 13:56:50.301513 14832 trainer.py:139] Epoch[692/1000] loss: 0.20787722244858742
I0803 13:57:06.301940 14832 trainer.py:139] Epoch[693/1000] loss: 0.20626674685627222
I0803 13:57:22.737709 14832 trainer.py:139] Epoch[694/1000] loss: 0.20595798082649708
I0803 13:57:39.453820 14832 trainer.py:139] Epoch[695/1000] loss: 0.20684182085096836
I0803 13:57:55.635968 14832 trainer.py:139] Epoch[696/1000] loss: 0.20643195323646069
I0803 13:58:11.748062 14832 trainer.py:139] Epoch[697/1000] loss: 0.20640676002949476
I0803 13:58:28.150501 14832 trainer.py:139] Epoch[698/1000] loss: 0.20629367791116238
I0803 13:58:44.354307 14832 trainer.py:139] Epoch[699/1000] loss: 0.20460903644561768
I0803 13:58:44.897022 14832 trainer.py:145] Test: [{'precision': 0.19879799666110182, 'recall': 0.28088607236136415, 'hit_ratio': 0.9108514190317195, 'ndcg': 0.31377447427105853}]
I0803 13:59:01.060986 14832 trainer.py:139] Epoch[700/1000] loss: 0.20673540607094765
I0803 13:59:17.411728 14832 trainer.py:139] Epoch[701/1000] loss: 0.20778367761522532
I0803 13:59:33.792489 14832 trainer.py:139] Epoch[702/1000] loss: 0.20605312567204237
I0803 13:59:50.052912 14832 trainer.py:139] Epoch[703/1000] loss: 0.20648373290896416
I0803 14:00:05.953070 14832 trainer.py:139] Epoch[704/1000] loss: 0.2066132901236415
I0803 14:00:22.340847 14832 trainer.py:139] Epoch[705/1000] loss: 0.20639048982411623
I0803 14:00:38.438317 14832 trainer.py:139] Epoch[706/1000] loss: 0.20773094333708286
I0803 14:00:54.407989 14832 trainer.py:139] Epoch[707/1000] loss: 0.20609008613973856
I0803 14:01:10.693344 14832 trainer.py:139] Epoch[708/1000] loss: 0.2067677453160286
I0803 14:01:26.855747 14832 trainer.py:139] Epoch[709/1000] loss: 0.20580475870519876
I0803 14:01:42.918741 14832 trainer.py:139] Epoch[710/1000] loss: 0.2064649062231183
I0803 14:01:59.085311 14832 trainer.py:139] Epoch[711/1000] loss: 0.2067293133586645
I0803 14:02:15.473955 14832 trainer.py:139] Epoch[712/1000] loss: 0.20708753634244204
I0803 14:02:31.858577 14832 trainer.py:139] Epoch[713/1000] loss: 0.20612337440252304
I0803 14:02:48.191789 14832 trainer.py:139] Epoch[714/1000] loss: 0.2068945337086916
I0803 14:03:04.252833 14832 trainer.py:139] Epoch[715/1000] loss: 0.20536452904343605
I0803 14:03:20.457481 14832 trainer.py:139] Epoch[716/1000] loss: 0.20567016582936049
I0803 14:03:36.902203 14832 trainer.py:139] Epoch[717/1000] loss: 0.20573415141552687
I0803 14:03:53.494808 14832 trainer.py:139] Epoch[718/1000] loss: 0.206801344640553
I0803 14:04:09.612754 14832 trainer.py:139] Epoch[719/1000] loss: 0.206487650051713
I0803 14:04:25.747689 14832 trainer.py:139] Epoch[720/1000] loss: 0.20661429315805435
I0803 14:04:41.990558 14832 trainer.py:139] Epoch[721/1000] loss: 0.20703283045440912
I0803 14:04:58.112352 14832 trainer.py:139] Epoch[722/1000] loss: 0.20678954105824232
I0803 14:05:13.893886 14832 trainer.py:139] Epoch[723/1000] loss: 0.20664946734905243
I0803 14:05:30.434744 14832 trainer.py:139] Epoch[724/1000] loss: 0.20610460173338652
I0803 14:05:46.976924 14832 trainer.py:139] Epoch[725/1000] loss: 0.20620259828865528
I0803 14:06:03.038330 14832 trainer.py:139] Epoch[726/1000] loss: 0.2072978401556611
I0803 14:06:19.588204 14832 trainer.py:139] Epoch[727/1000] loss: 0.2061303649097681
I0803 14:06:35.653423 14832 trainer.py:139] Epoch[728/1000] loss: 0.20564107783138752
I0803 14:06:51.767962 14832 trainer.py:139] Epoch[729/1000] loss: 0.20513503160327673
I0803 14:07:08.320444 14832 trainer.py:139] Epoch[730/1000] loss: 0.20529082510620356
I0803 14:07:24.554279 14832 trainer.py:139] Epoch[731/1000] loss: 0.2051873281598091
I0803 14:07:40.768937 14832 trainer.py:139] Epoch[732/1000] loss: 0.2056490620598197
I0803 14:07:57.307924 14832 trainer.py:139] Epoch[733/1000] loss: 0.2061500195413828
I0803 14:08:13.346724 14832 trainer.py:139] Epoch[734/1000] loss: 0.2063473742455244
I0803 14:08:29.974862 14832 trainer.py:139] Epoch[735/1000] loss: 0.20490417070686817
I0803 14:08:46.297909 14832 trainer.py:139] Epoch[736/1000] loss: 0.20646454952657223
I0803 14:09:02.529453 14832 trainer.py:139] Epoch[737/1000] loss: 0.2060244157910347
I0803 14:09:18.726601 14832 trainer.py:139] Epoch[738/1000] loss: 0.2050439789891243
I0803 14:09:35.341672 14832 trainer.py:139] Epoch[739/1000] loss: 0.20562596153467894
I0803 14:09:51.849808 14832 trainer.py:139] Epoch[740/1000] loss: 0.20444581378251314
I0803 14:10:08.005310 14832 trainer.py:139] Epoch[741/1000] loss: 0.20639153476804495
I0803 14:10:23.886180 14832 trainer.py:139] Epoch[742/1000] loss: 0.2055935999378562
I0803 14:10:40.235557 14832 trainer.py:139] Epoch[743/1000] loss: 0.2057734690606594
I0803 14:10:56.523637 14832 trainer.py:139] Epoch[744/1000] loss: 0.2057885266840458
I0803 14:11:13.225403 14832 trainer.py:139] Epoch[745/1000] loss: 0.20566745568066835
I0803 14:11:29.910183 14832 trainer.py:139] Epoch[746/1000] loss: 0.2061292566359043
I0803 14:11:46.222558 14832 trainer.py:139] Epoch[747/1000] loss: 0.20458784699440002
I0803 14:12:02.075721 14832 trainer.py:139] Epoch[748/1000] loss: 0.20632814802229404
I0803 14:12:18.216515 14832 trainer.py:139] Epoch[749/1000] loss: 0.20556449703872204
I0803 14:12:18.816056 14832 trainer.py:145] Test: [{'precision': 0.19916527545909848, 'recall': 0.28170113674633634, 'hit_ratio': 0.9101836393989984, 'ndcg': 0.31467611473899243}]
I0803 14:12:34.987830 14832 trainer.py:139] Epoch[750/1000] loss: 0.2046436918899417
I0803 14:12:51.059013 14832 trainer.py:139] Epoch[751/1000] loss: 0.20512797869741917
I0803 14:13:07.145976 14832 trainer.py:139] Epoch[752/1000] loss: 0.20462527684867382
I0803 14:13:23.648950 14832 trainer.py:139] Epoch[753/1000] loss: 0.20613512210547924
I0803 14:13:40.081805 14832 trainer.py:139] Epoch[754/1000] loss: 0.20524316281080246
I0803 14:13:56.540705 14832 trainer.py:139] Epoch[755/1000] loss: 0.20538206957280636
I0803 14:14:13.062802 14832 trainer.py:139] Epoch[756/1000] loss: 0.20509266015142202
I0803 14:14:29.357688 14832 trainer.py:139] Epoch[757/1000] loss: 0.2049507750198245
I0803 14:14:45.381707 14832 trainer.py:139] Epoch[758/1000] loss: 0.20510628446936607
I0803 14:15:01.975740 14832 trainer.py:139] Epoch[759/1000] loss: 0.20550793409347534
I0803 14:15:18.463758 14832 trainer.py:139] Epoch[760/1000] loss: 0.20604538451880217
I0803 14:15:35.079374 14832 trainer.py:139] Epoch[761/1000] loss: 0.20527320448309183
I0803 14:15:50.921110 14832 trainer.py:139] Epoch[762/1000] loss: 0.20478273555636406
I0803 14:16:07.211763 14832 trainer.py:139] Epoch[763/1000] loss: 0.20498333778232336
I0803 14:16:23.313939 14832 trainer.py:139] Epoch[764/1000] loss: 0.20404482074081898
I0803 14:16:39.306554 14832 trainer.py:139] Epoch[765/1000] loss: 0.204374510794878
I0803 14:16:55.103057 14832 trainer.py:139] Epoch[766/1000] loss: 0.2055468587204814
I0803 14:17:10.982971 14832 trainer.py:139] Epoch[767/1000] loss: 0.20483746472746134
I0803 14:17:27.802307 14832 trainer.py:139] Epoch[768/1000] loss: 0.20556944981217384
I0803 14:17:44.294775 14832 trainer.py:139] Epoch[769/1000] loss: 0.20500040892511606
I0803 14:18:00.543890 14832 trainer.py:139] Epoch[770/1000] loss: 0.20584373082965612
I0803 14:18:16.447965 14832 trainer.py:139] Epoch[771/1000] loss: 0.20486950408667326
I0803 14:18:32.509165 14832 trainer.py:139] Epoch[772/1000] loss: 0.2051325310021639
I0803 14:18:48.448829 14832 trainer.py:139] Epoch[773/1000] loss: 0.20463453140109777
I0803 14:19:04.624274 14832 trainer.py:139] Epoch[774/1000] loss: 0.20484743174165487
I0803 14:19:20.654551 14832 trainer.py:139] Epoch[775/1000] loss: 0.2050433335825801
I0803 14:19:36.594012 14832 trainer.py:139] Epoch[776/1000] loss: 0.20392029266804457
I0803 14:19:52.690896 14832 trainer.py:139] Epoch[777/1000] loss: 0.20490715745836496
I0803 14:20:09.008924 14832 trainer.py:139] Epoch[778/1000] loss: 0.2065091161057353
I0803 14:20:25.358528 14832 trainer.py:139] Epoch[779/1000] loss: 0.2064361097291112
I0803 14:20:41.707296 14832 trainer.py:139] Epoch[780/1000] loss: 0.20517158694565296
I0803 14:20:57.647506 14832 trainer.py:139] Epoch[781/1000] loss: 0.2051399303600192
I0803 14:21:13.997074 14832 trainer.py:139] Epoch[782/1000] loss: 0.2053705733269453
I0803 14:21:30.140092 14832 trainer.py:139] Epoch[783/1000] loss: 0.20462767034769058
I0803 14:21:46.424389 14832 trainer.py:139] Epoch[784/1000] loss: 0.20523474738001823
I0803 14:22:02.580435 14832 trainer.py:139] Epoch[785/1000] loss: 0.20443088933825493
I0803 14:22:19.106545 14832 trainer.py:139] Epoch[786/1000] loss: 0.2055631298571825
I0803 14:22:35.169693 14832 trainer.py:139] Epoch[787/1000] loss: 0.20651071425527334
I0803 14:22:51.203002 14832 trainer.py:139] Epoch[788/1000] loss: 0.20448629558086395
I0803 14:23:08.123654 14832 trainer.py:139] Epoch[789/1000] loss: 0.20398613810539246
I0803 14:23:24.756670 14832 trainer.py:139] Epoch[790/1000] loss: 0.20424728281795979
I0803 14:23:40.951795 14832 trainer.py:139] Epoch[791/1000] loss: 0.2052629552781582
I0803 14:23:57.115026 14832 trainer.py:139] Epoch[792/1000] loss: 0.20506169088184834
I0803 14:24:13.486357 14832 trainer.py:139] Epoch[793/1000] loss: 0.20446127094328403
I0803 14:24:29.825364 14832 trainer.py:139] Epoch[794/1000] loss: 0.20400595851242542
I0803 14:24:45.974390 14832 trainer.py:139] Epoch[795/1000] loss: 0.20564563758671284
I0803 14:25:01.962810 14832 trainer.py:139] Epoch[796/1000] loss: 0.20446115545928478
I0803 14:25:18.375507 14832 trainer.py:139] Epoch[797/1000] loss: 0.20349616929888725
I0803 14:25:34.619228 14832 trainer.py:139] Epoch[798/1000] loss: 0.20453216042369604
I0803 14:25:50.587692 14832 trainer.py:139] Epoch[799/1000] loss: 0.20487796235829592
I0803 14:25:51.160338 14832 trainer.py:145] Test: [{'precision': 0.19994991652754587, 'recall': 0.282502555518698, 'hit_ratio': 0.9103505843071786, 'ndcg': 0.31566857496388173}]
I0803 14:26:07.129155 14832 trainer.py:139] Epoch[800/1000] loss: 0.2048773979768157
I0803 14:26:23.653069 14832 trainer.py:139] Epoch[801/1000] loss: 0.203637913800776
I0803 14:26:39.742377 14832 trainer.py:139] Epoch[802/1000] loss: 0.20410539489239454
I0803 14:26:56.087326 14832 trainer.py:139] Epoch[803/1000] loss: 0.2043478861451149
I0803 14:27:12.810043 14832 trainer.py:139] Epoch[804/1000] loss: 0.2046737940981984
I0803 14:27:29.350006 14832 trainer.py:139] Epoch[805/1000] loss: 0.2044412363320589
I0803 14:27:45.613967 14832 trainer.py:139] Epoch[806/1000] loss: 0.20466436725109816
I0803 14:28:02.283343 14832 trainer.py:139] Epoch[807/1000] loss: 0.20545981265604496
I0803 14:28:18.763342 14832 trainer.py:139] Epoch[808/1000] loss: 0.20437264256179333
I0803 14:28:34.916613 14832 trainer.py:139] Epoch[809/1000] loss: 0.20463508646935225
I0803 14:28:50.949051 14832 trainer.py:139] Epoch[810/1000] loss: 0.20497707277536392
I0803 14:29:07.102969 14832 trainer.py:139] Epoch[811/1000] loss: 0.20435152854770422
I0803 14:29:23.615583 14832 trainer.py:139] Epoch[812/1000] loss: 0.20361645985394716
I0803 14:29:39.890832 14832 trainer.py:139] Epoch[813/1000] loss: 0.20450352784246206
I0803 14:29:56.409596 14832 trainer.py:139] Epoch[814/1000] loss: 0.2039382429793477
I0803 14:30:12.586995 14832 trainer.py:139] Epoch[815/1000] loss: 0.20387903600931168
I0803 14:30:28.854709 14832 trainer.py:139] Epoch[816/1000] loss: 0.20515806507319212
I0803 14:30:44.898363 14832 trainer.py:139] Epoch[817/1000] loss: 0.20526348892599344
I0803 14:31:01.224972 14832 trainer.py:139] Epoch[818/1000] loss: 0.20287876203656197
I0803 14:31:17.188390 14832 trainer.py:139] Epoch[819/1000] loss: 0.2046299735084176
I0803 14:31:33.686315 14832 trainer.py:139] Epoch[820/1000] loss: 0.20459106843918562
I0803 14:31:49.768330 14832 trainer.py:139] Epoch[821/1000] loss: 0.2043460998684168
I0803 14:32:06.042760 14832 trainer.py:139] Epoch[822/1000] loss: 0.2042545024305582
I0803 14:32:22.767641 14832 trainer.py:139] Epoch[823/1000] loss: 0.2045683115720749
I0803 14:32:38.899427 14832 trainer.py:139] Epoch[824/1000] loss: 0.203910605981946
I0803 14:32:55.010368 14832 trainer.py:139] Epoch[825/1000] loss: 0.20436920505017042
I0803 14:33:11.553106 14832 trainer.py:139] Epoch[826/1000] loss: 0.20568108279258013
I0803 14:33:28.330355 14832 trainer.py:139] Epoch[827/1000] loss: 0.20527044590562582
I0803 14:33:45.134590 14832 trainer.py:139] Epoch[828/1000] loss: 0.2035887222737074
I0803 14:34:01.791932 14832 trainer.py:139] Epoch[829/1000] loss: 0.20468718651682138
I0803 14:34:18.238514 14832 trainer.py:139] Epoch[830/1000] loss: 0.20308558642864227
I0803 14:34:34.644583 14832 trainer.py:139] Epoch[831/1000] loss: 0.2041154783219099
I0803 14:34:51.154625 14832 trainer.py:139] Epoch[832/1000] loss: 0.2035179128870368
I0803 14:35:08.054753 14832 trainer.py:139] Epoch[833/1000] loss: 0.20410774089396
I0803 14:35:25.045296 14832 trainer.py:139] Epoch[834/1000] loss: 0.20474314503371716
I0803 14:35:41.772800 14832 trainer.py:139] Epoch[835/1000] loss: 0.20389484334737062
I0803 14:35:58.044982 14832 trainer.py:139] Epoch[836/1000] loss: 0.20394427981227636
I0803 14:36:14.847462 14832 trainer.py:139] Epoch[837/1000] loss: 0.20316485036164522
I0803 14:36:31.325029 14832 trainer.py:139] Epoch[838/1000] loss: 0.20380758866667747
I0803 14:36:47.893189 14832 trainer.py:139] Epoch[839/1000] loss: 0.20383056160062551
I0803 14:37:04.436961 14832 trainer.py:139] Epoch[840/1000] loss: 0.2032472686842084
I0803 14:37:20.587112 14832 trainer.py:139] Epoch[841/1000] loss: 0.20392053294926882
I0803 14:37:37.144160 14832 trainer.py:139] Epoch[842/1000] loss: 0.20467676501721144
I0803 14:37:53.592019 14832 trainer.py:139] Epoch[843/1000] loss: 0.20405528508126736
I0803 14:38:09.913473 14832 trainer.py:139] Epoch[844/1000] loss: 0.20363019034266472
I0803 14:38:26.254899 14832 trainer.py:139] Epoch[845/1000] loss: 0.203396650031209
I0803 14:38:42.589283 14832 trainer.py:139] Epoch[846/1000] loss: 0.20456570386886597
I0803 14:38:59.033511 14832 trainer.py:139] Epoch[847/1000] loss: 0.20354741252958775
I0803 14:39:15.371387 14832 trainer.py:139] Epoch[848/1000] loss: 0.20451949164271355
I0803 14:39:32.317131 14832 trainer.py:139] Epoch[849/1000] loss: 0.20317212212830782
I0803 14:39:32.897740 14832 trainer.py:145] Test: [{'precision': 0.19987479131886474, 'recall': 0.28224262313006604, 'hit_ratio': 0.9106844741235393, 'ndcg': 0.3155199404964505}]
I0803 14:39:49.094312 14832 trainer.py:139] Epoch[850/1000] loss: 0.20446750428527594
I0803 14:40:05.339604 14832 trainer.py:139] Epoch[851/1000] loss: 0.2040881747379899
I0803 14:40:21.426562 14832 trainer.py:139] Epoch[852/1000] loss: 0.20425070356577635
I0803 14:40:37.643305 14832 trainer.py:139] Epoch[853/1000] loss: 0.20419452711939812
I0803 14:40:53.833837 14832 trainer.py:139] Epoch[854/1000] loss: 0.20388396829366684
I0803 14:41:10.046224 14832 trainer.py:139] Epoch[855/1000] loss: 0.20292247086763382
I0803 14:41:26.520205 14832 trainer.py:139] Epoch[856/1000] loss: 0.20348459668457508
I0803 14:41:42.840450 14832 trainer.py:139] Epoch[857/1000] loss: 0.20319082215428352
I0803 14:41:59.094762 14832 trainer.py:139] Epoch[858/1000] loss: 0.2034742310643196
I0803 14:42:15.766380 14832 trainer.py:139] Epoch[859/1000] loss: 0.2028461955487728
I0803 14:42:31.911911 14832 trainer.py:139] Epoch[860/1000] loss: 0.20345155242830515
I0803 14:42:47.692598 14832 trainer.py:139] Epoch[861/1000] loss: 0.20393008459359407
I0803 14:43:03.875996 14832 trainer.py:139] Epoch[862/1000] loss: 0.20395697094500065
I0803 14:43:20.024671 14832 trainer.py:139] Epoch[863/1000] loss: 0.20303948409855366
I0803 14:43:36.047751 14832 trainer.py:139] Epoch[864/1000] loss: 0.20354649890214205
I0803 14:43:51.848795 14832 trainer.py:139] Epoch[865/1000] loss: 0.20416782423853874
I0803 14:44:07.829070 14832 trainer.py:139] Epoch[866/1000] loss: 0.2036502854898572
I0803 14:44:24.295990 14832 trainer.py:139] Epoch[867/1000] loss: 0.20414179004728794
I0803 14:44:40.760843 14832 trainer.py:139] Epoch[868/1000] loss: 0.20318966545164585
I0803 14:44:57.397195 14832 trainer.py:139] Epoch[869/1000] loss: 0.2033612271770835
I0803 14:45:13.495342 14832 trainer.py:139] Epoch[870/1000] loss: 0.20336637180298567
I0803 14:45:29.792720 14832 trainer.py:139] Epoch[871/1000] loss: 0.2027800139039755
I0803 14:45:46.647680 14832 trainer.py:139] Epoch[872/1000] loss: 0.20416069775819778
I0803 14:46:02.934655 14832 trainer.py:139] Epoch[873/1000] loss: 0.20283207949250937
I0803 14:46:19.461252 14832 trainer.py:139] Epoch[874/1000] loss: 0.20252206176519394
I0803 14:46:35.556334 14832 trainer.py:139] Epoch[875/1000] loss: 0.20225559640675783
I0803 14:46:52.191374 14832 trainer.py:139] Epoch[876/1000] loss: 0.20310003962367773
I0803 14:47:08.060361 14832 trainer.py:139] Epoch[877/1000] loss: 0.20322344824671745
I0803 14:47:24.242238 14832 trainer.py:139] Epoch[878/1000] loss: 0.20185864344239235
I0803 14:47:40.645201 14832 trainer.py:139] Epoch[879/1000] loss: 0.2036727061495185
I0803 14:47:57.002299 14832 trainer.py:139] Epoch[880/1000] loss: 0.20302846189588308
I0803 14:48:12.936635 14832 trainer.py:139] Epoch[881/1000] loss: 0.20387471746653318
I0803 14:48:29.506481 14832 trainer.py:139] Epoch[882/1000] loss: 0.20422579534351826
I0803 14:48:45.719339 14832 trainer.py:139] Epoch[883/1000] loss: 0.2028036592528224
I0803 14:49:01.784834 14832 trainer.py:139] Epoch[884/1000] loss: 0.20425318833440542
I0803 14:49:17.684514 14832 trainer.py:139] Epoch[885/1000] loss: 0.20249631442129612
I0803 14:49:34.046796 14832 trainer.py:139] Epoch[886/1000] loss: 0.2040360737591982
I0803 14:49:49.820455 14832 trainer.py:139] Epoch[887/1000] loss: 0.2027876153588295
I0803 14:50:05.887879 14832 trainer.py:139] Epoch[888/1000] loss: 0.2033122731372714
I0803 14:50:22.291323 14832 trainer.py:139] Epoch[889/1000] loss: 0.20301550347357988
I0803 14:50:38.620240 14832 trainer.py:139] Epoch[890/1000] loss: 0.20355148054659367
I0803 14:50:54.968076 14832 trainer.py:139] Epoch[891/1000] loss: 0.2028332930058241
I0803 14:51:11.168603 14832 trainer.py:139] Epoch[892/1000] loss: 0.20337768364697695
I0803 14:51:27.463116 14832 trainer.py:139] Epoch[893/1000] loss: 0.20349857863038778
I0803 14:51:43.890580 14832 trainer.py:139] Epoch[894/1000] loss: 0.204303159378469
I0803 14:52:00.257169 14832 trainer.py:139] Epoch[895/1000] loss: 0.20315913390368223
I0803 14:52:16.784218 14832 trainer.py:139] Epoch[896/1000] loss: 0.20296726282685995
I0803 14:52:32.930173 14832 trainer.py:139] Epoch[897/1000] loss: 0.20294033456593752
I0803 14:52:49.148153 14832 trainer.py:139] Epoch[898/1000] loss: 0.20388419926166534
I0803 14:53:05.436650 14832 trainer.py:139] Epoch[899/1000] loss: 0.20379506144672632
I0803 14:53:05.989328 14832 trainer.py:145] Test: [{'precision': 0.2003505843071786, 'recall': 0.2834705638106678, 'hit_ratio': 0.9128547579298831, 'ndcg': 0.31721927281400764}]
I0803 14:53:22.410027 14832 trainer.py:139] Epoch[900/1000] loss: 0.20350424107164145
I0803 14:53:39.308395 14832 trainer.py:139] Epoch[901/1000] loss: 0.20335836987942457
I0803 14:53:55.492648 14832 trainer.py:139] Epoch[902/1000] loss: 0.2038754690438509
I0803 14:54:11.562243 14832 trainer.py:139] Epoch[903/1000] loss: 0.20298498217016459
I0803 14:54:27.914773 14832 trainer.py:139] Epoch[904/1000] loss: 0.2036201423034072
I0803 14:54:44.140766 14832 trainer.py:139] Epoch[905/1000] loss: 0.2032231381163001
I0803 14:55:00.176924 14832 trainer.py:139] Epoch[906/1000] loss: 0.20273821707814932
I0803 14:55:16.620768 14832 trainer.py:139] Epoch[907/1000] loss: 0.2020900072529912
I0803 14:55:32.723674 14832 trainer.py:139] Epoch[908/1000] loss: 0.20326180197298527
I0803 14:55:49.021520 14832 trainer.py:139] Epoch[909/1000] loss: 0.20313991606235504
I0803 14:56:05.023905 14832 trainer.py:139] Epoch[910/1000] loss: 0.20291262678802013
I0803 14:56:21.628038 14832 trainer.py:139] Epoch[911/1000] loss: 0.20323546696454287
I0803 14:56:37.889140 14832 trainer.py:139] Epoch[912/1000] loss: 0.20260258950293064
I0803 14:56:54.057087 14832 trainer.py:139] Epoch[913/1000] loss: 0.2031031297519803
I0803 14:57:10.848937 14832 trainer.py:139] Epoch[914/1000] loss: 0.20185580756515265
I0803 14:57:27.056815 14832 trainer.py:139] Epoch[915/1000] loss: 0.20307414419949055
I0803 14:57:43.388686 14832 trainer.py:139] Epoch[916/1000] loss: 0.2033222308382392
I0803 14:57:59.699272 14832 trainer.py:139] Epoch[917/1000] loss: 0.2031895825639367
I0803 14:58:15.877445 14832 trainer.py:139] Epoch[918/1000] loss: 0.20232318062335253
I0803 14:58:31.990047 14832 trainer.py:139] Epoch[919/1000] loss: 0.2026868537068367
I0803 14:58:48.091647 14832 trainer.py:139] Epoch[920/1000] loss: 0.20172670762985945
I0803 14:59:04.086682 14832 trainer.py:139] Epoch[921/1000] loss: 0.20287356059998274
I0803 14:59:20.434293 14832 trainer.py:139] Epoch[922/1000] loss: 0.20174979511648417
I0803 14:59:37.137714 14832 trainer.py:139] Epoch[923/1000] loss: 0.20268638618290424
I0803 14:59:53.962919 14832 trainer.py:139] Epoch[924/1000] loss: 0.20321382954716682
I0803 15:00:11.744312 14832 trainer.py:139] Epoch[925/1000] loss: 0.20430375542491674
I0803 15:00:28.787475 14832 trainer.py:139] Epoch[926/1000] loss: 0.20311901904642582
I0803 15:00:45.200048 14832 trainer.py:139] Epoch[927/1000] loss: 0.20288689713925123
I0803 15:01:01.449317 14832 trainer.py:139] Epoch[928/1000] loss: 0.20220435038208961
I0803 15:01:17.587249 14832 trainer.py:139] Epoch[929/1000] loss: 0.20210276823490858
I0803 15:01:33.865912 14832 trainer.py:139] Epoch[930/1000] loss: 0.20190739631652832
I0803 15:01:49.844306 14832 trainer.py:139] Epoch[931/1000] loss: 0.20269246771931648
I0803 15:02:06.248310 14832 trainer.py:139] Epoch[932/1000] loss: 0.20374579448252916
I0803 15:02:22.675613 14832 trainer.py:139] Epoch[933/1000] loss: 0.2030004309490323
I0803 15:02:39.498836 14832 trainer.py:139] Epoch[934/1000] loss: 0.20199616719037294
I0803 15:02:56.389211 14832 trainer.py:139] Epoch[935/1000] loss: 0.202944858931005
I0803 15:03:13.316463 14832 trainer.py:139] Epoch[936/1000] loss: 0.20305736735463142
I0803 15:03:29.831761 14832 trainer.py:139] Epoch[937/1000] loss: 0.20244790893048048
I0803 15:03:46.460197 14832 trainer.py:139] Epoch[938/1000] loss: 0.20182428508996964
I0803 15:04:02.559227 14832 trainer.py:139] Epoch[939/1000] loss: 0.20192907471209764
I0803 15:04:18.781370 14832 trainer.py:139] Epoch[940/1000] loss: 0.2018788754940033
I0803 15:04:35.469876 14832 trainer.py:139] Epoch[941/1000] loss: 0.20186984166502953
I0803 15:04:51.877713 14832 trainer.py:139] Epoch[942/1000] loss: 0.20190560165792704
I0803 15:05:10.189251 14832 trainer.py:139] Epoch[943/1000] loss: 0.20320879854261875
I0803 15:05:28.543941 14832 trainer.py:139] Epoch[944/1000] loss: 0.20247690565884113
I0803 15:05:47.586977 14832 trainer.py:139] Epoch[945/1000] loss: 0.2019228395074606
I0803 15:06:06.272965 14832 trainer.py:139] Epoch[946/1000] loss: 0.20215429086238146
I0803 15:06:25.337552 14832 trainer.py:139] Epoch[947/1000] loss: 0.20215350110083818
I0803 15:06:43.828126 14832 trainer.py:139] Epoch[948/1000] loss: 0.20215064752846956
I0803 15:07:01.987473 14832 trainer.py:139] Epoch[949/1000] loss: 0.20206725876778364
I0803 15:07:02.702081 14832 trainer.py:145] Test: [{'precision': 0.20058430717863102, 'recall': 0.2843630729546389, 'hit_ratio': 0.9131886477462438, 'ndcg': 0.31774176816454763}]
I0803 15:07:20.956406 14832 trainer.py:139] Epoch[950/1000] loss: 0.2015001531690359
I0803 15:07:40.305802 14832 trainer.py:139] Epoch[951/1000] loss: 0.20310143008828163
I0803 15:08:01.831767 14832 trainer.py:139] Epoch[952/1000] loss: 0.20215964131057262
I0803 15:08:21.342460 14832 trainer.py:139] Epoch[953/1000] loss: 0.20243853144347668
I0803 15:08:39.864444 14832 trainer.py:139] Epoch[954/1000] loss: 0.2015854362398386
I0803 15:08:58.417855 14832 trainer.py:139] Epoch[955/1000] loss: 0.20183616317808628
I0803 15:09:16.761354 14832 trainer.py:139] Epoch[956/1000] loss: 0.20157064124941826
I0803 15:09:35.360350 14832 trainer.py:139] Epoch[957/1000] loss: 0.20210978295654058
I0803 15:09:53.713169 14832 trainer.py:139] Epoch[958/1000] loss: 0.2028112541884184
I0803 15:10:12.344727 14832 trainer.py:139] Epoch[959/1000] loss: 0.20191343408077955
I0803 15:10:30.960132 14832 trainer.py:139] Epoch[960/1000] loss: 0.20162129029631615
I0803 15:10:49.148782 14832 trainer.py:139] Epoch[961/1000] loss: 0.20223357062786818
I0803 15:11:07.759953 14832 trainer.py:139] Epoch[962/1000] loss: 0.20271914917975664
I0803 15:11:26.240103 14832 trainer.py:139] Epoch[963/1000] loss: 0.20194983668625355
I0803 15:11:44.608244 14832 trainer.py:139] Epoch[964/1000] loss: 0.20236860308796167
I0803 15:12:03.223141 14832 trainer.py:139] Epoch[965/1000] loss: 0.20232715643942356
I0803 15:12:21.724470 14832 trainer.py:139] Epoch[966/1000] loss: 0.20212602522224188
I0803 15:12:40.264634 14832 trainer.py:139] Epoch[967/1000] loss: 0.20161781460046768
I0803 15:12:58.204365 14832 trainer.py:139] Epoch[968/1000] loss: 0.2018220964819193
I0803 15:13:16.188693 14832 trainer.py:139] Epoch[969/1000] loss: 0.20195692032575607
I0803 15:13:34.204129 14832 trainer.py:139] Epoch[970/1000] loss: 0.2023160746321082
I0803 15:13:52.741875 14832 trainer.py:139] Epoch[971/1000] loss: 0.20206815097481012
I0803 15:14:10.991720 14832 trainer.py:139] Epoch[972/1000] loss: 0.20285020023584366
I0803 15:14:29.107682 14832 trainer.py:139] Epoch[973/1000] loss: 0.20258385874330997
I0803 15:14:47.585104 14832 trainer.py:139] Epoch[974/1000] loss: 0.2025060337036848
I0803 15:15:06.222473 14832 trainer.py:139] Epoch[975/1000] loss: 0.20192911755293608
I0803 15:15:24.983301 14832 trainer.py:139] Epoch[976/1000] loss: 0.20200379751622677
I0803 15:15:43.930546 14832 trainer.py:139] Epoch[977/1000] loss: 0.20208276994526386
I0803 15:16:02.418769 14832 trainer.py:139] Epoch[978/1000] loss: 0.20163262449204922
I0803 15:16:20.294017 14832 trainer.py:139] Epoch[979/1000] loss: 0.20136146433651447
I0803 15:16:37.955401 14832 trainer.py:139] Epoch[980/1000] loss: 0.20203321985900402
I0803 15:16:56.786263 14832 trainer.py:139] Epoch[981/1000] loss: 0.2016332745552063
I0803 15:17:14.836102 14832 trainer.py:139] Epoch[982/1000] loss: 0.20135354530066252
I0803 15:17:32.799149 14832 trainer.py:139] Epoch[983/1000] loss: 0.2016668664291501
I0803 15:17:49.649048 14832 trainer.py:139] Epoch[984/1000] loss: 0.2019455088302493
I0803 15:18:06.655610 14832 trainer.py:139] Epoch[985/1000] loss: 0.20228502992540598
I0803 15:18:23.596886 14832 trainer.py:139] Epoch[986/1000] loss: 0.2004104796797037
I0803 15:18:42.404536 14832 trainer.py:139] Epoch[987/1000] loss: 0.20118983648717403
I0803 15:19:00.582618 14832 trainer.py:139] Epoch[988/1000] loss: 0.20133872982114553
I0803 15:19:18.389034 14832 trainer.py:139] Epoch[989/1000] loss: 0.20125201530754566
I0803 15:19:35.942575 14832 trainer.py:139] Epoch[990/1000] loss: 0.20285456534475088
I0803 15:19:53.055001 14832 trainer.py:139] Epoch[991/1000] loss: 0.20236330665647984
I0803 15:20:10.051168 14832 trainer.py:139] Epoch[992/1000] loss: 0.20224851090461016
I0803 15:20:27.606683 14832 trainer.py:139] Epoch[993/1000] loss: 0.20254348032176495
I0803 15:20:45.085800 14832 trainer.py:139] Epoch[994/1000] loss: 0.20207124948501587
I0803 15:21:02.805687 14832 trainer.py:139] Epoch[995/1000] loss: 0.20275665633380413
I0803 15:21:20.086042 14832 trainer.py:139] Epoch[996/1000] loss: 0.20176580362021923
I0803 15:21:36.807934 14832 trainer.py:139] Epoch[997/1000] loss: 0.20017713028937578
I0803 15:21:54.323764 14832 trainer.py:139] Epoch[998/1000] loss: 0.2024310976266861
I0803 15:22:11.858952 14832 trainer.py:139] Epoch[999/1000] loss: 0.20076555386185646
I0803 15:22:12.512764 14832 trainer.py:145] Test: [{'precision': 0.20045909849749574, 'recall': 0.28351735100793773, 'hit_ratio': 0.9120200333889816, 'ndcg': 0.31720088554100895}]
