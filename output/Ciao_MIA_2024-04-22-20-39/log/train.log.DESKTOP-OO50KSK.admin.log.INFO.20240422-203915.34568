I0422 20:39:24.355345 23876 trainer.py:118] Test: [{'precision': 0.0020524515393386543, 'recall': 0.009810182544159832, 'hit_ratio': 0.03620296465222349, 'ndcg': 0.007271181503949928}]
I0422 20:39:28.131889 23876 trainer.py:136] Epoch[0/1000] loss: 0.6962435394525528
I0422 20:39:31.709363 23876 trainer.py:136] Epoch[1/1000] loss: 0.6945501416921616
I0422 20:39:35.392994 23876 trainer.py:136] Epoch[2/1000] loss: 0.6836406141519547
I0422 20:39:39.005687 23876 trainer.py:136] Epoch[3/1000] loss: 0.6803879290819168
I0422 20:39:42.809813 23876 trainer.py:136] Epoch[4/1000] loss: 0.6750507354736328
I0422 20:39:46.450796 23876 trainer.py:136] Epoch[5/1000] loss: 0.669889822602272
I0422 20:39:50.156809 23876 trainer.py:136] Epoch[6/1000] loss: 0.6664941012859344
I0422 20:39:53.818269 23876 trainer.py:136] Epoch[7/1000] loss: 0.6643407642841339
I0422 20:39:57.539104 23876 trainer.py:136] Epoch[8/1000] loss: 0.6595838963985443
I0422 20:40:01.338274 23876 trainer.py:136] Epoch[9/1000] loss: 0.656801775097847
I0422 20:40:04.988854 23876 trainer.py:136] Epoch[10/1000] loss: 0.652087852358818
I0422 20:40:08.828757 23876 trainer.py:136] Epoch[11/1000] loss: 0.6483461558818817
I0422 20:40:12.469654 23876 trainer.py:136] Epoch[12/1000] loss: 0.6452996581792831
I0422 20:40:16.127782 23876 trainer.py:136] Epoch[13/1000] loss: 0.6422901004552841
I0422 20:40:19.796180 23876 trainer.py:136] Epoch[14/1000] loss: 0.639617994427681
I0422 20:40:23.639287 23876 trainer.py:136] Epoch[15/1000] loss: 0.6343134641647339
I0422 20:40:27.499760 23876 trainer.py:136] Epoch[16/1000] loss: 0.631090447306633
I0422 20:40:31.175704 23876 trainer.py:136] Epoch[17/1000] loss: 0.6273234188556671
I0422 20:40:35.094286 23876 trainer.py:136] Epoch[18/1000] loss: 0.6234177052974701
I0422 20:40:39.091407 23876 trainer.py:136] Epoch[19/1000] loss: 0.6186454743146896
I0422 20:40:42.933992 23876 trainer.py:136] Epoch[20/1000] loss: 0.612824559211731
I0422 20:40:46.725197 23876 trainer.py:136] Epoch[21/1000] loss: 0.6096446514129639
I0422 20:40:50.372338 23876 trainer.py:136] Epoch[22/1000] loss: 0.6036735326051712
I0422 20:40:54.259465 23876 trainer.py:136] Epoch[23/1000] loss: 0.5991941392421722
I0422 20:40:58.148264 23876 trainer.py:136] Epoch[24/1000] loss: 0.594155490398407
I0422 20:41:01.956535 23876 trainer.py:136] Epoch[25/1000] loss: 0.5880933851003647
I0422 20:41:05.649600 23876 trainer.py:136] Epoch[26/1000] loss: 0.5818126499652863
I0422 20:41:09.433260 23876 trainer.py:136] Epoch[27/1000] loss: 0.5761319696903229
I0422 20:41:13.138137 23876 trainer.py:136] Epoch[28/1000] loss: 0.5713798850774765
I0422 20:41:17.171955 23876 trainer.py:136] Epoch[29/1000] loss: 0.5668851137161255
I0422 20:41:21.049716 23876 trainer.py:136] Epoch[30/1000] loss: 0.5585236698389053
I0422 20:41:24.946206 23876 trainer.py:136] Epoch[31/1000] loss: 0.5534867495298386
I0422 20:41:29.246898 23876 trainer.py:136] Epoch[32/1000] loss: 0.5470728725194931
I0422 20:41:33.288894 23876 trainer.py:136] Epoch[33/1000] loss: 0.5399944186210632
I0422 20:41:37.154814 23876 trainer.py:136] Epoch[34/1000] loss: 0.5329336673021317
I0422 20:41:41.336183 23876 trainer.py:136] Epoch[35/1000] loss: 0.5264619588851929
I0422 20:41:45.341148 23876 trainer.py:136] Epoch[36/1000] loss: 0.5188868045806885
I0422 20:41:49.539297 23876 trainer.py:136] Epoch[37/1000] loss: 0.512917771935463
I0422 20:41:53.462900 23876 trainer.py:136] Epoch[38/1000] loss: 0.505396842956543
I0422 20:41:57.466117 23876 trainer.py:136] Epoch[39/1000] loss: 0.5001446455717087
I0422 20:42:01.339217 23876 trainer.py:136] Epoch[40/1000] loss: 0.49407611787319183
I0422 20:42:05.472186 23876 trainer.py:136] Epoch[41/1000] loss: 0.48468348383903503
I0422 20:42:09.800017 23876 trainer.py:136] Epoch[42/1000] loss: 0.4798734188079834
I0422 20:42:13.981376 23876 trainer.py:136] Epoch[43/1000] loss: 0.4736355096101761
I0422 20:42:18.239349 23876 trainer.py:136] Epoch[44/1000] loss: 0.46655992418527603
I0422 20:42:22.745194 23876 trainer.py:136] Epoch[45/1000] loss: 0.46036409586668015
I0422 20:42:26.975738 23876 trainer.py:136] Epoch[46/1000] loss: 0.4517751708626747
I0422 20:42:30.991132 23876 trainer.py:136] Epoch[47/1000] loss: 0.4466521590948105
I0422 20:42:35.182593 23876 trainer.py:136] Epoch[48/1000] loss: 0.4399918168783188
I0422 20:42:39.472528 23876 trainer.py:136] Epoch[49/1000] loss: 0.43389100581407547
I0422 20:42:40.946942 23876 trainer.py:142] Test: [{'precision': 0.013668757126567838, 'recall': 0.06471670851027171, 'hit_ratio': 0.18586088939566706, 'ndcg': 0.04370524055713455}]
I0422 20:42:45.275367 23876 trainer.py:136] Epoch[50/1000] loss: 0.4258456379175186
I0422 20:42:49.574270 23876 trainer.py:136] Epoch[51/1000] loss: 0.41992752999067307
I0422 20:42:53.747172 23876 trainer.py:136] Epoch[52/1000] loss: 0.41445883363485336
I0422 20:42:57.947499 23876 trainer.py:136] Epoch[53/1000] loss: 0.40774165838956833
I0422 20:43:02.157001 23876 trainer.py:136] Epoch[54/1000] loss: 0.4026789292693138
I0422 20:43:06.251322 23876 trainer.py:136] Epoch[55/1000] loss: 0.39757970720529556
I0422 20:43:10.357965 23876 trainer.py:136] Epoch[56/1000] loss: 0.3900647833943367
I0422 20:43:14.416644 23876 trainer.py:136] Epoch[57/1000] loss: 0.3852394223213196
I0422 20:43:18.551125 23876 trainer.py:136] Epoch[58/1000] loss: 0.3800360858440399
I0422 20:43:22.566946 23876 trainer.py:136] Epoch[59/1000] loss: 0.373536191880703
I0422 20:43:26.715327 23876 trainer.py:136] Epoch[60/1000] loss: 0.36796093732118607
I0422 20:43:30.658114 23876 trainer.py:136] Epoch[61/1000] loss: 0.3622683808207512
I0422 20:43:34.974935 23876 trainer.py:136] Epoch[62/1000] loss: 0.35745978355407715
I0422 20:43:39.423672 23876 trainer.py:136] Epoch[63/1000] loss: 0.3532750904560089
I0422 20:43:43.597963 23876 trainer.py:136] Epoch[64/1000] loss: 0.3484347388148308
I0422 20:43:47.823132 23876 trainer.py:136] Epoch[65/1000] loss: 0.34332042187452316
I0422 20:43:51.934643 23876 trainer.py:136] Epoch[66/1000] loss: 0.339841790497303
I0422 20:43:56.119067 23876 trainer.py:136] Epoch[67/1000] loss: 0.33472195267677307
I0422 20:44:00.311971 23876 trainer.py:136] Epoch[68/1000] loss: 0.33012933284044266
I0422 20:44:04.584235 23876 trainer.py:136] Epoch[69/1000] loss: 0.3250705748796463
I0422 20:44:08.981114 23876 trainer.py:136] Epoch[70/1000] loss: 0.3218393251299858
I0422 20:44:13.156008 23876 trainer.py:136] Epoch[71/1000] loss: 0.3176230117678642
I0422 20:44:17.282475 23876 trainer.py:136] Epoch[72/1000] loss: 0.31351151317358017
I0422 20:44:21.276365 23876 trainer.py:136] Epoch[73/1000] loss: 0.3089405819773674
I0422 20:44:25.374960 23876 trainer.py:136] Epoch[74/1000] loss: 0.3044782280921936
I0422 20:44:30.258554 23876 trainer.py:136] Epoch[75/1000] loss: 0.3022587224841118
I0422 20:44:35.971381 23876 trainer.py:136] Epoch[76/1000] loss: 0.2974514663219452
I0422 20:44:40.473148 23876 trainer.py:136] Epoch[77/1000] loss: 0.29506902396678925
I0422 20:44:44.645565 23876 trainer.py:136] Epoch[78/1000] loss: 0.28931356966495514
I0422 20:44:48.934611 23876 trainer.py:136] Epoch[79/1000] loss: 0.2869018241763115
I0422 20:44:53.062171 23876 trainer.py:136] Epoch[80/1000] loss: 0.28366076201200485
I0422 20:44:57.371729 23876 trainer.py:136] Epoch[81/1000] loss: 0.2787832096219063
I0422 20:45:01.461003 23876 trainer.py:136] Epoch[82/1000] loss: 0.27634767442941666
I0422 20:45:05.952416 23876 trainer.py:136] Epoch[83/1000] loss: 0.27315277606248856
I0422 20:45:12.671235 23876 trainer.py:136] Epoch[84/1000] loss: 0.27105625718832016
I0422 20:45:17.028363 23876 trainer.py:136] Epoch[85/1000] loss: 0.26702306419610977
I0422 20:45:21.350116 23876 trainer.py:136] Epoch[86/1000] loss: 0.2635197266936302
I0422 20:45:25.623296 23876 trainer.py:136] Epoch[87/1000] loss: 0.26200877130031586
I0422 20:45:29.907829 23876 trainer.py:136] Epoch[88/1000] loss: 0.25876355916261673
I0422 20:45:34.080929 23876 trainer.py:136] Epoch[89/1000] loss: 0.25622548162937164
I0422 20:45:39.365523 23876 trainer.py:136] Epoch[90/1000] loss: 0.2539559304714203
I0422 20:45:46.724727 23876 trainer.py:136] Epoch[91/1000] loss: 0.24889808520674706
I0422 20:45:51.818111 23876 trainer.py:136] Epoch[92/1000] loss: 0.24550700932741165
I0422 20:45:56.862314 23876 trainer.py:136] Epoch[93/1000] loss: 0.24520370736718178
I0422 20:46:04.823921 23876 trainer.py:136] Epoch[94/1000] loss: 0.2419598251581192
I0422 20:46:09.729398 23876 trainer.py:136] Epoch[95/1000] loss: 0.23977921158075333
I0422 20:46:14.580235 23876 trainer.py:136] Epoch[96/1000] loss: 0.23671220988035202
I0422 20:46:19.678126 23876 trainer.py:136] Epoch[97/1000] loss: 0.2357996702194214
I0422 20:46:26.541413 23876 trainer.py:136] Epoch[98/1000] loss: 0.23428761959075928
I0422 20:46:31.972192 23876 trainer.py:136] Epoch[99/1000] loss: 0.23041093721985817
I0422 20:46:33.980662 23876 trainer.py:142] Test: [{'precision': 0.014274515393386538, 'recall': 0.06837946926009589, 'hit_ratio': 0.19640820980615736, 'ndcg': 0.04506993306923692}]
I0422 20:46:39.094058 23876 trainer.py:136] Epoch[100/1000] loss: 0.22889788076281548
I0422 20:46:44.097075 23876 trainer.py:136] Epoch[101/1000] loss: 0.22811588272452354
I0422 20:46:51.828997 23876 trainer.py:136] Epoch[102/1000] loss: 0.22381584718823433
I0422 20:46:56.697685 23876 trainer.py:136] Epoch[103/1000] loss: 0.22279896587133408
I0422 20:47:01.730056 23876 trainer.py:136] Epoch[104/1000] loss: 0.22064071148633957
I0422 20:47:06.619523 23876 trainer.py:136] Epoch[105/1000] loss: 0.21816904097795486
I0422 20:47:11.740473 23876 trainer.py:136] Epoch[106/1000] loss: 0.21727079898118973
I0422 20:47:19.413542 23876 trainer.py:136] Epoch[107/1000] loss: 0.21497146412730217
I0422 20:47:24.520995 23876 trainer.py:136] Epoch[108/1000] loss: 0.21099641546607018
I0422 20:47:30.172297 23876 trainer.py:136] Epoch[109/1000] loss: 0.2113993801176548
I0422 20:47:37.979793 23876 trainer.py:136] Epoch[110/1000] loss: 0.20911157503724098
I0422 20:47:43.038158 23876 trainer.py:136] Epoch[111/1000] loss: 0.2071470059454441
I0422 20:47:47.933557 23876 trainer.py:136] Epoch[112/1000] loss: 0.2043352872133255
I0422 20:47:53.814056 23876 trainer.py:136] Epoch[113/1000] loss: 0.2022704891860485
I0422 20:48:00.806489 23876 trainer.py:136] Epoch[114/1000] loss: 0.20344964042305946
I0422 20:48:05.765257 23876 trainer.py:136] Epoch[115/1000] loss: 0.19999205693602562
I0422 20:48:10.670118 23876 trainer.py:136] Epoch[116/1000] loss: 0.19811635836958885
I0422 20:48:16.247227 23876 trainer.py:136] Epoch[117/1000] loss: 0.19731056317687035
I0422 20:48:23.151737 23876 trainer.py:136] Epoch[118/1000] loss: 0.19712211564183235
I0422 20:48:28.057917 23876 trainer.py:136] Epoch[119/1000] loss: 0.19467607885599136
I0422 20:48:33.061056 23876 trainer.py:136] Epoch[120/1000] loss: 0.19440606608986855
I0422 20:48:40.712859 23876 trainer.py:136] Epoch[121/1000] loss: 0.19232222065329552
I0422 20:48:45.703952 23876 trainer.py:136] Epoch[122/1000] loss: 0.19007518887519836
I0422 20:48:50.736445 23876 trainer.py:136] Epoch[123/1000] loss: 0.18835587054491043
I0422 20:48:55.923382 23876 trainer.py:136] Epoch[124/1000] loss: 0.18680636957287788
I0422 20:49:03.386152 23876 trainer.py:136] Epoch[125/1000] loss: 0.1868211328983307
I0422 20:49:08.250239 23876 trainer.py:136] Epoch[126/1000] loss: 0.18476146459579468
I0422 20:49:13.146650 23876 trainer.py:136] Epoch[127/1000] loss: 0.18291587010025978
I0422 20:49:20.799302 23876 trainer.py:136] Epoch[128/1000] loss: 0.18185044825077057
I0422 20:49:25.624591 23876 trainer.py:136] Epoch[129/1000] loss: 0.18128195777535439
I0422 20:49:30.663820 23876 trainer.py:136] Epoch[130/1000] loss: 0.18022292852401733
I0422 20:49:36.566488 23876 trainer.py:136] Epoch[131/1000] loss: 0.17927264049649239
I0422 20:49:43.210457 23876 trainer.py:136] Epoch[132/1000] loss: 0.17844856157898903
I0422 20:49:48.356866 23876 trainer.py:136] Epoch[133/1000] loss: 0.17712568119168282
I0422 20:49:53.636165 23876 trainer.py:136] Epoch[134/1000] loss: 0.17528538405895233
I0422 20:50:01.108724 23876 trainer.py:136] Epoch[135/1000] loss: 0.17555765435099602
I0422 20:50:06.035755 23876 trainer.py:136] Epoch[136/1000] loss: 0.17388856783509254
I0422 20:50:11.148077 23876 trainer.py:136] Epoch[137/1000] loss: 0.1724788062274456
I0422 20:50:18.430753 23876 trainer.py:136] Epoch[138/1000] loss: 0.17163746803998947
I0422 20:50:23.805144 23876 trainer.py:136] Epoch[139/1000] loss: 0.1699623502790928
I0422 20:50:28.523435 23876 trainer.py:136] Epoch[140/1000] loss: 0.17041319981217384
I0422 20:50:33.281561 23876 trainer.py:136] Epoch[141/1000] loss: 0.16959485411643982
I0422 20:50:41.027062 23876 trainer.py:136] Epoch[142/1000] loss: 0.16750279814004898
I0422 20:50:45.942324 23876 trainer.py:136] Epoch[143/1000] loss: 0.1669064164161682
I0422 20:50:50.506884 23876 trainer.py:136] Epoch[144/1000] loss: 0.16487286239862442
I0422 20:50:57.822453 23876 trainer.py:136] Epoch[145/1000] loss: 0.16501206159591675
I0422 20:51:01.980068 23876 trainer.py:136] Epoch[146/1000] loss: 0.16460837423801422
I0422 20:51:06.074195 23876 trainer.py:136] Epoch[147/1000] loss: 0.1629725955426693
I0422 20:51:10.196429 23876 trainer.py:136] Epoch[148/1000] loss: 0.1631758138537407
I0422 20:51:14.217225 23876 trainer.py:136] Epoch[149/1000] loss: 0.16084711626172066
I0422 20:51:15.670965 23876 trainer.py:142] Test: [{'precision': 0.014694982896237167, 'recall': 0.06955350524537697, 'hit_ratio': 0.20282212086659065, 'ndcg': 0.04595540838603403}]
I0422 20:51:19.784625 23876 trainer.py:136] Epoch[150/1000] loss: 0.15975910797715187
I0422 20:51:24.571317 23876 trainer.py:136] Epoch[151/1000] loss: 0.15964531525969505
I0422 20:51:30.719921 23876 trainer.py:136] Epoch[152/1000] loss: 0.15911195799708366
I0422 20:51:34.872571 23876 trainer.py:136] Epoch[153/1000] loss: 0.1581430435180664
I0422 20:51:38.908627 23876 trainer.py:136] Epoch[154/1000] loss: 0.15551672875881195
I0422 20:51:42.876577 23876 trainer.py:136] Epoch[155/1000] loss: 0.15782132744789124
I0422 20:51:47.222666 23876 trainer.py:136] Epoch[156/1000] loss: 0.15498952940106392
I0422 20:51:51.245052 23876 trainer.py:136] Epoch[157/1000] loss: 0.15589633211493492
I0422 20:51:55.392254 23876 trainer.py:136] Epoch[158/1000] loss: 0.15539959073066711
I0422 20:52:02.016574 23876 trainer.py:136] Epoch[159/1000] loss: 0.15301631391048431
I0422 20:52:06.113868 23876 trainer.py:136] Epoch[160/1000] loss: 0.15276550129055977
I0422 20:52:10.348599 23876 trainer.py:136] Epoch[161/1000] loss: 0.1508166790008545
I0422 20:52:14.515881 23876 trainer.py:136] Epoch[162/1000] loss: 0.15147708356380463
I0422 20:52:18.678793 23876 trainer.py:136] Epoch[163/1000] loss: 0.15166257694363594
I0422 20:52:22.846838 23876 trainer.py:136] Epoch[164/1000] loss: 0.14973989874124527
I0422 20:52:27.078105 23876 trainer.py:136] Epoch[165/1000] loss: 0.14890293031930923
I0422 20:52:33.930928 23876 trainer.py:136] Epoch[166/1000] loss: 0.14990949258208275
I0422 20:52:39.612370 23876 trainer.py:136] Epoch[167/1000] loss: 0.14943956583738327
I0422 20:52:43.934764 23876 trainer.py:136] Epoch[168/1000] loss: 0.14810111746191978
I0422 20:52:48.062558 23876 trainer.py:136] Epoch[169/1000] loss: 0.14668137580156326
I0422 20:52:52.322548 23876 trainer.py:136] Epoch[170/1000] loss: 0.14735009148716927
I0422 20:52:56.381241 23876 trainer.py:136] Epoch[171/1000] loss: 0.14595318585634232
I0422 20:53:01.586283 23876 trainer.py:136] Epoch[172/1000] loss: 0.14471986144781113
I0422 20:53:07.129745 23876 trainer.py:136] Epoch[173/1000] loss: 0.14319361001253128
I0422 20:53:11.267770 23876 trainer.py:136] Epoch[174/1000] loss: 0.1443188302218914
I0422 20:53:15.366024 23876 trainer.py:136] Epoch[175/1000] loss: 0.14268102496862411
I0422 20:53:19.576121 23876 trainer.py:136] Epoch[176/1000] loss: 0.1434221938252449
I0422 20:53:24.062494 23876 trainer.py:136] Epoch[177/1000] loss: 0.14172383025288582
I0422 20:53:30.718308 23876 trainer.py:136] Epoch[178/1000] loss: 0.14263425022363663
I0422 20:53:34.892269 23876 trainer.py:136] Epoch[179/1000] loss: 0.14008958265185356
I0422 20:53:38.772435 23876 trainer.py:136] Epoch[180/1000] loss: 0.1399175487458706
I0422 20:53:42.866251 23876 trainer.py:136] Epoch[181/1000] loss: 0.13988124206662178
I0422 20:53:46.945957 23876 trainer.py:136] Epoch[182/1000] loss: 0.13924087211489677
I0422 20:53:51.030588 23876 trainer.py:136] Epoch[183/1000] loss: 0.13893915712833405
I0422 20:53:55.139593 23876 trainer.py:136] Epoch[184/1000] loss: 0.1381036899983883
I0422 20:53:59.269486 23876 trainer.py:136] Epoch[185/1000] loss: 0.13731388747692108
I0422 20:54:04.786192 23876 trainer.py:136] Epoch[186/1000] loss: 0.1380963884294033
I0422 20:54:12.091346 23876 trainer.py:136] Epoch[187/1000] loss: 0.13698316738009453
I0422 20:54:17.065622 23876 trainer.py:136] Epoch[188/1000] loss: 0.13693002611398697
I0422 20:54:23.958995 23876 trainer.py:136] Epoch[189/1000] loss: 0.13527881726622581
I0422 20:54:30.070905 23876 trainer.py:136] Epoch[190/1000] loss: 0.13642502203583717
I0422 20:54:35.150370 23876 trainer.py:136] Epoch[191/1000] loss: 0.135289516299963
I0422 20:54:42.053777 23876 trainer.py:136] Epoch[192/1000] loss: 0.13445764034986496
I0422 20:54:48.278446 23876 trainer.py:136] Epoch[193/1000] loss: 0.13358261436223984
I0422 20:54:53.070853 23876 trainer.py:136] Epoch[194/1000] loss: 0.13313458114862442
I0422 20:54:57.840744 23876 trainer.py:136] Epoch[195/1000] loss: 0.1331598274409771
I0422 20:55:05.102388 23876 trainer.py:136] Epoch[196/1000] loss: 0.1322738490998745
I0422 20:55:10.061431 23876 trainer.py:136] Epoch[197/1000] loss: 0.1328427903354168
I0422 20:55:15.237709 23876 trainer.py:136] Epoch[198/1000] loss: 0.13275305181741714
I0422 20:55:23.187574 23876 trainer.py:136] Epoch[199/1000] loss: 0.13174889236688614
I0422 20:55:25.679986 23876 trainer.py:142] Test: [{'precision': 0.015115450399087803, 'recall': 0.07177130354383136, 'hit_ratio': 0.2080957810718358, 'ndcg': 0.04704011284180272}]
I0422 20:55:30.980595 23876 trainer.py:136] Epoch[200/1000] loss: 0.13197600096464157
I0422 20:55:38.030754 23876 trainer.py:136] Epoch[201/1000] loss: 0.1310497745871544
I0422 20:55:43.992621 23876 trainer.py:136] Epoch[202/1000] loss: 0.13043778389692307
I0422 20:55:48.999722 23876 trainer.py:136] Epoch[203/1000] loss: 0.13068407401442528
I0422 20:55:53.880720 23876 trainer.py:136] Epoch[204/1000] loss: 0.1291678510606289
I0422 20:56:00.783838 23876 trainer.py:136] Epoch[205/1000] loss: 0.12893733382225037
I0422 20:56:06.506116 23876 trainer.py:136] Epoch[206/1000] loss: 0.12911589443683624
I0422 20:56:11.430100 23876 trainer.py:136] Epoch[207/1000] loss: 0.1283896528184414
I0422 20:56:17.415730 23876 trainer.py:136] Epoch[208/1000] loss: 0.12760772556066513
I0422 20:56:24.956058 23876 trainer.py:136] Epoch[209/1000] loss: 0.12806296721100807
I0422 20:56:29.996643 23876 trainer.py:136] Epoch[210/1000] loss: 0.12844273447990417
I0422 20:56:34.945555 23876 trainer.py:136] Epoch[211/1000] loss: 0.1262172218412161
I0422 20:56:42.890816 23876 trainer.py:136] Epoch[212/1000] loss: 0.12654640153050423
I0422 20:56:48.034451 23876 trainer.py:136] Epoch[213/1000] loss: 0.12711427174508572
I0422 20:56:52.998274 23876 trainer.py:136] Epoch[214/1000] loss: 0.12561655417084694
I0422 20:57:00.448558 23876 trainer.py:136] Epoch[215/1000] loss: 0.12614518776535988
I0422 20:57:04.822266 23876 trainer.py:136] Epoch[216/1000] loss: 0.1252856571227312
I0422 20:57:09.476496 23876 trainer.py:136] Epoch[217/1000] loss: 0.1251382026821375
I0422 20:57:17.400755 23876 trainer.py:136] Epoch[218/1000] loss: 0.12414767406880856
I0422 20:57:22.643313 23876 trainer.py:136] Epoch[219/1000] loss: 0.12492282316088676
I0422 20:57:27.455754 23876 trainer.py:136] Epoch[220/1000] loss: 0.12419667653739452
I0422 20:57:34.970012 23876 trainer.py:136] Epoch[221/1000] loss: 0.1228773333132267
I0422 20:57:39.805881 23876 trainer.py:136] Epoch[222/1000] loss: 0.12375649996101856
I0422 20:57:44.608858 23876 trainer.py:136] Epoch[223/1000] loss: 0.12208501994609833
I0422 20:57:49.448787 23876 trainer.py:136] Epoch[224/1000] loss: 0.123505474999547
I0422 20:57:56.940333 23876 trainer.py:136] Epoch[225/1000] loss: 0.1228662058711052
I0422 20:58:02.008321 23876 trainer.py:136] Epoch[226/1000] loss: 0.1227722130715847
I0422 20:58:06.744303 23876 trainer.py:136] Epoch[227/1000] loss: 0.12303948774933815
I0422 20:58:14.414159 23876 trainer.py:136] Epoch[228/1000] loss: 0.12145615182816982
I0422 20:58:19.468761 23876 trainer.py:136] Epoch[229/1000] loss: 0.12181226536631584
I0422 20:58:24.302861 23876 trainer.py:136] Epoch[230/1000] loss: 0.12198399938642979
I0422 20:58:29.351610 23876 trainer.py:136] Epoch[231/1000] loss: 0.12095478363335133
I0422 20:58:36.965077 23876 trainer.py:136] Epoch[232/1000] loss: 0.11973443813621998
I0422 20:58:41.873479 23876 trainer.py:136] Epoch[233/1000] loss: 0.12204330042004585
I0422 20:58:46.737030 23876 trainer.py:136] Epoch[234/1000] loss: 0.1208083238452673
I0422 20:58:51.660373 23876 trainer.py:136] Epoch[235/1000] loss: 0.11817244440317154
I0422 20:58:59.350824 23876 trainer.py:136] Epoch[236/1000] loss: 0.11835539527237415
I0422 20:59:04.289822 23876 trainer.py:136] Epoch[237/1000] loss: 0.11786281503736973
I0422 20:59:09.863024 23876 trainer.py:136] Epoch[238/1000] loss: 0.11937104724347591
I0422 20:59:17.862757 23876 trainer.py:136] Epoch[239/1000] loss: 0.11823620460927486
I0422 20:59:23.005126 23876 trainer.py:136] Epoch[240/1000] loss: 0.11863220483064651
I0422 20:59:27.988983 23876 trainer.py:136] Epoch[241/1000] loss: 0.11924857832491398
I0422 20:59:36.179534 23876 trainer.py:136] Epoch[242/1000] loss: 0.11806266009807587
I0422 20:59:41.179673 23876 trainer.py:136] Epoch[243/1000] loss: 0.11768649332225323
I0422 20:59:46.024811 23876 trainer.py:136] Epoch[244/1000] loss: 0.11849859915673733
I0422 20:59:54.047333 23876 trainer.py:136] Epoch[245/1000] loss: 0.1172652542591095
I0422 20:59:59.194492 23876 trainer.py:136] Epoch[246/1000] loss: 0.11790133826434612
I0422 21:00:04.162458 23876 trainer.py:136] Epoch[247/1000] loss: 0.11666132137179375
I0422 21:00:11.753412 23876 trainer.py:136] Epoch[248/1000] loss: 0.1179298460483551
I0422 21:00:16.739885 23876 trainer.py:136] Epoch[249/1000] loss: 0.115853825584054
I0422 21:00:18.810122 23876 trainer.py:142] Test: [{'precision': 0.01527936145952109, 'recall': 0.07211487736617071, 'hit_ratio': 0.2110889395667047, 'ndcg': 0.0476331781604068}]
I0422 21:00:26.643688 23876 trainer.py:136] Epoch[250/1000] loss: 0.11649630777537823
I0422 21:00:32.452046 23876 trainer.py:136] Epoch[251/1000] loss: 0.11512690037488937
I0422 21:00:37.655553 23876 trainer.py:136] Epoch[252/1000] loss: 0.11558054015040398
I0422 21:00:45.246618 23876 trainer.py:136] Epoch[253/1000] loss: 0.11546595767140388
I0422 21:00:50.683488 23876 trainer.py:136] Epoch[254/1000] loss: 0.11480483785271645
I0422 21:00:55.712258 23876 trainer.py:136] Epoch[255/1000] loss: 0.11653814278542995
I0422 21:01:01.034966 23876 trainer.py:136] Epoch[256/1000] loss: 0.11449413001537323
I0422 21:01:08.872932 23876 trainer.py:136] Epoch[257/1000] loss: 0.11459103785455227
I0422 21:01:13.757466 23876 trainer.py:136] Epoch[258/1000] loss: 0.11399343237280846
I0422 21:01:18.836690 23876 trainer.py:136] Epoch[259/1000] loss: 0.11513514816761017
I0422 21:01:26.498731 23876 trainer.py:136] Epoch[260/1000] loss: 0.11408893018960953
I0422 21:01:31.936502 23876 trainer.py:136] Epoch[261/1000] loss: 0.11336274817585945
I0422 21:01:36.934868 23876 trainer.py:136] Epoch[262/1000] loss: 0.1138265710324049
I0422 21:01:42.075573 23876 trainer.py:136] Epoch[263/1000] loss: 0.11366364918649197
I0422 21:01:49.966634 23876 trainer.py:136] Epoch[264/1000] loss: 0.11386909894645214
I0422 21:01:55.159191 23876 trainer.py:136] Epoch[265/1000] loss: 0.1121952161192894
I0422 21:02:00.513710 23876 trainer.py:136] Epoch[266/1000] loss: 0.11258524283766747
I0422 21:02:07.765710 23876 trainer.py:136] Epoch[267/1000] loss: 0.11369448341429234
I0422 21:02:13.322156 23876 trainer.py:136] Epoch[268/1000] loss: 0.11200905591249466
I0422 21:02:18.487216 23876 trainer.py:136] Epoch[269/1000] loss: 0.11197595298290253
I0422 21:02:23.693134 23876 trainer.py:136] Epoch[270/1000] loss: 0.11296790465712547
I0422 21:02:31.912111 23876 trainer.py:136] Epoch[271/1000] loss: 0.11159401945769787
I0422 21:02:37.205475 23876 trainer.py:136] Epoch[272/1000] loss: 0.111289132386446
I0422 21:02:42.501891 23876 trainer.py:136] Epoch[273/1000] loss: 0.11225686594843864
I0422 21:02:50.608855 23876 trainer.py:136] Epoch[274/1000] loss: 0.11070117726922035
I0422 21:02:55.757675 23876 trainer.py:136] Epoch[275/1000] loss: 0.11237097345292568
I0422 21:03:00.754394 23876 trainer.py:136] Epoch[276/1000] loss: 0.1109111588448286
I0422 21:03:05.602009 23876 trainer.py:136] Epoch[277/1000] loss: 0.10965313017368317
I0422 21:03:13.692392 23876 trainer.py:136] Epoch[278/1000] loss: 0.11095810122787952
I0422 21:03:19.059844 23876 trainer.py:136] Epoch[279/1000] loss: 0.10986004397273064
I0422 21:03:24.365600 23876 trainer.py:136] Epoch[280/1000] loss: 0.11091931164264679
I0422 21:03:32.311152 23876 trainer.py:136] Epoch[281/1000] loss: 0.11021096631884575
I0422 21:03:37.447890 23876 trainer.py:136] Epoch[282/1000] loss: 0.1098428014665842
I0422 21:03:42.369435 23876 trainer.py:136] Epoch[283/1000] loss: 0.10975288972258568
I0422 21:03:49.842596 23876 trainer.py:136] Epoch[284/1000] loss: 0.10952690616250038
I0422 21:03:55.119837 23876 trainer.py:136] Epoch[285/1000] loss: 0.11033842526376247
I0422 21:04:00.186510 23876 trainer.py:136] Epoch[286/1000] loss: 0.11069163680076599
I0422 21:04:08.532541 23876 trainer.py:136] Epoch[287/1000] loss: 0.10963983088731766
I0422 21:04:13.584334 23876 trainer.py:136] Epoch[288/1000] loss: 0.10835462063550949
I0422 21:04:20.223563 23876 trainer.py:136] Epoch[289/1000] loss: 0.10881277918815613
I0422 21:04:26.072830 23876 trainer.py:136] Epoch[290/1000] loss: 0.10941597819328308
I0422 21:04:31.304426 23876 trainer.py:136] Epoch[291/1000] loss: 0.10775584354996681
I0422 21:04:36.255799 23876 trainer.py:136] Epoch[292/1000] loss: 0.10936172120273113
I0422 21:04:43.889343 23876 trainer.py:136] Epoch[293/1000] loss: 0.1095392145216465
I0422 21:04:48.894552 23876 trainer.py:136] Epoch[294/1000] loss: 0.10818365961313248
I0422 21:04:53.588389 23876 trainer.py:136] Epoch[295/1000] loss: 0.10805847309529781
I0422 21:04:59.286395 23876 trainer.py:136] Epoch[296/1000] loss: 0.10827002301812172
I0422 21:05:06.536238 23876 trainer.py:136] Epoch[297/1000] loss: 0.10918902233242989
I0422 21:05:11.395826 23876 trainer.py:136] Epoch[298/1000] loss: 0.10842268913984299
I0422 21:05:16.010271 23876 trainer.py:136] Epoch[299/1000] loss: 0.10640668123960495
I0422 21:05:18.117638 23876 trainer.py:142] Test: [{'precision': 0.015500285062713792, 'recall': 0.07296206453149615, 'hit_ratio': 0.21393956670467504, 'ndcg': 0.04848244165995924}]
I0422 21:05:25.713342 23876 trainer.py:136] Epoch[300/1000] loss: 0.10748323425650597
I0422 21:05:30.750374 23876 trainer.py:136] Epoch[301/1000] loss: 0.10749425739049911
I0422 21:05:35.581366 23876 trainer.py:136] Epoch[302/1000] loss: 0.10728263109922409
I0422 21:05:43.362950 23876 trainer.py:136] Epoch[303/1000] loss: 0.10783378593623638
I0422 21:05:48.121502 23876 trainer.py:136] Epoch[304/1000] loss: 0.1062275879085064
I0422 21:05:53.045511 23876 trainer.py:136] Epoch[305/1000] loss: 0.10700168274343014
I0422 21:05:59.439337 23876 trainer.py:136] Epoch[306/1000] loss: 0.10688282549381256
I0422 21:06:05.627195 23876 trainer.py:136] Epoch[307/1000] loss: 0.10542248748242855
I0422 21:06:10.697419 23876 trainer.py:136] Epoch[308/1000] loss: 0.10684406571090221
I0422 21:06:15.583474 23876 trainer.py:136] Epoch[309/1000] loss: 0.10732520185410976
I0422 21:06:23.202538 23876 trainer.py:136] Epoch[310/1000] loss: 0.10554011724889278
I0422 21:06:28.217402 23876 trainer.py:136] Epoch[311/1000] loss: 0.10475631430745125
I0422 21:06:33.219055 23876 trainer.py:136] Epoch[312/1000] loss: 0.10572141595184803
I0422 21:06:38.863891 23876 trainer.py:136] Epoch[313/1000] loss: 0.10473773814737797
I0422 21:06:45.943286 23876 trainer.py:136] Epoch[314/1000] loss: 0.10599343106150627
I0422 21:06:50.983258 23876 trainer.py:136] Epoch[315/1000] loss: 0.1049474235624075
I0422 21:06:56.058703 23876 trainer.py:136] Epoch[316/1000] loss: 0.1049062479287386
I0422 21:07:04.232755 23876 trainer.py:136] Epoch[317/1000] loss: 0.10449213720858097
I0422 21:07:09.539746 23876 trainer.py:136] Epoch[318/1000] loss: 0.10488918423652649
I0422 21:07:14.742138 23876 trainer.py:136] Epoch[319/1000] loss: 0.10543751902878284
I0422 21:07:22.853847 23876 trainer.py:136] Epoch[320/1000] loss: 0.10427945107221603
I0422 21:07:27.206371 23876 trainer.py:136] Epoch[321/1000] loss: 0.10482046753168106
I0422 21:07:31.623838 23876 trainer.py:136] Epoch[322/1000] loss: 0.10452460683882236
I0422 21:07:36.007833 23876 trainer.py:136] Epoch[323/1000] loss: 0.10407754778862
I0422 21:07:41.850300 23876 trainer.py:136] Epoch[324/1000] loss: 0.10546032898128033
I0422 21:07:47.048668 23876 trainer.py:136] Epoch[325/1000] loss: 0.10352491028606892
I0422 21:07:51.325367 23876 trainer.py:136] Epoch[326/1000] loss: 0.10309093818068504
I0422 21:07:55.431046 23876 trainer.py:136] Epoch[327/1000] loss: 0.10331856459379196
I0422 21:07:59.496277 23876 trainer.py:136] Epoch[328/1000] loss: 0.10554829426109791
I0422 21:08:03.561991 23876 trainer.py:136] Epoch[329/1000] loss: 0.1036370787769556
I0422 21:08:07.602673 23876 trainer.py:136] Epoch[330/1000] loss: 0.10412959195673466
I0422 21:08:11.747686 23876 trainer.py:136] Epoch[331/1000] loss: 0.10265468247234821
I0422 21:08:15.753029 23876 trainer.py:136] Epoch[332/1000] loss: 0.10453507862985134
I0422 21:08:22.274033 23876 trainer.py:136] Epoch[333/1000] loss: 0.10428799130022526
I0422 21:08:26.513703 23876 trainer.py:136] Epoch[334/1000] loss: 0.1039753258228302
I0422 21:08:30.871536 23876 trainer.py:136] Epoch[335/1000] loss: 0.10271214134991169
I0422 21:08:35.179695 23876 trainer.py:136] Epoch[336/1000] loss: 0.10274928249418736
I0422 21:08:39.550272 23876 trainer.py:136] Epoch[337/1000] loss: 0.10225584730505943
I0422 21:08:46.365575 23876 trainer.py:136] Epoch[338/1000] loss: 0.10256889462471008
I0422 21:08:50.434010 23876 trainer.py:136] Epoch[339/1000] loss: 0.10236898809671402
I0422 21:08:54.646744 23876 trainer.py:136] Epoch[340/1000] loss: 0.10316840745508671
I0422 21:08:58.776201 23876 trainer.py:136] Epoch[341/1000] loss: 0.10316381976008415
I0422 21:09:02.841178 23876 trainer.py:136] Epoch[342/1000] loss: 0.10301289707422256
I0422 21:09:07.021911 23876 trainer.py:136] Epoch[343/1000] loss: 0.10063626058399677
I0422 21:09:11.326518 23876 trainer.py:136] Epoch[344/1000] loss: 0.1019989475607872
I0422 21:09:18.224044 23876 trainer.py:136] Epoch[345/1000] loss: 0.10098095051944256
I0422 21:09:22.387477 23876 trainer.py:136] Epoch[346/1000] loss: 0.10131089575588703
I0422 21:09:26.489056 23876 trainer.py:136] Epoch[347/1000] loss: 0.1012010145932436
I0422 21:09:30.765594 23876 trainer.py:136] Epoch[348/1000] loss: 0.10252015292644501
I0422 21:09:35.066138 23876 trainer.py:136] Epoch[349/1000] loss: 0.10094445012509823
I0422 21:09:36.527460 23876 trainer.py:142] Test: [{'precision': 0.015657069555302154, 'recall': 0.07367006098051253, 'hit_ratio': 0.21536488027366021, 'ndcg': 0.04894916776750993}]
I0422 21:09:40.795028 23876 trainer.py:136] Epoch[350/1000] loss: 0.10115277767181396
I0422 21:09:44.803851 23876 trainer.py:136] Epoch[351/1000] loss: 0.10227121971547604
I0422 21:09:51.562344 23876 trainer.py:136] Epoch[352/1000] loss: 0.10071450285613537
I0422 21:09:55.839925 23876 trainer.py:136] Epoch[353/1000] loss: 0.10061757266521454
I0422 21:10:00.119731 23876 trainer.py:136] Epoch[354/1000] loss: 0.10074626095592976
I0422 21:10:04.156725 23876 trainer.py:136] Epoch[355/1000] loss: 0.10061098262667656
I0422 21:10:08.391604 23876 trainer.py:136] Epoch[356/1000] loss: 0.10166782885789871
I0422 21:10:12.400629 23876 trainer.py:136] Epoch[357/1000] loss: 0.10210698656737804
I0422 21:10:16.814113 23876 trainer.py:136] Epoch[358/1000] loss: 0.10092908889055252
I0422 21:10:24.511348 23876 trainer.py:136] Epoch[359/1000] loss: 0.10070996172726154
I0422 21:10:28.668035 23876 trainer.py:136] Epoch[360/1000] loss: 0.1027156300842762
I0422 21:10:32.820039 23876 trainer.py:136] Epoch[361/1000] loss: 0.1006335262209177
I0422 21:10:37.029242 23876 trainer.py:136] Epoch[362/1000] loss: 0.10017313621938229
I0422 21:10:41.329797 23876 trainer.py:136] Epoch[363/1000] loss: 0.09963584505021572
I0422 21:10:45.478669 23876 trainer.py:136] Epoch[364/1000] loss: 0.10023901052772999
I0422 21:10:49.530469 23876 trainer.py:136] Epoch[365/1000] loss: 0.09981006570160389
I0422 21:10:53.763478 23876 trainer.py:136] Epoch[366/1000] loss: 0.09983524680137634
I0422 21:10:58.654545 23876 trainer.py:136] Epoch[367/1000] loss: 0.09964253380894661
I0422 21:11:04.681024 23876 trainer.py:136] Epoch[368/1000] loss: 0.09965628758072853
I0422 21:11:08.879422 23876 trainer.py:136] Epoch[369/1000] loss: 0.10010145790874958
I0422 21:11:13.103049 23876 trainer.py:136] Epoch[370/1000] loss: 0.10010974481701851
I0422 21:11:17.332731 23876 trainer.py:136] Epoch[371/1000] loss: 0.09933120012283325
I0422 21:11:21.563834 23876 trainer.py:136] Epoch[372/1000] loss: 0.09902341663837433
I0422 21:11:25.638439 23876 trainer.py:136] Epoch[373/1000] loss: 0.1009192168712616
I0422 21:11:29.696115 23876 trainer.py:136] Epoch[374/1000] loss: 0.09795544482767582
I0422 21:11:33.747817 23876 trainer.py:136] Epoch[375/1000] loss: 0.09934700466692448
I0422 21:11:39.296487 23876 trainer.py:136] Epoch[376/1000] loss: 0.09954711981117725
I0422 21:11:44.801953 23876 trainer.py:136] Epoch[377/1000] loss: 0.09930234216153622
I0422 21:11:49.018149 23876 trainer.py:136] Epoch[378/1000] loss: 0.09844722039997578
I0422 21:11:53.255919 23876 trainer.py:136] Epoch[379/1000] loss: 0.10034070909023285
I0422 21:11:57.456127 23876 trainer.py:136] Epoch[380/1000] loss: 0.09979048557579517
I0422 21:12:01.526556 23876 trainer.py:136] Epoch[381/1000] loss: 0.09939485229551792
I0422 21:12:05.581904 23876 trainer.py:136] Epoch[382/1000] loss: 0.09846354462206364
I0422 21:12:09.642611 23876 trainer.py:136] Epoch[383/1000] loss: 0.09849632903933525
I0422 21:12:14.717164 23876 trainer.py:136] Epoch[384/1000] loss: 0.09782717935740948
I0422 21:12:21.314648 23876 trainer.py:136] Epoch[385/1000] loss: 0.0981694906949997
I0422 21:12:25.439196 23876 trainer.py:136] Epoch[386/1000] loss: 0.09878104738891125
I0422 21:12:29.878789 23876 trainer.py:136] Epoch[387/1000] loss: 0.09918820112943649
I0422 21:12:34.045091 23876 trainer.py:136] Epoch[388/1000] loss: 0.09845949523150921
I0422 21:12:38.223908 23876 trainer.py:136] Epoch[389/1000] loss: 0.09854958392679691
I0422 21:12:42.673373 23876 trainer.py:136] Epoch[390/1000] loss: 0.09828990511596203
I0422 21:12:49.502670 23876 trainer.py:136] Epoch[391/1000] loss: 0.09817069955170155
I0422 21:12:53.687631 23876 trainer.py:136] Epoch[392/1000] loss: 0.09799482487142086
I0422 21:12:58.032014 23876 trainer.py:136] Epoch[393/1000] loss: 0.09808465093374252
I0422 21:13:02.154984 23876 trainer.py:136] Epoch[394/1000] loss: 0.09737846627831459
I0422 21:13:06.375750 23876 trainer.py:136] Epoch[395/1000] loss: 0.09772570058703423
I0422 21:13:10.721491 23876 trainer.py:136] Epoch[396/1000] loss: 0.09708212874829769
I0422 21:13:16.980311 23876 trainer.py:136] Epoch[397/1000] loss: 0.09766439534723759
I0422 21:13:21.776557 23876 trainer.py:136] Epoch[398/1000] loss: 0.0980188213288784
I0422 21:13:25.827275 23876 trainer.py:136] Epoch[399/1000] loss: 0.09672632813453674
I0422 21:13:27.295500 23876 trainer.py:142] Test: [{'precision': 0.01575684150513112, 'recall': 0.07365873741835637, 'hit_ratio': 0.21664766248574688, 'ndcg': 0.049220708699762604}]
I0422 21:13:31.482846 23876 trainer.py:136] Epoch[400/1000] loss: 0.09686391800642014
I0422 21:13:36.011088 23876 trainer.py:136] Epoch[401/1000] loss: 0.09741903282701969
I0422 21:13:43.638406 23876 trainer.py:136] Epoch[402/1000] loss: 0.09634463302791119
I0422 21:13:49.536690 23876 trainer.py:136] Epoch[403/1000] loss: 0.0963386632502079
I0422 21:13:54.653521 23876 trainer.py:136] Epoch[404/1000] loss: 0.09778611361980438
I0422 21:13:59.686673 23876 trainer.py:136] Epoch[405/1000] loss: 0.09622103907167912
I0422 21:14:06.665316 23876 trainer.py:136] Epoch[406/1000] loss: 0.09762677922844887
I0422 21:14:12.700783 23876 trainer.py:136] Epoch[407/1000] loss: 0.09689942374825478
I0422 21:14:17.877057 23876 trainer.py:136] Epoch[408/1000] loss: 0.09564343467354774
I0422 21:14:22.696017 23876 trainer.py:136] Epoch[409/1000] loss: 0.09641016274690628
I0422 21:14:28.968219 23876 trainer.py:136] Epoch[410/1000] loss: 0.09713061712682247
I0422 21:14:35.104502 23876 trainer.py:136] Epoch[411/1000] loss: 0.09720313176512718
I0422 21:14:40.233821 23876 trainer.py:136] Epoch[412/1000] loss: 0.09779729507863522
I0422 21:14:47.263926 23876 trainer.py:136] Epoch[413/1000] loss: 0.0972253791987896
I0422 21:14:53.262271 23876 trainer.py:136] Epoch[414/1000] loss: 0.09701172076165676
I0422 21:14:58.294859 23876 trainer.py:136] Epoch[415/1000] loss: 0.09579668380320072
I0422 21:15:03.281972 23876 trainer.py:136] Epoch[416/1000] loss: 0.096488818526268
I0422 21:15:10.719294 23876 trainer.py:136] Epoch[417/1000] loss: 0.09626375511288643
I0422 21:15:16.071760 23876 trainer.py:136] Epoch[418/1000] loss: 0.09712132625281811
I0422 21:15:21.097556 23876 trainer.py:136] Epoch[419/1000] loss: 0.0961905512958765
I0422 21:15:26.110004 23876 trainer.py:136] Epoch[420/1000] loss: 0.09668653085827827
I0422 21:15:32.354474 23876 trainer.py:136] Epoch[421/1000] loss: 0.09465294145047665
I0422 21:15:39.135682 23876 trainer.py:136] Epoch[422/1000] loss: 0.09592171013355255
I0422 21:15:44.104873 23876 trainer.py:136] Epoch[423/1000] loss: 0.09571600146591663
I0422 21:15:49.193810 23876 trainer.py:136] Epoch[424/1000] loss: 0.09479178115725517
I0422 21:15:57.594955 23876 trainer.py:136] Epoch[425/1000] loss: 0.09588928148150444
I0422 21:16:02.701705 23876 trainer.py:136] Epoch[426/1000] loss: 0.09515818767249584
I0422 21:16:07.659265 23876 trainer.py:136] Epoch[427/1000] loss: 0.09542212449014187
I0422 21:16:15.385112 23876 trainer.py:136] Epoch[428/1000] loss: 0.09629831090569496
I0422 21:16:20.492638 23876 trainer.py:136] Epoch[429/1000] loss: 0.09492115490138531
I0422 21:16:25.411951 23876 trainer.py:136] Epoch[430/1000] loss: 0.09462540037930012
I0422 21:16:30.473870 23876 trainer.py:136] Epoch[431/1000] loss: 0.0948676448315382
I0422 21:16:38.311601 23876 trainer.py:136] Epoch[432/1000] loss: 0.09460606798529625
I0422 21:16:43.371598 23876 trainer.py:136] Epoch[433/1000] loss: 0.09483333863317966
I0422 21:16:48.574244 23876 trainer.py:136] Epoch[434/1000] loss: 0.0952166561037302
I0422 21:16:53.621165 23876 trainer.py:136] Epoch[435/1000] loss: 0.09571711346507072
I0422 21:16:59.701054 23876 trainer.py:136] Epoch[436/1000] loss: 0.09588748402893543
I0422 21:17:06.766564 23876 trainer.py:136] Epoch[437/1000] loss: 0.09463963471353054
I0422 21:17:11.945238 23876 trainer.py:136] Epoch[438/1000] loss: 0.0955225769430399
I0422 21:17:17.999632 23876 trainer.py:136] Epoch[439/1000] loss: 0.09409151040017605
I0422 21:17:24.933627 23876 trainer.py:136] Epoch[440/1000] loss: 0.09494307264685631
I0422 21:17:29.934473 23876 trainer.py:136] Epoch[441/1000] loss: 0.09519654139876366
I0422 21:17:35.162582 23876 trainer.py:136] Epoch[442/1000] loss: 0.09551339782774448
I0422 21:17:43.627479 23876 trainer.py:136] Epoch[443/1000] loss: 0.09428748674690723
I0422 21:17:48.913277 23876 trainer.py:136] Epoch[444/1000] loss: 0.09393083676695824
I0422 21:17:56.150124 23876 trainer.py:136] Epoch[445/1000] loss: 0.09446029365062714
I0422 21:18:01.676498 23876 trainer.py:136] Epoch[446/1000] loss: 0.09471856988966465
I0422 21:18:06.628316 23876 trainer.py:136] Epoch[447/1000] loss: 0.09387174621224403
I0422 21:18:11.755008 23876 trainer.py:136] Epoch[448/1000] loss: 0.09485060162842274
I0422 21:18:18.220420 23876 trainer.py:136] Epoch[449/1000] loss: 0.09491581842303276
I0422 21:18:21.031185 23876 trainer.py:142] Test: [{'precision': 0.015849486887115155, 'recall': 0.07453279831685476, 'hit_ratio': 0.2176453819840365, 'ndcg': 0.049525172060349454}]
I0422 21:18:26.142511 23876 trainer.py:136] Epoch[450/1000] loss: 0.09339996241033077
I0422 21:18:31.130236 23876 trainer.py:136] Epoch[451/1000] loss: 0.09489841014146805
I0422 21:18:36.240128 23876 trainer.py:136] Epoch[452/1000] loss: 0.09409042075276375
I0422 21:18:43.768823 23876 trainer.py:136] Epoch[453/1000] loss: 0.09434467554092407
I0422 21:18:49.339293 23876 trainer.py:136] Epoch[454/1000] loss: 0.09527337364852428
I0422 21:18:54.518746 23876 trainer.py:136] Epoch[455/1000] loss: 0.0939758699387312
I0422 21:19:02.417433 23876 trainer.py:136] Epoch[456/1000] loss: 0.09373105317354202
I0422 21:19:07.518832 23876 trainer.py:136] Epoch[457/1000] loss: 0.09294689819216728
I0422 21:19:12.370379 23876 trainer.py:136] Epoch[458/1000] loss: 0.09453159943223
I0422 21:19:19.003606 23876 trainer.py:136] Epoch[459/1000] loss: 0.09385218285024166
I0422 21:19:25.887968 23876 trainer.py:136] Epoch[460/1000] loss: 0.09435500204563141
I0422 21:19:30.783699 23876 trainer.py:136] Epoch[461/1000] loss: 0.09424333646893501
I0422 21:19:36.143147 23876 trainer.py:136] Epoch[462/1000] loss: 0.09370545484125614
I0422 21:19:43.844548 23876 trainer.py:136] Epoch[463/1000] loss: 0.09356684796512127
I0422 21:19:48.882393 23876 trainer.py:136] Epoch[464/1000] loss: 0.09449216164648533
I0422 21:19:54.086851 23876 trainer.py:136] Epoch[465/1000] loss: 0.09334149397909641
I0422 21:20:02.389047 23876 trainer.py:136] Epoch[466/1000] loss: 0.09388523362576962
I0422 21:20:07.326437 23876 trainer.py:136] Epoch[467/1000] loss: 0.09389129094779491
I0422 21:20:12.888783 23876 trainer.py:136] Epoch[468/1000] loss: 0.09332812763750553
I0422 21:20:20.661513 23876 trainer.py:136] Epoch[469/1000] loss: 0.09412219934165478
I0422 21:20:25.426036 23876 trainer.py:136] Epoch[470/1000] loss: 0.0936477817595005
I0422 21:20:30.351446 23876 trainer.py:136] Epoch[471/1000] loss: 0.09370837546885014
I0422 21:20:35.209085 23876 trainer.py:136] Epoch[472/1000] loss: 0.09280036203563213
I0422 21:20:42.913502 23876 trainer.py:136] Epoch[473/1000] loss: 0.09383996203541756
I0422 21:20:47.812396 23876 trainer.py:136] Epoch[474/1000] loss: 0.09283125028014183
I0422 21:20:52.957931 23876 trainer.py:136] Epoch[475/1000] loss: 0.09263605438172817
I0422 21:20:59.710136 23876 trainer.py:136] Epoch[476/1000] loss: 0.09311029128730297
I0422 21:21:05.593535 23876 trainer.py:136] Epoch[477/1000] loss: 0.09242350049316883
I0422 21:21:10.788002 23876 trainer.py:136] Epoch[478/1000] loss: 0.09310343489050865
I0422 21:21:15.718220 23876 trainer.py:136] Epoch[479/1000] loss: 0.09276869148015976
I0422 21:21:23.737218 23876 trainer.py:136] Epoch[480/1000] loss: 0.09274074994027615
I0422 21:21:28.754217 23876 trainer.py:136] Epoch[481/1000] loss: 0.09252647124230862
I0422 21:21:33.846031 23876 trainer.py:136] Epoch[482/1000] loss: 0.09418259374797344
I0422 21:21:41.590821 23876 trainer.py:136] Epoch[483/1000] loss: 0.09178564138710499
I0422 21:21:46.474378 23876 trainer.py:136] Epoch[484/1000] loss: 0.09381991997361183
I0422 21:21:51.603075 23876 trainer.py:136] Epoch[485/1000] loss: 0.09382966719567776
I0422 21:21:56.629148 23876 trainer.py:136] Epoch[486/1000] loss: 0.09339022636413574
I0422 21:22:04.369467 23876 trainer.py:136] Epoch[487/1000] loss: 0.09362412802875042
I0422 21:22:09.559071 23876 trainer.py:136] Epoch[488/1000] loss: 0.09230598248541355
I0422 21:22:14.463440 23876 trainer.py:136] Epoch[489/1000] loss: 0.09237724915146828
I0422 21:22:22.244127 23876 trainer.py:136] Epoch[490/1000] loss: 0.0921228788793087
I0422 21:22:27.246827 23876 trainer.py:136] Epoch[491/1000] loss: 0.09366611018776894
I0422 21:22:31.895883 23876 trainer.py:136] Epoch[492/1000] loss: 0.09270790405571461
I0422 21:22:36.218273 23876 trainer.py:136] Epoch[493/1000] loss: 0.09180494584143162
I0422 21:22:43.322303 23876 trainer.py:136] Epoch[494/1000] loss: 0.09301719814538956
I0422 21:22:47.454792 23876 trainer.py:136] Epoch[495/1000] loss: 0.09218711778521538
I0422 21:22:51.858320 23876 trainer.py:136] Epoch[496/1000] loss: 0.09203442744910717
I0422 21:22:56.784221 23876 trainer.py:136] Epoch[497/1000] loss: 0.0926942266523838
I0422 21:23:04.922771 23876 trainer.py:136] Epoch[498/1000] loss: 0.09369868040084839
I0422 21:23:10.028509 23876 trainer.py:136] Epoch[499/1000] loss: 0.09251959808170795
I0422 21:23:12.178047 23876 trainer.py:142] Test: [{'precision': 0.015942132269099192, 'recall': 0.07532704089760126, 'hit_ratio': 0.21921322690992018, 'ndcg': 0.04990833724813414}]
I0422 21:23:17.240997 23876 trainer.py:136] Epoch[500/1000] loss: 0.09220784157514572
I0422 21:23:25.126604 23876 trainer.py:136] Epoch[501/1000] loss: 0.09249914437532425
I0422 21:23:30.200416 23876 trainer.py:136] Epoch[502/1000] loss: 0.09145398437976837
I0422 21:23:36.209067 23876 trainer.py:136] Epoch[503/1000] loss: 0.09215886518359184
I0422 21:23:42.929398 23876 trainer.py:136] Epoch[504/1000] loss: 0.09236332587897778
I0422 21:23:48.000465 23876 trainer.py:136] Epoch[505/1000] loss: 0.09116723574697971
I0422 21:23:55.643361 23876 trainer.py:136] Epoch[506/1000] loss: 0.09120230562984943
I0422 21:24:00.941965 23876 trainer.py:136] Epoch[507/1000] loss: 0.09226005338132381
I0422 21:24:05.916131 23876 trainer.py:136] Epoch[508/1000] loss: 0.09161928109824657
I0422 21:24:11.799510 23876 trainer.py:136] Epoch[509/1000] loss: 0.09139426797628403
I0422 21:24:18.686555 23876 trainer.py:136] Epoch[510/1000] loss: 0.09126684814691544
I0422 21:24:23.735990 23876 trainer.py:136] Epoch[511/1000] loss: 0.09203431755304337
I0422 21:24:29.177920 23876 trainer.py:136] Epoch[512/1000] loss: 0.09212690964341164
I0422 21:24:36.813008 23876 trainer.py:136] Epoch[513/1000] loss: 0.09218869544565678
I0422 21:24:41.733473 23876 trainer.py:136] Epoch[514/1000] loss: 0.09252181462943554
I0422 21:24:46.959896 23876 trainer.py:136] Epoch[515/1000] loss: 0.09044483117759228
I0422 21:24:54.916316 23876 trainer.py:136] Epoch[516/1000] loss: 0.09152768179774284
I0422 21:24:59.779214 23876 trainer.py:136] Epoch[517/1000] loss: 0.0920526422560215
I0422 21:25:04.823797 23876 trainer.py:136] Epoch[518/1000] loss: 0.09144827723503113
I0422 21:25:12.619895 23876 trainer.py:136] Epoch[519/1000] loss: 0.09162758477032185
I0422 21:25:17.703216 23876 trainer.py:136] Epoch[520/1000] loss: 0.0914288405328989
I0422 21:25:22.818617 23876 trainer.py:136] Epoch[521/1000] loss: 0.09240537136793137
I0422 21:25:30.992849 23876 trainer.py:136] Epoch[522/1000] loss: 0.09221127815544605
I0422 21:25:35.791996 23876 trainer.py:136] Epoch[523/1000] loss: 0.09072906523942947
I0422 21:25:41.321544 23876 trainer.py:136] Epoch[524/1000] loss: 0.0912026446312666
I0422 21:25:48.269334 23876 trainer.py:136] Epoch[525/1000] loss: 0.09135016798973083
I0422 21:25:53.188999 23876 trainer.py:136] Epoch[526/1000] loss: 0.0903079193085432
I0422 21:25:58.112411 23876 trainer.py:136] Epoch[527/1000] loss: 0.0910416729748249
I0422 21:26:04.652273 23876 trainer.py:136] Epoch[528/1000] loss: 0.09095001593232155
I0422 21:26:10.419632 23876 trainer.py:136] Epoch[529/1000] loss: 0.0915072076022625
I0422 21:26:15.376025 23876 trainer.py:136] Epoch[530/1000] loss: 0.089699761942029
I0422 21:26:20.105776 23876 trainer.py:136] Epoch[531/1000] loss: 0.0907785315066576
I0422 21:26:26.033800 23876 trainer.py:136] Epoch[532/1000] loss: 0.09055572003126144
I0422 21:26:32.575004 23876 trainer.py:136] Epoch[533/1000] loss: 0.09124284982681274
I0422 21:26:37.421548 23876 trainer.py:136] Epoch[534/1000] loss: 0.09117994084954262
I0422 21:26:41.563435 23876 trainer.py:136] Epoch[535/1000] loss: 0.090352026745677
I0422 21:26:45.631352 23876 trainer.py:136] Epoch[536/1000] loss: 0.09127764403820038
I0422 21:26:49.623257 23876 trainer.py:136] Epoch[537/1000] loss: 0.09064033627510071
I0422 21:26:53.484650 23876 trainer.py:136] Epoch[538/1000] loss: 0.09179569780826569
I0422 21:26:57.511629 23876 trainer.py:136] Epoch[539/1000] loss: 0.08994478546082973
I0422 21:27:02.450046 23876 trainer.py:136] Epoch[540/1000] loss: 0.08996784687042236
I0422 21:27:07.978641 23876 trainer.py:136] Epoch[541/1000] loss: 0.09107205271720886
I0422 21:27:11.998951 23876 trainer.py:136] Epoch[542/1000] loss: 0.0897713415324688
I0422 21:27:16.125994 23876 trainer.py:136] Epoch[543/1000] loss: 0.0905420146882534
I0422 21:27:20.289377 23876 trainer.py:136] Epoch[544/1000] loss: 0.09070731326937675
I0422 21:27:24.356160 23876 trainer.py:136] Epoch[545/1000] loss: 0.09119882062077522
I0422 21:27:28.549929 23876 trainer.py:136] Epoch[546/1000] loss: 0.09091230854392052
I0422 21:27:32.499572 23876 trainer.py:136] Epoch[547/1000] loss: 0.09108235314488411
I0422 21:27:36.543893 23876 trainer.py:136] Epoch[548/1000] loss: 0.09137137420475483
I0422 21:27:40.694290 23876 trainer.py:136] Epoch[549/1000] loss: 0.09024159237742424
I0422 21:27:42.111094 23876 trainer.py:142] Test: [{'precision': 0.016056157354618013, 'recall': 0.07612228348501195, 'hit_ratio': 0.22063854047890535, 'ndcg': 0.050229846386933785}]
I0422 21:27:46.227166 23876 trainer.py:136] Epoch[550/1000] loss: 0.09090983308851719
I0422 21:27:50.257966 23876 trainer.py:136] Epoch[551/1000] loss: 0.09051341377198696
I0422 21:27:54.329935 23876 trainer.py:136] Epoch[552/1000] loss: 0.08901778981089592
I0422 21:27:58.270138 23876 trainer.py:136] Epoch[553/1000] loss: 0.09006098099052906
I0422 21:28:03.945405 23876 trainer.py:136] Epoch[554/1000] loss: 0.09020759724080563
I0422 21:28:09.240249 23876 trainer.py:136] Epoch[555/1000] loss: 0.09074331633746624
I0422 21:28:13.501362 23876 trainer.py:136] Epoch[556/1000] loss: 0.0902284849435091
I0422 21:28:17.580086 23876 trainer.py:136] Epoch[557/1000] loss: 0.08920946530997753
I0422 21:28:22.251595 23876 trainer.py:136] Epoch[558/1000] loss: 0.09029143862426281
I0422 21:28:30.036948 23876 trainer.py:136] Epoch[559/1000] loss: 0.0892206784337759
I0422 21:28:35.044989 23876 trainer.py:136] Epoch[560/1000] loss: 0.09016988798975945
I0422 21:28:39.991457 23876 trainer.py:136] Epoch[561/1000] loss: 0.08967101760208607
I0422 21:28:45.068414 23876 trainer.py:136] Epoch[562/1000] loss: 0.09016702324151993
I0422 21:28:52.505857 23876 trainer.py:136] Epoch[563/1000] loss: 0.08934647031128407
I0422 21:28:57.447312 23876 trainer.py:136] Epoch[564/1000] loss: 0.09085749462246895
I0422 21:29:02.666684 23876 trainer.py:136] Epoch[565/1000] loss: 0.08931599371135235
I0422 21:29:10.655428 23876 trainer.py:136] Epoch[566/1000] loss: 0.08943517506122589
I0422 21:29:15.653813 23876 trainer.py:136] Epoch[567/1000] loss: 0.08992878720164299
I0422 21:29:20.906099 23876 trainer.py:136] Epoch[568/1000] loss: 0.09032726474106312
I0422 21:29:29.160368 23876 trainer.py:136] Epoch[569/1000] loss: 0.08958417549729347
I0422 21:29:34.072933 23876 trainer.py:136] Epoch[570/1000] loss: 0.0888834148645401
I0422 21:29:38.807071 23876 trainer.py:136] Epoch[571/1000] loss: 0.09136282093822956
I0422 21:29:46.886272 23876 trainer.py:136] Epoch[572/1000] loss: 0.08986141718924046
I0422 21:29:51.828853 23876 trainer.py:136] Epoch[573/1000] loss: 0.08878961764276028
I0422 21:29:56.817135 23876 trainer.py:136] Epoch[574/1000] loss: 0.09048808179795742
I0422 21:30:04.621233 23876 trainer.py:136] Epoch[575/1000] loss: 0.08954240195453167
I0422 21:30:09.613598 23876 trainer.py:136] Epoch[576/1000] loss: 0.08965202607214451
I0422 21:30:14.692454 23876 trainer.py:136] Epoch[577/1000] loss: 0.08966008573770523
I0422 21:30:22.436543 23876 trainer.py:136] Epoch[578/1000] loss: 0.08954662457108498
I0422 21:30:26.641259 23876 trainer.py:136] Epoch[579/1000] loss: 0.0894554890692234
I0422 21:30:30.583051 23876 trainer.py:136] Epoch[580/1000] loss: 0.08910579606890678
I0422 21:30:34.724465 23876 trainer.py:136] Epoch[581/1000] loss: 0.09023057110607624
I0422 21:30:38.853930 23876 trainer.py:136] Epoch[582/1000] loss: 0.08925649709999561
I0422 21:30:43.194345 23876 trainer.py:136] Epoch[583/1000] loss: 0.09028943814337254
I0422 21:30:50.292969 23876 trainer.py:136] Epoch[584/1000] loss: 0.08971250057220459
I0422 21:30:54.566847 23876 trainer.py:136] Epoch[585/1000] loss: 0.08934764936566353
I0422 21:30:58.812601 23876 trainer.py:136] Epoch[586/1000] loss: 0.08818073943257332
I0422 21:31:02.961038 23876 trainer.py:136] Epoch[587/1000] loss: 0.0892241932451725
I0422 21:31:07.288452 23876 trainer.py:136] Epoch[588/1000] loss: 0.08947981148958206
I0422 21:31:11.521712 23876 trainer.py:136] Epoch[589/1000] loss: 0.08907846733927727
I0422 21:31:18.529678 23876 trainer.py:136] Epoch[590/1000] loss: 0.0888677854090929
I0422 21:31:22.779949 23876 trainer.py:136] Epoch[591/1000] loss: 0.0886741615831852
I0422 21:31:27.252844 23876 trainer.py:136] Epoch[592/1000] loss: 0.08871272392570972
I0422 21:31:31.753129 23876 trainer.py:136] Epoch[593/1000] loss: 0.08842892572283745
I0422 21:31:37.960831 23876 trainer.py:136] Epoch[594/1000] loss: 0.09036755189299583
I0422 21:31:44.666691 23876 trainer.py:136] Epoch[595/1000] loss: 0.08903719671070576
I0422 21:31:49.495352 23876 trainer.py:136] Epoch[596/1000] loss: 0.0880857203155756
I0422 21:31:56.187088 23876 trainer.py:136] Epoch[597/1000] loss: 0.08864911086857319
I0422 21:32:02.555421 23876 trainer.py:136] Epoch[598/1000] loss: 0.08901114389300346
I0422 21:32:07.483045 23876 trainer.py:136] Epoch[599/1000] loss: 0.08823432214558125
I0422 21:32:09.636156 23876 trainer.py:142] Test: [{'precision': 0.01607041049030786, 'recall': 0.07596913476795157, 'hit_ratio': 0.22006841505131128, 'ndcg': 0.05035147648906197}]
I0422 21:32:17.698675 23876 trainer.py:136] Epoch[600/1000] loss: 0.0887922327965498
I0422 21:32:22.876470 23876 trainer.py:136] Epoch[601/1000] loss: 0.0893245879560709
I0422 21:32:27.877460 23876 trainer.py:136] Epoch[602/1000] loss: 0.08844497613608837
I0422 21:32:35.955705 23876 trainer.py:136] Epoch[603/1000] loss: 0.08927976153790951
I0422 21:32:40.854692 23876 trainer.py:136] Epoch[604/1000] loss: 0.08808408305048943
I0422 21:32:46.847211 23876 trainer.py:136] Epoch[605/1000] loss: 0.08818235993385315
I0422 21:32:53.577794 23876 trainer.py:136] Epoch[606/1000] loss: 0.09004387818276882
I0422 21:32:57.988353 23876 trainer.py:136] Epoch[607/1000] loss: 0.090005436912179
I0422 21:33:02.080623 23876 trainer.py:136] Epoch[608/1000] loss: 0.08867968246340752
I0422 21:33:06.184696 23876 trainer.py:136] Epoch[609/1000] loss: 0.0880532693117857
I0422 21:33:13.052335 23876 trainer.py:136] Epoch[610/1000] loss: 0.08890647999942303
I0422 21:33:17.325064 23876 trainer.py:136] Epoch[611/1000] loss: 0.0887102410197258
I0422 21:33:21.575926 23876 trainer.py:136] Epoch[612/1000] loss: 0.08787093311548233
I0422 21:33:25.607825 23876 trainer.py:136] Epoch[613/1000] loss: 0.08856981061398983
I0422 21:33:29.750061 23876 trainer.py:136] Epoch[614/1000] loss: 0.08845180831849575
I0422 21:33:33.973219 23876 trainer.py:136] Epoch[615/1000] loss: 0.08905014209449291
I0422 21:33:41.504739 23876 trainer.py:136] Epoch[616/1000] loss: 0.088211165741086
I0422 21:33:46.421080 23876 trainer.py:136] Epoch[617/1000] loss: 0.08824526891112328
I0422 21:33:51.487025 23876 trainer.py:136] Epoch[618/1000] loss: 0.08922968059778214
I0422 21:33:59.742174 23876 trainer.py:136] Epoch[619/1000] loss: 0.08853048831224442
I0422 21:34:04.830996 23876 trainer.py:136] Epoch[620/1000] loss: 0.08871147409081459
I0422 21:34:09.813822 23876 trainer.py:136] Epoch[621/1000] loss: 0.08753811754286289
I0422 21:34:17.919813 23876 trainer.py:136] Epoch[622/1000] loss: 0.08826367370784283
I0422 21:34:22.965839 23876 trainer.py:136] Epoch[623/1000] loss: 0.08785746805369854
I0422 21:34:29.263859 23876 trainer.py:136] Epoch[624/1000] loss: 0.08766201511025429
I0422 21:34:36.271605 23876 trainer.py:136] Epoch[625/1000] loss: 0.08808141946792603
I0422 21:34:41.326826 23876 trainer.py:136] Epoch[626/1000] loss: 0.08846964687108994
I0422 21:34:48.021913 23876 trainer.py:136] Epoch[627/1000] loss: 0.0890023447573185
I0422 21:34:53.928638 23876 trainer.py:136] Epoch[628/1000] loss: 0.08743381686508656
I0422 21:34:57.938489 23876 trainer.py:136] Epoch[629/1000] loss: 0.08895783498883247
I0422 21:35:01.959613 23876 trainer.py:136] Epoch[630/1000] loss: 0.0882069580256939
I0422 21:35:06.016687 23876 trainer.py:136] Epoch[631/1000] loss: 0.08892988599836826
I0422 21:35:09.980441 23876 trainer.py:136] Epoch[632/1000] loss: 0.08880442380905151
I0422 21:35:16.662394 23876 trainer.py:136] Epoch[633/1000] loss: 0.0874139629304409
I0422 21:35:20.717113 23876 trainer.py:136] Epoch[634/1000] loss: 0.08814582228660583
I0422 21:35:24.844233 23876 trainer.py:136] Epoch[635/1000] loss: 0.08819041028618813
I0422 21:35:28.945873 23876 trainer.py:136] Epoch[636/1000] loss: 0.0881271343678236
I0422 21:35:33.098636 23876 trainer.py:136] Epoch[637/1000] loss: 0.08811129629611969
I0422 21:35:37.016634 23876 trainer.py:136] Epoch[638/1000] loss: 0.0888426024466753
I0422 21:35:41.227894 23876 trainer.py:136] Epoch[639/1000] loss: 0.08808131515979767
I0422 21:35:45.856223 23876 trainer.py:136] Epoch[640/1000] loss: 0.0878953505307436
I0422 21:35:51.933003 23876 trainer.py:136] Epoch[641/1000] loss: 0.08829933591187
I0422 21:35:56.063938 23876 trainer.py:136] Epoch[642/1000] loss: 0.08754362724721432
I0422 21:36:00.033942 23876 trainer.py:136] Epoch[643/1000] loss: 0.08746563829481602
I0422 21:36:04.239305 23876 trainer.py:136] Epoch[644/1000] loss: 0.08854628726840019
I0422 21:36:08.609852 23876 trainer.py:136] Epoch[645/1000] loss: 0.08732077665627003
I0422 21:36:13.878124 23876 trainer.py:136] Epoch[646/1000] loss: 0.08831893280148506
I0422 21:36:19.702766 23876 trainer.py:136] Epoch[647/1000] loss: 0.08817370422184467
I0422 21:36:23.817730 23876 trainer.py:136] Epoch[648/1000] loss: 0.08701571449637413
I0422 21:36:27.960251 23876 trainer.py:136] Epoch[649/1000] loss: 0.08711326122283936
I0422 21:36:29.441431 23876 trainer.py:142] Test: [{'precision': 0.016170182440136825, 'recall': 0.07639642561979448, 'hit_ratio': 0.22149372862029645, 'ndcg': 0.050529718744957215}]
I0422 21:36:33.743003 23876 trainer.py:136] Epoch[650/1000] loss: 0.08716596104204655
I0422 21:36:37.882448 23876 trainer.py:136] Epoch[651/1000] loss: 0.08845148980617523
I0422 21:36:44.577364 23876 trainer.py:136] Epoch[652/1000] loss: 0.08799004554748535
I0422 21:36:48.858992 23876 trainer.py:136] Epoch[653/1000] loss: 0.08748378232121468
I0422 21:36:52.916764 23876 trainer.py:136] Epoch[654/1000] loss: 0.08741225302219391
I0422 21:36:57.095268 23876 trainer.py:136] Epoch[655/1000] loss: 0.08848023414611816
I0422 21:37:01.250060 23876 trainer.py:136] Epoch[656/1000] loss: 0.08819573745131493
I0422 21:37:05.257812 23876 trainer.py:136] Epoch[657/1000] loss: 0.08752873726189137
I0422 21:37:09.337099 23876 trainer.py:136] Epoch[658/1000] loss: 0.08748816885054111
I0422 21:37:13.314152 23876 trainer.py:136] Epoch[659/1000] loss: 0.08775038458406925
I0422 21:37:17.395745 23876 trainer.py:136] Epoch[660/1000] loss: 0.08808499202132225
I0422 21:37:21.452204 23876 trainer.py:136] Epoch[661/1000] loss: 0.08781364932656288
I0422 21:37:25.512613 23876 trainer.py:136] Epoch[662/1000] loss: 0.08764597773551941
I0422 21:37:31.967211 23876 trainer.py:136] Epoch[663/1000] loss: 0.0878389272838831
I0422 21:37:36.039881 23876 trainer.py:136] Epoch[664/1000] loss: 0.08863539807498455
I0422 21:37:40.079492 23876 trainer.py:136] Epoch[665/1000] loss: 0.08743050321936607
I0422 21:37:44.214498 23876 trainer.py:136] Epoch[666/1000] loss: 0.08608927018940449
I0422 21:37:48.309010 23876 trainer.py:136] Epoch[667/1000] loss: 0.08800588920712471
I0422 21:37:52.204304 23876 trainer.py:136] Epoch[668/1000] loss: 0.08675681613385677
I0422 21:37:56.438362 23876 trainer.py:136] Epoch[669/1000] loss: 0.08757259882986546
I0422 21:38:00.793026 23876 trainer.py:136] Epoch[670/1000] loss: 0.08821079134941101
I0422 21:38:07.731035 23876 trainer.py:136] Epoch[671/1000] loss: 0.08655641227960587
I0422 21:38:12.141144 23876 trainer.py:136] Epoch[672/1000] loss: 0.08845850825309753
I0422 21:38:16.330445 23876 trainer.py:136] Epoch[673/1000] loss: 0.087308743968606
I0422 21:38:20.417347 23876 trainer.py:136] Epoch[674/1000] loss: 0.0873247068375349
I0422 21:38:24.715235 23876 trainer.py:136] Epoch[675/1000] loss: 0.08658995665609837
I0422 21:38:28.664268 23876 trainer.py:136] Epoch[676/1000] loss: 0.08808895200490952
I0422 21:38:35.303741 23876 trainer.py:136] Epoch[677/1000] loss: 0.08769595064222813
I0422 21:38:39.525497 23876 trainer.py:136] Epoch[678/1000] loss: 0.08698260225355625
I0422 21:38:43.643155 23876 trainer.py:136] Epoch[679/1000] loss: 0.08760561794042587
I0422 21:38:47.618639 23876 trainer.py:136] Epoch[680/1000] loss: 0.08622058480978012
I0422 21:38:51.780559 23876 trainer.py:136] Epoch[681/1000] loss: 0.08783337660133839
I0422 21:38:55.725114 23876 trainer.py:136] Epoch[682/1000] loss: 0.08702383376657963
I0422 21:38:59.958781 23876 trainer.py:136] Epoch[683/1000] loss: 0.08589154854416847
I0422 21:39:04.109380 23876 trainer.py:136] Epoch[684/1000] loss: 0.0869384091347456
I0422 21:39:08.105911 23876 trainer.py:136] Epoch[685/1000] loss: 0.08817834593355656
I0422 21:39:12.134477 23876 trainer.py:136] Epoch[686/1000] loss: 0.08694450557231903
I0422 21:39:16.229619 23876 trainer.py:136] Epoch[687/1000] loss: 0.08653278648853302
I0422 21:39:20.271010 23876 trainer.py:136] Epoch[688/1000] loss: 0.08619497157633305
I0422 21:39:24.425126 23876 trainer.py:136] Epoch[689/1000] loss: 0.08653020113706589
I0422 21:39:30.976789 23876 trainer.py:136] Epoch[690/1000] loss: 0.08689451217651367
I0422 21:39:35.074981 23876 trainer.py:136] Epoch[691/1000] loss: 0.086722232401371
I0422 21:39:39.190082 23876 trainer.py:136] Epoch[692/1000] loss: 0.08623424358665943
I0422 21:39:43.144146 23876 trainer.py:136] Epoch[693/1000] loss: 0.08705862052738667
I0422 21:39:47.072025 23876 trainer.py:136] Epoch[694/1000] loss: 0.08679482154548168
I0422 21:39:51.122278 23876 trainer.py:136] Epoch[695/1000] loss: 0.08682555891573429
I0422 21:39:55.219818 23876 trainer.py:136] Epoch[696/1000] loss: 0.08607049100100994
I0422 21:39:59.223739 23876 trainer.py:136] Epoch[697/1000] loss: 0.08614752069115639
I0422 21:40:03.367845 23876 trainer.py:136] Epoch[698/1000] loss: 0.08597285859286785
I0422 21:40:07.484643 23876 trainer.py:136] Epoch[699/1000] loss: 0.08740291371941566
I0422 21:40:08.941366 23876 trainer.py:142] Test: [{'precision': 0.016212941847206373, 'recall': 0.0771558179573018, 'hit_ratio': 0.22149372862029645, 'ndcg': 0.05089681819077873}]
I0422 21:40:13.218475 23876 trainer.py:136] Epoch[700/1000] loss: 0.0860107745975256
I0422 21:40:19.115465 23876 trainer.py:136] Epoch[701/1000] loss: 0.08642731793224812
I0422 21:40:23.832013 23876 trainer.py:136] Epoch[702/1000] loss: 0.0876846481114626
I0422 21:40:28.041731 23876 trainer.py:136] Epoch[703/1000] loss: 0.08721105381846428
I0422 21:40:32.144025 23876 trainer.py:136] Epoch[704/1000] loss: 0.08666257746517658
I0422 21:40:36.192849 23876 trainer.py:136] Epoch[705/1000] loss: 0.08658753894269466
I0422 21:40:40.173587 23876 trainer.py:136] Epoch[706/1000] loss: 0.0872371643781662
I0422 21:40:44.214738 23876 trainer.py:136] Epoch[707/1000] loss: 0.08649095520377159
I0422 21:40:48.324915 23876 trainer.py:136] Epoch[708/1000] loss: 0.08647718839347363
I0422 21:40:52.436920 23876 trainer.py:136] Epoch[709/1000] loss: 0.08618966862559319
I0422 21:40:56.571320 23876 trainer.py:136] Epoch[710/1000] loss: 0.08634351193904877
I0422 21:41:00.666651 23876 trainer.py:136] Epoch[711/1000] loss: 0.08690966479480267
I0422 21:41:04.796751 23876 trainer.py:136] Epoch[712/1000] loss: 0.08643757738173008
I0422 21:41:08.759266 23876 trainer.py:136] Epoch[713/1000] loss: 0.0860431157052517
I0422 21:41:15.203986 23876 trainer.py:136] Epoch[714/1000] loss: 0.08676069229841232
I0422 21:41:19.577609 23876 trainer.py:136] Epoch[715/1000] loss: 0.08601327240467072
I0422 21:41:23.531748 23876 trainer.py:136] Epoch[716/1000] loss: 0.08729621581733227
I0422 21:41:27.752994 23876 trainer.py:136] Epoch[717/1000] loss: 0.08645624108612537
I0422 21:41:32.081868 23876 trainer.py:136] Epoch[718/1000] loss: 0.08707504719495773
I0422 21:41:36.882200 23876 trainer.py:136] Epoch[719/1000] loss: 0.08747971802949905
I0422 21:41:42.918045 23876 trainer.py:136] Epoch[720/1000] loss: 0.08610009774565697
I0422 21:41:47.068409 23876 trainer.py:136] Epoch[721/1000] loss: 0.08628715202212334
I0422 21:41:51.123810 23876 trainer.py:136] Epoch[722/1000] loss: 0.08585911430418491
I0422 21:41:55.330939 23876 trainer.py:136] Epoch[723/1000] loss: 0.08575515262782574
I0422 21:41:59.404649 23876 trainer.py:136] Epoch[724/1000] loss: 0.0866488367319107
I0422 21:42:03.519276 23876 trainer.py:136] Epoch[725/1000] loss: 0.08648228645324707
I0422 21:42:08.721716 23876 trainer.py:136] Epoch[726/1000] loss: 0.08621180802583694
I0422 21:42:14.501932 23876 trainer.py:136] Epoch[727/1000] loss: 0.08587105385959148
I0422 21:42:18.772914 23876 trainer.py:136] Epoch[728/1000] loss: 0.08667957596480846
I0422 21:42:22.784744 23876 trainer.py:136] Epoch[729/1000] loss: 0.08611430786550045
I0422 21:42:27.123601 23876 trainer.py:136] Epoch[730/1000] loss: 0.08597356639802456
I0422 21:42:31.339276 23876 trainer.py:136] Epoch[731/1000] loss: 0.08596005290746689
I0422 21:42:35.357197 23876 trainer.py:136] Epoch[732/1000] loss: 0.08664305880665779
I0422 21:42:39.542547 23876 trainer.py:136] Epoch[733/1000] loss: 0.08522109501063824
I0422 21:42:46.446474 23876 trainer.py:136] Epoch[734/1000] loss: 0.08694049157202244
I0422 21:42:50.716025 23876 trainer.py:136] Epoch[735/1000] loss: 0.08620624430477619
I0422 21:42:54.982092 23876 trainer.py:136] Epoch[736/1000] loss: 0.08569680526852608
I0422 21:42:59.179054 23876 trainer.py:136] Epoch[737/1000] loss: 0.0850590243935585
I0422 21:43:03.481937 23876 trainer.py:136] Epoch[738/1000] loss: 0.08632786571979523
I0422 21:43:07.701078 23876 trainer.py:136] Epoch[739/1000] loss: 0.08588397689163685
I0422 21:43:11.782674 23876 trainer.py:136] Epoch[740/1000] loss: 0.08614134788513184
I0422 21:43:17.728353 23876 trainer.py:136] Epoch[741/1000] loss: 0.0869093555957079
I0422 21:43:22.317936 23876 trainer.py:136] Epoch[742/1000] loss: 0.0865931585431099
I0422 21:43:26.381214 23876 trainer.py:136] Epoch[743/1000] loss: 0.08595885336399078
I0422 21:43:30.658413 23876 trainer.py:136] Epoch[744/1000] loss: 0.08573636971414089
I0422 21:43:35.709768 23876 trainer.py:136] Epoch[745/1000] loss: 0.08658158779144287
I0422 21:43:43.221089 23876 trainer.py:136] Epoch[746/1000] loss: 0.08635813929140568
I0422 21:43:48.265629 23876 trainer.py:136] Epoch[747/1000] loss: 0.08574912138283253
I0422 21:43:53.205456 23876 trainer.py:136] Epoch[748/1000] loss: 0.08486078307032585
I0422 21:43:58.197564 23876 trainer.py:136] Epoch[749/1000] loss: 0.08617301657795906
I0422 21:44:00.870016 23876 trainer.py:142] Test: [{'precision': 0.016262827822120858, 'recall': 0.07739424271175839, 'hit_ratio': 0.22220638540478904, 'ndcg': 0.05113034959601523}]
I0422 21:44:07.519069 23876 trainer.py:136] Epoch[750/1000] loss: 0.08603065088391304
I0422 21:44:12.475644 23876 trainer.py:136] Epoch[751/1000] loss: 0.0851935725659132
I0422 21:44:17.432023 23876 trainer.py:136] Epoch[752/1000] loss: 0.08497831784188747
I0422 21:44:24.018323 23876 trainer.py:136] Epoch[753/1000] loss: 0.08625122345983982
I0422 21:44:30.003298 23876 trainer.py:136] Epoch[754/1000] loss: 0.0851270742714405
I0422 21:44:34.739368 23876 trainer.py:136] Epoch[755/1000] loss: 0.08573441579937935
I0422 21:44:39.813109 23876 trainer.py:136] Epoch[756/1000] loss: 0.08594362810254097
I0422 21:44:47.761046 23876 trainer.py:136] Epoch[757/1000] loss: 0.08585513010621071
I0422 21:44:52.550679 23876 trainer.py:136] Epoch[758/1000] loss: 0.08565409481525421
I0422 21:44:57.617617 23876 trainer.py:136] Epoch[759/1000] loss: 0.08558930084109306
I0422 21:45:02.758431 23876 trainer.py:136] Epoch[760/1000] loss: 0.08593634329736233
I0422 21:45:10.547033 23876 trainer.py:136] Epoch[761/1000] loss: 0.08611350320279598
I0422 21:45:15.195005 23876 trainer.py:136] Epoch[762/1000] loss: 0.08535004034638405
I0422 21:45:20.220046 23876 trainer.py:136] Epoch[763/1000] loss: 0.08592143841087818
I0422 21:45:25.134452 23876 trainer.py:136] Epoch[764/1000] loss: 0.08573436550796032
I0422 21:45:32.695868 23876 trainer.py:136] Epoch[765/1000] loss: 0.085794348269701
I0422 21:45:37.792241 23876 trainer.py:136] Epoch[766/1000] loss: 0.08478531613945961
I0422 21:45:42.673717 23876 trainer.py:136] Epoch[767/1000] loss: 0.08510988391935825
I0422 21:45:50.235088 23876 trainer.py:136] Epoch[768/1000] loss: 0.08601831085979939
I0422 21:45:55.195015 23876 trainer.py:136] Epoch[769/1000] loss: 0.08507209084928036
I0422 21:46:00.236016 23876 trainer.py:136] Epoch[770/1000] loss: 0.0865187831223011
I0422 21:46:05.118442 23876 trainer.py:136] Epoch[771/1000] loss: 0.08517807349562645
I0422 21:46:11.198714 23876 trainer.py:136] Epoch[772/1000] loss: 0.08629695884883404
I0422 21:46:17.771237 23876 trainer.py:136] Epoch[773/1000] loss: 0.08548637479543686
I0422 21:46:22.752510 23876 trainer.py:136] Epoch[774/1000] loss: 0.08532490767538548
I0422 21:46:27.767825 23876 trainer.py:136] Epoch[775/1000] loss: 0.08603183552622795
I0422 21:46:32.973300 23876 trainer.py:136] Epoch[776/1000] loss: 0.08538563922047615
I0422 21:46:40.523199 23876 trainer.py:136] Epoch[777/1000] loss: 0.08599280752241611
I0422 21:46:45.492097 23876 trainer.py:136] Epoch[778/1000] loss: 0.08524911291897297
I0422 21:46:50.558024 23876 trainer.py:136] Epoch[779/1000] loss: 0.08547426015138626
I0422 21:46:58.265860 23876 trainer.py:136] Epoch[780/1000] loss: 0.0855158381164074
I0422 21:47:03.345620 23876 trainer.py:136] Epoch[781/1000] loss: 0.0854467898607254
I0422 21:47:08.545406 23876 trainer.py:136] Epoch[782/1000] loss: 0.08472581394016743
I0422 21:47:14.787638 23876 trainer.py:136] Epoch[783/1000] loss: 0.08518463000655174
I0422 21:47:21.315526 23876 trainer.py:136] Epoch[784/1000] loss: 0.08500383049249649
I0422 21:47:26.126744 23876 trainer.py:136] Epoch[785/1000] loss: 0.08612088300287724
I0422 21:47:31.058722 23876 trainer.py:136] Epoch[786/1000] loss: 0.08611656725406647
I0422 21:47:37.219206 23876 trainer.py:136] Epoch[787/1000] loss: 0.08549325913190842
I0422 21:47:43.878539 23876 trainer.py:136] Epoch[788/1000] loss: 0.08550630696117878
I0422 21:47:48.919855 23876 trainer.py:136] Epoch[789/1000] loss: 0.08526857942342758
I0422 21:47:53.892618 23876 trainer.py:136] Epoch[790/1000] loss: 0.0852139312773943
I0422 21:47:59.216606 23876 trainer.py:136] Epoch[791/1000] loss: 0.0845013651996851
I0422 21:48:06.761466 23876 trainer.py:136] Epoch[792/1000] loss: 0.08514373935759068
I0422 21:48:11.931853 23876 trainer.py:136] Epoch[793/1000] loss: 0.08573734946548939
I0422 21:48:16.925976 23876 trainer.py:136] Epoch[794/1000] loss: 0.0853335689753294
I0422 21:48:21.832785 23876 trainer.py:136] Epoch[795/1000] loss: 0.08508864417672157
I0422 21:48:29.629335 23876 trainer.py:136] Epoch[796/1000] loss: 0.08511588536202908
I0422 21:48:34.450615 23876 trainer.py:136] Epoch[797/1000] loss: 0.08472823165357113
I0422 21:48:39.427275 23876 trainer.py:136] Epoch[798/1000] loss: 0.08513323031365871
I0422 21:48:44.348225 23876 trainer.py:136] Epoch[799/1000] loss: 0.08439161442220211
I0422 21:48:46.471646 23876 trainer.py:142] Test: [{'precision': 0.016362599771949822, 'recall': 0.07801926644492561, 'hit_ratio': 0.22320410490307868, 'ndcg': 0.051470036909547046}]
I0422 21:48:54.088286 23876 trainer.py:136] Epoch[800/1000] loss: 0.08575020171701908
I0422 21:48:59.097508 23876 trainer.py:136] Epoch[801/1000] loss: 0.08565452881157398
I0422 21:49:04.070469 23876 trainer.py:136] Epoch[802/1000] loss: 0.08560130558907986
I0422 21:49:09.060193 23876 trainer.py:136] Epoch[803/1000] loss: 0.08494270220398903
I0422 21:49:16.399987 23876 trainer.py:136] Epoch[804/1000] loss: 0.08516594022512436
I0422 21:49:21.460857 23876 trainer.py:136] Epoch[805/1000] loss: 0.08494830317795277
I0422 21:49:26.407205 23876 trainer.py:136] Epoch[806/1000] loss: 0.08546070009469986
I0422 21:49:32.042035 23876 trainer.py:136] Epoch[807/1000] loss: 0.08525658585131168
I0422 21:49:39.183401 23876 trainer.py:136] Epoch[808/1000] loss: 0.08519953116774559
I0422 21:49:44.107165 23876 trainer.py:136] Epoch[809/1000] loss: 0.08467641659080982
I0422 21:49:49.086331 23876 trainer.py:136] Epoch[810/1000] loss: 0.08588714338839054
I0422 21:49:55.232702 23876 trainer.py:136] Epoch[811/1000] loss: 0.08575289510190487
I0422 21:50:01.678556 23876 trainer.py:136] Epoch[812/1000] loss: 0.08510399051010609
I0422 21:50:06.559013 23876 trainer.py:136] Epoch[813/1000] loss: 0.08468016423285007
I0422 21:50:11.421649 23876 trainer.py:136] Epoch[814/1000] loss: 0.08611846528947353
I0422 21:50:16.392859 23876 trainer.py:136] Epoch[815/1000] loss: 0.08498614095151424
I0422 21:50:24.025162 23876 trainer.py:136] Epoch[816/1000] loss: 0.08520524948835373
I0422 21:50:28.785131 23876 trainer.py:136] Epoch[817/1000] loss: 0.0851050615310669
I0422 21:50:33.758670 23876 trainer.py:136] Epoch[818/1000] loss: 0.08614169433712959
I0422 21:50:38.835142 23876 trainer.py:136] Epoch[819/1000] loss: 0.08440732955932617
I0422 21:50:46.406026 23876 trainer.py:136] Epoch[820/1000] loss: 0.08528264984488487
I0422 21:50:51.346533 23876 trainer.py:136] Epoch[821/1000] loss: 0.08440843783318996
I0422 21:50:56.255403 23876 trainer.py:136] Epoch[822/1000] loss: 0.08508726395666599
I0422 21:51:01.278960 23876 trainer.py:136] Epoch[823/1000] loss: 0.0853981301188469
I0422 21:51:09.043633 23876 trainer.py:136] Epoch[824/1000] loss: 0.08519628271460533
I0422 21:51:13.893241 23876 trainer.py:136] Epoch[825/1000] loss: 0.0851366464048624
I0422 21:51:18.892436 23876 trainer.py:136] Epoch[826/1000] loss: 0.08452611789107323
I0422 21:51:24.158451 23876 trainer.py:136] Epoch[827/1000] loss: 0.08443174138665199
I0422 21:51:31.346121 23876 trainer.py:136] Epoch[828/1000] loss: 0.0852771271020174
I0422 21:51:36.390226 23876 trainer.py:136] Epoch[829/1000] loss: 0.08491256646811962
I0422 21:51:41.358208 23876 trainer.py:136] Epoch[830/1000] loss: 0.0837912019342184
I0422 21:51:46.338457 23876 trainer.py:136] Epoch[831/1000] loss: 0.08576144650578499
I0422 21:51:53.972703 23876 trainer.py:136] Epoch[832/1000] loss: 0.08408903330564499
I0422 21:51:59.064263 23876 trainer.py:136] Epoch[833/1000] loss: 0.08584807440638542
I0422 21:52:04.177494 23876 trainer.py:136] Epoch[834/1000] loss: 0.08478489704430103
I0422 21:52:11.253641 23876 trainer.py:136] Epoch[835/1000] loss: 0.08501304686069489
I0422 21:52:15.788097 23876 trainer.py:136] Epoch[836/1000] loss: 0.08461430110037327
I0422 21:52:19.834569 23876 trainer.py:136] Epoch[837/1000] loss: 0.08498877100646496
I0422 21:52:24.277276 23876 trainer.py:136] Epoch[838/1000] loss: 0.08491887524724007
I0422 21:52:29.209464 23876 trainer.py:136] Epoch[839/1000] loss: 0.0854648258537054
I0422 21:52:37.219187 23876 trainer.py:136] Epoch[840/1000] loss: 0.08522856421768665
I0422 21:52:42.078362 23876 trainer.py:136] Epoch[841/1000] loss: 0.08582179434597492
I0422 21:52:46.982489 23876 trainer.py:136] Epoch[842/1000] loss: 0.08436146937310696
I0422 21:52:53.201615 23876 trainer.py:136] Epoch[843/1000] loss: 0.08544914610683918
I0422 21:52:59.715492 23876 trainer.py:136] Epoch[844/1000] loss: 0.08495559170842171
I0422 21:53:04.747538 23876 trainer.py:136] Epoch[845/1000] loss: 0.0853839572519064
I0422 21:53:09.912127 23876 trainer.py:136] Epoch[846/1000] loss: 0.0850384496152401
I0422 21:53:17.959459 23876 trainer.py:136] Epoch[847/1000] loss: 0.0843230988830328
I0422 21:53:23.124862 23876 trainer.py:136] Epoch[848/1000] loss: 0.08620779775083065
I0422 21:53:28.298268 23876 trainer.py:136] Epoch[849/1000] loss: 0.0838380940258503
I0422 21:53:30.705399 23876 trainer.py:142] Test: [{'precision': 0.016476624857468637, 'recall': 0.07867644066384571, 'hit_ratio': 0.22534207525655645, 'ndcg': 0.0517271549887675}]
I0422 21:53:37.933569 23876 trainer.py:136] Epoch[850/1000] loss: 0.0843979250639677
I0422 21:53:42.759754 23876 trainer.py:136] Epoch[851/1000] loss: 0.08521532453596592
I0422 21:53:47.820471 23876 trainer.py:136] Epoch[852/1000] loss: 0.08464000187814236
I0422 21:53:55.407954 23876 trainer.py:136] Epoch[853/1000] loss: 0.08424216508865356
I0422 21:54:00.368688 23876 trainer.py:136] Epoch[854/1000] loss: 0.0846150629222393
I0422 21:54:05.396986 23876 trainer.py:136] Epoch[855/1000] loss: 0.08392907492816448
I0422 21:54:13.196894 23876 trainer.py:136] Epoch[856/1000] loss: 0.08382971584796906
I0422 21:54:18.334292 23876 trainer.py:136] Epoch[857/1000] loss: 0.08428342081606388
I0422 21:54:23.134433 23876 trainer.py:136] Epoch[858/1000] loss: 0.08477944135665894
I0422 21:54:31.019829 23876 trainer.py:136] Epoch[859/1000] loss: 0.08502382598817348
I0422 21:54:36.141050 23876 trainer.py:136] Epoch[860/1000] loss: 0.08473207987844944
I0422 21:54:41.332853 23876 trainer.py:136] Epoch[861/1000] loss: 0.08485651761293411
I0422 21:54:49.224513 23876 trainer.py:136] Epoch[862/1000] loss: 0.08444184623658657
I0422 21:54:54.190292 23876 trainer.py:136] Epoch[863/1000] loss: 0.085178067907691
I0422 21:54:59.180759 23876 trainer.py:136] Epoch[864/1000] loss: 0.08433618769049644
I0422 21:55:07.086461 23876 trainer.py:136] Epoch[865/1000] loss: 0.084296815097332
I0422 21:55:12.356203 23876 trainer.py:136] Epoch[866/1000] loss: 0.08408732153475285
I0422 21:55:17.318995 23876 trainer.py:136] Epoch[867/1000] loss: 0.08386381901800632
I0422 21:55:24.703826 23876 trainer.py:136] Epoch[868/1000] loss: 0.08442741259932518
I0422 21:55:30.198629 23876 trainer.py:136] Epoch[869/1000] loss: 0.08472373522818089
I0422 21:55:35.252525 23876 trainer.py:136] Epoch[870/1000] loss: 0.08421028405427933
I0422 21:55:41.675495 23876 trainer.py:136] Epoch[871/1000] loss: 0.0845642052590847
I0422 21:55:48.120918 23876 trainer.py:136] Epoch[872/1000] loss: 0.08444040827453136
I0422 21:55:53.305129 23876 trainer.py:136] Epoch[873/1000] loss: 0.0842850748449564
I0422 21:56:00.661397 23876 trainer.py:136] Epoch[874/1000] loss: 0.0853651836514473
I0422 21:56:06.389746 23876 trainer.py:136] Epoch[875/1000] loss: 0.0847664475440979
I0422 21:56:10.790202 23876 trainer.py:136] Epoch[876/1000] loss: 0.08491291850805283
I0422 21:56:18.821778 23876 trainer.py:136] Epoch[877/1000] loss: 0.08350417949259281
I0422 21:56:23.905805 23876 trainer.py:136] Epoch[878/1000] loss: 0.0837627574801445
I0422 21:56:28.952346 23876 trainer.py:136] Epoch[879/1000] loss: 0.08404110930860043
I0422 21:56:35.844749 23876 trainer.py:136] Epoch[880/1000] loss: 0.08369562774896622
I0422 21:56:41.604519 23876 trainer.py:136] Epoch[881/1000] loss: 0.08399983868002892
I0422 21:56:46.632418 23876 trainer.py:136] Epoch[882/1000] loss: 0.0841354951262474
I0422 21:56:52.453507 23876 trainer.py:136] Epoch[883/1000] loss: 0.08404364809393883
I0422 21:56:59.633968 23876 trainer.py:136] Epoch[884/1000] loss: 0.08440330438315868
I0422 21:57:04.640756 23876 trainer.py:136] Epoch[885/1000] loss: 0.08477499708533287
I0422 21:57:11.054838 23876 trainer.py:136] Epoch[886/1000] loss: 0.08363501355051994
I0422 21:57:17.383674 23876 trainer.py:136] Epoch[887/1000] loss: 0.08450492843985558
I0422 21:57:22.448416 23876 trainer.py:136] Epoch[888/1000] loss: 0.08456372283399105
I0422 21:57:29.629263 23876 trainer.py:136] Epoch[889/1000] loss: 0.08508545905351639
I0422 21:57:35.582566 23876 trainer.py:136] Epoch[890/1000] loss: 0.08449527062475681
I0422 21:57:40.875694 23876 trainer.py:136] Epoch[891/1000] loss: 0.08377288281917572
I0422 21:57:47.819760 23876 trainer.py:136] Epoch[892/1000] loss: 0.0845717117190361
I0422 21:57:53.958149 23876 trainer.py:136] Epoch[893/1000] loss: 0.08314844220876694
I0422 21:57:59.149411 23876 trainer.py:136] Epoch[894/1000] loss: 0.08527929149568081
I0422 21:58:06.937251 23876 trainer.py:136] Epoch[895/1000] loss: 0.08396049216389656
I0422 21:58:12.243336 23876 trainer.py:136] Epoch[896/1000] loss: 0.08430958725512028
I0422 21:58:16.878656 23876 trainer.py:136] Epoch[897/1000] loss: 0.08445672504603863
I0422 21:58:21.139615 23876 trainer.py:136] Epoch[898/1000] loss: 0.08414784632623196
I0422 21:58:28.341223 23876 trainer.py:136] Epoch[899/1000] loss: 0.0844511091709137
I0422 21:58:30.379857 23876 trainer.py:142] Test: [{'precision': 0.01652651083238312, 'recall': 0.07917495956931465, 'hit_ratio': 0.22576966932725198, 'ndcg': 0.05183183875063685}]
I0422 21:58:35.433854 23876 trainer.py:136] Epoch[900/1000] loss: 0.08451645262539387
I0422 21:58:41.106828 23876 trainer.py:136] Epoch[901/1000] loss: 0.08454380556941032
I0422 21:58:48.622371 23876 trainer.py:136] Epoch[902/1000] loss: 0.08404943719506264
I0422 21:58:53.653967 23876 trainer.py:136] Epoch[903/1000] loss: 0.084581408649683
I0422 21:59:01.785431 23876 trainer.py:136] Epoch[904/1000] loss: 0.08388954773545265
I0422 21:59:06.978024 23876 trainer.py:136] Epoch[905/1000] loss: 0.08490647748112679
I0422 21:59:11.984805 23876 trainer.py:136] Epoch[906/1000] loss: 0.0844870526343584
I0422 21:59:18.536200 23876 trainer.py:136] Epoch[907/1000] loss: 0.08517194725573063
I0422 21:59:24.790311 23876 trainer.py:136] Epoch[908/1000] loss: 0.08444669842720032
I0422 21:59:29.877176 23876 trainer.py:136] Epoch[909/1000] loss: 0.08394729532301426
I0422 21:59:37.850742 23876 trainer.py:136] Epoch[910/1000] loss: 0.08312205225229263
I0422 21:59:43.044214 23876 trainer.py:136] Epoch[911/1000] loss: 0.08397209271788597
I0422 21:59:48.139543 23876 trainer.py:136] Epoch[912/1000] loss: 0.08388637378811836
I0422 21:59:54.948433 23876 trainer.py:136] Epoch[913/1000] loss: 0.08468997478485107
I0422 21:59:59.181102 23876 trainer.py:136] Epoch[914/1000] loss: 0.08404318802058697
I0422 22:00:03.398901 23876 trainer.py:136] Epoch[915/1000] loss: 0.08393830247223377
I0422 22:00:07.370398 23876 trainer.py:136] Epoch[916/1000] loss: 0.08440683782100677
I0422 22:00:11.341928 23876 trainer.py:136] Epoch[917/1000] loss: 0.08392652496695518
I0422 22:00:15.514255 23876 trainer.py:136] Epoch[918/1000] loss: 0.08395862951874733
I0422 22:00:19.684514 23876 trainer.py:136] Epoch[919/1000] loss: 0.083180021494627
I0422 22:00:23.738625 23876 trainer.py:136] Epoch[920/1000] loss: 0.0834999680519104
I0422 22:00:30.448878 23876 trainer.py:136] Epoch[921/1000] loss: 0.08328257501125336
I0422 22:00:34.615279 23876 trainer.py:136] Epoch[922/1000] loss: 0.08440041914582253
I0422 22:00:38.730329 23876 trainer.py:136] Epoch[923/1000] loss: 0.08439402282238007
I0422 22:00:42.998354 23876 trainer.py:136] Epoch[924/1000] loss: 0.08268564380705357
I0422 22:00:47.020378 23876 trainer.py:136] Epoch[925/1000] loss: 0.08366792276501656
I0422 22:00:51.166558 23876 trainer.py:136] Epoch[926/1000] loss: 0.08367391489446163
I0422 22:00:55.415511 23876 trainer.py:136] Epoch[927/1000] loss: 0.0840892381966114
I0422 22:01:02.502862 23876 trainer.py:136] Epoch[928/1000] loss: 0.08406510762870312
I0422 22:01:06.609850 23876 trainer.py:136] Epoch[929/1000] loss: 0.08321933634579182
I0422 22:01:10.782450 23876 trainer.py:136] Epoch[930/1000] loss: 0.08275434002280235
I0422 22:01:15.396689 23876 trainer.py:136] Epoch[931/1000] loss: 0.08362623490393162
I0422 22:01:22.841830 23876 trainer.py:136] Epoch[932/1000] loss: 0.08277838118374348
I0422 22:01:28.511867 23876 trainer.py:136] Epoch[933/1000] loss: 0.08482246659696102
I0422 22:01:33.387398 23876 trainer.py:136] Epoch[934/1000] loss: 0.08389023318886757
I0422 22:01:40.508371 23876 trainer.py:136] Epoch[935/1000] loss: 0.08298646286129951
I0422 22:01:47.026764 23876 trainer.py:136] Epoch[936/1000] loss: 0.08348913304507732
I0422 22:01:52.299371 23876 trainer.py:136] Epoch[937/1000] loss: 0.08321485482156277
I0422 22:02:00.424522 23876 trainer.py:136] Epoch[938/1000] loss: 0.08383327536284924
I0422 22:02:05.269471 23876 trainer.py:136] Epoch[939/1000] loss: 0.08407102152705193
I0422 22:02:10.200413 23876 trainer.py:136] Epoch[940/1000] loss: 0.08356394246220589
I0422 22:02:18.038617 23876 trainer.py:136] Epoch[941/1000] loss: 0.0836059171706438
I0422 22:02:23.038885 23876 trainer.py:136] Epoch[942/1000] loss: 0.08294758945703506
I0422 22:02:27.597304 23876 trainer.py:136] Epoch[943/1000] loss: 0.0841584112495184
I0422 22:02:34.158909 23876 trainer.py:136] Epoch[944/1000] loss: 0.08414210937917233
I0422 22:02:38.465761 23876 trainer.py:136] Epoch[945/1000] loss: 0.08412195555865765
I0422 22:02:42.630761 23876 trainer.py:136] Epoch[946/1000] loss: 0.08425350114703178
I0422 22:02:46.843137 23876 trainer.py:136] Epoch[947/1000] loss: 0.08304866217076778
I0422 22:02:51.001033 23876 trainer.py:136] Epoch[948/1000] loss: 0.08282415568828583
I0422 22:02:55.018979 23876 trainer.py:136] Epoch[949/1000] loss: 0.08297463692724705
I0422 22:02:56.530348 23876 trainer.py:142] Test: [{'precision': 0.016462371721778776, 'recall': 0.07934641331871117, 'hit_ratio': 0.22591220068415052, 'ndcg': 0.052065705306926655}]
I0422 22:03:00.778155 23876 trainer.py:136] Epoch[950/1000] loss: 0.08348236791789532
I0422 22:03:07.641386 23876 trainer.py:136] Epoch[951/1000] loss: 0.08401473611593246
I0422 22:03:12.080815 23876 trainer.py:136] Epoch[952/1000] loss: 0.08372152782976627
I0422 22:03:16.214486 23876 trainer.py:136] Epoch[953/1000] loss: 0.08411148563027382
I0422 22:03:20.324480 23876 trainer.py:136] Epoch[954/1000] loss: 0.08378108218312263
I0422 22:03:24.539931 23876 trainer.py:136] Epoch[955/1000] loss: 0.08343879878520966
I0422 22:03:28.837347 23876 trainer.py:136] Epoch[956/1000] loss: 0.08337055891752243
I0422 22:03:35.464365 23876 trainer.py:136] Epoch[957/1000] loss: 0.08287467248737812
I0422 22:03:39.848965 23876 trainer.py:136] Epoch[958/1000] loss: 0.0839313380420208
I0422 22:03:44.042255 23876 trainer.py:136] Epoch[959/1000] loss: 0.08385949954390526
I0422 22:03:48.296642 23876 trainer.py:136] Epoch[960/1000] loss: 0.08402554132044315
I0422 22:03:52.481955 23876 trainer.py:136] Epoch[961/1000] loss: 0.08279259875416756
I0422 22:03:56.659702 23876 trainer.py:136] Epoch[962/1000] loss: 0.08414503931999207
I0422 22:04:00.782708 23876 trainer.py:136] Epoch[963/1000] loss: 0.08304691314697266
I0422 22:04:07.629980 23876 trainer.py:136] Epoch[964/1000] loss: 0.08301249146461487
I0422 22:04:11.759085 23876 trainer.py:136] Epoch[965/1000] loss: 0.0833204910159111
I0422 22:04:15.924808 23876 trainer.py:136] Epoch[966/1000] loss: 0.08374711126089096
I0422 22:04:20.025457 23876 trainer.py:136] Epoch[967/1000] loss: 0.08356994763016701
I0422 22:04:24.230228 23876 trainer.py:136] Epoch[968/1000] loss: 0.08418277278542519
I0422 22:04:28.418224 23876 trainer.py:136] Epoch[969/1000] loss: 0.08339984156191349
I0422 22:04:32.608009 23876 trainer.py:136] Epoch[970/1000] loss: 0.08323541842401028
I0422 22:04:36.695263 23876 trainer.py:136] Epoch[971/1000] loss: 0.08303113467991352
I0422 22:04:43.558557 23876 trainer.py:136] Epoch[972/1000] loss: 0.08364068157970905
I0422 22:04:47.793649 23876 trainer.py:136] Epoch[973/1000] loss: 0.08410696499049664
I0422 22:04:51.888224 23876 trainer.py:136] Epoch[974/1000] loss: 0.08348680846393108
I0422 22:04:55.892111 23876 trainer.py:136] Epoch[975/1000] loss: 0.08279554918408394
I0422 22:04:59.915925 23876 trainer.py:136] Epoch[976/1000] loss: 0.08399303257465363
I0422 22:05:03.971411 23876 trainer.py:136] Epoch[977/1000] loss: 0.08333594165742397
I0422 22:05:08.126882 23876 trainer.py:136] Epoch[978/1000] loss: 0.08302639052271843
I0422 22:05:12.070369 23876 trainer.py:136] Epoch[979/1000] loss: 0.08374608494341373
I0422 22:05:16.134613 23876 trainer.py:136] Epoch[980/1000] loss: 0.08347315900027752
I0422 22:05:20.071109 23876 trainer.py:136] Epoch[981/1000] loss: 0.08258266188204288
I0422 22:05:26.470498 23876 trainer.py:136] Epoch[982/1000] loss: 0.08408747240900993
I0422 22:05:30.524248 23876 trainer.py:136] Epoch[983/1000] loss: 0.08379965275526047
I0422 22:05:34.631881 23876 trainer.py:136] Epoch[984/1000] loss: 0.0837616715580225
I0422 22:05:38.727451 23876 trainer.py:136] Epoch[985/1000] loss: 0.08372951112687588
I0422 22:05:42.744365 23876 trainer.py:136] Epoch[986/1000] loss: 0.0845730360597372
I0422 22:05:46.863869 23876 trainer.py:136] Epoch[987/1000] loss: 0.08245772495865822
I0422 22:05:50.864981 23876 trainer.py:136] Epoch[988/1000] loss: 0.08295403234660625
I0422 22:05:54.955836 23876 trainer.py:136] Epoch[989/1000] loss: 0.08289330266416073
I0422 22:05:59.051000 23876 trainer.py:136] Epoch[990/1000] loss: 0.08410414308309555
I0422 22:06:03.069877 23876 trainer.py:136] Epoch[991/1000] loss: 0.08287972770631313
I0422 22:06:07.168023 23876 trainer.py:136] Epoch[992/1000] loss: 0.08375084958970547
I0422 22:06:11.294655 23876 trainer.py:136] Epoch[993/1000] loss: 0.08393933810293674
I0422 22:06:17.394845 23876 trainer.py:136] Epoch[994/1000] loss: 0.08405347727239132
I0422 22:06:21.925139 23876 trainer.py:136] Epoch[995/1000] loss: 0.0831048209220171
I0422 22:06:25.971886 23876 trainer.py:136] Epoch[996/1000] loss: 0.08381585776805878
I0422 22:06:30.031565 23876 trainer.py:136] Epoch[997/1000] loss: 0.0836116261780262
I0422 22:06:34.242334 23876 trainer.py:136] Epoch[998/1000] loss: 0.08387441188097
I0422 22:06:38.553253 23876 trainer.py:136] Epoch[999/1000] loss: 0.08323846384882927
I0422 22:06:40.018924 23876 trainer.py:142] Test: [{'precision': 0.016626282782212082, 'recall': 0.07987894580835059, 'hit_ratio': 0.2274800456100342, 'ndcg': 0.05246249860383685}]
