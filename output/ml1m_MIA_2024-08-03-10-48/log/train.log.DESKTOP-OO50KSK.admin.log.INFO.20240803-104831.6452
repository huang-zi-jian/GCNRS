I0803 10:48:40.987344 14408 trainer.py:119] Test: [{'precision': 0.03162771285475791, 'recall': 0.05963847834916299, 'hit_ratio': 0.3060100166944908, 'ndcg': 0.057021622867879394}]
I0803 10:48:57.907233 14408 trainer.py:139] Epoch[0/1000] loss: 0.6038172446191311
I0803 10:49:15.007467 14408 trainer.py:139] Epoch[1/1000] loss: 0.4293964847922325
I0803 10:49:31.996417 14408 trainer.py:139] Epoch[2/1000] loss: 0.42149185091257096
I0803 10:49:48.894062 14408 trainer.py:139] Epoch[3/1000] loss: 0.4158040933310986
I0803 10:50:05.950176 14408 trainer.py:139] Epoch[4/1000] loss: 0.4059392772614956
I0803 10:50:23.400511 14408 trainer.py:139] Epoch[5/1000] loss: 0.39891104102134706
I0803 10:50:39.409363 14408 trainer.py:139] Epoch[6/1000] loss: 0.38948291540145874
I0803 10:50:55.849773 14408 trainer.py:139] Epoch[7/1000] loss: 0.38644315004348756
I0803 10:51:12.545133 14408 trainer.py:139] Epoch[8/1000] loss: 0.3805892191827297
I0803 10:51:28.967420 14408 trainer.py:139] Epoch[9/1000] loss: 0.37714980021119116
I0803 10:51:46.334378 14408 trainer.py:139] Epoch[10/1000] loss: 0.37143701016902925
I0803 10:52:03.011209 14408 trainer.py:139] Epoch[11/1000] loss: 0.3712406598031521
I0803 10:52:19.763171 14408 trainer.py:139] Epoch[12/1000] loss: 0.3687251165509224
I0803 10:52:36.893855 14408 trainer.py:139] Epoch[13/1000] loss: 0.3664294950664043
I0803 10:52:53.778678 14408 trainer.py:139] Epoch[14/1000] loss: 0.36376709267497065
I0803 10:53:10.397427 14408 trainer.py:139] Epoch[15/1000] loss: 0.36188419088721274
I0803 10:53:27.297084 14408 trainer.py:139] Epoch[16/1000] loss: 0.3565907463431358
I0803 10:53:45.019331 14408 trainer.py:139] Epoch[17/1000] loss: 0.35702197775244715
I0803 10:54:01.725118 14408 trainer.py:139] Epoch[18/1000] loss: 0.35224817618727683
I0803 10:54:18.446621 14408 trainer.py:139] Epoch[19/1000] loss: 0.3511446364223957
I0803 10:54:35.494006 14408 trainer.py:139] Epoch[20/1000] loss: 0.34904247224330903
I0803 10:54:53.023707 14408 trainer.py:139] Epoch[21/1000] loss: 0.346414428204298
I0803 10:55:10.075303 14408 trainer.py:139] Epoch[22/1000] loss: 0.34344569966197014
I0803 10:55:27.190471 14408 trainer.py:139] Epoch[23/1000] loss: 0.34145525470376015
I0803 10:55:44.288333 14408 trainer.py:139] Epoch[24/1000] loss: 0.3368177764117718
I0803 10:56:01.191284 14408 trainer.py:139] Epoch[25/1000] loss: 0.3372530683875084
I0803 10:56:18.170012 14408 trainer.py:139] Epoch[26/1000] loss: 0.3330835819244385
I0803 10:56:35.296180 14408 trainer.py:139] Epoch[27/1000] loss: 0.33393187150359155
I0803 10:56:52.258596 14408 trainer.py:139] Epoch[28/1000] loss: 0.32838516086339953
I0803 10:57:09.208874 14408 trainer.py:139] Epoch[29/1000] loss: 0.32846970558166505
I0803 10:57:25.753971 14408 trainer.py:139] Epoch[30/1000] loss: 0.32521838769316674
I0803 10:57:42.560398 14408 trainer.py:139] Epoch[31/1000] loss: 0.3242411926388741
I0803 10:57:59.369691 14408 trainer.py:139] Epoch[32/1000] loss: 0.322353595495224
I0803 10:58:16.230956 14408 trainer.py:139] Epoch[33/1000] loss: 0.32049870640039446
I0803 10:58:33.096537 14408 trainer.py:139] Epoch[34/1000] loss: 0.3181023418903351
I0803 10:58:50.074265 14408 trainer.py:139] Epoch[35/1000] loss: 0.3171034768223763
I0803 10:59:06.809473 14408 trainer.py:139] Epoch[36/1000] loss: 0.3148784853518009
I0803 10:59:23.841399 14408 trainer.py:139] Epoch[37/1000] loss: 0.31388612911105157
I0803 10:59:40.815840 14408 trainer.py:139] Epoch[38/1000] loss: 0.3109967790544033
I0803 10:59:57.650505 14408 trainer.py:139] Epoch[39/1000] loss: 0.30793889835476873
I0803 11:00:14.596166 14408 trainer.py:139] Epoch[40/1000] loss: 0.30759131386876104
I0803 11:00:31.489909 14408 trainer.py:139] Epoch[41/1000] loss: 0.306517643481493
I0803 11:00:47.947881 14408 trainer.py:139] Epoch[42/1000] loss: 0.3043687425553799
I0803 11:01:04.617925 14408 trainer.py:139] Epoch[43/1000] loss: 0.3026128806173801
I0803 11:01:21.295789 14408 trainer.py:139] Epoch[44/1000] loss: 0.30104960426688193
I0803 11:01:37.871788 14408 trainer.py:139] Epoch[45/1000] loss: 0.2995790049433708
I0803 11:01:54.687652 14408 trainer.py:139] Epoch[46/1000] loss: 0.2987572945654392
I0803 11:02:11.442149 14408 trainer.py:139] Epoch[47/1000] loss: 0.2964972466230392
I0803 11:02:28.954543 14408 trainer.py:139] Epoch[48/1000] loss: 0.29536917358636855
I0803 11:02:45.960949 14408 trainer.py:139] Epoch[49/1000] loss: 0.29448414742946627
I0803 11:02:46.518084 14408 trainer.py:145] Test: [{'precision': 0.1675375626043406, 'recall': 0.22998954835038812, 'hit_ratio': 0.8701168614357262, 'ndcg': 0.2583226322365753}]
I0803 11:03:03.591597 14408 trainer.py:139] Epoch[50/1000] loss: 0.29303387776017187
I0803 11:03:20.651848 14408 trainer.py:139] Epoch[51/1000] loss: 0.29163718298077584
I0803 11:03:37.683167 14408 trainer.py:139] Epoch[52/1000] loss: 0.2898064561188221
I0803 11:03:54.739677 14408 trainer.py:139] Epoch[53/1000] loss: 0.2882282882928848
I0803 11:04:11.588117 14408 trainer.py:139] Epoch[54/1000] loss: 0.28712375909090043
I0803 11:04:28.527378 14408 trainer.py:139] Epoch[55/1000] loss: 0.2861143559217453
I0803 11:04:45.397925 14408 trainer.py:139] Epoch[56/1000] loss: 0.285488685965538
I0803 11:05:02.431158 14408 trainer.py:139] Epoch[57/1000] loss: 0.2824337683618069
I0803 11:05:19.293361 14408 trainer.py:139] Epoch[58/1000] loss: 0.28163463100790975
I0803 11:05:36.297422 14408 trainer.py:139] Epoch[59/1000] loss: 0.2802225075662136
I0803 11:05:53.115730 14408 trainer.py:139] Epoch[60/1000] loss: 0.2785905979573727
I0803 11:06:09.870193 14408 trainer.py:139] Epoch[61/1000] loss: 0.2771285861730576
I0803 11:06:26.715443 14408 trainer.py:139] Epoch[62/1000] loss: 0.27742263302206993
I0803 11:06:43.258220 14408 trainer.py:139] Epoch[63/1000] loss: 0.27812066227197646
I0803 11:06:59.898119 14408 trainer.py:139] Epoch[64/1000] loss: 0.274999787658453
I0803 11:07:16.533810 14408 trainer.py:139] Epoch[65/1000] loss: 0.2750100739300251
I0803 11:07:33.120671 14408 trainer.py:139] Epoch[66/1000] loss: 0.27305454313755034
I0803 11:07:49.751538 14408 trainer.py:139] Epoch[67/1000] loss: 0.2707591153681278
I0803 11:08:06.470179 14408 trainer.py:139] Epoch[68/1000] loss: 0.2707015059888363
I0803 11:08:23.347170 14408 trainer.py:139] Epoch[69/1000] loss: 0.2697398580610752
I0803 11:08:40.374346 14408 trainer.py:139] Epoch[70/1000] loss: 0.2682157471776009
I0803 11:08:57.058297 14408 trainer.py:139] Epoch[71/1000] loss: 0.2695947676897049
I0803 11:09:13.783758 14408 trainer.py:139] Epoch[72/1000] loss: 0.267231335490942
I0803 11:09:30.928179 14408 trainer.py:139] Epoch[73/1000] loss: 0.26647489592432977
I0803 11:09:47.911086 14408 trainer.py:139] Epoch[74/1000] loss: 0.265018805116415
I0803 11:10:04.580667 14408 trainer.py:139] Epoch[75/1000] loss: 0.264585205167532
I0803 11:10:21.417445 14408 trainer.py:139] Epoch[76/1000] loss: 0.26351851373910906
I0803 11:10:38.014005 14408 trainer.py:139] Epoch[77/1000] loss: 0.26297339126467706
I0803 11:10:54.787028 14408 trainer.py:139] Epoch[78/1000] loss: 0.2614648755639791
I0803 11:11:11.724065 14408 trainer.py:139] Epoch[79/1000] loss: 0.2622939184308052
I0803 11:11:28.865652 14408 trainer.py:139] Epoch[80/1000] loss: 0.261191226914525
I0803 11:11:45.723820 14408 trainer.py:139] Epoch[81/1000] loss: 0.25999814718961717
I0803 11:12:02.629816 14408 trainer.py:139] Epoch[82/1000] loss: 0.2593369290232658
I0803 11:12:19.426042 14408 trainer.py:139] Epoch[83/1000] loss: 0.2594871211796999
I0803 11:12:36.265422 14408 trainer.py:139] Epoch[84/1000] loss: 0.25881606303155424
I0803 11:12:52.938694 14408 trainer.py:139] Epoch[85/1000] loss: 0.25583686530590055
I0803 11:13:09.356148 14408 trainer.py:139] Epoch[86/1000] loss: 0.2562708664685488
I0803 11:13:26.074140 14408 trainer.py:139] Epoch[87/1000] loss: 0.25653074979782103
I0803 11:13:42.839344 14408 trainer.py:139] Epoch[88/1000] loss: 0.25485731549561025
I0803 11:13:59.502585 14408 trainer.py:139] Epoch[89/1000] loss: 0.25592941865324975
I0803 11:14:16.567267 14408 trainer.py:139] Epoch[90/1000] loss: 0.2528671305626631
I0803 11:14:33.565293 14408 trainer.py:139] Epoch[91/1000] loss: 0.25350073017179964
I0803 11:14:50.243784 14408 trainer.py:139] Epoch[92/1000] loss: 0.2526352483779192
I0803 11:15:06.975730 14408 trainer.py:139] Epoch[93/1000] loss: 0.252010690048337
I0803 11:15:23.776625 14408 trainer.py:139] Epoch[94/1000] loss: 0.2509561639279127
I0803 11:15:40.519379 14408 trainer.py:139] Epoch[95/1000] loss: 0.24956800937652587
I0803 11:15:57.271851 14408 trainer.py:139] Epoch[96/1000] loss: 0.24927834570407867
I0803 11:16:14.027455 14408 trainer.py:139] Epoch[97/1000] loss: 0.24954184219241143
I0803 11:16:31.016706 14408 trainer.py:139] Epoch[98/1000] loss: 0.24860966838896276
I0803 11:16:47.836645 14408 trainer.py:139] Epoch[99/1000] loss: 0.24850077778100968
I0803 11:16:48.436784 14408 trainer.py:145] Test: [{'precision': 0.18282136894824708, 'recall': 0.25543982869385273, 'hit_ratio': 0.8923205342237062, 'ndcg': 0.2845174900084753}]
I0803 11:17:04.992841 14408 trainer.py:139] Epoch[100/1000] loss: 0.248839046433568
I0803 11:17:21.847087 14408 trainer.py:139] Epoch[101/1000] loss: 0.248042668774724
I0803 11:17:38.607672 14408 trainer.py:139] Epoch[102/1000] loss: 0.24719019904732703
I0803 11:17:55.211161 14408 trainer.py:139] Epoch[103/1000] loss: 0.24682458378374578
I0803 11:18:11.928115 14408 trainer.py:139] Epoch[104/1000] loss: 0.24521286971867085
I0803 11:18:28.470697 14408 trainer.py:139] Epoch[105/1000] loss: 0.24610792621970176
I0803 11:18:45.057424 14408 trainer.py:139] Epoch[106/1000] loss: 0.24401644207537174
I0803 11:19:01.725497 14408 trainer.py:139] Epoch[107/1000] loss: 0.24500957168638707
I0803 11:19:19.152498 14408 trainer.py:139] Epoch[108/1000] loss: 0.24358953684568405
I0803 11:19:36.762614 14408 trainer.py:139] Epoch[109/1000] loss: 0.24305489286780357
I0803 11:19:54.091544 14408 trainer.py:139] Epoch[110/1000] loss: 0.24269893020391464
I0803 11:20:10.820859 14408 trainer.py:139] Epoch[111/1000] loss: 0.24323677085340023
I0803 11:20:27.660521 14408 trainer.py:139] Epoch[112/1000] loss: 0.24317252784967422
I0803 11:20:44.402220 14408 trainer.py:139] Epoch[113/1000] loss: 0.24271700233221055
I0803 11:21:01.188527 14408 trainer.py:139] Epoch[114/1000] loss: 0.2406428623944521
I0803 11:21:18.053185 14408 trainer.py:139] Epoch[115/1000] loss: 0.24059537351131438
I0803 11:21:34.831525 14408 trainer.py:139] Epoch[116/1000] loss: 0.24215631783008576
I0803 11:21:51.725568 14408 trainer.py:139] Epoch[117/1000] loss: 0.2384763892740011
I0803 11:22:08.507721 14408 trainer.py:139] Epoch[118/1000] loss: 0.24107822254300118
I0803 11:22:25.173173 14408 trainer.py:139] Epoch[119/1000] loss: 0.23845618180930614
I0803 11:22:42.202520 14408 trainer.py:139] Epoch[120/1000] loss: 0.2402560908347368
I0803 11:22:58.776485 14408 trainer.py:139] Epoch[121/1000] loss: 0.2386293489485979
I0803 11:23:15.665108 14408 trainer.py:139] Epoch[122/1000] loss: 0.23819204047322273
I0803 11:23:32.826607 14408 trainer.py:139] Epoch[123/1000] loss: 0.23748445995151996
I0803 11:23:49.491251 14408 trainer.py:139] Epoch[124/1000] loss: 0.23845026828348637
I0803 11:24:06.466979 14408 trainer.py:139] Epoch[125/1000] loss: 0.2377064134925604
I0803 11:24:23.044252 14408 trainer.py:139] Epoch[126/1000] loss: 0.23682650178670883
I0803 11:24:39.880310 14408 trainer.py:139] Epoch[127/1000] loss: 0.2381460051983595
I0803 11:24:56.487529 14408 trainer.py:139] Epoch[128/1000] loss: 0.23771640099585056
I0803 11:25:13.288915 14408 trainer.py:139] Epoch[129/1000] loss: 0.23598150797188283
I0803 11:25:29.897789 14408 trainer.py:139] Epoch[130/1000] loss: 0.23700805380940437
I0803 11:25:46.564606 14408 trainer.py:139] Epoch[131/1000] loss: 0.23561188913881778
I0803 11:26:03.353064 14408 trainer.py:139] Epoch[132/1000] loss: 0.23438792265951633
I0803 11:26:20.548943 14408 trainer.py:139] Epoch[133/1000] loss: 0.2360391542315483
I0803 11:26:37.564053 14408 trainer.py:139] Epoch[134/1000] loss: 0.23505650758743285
I0803 11:26:54.809565 14408 trainer.py:139] Epoch[135/1000] loss: 0.2336501095443964
I0803 11:27:11.699071 14408 trainer.py:139] Epoch[136/1000] loss: 0.23417150378227233
I0803 11:27:28.622618 14408 trainer.py:139] Epoch[137/1000] loss: 0.23450336568057537
I0803 11:27:45.208224 14408 trainer.py:139] Epoch[138/1000] loss: 0.23382120728492736
I0803 11:28:02.263761 14408 trainer.py:139] Epoch[139/1000] loss: 0.23433480374515056
I0803 11:28:19.346828 14408 trainer.py:139] Epoch[140/1000] loss: 0.23209974244236947
I0803 11:28:36.131502 14408 trainer.py:139] Epoch[141/1000] loss: 0.23312256522476674
I0803 11:28:52.796869 14408 trainer.py:139] Epoch[142/1000] loss: 0.2325571935623884
I0803 11:29:09.104990 14408 trainer.py:139] Epoch[143/1000] loss: 0.23253669887781142
I0803 11:29:26.036788 14408 trainer.py:139] Epoch[144/1000] loss: 0.23226084411144257
I0803 11:29:42.843828 14408 trainer.py:139] Epoch[145/1000] loss: 0.23107030913233756
I0803 11:30:00.009600 14408 trainer.py:139] Epoch[146/1000] loss: 0.23004482537508011
I0803 11:30:16.742470 14408 trainer.py:139] Epoch[147/1000] loss: 0.23073909990489483
I0803 11:30:33.472700 14408 trainer.py:139] Epoch[148/1000] loss: 0.23132893964648246
I0803 11:30:50.158404 14408 trainer.py:139] Epoch[149/1000] loss: 0.23066460266709327
I0803 11:30:50.789836 14408 trainer.py:145] Test: [{'precision': 0.18903171953255432, 'recall': 0.2652042457530633, 'hit_ratio': 0.9003338898163606, 'ndcg': 0.29504182086470193}]
I0803 11:31:07.476689 14408 trainer.py:139] Epoch[150/1000] loss: 0.2303782645612955
I0803 11:31:24.102752 14408 trainer.py:139] Epoch[151/1000] loss: 0.23072860911488532
I0803 11:31:40.730334 14408 trainer.py:139] Epoch[152/1000] loss: 0.22945489212870598
I0803 11:31:57.526723 14408 trainer.py:139] Epoch[153/1000] loss: 0.2301650047302246
I0803 11:32:14.281719 14408 trainer.py:139] Epoch[154/1000] loss: 0.23028149902820588
I0803 11:32:31.450223 14408 trainer.py:139] Epoch[155/1000] loss: 0.22977391593158245
I0803 11:32:48.173132 14408 trainer.py:139] Epoch[156/1000] loss: 0.2290427979081869
I0803 11:33:04.898716 14408 trainer.py:139] Epoch[157/1000] loss: 0.2286683939397335
I0803 11:33:21.742929 14408 trainer.py:139] Epoch[158/1000] loss: 0.22850795947015284
I0803 11:33:38.610109 14408 trainer.py:139] Epoch[159/1000] loss: 0.22846762724220754
I0803 11:33:55.416497 14408 trainer.py:139] Epoch[160/1000] loss: 0.22774581909179686
I0803 11:34:12.040009 14408 trainer.py:139] Epoch[161/1000] loss: 0.228017595410347
I0803 11:34:28.943540 14408 trainer.py:139] Epoch[162/1000] loss: 0.22763727642595769
I0803 11:34:45.705229 14408 trainer.py:139] Epoch[163/1000] loss: 0.2273037377744913
I0803 11:35:02.495402 14408 trainer.py:139] Epoch[164/1000] loss: 0.22793451249599456
I0803 11:35:19.085719 14408 trainer.py:139] Epoch[165/1000] loss: 0.22748101837933063
I0803 11:35:35.997588 14408 trainer.py:139] Epoch[166/1000] loss: 0.2273656725883484
I0803 11:35:52.654056 14408 trainer.py:139] Epoch[167/1000] loss: 0.22782053835690022
I0803 11:36:09.600432 14408 trainer.py:139] Epoch[168/1000] loss: 0.22684590928256512
I0803 11:36:26.383839 14408 trainer.py:139] Epoch[169/1000] loss: 0.22689432129263878
I0803 11:36:43.218987 14408 trainer.py:139] Epoch[170/1000] loss: 0.22686517536640166
I0803 11:37:00.027299 14408 trainer.py:139] Epoch[171/1000] loss: 0.22658498212695122
I0803 11:37:16.683970 14408 trainer.py:139] Epoch[172/1000] loss: 0.22628721222281456
I0803 11:37:33.225895 14408 trainer.py:139] Epoch[173/1000] loss: 0.22656576670706272
I0803 11:37:50.125036 14408 trainer.py:139] Epoch[174/1000] loss: 0.2253664817661047
I0803 11:38:06.543098 14408 trainer.py:139] Epoch[175/1000] loss: 0.22611731328070164
I0803 11:38:23.525610 14408 trainer.py:139] Epoch[176/1000] loss: 0.22597622200846673
I0803 11:38:40.323804 14408 trainer.py:139] Epoch[177/1000] loss: 0.2248914334923029
I0803 11:38:57.294372 14408 trainer.py:139] Epoch[178/1000] loss: 0.22648396901786327
I0803 11:39:13.987637 14408 trainer.py:139] Epoch[179/1000] loss: 0.22565863467752934
I0803 11:39:30.975464 14408 trainer.py:139] Epoch[180/1000] loss: 0.2254436008632183
I0803 11:39:47.471920 14408 trainer.py:139] Epoch[181/1000] loss: 0.22368453145027162
I0803 11:40:04.168549 14408 trainer.py:139] Epoch[182/1000] loss: 0.2245323672890663
I0803 11:40:21.044457 14408 trainer.py:139] Epoch[183/1000] loss: 0.22502412721514703
I0803 11:40:37.814760 14408 trainer.py:139] Epoch[184/1000] loss: 0.22388241887092591
I0803 11:40:54.696108 14408 trainer.py:139] Epoch[185/1000] loss: 0.22431387566030025
I0803 11:41:11.232154 14408 trainer.py:139] Epoch[186/1000] loss: 0.22413139194250106
I0803 11:41:28.429186 14408 trainer.py:139] Epoch[187/1000] loss: 0.2225709345191717
I0803 11:41:45.712652 14408 trainer.py:139] Epoch[188/1000] loss: 0.22352173291146754
I0803 11:42:02.729827 14408 trainer.py:139] Epoch[189/1000] loss: 0.22274063862860202
I0803 11:42:19.672255 14408 trainer.py:139] Epoch[190/1000] loss: 0.22279367856681348
I0803 11:42:36.974695 14408 trainer.py:139] Epoch[191/1000] loss: 0.22282640300691128
I0803 11:42:53.731693 14408 trainer.py:139] Epoch[192/1000] loss: 0.2230197809636593
I0803 11:43:10.330651 14408 trainer.py:139] Epoch[193/1000] loss: 0.22251740470528603
I0803 11:43:26.941291 14408 trainer.py:139] Epoch[194/1000] loss: 0.2218653965741396
I0803 11:43:43.547206 14408 trainer.py:139] Epoch[195/1000] loss: 0.22207785956561565
I0803 11:44:00.234902 14408 trainer.py:139] Epoch[196/1000] loss: 0.2226236190646887
I0803 11:44:16.669727 14408 trainer.py:139] Epoch[197/1000] loss: 0.22218735963106157
I0803 11:44:33.192348 14408 trainer.py:139] Epoch[198/1000] loss: 0.22244387157261372
I0803 11:44:49.837206 14408 trainer.py:139] Epoch[199/1000] loss: 0.22111719697713852
I0803 11:44:50.414275 14408 trainer.py:145] Test: [{'precision': 0.1921285475792988, 'recall': 0.2701022502547687, 'hit_ratio': 0.9043405676126878, 'ndcg': 0.3002470471930027}]
I0803 11:45:07.061435 14408 trainer.py:139] Epoch[200/1000] loss: 0.2219222817569971
I0803 11:45:24.013010 14408 trainer.py:139] Epoch[201/1000] loss: 0.2213077113032341
I0803 11:45:40.813897 14408 trainer.py:139] Epoch[202/1000] loss: 0.22155807316303253
I0803 11:45:57.517008 14408 trainer.py:139] Epoch[203/1000] loss: 0.22184764482080938
I0803 11:46:14.302096 14408 trainer.py:139] Epoch[204/1000] loss: 0.2213641706854105
I0803 11:46:30.890827 14408 trainer.py:139] Epoch[205/1000] loss: 0.22193606123328208
I0803 11:46:47.911182 14408 trainer.py:139] Epoch[206/1000] loss: 0.2199637107551098
I0803 11:47:04.581842 14408 trainer.py:139] Epoch[207/1000] loss: 0.22196706235408784
I0803 11:47:21.185191 14408 trainer.py:139] Epoch[208/1000] loss: 0.21997955664992333
I0803 11:47:37.579214 14408 trainer.py:139] Epoch[209/1000] loss: 0.22104522548615932
I0803 11:47:54.304961 14408 trainer.py:139] Epoch[210/1000] loss: 0.22037468813359737
I0803 11:48:10.898482 14408 trainer.py:139] Epoch[211/1000] loss: 0.22138830907642842
I0803 11:48:27.355186 14408 trainer.py:139] Epoch[212/1000] loss: 0.2190024744719267
I0803 11:48:43.608403 14408 trainer.py:139] Epoch[213/1000] loss: 0.21912682056427002
I0803 11:49:00.367600 14408 trainer.py:139] Epoch[214/1000] loss: 0.22060478180646897
I0803 11:49:16.622323 14408 trainer.py:139] Epoch[215/1000] loss: 0.21982803344726562
I0803 11:49:32.944896 14408 trainer.py:139] Epoch[216/1000] loss: 0.22039599232375623
I0803 11:49:49.498101 14408 trainer.py:139] Epoch[217/1000] loss: 0.21943952105939388
I0803 11:50:06.084520 14408 trainer.py:139] Epoch[218/1000] loss: 0.22068825773894787
I0803 11:50:22.874930 14408 trainer.py:139] Epoch[219/1000] loss: 0.2186942517757416
I0803 11:50:39.352866 14408 trainer.py:139] Epoch[220/1000] loss: 0.21823536939918994
I0803 11:50:55.884101 14408 trainer.py:139] Epoch[221/1000] loss: 0.21988688595592976
I0803 11:51:12.704464 14408 trainer.py:139] Epoch[222/1000] loss: 0.21905641667544842
I0803 11:51:29.281884 14408 trainer.py:139] Epoch[223/1000] loss: 0.21967429034411906
I0803 11:51:46.127704 14408 trainer.py:139] Epoch[224/1000] loss: 0.21977448388934134
I0803 11:52:02.627196 14408 trainer.py:139] Epoch[225/1000] loss: 0.2189404584467411
I0803 11:52:19.279992 14408 trainer.py:139] Epoch[226/1000] loss: 0.2189745556563139
I0803 11:52:36.002106 14408 trainer.py:139] Epoch[227/1000] loss: 0.21733127869665622
I0803 11:52:52.187769 14408 trainer.py:139] Epoch[228/1000] loss: 0.21844523958861828
I0803 11:53:08.681593 14408 trainer.py:139] Epoch[229/1000] loss: 0.21763697899878026
I0803 11:53:25.260054 14408 trainer.py:139] Epoch[230/1000] loss: 0.21761963814496993
I0803 11:53:41.641383 14408 trainer.py:139] Epoch[231/1000] loss: 0.21892909668385982
I0803 11:53:57.909219 14408 trainer.py:139] Epoch[232/1000] loss: 0.21826400198042392
I0803 11:54:14.434346 14408 trainer.py:139] Epoch[233/1000] loss: 0.21785870678722857
I0803 11:54:31.104928 14408 trainer.py:139] Epoch[234/1000] loss: 0.2178278721868992
I0803 11:54:47.535691 14408 trainer.py:139] Epoch[235/1000] loss: 0.2181162007153034
I0803 11:55:04.607980 14408 trainer.py:139] Epoch[236/1000] loss: 0.21775298453867437
I0803 11:55:21.201293 14408 trainer.py:139] Epoch[237/1000] loss: 0.2174799893051386
I0803 11:55:37.771451 14408 trainer.py:139] Epoch[238/1000] loss: 0.2172684095799923
I0803 11:55:54.441231 14408 trainer.py:139] Epoch[239/1000] loss: 0.21685034930706024
I0803 11:56:10.934142 14408 trainer.py:139] Epoch[240/1000] loss: 0.21693602651357652
I0803 11:56:27.735560 14408 trainer.py:139] Epoch[241/1000] loss: 0.2176283612847328
I0803 11:56:44.531928 14408 trainer.py:139] Epoch[242/1000] loss: 0.21656513027846813
I0803 11:57:01.314609 14408 trainer.py:139] Epoch[243/1000] loss: 0.2167432952672243
I0803 11:57:17.912793 14408 trainer.py:139] Epoch[244/1000] loss: 0.2160980336368084
I0803 11:57:34.579727 14408 trainer.py:139] Epoch[245/1000] loss: 0.21681660749018192
I0803 11:57:51.183228 14408 trainer.py:139] Epoch[246/1000] loss: 0.21694199591875077
I0803 11:58:07.892781 14408 trainer.py:139] Epoch[247/1000] loss: 0.21792452819645405
I0803 11:58:24.482412 14408 trainer.py:139] Epoch[248/1000] loss: 0.2175485361367464
I0803 11:58:40.893395 14408 trainer.py:139] Epoch[249/1000] loss: 0.21670431979000568
I0803 11:58:41.405681 14408 trainer.py:145] Test: [{'precision': 0.19472454090150249, 'recall': 0.2744387831213492, 'hit_ratio': 0.9071786310517529, 'ndcg': 0.3056687366888376}]
I0803 11:58:57.977789 14408 trainer.py:139] Epoch[250/1000] loss: 0.21550860553979873
I0803 11:59:14.740479 14408 trainer.py:139] Epoch[251/1000] loss: 0.21522806398570538
I0803 11:59:31.393055 14408 trainer.py:139] Epoch[252/1000] loss: 0.21657648719847203
I0803 11:59:47.877274 14408 trainer.py:139] Epoch[253/1000] loss: 0.2159401461482048
I0803 12:00:04.006834 14408 trainer.py:139] Epoch[254/1000] loss: 0.2164266224950552
I0803 12:00:20.527163 14408 trainer.py:139] Epoch[255/1000] loss: 0.21608022674918176
I0803 12:00:36.999976 14408 trainer.py:139] Epoch[256/1000] loss: 0.21474021561443807
I0803 12:00:53.482288 14408 trainer.py:139] Epoch[257/1000] loss: 0.21534750573337078
I0803 12:01:09.933072 14408 trainer.py:139] Epoch[258/1000] loss: 0.21498706042766572
I0803 12:01:26.542486 14408 trainer.py:139] Epoch[259/1000] loss: 0.21460457034409047
I0803 12:01:43.029035 14408 trainer.py:139] Epoch[260/1000] loss: 0.21550717912614345
I0803 12:01:59.439494 14408 trainer.py:139] Epoch[261/1000] loss: 0.2158300306648016
I0803 12:02:15.949950 14408 trainer.py:139] Epoch[262/1000] loss: 0.21519577614963054
I0803 12:02:32.561966 14408 trainer.py:139] Epoch[263/1000] loss: 0.21509307399392127
I0803 12:02:49.133699 14408 trainer.py:139] Epoch[264/1000] loss: 0.2141440909355879
I0803 12:03:05.469420 14408 trainer.py:139] Epoch[265/1000] loss: 0.21417840868234633
I0803 12:03:22.381250 14408 trainer.py:139] Epoch[266/1000] loss: 0.21395804397761822
I0803 12:03:39.352667 14408 trainer.py:139] Epoch[267/1000] loss: 0.21469993703067303
I0803 12:03:55.849518 14408 trainer.py:139] Epoch[268/1000] loss: 0.2135772794485092
I0803 12:04:12.556976 14408 trainer.py:139] Epoch[269/1000] loss: 0.21504305377602578
I0803 12:04:28.946827 14408 trainer.py:139] Epoch[270/1000] loss: 0.21476648971438408
I0803 12:04:45.529438 14408 trainer.py:139] Epoch[271/1000] loss: 0.21365799978375435
I0803 12:05:02.301144 14408 trainer.py:139] Epoch[272/1000] loss: 0.21519260816276073
I0803 12:05:18.745189 14408 trainer.py:139] Epoch[273/1000] loss: 0.21508607678115368
I0803 12:05:35.463994 14408 trainer.py:139] Epoch[274/1000] loss: 0.21352446004748343
I0803 12:05:51.846851 14408 trainer.py:139] Epoch[275/1000] loss: 0.21452778577804565
I0803 12:06:08.247876 14408 trainer.py:139] Epoch[276/1000] loss: 0.21348156929016113
I0803 12:06:24.506718 14408 trainer.py:139] Epoch[277/1000] loss: 0.2145134497433901
I0803 12:06:40.911469 14408 trainer.py:139] Epoch[278/1000] loss: 0.21300064995884896
I0803 12:06:57.402673 14408 trainer.py:139] Epoch[279/1000] loss: 0.21240864433348178
I0803 12:07:14.019959 14408 trainer.py:139] Epoch[280/1000] loss: 0.21346055045723916
I0803 12:07:30.602866 14408 trainer.py:139] Epoch[281/1000] loss: 0.21378687657415868
I0803 12:07:47.225152 14408 trainer.py:139] Epoch[282/1000] loss: 0.2135473493486643
I0803 12:08:03.843547 14408 trainer.py:139] Epoch[283/1000] loss: 0.21227278523147106
I0803 12:08:20.519462 14408 trainer.py:139] Epoch[284/1000] loss: 0.21298967562615873
I0803 12:08:37.238391 14408 trainer.py:139] Epoch[285/1000] loss: 0.21309607475996017
I0803 12:08:53.753813 14408 trainer.py:139] Epoch[286/1000] loss: 0.21294067949056625
I0803 12:09:10.329043 14408 trainer.py:139] Epoch[287/1000] loss: 0.21351789720356465
I0803 12:09:26.956922 14408 trainer.py:139] Epoch[288/1000] loss: 0.2130660403519869
I0803 12:09:43.602377 14408 trainer.py:139] Epoch[289/1000] loss: 0.21372086368501186
I0803 12:10:00.389618 14408 trainer.py:139] Epoch[290/1000] loss: 0.21298830956220627
I0803 12:10:16.807758 14408 trainer.py:139] Epoch[291/1000] loss: 0.21137845776975156
I0803 12:10:33.336838 14408 trainer.py:139] Epoch[292/1000] loss: 0.21337575912475587
I0803 12:10:50.189234 14408 trainer.py:139] Epoch[293/1000] loss: 0.21212047673761844
I0803 12:11:06.852050 14408 trainer.py:139] Epoch[294/1000] loss: 0.21303346417844296
I0803 12:11:23.815849 14408 trainer.py:139] Epoch[295/1000] loss: 0.2135324716567993
I0803 12:11:40.236222 14408 trainer.py:139] Epoch[296/1000] loss: 0.21174529902637004
I0803 12:11:56.650256 14408 trainer.py:139] Epoch[297/1000] loss: 0.21267370991408824
I0803 12:12:12.920576 14408 trainer.py:139] Epoch[298/1000] loss: 0.212807472422719
I0803 12:12:29.355888 14408 trainer.py:139] Epoch[299/1000] loss: 0.2127572014927864
I0803 12:12:29.974357 14408 trainer.py:145] Test: [{'precision': 0.1960434056761268, 'recall': 0.2770841588166491, 'hit_ratio': 0.9076794657762938, 'ndcg': 0.3081390003877173}]
I0803 12:12:46.523003 14408 trainer.py:139] Epoch[300/1000] loss: 0.21197229214012622
I0803 12:13:03.023862 14408 trainer.py:139] Epoch[301/1000] loss: 0.2121479157358408
I0803 12:13:19.436625 14408 trainer.py:139] Epoch[302/1000] loss: 0.21169039979577065
I0803 12:13:35.715826 14408 trainer.py:139] Epoch[303/1000] loss: 0.2117462944239378
I0803 12:13:52.275267 14408 trainer.py:139] Epoch[304/1000] loss: 0.21103722415864468
I0803 12:14:08.958084 14408 trainer.py:139] Epoch[305/1000] loss: 0.21203368045389653
I0803 12:14:25.406563 14408 trainer.py:139] Epoch[306/1000] loss: 0.2123992968350649
I0803 12:14:41.672043 14408 trainer.py:139] Epoch[307/1000] loss: 0.2124892920255661
I0803 12:14:58.396677 14408 trainer.py:139] Epoch[308/1000] loss: 0.21221726834774018
I0803 12:15:15.208429 14408 trainer.py:139] Epoch[309/1000] loss: 0.21178945638239383
I0803 12:15:31.515351 14408 trainer.py:139] Epoch[310/1000] loss: 0.2125941202044487
I0803 12:15:47.855768 14408 trainer.py:139] Epoch[311/1000] loss: 0.2114161178469658
I0803 12:16:04.203518 14408 trainer.py:139] Epoch[312/1000] loss: 0.21129197366535662
I0803 12:16:20.895289 14408 trainer.py:139] Epoch[313/1000] loss: 0.21098791994154453
I0803 12:16:37.191041 14408 trainer.py:139] Epoch[314/1000] loss: 0.21092556305229665
I0803 12:16:54.001523 14408 trainer.py:139] Epoch[315/1000] loss: 0.21110284514725208
I0803 12:17:10.420942 14408 trainer.py:139] Epoch[316/1000] loss: 0.2110376473516226
I0803 12:17:26.785396 14408 trainer.py:139] Epoch[317/1000] loss: 0.21157877184450627
I0803 12:17:43.165581 14408 trainer.py:139] Epoch[318/1000] loss: 0.21081988885998726
I0803 12:17:59.295737 14408 trainer.py:139] Epoch[319/1000] loss: 0.21199413053691388
I0803 12:18:15.535031 14408 trainer.py:139] Epoch[320/1000] loss: 0.2107149925082922
I0803 12:18:32.165273 14408 trainer.py:139] Epoch[321/1000] loss: 0.21109826304018497
I0803 12:18:48.722110 14408 trainer.py:139] Epoch[322/1000] loss: 0.21171964779496194
I0803 12:19:05.251845 14408 trainer.py:139] Epoch[323/1000] loss: 0.2105448864400387
I0803 12:19:21.978635 14408 trainer.py:139] Epoch[324/1000] loss: 0.21059924140572547
I0803 12:19:38.425336 14408 trainer.py:139] Epoch[325/1000] loss: 0.21112280562520028
I0803 12:19:55.108664 14408 trainer.py:139] Epoch[326/1000] loss: 0.21178890876471995
I0803 12:20:11.505099 14408 trainer.py:139] Epoch[327/1000] loss: 0.21020406894385815
I0803 12:20:28.040683 14408 trainer.py:139] Epoch[328/1000] loss: 0.2107134535908699
I0803 12:20:44.753338 14408 trainer.py:139] Epoch[329/1000] loss: 0.21148946993052958
I0803 12:21:01.360978 14408 trainer.py:139] Epoch[330/1000] loss: 0.20987709052860737
I0803 12:21:18.184021 14408 trainer.py:139] Epoch[331/1000] loss: 0.21104771941900252
I0803 12:21:34.974674 14408 trainer.py:139] Epoch[332/1000] loss: 0.2099982861429453
I0803 12:21:51.533985 14408 trainer.py:139] Epoch[333/1000] loss: 0.2094906534999609
I0803 12:22:08.063611 14408 trainer.py:139] Epoch[334/1000] loss: 0.21055507175624372
I0803 12:22:24.710565 14408 trainer.py:139] Epoch[335/1000] loss: 0.21012489311397076
I0803 12:22:41.588562 14408 trainer.py:139] Epoch[336/1000] loss: 0.20990990437567233
I0803 12:22:57.929158 14408 trainer.py:139] Epoch[337/1000] loss: 0.2104995310306549
I0803 12:23:14.372672 14408 trainer.py:139] Epoch[338/1000] loss: 0.2104474425315857
I0803 12:23:30.813822 14408 trainer.py:139] Epoch[339/1000] loss: 0.20998689942061902
I0803 12:23:47.034625 14408 trainer.py:139] Epoch[340/1000] loss: 0.20954760462045668
I0803 12:24:03.550226 14408 trainer.py:139] Epoch[341/1000] loss: 0.21071017906069756
I0803 12:24:19.994288 14408 trainer.py:139] Epoch[342/1000] loss: 0.2104278139770031
I0803 12:24:36.537372 14408 trainer.py:139] Epoch[343/1000] loss: 0.20869947150349616
I0803 12:24:53.090265 14408 trainer.py:139] Epoch[344/1000] loss: 0.21091664992272854
I0803 12:25:09.520516 14408 trainer.py:139] Epoch[345/1000] loss: 0.20942730382084845
I0803 12:25:26.174504 14408 trainer.py:139] Epoch[346/1000] loss: 0.21004216447472573
I0803 12:25:42.471929 14408 trainer.py:139] Epoch[347/1000] loss: 0.20879661627113819
I0803 12:25:59.014805 14408 trainer.py:139] Epoch[348/1000] loss: 0.20998659245669843
I0803 12:26:15.442003 14408 trainer.py:139] Epoch[349/1000] loss: 0.2105685044080019
I0803 12:26:16.024601 14408 trainer.py:145] Test: [{'precision': 0.1979632721202003, 'recall': 0.2797943960396675, 'hit_ratio': 0.9095158597662771, 'ndcg': 0.31143624342922627}]
I0803 12:26:32.918595 14408 trainer.py:139] Epoch[350/1000] loss: 0.2091352105140686
I0803 12:26:49.333788 14408 trainer.py:139] Epoch[351/1000] loss: 0.20885594002902508
I0803 12:27:06.100279 14408 trainer.py:139] Epoch[352/1000] loss: 0.2090618759393692
I0803 12:27:22.659109 14408 trainer.py:139] Epoch[353/1000] loss: 0.20958656892180444
I0803 12:27:39.354631 14408 trainer.py:139] Epoch[354/1000] loss: 0.20900660902261733
I0803 12:27:55.934648 14408 trainer.py:139] Epoch[355/1000] loss: 0.21010508611798287
I0803 12:28:12.473414 14408 trainer.py:139] Epoch[356/1000] loss: 0.20904094576835633
I0803 12:28:29.549441 14408 trainer.py:139] Epoch[357/1000] loss: 0.20973079092800617
I0803 12:28:46.174639 14408 trainer.py:139] Epoch[358/1000] loss: 0.20938623398542405
I0803 12:29:02.608700 14408 trainer.py:139] Epoch[359/1000] loss: 0.2084547258913517
I0803 12:29:19.146742 14408 trainer.py:139] Epoch[360/1000] loss: 0.21024433262646197
I0803 12:29:36.052584 14408 trainer.py:139] Epoch[361/1000] loss: 0.2089982584118843
I0803 12:29:52.398762 14408 trainer.py:139] Epoch[362/1000] loss: 0.20866406820714473
I0803 12:30:09.057405 14408 trainer.py:139] Epoch[363/1000] loss: 0.2095667988061905
I0803 12:30:25.632830 14408 trainer.py:139] Epoch[364/1000] loss: 0.20821401737630368
I0803 12:30:41.961780 14408 trainer.py:139] Epoch[365/1000] loss: 0.20895751677453517
I0803 12:30:58.336395 14408 trainer.py:139] Epoch[366/1000] loss: 0.20846095085144042
I0803 12:31:14.719448 14408 trainer.py:139] Epoch[367/1000] loss: 0.20820049270987512
I0803 12:31:31.254138 14408 trainer.py:139] Epoch[368/1000] loss: 0.20976744331419467
I0803 12:31:47.860765 14408 trainer.py:139] Epoch[369/1000] loss: 0.2090781234204769
I0803 12:32:04.417046 14408 trainer.py:139] Epoch[370/1000] loss: 0.20788054578006268
I0803 12:32:21.030972 14408 trainer.py:139] Epoch[371/1000] loss: 0.20885961912572384
I0803 12:32:37.449293 14408 trainer.py:139] Epoch[372/1000] loss: 0.20827379636466503
I0803 12:32:54.058070 14408 trainer.py:139] Epoch[373/1000] loss: 0.2080634955316782
I0803 12:33:10.752674 14408 trainer.py:139] Epoch[374/1000] loss: 0.2079911157488823
I0803 12:33:27.472830 14408 trainer.py:139] Epoch[375/1000] loss: 0.20816318206489087
I0803 12:33:44.253521 14408 trainer.py:139] Epoch[376/1000] loss: 0.20773196406662464
I0803 12:34:01.077610 14408 trainer.py:139] Epoch[377/1000] loss: 0.20912112817168235
I0803 12:34:17.527026 14408 trainer.py:139] Epoch[378/1000] loss: 0.20820738077163697
I0803 12:34:34.366693 14408 trainer.py:139] Epoch[379/1000] loss: 0.20787418335676194
I0803 12:34:50.703194 14408 trainer.py:139] Epoch[380/1000] loss: 0.20791296139359475
I0803 12:35:07.447129 14408 trainer.py:139] Epoch[381/1000] loss: 0.20829478986561298
I0803 12:35:23.890309 14408 trainer.py:139] Epoch[382/1000] loss: 0.2078724030405283
I0803 12:35:40.439765 14408 trainer.py:139] Epoch[383/1000] loss: 0.20805501006543636
I0803 12:35:57.060192 14408 trainer.py:139] Epoch[384/1000] loss: 0.20797366611659526
I0803 12:36:14.210175 14408 trainer.py:139] Epoch[385/1000] loss: 0.20729841701686383
I0803 12:36:31.834209 14408 trainer.py:139] Epoch[386/1000] loss: 0.20829341039061547
I0803 12:36:49.418850 14408 trainer.py:139] Epoch[387/1000] loss: 0.20729693546891212
I0803 12:37:06.686569 14408 trainer.py:139] Epoch[388/1000] loss: 0.20732681974768638
I0803 12:37:23.838735 14408 trainer.py:139] Epoch[389/1000] loss: 0.2065211959183216
I0803 12:37:40.801784 14408 trainer.py:139] Epoch[390/1000] loss: 0.20793226249516011
I0803 12:37:58.199438 14408 trainer.py:139] Epoch[391/1000] loss: 0.20796433240175247
I0803 12:38:15.513600 14408 trainer.py:139] Epoch[392/1000] loss: 0.20735933855175973
I0803 12:38:32.855444 14408 trainer.py:139] Epoch[393/1000] loss: 0.20764594599604608
I0803 12:38:50.136888 14408 trainer.py:139] Epoch[394/1000] loss: 0.2077886514365673
I0803 12:39:06.541866 14408 trainer.py:139] Epoch[395/1000] loss: 0.2072956208139658
I0803 12:39:23.600395 14408 trainer.py:139] Epoch[396/1000] loss: 0.20789894759654998
I0803 12:39:40.493271 14408 trainer.py:139] Epoch[397/1000] loss: 0.2077843826264143
I0803 12:39:57.389836 14408 trainer.py:139] Epoch[398/1000] loss: 0.20647240728139876
I0803 12:40:14.269584 14408 trainer.py:139] Epoch[399/1000] loss: 0.2069678705185652
I0803 12:40:14.822309 14408 trainer.py:145] Test: [{'precision': 0.19878964941569277, 'recall': 0.28061904646830194, 'hit_ratio': 0.9098497495826378, 'ndcg': 0.3129502040918486}]
I0803 12:40:31.789453 14408 trainer.py:139] Epoch[400/1000] loss: 0.20603177063167094
I0803 12:40:48.453244 14408 trainer.py:139] Epoch[401/1000] loss: 0.207834829390049
I0803 12:41:05.455238 14408 trainer.py:139] Epoch[402/1000] loss: 0.20696067363023757
I0803 12:41:22.626702 14408 trainer.py:139] Epoch[403/1000] loss: 0.20830138958990574
I0803 12:41:39.635192 14408 trainer.py:139] Epoch[404/1000] loss: 0.20658240132033825
I0803 12:41:56.731147 14408 trainer.py:139] Epoch[405/1000] loss: 0.2070098638534546
I0803 12:42:13.712049 14408 trainer.py:139] Epoch[406/1000] loss: 0.20812076069414615
I0803 12:42:30.604212 14408 trainer.py:139] Epoch[407/1000] loss: 0.2070943597704172
I0803 12:42:47.279285 14408 trainer.py:139] Epoch[408/1000] loss: 0.20673262961208821
I0803 12:43:04.389111 14408 trainer.py:139] Epoch[409/1000] loss: 0.20730375088751316
I0803 12:43:21.462008 14408 trainer.py:139] Epoch[410/1000] loss: 0.20698849707841874
I0803 12:43:38.533598 14408 trainer.py:139] Epoch[411/1000] loss: 0.20666721127927304
I0803 12:43:55.177428 14408 trainer.py:139] Epoch[412/1000] loss: 0.2066059283912182
I0803 12:44:11.988862 14408 trainer.py:139] Epoch[413/1000] loss: 0.20720478259027003
I0803 12:44:28.738211 14408 trainer.py:139] Epoch[414/1000] loss: 0.20523865818977355
I0803 12:44:46.128428 14408 trainer.py:139] Epoch[415/1000] loss: 0.20652719400823116
I0803 12:45:03.078155 14408 trainer.py:139] Epoch[416/1000] loss: 0.2067955233156681
I0803 12:45:20.292417 14408 trainer.py:139] Epoch[417/1000] loss: 0.20692896097898483
I0803 12:45:37.368917 14408 trainer.py:139] Epoch[418/1000] loss: 0.20739343538880348
I0803 12:45:54.589576 14408 trainer.py:139] Epoch[419/1000] loss: 0.20721224769949914
I0803 12:46:11.634981 14408 trainer.py:139] Epoch[420/1000] loss: 0.20655043609440327
I0803 12:46:28.490801 14408 trainer.py:139] Epoch[421/1000] loss: 0.2069205179810524
I0803 12:46:45.154694 14408 trainer.py:139] Epoch[422/1000] loss: 0.20745407082140446
I0803 12:47:01.656369 14408 trainer.py:139] Epoch[423/1000] loss: 0.20631245858967304
I0803 12:47:18.612077 14408 trainer.py:139] Epoch[424/1000] loss: 0.20670929178595543
I0803 12:47:35.790355 14408 trainer.py:139] Epoch[425/1000] loss: 0.20620878599584103
I0803 12:47:52.706413 14408 trainer.py:139] Epoch[426/1000] loss: 0.20562808997929097
I0803 12:48:09.620548 14408 trainer.py:139] Epoch[427/1000] loss: 0.20611919574439524
I0803 12:48:26.935006 14408 trainer.py:139] Epoch[428/1000] loss: 0.2054041288793087
I0803 12:48:43.844980 14408 trainer.py:139] Epoch[429/1000] loss: 0.20618773475289345
I0803 12:49:00.879195 14408 trainer.py:139] Epoch[430/1000] loss: 0.2060157500207424
I0803 12:49:17.755243 14408 trainer.py:139] Epoch[431/1000] loss: 0.20565040595829487
I0803 12:49:34.694651 14408 trainer.py:139] Epoch[432/1000] loss: 0.2067224968224764
I0803 12:49:51.452939 14408 trainer.py:139] Epoch[433/1000] loss: 0.20580053888261318
I0803 12:50:08.142335 14408 trainer.py:139] Epoch[434/1000] loss: 0.20757539756596088
I0803 12:50:25.375443 14408 trainer.py:139] Epoch[435/1000] loss: 0.20523626394569874
I0803 12:50:41.915479 14408 trainer.py:139] Epoch[436/1000] loss: 0.2067265074700117
I0803 12:50:58.911967 14408 trainer.py:139] Epoch[437/1000] loss: 0.20555813945829868
I0803 12:51:15.839886 14408 trainer.py:139] Epoch[438/1000] loss: 0.20691417418420316
I0803 12:51:33.263713 14408 trainer.py:139] Epoch[439/1000] loss: 0.20647825859487057
I0803 12:51:50.115844 14408 trainer.py:139] Epoch[440/1000] loss: 0.2057404700666666
I0803 12:52:07.391642 14408 trainer.py:139] Epoch[441/1000] loss: 0.20627886131405831
I0803 12:52:24.307826 14408 trainer.py:139] Epoch[442/1000] loss: 0.20561284571886063
I0803 12:52:41.312351 14408 trainer.py:139] Epoch[443/1000] loss: 0.20476097017526626
I0803 12:52:57.995898 14408 trainer.py:139] Epoch[444/1000] loss: 0.2056567169725895
I0803 12:53:14.849653 14408 trainer.py:139] Epoch[445/1000] loss: 0.20588088035583496
I0803 12:53:32.345693 14408 trainer.py:139] Epoch[446/1000] loss: 0.2063042927533388
I0803 12:53:49.354024 14408 trainer.py:139] Epoch[447/1000] loss: 0.2066874962300062
I0803 12:54:06.316913 14408 trainer.py:139] Epoch[448/1000] loss: 0.20541331432759763
I0803 12:54:23.307081 14408 trainer.py:139] Epoch[449/1000] loss: 0.20631851591169834
I0803 12:54:23.933187 14408 trainer.py:145] Test: [{'precision': 0.1992487479131886, 'recall': 0.28177844427190696, 'hit_ratio': 0.9108514190317195, 'ndcg': 0.31377530017775396}]
I0803 12:54:41.057475 14408 trainer.py:139] Epoch[450/1000] loss: 0.20573228150606154
I0803 12:54:57.504674 14408 trainer.py:139] Epoch[451/1000] loss: 0.2058108475059271
I0803 12:55:14.251255 14408 trainer.py:139] Epoch[452/1000] loss: 0.20464287251234053
I0803 12:55:31.402761 14408 trainer.py:139] Epoch[453/1000] loss: 0.20583051368594169
I0803 12:55:48.091224 14408 trainer.py:139] Epoch[454/1000] loss: 0.20493048727512359
I0803 12:56:04.851850 14408 trainer.py:139] Epoch[455/1000] loss: 0.20614881664514542
I0803 12:56:21.869071 14408 trainer.py:139] Epoch[456/1000] loss: 0.20561303272843362
I0803 12:56:38.986390 14408 trainer.py:139] Epoch[457/1000] loss: 0.20441035218536854
I0803 12:56:56.230905 14408 trainer.py:139] Epoch[458/1000] loss: 0.20509175583720207
I0803 12:57:13.357281 14408 trainer.py:139] Epoch[459/1000] loss: 0.20537201426923274
I0803 12:57:30.418892 14408 trainer.py:139] Epoch[460/1000] loss: 0.20459140315651894
I0803 12:57:47.983902 14408 trainer.py:139] Epoch[461/1000] loss: 0.20595518536865712
I0803 12:58:05.017565 14408 trainer.py:139] Epoch[462/1000] loss: 0.20558932051062584
I0803 12:58:22.046162 14408 trainer.py:139] Epoch[463/1000] loss: 0.20556301735341548
I0803 12:58:38.978183 14408 trainer.py:139] Epoch[464/1000] loss: 0.20490524247288705
I0803 12:58:55.525784 14408 trainer.py:139] Epoch[465/1000] loss: 0.20536061525344848
I0803 12:59:12.306821 14408 trainer.py:139] Epoch[466/1000] loss: 0.20414660833775997
I0803 12:59:29.450938 14408 trainer.py:139] Epoch[467/1000] loss: 0.20597471222281455
I0803 12:59:46.104283 14408 trainer.py:139] Epoch[468/1000] loss: 0.20409487932920456
I0803 13:00:03.040444 14408 trainer.py:139] Epoch[469/1000] loss: 0.20471162907779217
I0803 13:00:20.121418 14408 trainer.py:139] Epoch[470/1000] loss: 0.2046019721776247
I0803 13:00:37.010215 14408 trainer.py:139] Epoch[471/1000] loss: 0.20484834909439087
I0803 13:00:54.152774 14408 trainer.py:139] Epoch[472/1000] loss: 0.20508916154503823
I0803 13:01:10.952224 14408 trainer.py:139] Epoch[473/1000] loss: 0.20454841665923595
I0803 13:01:27.565533 14408 trainer.py:139] Epoch[474/1000] loss: 0.20428809747099877
I0803 13:01:44.333048 14408 trainer.py:139] Epoch[475/1000] loss: 0.20469421446323394
I0803 13:02:01.421576 14408 trainer.py:139] Epoch[476/1000] loss: 0.20370437242090703
I0803 13:02:18.319657 14408 trainer.py:139] Epoch[477/1000] loss: 0.20517825558781624
I0803 13:02:35.167949 14408 trainer.py:139] Epoch[478/1000] loss: 0.20484797433018684
I0803 13:02:51.920649 14408 trainer.py:139] Epoch[479/1000] loss: 0.20408936776220798
I0803 13:03:09.258165 14408 trainer.py:139] Epoch[480/1000] loss: 0.20492055416107177
I0803 13:03:26.319734 14408 trainer.py:139] Epoch[481/1000] loss: 0.2047019574791193
I0803 13:03:43.317115 14408 trainer.py:139] Epoch[482/1000] loss: 0.20516405552625655
I0803 13:04:00.264852 14408 trainer.py:139] Epoch[483/1000] loss: 0.20542806796729565
I0803 13:04:16.779320 14408 trainer.py:139] Epoch[484/1000] loss: 0.2045597169548273
I0803 13:04:34.004261 14408 trainer.py:139] Epoch[485/1000] loss: 0.20508093051612378
I0803 13:04:51.163537 14408 trainer.py:139] Epoch[486/1000] loss: 0.204998118057847
I0803 13:05:08.225788 14408 trainer.py:139] Epoch[487/1000] loss: 0.20534526221454144
I0803 13:05:25.616647 14408 trainer.py:139] Epoch[488/1000] loss: 0.2044385302811861
I0803 13:05:42.982576 14408 trainer.py:139] Epoch[489/1000] loss: 0.20415387600660323
I0803 13:06:00.095889 14408 trainer.py:139] Epoch[490/1000] loss: 0.20494716204702854
I0803 13:06:16.684453 14408 trainer.py:139] Epoch[491/1000] loss: 0.20498628318309783
I0803 13:06:33.518485 14408 trainer.py:139] Epoch[492/1000] loss: 0.2041399333626032
I0803 13:06:50.144452 14408 trainer.py:139] Epoch[493/1000] loss: 0.20363471657037735
I0803 13:07:07.081594 14408 trainer.py:139] Epoch[494/1000] loss: 0.2045269288122654
I0803 13:07:23.653924 14408 trainer.py:139] Epoch[495/1000] loss: 0.20370740108191968
I0803 13:07:40.415167 14408 trainer.py:139] Epoch[496/1000] loss: 0.20511899441480635
I0803 13:07:57.472572 14408 trainer.py:139] Epoch[497/1000] loss: 0.2042509164661169
I0803 13:08:14.304972 14408 trainer.py:139] Epoch[498/1000] loss: 0.20402515307068825
I0803 13:08:31.372394 14408 trainer.py:139] Epoch[499/1000] loss: 0.20447062626481055
I0803 13:08:31.986939 14408 trainer.py:145] Test: [{'precision': 0.19965776293823043, 'recall': 0.2820373263944987, 'hit_ratio': 0.9110183639398999, 'ndcg': 0.3153525837009373}]
I0803 13:08:49.264307 14408 trainer.py:139] Epoch[500/1000] loss: 0.20434401445090772
I0803 13:09:06.262933 14408 trainer.py:139] Epoch[501/1000] loss: 0.20496224313974382
I0803 13:09:23.364371 14408 trainer.py:139] Epoch[502/1000] loss: 0.20446859523653985
I0803 13:09:40.468347 14408 trainer.py:139] Epoch[503/1000] loss: 0.2045273505151272
I0803 13:09:57.190711 14408 trainer.py:139] Epoch[504/1000] loss: 0.20423593372106552
I0803 13:10:13.816561 14408 trainer.py:139] Epoch[505/1000] loss: 0.20300431549549103
I0803 13:10:30.605557 14408 trainer.py:139] Epoch[506/1000] loss: 0.2030169829726219
I0803 13:10:47.509612 14408 trainer.py:139] Epoch[507/1000] loss: 0.20467007756233216
I0803 13:11:04.270045 14408 trainer.py:139] Epoch[508/1000] loss: 0.20416785776615143
I0803 13:11:21.479491 14408 trainer.py:139] Epoch[509/1000] loss: 0.2029469884932041
I0803 13:11:38.585429 14408 trainer.py:139] Epoch[510/1000] loss: 0.2041407436132431
I0803 13:11:55.535788 14408 trainer.py:139] Epoch[511/1000] loss: 0.20234579779207706
I0803 13:12:12.360226 14408 trainer.py:139] Epoch[512/1000] loss: 0.20333517529070377
I0803 13:12:29.230309 14408 trainer.py:139] Epoch[513/1000] loss: 0.2045340698212385
I0803 13:12:46.195135 14408 trainer.py:139] Epoch[514/1000] loss: 0.2029436744749546
I0803 13:13:03.063710 14408 trainer.py:139] Epoch[515/1000] loss: 0.2032769326120615
I0803 13:13:19.690326 14408 trainer.py:139] Epoch[516/1000] loss: 0.20387933626770974
I0803 13:13:36.626173 14408 trainer.py:139] Epoch[517/1000] loss: 0.20431481897830964
I0803 13:13:53.489309 14408 trainer.py:139] Epoch[518/1000] loss: 0.20418765097856523
I0803 13:14:10.474161 14408 trainer.py:139] Epoch[519/1000] loss: 0.20243381820619105
I0803 13:14:27.441122 14408 trainer.py:139] Epoch[520/1000] loss: 0.2044195495545864
I0803 13:14:44.608265 14408 trainer.py:139] Epoch[521/1000] loss: 0.20292544029653073
I0803 13:15:01.314069 14408 trainer.py:139] Epoch[522/1000] loss: 0.20401760376989841
I0803 13:15:18.375153 14408 trainer.py:139] Epoch[523/1000] loss: 0.20322527401149273
I0803 13:15:35.447647 14408 trainer.py:139] Epoch[524/1000] loss: 0.20426140427589418
I0803 13:15:52.306007 14408 trainer.py:139] Epoch[525/1000] loss: 0.2040057446807623
I0803 13:16:09.519670 14408 trainer.py:139] Epoch[526/1000] loss: 0.20386396907269955
I0803 13:16:26.365482 14408 trainer.py:139] Epoch[527/1000] loss: 0.20300565622746944
I0803 13:16:43.464511 14408 trainer.py:139] Epoch[528/1000] loss: 0.20223943665623664
I0803 13:17:00.333487 14408 trainer.py:139] Epoch[529/1000] loss: 0.2029135126620531
I0803 13:17:17.412282 14408 trainer.py:139] Epoch[530/1000] loss: 0.2029138457030058
I0803 13:17:34.427932 14408 trainer.py:139] Epoch[531/1000] loss: 0.20301453731954097
I0803 13:17:51.312464 14408 trainer.py:139] Epoch[532/1000] loss: 0.2040392506867647
I0803 13:18:08.193755 14408 trainer.py:139] Epoch[533/1000] loss: 0.20348996557295324
I0803 13:18:24.988186 14408 trainer.py:139] Epoch[534/1000] loss: 0.2028087556362152
I0803 13:18:41.937712 14408 trainer.py:139] Epoch[535/1000] loss: 0.2038881566375494
I0803 13:18:58.703065 14408 trainer.py:139] Epoch[536/1000] loss: 0.2034681461751461
I0803 13:19:15.475473 14408 trainer.py:139] Epoch[537/1000] loss: 0.20286559388041497
I0803 13:19:32.341529 14408 trainer.py:139] Epoch[538/1000] loss: 0.20321587957441806
I0803 13:19:49.178308 14408 trainer.py:139] Epoch[539/1000] loss: 0.2033041138201952
I0803 13:20:06.007440 14408 trainer.py:139] Epoch[540/1000] loss: 0.20329076386988162
I0803 13:20:22.934630 14408 trainer.py:139] Epoch[541/1000] loss: 0.20274693779647351
I0803 13:20:40.096185 14408 trainer.py:139] Epoch[542/1000] loss: 0.2024163518100977
I0803 13:20:57.150943 14408 trainer.py:139] Epoch[543/1000] loss: 0.20313853174448013
I0803 13:21:14.245775 14408 trainer.py:139] Epoch[544/1000] loss: 0.2031143508851528
I0803 13:21:31.112849 14408 trainer.py:139] Epoch[545/1000] loss: 0.20321252085268499
I0803 13:21:48.267483 14408 trainer.py:139] Epoch[546/1000] loss: 0.20321761518716813
I0803 13:22:05.269687 14408 trainer.py:139] Epoch[547/1000] loss: 0.2021245151758194
I0803 13:22:21.875815 14408 trainer.py:139] Epoch[548/1000] loss: 0.20352535098791122
I0803 13:22:38.593830 14408 trainer.py:139] Epoch[549/1000] loss: 0.20244466401636602
I0803 13:22:39.136601 14408 trainer.py:145] Test: [{'precision': 0.20044240400667782, 'recall': 0.2836401823587137, 'hit_ratio': 0.913355592654424, 'ndcg': 0.31673201945090523}]
I0803 13:22:55.685119 14408 trainer.py:139] Epoch[550/1000] loss: 0.20255573019385337
I0803 13:23:12.456696 14408 trainer.py:139] Epoch[551/1000] loss: 0.20220924131572246
I0803 13:23:29.638782 14408 trainer.py:139] Epoch[552/1000] loss: 0.2028538402169943
I0803 13:23:46.666846 14408 trainer.py:139] Epoch[553/1000] loss: 0.20306752882897855
I0803 13:24:03.415246 14408 trainer.py:139] Epoch[554/1000] loss: 0.20309041775763034
I0803 13:24:20.299196 14408 trainer.py:139] Epoch[555/1000] loss: 0.20186105445027352
I0803 13:24:37.117453 14408 trainer.py:139] Epoch[556/1000] loss: 0.20356039851903915
I0803 13:24:53.988745 14408 trainer.py:139] Epoch[557/1000] loss: 0.20303694382309914
I0803 13:25:10.744226 14408 trainer.py:139] Epoch[558/1000] loss: 0.2027715142816305
I0803 13:25:27.676940 14408 trainer.py:139] Epoch[559/1000] loss: 0.20284707099199295
I0803 13:25:44.731143 14408 trainer.py:139] Epoch[560/1000] loss: 0.20270158164203167
I0803 13:26:01.542559 14408 trainer.py:139] Epoch[561/1000] loss: 0.20355154387652874
I0803 13:26:18.486777 14408 trainer.py:139] Epoch[562/1000] loss: 0.20237633176147937
I0803 13:26:35.356654 14408 trainer.py:139] Epoch[563/1000] loss: 0.20206825919449328
I0803 13:26:52.396197 14408 trainer.py:139] Epoch[564/1000] loss: 0.2020161285996437
I0803 13:27:09.336878 14408 trainer.py:139] Epoch[565/1000] loss: 0.20293645337224006
I0803 13:27:26.231923 14408 trainer.py:139] Epoch[566/1000] loss: 0.20305850878357887
I0803 13:27:43.213381 14408 trainer.py:139] Epoch[567/1000] loss: 0.20215988494455814
I0803 13:28:00.548200 14408 trainer.py:139] Epoch[568/1000] loss: 0.20260396972298622
I0803 13:28:17.193089 14408 trainer.py:139] Epoch[569/1000] loss: 0.20251505747437476
I0803 13:28:34.210828 14408 trainer.py:139] Epoch[570/1000] loss: 0.20212760157883167
I0803 13:28:51.071775 14408 trainer.py:139] Epoch[571/1000] loss: 0.20081140361726285
I0803 13:29:07.680091 14408 trainer.py:139] Epoch[572/1000] loss: 0.20183809101581573
I0803 13:29:24.808372 14408 trainer.py:139] Epoch[573/1000] loss: 0.20291717611253263
I0803 13:29:42.237556 14408 trainer.py:139] Epoch[574/1000] loss: 0.20174688696861268
I0803 13:29:59.212275 14408 trainer.py:139] Epoch[575/1000] loss: 0.20270926877856255
I0803 13:30:15.976014 14408 trainer.py:139] Epoch[576/1000] loss: 0.20341107696294786
I0803 13:30:32.738636 14408 trainer.py:139] Epoch[577/1000] loss: 0.2026688948273659
I0803 13:30:49.581617 14408 trainer.py:139] Epoch[578/1000] loss: 0.20209824480116367
I0803 13:31:06.304137 14408 trainer.py:139] Epoch[579/1000] loss: 0.2037253390997648
I0803 13:31:23.264170 14408 trainer.py:139] Epoch[580/1000] loss: 0.20164255984127522
I0803 13:31:39.968847 14408 trainer.py:139] Epoch[581/1000] loss: 0.20288281925022603
I0803 13:31:57.134475 14408 trainer.py:139] Epoch[582/1000] loss: 0.20316106528043748
I0803 13:32:14.119827 14408 trainer.py:139] Epoch[583/1000] loss: 0.201979211717844
I0803 13:32:30.863225 14408 trainer.py:139] Epoch[584/1000] loss: 0.20336598046123983
I0803 13:32:47.802129 14408 trainer.py:139] Epoch[585/1000] loss: 0.2023498799651861
I0803 13:33:05.106803 14408 trainer.py:139] Epoch[586/1000] loss: 0.2017063457518816
I0803 13:33:22.060494 14408 trainer.py:139] Epoch[587/1000] loss: 0.20192807167768478
I0803 13:33:39.466170 14408 trainer.py:139] Epoch[588/1000] loss: 0.20160951912403108
I0803 13:33:56.084821 14408 trainer.py:139] Epoch[589/1000] loss: 0.2033036656677723
I0803 13:34:13.225580 14408 trainer.py:139] Epoch[590/1000] loss: 0.20243432857096194
I0803 13:34:30.282119 14408 trainer.py:139] Epoch[591/1000] loss: 0.2019051294773817
I0803 13:34:47.185624 14408 trainer.py:139] Epoch[592/1000] loss: 0.20079345628619194
I0803 13:35:04.386339 14408 trainer.py:139] Epoch[593/1000] loss: 0.20224568657577038
I0803 13:35:21.215102 14408 trainer.py:139] Epoch[594/1000] loss: 0.20245892331004142
I0803 13:35:38.690284 14408 trainer.py:139] Epoch[595/1000] loss: 0.20208861120045185
I0803 13:35:55.859269 14408 trainer.py:139] Epoch[596/1000] loss: 0.20243813209235667
I0803 13:36:12.823860 14408 trainer.py:139] Epoch[597/1000] loss: 0.2019843764603138
I0803 13:36:29.751557 14408 trainer.py:139] Epoch[598/1000] loss: 0.20079491809010505
I0803 13:36:46.704476 14408 trainer.py:139] Epoch[599/1000] loss: 0.20228350795805455
I0803 13:36:47.292063 14408 trainer.py:145] Test: [{'precision': 0.20076794657762934, 'recall': 0.2844807697505466, 'hit_ratio': 0.9130217028380634, 'ndcg': 0.31671547474708023}]
I0803 13:37:04.035897 14408 trainer.py:139] Epoch[600/1000] loss: 0.20180818252265453
I0803 13:37:20.802806 14408 trainer.py:139] Epoch[601/1000] loss: 0.2023303359746933
I0803 13:37:37.480144 14408 trainer.py:139] Epoch[602/1000] loss: 0.20131332315504552
I0803 13:37:54.187189 14408 trainer.py:139] Epoch[603/1000] loss: 0.2016185600310564
I0803 13:38:11.190420 14408 trainer.py:139] Epoch[604/1000] loss: 0.20162435844540597
I0803 13:38:28.098427 14408 trainer.py:139] Epoch[605/1000] loss: 0.202664377912879
I0803 13:38:45.024112 14408 trainer.py:139] Epoch[606/1000] loss: 0.2017251219600439
I0803 13:39:01.978680 14408 trainer.py:139] Epoch[607/1000] loss: 0.20240498185157776
I0803 13:39:18.990202 14408 trainer.py:139] Epoch[608/1000] loss: 0.20067751966416836
I0803 13:39:35.738816 14408 trainer.py:139] Epoch[609/1000] loss: 0.20228103995323182
I0803 13:39:52.554396 14408 trainer.py:139] Epoch[610/1000] loss: 0.2013999566435814
I0803 13:40:09.780175 14408 trainer.py:139] Epoch[611/1000] loss: 0.20170379802584648
I0803 13:40:26.579629 14408 trainer.py:139] Epoch[612/1000] loss: 0.20168761797249318
I0803 13:40:43.248020 14408 trainer.py:139] Epoch[613/1000] loss: 0.20111206024885178
I0803 13:41:00.103702 14408 trainer.py:139] Epoch[614/1000] loss: 0.20152316763997077
I0803 13:41:17.231875 14408 trainer.py:139] Epoch[615/1000] loss: 0.2025981444865465
I0803 13:41:34.739674 14408 trainer.py:139] Epoch[616/1000] loss: 0.20107945203781127
I0803 13:41:51.510390 14408 trainer.py:139] Epoch[617/1000] loss: 0.2009782150387764
I0803 13:42:08.437090 14408 trainer.py:139] Epoch[618/1000] loss: 0.20155370868742467
I0803 13:42:25.551163 14408 trainer.py:139] Epoch[619/1000] loss: 0.20214443914592267
I0803 13:42:42.625690 14408 trainer.py:139] Epoch[620/1000] loss: 0.2019763972610235
I0803 13:42:59.689191 14408 trainer.py:139] Epoch[621/1000] loss: 0.20011143758893013
I0803 13:43:16.452378 14408 trainer.py:139] Epoch[622/1000] loss: 0.20135752521455288
I0803 13:43:33.290760 14408 trainer.py:139] Epoch[623/1000] loss: 0.2013635326176882
I0803 13:43:50.550278 14408 trainer.py:139] Epoch[624/1000] loss: 0.20136932022869586
I0803 13:44:07.354190 14408 trainer.py:139] Epoch[625/1000] loss: 0.20076746940612794
I0803 13:44:24.056621 14408 trainer.py:139] Epoch[626/1000] loss: 0.20160009451210498
I0803 13:44:41.288865 14408 trainer.py:139] Epoch[627/1000] loss: 0.20051393210887908
I0803 13:44:58.258434 14408 trainer.py:139] Epoch[628/1000] loss: 0.2021164894104004
I0803 13:45:15.535196 14408 trainer.py:139] Epoch[629/1000] loss: 0.20214667804539205
I0803 13:45:32.804087 14408 trainer.py:139] Epoch[630/1000] loss: 0.20230271741747857
I0803 13:45:49.554398 14408 trainer.py:139] Epoch[631/1000] loss: 0.2018418651074171
I0803 13:46:06.238622 14408 trainer.py:139] Epoch[632/1000] loss: 0.20142889767885208
I0803 13:46:23.149528 14408 trainer.py:139] Epoch[633/1000] loss: 0.20088463947176932
I0803 13:46:40.119541 14408 trainer.py:139] Epoch[634/1000] loss: 0.2020226638764143
I0803 13:46:56.758024 14408 trainer.py:139] Epoch[635/1000] loss: 0.20082703605294228
I0803 13:47:13.432333 14408 trainer.py:139] Epoch[636/1000] loss: 0.2027206938713789
I0803 13:47:30.528948 14408 trainer.py:139] Epoch[637/1000] loss: 0.20144521556794642
I0803 13:47:47.936561 14408 trainer.py:139] Epoch[638/1000] loss: 0.20016313791275026
I0803 13:48:04.628046 14408 trainer.py:139] Epoch[639/1000] loss: 0.2027423344552517
I0803 13:48:21.622877 14408 trainer.py:139] Epoch[640/1000] loss: 0.20167782977223397
I0803 13:48:38.671430 14408 trainer.py:139] Epoch[641/1000] loss: 0.20145571269094945
I0803 13:48:55.799359 14408 trainer.py:139] Epoch[642/1000] loss: 0.2010179478675127
I0803 13:49:12.436620 14408 trainer.py:139] Epoch[643/1000] loss: 0.20136707574129104
I0803 13:49:29.215846 14408 trainer.py:139] Epoch[644/1000] loss: 0.20060876570641994
I0803 13:49:46.035943 14408 trainer.py:139] Epoch[645/1000] loss: 0.2008759777992964
I0803 13:50:02.710724 14408 trainer.py:139] Epoch[646/1000] loss: 0.20166173689067363
I0803 13:50:19.988030 14408 trainer.py:139] Epoch[647/1000] loss: 0.20176211930811405
I0803 13:50:36.691859 14408 trainer.py:139] Epoch[648/1000] loss: 0.20184761397540568
I0803 13:50:53.926358 14408 trainer.py:139] Epoch[649/1000] loss: 0.20295973792672156
I0803 13:50:54.503427 14408 trainer.py:145] Test: [{'precision': 0.2015191986644407, 'recall': 0.28484779746160716, 'hit_ratio': 0.9131886477462438, 'ndcg': 0.31816367225738756}]
I0803 13:51:11.764648 14408 trainer.py:139] Epoch[650/1000] loss: 0.20167761631309986
I0803 13:51:28.794100 14408 trainer.py:139] Epoch[651/1000] loss: 0.20130055844783784
I0803 13:51:46.061887 14408 trainer.py:139] Epoch[652/1000] loss: 0.20077984295785428
I0803 13:52:03.584096 14408 trainer.py:139] Epoch[653/1000] loss: 0.20132936537265778
I0803 13:52:20.799637 14408 trainer.py:139] Epoch[654/1000] loss: 0.20059882327914239
I0803 13:52:37.490768 14408 trainer.py:139] Epoch[655/1000] loss: 0.2010698277503252
I0803 13:52:54.290166 14408 trainer.py:139] Epoch[656/1000] loss: 0.2005857050418854
I0803 13:53:11.348052 14408 trainer.py:139] Epoch[657/1000] loss: 0.20052421577274798
I0803 13:53:28.542844 14408 trainer.py:139] Epoch[658/1000] loss: 0.20104652345180513
I0803 13:53:45.612403 14408 trainer.py:139] Epoch[659/1000] loss: 0.20047721564769744
I0803 13:54:02.474193 14408 trainer.py:139] Epoch[660/1000] loss: 0.20102725252509118
I0803 13:54:19.414026 14408 trainer.py:139] Epoch[661/1000] loss: 0.20131750889122485
I0803 13:54:36.438249 14408 trainer.py:139] Epoch[662/1000] loss: 0.200114319100976
I0803 13:54:53.216779 14408 trainer.py:139] Epoch[663/1000] loss: 0.20064938105642796
I0803 13:55:10.045487 14408 trainer.py:139] Epoch[664/1000] loss: 0.20014150254428387
I0803 13:55:27.192443 14408 trainer.py:139] Epoch[665/1000] loss: 0.20136654004454613
I0803 13:55:44.053412 14408 trainer.py:139] Epoch[666/1000] loss: 0.20155324675142766
I0803 13:56:01.045842 14408 trainer.py:139] Epoch[667/1000] loss: 0.20147601515054703
I0803 13:56:18.397344 14408 trainer.py:139] Epoch[668/1000] loss: 0.20073185116052628
I0803 13:56:35.283008 14408 trainer.py:139] Epoch[669/1000] loss: 0.20097644589841365
I0803 13:56:52.325896 14408 trainer.py:139] Epoch[670/1000] loss: 0.20115012004971505
I0803 13:57:09.390469 14408 trainer.py:139] Epoch[671/1000] loss: 0.2009422115981579
I0803 13:57:26.525193 14408 trainer.py:139] Epoch[672/1000] loss: 0.2012545082718134
I0803 13:57:43.694754 14408 trainer.py:139] Epoch[673/1000] loss: 0.19970953315496445
I0803 13:58:00.495593 14408 trainer.py:139] Epoch[674/1000] loss: 0.20167169906198978
I0803 13:58:17.794620 14408 trainer.py:139] Epoch[675/1000] loss: 0.20048335008323193
I0803 13:58:34.579373 14408 trainer.py:139] Epoch[676/1000] loss: 0.19967583194375038
I0803 13:58:51.282045 14408 trainer.py:139] Epoch[677/1000] loss: 0.20157497338950633
I0803 13:59:08.148177 14408 trainer.py:139] Epoch[678/1000] loss: 0.20148053541779518
I0803 13:59:25.404559 14408 trainer.py:139] Epoch[679/1000] loss: 0.20059338733553886
I0803 13:59:42.307433 14408 trainer.py:139] Epoch[680/1000] loss: 0.2002690438181162
I0803 13:59:59.325320 14408 trainer.py:139] Epoch[681/1000] loss: 0.20140841826796532
I0803 14:00:16.280726 14408 trainer.py:139] Epoch[682/1000] loss: 0.19987962990999222
I0803 14:00:32.916633 14408 trainer.py:139] Epoch[683/1000] loss: 0.20070632547140121
I0803 14:00:50.138116 14408 trainer.py:139] Epoch[684/1000] loss: 0.20036408342421055
I0803 14:01:06.883483 14408 trainer.py:139] Epoch[685/1000] loss: 0.20095334202051163
I0803 14:01:23.659220 14408 trainer.py:139] Epoch[686/1000] loss: 0.20001602843403815
I0803 14:01:40.570933 14408 trainer.py:139] Epoch[687/1000] loss: 0.20066631026566029
I0803 14:01:57.479588 14408 trainer.py:139] Epoch[688/1000] loss: 0.2000427544116974
I0803 14:02:14.669097 14408 trainer.py:139] Epoch[689/1000] loss: 0.20067529790103436
I0803 14:02:31.595885 14408 trainer.py:139] Epoch[690/1000] loss: 0.19847687445580958
I0803 14:02:48.595438 14408 trainer.py:139] Epoch[691/1000] loss: 0.1990548897534609
I0803 14:03:05.879509 14408 trainer.py:139] Epoch[692/1000] loss: 0.2007260572165251
I0803 14:03:22.968696 14408 trainer.py:139] Epoch[693/1000] loss: 0.20174085795879365
I0803 14:03:40.095736 14408 trainer.py:139] Epoch[694/1000] loss: 0.20054305344820023
I0803 14:03:57.225561 14408 trainer.py:139] Epoch[695/1000] loss: 0.20188447646796703
I0803 14:04:13.870290 14408 trainer.py:139] Epoch[696/1000] loss: 0.19952993504703045
I0803 14:04:30.740814 14408 trainer.py:139] Epoch[697/1000] loss: 0.20090946592390538
I0803 14:04:47.395429 14408 trainer.py:139] Epoch[698/1000] loss: 0.2003187544643879
I0803 14:05:04.060047 14408 trainer.py:139] Epoch[699/1000] loss: 0.20098920501768588
I0803 14:05:04.646086 14408 trainer.py:145] Test: [{'precision': 0.20134390651085146, 'recall': 0.2850422621472669, 'hit_ratio': 0.9121869782971619, 'ndcg': 0.318540008281434}]
I0803 14:05:21.405963 14408 trainer.py:139] Epoch[700/1000] loss: 0.2004006564617157
I0803 14:05:38.354622 14408 trainer.py:139] Epoch[701/1000] loss: 0.2012858461588621
I0803 14:05:55.215049 14408 trainer.py:139] Epoch[702/1000] loss: 0.19961006082594396
I0803 14:06:12.295687 14408 trainer.py:139] Epoch[703/1000] loss: 0.19980427399277687
I0803 14:06:29.251477 14408 trainer.py:139] Epoch[704/1000] loss: 0.19951847679913043
I0803 14:06:46.052770 14408 trainer.py:139] Epoch[705/1000] loss: 0.19984987005591393
I0803 14:07:02.653918 14408 trainer.py:139] Epoch[706/1000] loss: 0.20060897804796696
I0803 14:07:19.756150 14408 trainer.py:139] Epoch[707/1000] loss: 0.2010141544044018
I0803 14:07:36.644784 14408 trainer.py:139] Epoch[708/1000] loss: 0.19955221153795719
I0803 14:07:53.761146 14408 trainer.py:139] Epoch[709/1000] loss: 0.200841086730361
I0803 14:08:10.715811 14408 trainer.py:139] Epoch[710/1000] loss: 0.20044452995061873
I0803 14:08:27.665713 14408 trainer.py:139] Epoch[711/1000] loss: 0.20020579174160957
I0803 14:08:44.773841 14408 trainer.py:139] Epoch[712/1000] loss: 0.1991145469248295
I0803 14:09:01.787935 14408 trainer.py:139] Epoch[713/1000] loss: 0.20096688494086265
I0803 14:09:19.027127 14408 trainer.py:139] Epoch[714/1000] loss: 0.20039204880595207
I0803 14:09:36.182411 14408 trainer.py:139] Epoch[715/1000] loss: 0.20018833987414836
I0803 14:09:53.659356 14408 trainer.py:139] Epoch[716/1000] loss: 0.19887015409767628
I0803 14:10:10.661529 14408 trainer.py:139] Epoch[717/1000] loss: 0.20067631863057614
I0803 14:10:27.484785 14408 trainer.py:139] Epoch[718/1000] loss: 0.20068068392574787
I0803 14:10:44.425678 14408 trainer.py:139] Epoch[719/1000] loss: 0.20049275346100331
I0803 14:11:01.352417 14408 trainer.py:139] Epoch[720/1000] loss: 0.20044039115309714
I0803 14:11:18.362085 14408 trainer.py:139] Epoch[721/1000] loss: 0.20012742504477501
I0803 14:11:35.602002 14408 trainer.py:139] Epoch[722/1000] loss: 0.20044606253504754
I0803 14:11:52.426188 14408 trainer.py:139] Epoch[723/1000] loss: 0.2000430293381214
I0803 14:12:09.389024 14408 trainer.py:139] Epoch[724/1000] loss: 0.1989993005990982
I0803 14:12:26.314862 14408 trainer.py:139] Epoch[725/1000] loss: 0.20064940117299557
I0803 14:12:43.026509 14408 trainer.py:139] Epoch[726/1000] loss: 0.19943929985165595
I0803 14:12:59.706446 14408 trainer.py:139] Epoch[727/1000] loss: 0.1996265694499016
I0803 14:13:16.631413 14408 trainer.py:139] Epoch[728/1000] loss: 0.1998379949480295
I0803 14:13:33.402102 14408 trainer.py:139] Epoch[729/1000] loss: 0.19922164231538772
I0803 14:13:50.488920 14408 trainer.py:139] Epoch[730/1000] loss: 0.19858369380235671
I0803 14:14:07.363504 14408 trainer.py:139] Epoch[731/1000] loss: 0.19974060393869877
I0803 14:14:24.332179 14408 trainer.py:139] Epoch[732/1000] loss: 0.20058521591126918
I0803 14:14:41.455650 14408 trainer.py:139] Epoch[733/1000] loss: 0.20038923993706703
I0803 14:14:58.251866 14408 trainer.py:139] Epoch[734/1000] loss: 0.2006450068205595
I0803 14:15:15.556590 14408 trainer.py:139] Epoch[735/1000] loss: 0.20007861889898776
I0803 14:15:32.851739 14408 trainer.py:139] Epoch[736/1000] loss: 0.2003637056797743
I0803 14:15:49.553041 14408 trainer.py:139] Epoch[737/1000] loss: 0.19990735314786434
I0803 14:16:06.556409 14408 trainer.py:139] Epoch[738/1000] loss: 0.20001605115830898
I0803 14:16:23.426562 14408 trainer.py:139] Epoch[739/1000] loss: 0.19989785067737104
I0803 14:16:40.320772 14408 trainer.py:139] Epoch[740/1000] loss: 0.19887276105582713
I0803 14:16:56.939018 14408 trainer.py:139] Epoch[741/1000] loss: 0.20010766796767712
I0803 14:17:13.724985 14408 trainer.py:139] Epoch[742/1000] loss: 0.20005524381995202
I0803 14:17:31.098898 14408 trainer.py:139] Epoch[743/1000] loss: 0.1999842669814825
I0803 14:17:48.333863 14408 trainer.py:139] Epoch[744/1000] loss: 0.19998934492468834
I0803 14:18:05.030112 14408 trainer.py:139] Epoch[745/1000] loss: 0.20122357308864594
I0803 14:18:21.923015 14408 trainer.py:139] Epoch[746/1000] loss: 0.19955278970301152
I0803 14:18:38.799069 14408 trainer.py:139] Epoch[747/1000] loss: 0.20096417106688022
I0803 14:18:55.367524 14408 trainer.py:139] Epoch[748/1000] loss: 0.2000949777662754
I0803 14:19:12.202987 14408 trainer.py:139] Epoch[749/1000] loss: 0.19969098567962645
I0803 14:19:12.814503 14408 trainer.py:145] Test: [{'precision': 0.20120200333889812, 'recall': 0.2849528763107439, 'hit_ratio': 0.9146911519198665, 'ndcg': 0.31836063330822506}]
I0803 14:19:29.448029 14408 trainer.py:139] Epoch[750/1000] loss: 0.1992375638335943
I0803 14:19:46.222695 14408 trainer.py:139] Epoch[751/1000] loss: 0.19927605167031287
I0803 14:20:03.397252 14408 trainer.py:139] Epoch[752/1000] loss: 0.20007336959242822
I0803 14:20:20.552825 14408 trainer.py:139] Epoch[753/1000] loss: 0.20113882087171078
I0803 14:20:37.509138 14408 trainer.py:139] Epoch[754/1000] loss: 0.1984204314649105
I0803 14:20:54.117672 14408 trainer.py:139] Epoch[755/1000] loss: 0.19877633564174174
I0803 14:21:11.232656 14408 trainer.py:139] Epoch[756/1000] loss: 0.19971099719405175
I0803 14:21:28.239306 14408 trainer.py:139] Epoch[757/1000] loss: 0.20057932287454605
I0803 14:21:45.033498 14408 trainer.py:139] Epoch[758/1000] loss: 0.19991576820611953
I0803 14:22:02.168813 14408 trainer.py:139] Epoch[759/1000] loss: 0.199515962600708
I0803 14:22:19.114518 14408 trainer.py:139] Epoch[760/1000] loss: 0.19959102161228656
I0803 14:22:36.069212 14408 trainer.py:139] Epoch[761/1000] loss: 0.19942495822906495
I0803 14:22:52.831395 14408 trainer.py:139] Epoch[762/1000] loss: 0.19962495937943459
I0803 14:23:10.082328 14408 trainer.py:139] Epoch[763/1000] loss: 0.19941701404750348
I0803 14:23:27.375591 14408 trainer.py:139] Epoch[764/1000] loss: 0.20013757571578025
I0803 14:23:44.543400 14408 trainer.py:139] Epoch[765/1000] loss: 0.1995063241571188
I0803 14:24:01.485175 14408 trainer.py:139] Epoch[766/1000] loss: 0.19993420727550984
I0803 14:24:18.618027 14408 trainer.py:139] Epoch[767/1000] loss: 0.20034448020160198
I0803 14:24:35.511126 14408 trainer.py:139] Epoch[768/1000] loss: 0.20009303763508796
I0803 14:24:52.228730 14408 trainer.py:139] Epoch[769/1000] loss: 0.19902155175805092
I0803 14:25:09.053751 14408 trainer.py:139] Epoch[770/1000] loss: 0.19917962849140167
I0803 14:25:25.540562 14408 trainer.py:139] Epoch[771/1000] loss: 0.19913443215191365
I0803 14:25:42.017962 14408 trainer.py:139] Epoch[772/1000] loss: 0.19862659461796284
I0803 14:25:58.717061 14408 trainer.py:139] Epoch[773/1000] loss: 0.20067054815590382
I0803 14:26:15.880081 14408 trainer.py:139] Epoch[774/1000] loss: 0.19978179261088372
I0803 14:26:32.928805 14408 trainer.py:139] Epoch[775/1000] loss: 0.19906189553439618
I0803 14:26:49.979335 14408 trainer.py:139] Epoch[776/1000] loss: 0.1991689123213291
I0803 14:27:07.116022 14408 trainer.py:139] Epoch[777/1000] loss: 0.19949757754802705
I0803 14:27:23.884362 14408 trainer.py:139] Epoch[778/1000] loss: 0.19838739819824697
I0803 14:27:41.036237 14408 trainer.py:139] Epoch[779/1000] loss: 0.198842416331172
I0803 14:27:58.376551 14408 trainer.py:139] Epoch[780/1000] loss: 0.1983589969575405
I0803 14:28:15.251993 14408 trainer.py:139] Epoch[781/1000] loss: 0.19919713102281095
I0803 14:28:32.273842 14408 trainer.py:139] Epoch[782/1000] loss: 0.19904003702104092
I0803 14:28:49.206654 14408 trainer.py:139] Epoch[783/1000] loss: 0.1991641480475664
I0803 14:29:05.761326 14408 trainer.py:139] Epoch[784/1000] loss: 0.1986727837473154
I0803 14:29:22.954795 14408 trainer.py:139] Epoch[785/1000] loss: 0.19919363558292388
I0803 14:29:40.089168 14408 trainer.py:139] Epoch[786/1000] loss: 0.1989608071744442
I0803 14:29:57.160624 14408 trainer.py:139] Epoch[787/1000] loss: 0.19976165294647216
I0803 14:30:14.167879 14408 trainer.py:139] Epoch[788/1000] loss: 0.19951230362057687
I0803 14:30:31.187006 14408 trainer.py:139] Epoch[789/1000] loss: 0.19926298186182975
I0803 14:30:47.961805 14408 trainer.py:139] Epoch[790/1000] loss: 0.19863415695726871
I0803 14:31:04.396022 14408 trainer.py:139] Epoch[791/1000] loss: 0.19939417876303195
I0803 14:31:21.376542 14408 trainer.py:139] Epoch[792/1000] loss: 0.19954019114375116
I0803 14:31:38.466144 14408 trainer.py:139] Epoch[793/1000] loss: 0.19850941002368927
I0803 14:31:55.034999 14408 trainer.py:139] Epoch[794/1000] loss: 0.19984176717698574
I0803 14:32:12.532346 14408 trainer.py:139] Epoch[795/1000] loss: 0.19924392364919186
I0803 14:32:29.553951 14408 trainer.py:139] Epoch[796/1000] loss: 0.20010698214173317
I0803 14:32:46.818384 14408 trainer.py:139] Epoch[797/1000] loss: 0.19906664788722991
I0803 14:33:03.976555 14408 trainer.py:139] Epoch[798/1000] loss: 0.19939923398196696
I0803 14:33:21.805881 14408 trainer.py:139] Epoch[799/1000] loss: 0.19840193279087542
I0803 14:33:22.413847 14408 trainer.py:145] Test: [{'precision': 0.20188647746243737, 'recall': 0.2858708800256334, 'hit_ratio': 0.9153589315525876, 'ndcg': 0.3195547473293851}]
I0803 14:33:39.841471 14408 trainer.py:139] Epoch[800/1000] loss: 0.19860388711094856
I0803 14:33:57.467039 14408 trainer.py:139] Epoch[801/1000] loss: 0.19970175065100193
I0803 14:34:14.684186 14408 trainer.py:139] Epoch[802/1000] loss: 0.1991074237972498
I0803 14:34:32.088044 14408 trainer.py:139] Epoch[803/1000] loss: 0.1990009367465973
I0803 14:34:49.301042 14408 trainer.py:139] Epoch[804/1000] loss: 0.20003316849470137
I0803 14:35:06.695224 14408 trainer.py:139] Epoch[805/1000] loss: 0.1985067255795002
I0803 14:35:24.139770 14408 trainer.py:139] Epoch[806/1000] loss: 0.1990716703236103
I0803 14:35:41.788297 14408 trainer.py:139] Epoch[807/1000] loss: 0.19944268837571144
I0803 14:35:58.887697 14408 trainer.py:139] Epoch[808/1000] loss: 0.19875637255609035
I0803 14:36:16.030738 14408 trainer.py:139] Epoch[809/1000] loss: 0.19913039542734623
I0803 14:36:33.099191 14408 trainer.py:139] Epoch[810/1000] loss: 0.1993016429245472
I0803 14:36:50.406895 14408 trainer.py:139] Epoch[811/1000] loss: 0.19907124601304532
I0803 14:37:07.789981 14408 trainer.py:139] Epoch[812/1000] loss: 0.19907255955040454
I0803 14:37:24.795744 14408 trainer.py:139] Epoch[813/1000] loss: 0.19925231970846652
I0803 14:37:41.814340 14408 trainer.py:139] Epoch[814/1000] loss: 0.19930853880941868
I0803 14:37:58.846814 14408 trainer.py:139] Epoch[815/1000] loss: 0.19838110245764257
I0803 14:38:15.912873 14408 trainer.py:139] Epoch[816/1000] loss: 0.19887180998921394
I0803 14:38:32.781101 14408 trainer.py:139] Epoch[817/1000] loss: 0.1984893884509802
I0803 14:38:50.114460 14408 trainer.py:139] Epoch[818/1000] loss: 0.19846094250679017
I0803 14:39:07.211291 14408 trainer.py:139] Epoch[819/1000] loss: 0.19906047992408277
I0803 14:39:24.590518 14408 trainer.py:139] Epoch[820/1000] loss: 0.19936523027718067
I0803 14:39:41.848555 14408 trainer.py:139] Epoch[821/1000] loss: 0.1988239787518978
I0803 14:39:58.771942 14408 trainer.py:139] Epoch[822/1000] loss: 0.1981745108962059
I0803 14:40:15.558991 14408 trainer.py:139] Epoch[823/1000] loss: 0.19868524745106697
I0803 14:40:32.590434 14408 trainer.py:139] Epoch[824/1000] loss: 0.19840448088943957
I0803 14:40:49.390901 14408 trainer.py:139] Epoch[825/1000] loss: 0.1982699863612652
I0803 14:41:06.239715 14408 trainer.py:139] Epoch[826/1000] loss: 0.19955638013780116
I0803 14:41:23.124816 14408 trainer.py:139] Epoch[827/1000] loss: 0.19837925098836423
I0803 14:41:40.168748 14408 trainer.py:139] Epoch[828/1000] loss: 0.19937109015882015
I0803 14:41:57.094356 14408 trainer.py:139] Epoch[829/1000] loss: 0.19851299077272416
I0803 14:42:14.159634 14408 trainer.py:139] Epoch[830/1000] loss: 0.19920986220240594
I0803 14:42:31.171838 14408 trainer.py:139] Epoch[831/1000] loss: 0.19786126911640167
I0803 14:42:48.088800 14408 trainer.py:139] Epoch[832/1000] loss: 0.19898738749325276
I0803 14:43:04.947022 14408 trainer.py:139] Epoch[833/1000] loss: 0.19859781637787818
I0803 14:43:21.756462 14408 trainer.py:139] Epoch[834/1000] loss: 0.19799500964581968
I0803 14:43:38.367076 14408 trainer.py:139] Epoch[835/1000] loss: 0.1974211923778057
I0803 14:43:54.918158 14408 trainer.py:139] Epoch[836/1000] loss: 0.19838864915072918
I0803 14:44:11.917665 14408 trainer.py:139] Epoch[837/1000] loss: 0.19944948889315128
I0803 14:44:28.863420 14408 trainer.py:139] Epoch[838/1000] loss: 0.1978325229138136
I0803 14:44:46.301636 14408 trainer.py:139] Epoch[839/1000] loss: 0.20014039501547815
I0803 14:45:03.283071 14408 trainer.py:139] Epoch[840/1000] loss: 0.1983336377888918
I0803 14:45:20.264089 14408 trainer.py:139] Epoch[841/1000] loss: 0.19889892488718033
I0803 14:45:37.064250 14408 trainer.py:139] Epoch[842/1000] loss: 0.1986187919974327
I0803 14:45:54.204863 14408 trainer.py:139] Epoch[843/1000] loss: 0.19866276867687702
I0803 14:46:11.209308 14408 trainer.py:139] Epoch[844/1000] loss: 0.19864039085805416
I0803 14:46:28.171198 14408 trainer.py:139] Epoch[845/1000] loss: 0.19901653192937374
I0803 14:46:45.058043 14408 trainer.py:139] Epoch[846/1000] loss: 0.19826483726501465
I0803 14:47:02.044898 14408 trainer.py:139] Epoch[847/1000] loss: 0.2000918172299862
I0803 14:47:19.011798 14408 trainer.py:139] Epoch[848/1000] loss: 0.1983435597270727
I0803 14:47:36.089173 14408 trainer.py:139] Epoch[849/1000] loss: 0.19914664477109909
I0803 14:47:36.741990 14408 trainer.py:145] Test: [{'precision': 0.20188647746243737, 'recall': 0.28632203376777393, 'hit_ratio': 0.9151919866444074, 'ndcg': 0.31919555303022906}]
I0803 14:47:53.901962 14408 trainer.py:139] Epoch[850/1000] loss: 0.1985853135585785
I0803 14:48:10.976100 14408 trainer.py:139] Epoch[851/1000] loss: 0.1974440310150385
I0803 14:48:28.273063 14408 trainer.py:139] Epoch[852/1000] loss: 0.19869208075106143
I0803 14:48:45.060543 14408 trainer.py:139] Epoch[853/1000] loss: 0.19700062461197376
I0803 14:49:02.321040 14408 trainer.py:139] Epoch[854/1000] loss: 0.19816909693181514
I0803 14:49:19.040071 14408 trainer.py:139] Epoch[855/1000] loss: 0.19679012298583984
I0803 14:49:35.715811 14408 trainer.py:139] Epoch[856/1000] loss: 0.19908899553120135
I0803 14:49:52.641134 14408 trainer.py:139] Epoch[857/1000] loss: 0.19735483042895793
I0803 14:50:09.335075 14408 trainer.py:139] Epoch[858/1000] loss: 0.19805372208356858
I0803 14:50:26.288154 14408 trainer.py:139] Epoch[859/1000] loss: 0.19795541986823081
I0803 14:50:43.448835 14408 trainer.py:139] Epoch[860/1000] loss: 0.19877874106168747
I0803 14:51:00.101118 14408 trainer.py:139] Epoch[861/1000] loss: 0.19894885942339896
I0803 14:51:17.333393 14408 trainer.py:139] Epoch[862/1000] loss: 0.19796952828764916
I0803 14:51:34.300148 14408 trainer.py:139] Epoch[863/1000] loss: 0.19912635460495948
I0803 14:51:51.593980 14408 trainer.py:139] Epoch[864/1000] loss: 0.19928852505981923
I0803 14:52:08.586965 14408 trainer.py:139] Epoch[865/1000] loss: 0.1982223991304636
I0803 14:52:25.615147 14408 trainer.py:139] Epoch[866/1000] loss: 0.20018710047006608
I0803 14:52:42.666231 14408 trainer.py:139] Epoch[867/1000] loss: 0.19757703579962255
I0803 14:52:59.642754 14408 trainer.py:139] Epoch[868/1000] loss: 0.1979697708040476
I0803 14:53:16.693780 14408 trainer.py:139] Epoch[869/1000] loss: 0.19865773059427738
I0803 14:53:34.164827 14408 trainer.py:139] Epoch[870/1000] loss: 0.19896529465913773
I0803 14:53:51.221053 14408 trainer.py:139] Epoch[871/1000] loss: 0.1991456810384989
I0803 14:54:08.055817 14408 trainer.py:139] Epoch[872/1000] loss: 0.19899627491831778
I0803 14:54:24.853350 14408 trainer.py:139] Epoch[873/1000] loss: 0.19923108033835887
I0803 14:54:41.680923 14408 trainer.py:139] Epoch[874/1000] loss: 0.19838958382606506
I0803 14:54:58.733016 14408 trainer.py:139] Epoch[875/1000] loss: 0.1987868756055832
I0803 14:55:15.472076 14408 trainer.py:139] Epoch[876/1000] loss: 0.1986225288361311
I0803 14:55:32.146605 14408 trainer.py:139] Epoch[877/1000] loss: 0.198549285531044
I0803 14:55:48.944778 14408 trainer.py:139] Epoch[878/1000] loss: 0.19896095842123032
I0803 14:56:06.138751 14408 trainer.py:139] Epoch[879/1000] loss: 0.19838168546557428
I0803 14:56:23.127134 14408 trainer.py:139] Epoch[880/1000] loss: 0.19883094131946563
I0803 14:56:40.188559 14408 trainer.py:139] Epoch[881/1000] loss: 0.198380795866251
I0803 14:56:57.117467 14408 trainer.py:139] Epoch[882/1000] loss: 0.19848752617836
I0803 14:57:14.100672 14408 trainer.py:139] Epoch[883/1000] loss: 0.19814180620014668
I0803 14:57:31.084207 14408 trainer.py:139] Epoch[884/1000] loss: 0.19840640276670457
I0803 14:57:48.252358 14408 trainer.py:139] Epoch[885/1000] loss: 0.19827234894037246
I0803 14:58:05.329578 14408 trainer.py:139] Epoch[886/1000] loss: 0.19803062044084072
I0803 14:58:22.136488 14408 trainer.py:139] Epoch[887/1000] loss: 0.19765721037983894
I0803 14:58:39.185923 14408 trainer.py:139] Epoch[888/1000] loss: 0.19729212820529937
I0803 14:58:55.625986 14408 trainer.py:139] Epoch[889/1000] loss: 0.19854937084019184
I0803 14:59:12.525803 14408 trainer.py:139] Epoch[890/1000] loss: 0.1979286026209593
I0803 14:59:30.004908 14408 trainer.py:139] Epoch[891/1000] loss: 0.19854559563100338
I0803 14:59:47.635133 14408 trainer.py:139] Epoch[892/1000] loss: 0.197760770842433
I0803 15:00:05.442989 14408 trainer.py:139] Epoch[893/1000] loss: 0.19866874255239964
I0803 15:00:23.653360 14408 trainer.py:139] Epoch[894/1000] loss: 0.19782833717763423
I0803 15:00:40.871344 14408 trainer.py:139] Epoch[895/1000] loss: 0.19922262392938136
I0803 15:00:58.012395 14408 trainer.py:139] Epoch[896/1000] loss: 0.19800172857940196
I0803 15:01:14.908569 14408 trainer.py:139] Epoch[897/1000] loss: 0.19725265800952912
I0803 15:01:31.915307 14408 trainer.py:139] Epoch[898/1000] loss: 0.19838916026055814
I0803 15:01:48.521641 14408 trainer.py:139] Epoch[899/1000] loss: 0.198257914185524
I0803 15:01:49.080303 14408 trainer.py:145] Test: [{'precision': 0.20228714524207012, 'recall': 0.28635196385748946, 'hit_ratio': 0.9158597662771285, 'ndcg': 0.3200647606828299}]
I0803 15:02:06.432693 14408 trainer.py:139] Epoch[900/1000] loss: 0.19869102574884892
I0803 15:02:23.452577 14408 trainer.py:139] Epoch[901/1000] loss: 0.19765978008508683
I0803 15:02:40.713320 14408 trainer.py:139] Epoch[902/1000] loss: 0.19823814369738102
I0803 15:02:57.568809 14408 trainer.py:139] Epoch[903/1000] loss: 0.1980723947286606
I0803 15:03:15.178302 14408 trainer.py:139] Epoch[904/1000] loss: 0.1970516037195921
I0803 15:03:32.376355 14408 trainer.py:139] Epoch[905/1000] loss: 0.197288179397583
I0803 15:03:49.874043 14408 trainer.py:139] Epoch[906/1000] loss: 0.19781264662742615
I0803 15:04:06.736476 14408 trainer.py:139] Epoch[907/1000] loss: 0.19858768470585347
I0803 15:04:24.259736 14408 trainer.py:139] Epoch[908/1000] loss: 0.19779598377645016
I0803 15:04:41.360513 14408 trainer.py:139] Epoch[909/1000] loss: 0.19790802597999574
I0803 15:04:58.891996 14408 trainer.py:139] Epoch[910/1000] loss: 0.1981682438403368
I0803 15:05:18.232833 14408 trainer.py:139] Epoch[911/1000] loss: 0.19808804355561732
I0803 15:05:38.118593 14408 trainer.py:139] Epoch[912/1000] loss: 0.1990354899317026
I0803 15:05:58.275028 14408 trainer.py:139] Epoch[913/1000] loss: 0.19840172529220582
I0803 15:06:17.786781 14408 trainer.py:139] Epoch[914/1000] loss: 0.19865207076072694
I0803 15:06:36.669879 14408 trainer.py:139] Epoch[915/1000] loss: 0.19884508140385151
I0803 15:06:55.955399 14408 trainer.py:139] Epoch[916/1000] loss: 0.19901596046984196
I0803 15:07:15.188932 14408 trainer.py:139] Epoch[917/1000] loss: 0.19666136391460895
I0803 15:07:34.840360 14408 trainer.py:139] Epoch[918/1000] loss: 0.19793948605656625
I0803 15:07:57.876616 14408 trainer.py:139] Epoch[919/1000] loss: 0.19834295175969602
I0803 15:08:17.943932 14408 trainer.py:139] Epoch[920/1000] loss: 0.19791083857417108
I0803 15:08:37.077083 14408 trainer.py:139] Epoch[921/1000] loss: 0.1984660305082798
I0803 15:08:56.357437 14408 trainer.py:139] Epoch[922/1000] loss: 0.19783277101814747
I0803 15:09:15.333596 14408 trainer.py:139] Epoch[923/1000] loss: 0.19715666435658932
I0803 15:09:34.973644 14408 trainer.py:139] Epoch[924/1000] loss: 0.19792002849280835
I0803 15:09:54.071503 14408 trainer.py:139] Epoch[925/1000] loss: 0.19698582626879216
I0803 15:10:13.421700 14408 trainer.py:139] Epoch[926/1000] loss: 0.19766076430678367
I0803 15:10:32.257467 14408 trainer.py:139] Epoch[927/1000] loss: 0.19779745638370513
I0803 15:10:51.561828 14408 trainer.py:139] Epoch[928/1000] loss: 0.1982247307896614
I0803 15:11:10.283606 14408 trainer.py:139] Epoch[929/1000] loss: 0.19803292192518712
I0803 15:11:29.958894 14408 trainer.py:139] Epoch[930/1000] loss: 0.19872829578816892
I0803 15:11:49.314830 14408 trainer.py:139] Epoch[931/1000] loss: 0.19817126356065273
I0803 15:12:08.557450 14408 trainer.py:139] Epoch[932/1000] loss: 0.19848487973213197
I0803 15:12:28.119347 14408 trainer.py:139] Epoch[933/1000] loss: 0.1978095643222332
I0803 15:12:47.236597 14408 trainer.py:139] Epoch[934/1000] loss: 0.19764546528458596
I0803 15:13:06.254241 14408 trainer.py:139] Epoch[935/1000] loss: 0.19792155958712102
I0803 15:13:25.058404 14408 trainer.py:139] Epoch[936/1000] loss: 0.19801958575844764
I0803 15:13:43.651613 14408 trainer.py:139] Epoch[937/1000] loss: 0.19824806228280067
I0803 15:14:02.660350 14408 trainer.py:139] Epoch[938/1000] loss: 0.19770714603364467
I0803 15:14:21.430289 14408 trainer.py:139] Epoch[939/1000] loss: 0.19929799139499665
I0803 15:14:40.629461 14408 trainer.py:139] Epoch[940/1000] loss: 0.19855527505278586
I0803 15:15:00.324436 14408 trainer.py:139] Epoch[941/1000] loss: 0.19786919504404069
I0803 15:15:19.554033 14408 trainer.py:139] Epoch[942/1000] loss: 0.1975981317460537
I0803 15:15:38.472452 14408 trainer.py:139] Epoch[943/1000] loss: 0.19734147377312183
I0803 15:15:57.321945 14408 trainer.py:139] Epoch[944/1000] loss: 0.19852385558187963
I0803 15:16:16.145738 14408 trainer.py:139] Epoch[945/1000] loss: 0.19833259098231792
I0803 15:16:34.993626 14408 trainer.py:139] Epoch[946/1000] loss: 0.19804526194930078
I0803 15:16:54.448426 14408 trainer.py:139] Epoch[947/1000] loss: 0.19788433127105237
I0803 15:17:13.933872 14408 trainer.py:139] Epoch[948/1000] loss: 0.19774903543293476
I0803 15:17:32.644123 14408 trainer.py:139] Epoch[949/1000] loss: 0.19847299270331858
I0803 15:17:33.221735 14408 trainer.py:145] Test: [{'precision': 0.20235392320534226, 'recall': 0.2870963907420405, 'hit_ratio': 0.9161936560934891, 'ndcg': 0.32052000224412713}]
I0803 15:17:50.993605 14408 trainer.py:139] Epoch[950/1000] loss: 0.19792707934975623
I0803 15:18:08.898755 14408 trainer.py:139] Epoch[951/1000] loss: 0.19780367463827134
I0803 15:18:27.304434 14408 trainer.py:139] Epoch[952/1000] loss: 0.19846573173999787
I0803 15:18:47.215394 14408 trainer.py:139] Epoch[953/1000] loss: 0.19693093225359917
I0803 15:19:05.361464 14408 trainer.py:139] Epoch[954/1000] loss: 0.19793168120086194
I0803 15:19:23.715439 14408 trainer.py:139] Epoch[955/1000] loss: 0.1976367522031069
I0803 15:19:41.988734 14408 trainer.py:139] Epoch[956/1000] loss: 0.19768499433994294
I0803 15:20:00.477092 14408 trainer.py:139] Epoch[957/1000] loss: 0.19778166823089122
I0803 15:20:19.178188 14408 trainer.py:139] Epoch[958/1000] loss: 0.19809957779943943
I0803 15:20:37.485692 14408 trainer.py:139] Epoch[959/1000] loss: 0.198505524918437
I0803 15:20:55.907889 14408 trainer.py:139] Epoch[960/1000] loss: 0.19825817719101907
I0803 15:21:14.153751 14408 trainer.py:139] Epoch[961/1000] loss: 0.1973713044077158
I0803 15:21:32.003134 14408 trainer.py:139] Epoch[962/1000] loss: 0.19752739891409873
I0803 15:21:50.299012 14408 trainer.py:139] Epoch[963/1000] loss: 0.19808219447731973
I0803 15:22:08.812641 14408 trainer.py:139] Epoch[964/1000] loss: 0.1972721040248871
I0803 15:22:27.485137 14408 trainer.py:139] Epoch[965/1000] loss: 0.19727069959044458
I0803 15:22:46.378283 14408 trainer.py:139] Epoch[966/1000] loss: 0.19813962206244468
I0803 15:23:04.321080 14408 trainer.py:139] Epoch[967/1000] loss: 0.19751505926251411
I0803 15:23:21.245718 14408 trainer.py:139] Epoch[968/1000] loss: 0.19753201305866241
I0803 15:23:38.102644 14408 trainer.py:139] Epoch[969/1000] loss: 0.19734206311404706
I0803 15:23:55.260127 14408 trainer.py:139] Epoch[970/1000] loss: 0.19793266765773296
I0803 15:24:12.184188 14408 trainer.py:139] Epoch[971/1000] loss: 0.1982257328927517
I0803 15:24:29.365874 14408 trainer.py:139] Epoch[972/1000] loss: 0.19790523499250412
I0803 15:24:46.266946 14408 trainer.py:139] Epoch[973/1000] loss: 0.19714499674737454
I0803 15:25:03.090588 14408 trainer.py:139] Epoch[974/1000] loss: 0.19805986024439334
I0803 15:25:19.934124 14408 trainer.py:139] Epoch[975/1000] loss: 0.1972641833126545
I0803 15:25:36.753838 14408 trainer.py:139] Epoch[976/1000] loss: 0.19701545573771
I0803 15:25:53.446701 14408 trainer.py:139] Epoch[977/1000] loss: 0.19771946147084235
I0803 15:26:10.205435 14408 trainer.py:139] Epoch[978/1000] loss: 0.19742827937006951
I0803 15:26:26.999310 14408 trainer.py:139] Epoch[979/1000] loss: 0.1978663843125105
I0803 15:26:43.641017 14408 trainer.py:139] Epoch[980/1000] loss: 0.19783152379095553
I0803 15:27:00.167884 14408 trainer.py:139] Epoch[981/1000] loss: 0.1977103989571333
I0803 15:27:16.874838 14408 trainer.py:139] Epoch[982/1000] loss: 0.19742655344307422
I0803 15:27:33.870041 14408 trainer.py:139] Epoch[983/1000] loss: 0.19787946827709674
I0803 15:27:51.029709 14408 trainer.py:139] Epoch[984/1000] loss: 0.19686775393784045
I0803 15:28:07.763676 14408 trainer.py:139] Epoch[985/1000] loss: 0.1981935441493988
I0803 15:28:24.263250 14408 trainer.py:139] Epoch[986/1000] loss: 0.19664158299565315
I0803 15:28:41.197875 14408 trainer.py:139] Epoch[987/1000] loss: 0.1976387333124876
I0803 15:28:57.953276 14408 trainer.py:139] Epoch[988/1000] loss: 0.19721575118601323
I0803 15:29:14.917019 14408 trainer.py:139] Epoch[989/1000] loss: 0.1985512427985668
I0803 15:29:31.774315 14408 trainer.py:139] Epoch[990/1000] loss: 0.19771391935646535
I0803 15:29:48.559867 14408 trainer.py:139] Epoch[991/1000] loss: 0.19670489132404329
I0803 15:30:05.386342 14408 trainer.py:139] Epoch[992/1000] loss: 0.19704975709319114
I0803 15:30:22.253588 14408 trainer.py:139] Epoch[993/1000] loss: 0.19726084172725677
I0803 15:30:39.136620 14408 trainer.py:139] Epoch[994/1000] loss: 0.19713807813823223
I0803 15:30:56.291986 14408 trainer.py:139] Epoch[995/1000] loss: 0.19765433184802533
I0803 15:31:13.355076 14408 trainer.py:139] Epoch[996/1000] loss: 0.19853470101952553
I0803 15:31:30.489949 14408 trainer.py:139] Epoch[997/1000] loss: 0.19742249250411986
I0803 15:31:47.237581 14408 trainer.py:139] Epoch[998/1000] loss: 0.19793234691023825
I0803 15:32:04.002410 14408 trainer.py:139] Epoch[999/1000] loss: 0.19807683378458024
I0803 15:32:04.618322 14408 trainer.py:145] Test: [{'precision': 0.2021786310517529, 'recall': 0.2868770988309142, 'hit_ratio': 0.9158597662771285, 'ndcg': 0.3206944443837549}]
