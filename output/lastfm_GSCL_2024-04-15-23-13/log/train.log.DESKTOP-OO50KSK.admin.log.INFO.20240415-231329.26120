I0427 10:15:48.322655 28032 trainer.py:118] Test: [{'precision': 0.024986595174262712, 'recall': 0.057897299961248844, 'hit_ratio': 0.3249329758713137, 'ndcg': 0.04584296328910265}]
I0427 10:15:50.354978 28032 trainer.py:136] Epoch[0/1000] loss: 0.63701198498408
I0427 10:15:52.388306 28032 trainer.py:136] Epoch[1/1000] loss: 0.5378512607680427
I0427 10:15:54.664828 28032 trainer.py:136] Epoch[2/1000] loss: 0.5011442369884915
I0427 10:15:56.752845 28032 trainer.py:136] Epoch[3/1000] loss: 0.4759041236506568
I0427 10:15:58.811211 28032 trainer.py:136] Epoch[4/1000] loss: 0.46445992588996887
I0427 10:16:01.167446 28032 trainer.py:136] Epoch[5/1000] loss: 0.44867075483004254
I0427 10:16:03.355347 28032 trainer.py:136] Epoch[6/1000] loss: 0.4516908559534285
I0427 10:16:05.493817 28032 trainer.py:136] Epoch[7/1000] loss: 0.4311221308178372
I0427 10:16:07.619663 28032 trainer.py:136] Epoch[8/1000] loss: 0.4290342264705234
I0427 10:16:09.872046 28032 trainer.py:136] Epoch[9/1000] loss: 0.42579083972507054
I0427 10:16:12.208379 28032 trainer.py:136] Epoch[10/1000] loss: 0.4181029465463426
I0427 10:16:14.513979 28032 trainer.py:136] Epoch[11/1000] loss: 0.4031997124354045
I0427 10:16:16.774570 28032 trainer.py:136] Epoch[12/1000] loss: 0.41199181146091884
I0427 10:16:19.000298 28032 trainer.py:136] Epoch[13/1000] loss: 0.3945968581570519
I0427 10:16:21.210100 28032 trainer.py:136] Epoch[14/1000] loss: 0.3895915514893002
I0427 10:16:23.739353 28032 trainer.py:136] Epoch[15/1000] loss: 0.3995491001341078
I0427 10:16:25.856422 28032 trainer.py:136] Epoch[16/1000] loss: 0.37637797991434735
I0427 10:16:27.967453 28032 trainer.py:136] Epoch[17/1000] loss: 0.377404295735889
I0427 10:16:30.114266 28032 trainer.py:136] Epoch[18/1000] loss: 0.3708227872848511
I0427 10:16:32.341923 28032 trainer.py:136] Epoch[19/1000] loss: 0.3722739881939358
I0427 10:16:34.561309 28032 trainer.py:136] Epoch[20/1000] loss: 0.3628556728363037
I0427 10:16:36.724189 28032 trainer.py:136] Epoch[21/1000] loss: 0.3665231201383803
I0427 10:16:39.094429 28032 trainer.py:136] Epoch[22/1000] loss: 0.35872629947132534
I0427 10:16:41.255357 28032 trainer.py:136] Epoch[23/1000] loss: 0.35276445415284896
I0427 10:16:43.432598 28032 trainer.py:136] Epoch[24/1000] loss: 0.3444153401586745
I0427 10:16:45.605029 28032 trainer.py:136] Epoch[25/1000] loss: 0.3383936716450585
I0427 10:16:47.828520 28032 trainer.py:136] Epoch[26/1000] loss: 0.33344607551892597
I0427 10:16:49.935606 28032 trainer.py:136] Epoch[27/1000] loss: 0.32859118779500324
I0427 10:16:52.183258 28032 trainer.py:136] Epoch[28/1000] loss: 0.3218057122495439
I0427 10:16:54.652733 28032 trainer.py:136] Epoch[29/1000] loss: 0.3337733679347568
I0427 10:16:56.886409 28032 trainer.py:136] Epoch[30/1000] loss: 0.32530590560701156
I0427 10:16:59.138980 28032 trainer.py:136] Epoch[31/1000] loss: 0.32357309261957806
I0427 10:17:01.257456 28032 trainer.py:136] Epoch[32/1000] loss: 0.31000075737635296
I0427 10:17:03.413732 28032 trainer.py:136] Epoch[33/1000] loss: 0.31310544080204433
I0427 10:17:05.605743 28032 trainer.py:136] Epoch[34/1000] loss: 0.2996521128548516
I0427 10:17:07.810847 28032 trainer.py:136] Epoch[35/1000] loss: 0.3105617165565491
I0427 10:17:09.943870 28032 trainer.py:136] Epoch[36/1000] loss: 0.3011488947603438
I0427 10:17:12.127911 28032 trainer.py:136] Epoch[37/1000] loss: 0.29981664485401577
I0427 10:17:14.259902 28032 trainer.py:136] Epoch[38/1000] loss: 0.2934728529718187
I0427 10:17:16.520017 28032 trainer.py:136] Epoch[39/1000] loss: 0.2902819017569224
I0427 10:17:18.817467 28032 trainer.py:136] Epoch[40/1000] loss: 0.289716684155994
I0427 10:17:21.016264 28032 trainer.py:136] Epoch[41/1000] loss: 0.2878145178159078
I0427 10:17:23.073537 28032 trainer.py:136] Epoch[42/1000] loss: 0.28210898571544224
I0427 10:17:25.259823 28032 trainer.py:136] Epoch[43/1000] loss: 0.2871321274174584
I0427 10:17:27.396845 28032 trainer.py:136] Epoch[44/1000] loss: 0.2775585419601864
I0427 10:17:29.750216 28032 trainer.py:136] Epoch[45/1000] loss: 0.27528730034828186
I0427 10:17:31.908990 28032 trainer.py:136] Epoch[46/1000] loss: 0.2716377344396379
I0427 10:17:34.052992 28032 trainer.py:136] Epoch[47/1000] loss: 0.2691031363275316
I0427 10:17:36.312055 28032 trainer.py:136] Epoch[48/1000] loss: 0.26353266338507336
I0427 10:17:38.527927 28032 trainer.py:136] Epoch[49/1000] loss: 0.26838090684678817
I0427 10:17:38.683407 28032 trainer.py:142] Test: [{'precision': 0.10327077747989283, 'recall': 0.24023303121907452, 'hit_ratio': 0.7860589812332439, 'ndcg': 0.2275199133460721}]
I0427 10:17:40.815398 28032 trainer.py:136] Epoch[50/1000] loss: 0.27028127511342365
I0427 10:17:43.019132 28032 trainer.py:136] Epoch[51/1000] loss: 0.25863000916110146
I0427 10:17:45.282041 28032 trainer.py:136] Epoch[52/1000] loss: 0.2552732229232788
I0427 10:17:47.551553 28032 trainer.py:136] Epoch[53/1000] loss: 0.26283471120728386
I0427 10:17:49.735597 28032 trainer.py:136] Epoch[54/1000] loss: 0.26276443401972455
I0427 10:17:51.918797 28032 trainer.py:136] Epoch[55/1000] loss: 0.2691360314687093
I0427 10:17:54.089722 28032 trainer.py:136] Epoch[56/1000] loss: 0.2593089822265837
I0427 10:17:56.261807 28032 trainer.py:136] Epoch[57/1000] loss: 0.2634658151202732
I0427 10:17:58.566797 28032 trainer.py:136] Epoch[58/1000] loss: 0.2542629556523429
I0427 10:18:00.708727 28032 trainer.py:136] Epoch[59/1000] loss: 0.25606170296669006
I0427 10:18:03.096585 28032 trainer.py:136] Epoch[60/1000] loss: 0.24588711559772491
I0427 10:18:05.310288 28032 trainer.py:136] Epoch[61/1000] loss: 0.24080213407675424
I0427 10:18:07.434360 28032 trainer.py:136] Epoch[62/1000] loss: 0.24346043831772274
I0427 10:18:09.626258 28032 trainer.py:136] Epoch[63/1000] loss: 0.246991495291392
I0427 10:18:11.753890 28032 trainer.py:136] Epoch[64/1000] loss: 0.2488945292101966
I0427 10:18:14.008088 28032 trainer.py:136] Epoch[65/1000] loss: 0.2300527592500051
I0427 10:18:16.127094 28032 trainer.py:136] Epoch[66/1000] loss: 0.23891918692323896
I0427 10:18:18.365350 28032 trainer.py:136] Epoch[67/1000] loss: 0.23147201372517479
I0427 10:18:20.477961 28032 trainer.py:136] Epoch[68/1000] loss: 0.23570133248964945
I0427 10:18:22.611969 28032 trainer.py:136] Epoch[69/1000] loss: 0.23682154383924273
I0427 10:18:24.852613 28032 trainer.py:136] Epoch[70/1000] loss: 0.22898220188087887
I0427 10:18:26.982736 28032 trainer.py:136] Epoch[71/1000] loss: 0.231120432416598
I0427 10:18:29.196382 28032 trainer.py:136] Epoch[72/1000] loss: 0.2267016354534361
I0427 10:18:31.344543 28032 trainer.py:136] Epoch[73/1000] loss: 0.22565100093682608
I0427 10:18:33.579502 28032 trainer.py:136] Epoch[74/1000] loss: 0.22451865838633644
I0427 10:18:35.782259 28032 trainer.py:136] Epoch[75/1000] loss: 0.22325053479936388
I0427 10:18:37.905300 28032 trainer.py:136] Epoch[76/1000] loss: 0.2327200108104282
I0427 10:18:40.111076 28032 trainer.py:136] Epoch[77/1000] loss: 0.2195026675860087
I0427 10:18:42.302129 28032 trainer.py:136] Epoch[78/1000] loss: 0.2205595208538903
I0427 10:18:44.361404 28032 trainer.py:136] Epoch[79/1000] loss: 0.2140814099046919
I0427 10:18:46.622533 28032 trainer.py:136] Epoch[80/1000] loss: 0.22665463553534615
I0427 10:18:48.791413 28032 trainer.py:136] Epoch[81/1000] loss: 0.22091905607117546
I0427 10:18:51.035893 28032 trainer.py:136] Epoch[82/1000] loss: 0.2203962504863739
I0427 10:18:53.314208 28032 trainer.py:136] Epoch[83/1000] loss: 0.2060438593228658
I0427 10:18:55.406409 28032 trainer.py:136] Epoch[84/1000] loss: 0.21310579776763916
I0427 10:18:57.626767 28032 trainer.py:136] Epoch[85/1000] loss: 0.2130975474913915
I0427 10:18:59.710961 28032 trainer.py:136] Epoch[86/1000] loss: 0.22283180058002472
I0427 10:19:01.929647 28032 trainer.py:136] Epoch[87/1000] loss: 0.20221637023819816
I0427 10:19:04.041713 28032 trainer.py:136] Epoch[88/1000] loss: 0.20092378722296822
I0427 10:19:06.189029 28032 trainer.py:136] Epoch[89/1000] loss: 0.21132346325450474
I0427 10:19:08.332681 28032 trainer.py:136] Epoch[90/1000] loss: 0.20508350597487557
I0427 10:19:10.703434 28032 trainer.py:136] Epoch[91/1000] loss: 0.2025274998611874
I0427 10:19:12.882493 28032 trainer.py:136] Epoch[92/1000] loss: 0.19760435157352024
I0427 10:19:15.118128 28032 trainer.py:136] Epoch[93/1000] loss: 0.19939213825596702
I0427 10:19:17.439068 28032 trainer.py:136] Epoch[94/1000] loss: 0.1939141203959783
I0427 10:19:19.724587 28032 trainer.py:136] Epoch[95/1000] loss: 0.217169099383884
I0427 10:19:21.915373 28032 trainer.py:136] Epoch[96/1000] loss: 0.1997803052266439
I0427 10:19:24.019528 28032 trainer.py:136] Epoch[97/1000] loss: 0.2007498111989763
I0427 10:19:26.194447 28032 trainer.py:136] Epoch[98/1000] loss: 0.19862456950876448
I0427 10:19:28.351090 28032 trainer.py:136] Epoch[99/1000] loss: 0.19661549727121988
I0427 10:19:28.543020 28032 trainer.py:142] Test: [{'precision': 0.11150134048257382, 'recall': 0.2604152670648493, 'hit_ratio': 0.8273458445040215, 'ndcg': 0.24617110786928437}]
I0427 10:19:30.751732 28032 trainer.py:136] Epoch[100/1000] loss: 0.19844605194197762
I0427 10:19:32.909304 28032 trainer.py:136] Epoch[101/1000] loss: 0.20370071795251635
I0427 10:19:35.121750 28032 trainer.py:136] Epoch[102/1000] loss: 0.19902144538031685
I0427 10:19:37.352300 28032 trainer.py:136] Epoch[103/1000] loss: 0.1914862874481413
I0427 10:19:39.554401 28032 trainer.py:136] Epoch[104/1000] loss: 0.19945871167712742
I0427 10:19:41.653741 28032 trainer.py:136] Epoch[105/1000] loss: 0.19472213917308384
I0427 10:19:44.030470 28032 trainer.py:136] Epoch[106/1000] loss: 0.19118316968282065
I0427 10:19:46.231282 28032 trainer.py:136] Epoch[107/1000] loss: 0.1924409502082401
I0427 10:19:48.390147 28032 trainer.py:136] Epoch[108/1000] loss: 0.18882019486692217
I0427 10:19:50.650275 28032 trainer.py:136] Epoch[109/1000] loss: 0.1893708027071423
I0427 10:19:52.873946 28032 trainer.py:136] Epoch[110/1000] loss: 0.18796306020683712
I0427 10:19:55.029826 28032 trainer.py:136] Epoch[111/1000] loss: 0.19101234277089438
I0427 10:19:57.198909 28032 trainer.py:136] Epoch[112/1000] loss: 0.19099636375904083
I0427 10:19:59.495235 28032 trainer.py:136] Epoch[113/1000] loss: 0.18999579383267295
I0427 10:20:01.729424 28032 trainer.py:136] Epoch[114/1000] loss: 0.18839811782042185
I0427 10:20:03.898068 28032 trainer.py:136] Epoch[115/1000] loss: 0.18688471284177569
I0427 10:20:06.105449 28032 trainer.py:136] Epoch[116/1000] loss: 0.19144540197319454
I0427 10:20:08.203943 28032 trainer.py:136] Epoch[117/1000] loss: 0.1886097921265496
I0427 10:20:10.291918 28032 trainer.py:136] Epoch[118/1000] loss: 0.1811092330349816
I0427 10:20:12.410998 28032 trainer.py:136] Epoch[119/1000] loss: 0.1815645777516895
I0427 10:20:14.514719 28032 trainer.py:136] Epoch[120/1000] loss: 0.17712006635136074
I0427 10:20:16.619910 28032 trainer.py:136] Epoch[121/1000] loss: 0.18108053670989144
I0427 10:20:18.792794 28032 trainer.py:136] Epoch[122/1000] loss: 0.18356475068463218
I0427 10:20:21.172815 28032 trainer.py:136] Epoch[123/1000] loss: 0.18431323270003
I0427 10:20:23.315322 28032 trainer.py:136] Epoch[124/1000] loss: 0.17644636664125654
I0427 10:20:25.486822 28032 trainer.py:136] Epoch[125/1000] loss: 0.18219210704167685
I0427 10:20:27.700612 28032 trainer.py:136] Epoch[126/1000] loss: 0.18134276237752703
I0427 10:20:29.828460 28032 trainer.py:136] Epoch[127/1000] loss: 0.1712071349223455
I0427 10:20:31.939705 28032 trainer.py:136] Epoch[128/1000] loss: 0.17448180748356712
I0427 10:20:34.114826 28032 trainer.py:136] Epoch[129/1000] loss: 0.17883296310901642
I0427 10:20:36.267774 28032 trainer.py:136] Epoch[130/1000] loss: 0.1849988963868883
I0427 10:20:38.462210 28032 trainer.py:136] Epoch[131/1000] loss: 0.17662654982672799
I0427 10:20:40.557360 28032 trainer.py:136] Epoch[132/1000] loss: 0.17100283172395495
I0427 10:20:42.691333 28032 trainer.py:136] Epoch[133/1000] loss: 0.17733689314789242
I0427 10:20:44.914015 28032 trainer.py:136] Epoch[134/1000] loss: 0.17015254331959617
I0427 10:20:47.126725 28032 trainer.py:136] Epoch[135/1000] loss: 0.16660762164327833
I0427 10:20:49.185986 28032 trainer.py:136] Epoch[136/1000] loss: 0.1691167867845959
I0427 10:20:51.510929 28032 trainer.py:136] Epoch[137/1000] loss: 0.17385076814227635
I0427 10:20:53.628960 28032 trainer.py:136] Epoch[138/1000] loss: 0.17409724493821463
I0427 10:20:55.848782 28032 trainer.py:136] Epoch[139/1000] loss: 0.16664567258622912
I0427 10:20:58.063619 28032 trainer.py:136] Epoch[140/1000] loss: 0.17047623958852556
I0427 10:21:00.177682 28032 trainer.py:136] Epoch[141/1000] loss: 0.1701155122783449
I0427 10:21:02.372445 28032 trainer.py:136] Epoch[142/1000] loss: 0.16594685282972124
I0427 10:21:04.611635 28032 trainer.py:136] Epoch[143/1000] loss: 0.1653273751338323
I0427 10:21:06.845254 28032 trainer.py:136] Epoch[144/1000] loss: 0.1605105996131897
I0427 10:21:09.002219 28032 trainer.py:136] Epoch[145/1000] loss: 0.1677142083644867
I0427 10:21:11.096417 28032 trainer.py:136] Epoch[146/1000] loss: 0.16320508387353685
I0427 10:21:13.333270 28032 trainer.py:136] Epoch[147/1000] loss: 0.17135587003495958
I0427 10:21:15.663108 28032 trainer.py:136] Epoch[148/1000] loss: 0.16598915888203514
I0427 10:21:17.836982 28032 trainer.py:136] Epoch[149/1000] loss: 0.1695373406012853
I0427 10:21:18.001433 28032 trainer.py:142] Test: [{'precision': 0.11836461126005371, 'recall': 0.2786249235003376, 'hit_ratio': 0.8466487935656837, 'ndcg': 0.2607895490888791}]
I0427 10:21:20.108604 28032 trainer.py:136] Epoch[150/1000] loss: 0.1579185442792045
I0427 10:21:22.356673 28032 trainer.py:136] Epoch[151/1000] loss: 0.16242503788736132
I0427 10:21:24.682587 28032 trainer.py:136] Epoch[152/1000] loss: 0.16588523983955383
I0427 10:21:26.828601 28032 trainer.py:136] Epoch[153/1000] loss: 0.1670289784669876
I0427 10:21:29.061989 28032 trainer.py:136] Epoch[154/1000] loss: 0.16558404432402718
I0427 10:21:31.293779 28032 trainer.py:136] Epoch[155/1000] loss: 0.15914013816250694
I0427 10:21:33.593536 28032 trainer.py:136] Epoch[156/1000] loss: 0.1605256199836731
I0427 10:21:35.814038 28032 trainer.py:136] Epoch[157/1000] loss: 0.15823261108663347
I0427 10:21:38.072808 28032 trainer.py:136] Epoch[158/1000] loss: 0.16025441553857592
I0427 10:21:40.292556 28032 trainer.py:136] Epoch[159/1000] loss: 0.15764346056514317
I0427 10:21:42.425194 28032 trainer.py:136] Epoch[160/1000] loss: 0.16471981505552927
I0427 10:21:44.575781 28032 trainer.py:136] Epoch[161/1000] loss: 0.15649635758664873
I0427 10:21:46.747144 28032 trainer.py:136] Epoch[162/1000] loss: 0.15853371885087755
I0427 10:21:48.871174 28032 trainer.py:136] Epoch[163/1000] loss: 0.155519747071796
I0427 10:21:50.980302 28032 trainer.py:136] Epoch[164/1000] loss: 0.15726147095362344
I0427 10:21:53.096401 28032 trainer.py:136] Epoch[165/1000] loss: 0.15993302894963157
I0427 10:21:55.195562 28032 trainer.py:136] Epoch[166/1000] loss: 0.15656365123060015
I0427 10:21:57.351916 28032 trainer.py:136] Epoch[167/1000] loss: 0.15872690909438664
I0427 10:21:59.469995 28032 trainer.py:136] Epoch[168/1000] loss: 0.152388044529491
I0427 10:22:01.657704 28032 trainer.py:136] Epoch[169/1000] loss: 0.1520887315273285
I0427 10:22:03.847234 28032 trainer.py:136] Epoch[170/1000] loss: 0.15468977722856733
I0427 10:22:05.991118 28032 trainer.py:136] Epoch[171/1000] loss: 0.15580936272939047
I0427 10:22:08.149721 28032 trainer.py:136] Epoch[172/1000] loss: 0.15385007692707908
I0427 10:22:10.239955 28032 trainer.py:136] Epoch[173/1000] loss: 0.14767684125237995
I0427 10:22:12.430274 28032 trainer.py:136] Epoch[174/1000] loss: 0.14956508576869965
I0427 10:22:14.626859 28032 trainer.py:136] Epoch[175/1000] loss: 0.1595260418123669
I0427 10:22:16.846134 28032 trainer.py:136] Epoch[176/1000] loss: 0.14967984954516092
I0427 10:22:18.908300 28032 trainer.py:136] Epoch[177/1000] loss: 0.15869286325242785
I0427 10:22:21.052826 28032 trainer.py:136] Epoch[178/1000] loss: 0.15589599476920235
I0427 10:22:23.201812 28032 trainer.py:136] Epoch[179/1000] loss: 0.1476128101348877
I0427 10:22:25.339850 28032 trainer.py:136] Epoch[180/1000] loss: 0.153300811847051
I0427 10:22:27.457998 28032 trainer.py:136] Epoch[181/1000] loss: 0.1495780779255761
I0427 10:22:29.679829 28032 trainer.py:136] Epoch[182/1000] loss: 0.15151932173305088
I0427 10:22:31.740399 28032 trainer.py:136] Epoch[183/1000] loss: 0.14522234929932487
I0427 10:22:33.888003 28032 trainer.py:136] Epoch[184/1000] loss: 0.15100042356385124
I0427 10:22:36.087374 28032 trainer.py:136] Epoch[185/1000] loss: 0.15294954677422842
I0427 10:22:38.238610 28032 trainer.py:136] Epoch[186/1000] loss: 0.1445209433635076
I0427 10:22:40.469905 28032 trainer.py:136] Epoch[187/1000] loss: 0.1483331604136361
I0427 10:22:42.826876 28032 trainer.py:136] Epoch[188/1000] loss: 0.14546493937571844
I0427 10:22:44.964720 28032 trainer.py:136] Epoch[189/1000] loss: 0.14600723485151926
I0427 10:22:47.293091 28032 trainer.py:136] Epoch[190/1000] loss: 0.15089419980843863
I0427 10:22:49.566757 28032 trainer.py:136] Epoch[191/1000] loss: 0.1412058100104332
I0427 10:22:51.897214 28032 trainer.py:136] Epoch[192/1000] loss: 0.14216840432749855
I0427 10:22:54.028480 28032 trainer.py:136] Epoch[193/1000] loss: 0.14014754609929192
I0427 10:22:56.263131 28032 trainer.py:136] Epoch[194/1000] loss: 0.1477489305867089
I0427 10:22:58.388180 28032 trainer.py:136] Epoch[195/1000] loss: 0.1454296674993303
I0427 10:23:00.963736 28032 trainer.py:136] Epoch[196/1000] loss: 0.14104117453098297
I0427 10:23:03.128698 28032 trainer.py:136] Epoch[197/1000] loss: 0.14490300085809496
I0427 10:23:05.226164 28032 trainer.py:136] Epoch[198/1000] loss: 0.13993032276630402
I0427 10:23:07.433365 28032 trainer.py:136] Epoch[199/1000] loss: 0.1436721384525299
I0427 10:23:07.597411 28032 trainer.py:142] Test: [{'precision': 0.12176943699731915, 'recall': 0.2875141181603098, 'hit_ratio': 0.857372654155496, 'ndcg': 0.26856129759111536}]
I0427 10:23:09.943711 28032 trainer.py:136] Epoch[200/1000] loss: 0.1431077950530582
I0427 10:23:12.339798 28032 trainer.py:136] Epoch[201/1000] loss: 0.1489916741847992
I0427 10:23:14.428932 28032 trainer.py:136] Epoch[202/1000] loss: 0.14913447697957358
I0427 10:23:16.787759 28032 trainer.py:136] Epoch[203/1000] loss: 0.13729076666964424
I0427 10:23:19.250290 28032 trainer.py:136] Epoch[204/1000] loss: 0.1398734466897117
I0427 10:23:21.439129 28032 trainer.py:136] Epoch[205/1000] loss: 0.13943419026003945
I0427 10:23:23.606585 28032 trainer.py:136] Epoch[206/1000] loss: 0.14603545599513584
I0427 10:23:25.944903 28032 trainer.py:136] Epoch[207/1000] loss: 0.1316452274719874
I0427 10:23:28.174454 28032 trainer.py:136] Epoch[208/1000] loss: 0.14412876963615417
I0427 10:23:30.341899 28032 trainer.py:136] Epoch[209/1000] loss: 0.14159791005982292
I0427 10:23:32.668216 28032 trainer.py:136] Epoch[210/1000] loss: 0.13944878346390194
I0427 10:23:34.824825 28032 trainer.py:136] Epoch[211/1000] loss: 0.13467799789375728
I0427 10:23:37.188086 28032 trainer.py:136] Epoch[212/1000] loss: 0.13648728612396452
I0427 10:23:39.534965 28032 trainer.py:136] Epoch[213/1000] loss: 0.13626189695464241
I0427 10:23:42.121454 28032 trainer.py:136] Epoch[214/1000] loss: 0.13639122909969753
I0427 10:23:44.478695 28032 trainer.py:136] Epoch[215/1000] loss: 0.13603645149204466
I0427 10:23:46.654524 28032 trainer.py:136] Epoch[216/1000] loss: 0.1353206444117758
I0427 10:23:48.913080 28032 trainer.py:136] Epoch[217/1000] loss: 0.1404460304313236
I0427 10:23:50.936441 28032 trainer.py:136] Epoch[218/1000] loss: 0.13652095033062828
I0427 10:23:53.034343 28032 trainer.py:136] Epoch[219/1000] loss: 0.14178197416994306
I0427 10:23:55.055726 28032 trainer.py:136] Epoch[220/1000] loss: 0.14077531960275438
I0427 10:23:57.231540 28032 trainer.py:136] Epoch[221/1000] loss: 0.14038758973280588
I0427 10:23:59.354590 28032 trainer.py:136] Epoch[222/1000] loss: 0.13898149463865492
I0427 10:24:01.535376 28032 trainer.py:136] Epoch[223/1000] loss: 0.1380336880683899
I0427 10:24:03.711265 28032 trainer.py:136] Epoch[224/1000] loss: 0.13545743210448158
I0427 10:24:05.793562 28032 trainer.py:136] Epoch[225/1000] loss: 0.13624163303110334
I0427 10:24:07.988374 28032 trainer.py:136] Epoch[226/1000] loss: 0.13254444052775702
I0427 10:24:10.108823 28032 trainer.py:136] Epoch[227/1000] loss: 0.1307247852285703
I0427 10:24:12.196924 28032 trainer.py:136] Epoch[228/1000] loss: 0.1355915152364307
I0427 10:24:14.321919 28032 trainer.py:136] Epoch[229/1000] loss: 0.1364236937628852
I0427 10:24:16.459952 28032 trainer.py:136] Epoch[230/1000] loss: 0.13477744493219587
I0427 10:24:18.471233 28032 trainer.py:136] Epoch[231/1000] loss: 0.13528309762477875
I0427 10:24:20.632133 28032 trainer.py:136] Epoch[232/1000] loss: 0.1370892028013865
I0427 10:24:22.760163 28032 trainer.py:136] Epoch[233/1000] loss: 0.12968072377973133
I0427 10:24:24.969046 28032 trainer.py:136] Epoch[234/1000] loss: 0.13534049524201286
I0427 10:24:27.012340 28032 trainer.py:136] Epoch[235/1000] loss: 0.13633793261316088
I0427 10:24:29.138725 28032 trainer.py:136] Epoch[236/1000] loss: 0.13037792344888052
I0427 10:24:31.323426 28032 trainer.py:136] Epoch[237/1000] loss: 0.13164052367210388
I0427 10:24:33.431063 28032 trainer.py:136] Epoch[238/1000] loss: 0.14037306275632647
I0427 10:24:35.568416 28032 trainer.py:136] Epoch[239/1000] loss: 0.13600069615576002
I0427 10:24:37.697986 28032 trainer.py:136] Epoch[240/1000] loss: 0.13126565681563485
I0427 10:24:39.821064 28032 trainer.py:136] Epoch[241/1000] loss: 0.13067032314009136
I0427 10:24:41.896495 28032 trainer.py:136] Epoch[242/1000] loss: 0.1372120694981681
I0427 10:24:44.010736 28032 trainer.py:136] Epoch[243/1000] loss: 0.1319424675570594
I0427 10:24:46.063073 28032 trainer.py:136] Epoch[244/1000] loss: 0.12787120789289474
I0427 10:24:48.077137 28032 trainer.py:136] Epoch[245/1000] loss: 0.12499001870552699
I0427 10:24:50.136350 28032 trainer.py:136] Epoch[246/1000] loss: 0.1291468565662702
I0427 10:24:52.327278 28032 trainer.py:136] Epoch[247/1000] loss: 0.1317411611477534
I0427 10:24:54.443338 28032 trainer.py:136] Epoch[248/1000] loss: 0.13568310191233954
I0427 10:24:56.485327 28032 trainer.py:136] Epoch[249/1000] loss: 0.12948725952042472
I0427 10:24:56.646787 28032 trainer.py:142] Test: [{'precision': 0.12431635388739956, 'recall': 0.29372044705194067, 'hit_ratio': 0.864343163538874, 'ndcg': 0.2756757666563552}]
I0427 10:24:58.785752 28032 trainer.py:136] Epoch[250/1000] loss: 0.1331708754102389
I0427 10:25:00.892593 28032 trainer.py:136] Epoch[251/1000] loss: 0.13159354031085968
I0427 10:25:03.044263 28032 trainer.py:136] Epoch[252/1000] loss: 0.12679602040184867
I0427 10:25:05.143450 28032 trainer.py:136] Epoch[253/1000] loss: 0.12411709047026104
I0427 10:25:07.276222 28032 trainer.py:136] Epoch[254/1000] loss: 0.1232441398832533
I0427 10:25:09.318590 28032 trainer.py:136] Epoch[255/1000] loss: 0.12867576049433815
I0427 10:25:11.364939 28032 trainer.py:136] Epoch[256/1000] loss: 0.12693877932098177
I0427 10:25:13.450139 28032 trainer.py:136] Epoch[257/1000] loss: 0.12657692366176182
I0427 10:25:15.578779 28032 trainer.py:136] Epoch[258/1000] loss: 0.12810900062322617
I0427 10:25:17.692818 28032 trainer.py:136] Epoch[259/1000] loss: 0.126066525777181
I0427 10:25:19.862764 28032 trainer.py:136] Epoch[260/1000] loss: 0.12920450667540231
I0427 10:25:22.073585 28032 trainer.py:136] Epoch[261/1000] loss: 0.12221763365798527
I0427 10:25:24.204672 28032 trainer.py:136] Epoch[262/1000] loss: 0.12202885912524329
I0427 10:25:26.273361 28032 trainer.py:136] Epoch[263/1000] loss: 0.12608532855908075
I0427 10:25:28.379338 28032 trainer.py:136] Epoch[264/1000] loss: 0.12245364569955403
I0427 10:25:30.575448 28032 trainer.py:136] Epoch[265/1000] loss: 0.13152312321795356
I0427 10:25:32.676408 28032 trainer.py:136] Epoch[266/1000] loss: 0.12724842131137848
I0427 10:25:34.867202 28032 trainer.py:136] Epoch[267/1000] loss: 0.12535044964816835
I0427 10:25:37.040074 28032 trainer.py:136] Epoch[268/1000] loss: 0.12592862877580854
I0427 10:25:39.277492 28032 trainer.py:136] Epoch[269/1000] loss: 0.12318387462033166
I0427 10:25:41.430413 28032 trainer.py:136] Epoch[270/1000] loss: 0.13052677197588813
I0427 10:25:43.661707 28032 trainer.py:136] Epoch[271/1000] loss: 0.12318588213788138
I0427 10:25:45.858507 28032 trainer.py:136] Epoch[272/1000] loss: 0.1247495851582951
I0427 10:25:48.101157 28032 trainer.py:136] Epoch[273/1000] loss: 0.13128775275415844
I0427 10:25:50.302180 28032 trainer.py:136] Epoch[274/1000] loss: 0.12715359363290998
I0427 10:25:52.459089 28032 trainer.py:136] Epoch[275/1000] loss: 0.12269069916672176
I0427 10:25:54.651424 28032 trainer.py:136] Epoch[276/1000] loss: 0.11743603646755219
I0427 10:25:56.796555 28032 trainer.py:136] Epoch[277/1000] loss: 0.12377046545346577
I0427 10:25:59.114189 28032 trainer.py:136] Epoch[278/1000] loss: 0.12333575470579995
I0427 10:26:01.214690 28032 trainer.py:136] Epoch[279/1000] loss: 0.1225347841779391
I0427 10:26:03.337911 28032 trainer.py:136] Epoch[280/1000] loss: 0.12006092154317433
I0427 10:26:05.582102 28032 trainer.py:136] Epoch[281/1000] loss: 0.12290380398432414
I0427 10:26:07.876856 28032 trainer.py:136] Epoch[282/1000] loss: 0.12244896921846601
I0427 10:26:09.945141 28032 trainer.py:136] Epoch[283/1000] loss: 0.12025267879168193
I0427 10:26:12.036952 28032 trainer.py:136] Epoch[284/1000] loss: 0.1186144244339731
I0427 10:26:14.167969 28032 trainer.py:136] Epoch[285/1000] loss: 0.12081968287626903
I0427 10:26:16.305552 28032 trainer.py:136] Epoch[286/1000] loss: 0.11805080374081929
I0427 10:26:18.486619 28032 trainer.py:136] Epoch[287/1000] loss: 0.12568513138426674
I0427 10:26:20.527931 28032 trainer.py:136] Epoch[288/1000] loss: 0.11781777027580473
I0427 10:26:22.901574 28032 trainer.py:136] Epoch[289/1000] loss: 0.11946962277094524
I0427 10:26:25.118163 28032 trainer.py:136] Epoch[290/1000] loss: 0.12046451618274052
I0427 10:26:27.351232 28032 trainer.py:136] Epoch[291/1000] loss: 0.11713413066334194
I0427 10:26:29.409431 28032 trainer.py:136] Epoch[292/1000] loss: 0.11891713738441467
I0427 10:26:31.522137 28032 trainer.py:136] Epoch[293/1000] loss: 0.11716203722688887
I0427 10:26:33.665156 28032 trainer.py:136] Epoch[294/1000] loss: 0.11906840155522029
I0427 10:26:35.875883 28032 trainer.py:136] Epoch[295/1000] loss: 0.12020808375544018
I0427 10:26:37.991099 28032 trainer.py:136] Epoch[296/1000] loss: 0.11625013914373186
I0427 10:26:40.049359 28032 trainer.py:136] Epoch[297/1000] loss: 0.11635812206400765
I0427 10:26:42.145687 28032 trainer.py:136] Epoch[298/1000] loss: 0.11388235539197922
I0427 10:26:44.306585 28032 trainer.py:136] Epoch[299/1000] loss: 0.12262528472476536
I0427 10:26:44.465642 28032 trainer.py:142] Test: [{'precision': 0.12672922252010735, 'recall': 0.3005393708256035, 'hit_ratio': 0.8718498659517426, 'ndcg': 0.2807921729506469}]
I0427 10:26:46.514053 28032 trainer.py:136] Epoch[300/1000] loss: 0.12015999688042535
I0427 10:26:48.700736 28032 trainer.py:136] Epoch[301/1000] loss: 0.1210453203982777
I0427 10:26:50.829133 28032 trainer.py:136] Epoch[302/1000] loss: 0.11964012765222126
I0427 10:26:52.888410 28032 trainer.py:136] Epoch[303/1000] loss: 0.11533231619331571
I0427 10:26:55.067227 28032 trainer.py:136] Epoch[304/1000] loss: 0.11346022619141473
I0427 10:26:57.220164 28032 trainer.py:136] Epoch[305/1000] loss: 0.1141543115178744
I0427 10:26:59.297342 28032 trainer.py:136] Epoch[306/1000] loss: 0.12079310417175293
I0427 10:27:01.463783 28032 trainer.py:136] Epoch[307/1000] loss: 0.1170272429784139
I0427 10:27:03.686479 28032 trainer.py:136] Epoch[308/1000] loss: 0.11545892308155696
I0427 10:27:05.804324 28032 trainer.py:136] Epoch[309/1000] loss: 0.11395199431313409
I0427 10:27:07.985170 28032 trainer.py:136] Epoch[310/1000] loss: 0.11783685783545177
I0427 10:27:10.229853 28032 trainer.py:136] Epoch[311/1000] loss: 0.11113613926702076
I0427 10:27:12.414044 28032 trainer.py:136] Epoch[312/1000] loss: 0.12080985473261939
I0427 10:27:14.567838 28032 trainer.py:136] Epoch[313/1000] loss: 0.11419419116444057
I0427 10:27:16.655457 28032 trainer.py:136] Epoch[314/1000] loss: 0.11438282496399349
I0427 10:27:18.971496 28032 trainer.py:136] Epoch[315/1000] loss: 0.11317760331763162
I0427 10:27:21.049459 28032 trainer.py:136] Epoch[316/1000] loss: 0.12053349200222227
I0427 10:27:23.170104 28032 trainer.py:136] Epoch[317/1000] loss: 0.11048039462831286
I0427 10:27:25.272225 28032 trainer.py:136] Epoch[318/1000] loss: 0.11261299914783901
I0427 10:27:27.341677 28032 trainer.py:136] Epoch[319/1000] loss: 0.11534766438934538
I0427 10:27:29.420858 28032 trainer.py:136] Epoch[320/1000] loss: 0.11460292587677638
I0427 10:27:31.569340 28032 trainer.py:136] Epoch[321/1000] loss: 0.10916442175706227
I0427 10:27:33.666396 28032 trainer.py:136] Epoch[322/1000] loss: 0.10939848257435693
I0427 10:27:35.757539 28032 trainer.py:136] Epoch[323/1000] loss: 0.11524111694759792
I0427 10:27:37.805111 28032 trainer.py:136] Epoch[324/1000] loss: 0.11834449486600028
I0427 10:27:40.105901 28032 trainer.py:136] Epoch[325/1000] loss: 0.11053233842055003
I0427 10:27:42.171530 28032 trainer.py:136] Epoch[326/1000] loss: 0.1101515649093522
I0427 10:27:44.312252 28032 trainer.py:136] Epoch[327/1000] loss: 0.1149982362985611
I0427 10:27:46.379590 28032 trainer.py:136] Epoch[328/1000] loss: 0.11681358267863591
I0427 10:27:48.534161 28032 trainer.py:136] Epoch[329/1000] loss: 0.11294771648115581
I0427 10:27:50.690648 28032 trainer.py:136] Epoch[330/1000] loss: 0.1106800561149915
I0427 10:27:52.898396 28032 trainer.py:136] Epoch[331/1000] loss: 0.10963633325364855
I0427 10:27:55.060286 28032 trainer.py:136] Epoch[332/1000] loss: 0.11018011967341106
I0427 10:27:57.125621 28032 trainer.py:136] Epoch[333/1000] loss: 0.11462629586458206
I0427 10:27:59.312165 28032 trainer.py:136] Epoch[334/1000] loss: 0.11324987312157948
I0427 10:28:01.415369 28032 trainer.py:136] Epoch[335/1000] loss: 0.11403060870038138
I0427 10:28:03.571212 28032 trainer.py:136] Epoch[336/1000] loss: 0.117680624127388
I0427 10:28:05.754019 28032 trainer.py:136] Epoch[337/1000] loss: 0.11874279462628895
I0427 10:28:07.937829 28032 trainer.py:136] Epoch[338/1000] loss: 0.1134177984462844
I0427 10:28:10.076829 28032 trainer.py:136] Epoch[339/1000] loss: 0.1136669632461336
I0427 10:28:12.174984 28032 trainer.py:136] Epoch[340/1000] loss: 0.10938190586037105
I0427 10:28:14.282113 28032 trainer.py:136] Epoch[341/1000] loss: 0.11190841264194912
I0427 10:28:16.465602 28032 trainer.py:136] Epoch[342/1000] loss: 0.10786726077397664
I0427 10:28:18.669433 28032 trainer.py:136] Epoch[343/1000] loss: 0.10708784560362498
I0427 10:28:20.856267 28032 trainer.py:136] Epoch[344/1000] loss: 0.11257524871163899
I0427 10:28:23.036162 28032 trainer.py:136] Epoch[345/1000] loss: 0.10851098514265484
I0427 10:28:25.123002 28032 trainer.py:136] Epoch[346/1000] loss: 0.1123192095094257
I0427 10:28:27.306067 28032 trainer.py:136] Epoch[347/1000] loss: 0.11067733416954677
I0427 10:28:29.446953 28032 trainer.py:136] Epoch[348/1000] loss: 0.10542601429753834
I0427 10:28:31.605465 28032 trainer.py:136] Epoch[349/1000] loss: 0.10742542478773329
I0427 10:28:31.776892 28032 trainer.py:142] Test: [{'precision': 0.12758713136729233, 'recall': 0.3023304550764732, 'hit_ratio': 0.8739946380697051, 'ndcg': 0.28407035405403425}]
I0427 10:28:33.901803 28032 trainer.py:136] Epoch[350/1000] loss: 0.1106305064426528
I0427 10:28:36.107667 28032 trainer.py:136] Epoch[351/1000] loss: 0.10715197606219186
I0427 10:28:38.277558 28032 trainer.py:136] Epoch[352/1000] loss: 0.10682739400201374
I0427 10:28:40.400651 28032 trainer.py:136] Epoch[353/1000] loss: 0.10732348925537533
I0427 10:28:42.450998 28032 trainer.py:136] Epoch[354/1000] loss: 0.10701857507228851
I0427 10:28:44.575600 28032 trainer.py:136] Epoch[355/1000] loss: 0.10849113431241778
I0427 10:28:46.682757 28032 trainer.py:136] Epoch[356/1000] loss: 0.10780868265363905
I0427 10:28:48.743045 28032 trainer.py:136] Epoch[357/1000] loss: 0.109723552233643
I0427 10:28:50.898952 28032 trainer.py:136] Epoch[358/1000] loss: 0.10791094104448955
I0427 10:28:53.122036 28032 trainer.py:136] Epoch[359/1000] loss: 0.10786257518662347
I0427 10:28:55.315881 28032 trainer.py:136] Epoch[360/1000] loss: 0.10520303166574901
I0427 10:28:57.398603 28032 trainer.py:136] Epoch[361/1000] loss: 0.10491799066464107
I0427 10:28:59.524969 28032 trainer.py:136] Epoch[362/1000] loss: 0.10616354230377409
I0427 10:29:01.639122 28032 trainer.py:136] Epoch[363/1000] loss: 0.10684137294689815
I0427 10:29:03.847800 28032 trainer.py:136] Epoch[364/1000] loss: 0.10768942369355096
I0427 10:29:05.950861 28032 trainer.py:136] Epoch[365/1000] loss: 0.10629344152079688
I0427 10:29:08.031045 28032 trainer.py:136] Epoch[366/1000] loss: 0.10963761392566893
I0427 10:29:10.148894 28032 trainer.py:136] Epoch[367/1000] loss: 0.10528332988421123
I0427 10:29:12.208447 28032 trainer.py:136] Epoch[368/1000] loss: 0.10170893950594796
I0427 10:29:14.317564 28032 trainer.py:136] Epoch[369/1000] loss: 0.11048314140902625
I0427 10:29:16.422653 28032 trainer.py:136] Epoch[370/1000] loss: 0.10686647478077146
I0427 10:29:18.629091 28032 trainer.py:136] Epoch[371/1000] loss: 0.11231133341789246
I0427 10:29:20.676959 28032 trainer.py:136] Epoch[372/1000] loss: 0.10811722526947658
I0427 10:29:22.814986 28032 trainer.py:136] Epoch[373/1000] loss: 0.11374320669306649
I0427 10:29:24.903954 28032 trainer.py:136] Epoch[374/1000] loss: 0.10927801993158129
I0427 10:29:27.017053 28032 trainer.py:136] Epoch[375/1000] loss: 0.10388779391845067
I0427 10:29:29.097815 28032 trainer.py:136] Epoch[376/1000] loss: 0.10669055498308605
I0427 10:29:31.177423 28032 trainer.py:136] Epoch[377/1000] loss: 0.10432620346546173
I0427 10:29:33.247600 28032 trainer.py:136] Epoch[378/1000] loss: 0.10382551037602955
I0427 10:29:35.306839 28032 trainer.py:136] Epoch[379/1000] loss: 0.10208261095815235
I0427 10:29:37.432426 28032 trainer.py:136] Epoch[380/1000] loss: 0.10465671122074127
I0427 10:29:39.578836 28032 trainer.py:136] Epoch[381/1000] loss: 0.10169636540942723
I0427 10:29:41.775889 28032 trainer.py:136] Epoch[382/1000] loss: 0.10770984987417857
I0427 10:29:43.830620 28032 trainer.py:136] Epoch[383/1000] loss: 0.10272178798913956
I0427 10:29:45.923236 28032 trainer.py:136] Epoch[384/1000] loss: 0.1044711023569107
I0427 10:29:47.989468 28032 trainer.py:136] Epoch[385/1000] loss: 0.10076424479484558
I0427 10:29:50.188778 28032 trainer.py:136] Epoch[386/1000] loss: 0.09877117888795005
I0427 10:29:52.366269 28032 trainer.py:136] Epoch[387/1000] loss: 0.10375141683552
I0427 10:29:54.437571 28032 trainer.py:136] Epoch[388/1000] loss: 0.10581970545980665
I0427 10:29:56.533356 28032 trainer.py:136] Epoch[389/1000] loss: 0.1056536551978853
I0427 10:29:58.718221 28032 trainer.py:136] Epoch[390/1000] loss: 0.10282033516301049
I0427 10:30:00.889133 28032 trainer.py:136] Epoch[391/1000] loss: 0.10351592633459303
I0427 10:30:02.984295 28032 trainer.py:136] Epoch[392/1000] loss: 0.1011744381652938
I0427 10:30:05.114341 28032 trainer.py:136] Epoch[393/1000] loss: 0.101749406920539
I0427 10:30:07.274315 28032 trainer.py:136] Epoch[394/1000] loss: 0.10374443729718526
I0427 10:30:09.400678 28032 trainer.py:136] Epoch[395/1000] loss: 0.10240981231133144
I0427 10:30:11.423586 28032 trainer.py:136] Epoch[396/1000] loss: 0.1068685683939192
I0427 10:30:13.515580 28032 trainer.py:136] Epoch[397/1000] loss: 0.10189236286613676
I0427 10:30:15.679894 28032 trainer.py:136] Epoch[398/1000] loss: 0.10264297409190072
I0427 10:30:17.919533 28032 trainer.py:136] Epoch[399/1000] loss: 0.10111966398027208
I0427 10:30:18.069033 28032 trainer.py:142] Test: [{'precision': 0.12900804289544246, 'recall': 0.3051977426890691, 'hit_ratio': 0.87828418230563, 'ndcg': 0.2868895012264979}]
I0427 10:30:20.274755 28032 trainer.py:136] Epoch[400/1000] loss: 0.10172681676016913
I0427 10:30:22.424711 28032 trainer.py:136] Epoch[401/1000] loss: 0.10378703888919619
I0427 10:30:24.548364 28032 trainer.py:136] Epoch[402/1000] loss: 0.10561575243870418
I0427 10:30:26.809524 28032 trainer.py:136] Epoch[403/1000] loss: 0.10687725742657979
I0427 10:30:28.957684 28032 trainer.py:136] Epoch[404/1000] loss: 0.10368590139680439
I0427 10:30:31.036013 28032 trainer.py:136] Epoch[405/1000] loss: 0.10466292666064368
I0427 10:30:33.158679 28032 trainer.py:136] Epoch[406/1000] loss: 0.10269634425640106
I0427 10:30:35.245657 28032 trainer.py:136] Epoch[407/1000] loss: 0.10448874947097567
I0427 10:30:37.407656 28032 trainer.py:136] Epoch[408/1000] loss: 0.10071020656161839
I0427 10:30:39.608598 28032 trainer.py:136] Epoch[409/1000] loss: 0.09954895658625497
I0427 10:30:41.708784 28032 trainer.py:136] Epoch[410/1000] loss: 0.1032315260834164
I0427 10:30:43.872456 28032 trainer.py:136] Epoch[411/1000] loss: 0.0973164944185151
I0427 10:30:46.068523 28032 trainer.py:136] Epoch[412/1000] loss: 0.09989591770701939
I0427 10:30:48.191334 28032 trainer.py:136] Epoch[413/1000] loss: 0.10258905506796306
I0427 10:30:50.295243 28032 trainer.py:136] Epoch[414/1000] loss: 0.0957438920934995
I0427 10:30:52.539746 28032 trainer.py:136] Epoch[415/1000] loss: 0.10189975798130035
I0427 10:30:54.724636 28032 trainer.py:136] Epoch[416/1000] loss: 0.09864049156506856
I0427 10:30:56.821558 28032 trainer.py:136] Epoch[417/1000] loss: 0.1011721243460973
I0427 10:30:58.968503 28032 trainer.py:136] Epoch[418/1000] loss: 0.09681358767880334
I0427 10:31:01.116461 28032 trainer.py:136] Epoch[419/1000] loss: 0.10324809783034855
I0427 10:31:03.271363 28032 trainer.py:136] Epoch[420/1000] loss: 0.10569012744559182
I0427 10:31:05.389296 28032 trainer.py:136] Epoch[421/1000] loss: 0.10209496898783578
I0427 10:31:07.548846 28032 trainer.py:136] Epoch[422/1000] loss: 0.09815068791309993
I0427 10:31:09.651947 28032 trainer.py:136] Epoch[423/1000] loss: 0.10634432567490472
I0427 10:31:11.785812 28032 trainer.py:136] Epoch[424/1000] loss: 0.09676046835051642
I0427 10:31:13.906415 28032 trainer.py:136] Epoch[425/1000] loss: 0.09814998341931237
I0427 10:31:16.060223 28032 trainer.py:136] Epoch[426/1000] loss: 0.09973667810360591
I0427 10:31:18.238083 28032 trainer.py:136] Epoch[427/1000] loss: 0.09882680823405583
I0427 10:31:20.375079 28032 trainer.py:136] Epoch[428/1000] loss: 0.1013879312409295
I0427 10:31:22.612835 28032 trainer.py:136] Epoch[429/1000] loss: 0.09523626416921616
I0427 10:31:24.744836 28032 trainer.py:136] Epoch[430/1000] loss: 0.09914510614342159
I0427 10:31:26.813146 28032 trainer.py:136] Epoch[431/1000] loss: 0.10203822950522105
I0427 10:31:29.033217 28032 trainer.py:136] Epoch[432/1000] loss: 0.10141746948162715
I0427 10:31:31.199616 28032 trainer.py:136] Epoch[433/1000] loss: 0.10259121076928245
I0427 10:31:33.303766 28032 trainer.py:136] Epoch[434/1000] loss: 0.09721685200929642
I0427 10:31:35.434739 28032 trainer.py:136] Epoch[435/1000] loss: 0.10059210740857655
I0427 10:31:37.589205 28032 trainer.py:136] Epoch[436/1000] loss: 0.1046573527985149
I0427 10:31:39.727224 28032 trainer.py:136] Epoch[437/1000] loss: 0.10116268859969245
I0427 10:31:41.889110 28032 trainer.py:136] Epoch[438/1000] loss: 0.0964528438117769
I0427 10:31:43.988242 28032 trainer.py:136] Epoch[439/1000] loss: 0.10083811647362179
I0427 10:31:46.025341 28032 trainer.py:136] Epoch[440/1000] loss: 0.09906554387675391
I0427 10:31:48.151676 28032 trainer.py:136] Epoch[441/1000] loss: 0.09840288509925206
I0427 10:31:50.361432 28032 trainer.py:136] Epoch[442/1000] loss: 0.10075582398308648
I0427 10:31:52.531022 28032 trainer.py:136] Epoch[443/1000] loss: 0.09779377861155404
I0427 10:31:54.702931 28032 trainer.py:136] Epoch[444/1000] loss: 0.09496782637304729
I0427 10:31:56.808071 28032 trainer.py:136] Epoch[445/1000] loss: 0.09508868720796373
I0427 10:31:58.904229 28032 trainer.py:136] Epoch[446/1000] loss: 0.10081442693869273
I0427 10:32:01.168823 28032 trainer.py:136] Epoch[447/1000] loss: 0.09668906529744466
I0427 10:32:03.228065 28032 trainer.py:136] Epoch[448/1000] loss: 0.09963229381375843
I0427 10:32:05.381000 28032 trainer.py:136] Epoch[449/1000] loss: 0.09589910010496776
I0427 10:32:05.537650 28032 trainer.py:142] Test: [{'precision': 0.1304021447721181, 'recall': 0.3087791327808677, 'hit_ratio': 0.8804289544235925, 'ndcg': 0.28930658172031976}]
I0427 10:32:07.617745 28032 trainer.py:136] Epoch[450/1000] loss: 0.09864936023950577
I0427 10:32:09.879479 28032 trainer.py:136] Epoch[451/1000] loss: 0.09839222249057558
I0427 10:32:12.070702 28032 trainer.py:136] Epoch[452/1000] loss: 0.09422715587748422
I0427 10:32:14.178866 28032 trainer.py:136] Epoch[453/1000] loss: 0.0954512432217598
I0427 10:32:16.256066 28032 trainer.py:136] Epoch[454/1000] loss: 0.10148122409979503
I0427 10:32:18.387060 28032 trainer.py:136] Epoch[455/1000] loss: 0.09916599343220393
I0427 10:32:20.466747 28032 trainer.py:136] Epoch[456/1000] loss: 0.10517188244395786
I0427 10:32:22.544035 28032 trainer.py:136] Epoch[457/1000] loss: 0.09505391948752934
I0427 10:32:24.612261 28032 trainer.py:136] Epoch[458/1000] loss: 0.10101055022743013
I0427 10:32:26.659558 28032 trainer.py:136] Epoch[459/1000] loss: 0.09518581132094066
I0427 10:32:28.833178 28032 trainer.py:136] Epoch[460/1000] loss: 0.09477973067098194
I0427 10:32:30.968108 28032 trainer.py:136] Epoch[461/1000] loss: 0.0984072478281127
I0427 10:32:33.158677 28032 trainer.py:136] Epoch[462/1000] loss: 0.08942205790016386
I0427 10:32:35.258132 28032 trainer.py:136] Epoch[463/1000] loss: 0.09501434034771389
I0427 10:32:37.434082 28032 trainer.py:136] Epoch[464/1000] loss: 0.09382552653551102
I0427 10:32:39.578913 28032 trainer.py:136] Epoch[465/1000] loss: 0.0912145111295912
I0427 10:32:41.733823 28032 trainer.py:136] Epoch[466/1000] loss: 0.09117510583665636
I0427 10:32:43.872863 28032 trainer.py:136] Epoch[467/1000] loss: 0.0954865747027927
I0427 10:32:46.030388 28032 trainer.py:136] Epoch[468/1000] loss: 0.09593825373384687
I0427 10:32:48.211199 28032 trainer.py:136] Epoch[469/1000] loss: 0.0955845531490114
I0427 10:32:50.388663 28032 trainer.py:136] Epoch[470/1000] loss: 0.09563789682255851
I0427 10:32:52.465774 28032 trainer.py:136] Epoch[471/1000] loss: 0.09655110951926973
I0427 10:32:54.560270 28032 trainer.py:136] Epoch[472/1000] loss: 0.09784025367763308
I0427 10:32:56.833747 28032 trainer.py:136] Epoch[473/1000] loss: 0.09273979233370887
I0427 10:32:58.921361 28032 trainer.py:136] Epoch[474/1000] loss: 0.09614413893885082
I0427 10:33:01.076555 28032 trainer.py:136] Epoch[475/1000] loss: 0.09340569625298183
I0427 10:33:03.224239 28032 trainer.py:136] Epoch[476/1000] loss: 0.09005097382598454
I0427 10:33:05.366040 28032 trainer.py:136] Epoch[477/1000] loss: 0.09377426240179274
I0427 10:33:07.450472 28032 trainer.py:136] Epoch[478/1000] loss: 0.09135956813891728
I0427 10:33:09.494428 28032 trainer.py:136] Epoch[479/1000] loss: 0.08994957639111413
I0427 10:33:11.649395 28032 trainer.py:136] Epoch[480/1000] loss: 0.0946778514318996
I0427 10:33:13.784397 28032 trainer.py:136] Epoch[481/1000] loss: 0.0927710019879871
I0427 10:33:15.831954 28032 trainer.py:136] Epoch[482/1000] loss: 0.09246703734000523
I0427 10:33:17.897452 28032 trainer.py:136] Epoch[483/1000] loss: 0.0943792677587933
I0427 10:33:20.018445 28032 trainer.py:136] Epoch[484/1000] loss: 0.09292686151133643
I0427 10:33:22.145690 28032 trainer.py:136] Epoch[485/1000] loss: 0.09272986733251148
I0427 10:33:24.288587 28032 trainer.py:136] Epoch[486/1000] loss: 0.09771690352095498
I0427 10:33:26.480329 28032 trainer.py:136] Epoch[487/1000] loss: 0.08976417614354028
I0427 10:33:28.500982 28032 trainer.py:136] Epoch[488/1000] loss: 0.09689443392886056
I0427 10:33:30.662909 28032 trainer.py:136] Epoch[489/1000] loss: 0.0916958178083102
I0427 10:33:32.846939 28032 trainer.py:136] Epoch[490/1000] loss: 0.09640432728661431
I0427 10:33:34.976374 28032 trainer.py:136] Epoch[491/1000] loss: 0.0920347347855568
I0427 10:33:37.099563 28032 trainer.py:136] Epoch[492/1000] loss: 0.09426002949476242
I0427 10:33:39.277390 28032 trainer.py:136] Epoch[493/1000] loss: 0.09936680727534825
I0427 10:33:41.503718 28032 trainer.py:136] Epoch[494/1000] loss: 0.0935284975502226
I0427 10:33:43.556777 28032 trainer.py:136] Epoch[495/1000] loss: 0.09195124440722996
I0427 10:33:45.656953 28032 trainer.py:136] Epoch[496/1000] loss: 0.09400142894850837
I0427 10:33:47.792963 28032 trainer.py:136] Epoch[497/1000] loss: 0.09131043404340744
I0427 10:33:49.897649 28032 trainer.py:136] Epoch[498/1000] loss: 0.09809876564476225
I0427 10:33:52.018724 28032 trainer.py:136] Epoch[499/1000] loss: 0.09184197253651089
I0427 10:33:52.175200 28032 trainer.py:142] Test: [{'precision': 0.1318230563002682, 'recall': 0.31166151000167736, 'hit_ratio': 0.8809651474530831, 'ndcg': 0.2911533986724405}]
I0427 10:33:54.174215 28032 trainer.py:136] Epoch[500/1000] loss: 0.0889482018020418
I0427 10:33:56.260866 28032 trainer.py:136] Epoch[501/1000] loss: 0.09311486615075006
I0427 10:33:58.332879 28032 trainer.py:136] Epoch[502/1000] loss: 0.0924290700091256
I0427 10:34:00.511261 28032 trainer.py:136] Epoch[503/1000] loss: 0.09248457600673039
I0427 10:34:02.658778 28032 trainer.py:136] Epoch[504/1000] loss: 0.09967547158400218
I0427 10:34:04.796753 28032 trainer.py:136] Epoch[505/1000] loss: 0.08703454749451743
I0427 10:34:06.969683 28032 trainer.py:136] Epoch[506/1000] loss: 0.09347494939963023
I0427 10:34:09.208419 28032 trainer.py:136] Epoch[507/1000] loss: 0.09129134648376042
I0427 10:34:11.312505 28032 trainer.py:136] Epoch[508/1000] loss: 0.09634646276632945
I0427 10:34:13.410653 28032 trainer.py:136] Epoch[509/1000] loss: 0.09556410544448429
I0427 10:34:15.505916 28032 trainer.py:136] Epoch[510/1000] loss: 0.0902807546986474
I0427 10:34:17.659414 28032 trainer.py:136] Epoch[511/1000] loss: 0.0937695453564326
I0427 10:34:19.805414 28032 trainer.py:136] Epoch[512/1000] loss: 0.09103855573468739
I0427 10:34:21.882644 28032 trainer.py:136] Epoch[513/1000] loss: 0.08892855213748084
I0427 10:34:24.036360 28032 trainer.py:136] Epoch[514/1000] loss: 0.09018629954920875
I0427 10:34:26.158455 28032 trainer.py:136] Epoch[515/1000] loss: 0.09209722611639234
I0427 10:34:28.329234 28032 trainer.py:136] Epoch[516/1000] loss: 0.08990206569433212
I0427 10:34:30.440960 28032 trainer.py:136] Epoch[517/1000] loss: 0.08870807041724522
I0427 10:34:32.532030 28032 trainer.py:136] Epoch[518/1000] loss: 0.09088082777129279
I0427 10:34:34.629154 28032 trainer.py:136] Epoch[519/1000] loss: 0.08740585959619945
I0427 10:34:36.736276 28032 trainer.py:136] Epoch[520/1000] loss: 0.08654872866140471
I0427 10:34:38.846351 28032 trainer.py:136] Epoch[521/1000] loss: 0.09370500263240603
I0427 10:34:40.933939 28032 trainer.py:136] Epoch[522/1000] loss: 0.09523468961318333
I0427 10:34:43.001202 28032 trainer.py:136] Epoch[523/1000] loss: 0.0878604290386041
I0427 10:34:45.094482 28032 trainer.py:136] Epoch[524/1000] loss: 0.08853435185220507
I0427 10:34:47.237057 28032 trainer.py:136] Epoch[525/1000] loss: 0.09051557464732064
I0427 10:34:49.386862 28032 trainer.py:136] Epoch[526/1000] loss: 0.08958487874931759
I0427 10:34:51.637035 28032 trainer.py:136] Epoch[527/1000] loss: 0.0886706295940611
I0427 10:34:53.771057 28032 trainer.py:136] Epoch[528/1000] loss: 0.0920332678490215
I0427 10:34:55.929709 28032 trainer.py:136] Epoch[529/1000] loss: 0.0922112688422203
I0427 10:34:58.016595 28032 trainer.py:136] Epoch[530/1000] loss: 0.0913275314701928
I0427 10:35:00.105022 28032 trainer.py:136] Epoch[531/1000] loss: 0.08784272190597323
I0427 10:35:02.338390 28032 trainer.py:136] Epoch[532/1000] loss: 0.08767816672722499
I0427 10:35:04.489978 28032 trainer.py:136] Epoch[533/1000] loss: 0.08524781838059425
I0427 10:35:06.542909 28032 trainer.py:136] Epoch[534/1000] loss: 0.08898591415749656
I0427 10:35:08.581353 28032 trainer.py:136] Epoch[535/1000] loss: 0.09113136844502555
I0427 10:35:10.651193 28032 trainer.py:136] Epoch[536/1000] loss: 0.08739509847429064
I0427 10:35:12.803116 28032 trainer.py:136] Epoch[537/1000] loss: 0.08652566207779779
I0427 10:35:15.072656 28032 trainer.py:136] Epoch[538/1000] loss: 0.0895797246032291
I0427 10:35:17.291275 28032 trainer.py:136] Epoch[539/1000] loss: 0.08659124581350221
I0427 10:35:19.406763 28032 trainer.py:136] Epoch[540/1000] loss: 0.09160661614603466
I0427 10:35:21.501724 28032 trainer.py:136] Epoch[541/1000] loss: 0.08748008641931745
I0427 10:35:23.694628 28032 trainer.py:136] Epoch[542/1000] loss: 0.08714015864663655
I0427 10:35:25.882503 28032 trainer.py:136] Epoch[543/1000] loss: 0.08566986893614133
I0427 10:35:28.048466 28032 trainer.py:136] Epoch[544/1000] loss: 0.09038998103804058
I0427 10:35:30.136909 28032 trainer.py:136] Epoch[545/1000] loss: 0.09001407441165712
I0427 10:35:32.270812 28032 trainer.py:136] Epoch[546/1000] loss: 0.08808693455325232
I0427 10:35:34.343133 28032 trainer.py:136] Epoch[547/1000] loss: 0.08429977587527698
I0427 10:35:36.469815 28032 trainer.py:136] Epoch[548/1000] loss: 0.09196807940800984
I0427 10:35:38.769847 28032 trainer.py:136] Epoch[549/1000] loss: 0.0881565660238266
I0427 10:35:38.924379 28032 trainer.py:142] Test: [{'precision': 0.13195710455764084, 'recall': 0.31256344318913326, 'hit_ratio': 0.8788203753351207, 'ndcg': 0.29381623892762615}]
I0427 10:35:40.982231 28032 trainer.py:136] Epoch[550/1000] loss: 0.08931559324264526
I0427 10:35:43.116856 28032 trainer.py:136] Epoch[551/1000] loss: 0.08910259852806728
I0427 10:35:45.241281 28032 trainer.py:136] Epoch[552/1000] loss: 0.09200928525792228
I0427 10:35:47.389025 28032 trainer.py:136] Epoch[553/1000] loss: 0.08468146911925739
I0427 10:35:49.437953 28032 trainer.py:136] Epoch[554/1000] loss: 0.08483352139592171
I0427 10:35:51.569521 28032 trainer.py:136] Epoch[555/1000] loss: 0.08273014591799842
I0427 10:35:53.640578 28032 trainer.py:136] Epoch[556/1000] loss: 0.087983015510771
I0427 10:35:55.698582 28032 trainer.py:136] Epoch[557/1000] loss: 0.08490230474207136
I0427 10:35:57.786012 28032 trainer.py:136] Epoch[558/1000] loss: 0.08675283938646317
I0427 10:35:59.946347 28032 trainer.py:136] Epoch[559/1000] loss: 0.08409880846738815
I0427 10:36:02.103304 28032 trainer.py:136] Epoch[560/1000] loss: 0.09152005943987104
I0427 10:36:04.231168 28032 trainer.py:136] Epoch[561/1000] loss: 0.08534832961029476
I0427 10:36:06.320179 28032 trainer.py:136] Epoch[562/1000] loss: 0.08254542367325889
I0427 10:36:08.491174 28032 trainer.py:136] Epoch[563/1000] loss: 0.08466912723249859
I0427 10:36:10.624163 28032 trainer.py:136] Epoch[564/1000] loss: 0.08815342436234157
I0427 10:36:12.699920 28032 trainer.py:136] Epoch[565/1000] loss: 0.08662770026259953
I0427 10:36:14.768208 28032 trainer.py:136] Epoch[566/1000] loss: 0.08586506876680586
I0427 10:36:16.910208 28032 trainer.py:136] Epoch[567/1000] loss: 0.08521431518925561
I0427 10:36:19.010331 28032 trainer.py:136] Epoch[568/1000] loss: 0.08745770735873117
I0427 10:36:21.114012 28032 trainer.py:136] Epoch[569/1000] loss: 0.09570350332392587
I0427 10:36:23.231676 28032 trainer.py:136] Epoch[570/1000] loss: 0.08233136311173439
I0427 10:36:25.411262 28032 trainer.py:136] Epoch[571/1000] loss: 0.08580789880620109
I0427 10:36:27.645328 28032 trainer.py:136] Epoch[572/1000] loss: 0.08519714408450657
I0427 10:36:29.753760 28032 trainer.py:136] Epoch[573/1000] loss: 0.08771715975470012
I0427 10:36:31.910482 28032 trainer.py:136] Epoch[574/1000] loss: 0.08043970084852642
I0427 10:36:33.997842 28032 trainer.py:136] Epoch[575/1000] loss: 0.08545069230927362
I0427 10:36:36.110842 28032 trainer.py:136] Epoch[576/1000] loss: 0.08732823448048697
I0427 10:36:38.282202 28032 trainer.py:136] Epoch[577/1000] loss: 0.08501759585407045
I0427 10:36:40.369345 28032 trainer.py:136] Epoch[578/1000] loss: 0.08341512249575721
I0427 10:36:42.544890 28032 trainer.py:136] Epoch[579/1000] loss: 0.08753146727879842
I0427 10:36:44.657963 28032 trainer.py:136] Epoch[580/1000] loss: 0.08775907672113842
I0427 10:36:46.923421 28032 trainer.py:136] Epoch[581/1000] loss: 0.08525407397084767
I0427 10:36:49.105696 28032 trainer.py:136] Epoch[582/1000] loss: 0.08271754036347072
I0427 10:36:51.237729 28032 trainer.py:136] Epoch[583/1000] loss: 0.08368973433971405
I0427 10:36:53.380732 28032 trainer.py:136] Epoch[584/1000] loss: 0.08024658883611362
I0427 10:36:55.546028 28032 trainer.py:136] Epoch[585/1000] loss: 0.08544931643539005
I0427 10:36:57.631282 28032 trainer.py:136] Epoch[586/1000] loss: 0.08487255705727471
I0427 10:36:59.672593 28032 trainer.py:136] Epoch[587/1000] loss: 0.08352435214651956
I0427 10:37:01.811200 28032 trainer.py:136] Epoch[588/1000] loss: 0.08815897090567483
I0427 10:37:04.002018 28032 trainer.py:136] Epoch[589/1000] loss: 0.08311080849832958
I0427 10:37:06.090215 28032 trainer.py:136] Epoch[590/1000] loss: 0.08218177573548423
I0427 10:37:08.248463 28032 trainer.py:136] Epoch[591/1000] loss: 0.08441972980896632
I0427 10:37:10.378902 28032 trainer.py:136] Epoch[592/1000] loss: 0.08285999256703588
I0427 10:37:12.534268 28032 trainer.py:136] Epoch[593/1000] loss: 0.08886771814690696
I0427 10:37:14.701980 28032 trainer.py:136] Epoch[594/1000] loss: 0.08529809945159489
I0427 10:37:16.892436 28032 trainer.py:136] Epoch[595/1000] loss: 0.08487780226601495
I0427 10:37:18.979296 28032 trainer.py:136] Epoch[596/1000] loss: 0.08474006752173106
I0427 10:37:21.103175 28032 trainer.py:136] Epoch[597/1000] loss: 0.08677924258841409
I0427 10:37:23.290067 28032 trainer.py:136] Epoch[598/1000] loss: 0.08306897679964702
I0427 10:37:25.389232 28032 trainer.py:136] Epoch[599/1000] loss: 0.09010974483357535
I0427 10:37:25.539287 28032 trainer.py:142] Test: [{'precision': 0.13300268096514753, 'recall': 0.31541085099869215, 'hit_ratio': 0.8820375335120644, 'ndcg': 0.2967210027136642}]
I0427 10:37:27.653800 28032 trainer.py:136] Epoch[600/1000] loss: 0.09085496515035629
I0427 10:37:29.859549 28032 trainer.py:136] Epoch[601/1000] loss: 0.0834420853190952
I0427 10:37:31.987532 28032 trainer.py:136] Epoch[602/1000] loss: 0.08473526686429977
I0427 10:37:34.170273 28032 trainer.py:136] Epoch[603/1000] loss: 0.08558472742636998
I0427 10:37:36.277520 28032 trainer.py:136] Epoch[604/1000] loss: 0.08572401023573345
I0427 10:37:38.415481 28032 trainer.py:136] Epoch[605/1000] loss: 0.08185012555784649
I0427 10:37:40.588284 28032 trainer.py:136] Epoch[606/1000] loss: 0.08161830984883839
I0427 10:37:42.688468 28032 trainer.py:136] Epoch[607/1000] loss: 0.08688831826051076
I0427 10:37:44.730770 28032 trainer.py:136] Epoch[608/1000] loss: 0.08264330526192983
I0427 10:37:46.852863 28032 trainer.py:136] Epoch[609/1000] loss: 0.08090361207723618
I0427 10:37:49.021722 28032 trainer.py:136] Epoch[610/1000] loss: 0.0863210881749789
I0427 10:37:51.167342 28032 trainer.py:136] Epoch[611/1000] loss: 0.08449523895978928
I0427 10:37:53.306841 28032 trainer.py:136] Epoch[612/1000] loss: 0.08467797024382485
I0427 10:37:55.393884 28032 trainer.py:136] Epoch[613/1000] loss: 0.08473813533782959
I0427 10:37:57.534425 28032 trainer.py:136] Epoch[614/1000] loss: 0.08373808860778809
I0427 10:37:59.617635 28032 trainer.py:136] Epoch[615/1000] loss: 0.08056184732251698
I0427 10:38:01.833228 28032 trainer.py:136] Epoch[616/1000] loss: 0.08624707079595989
I0427 10:38:03.956317 28032 trainer.py:136] Epoch[617/1000] loss: 0.08409233225716485
I0427 10:38:06.132007 28032 trainer.py:136] Epoch[618/1000] loss: 0.08119864886005719
I0427 10:38:08.251366 28032 trainer.py:136] Epoch[619/1000] loss: 0.08811907718578975
I0427 10:38:10.466188 28032 trainer.py:136] Epoch[620/1000] loss: 0.08502104298935996
I0427 10:38:12.684443 28032 trainer.py:136] Epoch[621/1000] loss: 0.09190010941690868
I0427 10:38:14.779586 28032 trainer.py:136] Epoch[622/1000] loss: 0.07916727082596885
I0427 10:38:16.854783 28032 trainer.py:136] Epoch[623/1000] loss: 0.08451972239547306
I0427 10:38:19.008692 28032 trainer.py:136] Epoch[624/1000] loss: 0.08165607560012075
I0427 10:38:21.167776 28032 trainer.py:136] Epoch[625/1000] loss: 0.08062086875240008
I0427 10:38:23.304784 28032 trainer.py:136] Epoch[626/1000] loss: 0.08227492454979154
I0427 10:38:25.450739 28032 trainer.py:136] Epoch[627/1000] loss: 0.08092498655120532
I0427 10:38:27.618987 28032 trainer.py:136] Epoch[628/1000] loss: 0.08095343576537238
I0427 10:38:29.838592 28032 trainer.py:136] Epoch[629/1000] loss: 0.07897763782077366
I0427 10:38:31.977270 28032 trainer.py:136] Epoch[630/1000] loss: 0.08492414156595866
I0427 10:38:34.152814 28032 trainer.py:136] Epoch[631/1000] loss: 0.08511932773722543
I0427 10:38:36.388474 28032 trainer.py:136] Epoch[632/1000] loss: 0.08587506827380922
I0427 10:38:38.534528 28032 trainer.py:136] Epoch[633/1000] loss: 0.08316616382863787
I0427 10:38:40.698994 28032 trainer.py:136] Epoch[634/1000] loss: 0.08195582611693276
I0427 10:38:42.797126 28032 trainer.py:136] Epoch[635/1000] loss: 0.08181394636631012
I0427 10:38:44.921128 28032 trainer.py:136] Epoch[636/1000] loss: 0.08925655815336439
I0427 10:38:47.059114 28032 trainer.py:136] Epoch[637/1000] loss: 0.0838305229942004
I0427 10:38:49.253611 28032 trainer.py:136] Epoch[638/1000] loss: 0.07894638843006557
I0427 10:38:51.371719 28032 trainer.py:136] Epoch[639/1000] loss: 0.07978967246082094
I0427 10:38:53.558491 28032 trainer.py:136] Epoch[640/1000] loss: 0.08508767353163825
I0427 10:38:55.640663 28032 trainer.py:136] Epoch[641/1000] loss: 0.08331698841518825
I0427 10:38:57.773694 28032 trainer.py:136] Epoch[642/1000] loss: 0.08262034919526842
I0427 10:38:59.912336 28032 trainer.py:136] Epoch[643/1000] loss: 0.08531736665301853
I0427 10:39:02.012429 28032 trainer.py:136] Epoch[644/1000] loss: 0.08058352354500029
I0427 10:39:04.130500 28032 trainer.py:136] Epoch[645/1000] loss: 0.07934430986642838
I0427 10:39:06.297453 28032 trainer.py:136] Epoch[646/1000] loss: 0.07956418643395106
I0427 10:39:08.451655 28032 trainer.py:136] Epoch[647/1000] loss: 0.07911504391166899
I0427 10:39:10.571242 28032 trainer.py:136] Epoch[648/1000] loss: 0.07964497639073266
I0427 10:39:12.743107 28032 trainer.py:136] Epoch[649/1000] loss: 0.0816987074083752
I0427 10:39:12.895597 28032 trainer.py:142] Test: [{'precision': 0.13410187667560333, 'recall': 0.317841808483269, 'hit_ratio': 0.8863270777479892, 'ndcg': 0.29836569869255314}]
I0427 10:39:15.082484 28032 trainer.py:136] Epoch[650/1000] loss: 0.08045558631420135
I0427 10:39:17.176661 28032 trainer.py:136] Epoch[651/1000] loss: 0.0844115631447898
I0427 10:39:19.254945 28032 trainer.py:136] Epoch[652/1000] loss: 0.08003098931577471
I0427 10:39:21.351038 28032 trainer.py:136] Epoch[653/1000] loss: 0.07979833086331685
I0427 10:39:23.475790 28032 trainer.py:136] Epoch[654/1000] loss: 0.07985675748851565
I0427 10:39:25.677148 28032 trainer.py:136] Epoch[655/1000] loss: 0.07992853141493267
I0427 10:39:27.882764 28032 trainer.py:136] Epoch[656/1000] loss: 0.08250545627541012
I0427 10:39:29.909607 28032 trainer.py:136] Epoch[657/1000] loss: 0.07787884523471196
I0427 10:39:32.043930 28032 trainer.py:136] Epoch[658/1000] loss: 0.078330400503344
I0427 10:39:34.161949 28032 trainer.py:136] Epoch[659/1000] loss: 0.07863257287277116
I0427 10:39:36.273090 28032 trainer.py:136] Epoch[660/1000] loss: 0.08191853016614914
I0427 10:39:38.396253 28032 trainer.py:136] Epoch[661/1000] loss: 0.0781289939251211
I0427 10:39:40.508025 28032 trainer.py:136] Epoch[662/1000] loss: 0.07977829376856486
I0427 10:39:42.772209 28032 trainer.py:136] Epoch[663/1000] loss: 0.08045567820469539
I0427 10:39:44.863703 28032 trainer.py:136] Epoch[664/1000] loss: 0.08044720523887211
I0427 10:39:46.975857 28032 trainer.py:136] Epoch[665/1000] loss: 0.07928888665305243
I0427 10:39:49.018795 28032 trainer.py:136] Epoch[666/1000] loss: 0.08173047254482906
I0427 10:39:51.102938 28032 trainer.py:136] Epoch[667/1000] loss: 0.08278754850228627
I0427 10:39:53.241900 28032 trainer.py:136] Epoch[668/1000] loss: 0.07938537084394032
I0427 10:39:55.351069 28032 trainer.py:136] Epoch[669/1000] loss: 0.08041385230090883
I0427 10:39:57.421703 28032 trainer.py:136] Epoch[670/1000] loss: 0.07851111061043209
I0427 10:39:59.489531 28032 trainer.py:136] Epoch[671/1000] loss: 0.0780923283762402
I0427 10:40:01.652423 28032 trainer.py:136] Epoch[672/1000] loss: 0.0787945803668764
I0427 10:40:03.826325 28032 trainer.py:136] Epoch[673/1000] loss: 0.08003013498253292
I0427 10:40:05.932015 28032 trainer.py:136] Epoch[674/1000] loss: 0.08034850491417779
I0427 10:40:08.081754 28032 trainer.py:136] Epoch[675/1000] loss: 0.07802007264561123
I0427 10:40:10.178232 28032 trainer.py:136] Epoch[676/1000] loss: 0.07990357445345984
I0427 10:40:12.306965 28032 trainer.py:136] Epoch[677/1000] loss: 0.08246806263923645
I0427 10:40:14.488955 28032 trainer.py:136] Epoch[678/1000] loss: 0.08059236821201113
I0427 10:40:16.712780 28032 trainer.py:136] Epoch[679/1000] loss: 0.08153803977701399
I0427 10:40:18.807995 28032 trainer.py:136] Epoch[680/1000] loss: 0.07913997521003087
I0427 10:40:20.963654 28032 trainer.py:136] Epoch[681/1000] loss: 0.08391346865230137
I0427 10:40:23.132581 28032 trainer.py:136] Epoch[682/1000] loss: 0.08000228885147306
I0427 10:40:25.212771 28032 trainer.py:136] Epoch[683/1000] loss: 0.07866812414593166
I0427 10:40:27.372681 28032 trainer.py:136] Epoch[684/1000] loss: 0.08332650942934884
I0427 10:40:29.562067 28032 trainer.py:136] Epoch[685/1000] loss: 0.08352426025602552
I0427 10:40:31.849781 28032 trainer.py:136] Epoch[686/1000] loss: 0.08129737029472987
I0427 10:40:33.965359 28032 trainer.py:136] Epoch[687/1000] loss: 0.07930141190687816
I0427 10:40:36.153551 28032 trainer.py:136] Epoch[688/1000] loss: 0.08109939843416214
I0427 10:40:38.371382 28032 trainer.py:136] Epoch[689/1000] loss: 0.08078055249320136
I0427 10:40:40.591678 28032 trainer.py:136] Epoch[690/1000] loss: 0.07867202659447987
I0427 10:40:42.751262 28032 trainer.py:136] Epoch[691/1000] loss: 0.08318636649184757
I0427 10:40:44.825454 28032 trainer.py:136] Epoch[692/1000] loss: 0.08015409774250454
I0427 10:40:46.925613 28032 trainer.py:136] Epoch[693/1000] loss: 0.07820141149891748
I0427 10:40:49.106147 28032 trainer.py:136] Epoch[694/1000] loss: 0.07582437288430002
I0427 10:40:51.254082 28032 trainer.py:136] Epoch[695/1000] loss: 0.07362595697244008
I0427 10:40:53.429958 28032 trainer.py:136] Epoch[696/1000] loss: 0.0814980309870508
I0427 10:40:55.614441 28032 trainer.py:136] Epoch[697/1000] loss: 0.08069947113593419
I0427 10:40:57.809005 28032 trainer.py:136] Epoch[698/1000] loss: 0.07861444933546914
I0427 10:40:59.955051 28032 trainer.py:136] Epoch[699/1000] loss: 0.07962227116028468
I0427 10:41:00.108537 28032 trainer.py:142] Test: [{'precision': 0.13418230563002692, 'recall': 0.3186047358256001, 'hit_ratio': 0.8879356568364611, 'ndcg': 0.29873238351472353}]
I0427 10:41:02.288140 28032 trainer.py:136] Epoch[700/1000] loss: 0.0771997935242123
I0427 10:41:04.406229 28032 trainer.py:136] Epoch[701/1000] loss: 0.07845797472529942
I0427 10:41:06.606236 28032 trainer.py:136] Epoch[702/1000] loss: 0.07936647948291567
I0427 10:41:08.766654 28032 trainer.py:136] Epoch[703/1000] loss: 0.07582239558299382
I0427 10:41:10.844258 28032 trainer.py:136] Epoch[704/1000] loss: 0.07588459841079181
I0427 10:41:12.965141 28032 trainer.py:136] Epoch[705/1000] loss: 0.07980040709177653
I0427 10:41:15.092747 28032 trainer.py:136] Epoch[706/1000] loss: 0.08156962278816435
I0427 10:41:17.321998 28032 trainer.py:136] Epoch[707/1000] loss: 0.08091715640491909
I0427 10:41:19.470511 28032 trainer.py:136] Epoch[708/1000] loss: 0.08135724067687988
I0427 10:41:21.549297 28032 trainer.py:136] Epoch[709/1000] loss: 0.07720835920837191
I0427 10:41:23.636236 28032 trainer.py:136] Epoch[710/1000] loss: 0.0796177585919698
I0427 10:41:25.796158 28032 trainer.py:136] Epoch[711/1000] loss: 0.08106860766808192
I0427 10:41:27.929751 28032 trainer.py:136] Epoch[712/1000] loss: 0.08353185736470753
I0427 10:41:30.093366 28032 trainer.py:136] Epoch[713/1000] loss: 0.07874372684293324
I0427 10:41:32.312167 28032 trainer.py:136] Epoch[714/1000] loss: 0.07785012159082624
I0427 10:41:34.523734 28032 trainer.py:136] Epoch[715/1000] loss: 0.08062778330511516
I0427 10:41:36.655783 28032 trainer.py:136] Epoch[716/1000] loss: 0.07666347838110393
I0427 10:41:38.747062 28032 trainer.py:136] Epoch[717/1000] loss: 0.08481612139277989
I0427 10:41:40.883025 28032 trainer.py:136] Epoch[718/1000] loss: 0.07804488721821043
I0427 10:41:43.116256 28032 trainer.py:136] Epoch[719/1000] loss: 0.07920264287127389
I0427 10:41:45.254231 28032 trainer.py:136] Epoch[720/1000] loss: 0.07943731215265062
I0427 10:41:47.355661 28032 trainer.py:136] Epoch[721/1000] loss: 0.07324099126789305
I0427 10:41:49.465361 28032 trainer.py:136] Epoch[722/1000] loss: 0.07600682063235177
I0427 10:41:51.597397 28032 trainer.py:136] Epoch[723/1000] loss: 0.07583260867330763
I0427 10:41:53.811642 28032 trainer.py:136] Epoch[724/1000] loss: 0.07717587136560017
I0427 10:41:55.915956 28032 trainer.py:136] Epoch[725/1000] loss: 0.0773134430249532
I0427 10:41:58.063672 28032 trainer.py:136] Epoch[726/1000] loss: 0.0763817537162039
I0427 10:42:00.218678 28032 trainer.py:136] Epoch[727/1000] loss: 0.08071700152423647
I0427 10:42:02.523260 28032 trainer.py:136] Epoch[728/1000] loss: 0.07259376802378231
I0427 10:42:04.708658 28032 trainer.py:136] Epoch[729/1000] loss: 0.0776069172554546
I0427 10:42:06.834702 28032 trainer.py:136] Epoch[730/1000] loss: 0.07724379003047943
I0427 10:42:08.961707 28032 trainer.py:136] Epoch[731/1000] loss: 0.07690669596195221
I0427 10:42:11.149513 28032 trainer.py:136] Epoch[732/1000] loss: 0.07511208040846719
I0427 10:42:13.356528 28032 trainer.py:136] Epoch[733/1000] loss: 0.08125703202353583
I0427 10:42:15.454431 28032 trainer.py:136] Epoch[734/1000] loss: 0.07666339228550594
I0427 10:42:17.607344 28032 trainer.py:136] Epoch[735/1000] loss: 0.07588302012946871
I0427 10:42:19.764280 28032 trainer.py:136] Epoch[736/1000] loss: 0.07485195828808679
I0427 10:42:21.962019 28032 trainer.py:136] Epoch[737/1000] loss: 0.0803440594010883
I0427 10:42:24.156844 28032 trainer.py:136] Epoch[738/1000] loss: 0.08174378921588261
I0427 10:42:26.354605 28032 trainer.py:136] Epoch[739/1000] loss: 0.08132885975970162
I0427 10:42:28.500968 28032 trainer.py:136] Epoch[740/1000] loss: 0.07639371355374654
I0427 10:42:30.674303 28032 trainer.py:136] Epoch[741/1000] loss: 0.0794393155309889
I0427 10:42:32.818309 28032 trainer.py:136] Epoch[742/1000] loss: 0.07505925248066585
I0427 10:42:35.020727 28032 trainer.py:136] Epoch[743/1000] loss: 0.07410040828916761
I0427 10:42:37.160183 28032 trainer.py:136] Epoch[744/1000] loss: 0.07559624562660854
I0427 10:42:39.321370 28032 trainer.py:136] Epoch[745/1000] loss: 0.0749223538570934
I0427 10:42:41.457053 28032 trainer.py:136] Epoch[746/1000] loss: 0.07601288209358852
I0427 10:42:43.593895 28032 trainer.py:136] Epoch[747/1000] loss: 0.07934045626057519
I0427 10:42:45.634260 28032 trainer.py:136] Epoch[748/1000] loss: 0.07601703455050786
I0427 10:42:47.763302 28032 trainer.py:136] Epoch[749/1000] loss: 0.07284034333295292
I0427 10:42:47.917786 28032 trainer.py:142] Test: [{'precision': 0.1347721179624666, 'recall': 0.31941817395137073, 'hit_ratio': 0.885254691689008, 'ndcg': 0.29907303337158064}]
I0427 10:42:50.096383 28032 trainer.py:136] Epoch[750/1000] loss: 0.07682083547115326
I0427 10:42:52.232423 28032 trainer.py:136] Epoch[751/1000] loss: 0.07840362191200256
I0427 10:42:54.376138 28032 trainer.py:136] Epoch[752/1000] loss: 0.07859765572680368
I0427 10:42:56.450343 28032 trainer.py:136] Epoch[753/1000] loss: 0.07538645135031806
I0427 10:42:58.616828 28032 trainer.py:136] Epoch[754/1000] loss: 0.07773448857996199
I0427 10:43:00.730984 28032 trainer.py:136] Epoch[755/1000] loss: 0.07425128834115134
I0427 10:43:02.884147 28032 trainer.py:136] Epoch[756/1000] loss: 0.07343007996678352
I0427 10:43:04.929862 28032 trainer.py:136] Epoch[757/1000] loss: 0.07860998312632243
I0427 10:43:07.134126 28032 trainer.py:136] Epoch[758/1000] loss: 0.07831682595941755
I0427 10:43:09.421834 28032 trainer.py:136] Epoch[759/1000] loss: 0.07502824895911747
I0427 10:43:11.523728 28032 trainer.py:136] Epoch[760/1000] loss: 0.0727143031027582
I0427 10:43:13.716642 28032 trainer.py:136] Epoch[761/1000] loss: 0.07381660532620218
I0427 10:43:15.865729 28032 trainer.py:136] Epoch[762/1000] loss: 0.07905388623476028
I0427 10:43:18.054403 28032 trainer.py:136] Epoch[763/1000] loss: 0.07328841586907704
I0427 10:43:20.140562 28032 trainer.py:136] Epoch[764/1000] loss: 0.07723723020818499
I0427 10:43:22.296844 28032 trainer.py:136] Epoch[765/1000] loss: 0.07559250129593743
I0427 10:43:24.423670 28032 trainer.py:136] Epoch[766/1000] loss: 0.07649019029405382
I0427 10:43:26.539097 28032 trainer.py:136] Epoch[767/1000] loss: 0.0744389726055993
I0427 10:43:28.693117 28032 trainer.py:136] Epoch[768/1000] loss: 0.07115886070662075
I0427 10:43:30.815611 28032 trainer.py:136] Epoch[769/1000] loss: 0.07355844063891305
I0427 10:43:32.960517 28032 trainer.py:136] Epoch[770/1000] loss: 0.07697047375970417
I0427 10:43:35.081731 28032 trainer.py:136] Epoch[771/1000] loss: 0.07530568954017428
I0427 10:43:37.195748 28032 trainer.py:136] Epoch[772/1000] loss: 0.07437502758370505
I0427 10:43:39.399540 28032 trainer.py:136] Epoch[773/1000] loss: 0.0751898768875334
I0427 10:43:41.560574 28032 trainer.py:136] Epoch[774/1000] loss: 0.07678806285063426
I0427 10:43:43.606681 28032 trainer.py:136] Epoch[775/1000] loss: 0.0752842269010014
I0427 10:43:45.822255 28032 trainer.py:136] Epoch[776/1000] loss: 0.07343556649155086
I0427 10:43:48.020071 28032 trainer.py:136] Epoch[777/1000] loss: 0.07861045665211147
I0427 10:43:50.137162 28032 trainer.py:136] Epoch[778/1000] loss: 0.07591053512361315
I0427 10:43:52.239546 28032 trainer.py:136] Epoch[779/1000] loss: 0.07548537022537655
I0427 10:43:54.405446 28032 trainer.py:136] Epoch[780/1000] loss: 0.07569737318489286
I0427 10:43:56.576714 28032 trainer.py:136] Epoch[781/1000] loss: 0.07507392598523034
I0427 10:43:58.673789 28032 trainer.py:136] Epoch[782/1000] loss: 0.07301925122737885
I0427 10:44:00.813794 28032 trainer.py:136] Epoch[783/1000] loss: 0.07217172326313125
I0427 10:44:02.964759 28032 trainer.py:136] Epoch[784/1000] loss: 0.07619422011905247
I0427 10:44:05.140622 28032 trainer.py:136] Epoch[785/1000] loss: 0.07671112070480983
I0427 10:44:07.194930 28032 trainer.py:136] Epoch[786/1000] loss: 0.07277546988593207
I0427 10:44:09.295368 28032 trainer.py:136] Epoch[787/1000] loss: 0.07639256782001919
I0427 10:44:11.380538 28032 trainer.py:136] Epoch[788/1000] loss: 0.07466212742858463
I0427 10:44:13.622809 28032 trainer.py:136] Epoch[789/1000] loss: 0.07137357319394748
I0427 10:44:15.689131 28032 trainer.py:136] Epoch[790/1000] loss: 0.07761179159084956
I0427 10:44:17.784775 28032 trainer.py:136] Epoch[791/1000] loss: 0.07632643315527174
I0427 10:44:19.871760 28032 trainer.py:136] Epoch[792/1000] loss: 0.07782571762800217
I0427 10:44:22.009591 28032 trainer.py:136] Epoch[793/1000] loss: 0.0739781293604109
I0427 10:44:24.175982 28032 trainer.py:136] Epoch[794/1000] loss: 0.07364823420842488
I0427 10:44:26.239179 28032 trainer.py:136] Epoch[795/1000] loss: 0.07281934469938278
I0427 10:44:28.384093 28032 trainer.py:136] Epoch[796/1000] loss: 0.0772187461455663
I0427 10:44:30.492052 28032 trainer.py:136] Epoch[797/1000] loss: 0.07384464475843641
I0427 10:44:32.685893 28032 trainer.py:136] Epoch[798/1000] loss: 0.07395820236868328
I0427 10:44:34.770042 28032 trainer.py:136] Epoch[799/1000] loss: 0.07646795279449886
I0427 10:44:34.935488 28032 trainer.py:142] Test: [{'precision': 0.1352278820375336, 'recall': 0.3206132592459671, 'hit_ratio': 0.8863270777479892, 'ndcg': 0.3008280671254796}]
I0427 10:44:37.084642 28032 trainer.py:136] Epoch[800/1000] loss: 0.06983126741316584
I0427 10:44:39.290409 28032 trainer.py:136] Epoch[801/1000] loss: 0.0724646465645896
I0427 10:44:41.409480 28032 trainer.py:136] Epoch[802/1000] loss: 0.07198911077446407
I0427 10:44:43.555855 28032 trainer.py:136] Epoch[803/1000] loss: 0.07609959774547154
I0427 10:44:45.715476 28032 trainer.py:136] Epoch[804/1000] loss: 0.0740257054567337
I0427 10:44:47.856489 28032 trainer.py:136] Epoch[805/1000] loss: 0.07260794192552567
I0427 10:44:50.060883 28032 trainer.py:136] Epoch[806/1000] loss: 0.0766368235150973
I0427 10:44:52.238754 28032 trainer.py:136] Epoch[807/1000] loss: 0.07240101943413417
I0427 10:44:54.352975 28032 trainer.py:136] Epoch[808/1000] loss: 0.07091112641824616
I0427 10:44:56.466926 28032 trainer.py:136] Epoch[809/1000] loss: 0.07350816577672958
I0427 10:44:58.596905 28032 trainer.py:136] Epoch[810/1000] loss: 0.07259135693311691
I0427 10:45:00.760815 28032 trainer.py:136] Epoch[811/1000] loss: 0.07473430120282704
I0427 10:45:02.851857 28032 trainer.py:136] Epoch[812/1000] loss: 0.08003562854395972
I0427 10:45:04.953927 28032 trainer.py:136] Epoch[813/1000] loss: 0.07288555800914764
I0427 10:45:07.062024 28032 trainer.py:136] Epoch[814/1000] loss: 0.0755232721567154
I0427 10:45:09.251858 28032 trainer.py:136] Epoch[815/1000] loss: 0.07412321203284794
I0427 10:45:11.420498 28032 trainer.py:136] Epoch[816/1000] loss: 0.07167887811859448
I0427 10:45:13.604923 28032 trainer.py:136] Epoch[817/1000] loss: 0.07663076867659886
I0427 10:45:15.694066 28032 trainer.py:136] Epoch[818/1000] loss: 0.08081665800677405
I0427 10:45:17.830095 28032 trainer.py:136] Epoch[819/1000] loss: 0.07508501907189687
I0427 10:45:19.940208 28032 trainer.py:136] Epoch[820/1000] loss: 0.07321914492381944
I0427 10:45:22.121109 28032 trainer.py:136] Epoch[821/1000] loss: 0.07564264949825075
I0427 10:45:24.179368 28032 trainer.py:136] Epoch[822/1000] loss: 0.07295277466376622
I0427 10:45:26.263406 28032 trainer.py:136] Epoch[823/1000] loss: 0.0758844514687856
I0427 10:45:28.478962 28032 trainer.py:136] Epoch[824/1000] loss: 0.07203967372576396
I0427 10:45:30.631547 28032 trainer.py:136] Epoch[825/1000] loss: 0.07241938718491131
I0427 10:45:32.733866 28032 trainer.py:136] Epoch[826/1000] loss: 0.07562736504607731
I0427 10:45:34.941275 28032 trainer.py:136] Epoch[827/1000] loss: 0.07263452559709549
I0427 10:45:37.047268 28032 trainer.py:136] Epoch[828/1000] loss: 0.07003531522221035
I0427 10:45:39.152360 28032 trainer.py:136] Epoch[829/1000] loss: 0.07474406643046273
I0427 10:45:41.248464 28032 trainer.py:136] Epoch[830/1000] loss: 0.07012974470853806
I0427 10:45:43.349622 28032 trainer.py:136] Epoch[831/1000] loss: 0.07108841381139225
I0427 10:45:45.587827 28032 trainer.py:136] Epoch[832/1000] loss: 0.07346425702174504
I0427 10:45:47.689931 28032 trainer.py:136] Epoch[833/1000] loss: 0.07048425119784144
I0427 10:45:49.774109 28032 trainer.py:136] Epoch[834/1000] loss: 0.07236036658287048
I0427 10:45:51.901117 28032 trainer.py:136] Epoch[835/1000] loss: 0.07319398389922248
I0427 10:45:53.945687 28032 trainer.py:136] Epoch[836/1000] loss: 0.07560168703397115
I0427 10:45:56.166183 28032 trainer.py:136] Epoch[837/1000] loss: 0.07226706710126665
I0427 10:45:58.314051 28032 trainer.py:136] Epoch[838/1000] loss: 0.07098958848251237
I0427 10:46:00.565219 28032 trainer.py:136] Epoch[839/1000] loss: 0.07403573476605946
I0427 10:46:02.673275 28032 trainer.py:136] Epoch[840/1000] loss: 0.06944390013813972
I0427 10:46:04.862756 28032 trainer.py:136] Epoch[841/1000] loss: 0.07127485010359022
I0427 10:46:06.976319 28032 trainer.py:136] Epoch[842/1000] loss: 0.07441241625282499
I0427 10:46:09.052552 28032 trainer.py:136] Epoch[843/1000] loss: 0.06931328525145848
I0427 10:46:11.239804 28032 trainer.py:136] Epoch[844/1000] loss: 0.07401572581794527
I0427 10:46:13.443060 28032 trainer.py:136] Epoch[845/1000] loss: 0.07374022404352824
I0427 10:46:15.626441 28032 trainer.py:136] Epoch[846/1000] loss: 0.07250911742448807
I0427 10:46:17.767438 28032 trainer.py:136] Epoch[847/1000] loss: 0.07151423477464253
I0427 10:46:19.906695 28032 trainer.py:136] Epoch[848/1000] loss: 0.07069094686044587
I0427 10:46:22.083178 28032 trainer.py:136] Epoch[849/1000] loss: 0.07091647138198216
I0427 10:46:22.237661 28032 trainer.py:142] Test: [{'precision': 0.1351206434316355, 'recall': 0.31994614656576503, 'hit_ratio': 0.8868632707774798, 'ndcg': 0.3113940803174641}]
I0427 10:46:24.397659 28032 trainer.py:136] Epoch[850/1000] loss: 0.0707532564798991
I0427 10:46:26.527526 28032 trainer.py:136] Epoch[851/1000] loss: 0.07147543877363205
I0427 10:46:28.740829 28032 trainer.py:136] Epoch[852/1000] loss: 0.07019037132461865
I0427 10:46:30.957540 28032 trainer.py:136] Epoch[853/1000] loss: 0.07125547114345762
I0427 10:46:33.174360 28032 trainer.py:136] Epoch[854/1000] loss: 0.07019235442082088
I0427 10:46:35.295684 28032 trainer.py:136] Epoch[855/1000] loss: 0.0741339781218105
I0427 10:46:37.523922 28032 trainer.py:136] Epoch[856/1000] loss: 0.07489667584498723
I0427 10:46:39.807435 28032 trainer.py:136] Epoch[857/1000] loss: 0.07096526109509999
I0427 10:46:42.011883 28032 trainer.py:136] Epoch[858/1000] loss: 0.0742648947570059
I0427 10:46:44.106990 28032 trainer.py:136] Epoch[859/1000] loss: 0.06956686245070563
I0427 10:46:46.201099 28032 trainer.py:136] Epoch[860/1000] loss: 0.073549661371443
I0427 10:46:48.371683 28032 trainer.py:136] Epoch[861/1000] loss: 0.07320219278335571
I0427 10:46:50.474788 28032 trainer.py:136] Epoch[862/1000] loss: 0.06916715701421101
I0427 10:46:52.716883 28032 trainer.py:136] Epoch[863/1000] loss: 0.07020212295982572
I0427 10:46:54.984090 28032 trainer.py:136] Epoch[864/1000] loss: 0.07281215654479133
I0427 10:46:57.047373 28032 trainer.py:136] Epoch[865/1000] loss: 0.07247278177075916
I0427 10:46:59.176893 28032 trainer.py:136] Epoch[866/1000] loss: 0.0688480031159189
I0427 10:47:01.464273 28032 trainer.py:136] Epoch[867/1000] loss: 0.07100461257828607
I0427 10:47:03.658934 28032 trainer.py:136] Epoch[868/1000] loss: 0.07512976891464657
I0427 10:47:05.749078 28032 trainer.py:136] Epoch[869/1000] loss: 0.0692463686896695
I0427 10:47:07.970773 28032 trainer.py:136] Epoch[870/1000] loss: 0.06874211712016
I0427 10:47:10.150716 28032 trainer.py:136] Epoch[871/1000] loss: 0.07257890866862403
I0427 10:47:12.201178 28032 trainer.py:136] Epoch[872/1000] loss: 0.07095507284005483
I0427 10:47:14.301562 28032 trainer.py:136] Epoch[873/1000] loss: 0.07007186280356513
I0427 10:47:16.456896 28032 trainer.py:136] Epoch[874/1000] loss: 0.07106734729475445
I0427 10:47:18.602060 28032 trainer.py:136] Epoch[875/1000] loss: 0.0671895986629857
I0427 10:47:20.747058 28032 trainer.py:136] Epoch[876/1000] loss: 0.070283609131972
I0427 10:47:22.833256 28032 trainer.py:136] Epoch[877/1000] loss: 0.06931942328810692
I0427 10:47:24.991697 28032 trainer.py:136] Epoch[878/1000] loss: 0.07361307740211487
I0427 10:47:27.114769 28032 trainer.py:136] Epoch[879/1000] loss: 0.07353711459371778
I0427 10:47:29.327301 28032 trainer.py:136] Epoch[880/1000] loss: 0.06973132408327526
I0427 10:47:31.441409 28032 trainer.py:136] Epoch[881/1000] loss: 0.07057120651006699
I0427 10:47:33.543955 28032 trainer.py:136] Epoch[882/1000] loss: 0.07127771443790859
I0427 10:47:35.755648 28032 trainer.py:136] Epoch[883/1000] loss: 0.069765019747946
I0427 10:47:37.894542 28032 trainer.py:136] Epoch[884/1000] loss: 0.07374828722741869
I0427 10:47:40.060473 28032 trainer.py:136] Epoch[885/1000] loss: 0.07262239936325285
I0427 10:47:42.157509 28032 trainer.py:136] Epoch[886/1000] loss: 0.06845434258381526
I0427 10:47:44.255784 28032 trainer.py:136] Epoch[887/1000] loss: 0.07508746617370182
I0427 10:47:46.398776 28032 trainer.py:136] Epoch[888/1000] loss: 0.0719599434071117
I0427 10:47:48.500419 28032 trainer.py:136] Epoch[889/1000] loss: 0.06938239600923327
I0427 10:47:50.506634 28032 trainer.py:136] Epoch[890/1000] loss: 0.07247086614370346
I0427 10:47:52.629238 28032 trainer.py:136] Epoch[891/1000] loss: 0.07072265528970295
I0427 10:47:54.678257 28032 trainer.py:136] Epoch[892/1000] loss: 0.07535137070549859
I0427 10:47:56.839547 28032 trainer.py:136] Epoch[893/1000] loss: 0.0707069370481703
I0427 10:47:58.965123 28032 trainer.py:136] Epoch[894/1000] loss: 0.06789277949266964
I0427 10:48:01.081225 28032 trainer.py:136] Epoch[895/1000] loss: 0.07035051451789008
I0427 10:48:03.259085 28032 trainer.py:136] Epoch[896/1000] loss: 0.06918682571914461
I0427 10:48:05.448466 28032 trainer.py:136] Epoch[897/1000] loss: 0.06796231410569614
I0427 10:48:07.524914 28032 trainer.py:136] Epoch[898/1000] loss: 0.0719596619407336
I0427 10:48:09.589109 28032 trainer.py:136] Epoch[899/1000] loss: 0.06996200150913662
I0427 10:48:09.748580 28032 trainer.py:142] Test: [{'precision': 0.13597855227882047, 'recall': 0.322435856517626, 'hit_ratio': 0.8906166219839142, 'ndcg': 0.3129373084936831}]
I0427 10:48:11.904165 28032 trainer.py:136] Epoch[900/1000] loss: 0.07112326307429208
I0427 10:48:14.033159 28032 trainer.py:136] Epoch[901/1000] loss: 0.07360104223092397
I0427 10:48:16.169662 28032 trainer.py:136] Epoch[902/1000] loss: 0.07556275112761392
I0427 10:48:18.385669 28032 trainer.py:136] Epoch[903/1000] loss: 0.07323758635256025
I0427 10:48:20.542170 28032 trainer.py:136] Epoch[904/1000] loss: 0.07374035235908297
I0427 10:48:22.704355 28032 trainer.py:136] Epoch[905/1000] loss: 0.07214456879430348
I0427 10:48:24.871791 28032 trainer.py:136] Epoch[906/1000] loss: 0.07099559985929066
I0427 10:48:26.984386 28032 trainer.py:136] Epoch[907/1000] loss: 0.06646322997079955
I0427 10:48:29.151726 28032 trainer.py:136] Epoch[908/1000] loss: 0.07009364167849223
I0427 10:48:31.295708 28032 trainer.py:136] Epoch[909/1000] loss: 0.07070322583119075
I0427 10:48:33.484920 28032 trainer.py:136] Epoch[910/1000] loss: 0.06961242026752895
I0427 10:48:35.565121 28032 trainer.py:136] Epoch[911/1000] loss: 0.06892839156919056
I0427 10:48:37.735990 28032 trainer.py:136] Epoch[912/1000] loss: 0.06833879111541642
I0427 10:48:39.759331 28032 trainer.py:136] Epoch[913/1000] loss: 0.07190397464566761
I0427 10:48:41.814676 28032 trainer.py:136] Epoch[914/1000] loss: 0.0709895317753156
I0427 10:48:43.986588 28032 trainer.py:136] Epoch[915/1000] loss: 0.06922082271840838
I0427 10:48:46.072732 28032 trainer.py:136] Epoch[916/1000] loss: 0.07098352909088135
I0427 10:48:48.241702 28032 trainer.py:136] Epoch[917/1000] loss: 0.07492234143945906
I0427 10:48:50.321712 28032 trainer.py:136] Epoch[918/1000] loss: 0.06993754539224836
I0427 10:48:52.516890 28032 trainer.py:136] Epoch[919/1000] loss: 0.07097132172849444
I0427 10:48:54.583189 28032 trainer.py:136] Epoch[920/1000] loss: 0.07004913108216392
I0427 10:48:56.708345 28032 trainer.py:136] Epoch[921/1000] loss: 0.06817005077997844
I0427 10:48:58.791797 28032 trainer.py:136] Epoch[922/1000] loss: 0.0683813922935062
I0427 10:49:00.934833 28032 trainer.py:136] Epoch[923/1000] loss: 0.06955107963747448
I0427 10:49:03.069499 28032 trainer.py:136] Epoch[924/1000] loss: 0.07236367132928637
I0427 10:49:05.132361 28032 trainer.py:136] Epoch[925/1000] loss: 0.07531355486975776
I0427 10:49:07.221529 28032 trainer.py:136] Epoch[926/1000] loss: 0.0721530011958546
I0427 10:49:09.290781 28032 trainer.py:136] Epoch[927/1000] loss: 0.07018514888154136
I0427 10:49:11.461328 28032 trainer.py:136] Epoch[928/1000] loss: 0.0686840671632025
I0427 10:49:13.501628 28032 trainer.py:136] Epoch[929/1000] loss: 0.07058661099937227
I0427 10:49:15.751223 28032 trainer.py:136] Epoch[930/1000] loss: 0.06975287447373073
I0427 10:49:17.873068 28032 trainer.py:136] Epoch[931/1000] loss: 0.06945917920933829
I0427 10:49:20.026022 28032 trainer.py:136] Epoch[932/1000] loss: 0.06996097829606798
I0427 10:49:22.137081 28032 trainer.py:136] Epoch[933/1000] loss: 0.07124374475744036
I0427 10:49:24.275583 28032 trainer.py:136] Epoch[934/1000] loss: 0.06789178484015995
I0427 10:49:26.368785 28032 trainer.py:136] Epoch[935/1000] loss: 0.07314493341578378
I0427 10:49:28.600070 28032 trainer.py:136] Epoch[936/1000] loss: 0.06977943206826846
I0427 10:49:30.686197 28032 trainer.py:136] Epoch[937/1000] loss: 0.06886915117502213
I0427 10:49:32.771918 28032 trainer.py:136] Epoch[938/1000] loss: 0.0734504618578487
I0427 10:49:34.826147 28032 trainer.py:136] Epoch[939/1000] loss: 0.06952126324176788
I0427 10:49:36.906405 28032 trainer.py:136] Epoch[940/1000] loss: 0.06682931755979855
I0427 10:49:39.074253 28032 trainer.py:136] Epoch[941/1000] loss: 0.06760842642850345
I0427 10:49:41.215329 28032 trainer.py:136] Epoch[942/1000] loss: 0.06884107573164834
I0427 10:49:43.323485 28032 trainer.py:136] Epoch[943/1000] loss: 0.07177014069424735
I0427 10:49:45.379216 28032 trainer.py:136] Epoch[944/1000] loss: 0.07259824126958847
I0427 10:49:47.509903 28032 trainer.py:136] Epoch[945/1000] loss: 0.06972329898013009
I0427 10:49:49.627882 28032 trainer.py:136] Epoch[946/1000] loss: 0.0705243597428004
I0427 10:49:51.749864 28032 trainer.py:136] Epoch[947/1000] loss: 0.07101986640029484
I0427 10:49:53.742372 28032 trainer.py:136] Epoch[948/1000] loss: 0.06836678832769394
I0427 10:49:55.877793 28032 trainer.py:136] Epoch[949/1000] loss: 0.06860328921013409
I0427 10:49:56.040249 28032 trainer.py:142] Test: [{'precision': 0.13595174262734594, 'recall': 0.32339327589895966, 'hit_ratio': 0.8884718498659517, 'ndcg': 0.31362938426757713}]
I0427 10:49:58.222121 28032 trainer.py:136] Epoch[950/1000] loss: 0.06765507244401509
I0427 10:50:00.318029 28032 trainer.py:136] Epoch[951/1000] loss: 0.0702323392033577
I0427 10:50:02.417725 28032 trainer.py:136] Epoch[952/1000] loss: 0.0675035450193617
I0427 10:50:04.493080 28032 trainer.py:136] Epoch[953/1000] loss: 0.06805460196402338
I0427 10:50:06.663062 28032 trainer.py:136] Epoch[954/1000] loss: 0.06656532610456149
I0427 10:50:08.757978 28032 trainer.py:136] Epoch[955/1000] loss: 0.067063773671786
I0427 10:50:10.820371 28032 trainer.py:136] Epoch[956/1000] loss: 0.07194581627845764
I0427 10:50:12.874693 28032 trainer.py:136] Epoch[957/1000] loss: 0.0673175992237197
I0427 10:50:14.973441 28032 trainer.py:136] Epoch[958/1000] loss: 0.06700226623151037
I0427 10:50:17.158352 28032 trainer.py:136] Epoch[959/1000] loss: 0.07180461618635389
I0427 10:50:19.268539 28032 trainer.py:136] Epoch[960/1000] loss: 0.0706141624185774
I0427 10:50:21.398552 28032 trainer.py:136] Epoch[961/1000] loss: 0.06921697242392434
I0427 10:50:23.483303 28032 trainer.py:136] Epoch[962/1000] loss: 0.06622568310962783
I0427 10:50:25.636300 28032 trainer.py:136] Epoch[963/1000] loss: 0.0706950608226988
I0427 10:50:27.814170 28032 trainer.py:136] Epoch[964/1000] loss: 0.06684251171019343
I0427 10:50:30.247676 28032 trainer.py:136] Epoch[965/1000] loss: 0.06976529128021663
I0427 10:50:32.405067 28032 trainer.py:136] Epoch[966/1000] loss: 0.06591259605354732
I0427 10:50:34.733080 28032 trainer.py:136] Epoch[967/1000] loss: 0.0668346020910475
I0427 10:50:36.889108 28032 trainer.py:136] Epoch[968/1000] loss: 0.06788076046440336
I0427 10:50:38.938088 28032 trainer.py:136] Epoch[969/1000] loss: 0.07127135826481713
I0427 10:50:41.109989 28032 trainer.py:136] Epoch[970/1000] loss: 0.0702900563677152
I0427 10:50:43.305825 28032 trainer.py:136] Epoch[971/1000] loss: 0.06874495413568285
I0427 10:50:45.401944 28032 trainer.py:136] Epoch[972/1000] loss: 0.06909883767366409
I0427 10:50:47.531618 28032 trainer.py:136] Epoch[973/1000] loss: 0.06627304148342875
I0427 10:50:49.787268 28032 trainer.py:136] Epoch[974/1000] loss: 0.07351970507038964
I0427 10:50:52.062772 28032 trainer.py:136] Epoch[975/1000] loss: 0.06915832890404595
I0427 10:50:54.166913 28032 trainer.py:136] Epoch[976/1000] loss: 0.06653905370169216
I0427 10:50:56.345765 28032 trainer.py:136] Epoch[977/1000] loss: 0.07160552591085434
I0427 10:50:58.537356 28032 trainer.py:136] Epoch[978/1000] loss: 0.06822213364972009
I0427 10:51:00.759096 28032 trainer.py:136] Epoch[979/1000] loss: 0.0652388371527195
I0427 10:51:02.936917 28032 trainer.py:136] Epoch[980/1000] loss: 0.07106944504711363
I0427 10:51:05.130141 28032 trainer.py:136] Epoch[981/1000] loss: 0.07277609490685993
I0427 10:51:07.303951 28032 trainer.py:136] Epoch[982/1000] loss: 0.06614988297224045
I0427 10:51:09.394846 28032 trainer.py:136] Epoch[983/1000] loss: 0.06917135996950997
I0427 10:51:11.716770 28032 trainer.py:136] Epoch[984/1000] loss: 0.06636420968506071
I0427 10:51:13.876191 28032 trainer.py:136] Epoch[985/1000] loss: 0.069698932270209
I0427 10:51:15.978324 28032 trainer.py:136] Epoch[986/1000] loss: 0.06961831533246571
I0427 10:51:18.076503 28032 trainer.py:136] Epoch[987/1000] loss: 0.07146174626217948
I0427 10:51:20.179661 28032 trainer.py:136] Epoch[988/1000] loss: 0.06566413988669713
I0427 10:51:22.206259 28032 trainer.py:136] Epoch[989/1000] loss: 0.06739057766066657
I0427 10:51:24.324353 28032 trainer.py:136] Epoch[990/1000] loss: 0.0669755567279127
I0427 10:51:26.316793 28032 trainer.py:136] Epoch[991/1000] loss: 0.06645988590187496
I0427 10:51:28.378065 28032 trainer.py:136] Epoch[992/1000] loss: 0.06626400185955895
I0427 10:51:30.413767 28032 trainer.py:136] Epoch[993/1000] loss: 0.0663245783911811
I0427 10:51:32.432390 28032 trainer.py:136] Epoch[994/1000] loss: 0.07277848488754696
I0427 10:51:34.446386 28032 trainer.py:136] Epoch[995/1000] loss: 0.06566489198141628
I0427 10:51:36.565063 28032 trainer.py:136] Epoch[996/1000] loss: 0.07110376076565848
I0427 10:51:38.700060 28032 trainer.py:136] Epoch[997/1000] loss: 0.06674070035417874
I0427 10:51:40.752352 28032 trainer.py:136] Epoch[998/1000] loss: 0.06820354362328847
I0427 10:51:42.789681 28032 trainer.py:136] Epoch[999/1000] loss: 0.0681400630209181
I0427 10:51:42.951141 28032 trainer.py:142] Test: [{'precision': 0.13686327077747998, 'recall': 0.32389921504771673, 'hit_ratio': 0.8916890080428954, 'ndcg': 0.3137011821904743}]
