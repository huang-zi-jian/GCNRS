I0415 10:04:45.585273 31272 trainer.py:121] Test: {'precision': 0.026844741235392308, 'recall': 0.02710669446413546, 'hit_ratio': 0.23589315525876461, 'ndcg': 0.03591579733095857}
I0415 10:05:38.405566 31272 trainer.py:139] Epoch[0/1500] loss: 0.44178166627883914
I0415 10:06:30.861547 31272 trainer.py:139] Epoch[1/1500] loss: 0.4121373637517293
I0415 10:07:22.686179 31272 trainer.py:139] Epoch[2/1500] loss: 0.38518164078394573
I0415 10:08:14.871021 31272 trainer.py:139] Epoch[3/1500] loss: 0.3672097586260902
I0415 10:09:06.855175 31272 trainer.py:139] Epoch[4/1500] loss: 0.351797018316057
I0415 10:09:59.713343 31272 trainer.py:139] Epoch[5/1500] loss: 0.3402614136536916
I0415 10:10:52.312829 31272 trainer.py:139] Epoch[6/1500] loss: 0.3306437492370605
I0415 10:12:00.667816 31272 trainer.py:139] Epoch[7/1500] loss: 0.32275871528519523
I0415 10:13:18.553257 31272 trainer.py:139] Epoch[8/1500] loss: 0.31340970105595056
I0415 10:14:10.843325 31272 trainer.py:139] Epoch[9/1500] loss: 0.3098113323582543
I0415 10:15:03.092141 31272 trainer.py:139] Epoch[10/1500] loss: 0.3034839398331112
I0415 10:15:56.091835 31272 trainer.py:139] Epoch[11/1500] loss: 0.2995783609814114
I0415 10:16:48.356891 31272 trainer.py:139] Epoch[12/1500] loss: 0.2959554084142049
I0415 10:17:43.886122 31272 trainer.py:139] Epoch[13/1500] loss: 0.2922083032131195
I0415 10:18:37.170863 31272 trainer.py:139] Epoch[14/1500] loss: 0.28727991872363623
I0415 10:19:35.611354 31272 trainer.py:139] Epoch[15/1500] loss: 0.2852446054087745
I0415 10:20:34.566126 31272 trainer.py:139] Epoch[16/1500] loss: 0.28281552619404265
I0415 10:21:31.324247 31272 trainer.py:139] Epoch[17/1500] loss: 0.27871171010865103
I0415 10:22:28.237847 31272 trainer.py:139] Epoch[18/1500] loss: 0.2770640469259686
I0415 10:23:26.669369 31272 trainer.py:139] Epoch[19/1500] loss: 0.2735811236169603
I0415 10:24:25.016175 31272 trainer.py:139] Epoch[20/1500] loss: 0.27063663105169933
I0415 10:25:26.498491 31272 trainer.py:139] Epoch[21/1500] loss: 0.26914542025989957
I0415 10:26:27.018028 31272 trainer.py:139] Epoch[22/1500] loss: 0.2668564114305708
I0415 10:27:32.473054 31272 trainer.py:139] Epoch[23/1500] loss: 0.2645162871148851
I0415 10:28:40.826383 31272 trainer.py:139] Epoch[24/1500] loss: 0.2632368085119459
I0415 10:29:44.104692 31272 trainer.py:139] Epoch[25/1500] loss: 0.26170029766029784
I0415 10:30:49.416197 31272 trainer.py:139] Epoch[26/1500] loss: 0.25979546586672464
I0415 10:31:50.275596 31272 trainer.py:139] Epoch[27/1500] loss: 0.25706026964717443
I0415 10:32:56.345565 31272 trainer.py:139] Epoch[28/1500] loss: 0.25389395316441854
I0415 10:33:56.746498 31272 trainer.py:139] Epoch[29/1500] loss: 0.2529262670543459
I0415 10:34:53.297404 31272 trainer.py:139] Epoch[30/1500] loss: 0.25125119778845045
I0415 10:35:51.350193 31272 trainer.py:139] Epoch[31/1500] loss: 0.25072417610221437
I0415 10:36:56.300906 31272 trainer.py:139] Epoch[32/1500] loss: 0.24967045671410032
I0415 10:38:02.538314 31272 trainer.py:139] Epoch[33/1500] loss: 0.24797349916564093
I0415 10:39:08.736852 31272 trainer.py:139] Epoch[34/1500] loss: 0.24747316433323754
I0415 10:40:05.056815 31272 trainer.py:139] Epoch[35/1500] loss: 0.24401459217071533
I0415 10:41:03.842154 31272 trainer.py:139] Epoch[36/1500] loss: 0.24370733982986875
I0415 10:42:08.937383 31272 trainer.py:139] Epoch[37/1500] loss: 0.24296052926116518
I0415 10:43:12.327316 31272 trainer.py:139] Epoch[38/1500] loss: 0.24191417071554397
I0415 10:44:16.109937 31272 trainer.py:139] Epoch[39/1500] loss: 0.24095777213573455
I0415 10:45:19.488342 31272 trainer.py:139] Epoch[40/1500] loss: 0.239491665230857
I0415 10:46:22.913160 31272 trainer.py:139] Epoch[41/1500] loss: 0.2391989705959956
I0415 10:47:25.329352 31272 trainer.py:139] Epoch[42/1500] loss: 0.23743127200338576
I0415 10:48:25.749221 31272 trainer.py:139] Epoch[43/1500] loss: 0.23651156663894654
I0415 10:49:29.842308 31272 trainer.py:139] Epoch[44/1500] loss: 0.2357112459341685
I0415 10:50:24.127702 31272 trainer.py:139] Epoch[45/1500] loss: 0.23596756352318657
I0415 10:51:19.407823 31272 trainer.py:139] Epoch[46/1500] loss: 0.23456700775358413
I0415 10:52:15.444516 31272 trainer.py:139] Epoch[47/1500] loss: 0.23408361011081272
I0415 10:53:18.950062 31272 trainer.py:139] Epoch[48/1500] loss: 0.23326703210671743
I0415 10:54:24.388931 31272 trainer.py:139] Epoch[49/1500] loss: 0.23282200396060942
I0415 10:54:25.480281 31272 trainer.py:145] Test: {'precision': 0.18465776293823036, 'recall': 0.2583463634982884, 'hit_ratio': 0.8923205342237062, 'ndcg': 0.2882799447558334}
I0415 10:55:30.958667 31272 trainer.py:139] Epoch[50/1500] loss: 0.23149677322970497
I0415 10:56:35.466727 31272 trainer.py:139] Epoch[51/1500] loss: 0.23092808491653866
I0415 10:57:41.322412 31272 trainer.py:139] Epoch[52/1500] loss: 0.23101243469450208
I0415 10:58:48.692032 31272 trainer.py:139] Epoch[53/1500] loss: 0.2303307565715578
I0415 10:59:54.053799 31272 trainer.py:139] Epoch[54/1500] loss: 0.22982354058159724
I0415 11:00:59.220787 31272 trainer.py:139] Epoch[55/1500] loss: 0.22893333931763968
I0415 11:02:11.331753 31272 trainer.py:139] Epoch[56/1500] loss: 0.22709362460507287
I0415 11:03:24.814920 31272 trainer.py:139] Epoch[57/1500] loss: 0.22795491966936324
I0415 11:04:38.610485 31272 trainer.py:139] Epoch[58/1500] loss: 0.2273048953877555
I0415 11:05:49.970598 31272 trainer.py:139] Epoch[59/1500] loss: 0.22598797652456495
I0415 11:07:02.478030 31272 trainer.py:139] Epoch[60/1500] loss: 0.22600554327170055
I0415 11:08:15.446353 31272 trainer.py:139] Epoch[61/1500] loss: 0.2257472723722458
I0415 11:09:28.152155 31272 trainer.py:139] Epoch[62/1500] loss: 0.22413519554668002
I0415 11:10:37.379560 31272 trainer.py:139] Epoch[63/1500] loss: 0.22435341497262318
I0415 11:11:40.631954 31272 trainer.py:139] Epoch[64/1500] loss: 0.22496684663825564
I0415 11:12:42.934944 31272 trainer.py:139] Epoch[65/1500] loss: 0.22429162124792734
I0415 11:13:42.499602 31272 trainer.py:139] Epoch[66/1500] loss: 0.22321061882707807
I0415 11:14:51.693274 31272 trainer.py:139] Epoch[67/1500] loss: 0.22235227002037897
I0415 11:16:04.688950 31272 trainer.py:139] Epoch[68/1500] loss: 0.22235016074445513
I0415 11:17:19.431904 31272 trainer.py:139] Epoch[69/1500] loss: 0.22140932069884406
I0415 11:18:30.204141 31272 trainer.py:139] Epoch[70/1500] loss: 0.22147503674030303
I0415 11:19:32.668648 31272 trainer.py:139] Epoch[71/1500] loss: 0.22122752924760183
I0415 11:20:39.750663 31272 trainer.py:139] Epoch[72/1500] loss: 0.22107692486710018
I0415 11:21:45.488534 31272 trainer.py:139] Epoch[73/1500] loss: 0.22052848570876651
I0415 11:22:54.680060 31272 trainer.py:139] Epoch[74/1500] loss: 0.22004908449119992
I0415 11:24:06.518579 31272 trainer.py:139] Epoch[75/1500] loss: 0.21925506307019127
I0415 11:25:18.469872 31272 trainer.py:139] Epoch[76/1500] loss: 0.22059245593018
I0415 11:26:31.595237 31272 trainer.py:139] Epoch[77/1500] loss: 0.21869355056020948
I0415 11:27:44.791366 31272 trainer.py:139] Epoch[78/1500] loss: 0.21877083718776702
I0415 11:28:58.492239 31272 trainer.py:139] Epoch[79/1500] loss: 0.21766507691807216
I0415 11:30:11.335547 31272 trainer.py:139] Epoch[80/1500] loss: 0.21782944745487637
I0415 11:31:23.842979 31272 trainer.py:139] Epoch[81/1500] loss: 0.21744604216681587
I0415 11:32:32.936832 31272 trainer.py:139] Epoch[82/1500] loss: 0.2172373918029997
I0415 11:33:42.692470 31272 trainer.py:139] Epoch[83/1500] loss: 0.2170714588297738
I0415 11:34:49.923554 31272 trainer.py:139] Epoch[84/1500] loss: 0.21636973407533433
I0415 11:35:58.213001 31272 trainer.py:139] Epoch[85/1500] loss: 0.21630966040823194
I0415 11:37:07.276953 31272 trainer.py:139] Epoch[86/1500] loss: 0.21597715530130598
I0415 11:38:15.988369 31272 trainer.py:139] Epoch[87/1500] loss: 0.21481230464246537
I0415 11:39:24.732069 31272 trainer.py:139] Epoch[88/1500] loss: 0.21566623588403067
I0415 11:40:39.572697 31272 trainer.py:139] Epoch[89/1500] loss: 0.21411465320322248
I0415 11:41:52.221655 31272 trainer.py:139] Epoch[90/1500] loss: 0.21508087906572554
I0415 11:43:05.623535 31272 trainer.py:139] Epoch[91/1500] loss: 0.2146694099240833
I0415 11:44:15.142962 31272 trainer.py:139] Epoch[92/1500] loss: 0.21376741508642833
I0415 11:45:29.363663 31272 trainer.py:139] Epoch[93/1500] loss: 0.2144289653831058
I0415 11:46:45.477894 31272 trainer.py:139] Epoch[94/1500] loss: 0.212979280617502
I0415 11:47:58.607246 31272 trainer.py:139] Epoch[95/1500] loss: 0.2148266280359692
I0415 11:49:11.025441 31272 trainer.py:139] Epoch[96/1500] loss: 0.21433909727467432
I0415 11:50:27.811559 31272 trainer.py:139] Epoch[97/1500] loss: 0.21383005254798465
I0415 11:51:41.430274 31272 trainer.py:139] Epoch[98/1500] loss: 0.2122340962621901
I0415 11:52:55.328055 31272 trainer.py:139] Epoch[99/1500] loss: 0.21265408171547784
I0415 11:52:56.603787 31272 trainer.py:145] Test: {'precision': 0.19342237061769615, 'recall': 0.27262859053674093, 'hit_ratio': 0.9030050083472454, 'ndcg': 0.3032223980330098}
I0415 11:54:06.254775 31272 trainer.py:139] Epoch[100/1500] loss: 0.21222664025094773
I0415 11:55:13.943329 31272 trainer.py:139] Epoch[101/1500] loss: 0.21329567160871293
I0415 11:56:19.830857 31272 trainer.py:139] Epoch[102/1500] loss: 0.21242350525326198
I0415 11:57:31.877800 31272 trainer.py:139] Epoch[103/1500] loss: 0.21255835592746736
I0415 11:58:47.536690 31272 trainer.py:139] Epoch[104/1500] loss: 0.21171090755197736
I0415 12:00:01.442444 31272 trainer.py:139] Epoch[105/1500] loss: 0.21210097670555114
I0415 12:01:17.375925 31272 trainer.py:139] Epoch[106/1500] loss: 0.21064415236314138
I0415 12:02:32.688973 31272 trainer.py:139] Epoch[107/1500] loss: 0.2099348752366172
I0415 12:03:44.778801 31272 trainer.py:139] Epoch[108/1500] loss: 0.2115990599658754
I0415 12:04:58.505639 31272 trainer.py:139] Epoch[109/1500] loss: 0.2114282790819804
I0415 12:06:13.573505 31272 trainer.py:139] Epoch[110/1500] loss: 0.20996290193663703
I0415 12:07:26.264325 31272 trainer.py:139] Epoch[111/1500] loss: 0.2098040657573276
I0415 12:08:41.214584 31272 trainer.py:139] Epoch[112/1500] loss: 0.21047071900632647
I0415 12:09:55.113364 31272 trainer.py:139] Epoch[113/1500] loss: 0.20954185836844974
I0415 12:11:10.419192 31272 trainer.py:139] Epoch[114/1500] loss: 0.21050881531503465
I0415 12:12:26.207648 31272 trainer.py:139] Epoch[115/1500] loss: 0.2093839290406969
I0415 12:13:41.801754 31272 trainer.py:139] Epoch[116/1500] loss: 0.20779728452364604
I0415 12:14:57.819443 31272 trainer.py:139] Epoch[117/1500] loss: 0.2099352123339971
I0415 12:16:13.003920 31272 trainer.py:139] Epoch[118/1500] loss: 0.2082025005420049
I0415 12:17:27.167811 31272 trainer.py:139] Epoch[119/1500] loss: 0.2090884299410714
I0415 12:18:41.347649 31272 trainer.py:139] Epoch[120/1500] loss: 0.2073025005393558
I0415 12:19:53.659735 31272 trainer.py:139] Epoch[121/1500] loss: 0.20828174571196237
I0415 12:21:08.020966 31272 trainer.py:139] Epoch[122/1500] loss: 0.20694850305716198
I0415 12:22:24.453268 31272 trainer.py:139] Epoch[123/1500] loss: 0.20874593045976428
I0415 12:23:35.704901 31272 trainer.py:139] Epoch[124/1500] loss: 0.20830939458476172
I0415 12:24:47.901373 31272 trainer.py:139] Epoch[125/1500] loss: 0.20745064636071522
I0415 12:25:59.843697 31272 trainer.py:139] Epoch[126/1500] loss: 0.20784562548001606
I0415 12:27:11.933526 31272 trainer.py:139] Epoch[127/1500] loss: 0.20837054544024997
I0415 12:28:25.455564 31272 trainer.py:139] Epoch[128/1500] loss: 0.20656180673175387
I0415 12:29:38.613820 31272 trainer.py:139] Epoch[129/1500] loss: 0.20656576057275136
I0415 12:30:50.828232 31272 trainer.py:139] Epoch[130/1500] loss: 0.20636185818248326
I0415 12:32:01.536682 31272 trainer.py:139] Epoch[131/1500] loss: 0.20753438121742673
I0415 12:33:02.100499 31272 trainer.py:139] Epoch[132/1500] loss: 0.2061546869410409
I0415 12:34:00.561362 31272 trainer.py:139] Epoch[133/1500] loss: 0.20664929668108623
I0415 12:34:59.378791 31272 trainer.py:139] Epoch[134/1500] loss: 0.2050504559940762
I0415 12:35:57.212110 31272 trainer.py:139] Epoch[135/1500] loss: 0.2062862569755978
I0415 12:36:53.133418 31272 trainer.py:139] Epoch[136/1500] loss: 0.2057969617843628
I0415 12:37:52.890124 31272 trainer.py:139] Epoch[137/1500] loss: 0.20582033269935185
I0415 12:38:50.476773 31272 trainer.py:139] Epoch[138/1500] loss: 0.20548734618557823
I0415 12:39:48.841367 31272 trainer.py:139] Epoch[139/1500] loss: 0.20537767820888095
I0415 12:40:46.668330 31272 trainer.py:139] Epoch[140/1500] loss: 0.20630124708016714
I0415 12:41:45.353886 31272 trainer.py:139] Epoch[141/1500] loss: 0.20558827737967172
I0415 12:42:43.646801 31272 trainer.py:139] Epoch[142/1500] loss: 0.20590096963776483
I0415 12:43:41.463762 31272 trainer.py:139] Epoch[143/1500] loss: 0.20529168241553836
I0415 12:44:39.707768 31272 trainer.py:139] Epoch[144/1500] loss: 0.20564068304167854
I0415 12:45:38.100404 31272 trainer.py:139] Epoch[145/1500] loss: 0.20587096340126462
I0415 12:46:36.670805 31272 trainer.py:139] Epoch[146/1500] loss: 0.20442784382237328
I0415 12:47:35.265432 31272 trainer.py:139] Epoch[147/1500] loss: 0.2043524220254686
I0415 12:48:34.047814 31272 trainer.py:139] Epoch[148/1500] loss: 0.20586770521269904
I0415 12:49:32.493592 31272 trainer.py:139] Epoch[149/1500] loss: 0.2036248340871599
I0415 12:49:33.396571 31272 trainer.py:145] Test: {'precision': 0.1962604340567613, 'recall': 0.27723792194432545, 'hit_ratio': 0.905008347245409, 'ndcg': 0.309206250554593}
I0415 12:50:32.311321 31272 trainer.py:139] Epoch[150/1500] loss: 0.20440566056304507
I0415 12:51:30.014481 31272 trainer.py:139] Epoch[151/1500] loss: 0.20487433135509492
I0415 12:52:28.754800 31272 trainer.py:139] Epoch[152/1500] loss: 0.20330951392650604
I0415 12:53:26.712789 31272 trainer.py:139] Epoch[153/1500] loss: 0.20316651860872906
I0415 12:54:25.884147 31272 trainer.py:139] Epoch[154/1500] loss: 0.20508458250098757
I0415 12:55:23.637224 31272 trainer.py:139] Epoch[155/1500] loss: 0.20288689725928835
I0415 12:56:23.186682 31272 trainer.py:139] Epoch[156/1500] loss: 0.20336456914742787
I0415 12:57:21.055365 31272 trainer.py:139] Epoch[157/1500] loss: 0.20355542732609644
I0415 12:58:19.005820 31272 trainer.py:139] Epoch[158/1500] loss: 0.20363370928499433
I0415 12:59:16.971113 31272 trainer.py:139] Epoch[159/1500] loss: 0.20384928789403703
I0415 13:00:15.420358 31272 trainer.py:139] Epoch[160/1500] loss: 0.20372169653574626
I0415 13:01:14.320083 31272 trainer.py:139] Epoch[161/1500] loss: 0.20319325069586436
I0415 13:02:12.704615 31272 trainer.py:139] Epoch[162/1500] loss: 0.20310920112662845
I0415 13:03:10.715966 31272 trainer.py:139] Epoch[163/1500] loss: 0.20320586356851789
I0415 13:04:08.880943 31272 trainer.py:139] Epoch[164/1500] loss: 0.20311277627944946
I0415 13:05:07.086228 31272 trainer.py:139] Epoch[165/1500] loss: 0.20164513621065352
I0415 13:06:05.485765 31272 trainer.py:139] Epoch[166/1500] loss: 0.2029596624771754
I0415 13:07:03.947812 31272 trainer.py:139] Epoch[167/1500] loss: 0.2022652135954963
I0415 13:08:01.880749 31272 trainer.py:139] Epoch[168/1500] loss: 0.2029116310013665
I0415 13:09:00.474690 31272 trainer.py:139] Epoch[169/1500] loss: 0.20207433693938784
I0415 13:09:59.285087 31272 trainer.py:139] Epoch[170/1500] loss: 0.20207674357626174
I0415 13:10:58.366431 31272 trainer.py:139] Epoch[171/1500] loss: 0.2017985040611691
I0415 13:11:56.922538 31272 trainer.py:139] Epoch[172/1500] loss: 0.20338529017236498
I0415 13:12:55.349916 31272 trainer.py:139] Epoch[173/1500] loss: 0.20171110418107774
I0415 13:13:53.559047 31272 trainer.py:139] Epoch[174/1500] loss: 0.2016103082895279
I0415 13:14:51.644673 31272 trainer.py:139] Epoch[175/1500] loss: 0.20167543258931903
I0415 13:15:50.244335 31272 trainer.py:139] Epoch[176/1500] loss: 0.20215450849797992
I0415 13:16:48.548985 31272 trainer.py:139] Epoch[177/1500] loss: 0.20237345609400006
I0415 13:17:46.813990 31272 trainer.py:139] Epoch[178/1500] loss: 0.20203437917762332
I0415 13:18:45.636174 31272 trainer.py:139] Epoch[179/1500] loss: 0.20125958018832737
I0415 13:19:44.503415 31272 trainer.py:139] Epoch[180/1500] loss: 0.20025586393144396
I0415 13:20:42.387635 31272 trainer.py:139] Epoch[181/1500] loss: 0.2019453830189175
I0415 13:21:40.892920 31272 trainer.py:139] Epoch[182/1500] loss: 0.2012379374106725
I0415 13:22:39.900326 31272 trainer.py:139] Epoch[183/1500] loss: 0.20074004921648236
I0415 13:23:40.387909 31272 trainer.py:139] Epoch[184/1500] loss: 0.2012979405456119
I0415 13:24:38.813365 31272 trainer.py:139] Epoch[185/1500] loss: 0.2011811993519465
I0415 13:25:37.235794 31272 trainer.py:139] Epoch[186/1500] loss: 0.20118450231022306
I0415 13:26:36.126615 31272 trainer.py:139] Epoch[187/1500] loss: 0.20100559658474393
I0415 13:27:34.508794 31272 trainer.py:139] Epoch[188/1500] loss: 0.2012441341744529
I0415 13:28:33.301489 31272 trainer.py:139] Epoch[189/1500] loss: 0.20089452611075506
I0415 13:29:32.055339 31272 trainer.py:139] Epoch[190/1500] loss: 0.20102772871653238
I0415 13:30:30.653096 31272 trainer.py:139] Epoch[191/1500] loss: 0.2008958641688029
I0415 13:31:29.409495 31272 trainer.py:139] Epoch[192/1500] loss: 0.20175277233123778
I0415 13:32:27.574836 31272 trainer.py:139] Epoch[193/1500] loss: 0.20078119503127204
I0415 13:33:25.882745 31272 trainer.py:139] Epoch[194/1500] loss: 0.2010461676783032
I0415 13:34:23.534596 31272 trainer.py:139] Epoch[195/1500] loss: 0.19985785086949667
I0415 13:35:21.633456 31272 trainer.py:139] Epoch[196/1500] loss: 0.20035910083187952
I0415 13:36:20.823968 31272 trainer.py:139] Epoch[197/1500] loss: 0.20010985599623787
I0415 13:37:20.050842 31272 trainer.py:139] Epoch[198/1500] loss: 0.20101167420546215
I0415 13:38:18.988569 31272 trainer.py:139] Epoch[199/1500] loss: 0.2003309565782547
I0415 13:38:20.034072 31272 trainer.py:145] Test: {'precision': 0.19870617696160264, 'recall': 0.28097539695517854, 'hit_ratio': 0.9056761268781303, 'ndcg': 0.3128210842104465}
I0415 13:39:19.580016 31272 trainer.py:139] Epoch[200/1500] loss: 0.20079677124818165
I0415 13:40:19.686745 31272 trainer.py:139] Epoch[201/1500] loss: 0.20034948858949872
I0415 13:41:27.293573 31272 trainer.py:139] Epoch[202/1500] loss: 0.1992381488614612
I0415 13:42:43.002756 31272 trainer.py:139] Epoch[203/1500] loss: 0.1988458501630359
I0415 13:43:57.895211 31272 trainer.py:139] Epoch[204/1500] loss: 0.20086768130461374
I0415 13:45:13.590882 31272 trainer.py:139] Epoch[205/1500] loss: 0.2005706414911482
I0415 13:46:27.606269 31272 trainer.py:139] Epoch[206/1500] loss: 0.1989153822263082
I0415 13:47:43.251207 31272 trainer.py:139] Epoch[207/1500] loss: 0.19955013692378998
I0415 13:48:51.517824 31272 trainer.py:139] Epoch[208/1500] loss: 0.19990280124876234
I0415 13:50:07.429867 31272 trainer.py:139] Epoch[209/1500] loss: 0.199560380909178
I0415 13:51:20.913036 31272 trainer.py:139] Epoch[210/1500] loss: 0.1996290302938885
I0415 13:52:30.821166 31272 trainer.py:139] Epoch[211/1500] loss: 0.19904372758335537
I0415 13:53:41.747884 31272 trainer.py:139] Epoch[212/1500] loss: 0.19988139655854967
I0415 13:54:49.166769 31272 trainer.py:139] Epoch[213/1500] loss: 0.19977349506484138
I0415 13:55:58.695605 31272 trainer.py:139] Epoch[214/1500] loss: 0.1987767802344428
I0415 13:57:06.466312 31272 trainer.py:139] Epoch[215/1500] loss: 0.19877090950806936
I0415 13:58:15.603022 31272 trainer.py:139] Epoch[216/1500] loss: 0.19931596179803213
I0415 13:59:22.221156 31272 trainer.py:139] Epoch[217/1500] loss: 0.1994139697154363
I0415 14:00:33.712987 31272 trainer.py:139] Epoch[218/1500] loss: 0.19869342578781976
I0415 14:01:44.061640 31272 trainer.py:139] Epoch[219/1500] loss: 0.19900738464461432
I0415 14:02:54.145181 31272 trainer.py:139] Epoch[220/1500] loss: 0.19840020656585694
I0415 14:03:55.329494 31272 trainer.py:139] Epoch[221/1500] loss: 0.19964924017588298
I0415 14:04:57.149682 31272 trainer.py:139] Epoch[222/1500] loss: 0.19891147620148128
I0415 14:06:03.772798 31272 trainer.py:139] Epoch[223/1500] loss: 0.1993068257305357
I0415 14:07:13.201530 31272 trainer.py:139] Epoch[224/1500] loss: 0.1991545988453759
I0415 14:08:20.601051 31272 trainer.py:139] Epoch[225/1500] loss: 0.1988201575146781
I0415 14:09:26.901026 31272 trainer.py:139] Epoch[226/1500] loss: 0.1993854551182853
I0415 14:10:32.324158 31272 trainer.py:139] Epoch[227/1500] loss: 0.19906613137986925
I0415 14:11:41.780941 31272 trainer.py:139] Epoch[228/1500] loss: 0.19869869192441306
I0415 14:12:37.910166 31272 trainer.py:139] Epoch[229/1500] loss: 0.19868909272882673
I0415 14:13:26.791474 31272 trainer.py:139] Epoch[230/1500] loss: 0.19870455589559344
I0415 14:14:16.835059 31272 trainer.py:139] Epoch[231/1500] loss: 0.1985462874836392
I0415 14:15:09.735085 31272 trainer.py:139] Epoch[232/1500] loss: 0.19884351703855727
I0415 14:16:10.070915 31272 trainer.py:139] Epoch[233/1500] loss: 0.19791813890139262
I0415 14:17:10.484252 31272 trainer.py:139] Epoch[234/1500] loss: 0.19778808130158318
I0415 14:18:13.071303 31272 trainer.py:139] Epoch[235/1500] loss: 0.19718238572279612
I0415 14:19:19.163175 31272 trainer.py:139] Epoch[236/1500] loss: 0.19832081172201368
I0415 14:20:27.236865 31272 trainer.py:139] Epoch[237/1500] loss: 0.19790982557667627
I0415 14:21:39.728351 31272 trainer.py:139] Epoch[238/1500] loss: 0.19773980915546419
I0415 14:22:47.544477 31272 trainer.py:139] Epoch[239/1500] loss: 0.19861014703909555
I0415 14:23:52.345691 31272 trainer.py:139] Epoch[240/1500] loss: 0.19749251511361865
I0415 14:25:04.864596 31272 trainer.py:139] Epoch[241/1500] loss: 0.1978878045744366
I0415 14:26:16.112244 31272 trainer.py:139] Epoch[242/1500] loss: 0.19773997637960647
I0415 14:27:27.801413 31272 trainer.py:139] Epoch[243/1500] loss: 0.19734821961985693
I0415 14:28:38.366344 31272 trainer.py:139] Epoch[244/1500] loss: 0.19666590127680036
I0415 14:29:49.519771 31272 trainer.py:139] Epoch[245/1500] loss: 0.1976100681225459
I0415 14:30:56.013275 31272 trainer.py:139] Epoch[246/1500] loss: 0.1968859424855974
I0415 14:31:49.873090 31272 trainer.py:139] Epoch[247/1500] loss: 0.19704576896296608
I0415 14:32:42.395632 31272 trainer.py:139] Epoch[248/1500] loss: 0.1979058372312122
I0415 14:33:34.751440 31272 trainer.py:139] Epoch[249/1500] loss: 0.19811615990267858
I0415 14:33:35.548773 31272 trainer.py:145] Test: {'precision': 0.19993322203672784, 'recall': 0.2823999144285367, 'hit_ratio': 0.9093489148580969, 'ndcg': 0.3155176691758916}
I0415 14:34:36.481395 31272 trainer.py:139] Epoch[250/1500] loss: 0.1977718734741211
I0415 14:35:44.712135 31272 trainer.py:139] Epoch[251/1500] loss: 0.19783847683005862
I0415 14:36:53.385365 31272 trainer.py:139] Epoch[252/1500] loss: 0.19787513322300382
I0415 14:38:01.820835 31272 trainer.py:139] Epoch[253/1500] loss: 0.1969382209248013
I0415 14:39:10.404396 31272 trainer.py:139] Epoch[254/1500] loss: 0.19804824795987871
I0415 14:40:18.973006 31272 trainer.py:139] Epoch[255/1500] loss: 0.19720062898264992
I0415 14:41:27.725997 31272 trainer.py:139] Epoch[256/1500] loss: 0.1981036780277888
I0415 14:42:35.117545 31272 trainer.py:139] Epoch[257/1500] loss: 0.19828126390775044
I0415 14:43:43.069217 31272 trainer.py:139] Epoch[258/1500] loss: 0.197799205382665
I0415 14:44:49.367422 31272 trainer.py:139] Epoch[259/1500] loss: 0.1966765988535351
I0415 14:45:49.585966 31272 trainer.py:139] Epoch[260/1500] loss: 0.19642444246345095
I0415 14:46:56.020162 31272 trainer.py:139] Epoch[261/1500] loss: 0.19630535503228505
I0415 14:47:59.046312 31272 trainer.py:139] Epoch[262/1500] loss: 0.19798281676239438
I0415 14:49:08.026544 31272 trainer.py:139] Epoch[263/1500] loss: 0.19770167880588108
I0415 14:50:16.551301 31272 trainer.py:139] Epoch[264/1500] loss: 0.1971040168735716
I0415 14:51:25.194660 31272 trainer.py:139] Epoch[265/1500] loss: 0.1976651119523578
I0415 14:52:33.732373 31272 trainer.py:139] Epoch[266/1500] loss: 0.1968804695871141
I0415 14:53:41.506640 31272 trainer.py:139] Epoch[267/1500] loss: 0.19717614220248328
I0415 14:54:45.135768 31272 trainer.py:139] Epoch[268/1500] loss: 0.19903149002128176
I0415 14:55:51.032822 31272 trainer.py:139] Epoch[269/1500] loss: 0.19697625915209452
I0415 14:56:59.662229 31272 trainer.py:139] Epoch[270/1500] loss: 0.19685963028007084
I0415 14:58:04.784368 31272 trainer.py:139] Epoch[271/1500] loss: 0.19713349017832013
I0415 14:59:12.817767 31272 trainer.py:139] Epoch[272/1500] loss: 0.19715194271670447
I0415 15:00:21.114287 31272 trainer.py:139] Epoch[273/1500] loss: 0.19735310521390703
I0415 15:01:25.132121 31272 trainer.py:139] Epoch[274/1500] loss: 0.1962634465429518
I0415 15:02:34.375472 31272 trainer.py:139] Epoch[275/1500] loss: 0.19649334881040786
I0415 15:03:41.120185 31272 trainer.py:139] Epoch[276/1500] loss: 0.19614541007412806
I0415 15:04:49.371853 31272 trainer.py:139] Epoch[277/1500] loss: 0.1960243273443646
I0415 15:05:55.211495 31272 trainer.py:139] Epoch[278/1500] loss: 0.1969833587275611
I0415 15:07:04.592388 31272 trainer.py:139] Epoch[279/1500] loss: 0.19628039095136854
I0415 15:08:07.481996 31272 trainer.py:139] Epoch[280/1500] loss: 0.19580150690343645
I0415 15:08:59.434542 31272 trainer.py:139] Epoch[281/1500] loss: 0.19659966700606876
I0415 15:09:51.802182 31272 trainer.py:139] Epoch[282/1500] loss: 0.19658688538604313
I0415 15:10:43.855069 31272 trainer.py:139] Epoch[283/1500] loss: 0.19736321522129907
I0415 15:11:35.480361 31272 trainer.py:139] Epoch[284/1500] loss: 0.1966350272628996
I0415 15:12:27.428878 31272 trainer.py:139] Epoch[285/1500] loss: 0.19715072247717116
I0415 15:13:19.388054 31272 trainer.py:139] Epoch[286/1500] loss: 0.19611928158336214
I0415 15:14:11.602375 31272 trainer.py:139] Epoch[287/1500] loss: 0.19651321874724495
I0415 15:15:10.234226 31272 trainer.py:139] Epoch[288/1500] loss: 0.19654368082682291
I0415 15:16:16.232895 31272 trainer.py:139] Epoch[289/1500] loss: 0.1968493021196789
I0415 15:17:24.524432 31272 trainer.py:139] Epoch[290/1500] loss: 0.1962124170197381
I0415 15:18:31.527280 31272 trainer.py:139] Epoch[291/1500] loss: 0.19624566064940557
I0415 15:19:39.935438 31272 trainer.py:139] Epoch[292/1500] loss: 0.19681070062849257
I0415 15:20:46.432975 31272 trainer.py:139] Epoch[293/1500] loss: 0.19670344856050279
I0415 15:22:00.204180 31272 trainer.py:139] Epoch[294/1500] loss: 0.19578902721405028
I0415 15:23:13.842828 31272 trainer.py:139] Epoch[295/1500] loss: 0.19512673013740114
I0415 15:24:29.870484 31272 trainer.py:139] Epoch[296/1500] loss: 0.19681831651263768
I0415 15:25:40.626775 31272 trainer.py:139] Epoch[297/1500] loss: 0.19645587066809336
I0415 15:26:57.152385 31272 trainer.py:139] Epoch[298/1500] loss: 0.19525255196624333
I0415 15:28:09.527242 31272 trainer.py:139] Epoch[299/1500] loss: 0.19620233297348022
I0415 15:28:10.674405 31272 trainer.py:145] Test: {'precision': 0.20046744574290476, 'recall': 0.28385921044695134, 'hit_ratio': 0.9118530884808014, 'ndcg': 0.3165392927855095}
I0415 15:29:25.146145 31272 trainer.py:139] Epoch[300/1500] loss: 0.1963728705379698
I0415 15:30:35.411963 31272 trainer.py:139] Epoch[301/1500] loss: 0.19682226637999217
I0415 15:31:35.246100 31272 trainer.py:139] Epoch[302/1500] loss: 0.19606606907314725
I0415 15:32:28.364288 31272 trainer.py:139] Epoch[303/1500] loss: 0.19501278592480553
I0415 15:34:09.405460 31272 trainer.py:139] Epoch[304/1500] loss: 0.19677234093348187
I0415 15:35:39.167798 31272 trainer.py:139] Epoch[305/1500] loss: 0.1959952695502175
I0415 15:37:50.891185 31272 trainer.py:139] Epoch[306/1500] loss: 0.19518791841136085
I0415 15:40:02.485648 31272 trainer.py:139] Epoch[307/1500] loss: 0.19464737441804675
I0415 15:42:15.040652 31272 trainer.py:139] Epoch[308/1500] loss: 0.19559064269065857
I0415 15:44:11.634940 31272 trainer.py:139] Epoch[309/1500] loss: 0.1951442223125034
I0415 15:45:04.137298 31272 trainer.py:139] Epoch[310/1500] loss: 0.19613701972696515
I0415 15:46:07.208804 31272 trainer.py:139] Epoch[311/1500] loss: 0.19575539588928223
I0415 15:47:15.549955 31272 trainer.py:139] Epoch[312/1500] loss: 0.19766939381758372
I0415 15:48:24.451307 31272 trainer.py:139] Epoch[313/1500] loss: 0.19504297190242342
I0415 15:49:35.087508 31272 trainer.py:139] Epoch[314/1500] loss: 0.19499001648690967
I0415 15:50:47.585971 31272 trainer.py:139] Epoch[315/1500] loss: 0.1956343326303694
I0415 15:51:56.850672 31272 trainer.py:139] Epoch[316/1500] loss: 0.1955348622136646
I0415 15:53:08.157483 31272 trainer.py:139] Epoch[317/1500] loss: 0.1950969178146786
I0415 15:54:17.330527 31272 trainer.py:139] Epoch[318/1500] loss: 0.19515666868951587
I0415 15:55:10.263388 31272 trainer.py:139] Epoch[319/1500] loss: 0.19547249376773834
I0415 15:56:03.657243 31272 trainer.py:139] Epoch[320/1500] loss: 0.19454459647337596
I0415 15:57:11.985657 31272 trainer.py:139] Epoch[321/1500] loss: 0.19606270849704743
I0415 15:58:20.775527 31272 trainer.py:139] Epoch[322/1500] loss: 0.195381106072002
I0415 15:59:26.962099 31272 trainer.py:139] Epoch[323/1500] loss: 0.1948865544133716
I0415 16:00:33.011137 31272 trainer.py:139] Epoch[324/1500] loss: 0.19503063804573484
I0415 16:01:41.884726 31272 trainer.py:139] Epoch[325/1500] loss: 0.19531746016608345
I0415 16:02:54.701125 31272 trainer.py:139] Epoch[326/1500] loss: 0.19504155668947432
I0415 16:04:03.261363 31272 trainer.py:139] Epoch[327/1500] loss: 0.194740056792895
I0415 16:05:11.839939 31272 trainer.py:139] Epoch[328/1500] loss: 0.1953263651000129
I0415 16:06:24.931417 31272 trainer.py:139] Epoch[329/1500] loss: 0.19605226907465192
I0415 16:07:38.291995 31272 trainer.py:139] Epoch[330/1500] loss: 0.1959709080060323
I0415 16:08:51.810047 31272 trainer.py:139] Epoch[331/1500] loss: 0.19499176482359568
I0415 16:10:03.314834 31272 trainer.py:139] Epoch[332/1500] loss: 0.19495222389698028
I0415 16:11:15.468449 31272 trainer.py:139] Epoch[333/1500] loss: 0.19485879758993785
I0415 16:12:32.886523 31272 trainer.py:139] Epoch[334/1500] loss: 0.1953026372856564
I0415 16:13:52.510654 31272 trainer.py:139] Epoch[335/1500] loss: 0.19520466658804153
I0415 16:15:09.681486 31272 trainer.py:139] Epoch[336/1500] loss: 0.19623869597911836
I0415 16:16:29.781517 31272 trainer.py:139] Epoch[337/1500] loss: 0.19510009798738692
I0415 16:17:47.231417 31272 trainer.py:139] Epoch[338/1500] loss: 0.19486658341354793
I0415 16:19:08.362996 31272 trainer.py:139] Epoch[339/1500] loss: 0.19433041936821407
I0415 16:20:28.168522 31272 trainer.py:139] Epoch[340/1500] loss: 0.19412285407384236
I0415 16:21:40.102872 31272 trainer.py:139] Epoch[341/1500] loss: 0.19313928531275856
I0415 16:22:57.707265 31272 trainer.py:139] Epoch[342/1500] loss: 0.1956882835759057
I0415 16:24:12.928618 31272 trainer.py:139] Epoch[343/1500] loss: 0.19540916595194074
I0415 16:25:34.606373 31272 trainer.py:139] Epoch[344/1500] loss: 0.1947736362616221
I0415 16:26:53.715719 31272 trainer.py:139] Epoch[345/1500] loss: 0.1938206981950336
I0415 16:28:11.061442 31272 trainer.py:139] Epoch[346/1500] loss: 0.1947100015481313
I0415 16:29:24.666203 31272 trainer.py:139] Epoch[347/1500] loss: 0.1942545994785097
I0415 16:30:38.251032 31272 trainer.py:139] Epoch[348/1500] loss: 0.1948226139280531
I0415 16:31:57.595590 31272 trainer.py:139] Epoch[349/1500] loss: 0.19514056417677136
I0415 16:31:58.831457 31272 trainer.py:145] Test: {'precision': 0.20066777963272117, 'recall': 0.28517341628332427, 'hit_ratio': 0.9121869782971619, 'ndcg': 0.31741749995783936}
I0415 16:33:16.436833 31272 trainer.py:139] Epoch[350/1500] loss: 0.19394923932022518
I0415 16:34:35.316946 31272 trainer.py:139] Epoch[351/1500] loss: 0.1942132466369205
I0415 16:35:58.066116 31272 trainer.py:139] Epoch[352/1500] loss: 0.19408476538128322
I0415 16:37:18.825941 31272 trainer.py:139] Epoch[353/1500] loss: 0.19398479912016126
I0415 16:38:13.290241 31272 trainer.py:139] Epoch[354/1500] loss: 0.19437711748811934
I0415 16:39:08.137754 31272 trainer.py:139] Epoch[355/1500] loss: 0.1940590098169115
I0415 16:40:01.266010 31272 trainer.py:139] Epoch[356/1500] loss: 0.19489962286419338
I0415 16:40:53.378620 31272 trainer.py:139] Epoch[357/1500] loss: 0.1944066310591168
I0415 16:41:45.504650 31272 trainer.py:139] Epoch[358/1500] loss: 0.19370103703604805
I0415 16:42:37.447878 31272 trainer.py:139] Epoch[359/1500] loss: 0.19552635358439552
I0415 16:43:29.952229 31272 trainer.py:139] Epoch[360/1500] loss: 0.19446716169516245
I0415 16:44:22.539304 31272 trainer.py:139] Epoch[361/1500] loss: 0.19416663646697999
I0415 16:45:14.462599 31272 trainer.py:139] Epoch[362/1500] loss: 0.19506481640868717
I0415 16:46:06.817306 31272 trainer.py:139] Epoch[363/1500] loss: 0.19429228021038902
I0415 16:46:58.920921 31272 trainer.py:139] Epoch[364/1500] loss: 0.1951163601875305
I0415 16:47:51.829972 31272 trainer.py:139] Epoch[365/1500] loss: 0.19488044685787625
I0415 16:48:45.790241 31272 trainer.py:139] Epoch[366/1500] loss: 0.1938537413544125
I0415 16:49:40.813131 31272 trainer.py:139] Epoch[367/1500] loss: 0.19381144709057277
I0415 16:50:35.723408 31272 trainer.py:139] Epoch[368/1500] loss: 0.1939320284128189
I0415 16:51:28.136067 31272 trainer.py:139] Epoch[369/1500] loss: 0.19353075444698334
I0415 16:52:21.504529 31272 trainer.py:139] Epoch[370/1500] loss: 0.19263167129622566
I0415 16:53:14.069461 31272 trainer.py:139] Epoch[371/1500] loss: 0.19467052161693574
I0415 16:54:18.391800 31272 trainer.py:139] Epoch[372/1500] loss: 0.1946821269724104
I0415 16:55:19.633387 31272 trainer.py:139] Epoch[373/1500] loss: 0.1954046917623944
I0415 16:56:23.007377 31272 trainer.py:139] Epoch[374/1500] loss: 0.1944386123948627
I0415 16:57:24.127611 31272 trainer.py:139] Epoch[375/1500] loss: 0.1948767779933082
I0415 16:58:25.693133 31272 trainer.py:139] Epoch[376/1500] loss: 0.19450150609016417
I0415 16:59:26.496850 31272 trainer.py:139] Epoch[377/1500] loss: 0.19408756428294713
I0415 17:00:27.104922 31272 trainer.py:139] Epoch[378/1500] loss: 0.19436573525269826
I0415 17:01:30.576418 31272 trainer.py:139] Epoch[379/1500] loss: 0.19506128443611992
I0415 17:02:40.550719 31272 trainer.py:139] Epoch[380/1500] loss: 0.19401450627379946
I0415 17:03:51.965237 31272 trainer.py:139] Epoch[381/1500] loss: 0.19370932552549575
I0415 17:05:01.791446 31272 trainer.py:139] Epoch[382/1500] loss: 0.19404589176177978
I0415 17:06:13.965777 31272 trainer.py:139] Epoch[383/1500] loss: 0.19426350123352476
I0415 17:07:25.655962 31272 trainer.py:139] Epoch[384/1500] loss: 0.19401958730485705
I0415 17:08:18.085562 31272 trainer.py:139] Epoch[385/1500] loss: 0.19480455630355412
I0415 17:09:10.900332 31272 trainer.py:139] Epoch[386/1500] loss: 0.19468434618579017
I0415 17:10:06.768549 31272 trainer.py:139] Epoch[387/1500] loss: 0.19421283490127988
I0415 17:10:57.489897 31272 trainer.py:139] Epoch[388/1500] loss: 0.19439925975269742
I0415 17:11:42.767424 31272 trainer.py:139] Epoch[389/1500] loss: 0.19316461126009624
I0415 17:12:26.643598 31272 trainer.py:139] Epoch[390/1500] loss: 0.194569610092375
I0415 17:13:10.586527 31272 trainer.py:139] Epoch[391/1500] loss: 0.19383975161446465
I0415 17:13:54.357466 31272 trainer.py:139] Epoch[392/1500] loss: 0.19484004086918302
I0415 17:14:38.403123 31272 trainer.py:139] Epoch[393/1500] loss: 0.19376216113567352
I0415 17:15:22.347971 31272 trainer.py:139] Epoch[394/1500] loss: 0.19398780074384478
I0415 17:16:06.152566 31272 trainer.py:139] Epoch[395/1500] loss: 0.194017700486713
I0415 17:16:50.299947 31272 trainer.py:139] Epoch[396/1500] loss: 0.19383095641930898
I0415 17:17:34.168427 31272 trainer.py:139] Epoch[397/1500] loss: 0.19441378898090786
I0415 17:18:18.379956 31272 trainer.py:139] Epoch[398/1500] loss: 0.19412537455558776
I0415 17:19:04.422620 31272 trainer.py:139] Epoch[399/1500] loss: 0.1937845418850581
I0415 17:19:05.140219 31272 trainer.py:145] Test: {'precision': 0.20071786310517528, 'recall': 0.2837215540767869, 'hit_ratio': 0.9095158597662771, 'ndcg': 0.3171122493556334}
I0415 17:19:51.638090 31272 trainer.py:139] Epoch[400/1500] loss: 0.19383050673537783
I0415 17:20:38.169929 31272 trainer.py:139] Epoch[401/1500] loss: 0.1938931816154056
I0415 17:21:24.530267 31272 trainer.py:139] Epoch[402/1500] loss: 0.19383543597327338
I0415 17:22:10.637021 31272 trainer.py:139] Epoch[403/1500] loss: 0.19294479747613272
I0415 17:22:57.391058 31272 trainer.py:139] Epoch[404/1500] loss: 0.19424484524461957
I0415 17:23:43.569572 31272 trainer.py:139] Epoch[405/1500] loss: 0.19464985503090754
I0415 17:24:29.690120 31272 trainer.py:139] Epoch[406/1500] loss: 0.19319537255499097
I0415 17:25:15.960608 31272 trainer.py:139] Epoch[407/1500] loss: 0.19356740481323667
I0415 17:26:01.817110 31272 trainer.py:139] Epoch[408/1500] loss: 0.19431320899062687
I0415 17:26:47.839609 31272 trainer.py:139] Epoch[409/1500] loss: 0.19286289367410872
I0415 17:27:34.085318 31272 trainer.py:139] Epoch[410/1500] loss: 0.19366015156110128
I0415 17:28:20.011473 31272 trainer.py:139] Epoch[411/1500] loss: 0.19242741485436757
I0415 17:29:06.434115 31272 trainer.py:139] Epoch[412/1500] loss: 0.19347757710350885
I0415 17:29:52.466016 31272 trainer.py:139] Epoch[413/1500] loss: 0.19429215729236604
I0415 17:30:38.474610 31272 trainer.py:139] Epoch[414/1500] loss: 0.19244422058264415
I0415 17:31:24.733854 31272 trainer.py:139] Epoch[415/1500] loss: 0.19322600483894348
I0415 17:32:10.669103 31272 trainer.py:139] Epoch[416/1500] loss: 0.1936217223935657
I0415 17:32:56.811594 31272 trainer.py:139] Epoch[417/1500] loss: 0.19295662422974905
I0415 17:33:43.386792 31272 trainer.py:139] Epoch[418/1500] loss: 0.19329618023501502
I0415 17:34:30.006807 31272 trainer.py:139] Epoch[419/1500] loss: 0.19440026766724056
I0415 17:35:15.795179 31272 trainer.py:139] Epoch[420/1500] loss: 0.19301514698399438
I0415 17:36:01.757653 31272 trainer.py:139] Epoch[421/1500] loss: 0.19346832268767886
I0415 17:36:48.490313 31272 trainer.py:139] Epoch[422/1500] loss: 0.19390203124947017
I0415 17:37:34.992079 31272 trainer.py:139] Epoch[423/1500] loss: 0.19319608993000453
I0415 17:38:22.003259 31272 trainer.py:139] Epoch[424/1500] loss: 0.19340334680345322
I0415 17:39:11.589011 31272 trainer.py:139] Epoch[425/1500] loss: 0.19416811956299676
I0415 17:40:00.799381 31272 trainer.py:139] Epoch[426/1500] loss: 0.19318028370539347
I0415 17:40:49.739656 31272 trainer.py:139] Epoch[427/1500] loss: 0.19342778199248845
I0415 17:41:38.641482 31272 trainer.py:139] Epoch[428/1500] loss: 0.19284160567654504
I0415 17:42:28.401522 31272 trainer.py:139] Epoch[429/1500] loss: 0.1936435553100374
I0415 17:43:17.082119 31272 trainer.py:139] Epoch[430/1500] loss: 0.19391915109422472
I0415 17:44:06.495809 31272 trainer.py:139] Epoch[431/1500] loss: 0.19339153514968024
I0415 17:44:55.733568 31272 trainer.py:139] Epoch[432/1500] loss: 0.1945409235689375
I0415 17:45:46.112454 31272 trainer.py:139] Epoch[433/1500] loss: 0.19321223815282185
I0415 17:46:35.715728 31272 trainer.py:139] Epoch[434/1500] loss: 0.1929393133189943
I0415 17:47:24.606168 31272 trainer.py:139] Epoch[435/1500] loss: 0.19353683571020763
I0415 17:48:14.816663 31272 trainer.py:139] Epoch[436/1500] loss: 0.19271772815121543
I0415 17:49:03.997642 31272 trainer.py:139] Epoch[437/1500] loss: 0.19312532034185198
I0415 17:49:52.623397 31272 trainer.py:139] Epoch[438/1500] loss: 0.19358208199342092
I0415 17:50:43.107507 31272 trainer.py:139] Epoch[439/1500] loss: 0.1917217406961653
I0415 17:51:32.739673 31272 trainer.py:139] Epoch[440/1500] loss: 0.19330308728747897
I0415 17:52:22.337977 31272 trainer.py:139] Epoch[441/1500] loss: 0.19259311589929792
I0415 17:53:12.347554 31272 trainer.py:139] Epoch[442/1500] loss: 0.19334813535213471
I0415 17:54:02.620325 31272 trainer.py:139] Epoch[443/1500] loss: 0.19313113543722366
I0415 17:54:52.165621 31272 trainer.py:139] Epoch[444/1500] loss: 0.1932894888189104
I0415 17:55:41.229925 31272 trainer.py:139] Epoch[445/1500] loss: 0.19295198963748084
I0415 17:56:30.924098 31272 trainer.py:139] Epoch[446/1500] loss: 0.19380082415209876
I0415 17:57:19.706899 31272 trainer.py:139] Epoch[447/1500] loss: 0.1932724244064755
I0415 17:58:10.445158 31272 trainer.py:139] Epoch[448/1500] loss: 0.1927297399441401
I0415 17:59:04.721580 31272 trainer.py:139] Epoch[449/1500] loss: 0.19327460262510512
I0415 17:59:05.555790 31272 trainer.py:145] Test: {'precision': 0.2012353923205342, 'recall': 0.28573576666613165, 'hit_ratio': 0.9121869782971619, 'ndcg': 0.3184673495366125}
I0415 17:59:59.180837 31272 trainer.py:139] Epoch[450/1500] loss: 0.19244104630417294
I0415 18:00:53.772206 31272 trainer.py:139] Epoch[451/1500] loss: 0.1931599947479036
I0415 18:01:52.908830 31272 trainer.py:139] Epoch[452/1500] loss: 0.19351257416937087
I0415 18:02:55.486862 31272 trainer.py:139] Epoch[453/1500] loss: 0.19271490573883057
I0415 18:03:53.491370 31272 trainer.py:139] Epoch[454/1500] loss: 0.19344316568639544
I0415 18:04:53.525011 31272 trainer.py:139] Epoch[455/1500] loss: 0.19414056148793962
I0415 18:05:52.977064 31272 trainer.py:139] Epoch[456/1500] loss: 0.19231786919964686
I0415 18:06:52.678339 31272 trainer.py:139] Epoch[457/1500] loss: 0.1929739827579922
I0415 18:07:51.046579 31272 trainer.py:139] Epoch[458/1500] loss: 0.193331022395028
I0415 18:08:51.422248 31272 trainer.py:139] Epoch[459/1500] loss: 0.19252575225300259
I0415 18:09:50.644497 31272 trainer.py:139] Epoch[460/1500] loss: 0.19367708477709028
I0415 18:10:50.796711 31272 trainer.py:139] Epoch[461/1500] loss: 0.19250280506081052
I0415 18:11:50.745599 31272 trainer.py:139] Epoch[462/1500] loss: 0.1930140629079607
I0415 18:12:51.422613 31272 trainer.py:139] Epoch[463/1500] loss: 0.19317787349224091
I0415 18:13:51.408322 31272 trainer.py:139] Epoch[464/1500] loss: 0.19245558381080627
I0415 18:14:51.330250 31272 trainer.py:139] Epoch[465/1500] loss: 0.1925426662630505
I0415 18:15:51.449539 31272 trainer.py:139] Epoch[466/1500] loss: 0.19270080367724102
I0415 18:16:50.884315 31272 trainer.py:139] Epoch[467/1500] loss: 0.19301982568369971
I0415 18:17:51.071674 31272 trainer.py:139] Epoch[468/1500] loss: 0.1925755218002531
I0415 18:18:49.343583 31272 trainer.py:139] Epoch[469/1500] loss: 0.19251905077033574
I0415 18:19:49.851398 31272 trainer.py:139] Epoch[470/1500] loss: 0.19401807281706068
I0415 18:20:50.136124 31272 trainer.py:139] Epoch[471/1500] loss: 0.1936367575989829
I0415 18:21:50.322082 31272 trainer.py:139] Epoch[472/1500] loss: 0.19272574034002093
I0415 18:22:50.267605 31272 trainer.py:139] Epoch[473/1500] loss: 0.193335672683186
I0415 18:23:50.157988 31272 trainer.py:139] Epoch[474/1500] loss: 0.1929490672879749
I0415 18:24:49.003590 31272 trainer.py:139] Epoch[475/1500] loss: 0.19273258123132916
I0415 18:25:48.061017 31272 trainer.py:139] Epoch[476/1500] loss: 0.19263642052809396
I0415 18:26:47.693390 31272 trainer.py:139] Epoch[477/1500] loss: 0.19271935343742372
I0415 18:27:47.715138 31272 trainer.py:139] Epoch[478/1500] loss: 0.19316688319047293
I0415 18:28:47.678535 31272 trainer.py:139] Epoch[479/1500] loss: 0.1929087891843584
I0415 18:29:47.840745 31272 trainer.py:139] Epoch[480/1500] loss: 0.1933459312385983
I0415 18:30:47.599680 31272 trainer.py:139] Epoch[481/1500] loss: 0.1919082851542367
I0415 18:31:45.326918 31272 trainer.py:139] Epoch[482/1500] loss: 0.19298352360725401
I0415 18:32:45.173618 31272 trainer.py:139] Epoch[483/1500] loss: 0.19261289139588675
I0415 18:33:44.806027 31272 trainer.py:139] Epoch[484/1500] loss: 0.19296861853864458
I0415 18:34:44.685362 31272 trainer.py:139] Epoch[485/1500] loss: 0.19296037428908877
I0415 18:35:44.545388 31272 trainer.py:139] Epoch[486/1500] loss: 0.19261416090859307
I0415 18:36:43.399118 31272 trainer.py:139] Epoch[487/1500] loss: 0.19268832001421188
I0415 18:37:42.797886 31272 trainer.py:139] Epoch[488/1500] loss: 0.19208981070253583
I0415 18:38:43.029321 31272 trainer.py:139] Epoch[489/1500] loss: 0.19245695730050405
I0415 18:39:42.639168 31272 trainer.py:139] Epoch[490/1500] loss: 0.19260041309727563
I0415 18:40:42.513781 31272 trainer.py:139] Epoch[491/1500] loss: 0.19345025420188905
I0415 18:41:42.046019 31272 trainer.py:139] Epoch[492/1500] loss: 0.19245189792580075
I0415 18:42:41.636092 31272 trainer.py:139] Epoch[493/1500] loss: 0.1931748421324624
I0415 18:43:42.209887 31272 trainer.py:139] Epoch[494/1500] loss: 0.1928504017326567
I0415 18:44:42.115543 31272 trainer.py:139] Epoch[495/1500] loss: 0.19272507945696513
I0415 18:45:40.155797 31272 trainer.py:139] Epoch[496/1500] loss: 0.19207239151000977
I0415 18:46:40.700088 31272 trainer.py:139] Epoch[497/1500] loss: 0.19323697222603692
I0415 18:47:40.325027 31272 trainer.py:139] Epoch[498/1500] loss: 0.19259885920418635
I0415 18:48:40.642659 31272 trainer.py:139] Epoch[499/1500] loss: 0.19310213896963332
I0415 18:48:41.560557 31272 trainer.py:145] Test: {'precision': 0.2014023372287145, 'recall': 0.2853169667853807, 'hit_ratio': 0.9123539232053423, 'ndcg': 0.3192851316277007}
I0415 18:49:41.458286 31272 trainer.py:139] Epoch[500/1500] loss: 0.19223054303063286
I0415 18:50:41.303018 31272 trainer.py:139] Epoch[501/1500] loss: 0.1921895921230316
I0415 18:51:39.218135 31272 trainer.py:139] Epoch[502/1500] loss: 0.1927819204992718
I0415 18:52:39.460491 31272 trainer.py:139] Epoch[503/1500] loss: 0.19350811309284635
I0415 18:53:38.640510 31272 trainer.py:139] Epoch[504/1500] loss: 0.19223144630591074
I0415 18:54:38.719514 31272 trainer.py:139] Epoch[505/1500] loss: 0.19245523081885443
I0415 18:55:38.352423 31272 trainer.py:139] Epoch[506/1500] loss: 0.19305503216054704
I0415 18:56:36.501323 31272 trainer.py:139] Epoch[507/1500] loss: 0.19227440555890402
I0415 18:57:36.265788 31272 trainer.py:139] Epoch[508/1500] loss: 0.19219586167070601
I0415 18:58:36.555536 31272 trainer.py:139] Epoch[509/1500] loss: 0.19284438967704773
I0415 18:59:36.744205 31272 trainer.py:139] Epoch[510/1500] loss: 0.1930781489610672
I0415 19:00:36.786760 31272 trainer.py:139] Epoch[511/1500] loss: 0.1923156996568044
I0415 19:01:35.795310 31272 trainer.py:139] Epoch[512/1500] loss: 0.1944057818916109
I0415 19:02:35.424577 31272 trainer.py:139] Epoch[513/1500] loss: 0.1924194387594859
I0415 19:03:35.432996 31272 trainer.py:139] Epoch[514/1500] loss: 0.1922545540995068
I0415 19:04:33.872982 31272 trainer.py:139] Epoch[515/1500] loss: 0.1927089958720737
I0415 19:05:33.680338 31272 trainer.py:139] Epoch[516/1500] loss: 0.1929629644420412
I0415 19:06:33.638703 31272 trainer.py:139] Epoch[517/1500] loss: 0.19225782718923357
I0415 19:07:33.722850 31272 trainer.py:139] Epoch[518/1500] loss: 0.192680640551779
I0415 19:08:33.812298 31272 trainer.py:139] Epoch[519/1500] loss: 0.19301735745535956
I0415 19:09:33.276278 31272 trainer.py:139] Epoch[520/1500] loss: 0.19333499630292256
I0415 19:10:28.229419 31272 trainer.py:139] Epoch[521/1500] loss: 0.19302766190634835
I0415 19:11:22.239055 31272 trainer.py:139] Epoch[522/1500] loss: 0.19338132990731133
I0415 19:12:15.783983 31272 trainer.py:139] Epoch[523/1500] loss: 0.19131098482343886
I0415 19:13:09.508521 31272 trainer.py:139] Epoch[524/1500] loss: 0.19160068392753601
I0415 19:14:03.176536 31272 trainer.py:139] Epoch[525/1500] loss: 0.19279335525300767
I0415 19:14:56.967237 31272 trainer.py:139] Epoch[526/1500] loss: 0.19206220852004158
I0415 19:15:50.996043 31272 trainer.py:139] Epoch[527/1500] loss: 0.19203055878480277
I0415 19:16:45.297651 31272 trainer.py:139] Epoch[528/1500] loss: 0.19262064271503024
I0415 19:17:39.339662 31272 trainer.py:139] Epoch[529/1500] loss: 0.19330979996257358
I0415 19:18:32.961672 31272 trainer.py:139] Epoch[530/1500] loss: 0.19230819503466287
I0415 19:19:26.700168 31272 trainer.py:139] Epoch[531/1500] loss: 0.19317961427900526
I0415 19:20:20.502336 31272 trainer.py:139] Epoch[532/1500] loss: 0.192712302936448
I0415 19:21:14.509493 31272 trainer.py:139] Epoch[533/1500] loss: 0.1935467650492986
I0415 19:22:08.910767 31272 trainer.py:139] Epoch[534/1500] loss: 0.1924475512239668
I0415 19:23:02.537379 31272 trainer.py:139] Epoch[535/1500] loss: 0.19197489427195655
I0415 19:23:55.964510 31272 trainer.py:139] Epoch[536/1500] loss: 0.1927079102728102
I0415 19:24:49.831600 31272 trainer.py:139] Epoch[537/1500] loss: 0.19205470787154302
I0415 19:25:44.277457 31272 trainer.py:139] Epoch[538/1500] loss: 0.1918335117234124
I0415 19:26:38.331666 31272 trainer.py:139] Epoch[539/1500] loss: 0.1923828394545449
I0415 19:27:32.240308 31272 trainer.py:139] Epoch[540/1500] loss: 0.1928827671872245
I0415 19:28:28.025559 31272 trainer.py:139] Epoch[541/1500] loss: 0.1927216344409519
I0415 19:29:22.994453 31272 trainer.py:139] Epoch[542/1500] loss: 0.19178102076053619
I0415 19:30:17.125801 31272 trainer.py:139] Epoch[543/1500] loss: 0.19232748316393958
I0415 19:31:11.234613 31272 trainer.py:139] Epoch[544/1500] loss: 0.19227905346287621
I0415 19:32:05.503064 31272 trainer.py:139] Epoch[545/1500] loss: 0.1922277820772595
I0415 19:32:59.699902 31272 trainer.py:139] Epoch[546/1500] loss: 0.19140605105294123
I0415 19:33:53.726161 31272 trainer.py:139] Epoch[547/1500] loss: 0.19272716992431216
I0415 19:34:48.147101 31272 trainer.py:139] Epoch[548/1500] loss: 0.19191872431172266
I0415 19:35:39.842663 31272 trainer.py:139] Epoch[549/1500] loss: 0.19183596730232239
I0415 19:35:40.643983 31272 trainer.py:145] Test: {'precision': 0.20191986644407345, 'recall': 0.28617902067816037, 'hit_ratio': 0.9120200333889816, 'ndcg': 0.32099686359884066}
I0415 19:36:31.308347 31272 trainer.py:139] Epoch[550/1500] loss: 0.1926729389031728
I0415 19:37:22.961962 31272 trainer.py:139] Epoch[551/1500] loss: 0.19161161184310913
I0415 19:38:13.909053 31272 trainer.py:139] Epoch[552/1500] loss: 0.19175330221652984
I0415 19:39:04.414242 31272 trainer.py:139] Epoch[553/1500] loss: 0.19169005301263597
I0415 19:39:54.799007 31272 trainer.py:139] Epoch[554/1500] loss: 0.1915070272816552
I0415 19:40:47.299655 31272 trainer.py:139] Epoch[555/1500] loss: 0.19266339010662503
I0415 19:41:38.883526 31272 trainer.py:139] Epoch[556/1500] loss: 0.19229072391986846
I0415 19:42:29.378648 31272 trainer.py:139] Epoch[557/1500] loss: 0.19276462601290809
I0415 19:43:20.687491 31272 trainer.py:139] Epoch[558/1500] loss: 0.19172101252608828
I0415 19:44:11.979896 31272 trainer.py:139] Epoch[559/1500] loss: 0.1934911518626743
I0415 19:45:02.688256 31272 trainer.py:139] Epoch[560/1500] loss: 0.1918635735909144
I0415 19:45:53.507245 31272 trainer.py:139] Epoch[561/1500] loss: 0.1915998610523012
I0415 19:46:43.941805 31272 trainer.py:139] Epoch[562/1500] loss: 0.19245211528407202
I0415 19:47:34.096493 31272 trainer.py:139] Epoch[563/1500] loss: 0.1920792266395357
I0415 19:48:24.729681 31272 trainer.py:139] Epoch[564/1500] loss: 0.19272361901071336
I0415 19:49:15.542041 31272 trainer.py:139] Epoch[565/1500] loss: 0.19171420885456933
I0415 19:50:06.751156 31272 trainer.py:139] Epoch[566/1500] loss: 0.19165682673454285
I0415 19:51:00.641747 31272 trainer.py:139] Epoch[567/1500] loss: 0.1926741749710507
I0415 19:52:00.138885 31272 trainer.py:139] Epoch[568/1500] loss: 0.1925787369410197
I0415 19:53:08.950672 31272 trainer.py:139] Epoch[569/1500] loss: 0.1925498988231023
I0415 19:54:16.179710 31272 trainer.py:139] Epoch[570/1500] loss: 0.19162127759721545
I0415 19:55:24.501586 31272 trainer.py:139] Epoch[571/1500] loss: 0.19253314389122858
I0415 19:56:30.880519 31272 trainer.py:139] Epoch[572/1500] loss: 0.1918578318092558
I0415 19:57:39.684848 31272 trainer.py:139] Epoch[573/1500] loss: 0.19120763765441046
I0415 19:58:48.805140 31272 trainer.py:139] Epoch[574/1500] loss: 0.1920763001177046
I0415 19:59:57.166444 31272 trainer.py:139] Epoch[575/1500] loss: 0.1923600928650962
I0415 20:01:06.346455 31272 trainer.py:139] Epoch[576/1500] loss: 0.19292920463614993
I0415 20:02:15.013734 31272 trainer.py:139] Epoch[577/1500] loss: 0.19224005348152584
I0415 20:03:21.109056 31272 trainer.py:139] Epoch[578/1500] loss: 0.19157437960306803
I0415 20:04:29.633814 31272 trainer.py:139] Epoch[579/1500] loss: 0.19153993580076428
I0415 20:05:37.539109 31272 trainer.py:139] Epoch[580/1500] loss: 0.19226265774832832
I0415 20:06:45.908386 31272 trainer.py:139] Epoch[581/1500] loss: 0.19334352725081974
I0415 20:07:48.306638 31272 trainer.py:139] Epoch[582/1500] loss: 0.19234304103586408
I0415 20:08:50.444756 31272 trainer.py:139] Epoch[583/1500] loss: 0.19183951358000437
I0415 20:09:49.529095 31272 trainer.py:139] Epoch[584/1500] loss: 0.19213734434710608
I0415 20:10:50.939998 31272 trainer.py:139] Epoch[585/1500] loss: 0.19171606322129567
I0415 20:11:51.311033 31272 trainer.py:139] Epoch[586/1500] loss: 0.19133946306175656
I0415 20:12:52.552166 31272 trainer.py:139] Epoch[587/1500] loss: 0.1920129401816262
I0415 20:13:46.833995 31272 trainer.py:139] Epoch[588/1500] loss: 0.19202790293428634
I0415 20:14:41.432078 31272 trainer.py:139] Epoch[589/1500] loss: 0.19315366374121773
I0415 20:15:34.963422 31272 trainer.py:139] Epoch[590/1500] loss: 0.19120042343934376
I0415 20:16:31.285998 31272 trainer.py:139] Epoch[591/1500] loss: 0.19274594737423792
I0415 20:17:25.489083 31272 trainer.py:139] Epoch[592/1500] loss: 0.1924424558215671
I0415 20:18:21.505606 31272 trainer.py:139] Epoch[593/1500] loss: 0.19065779891279008
I0415 20:19:15.741165 31272 trainer.py:139] Epoch[594/1500] loss: 0.19239589783880445
I0415 20:20:10.733185 31272 trainer.py:139] Epoch[595/1500] loss: 0.19244924240642125
I0415 20:21:06.899286 31272 trainer.py:139] Epoch[596/1500] loss: 0.19154014964898428
I0415 20:22:01.498098 31272 trainer.py:139] Epoch[597/1500] loss: 0.19142407476902007
I0415 20:22:57.597928 31272 trainer.py:139] Epoch[598/1500] loss: 0.19206523140271506
I0415 20:23:51.240520 31272 trainer.py:139] Epoch[599/1500] loss: 0.19196736150317723
I0415 20:23:52.057787 31272 trainer.py:145] Test: {'precision': 0.20128547579298828, 'recall': 0.2848736210023578, 'hit_ratio': 0.9118530884808014, 'ndcg': 0.31894618486496823}
I0415 20:24:45.997336 31272 trainer.py:139] Epoch[600/1500] loss: 0.19216618531280094
I0415 20:25:43.107170 31272 trainer.py:139] Epoch[601/1500] loss: 0.19101906809541913
I0415 20:26:39.698847 31272 trainer.py:139] Epoch[602/1500] loss: 0.19229927274915906
I0415 20:27:33.821204 31272 trainer.py:139] Epoch[603/1500] loss: 0.19251859194702572
I0415 20:28:28.703230 31272 trainer.py:139] Epoch[604/1500] loss: 0.1921900201506085
I0415 20:29:22.648762 31272 trainer.py:139] Epoch[605/1500] loss: 0.19207878311475118
I0415 20:30:17.130190 31272 trainer.py:139] Epoch[606/1500] loss: 0.19196409198972914
I0415 20:31:13.356091 31272 trainer.py:139] Epoch[607/1500] loss: 0.19167458335558574
I0415 20:32:08.852433 31272 trainer.py:139] Epoch[608/1500] loss: 0.19197177059120601
I0415 20:33:03.081015 31272 trainer.py:139] Epoch[609/1500] loss: 0.19172780460781522
I0415 20:33:57.188443 31272 trainer.py:139] Epoch[610/1500] loss: 0.19192588680320316
I0415 20:34:51.720457 31272 trainer.py:139] Epoch[611/1500] loss: 0.1921160136991077
I0415 20:35:45.195115 31272 trainer.py:139] Epoch[612/1500] loss: 0.19179937329557206
I0415 20:36:38.293910 31272 trainer.py:139] Epoch[613/1500] loss: 0.1915070088704427
I0415 20:37:32.689607 31272 trainer.py:139] Epoch[614/1500] loss: 0.19244803779655031
I0415 20:38:26.030595 31272 trainer.py:139] Epoch[615/1500] loss: 0.1914633227719201
I0415 20:39:19.384185 31272 trainer.py:139] Epoch[616/1500] loss: 0.19098191334141626
I0415 20:40:12.804893 31272 trainer.py:139] Epoch[617/1500] loss: 0.19142457650767433
I0415 20:41:06.300708 31272 trainer.py:139] Epoch[618/1500] loss: 0.1917791905005773
I0415 20:42:00.916617 31272 trainer.py:139] Epoch[619/1500] loss: 0.19154644946257274
I0415 20:42:58.006984 31272 trainer.py:139] Epoch[620/1500] loss: 0.19134957710901895
I0415 20:43:58.019505 31272 trainer.py:139] Epoch[621/1500] loss: 0.19242566459708743
I0415 20:44:57.350028 31272 trainer.py:139] Epoch[622/1500] loss: 0.19286850869655608
I0415 20:45:56.946168 31272 trainer.py:139] Epoch[623/1500] loss: 0.19096380631128948
I0415 20:46:56.540940 31272 trainer.py:139] Epoch[624/1500] loss: 0.1905970513820648
I0415 20:47:55.722153 31272 trainer.py:139] Epoch[625/1500] loss: 0.1910662631193797
I0415 20:48:48.742201 31272 trainer.py:139] Epoch[626/1500] loss: 0.19166870421833462
I0415 20:49:41.014135 31272 trainer.py:139] Epoch[627/1500] loss: 0.19238527119159698
I0415 20:50:33.389800 31272 trainer.py:139] Epoch[628/1500] loss: 0.19126465843783486
I0415 20:51:25.162490 31272 trainer.py:139] Epoch[629/1500] loss: 0.19150672800011104
I0415 20:52:17.448572 31272 trainer.py:139] Epoch[630/1500] loss: 0.1927797723478741
I0415 20:53:09.525321 31272 trainer.py:139] Epoch[631/1500] loss: 0.19206127127011616
I0415 20:54:01.478516 31272 trainer.py:139] Epoch[632/1500] loss: 0.19175918188360003
I0415 20:54:53.780970 31272 trainer.py:139] Epoch[633/1500] loss: 0.1916861160596212
I0415 20:55:45.714400 31272 trainer.py:139] Epoch[634/1500] loss: 0.1920955608950721
I0415 20:56:38.347733 31272 trainer.py:139] Epoch[635/1500] loss: 0.19233595695760514
I0415 20:57:30.186729 31272 trainer.py:139] Epoch[636/1500] loss: 0.19183515806992849
I0415 20:58:18.233991 31272 trainer.py:139] Epoch[637/1500] loss: 0.1913760538895925
I0415 20:59:06.501903 31272 trainer.py:139] Epoch[638/1500] loss: 0.19154641224278343
I0415 20:59:54.576508 31272 trainer.py:139] Epoch[639/1500] loss: 0.1915783734454049
I0415 21:00:42.603795 31272 trainer.py:139] Epoch[640/1500] loss: 0.19145846943060557
I0415 21:01:30.522269 31272 trainer.py:139] Epoch[641/1500] loss: 0.19250347707006665
I0415 21:02:18.382592 31272 trainer.py:139] Epoch[642/1500] loss: 0.1933469147152371
I0415 21:03:06.213577 31272 trainer.py:139] Epoch[643/1500] loss: 0.19152592764960394
I0415 21:03:54.106709 31272 trainer.py:139] Epoch[644/1500] loss: 0.19156493835979038
I0415 21:04:41.728527 31272 trainer.py:139] Epoch[645/1500] loss: 0.19242348902755313
I0415 21:05:29.368588 31272 trainer.py:139] Epoch[646/1500] loss: 0.19163904388745626
I0415 21:06:17.265168 31272 trainer.py:139] Epoch[647/1500] loss: 0.19078494045469496
I0415 21:07:05.045195 31272 trainer.py:139] Epoch[648/1500] loss: 0.19128655427032046
I0415 21:07:52.703768 31272 trainer.py:139] Epoch[649/1500] loss: 0.19230444146527184
I0415 21:07:53.403428 31272 trainer.py:145] Test: {'precision': 0.20154424040066773, 'recall': 0.2864896962247526, 'hit_ratio': 0.9148580968280468, 'ndcg': 0.3200567626239867}
I0415 21:08:40.814716 31272 trainer.py:139] Epoch[650/1500] loss: 0.1921920910808775
I0415 21:09:28.861352 31272 trainer.py:139] Epoch[651/1500] loss: 0.19184805664751264
I0415 21:10:16.483561 31272 trainer.py:139] Epoch[652/1500] loss: 0.192092514567905
I0415 21:11:04.384888 31272 trainer.py:139] Epoch[653/1500] loss: 0.19207399937841627
I0415 21:11:52.281664 31272 trainer.py:139] Epoch[654/1500] loss: 0.19170960552162594
I0415 21:12:40.237503 31272 trainer.py:139] Epoch[655/1500] loss: 0.19223644137382506
I0415 21:13:28.837595 31272 trainer.py:139] Epoch[656/1500] loss: 0.19223978459835053
I0415 21:14:16.980479 31272 trainer.py:139] Epoch[657/1500] loss: 0.1913144948747423
I0415 21:15:04.950996 31272 trainer.py:139] Epoch[658/1500] loss: 0.19237290958563485
I0415 21:15:52.989288 31272 trainer.py:139] Epoch[659/1500] loss: 0.19091507679886288
I0415 21:16:40.853164 31272 trainer.py:139] Epoch[660/1500] loss: 0.191624868578381
I0415 21:17:29.101344 31272 trainer.py:139] Epoch[661/1500] loss: 0.19108775171968673
I0415 21:18:16.999106 31272 trainer.py:139] Epoch[662/1500] loss: 0.19198842777146233
I0415 21:19:05.697146 31272 trainer.py:139] Epoch[663/1500] loss: 0.1923006765709983
I0415 21:19:53.991581 31272 trainer.py:139] Epoch[664/1500] loss: 0.19213040563795303
I0415 21:20:43.454108 31272 trainer.py:139] Epoch[665/1500] loss: 0.19165726807382372
I0415 21:21:36.429882 31272 trainer.py:139] Epoch[666/1500] loss: 0.19165224836932288
I0415 21:22:31.535531 31272 trainer.py:139] Epoch[667/1500] loss: 0.19276776724391514
I0415 21:23:35.415825 31272 trainer.py:139] Epoch[668/1500] loss: 0.19090317130088807
I0415 21:24:37.542984 31272 trainer.py:139] Epoch[669/1500] loss: 0.19171884463893044
I0415 21:25:39.614329 31272 trainer.py:139] Epoch[670/1500] loss: 0.1907738185591168
I0415 21:26:40.974055 31272 trainer.py:139] Epoch[671/1500] loss: 0.19120232866870032
I0415 21:27:42.163351 31272 trainer.py:139] Epoch[672/1500] loss: 0.19111996074517568
I0415 21:28:43.135880 31272 trainer.py:139] Epoch[673/1500] loss: 0.19220349854893154
I0415 21:29:44.289541 31272 trainer.py:139] Epoch[674/1500] loss: 0.1916928677426444
I0415 21:30:44.187578 31272 trainer.py:139] Epoch[675/1500] loss: 0.19161432617240481
I0415 21:31:44.328311 31272 trainer.py:139] Epoch[676/1500] loss: 0.193236773080296
I0415 21:32:44.793031 31272 trainer.py:139] Epoch[677/1500] loss: 0.19157453755537668
I0415 21:33:45.126652 31272 trainer.py:139] Epoch[678/1500] loss: 0.19065754916932848
I0415 21:34:40.945914 31272 trainer.py:139] Epoch[679/1500] loss: 0.19232715374893614
I0415 21:35:35.766385 31272 trainer.py:139] Epoch[680/1500] loss: 0.19142621285385555
I0415 21:36:30.369610 31272 trainer.py:139] Epoch[681/1500] loss: 0.1912615606519911
I0415 21:37:25.363051 31272 trainer.py:139] Epoch[682/1500] loss: 0.19253567470444574
I0415 21:38:20.412886 31272 trainer.py:139] Epoch[683/1500] loss: 0.19194624722003936
I0415 21:39:15.826944 31272 trainer.py:139] Epoch[684/1500] loss: 0.1908612597650952
I0415 21:40:13.329574 31272 trainer.py:139] Epoch[685/1500] loss: 0.19128483169608645
I0415 21:41:17.126147 31272 trainer.py:139] Epoch[686/1500] loss: 0.19135963327354855
I0415 21:42:20.860927 31272 trainer.py:139] Epoch[687/1500] loss: 0.19203123642338646
I0415 21:43:23.570643 31272 trainer.py:139] Epoch[688/1500] loss: 0.19209377282195622
I0415 21:44:27.602498 31272 trainer.py:139] Epoch[689/1500] loss: 0.19190667887528737
I0415 21:45:28.910354 31272 trainer.py:139] Epoch[690/1500] loss: 0.19115347511238523
I0415 21:46:32.778215 31272 trainer.py:139] Epoch[691/1500] loss: 0.19154783719115787
I0415 21:47:33.663527 31272 trainer.py:139] Epoch[692/1500] loss: 0.19080456402566698
I0415 21:48:38.111367 31272 trainer.py:139] Epoch[693/1500] loss: 0.19220967239803738
I0415 21:49:42.122223 31272 trainer.py:139] Epoch[694/1500] loss: 0.19145667811234793
I0415 21:50:46.341383 31272 trainer.py:139] Epoch[695/1500] loss: 0.1915944950448142
I0415 21:51:48.010774 31272 trainer.py:139] Epoch[696/1500] loss: 0.19178364290131464
I0415 21:52:51.224299 31272 trainer.py:139] Epoch[697/1500] loss: 0.19253154046005672
I0415 21:53:55.134890 31272 trainer.py:139] Epoch[698/1500] loss: 0.19194782223966386
I0415 21:54:56.917624 31272 trainer.py:139] Epoch[699/1500] loss: 0.19126868764559427
I0415 21:54:57.913293 31272 trainer.py:145] Test: {'precision': 0.20119365609348908, 'recall': 0.28498802476829654, 'hit_ratio': 0.9126878130217029, 'ndcg': 0.319016466317443}
I0415 21:55:59.658099 31272 trainer.py:139] Epoch[700/1500] loss: 0.19133267296685114
I0415 21:57:00.477067 31272 trainer.py:139] Epoch[701/1500] loss: 0.19115195512771607
I0415 21:58:04.270739 31272 trainer.py:139] Epoch[702/1500] loss: 0.1926894074678421
I0415 21:59:09.205950 31272 trainer.py:139] Epoch[703/1500] loss: 0.19143067797025046
I0415 22:00:11.972969 31272 trainer.py:139] Epoch[704/1500] loss: 0.19109374900658926
I0415 22:01:05.548093 31272 trainer.py:139] Epoch[705/1500] loss: 0.1906284616390864
I0415 22:01:58.159085 31272 trainer.py:139] Epoch[706/1500] loss: 0.1916503887044059
I0415 22:02:51.410433 31272 trainer.py:139] Epoch[707/1500] loss: 0.19122936228911083
I0415 22:03:47.472377 31272 trainer.py:139] Epoch[708/1500] loss: 0.19221744861867693
I0415 22:04:48.392965 31272 trainer.py:139] Epoch[709/1500] loss: 0.1907159599992964
I0415 22:05:51.885557 31272 trainer.py:139] Epoch[710/1500] loss: 0.19148375418451097
I0415 22:06:55.834820 31272 trainer.py:139] Epoch[711/1500] loss: 0.19194844729370542
I0415 22:07:56.905952 31272 trainer.py:139] Epoch[712/1500] loss: 0.19216268797715505
I0415 22:08:57.934531 31272 trainer.py:139] Epoch[713/1500] loss: 0.1913435329331292
I0415 22:09:56.503024 31272 trainer.py:139] Epoch[714/1500] loss: 0.19070435576968722
I0415 22:11:01.159721 31272 trainer.py:139] Epoch[715/1500] loss: 0.1911423314942254
I0415 22:12:01.931871 31272 trainer.py:139] Epoch[716/1500] loss: 0.191416823665301
I0415 22:13:07.154282 31272 trainer.py:139] Epoch[717/1500] loss: 0.1916961171891954
I0415 22:14:09.366469 31272 trainer.py:139] Epoch[718/1500] loss: 0.19111475951141782
I0415 22:15:12.258317 31272 trainer.py:139] Epoch[719/1500] loss: 0.19243878973854914
I0415 22:16:11.130365 31272 trainer.py:139] Epoch[720/1500] loss: 0.1921908054086897
I0415 22:17:15.294056 31272 trainer.py:139] Epoch[721/1500] loss: 0.19114022175470988
I0415 22:18:17.011498 31272 trainer.py:139] Epoch[722/1500] loss: 0.1915856730937958
I0415 22:19:16.205401 31272 trainer.py:139] Epoch[723/1500] loss: 0.19187436746226416
I0415 22:20:11.137630 31272 trainer.py:139] Epoch[724/1500] loss: 0.1922915240128835
I0415 22:21:03.420720 31272 trainer.py:139] Epoch[725/1500] loss: 0.19190731028715768
I0415 22:21:55.464053 31272 trainer.py:139] Epoch[726/1500] loss: 0.19129298865795136
I0415 22:22:48.157207 31272 trainer.py:139] Epoch[727/1500] loss: 0.19205432752768198
I0415 22:23:40.720866 31272 trainer.py:139] Epoch[728/1500] loss: 0.19199979623158772
I0415 22:24:33.013433 31272 trainer.py:139] Epoch[729/1500] loss: 0.19126629306210413
I0415 22:25:25.066729 31272 trainer.py:139] Epoch[730/1500] loss: 0.19135199334886338
I0415 22:26:17.587027 31272 trainer.py:139] Epoch[731/1500] loss: 0.19204258256488377
I0415 22:27:09.876098 31272 trainer.py:139] Epoch[732/1500] loss: 0.19154462211661868
I0415 22:28:02.192079 31272 trainer.py:139] Epoch[733/1500] loss: 0.19222058024671343
I0415 22:28:54.406719 31272 trainer.py:139] Epoch[734/1500] loss: 0.19205732762813568
I0415 22:29:50.269834 31272 trainer.py:139] Epoch[735/1500] loss: 0.1909303201569451
I0415 22:30:46.309906 31272 trainer.py:139] Epoch[736/1500] loss: 0.19081912246015337
I0415 22:31:42.063982 31272 trainer.py:139] Epoch[737/1500] loss: 0.19170357465744017
I0415 22:32:38.428835 31272 trainer.py:139] Epoch[738/1500] loss: 0.19091024061044057
I0415 22:33:34.491218 31272 trainer.py:139] Epoch[739/1500] loss: 0.19125336938434176
I0415 22:34:31.346402 31272 trainer.py:139] Epoch[740/1500] loss: 0.1911480375793245
I0415 22:35:28.577785 31272 trainer.py:139] Epoch[741/1500] loss: 0.19114756882190703
I0415 22:36:25.053199 31272 trainer.py:139] Epoch[742/1500] loss: 0.19152546577983431
I0415 22:37:21.864146 31272 trainer.py:139] Epoch[743/1500] loss: 0.19185396167967056
I0415 22:38:18.632227 31272 trainer.py:139] Epoch[744/1500] loss: 0.18993669682078893
I0415 22:39:15.703812 31272 trainer.py:139] Epoch[745/1500] loss: 0.19050035344229804
I0415 22:40:12.171846 31272 trainer.py:139] Epoch[746/1500] loss: 0.19233341521686978
I0415 22:41:08.813834 31272 trainer.py:139] Epoch[747/1500] loss: 0.19089145892196233
I0415 22:42:06.041384 31272 trainer.py:139] Epoch[748/1500] loss: 0.19090314990944332
I0415 22:43:03.047002 31272 trainer.py:139] Epoch[749/1500] loss: 0.19222571439213224
I0415 22:43:03.938021 31272 trainer.py:145] Test: {'precision': 0.2019198664440734, 'recall': 0.2865972787319506, 'hit_ratio': 0.9128547579298831, 'ndcg': 0.3194953928283536}
I0415 22:44:00.950791 31272 trainer.py:139] Epoch[750/1500] loss: 0.1925380986266666
I0415 22:44:56.947923 31272 trainer.py:139] Epoch[751/1500] loss: 0.19175541122754414
I0415 22:45:53.092335 31272 trainer.py:139] Epoch[752/1500] loss: 0.191122970978419
I0415 22:46:50.145467 31272 trainer.py:139] Epoch[753/1500] loss: 0.1923395683368047
I0415 22:47:47.109850 31272 trainer.py:139] Epoch[754/1500] loss: 0.19206206931008232
I0415 22:48:44.440559 31272 trainer.py:139] Epoch[755/1500] loss: 0.19208398434850904
I0415 22:49:41.147175 31272 trainer.py:139] Epoch[756/1500] loss: 0.19046112166510687
I0415 22:50:37.668474 31272 trainer.py:139] Epoch[757/1500] loss: 0.1917966918150584
I0415 22:51:33.374033 31272 trainer.py:139] Epoch[758/1500] loss: 0.1908523631095886
I0415 22:52:30.317533 31272 trainer.py:139] Epoch[759/1500] loss: 0.19162921302848393
I0415 22:53:26.376991 31272 trainer.py:139] Epoch[760/1500] loss: 0.190833501484659
I0415 22:54:23.769987 31272 trainer.py:139] Epoch[761/1500] loss: 0.190737964047326
I0415 22:55:20.386507 31272 trainer.py:139] Epoch[762/1500] loss: 0.1908871673213111
I0415 22:56:16.782280 31272 trainer.py:139] Epoch[763/1500] loss: 0.19164864745404986
I0415 22:57:12.370263 31272 trainer.py:139] Epoch[764/1500] loss: 0.19224842528502145
I0415 22:58:08.728164 31272 trainer.py:139] Epoch[765/1500] loss: 0.19119728518856896
I0415 22:59:05.539096 31272 trainer.py:139] Epoch[766/1500] loss: 0.19172893914911482
I0415 23:00:01.669574 31272 trainer.py:139] Epoch[767/1500] loss: 0.19065347678131528
I0415 23:00:57.498236 31272 trainer.py:139] Epoch[768/1500] loss: 0.1914644283056259
I0415 23:01:53.896938 31272 trainer.py:139] Epoch[769/1500] loss: 0.1914855151043998
I0415 23:02:50.552330 31272 trainer.py:139] Epoch[770/1500] loss: 0.19153588990370432
I0415 23:03:47.567021 31272 trainer.py:139] Epoch[771/1500] loss: 0.19153804375065697
I0415 23:04:44.613597 31272 trainer.py:139] Epoch[772/1500] loss: 0.19238793836699591
I0415 23:05:40.882786 31272 trainer.py:139] Epoch[773/1500] loss: 0.190734506977929
I0415 23:06:37.346798 31272 trainer.py:139] Epoch[774/1500] loss: 0.19205336266093784
I0415 23:07:33.785985 31272 trainer.py:139] Epoch[775/1500] loss: 0.19084611899322934
I0415 23:08:29.367045 31272 trainer.py:139] Epoch[776/1500] loss: 0.19093553092744614
I0415 23:09:25.923508 31272 trainer.py:139] Epoch[777/1500] loss: 0.19078431685765584
I0415 23:10:22.799106 31272 trainer.py:139] Epoch[778/1500] loss: 0.19088162375821008
I0415 23:11:19.697619 31272 trainer.py:139] Epoch[779/1500] loss: 0.19247369872199163
I0415 23:12:14.890375 31272 trainer.py:139] Epoch[780/1500] loss: 0.19118863165378572
I0415 23:13:12.196662 31272 trainer.py:139] Epoch[781/1500] loss: 0.190661940574646
I0415 23:14:12.996569 31272 trainer.py:139] Epoch[782/1500] loss: 0.191059879594379
I0415 23:15:14.639358 31272 trainer.py:139] Epoch[783/1500] loss: 0.19071438676781124
I0415 23:16:16.620008 31272 trainer.py:139] Epoch[784/1500] loss: 0.19044609838061863
I0415 23:17:18.877730 31272 trainer.py:139] Epoch[785/1500] loss: 0.1913830547200309
I0415 23:18:20.854392 31272 trainer.py:139] Epoch[786/1500] loss: 0.19037551018926832
I0415 23:19:20.469967 31272 trainer.py:139] Epoch[787/1500] loss: 0.19176309910085465
I0415 23:20:20.273897 31272 trainer.py:139] Epoch[788/1500] loss: 0.19080073396364847
I0415 23:21:19.725349 31272 trainer.py:139] Epoch[789/1500] loss: 0.19148521039221023
I0415 23:22:19.595060 31272 trainer.py:139] Epoch[790/1500] loss: 0.1917473621500863
I0415 23:23:19.455165 31272 trainer.py:139] Epoch[791/1500] loss: 0.1909754706091351
I0415 23:24:19.337308 31272 trainer.py:139] Epoch[792/1500] loss: 0.19086477345890468
I0415 23:25:19.503352 31272 trainer.py:139] Epoch[793/1500] loss: 0.19191778315438165
I0415 23:26:18.737190 31272 trainer.py:139] Epoch[794/1500] loss: 0.19141267306274837
I0415 23:27:18.106520 31272 trainer.py:139] Epoch[795/1500] loss: 0.19129465646213956
I0415 23:28:17.801815 31272 trainer.py:139] Epoch[796/1500] loss: 0.1912267945210139
I0415 23:29:17.283307 31272 trainer.py:139] Epoch[797/1500] loss: 0.19238244507047866
I0415 23:30:17.157946 31272 trainer.py:139] Epoch[798/1500] loss: 0.19169271760516696
I0415 23:31:16.965863 31272 trainer.py:139] Epoch[799/1500] loss: 0.19169174936082628
I0415 23:31:17.953558 31272 trainer.py:145] Test: {'precision': 0.20140233722871453, 'recall': 0.2854079385791857, 'hit_ratio': 0.9113522537562604, 'ndcg': 0.31983181071751543}
I0415 23:32:17.292995 31272 trainer.py:139] Epoch[800/1500] loss: 0.19148264911439683
I0415 23:33:17.091721 31272 trainer.py:139] Epoch[801/1500] loss: 0.19105190674463907
I0415 23:34:16.482044 31272 trainer.py:139] Epoch[802/1500] loss: 0.19018966144985622
I0415 23:35:15.718823 31272 trainer.py:139] Epoch[803/1500] loss: 0.19071173071861267
I0415 23:36:15.520760 31272 trainer.py:139] Epoch[804/1500] loss: 0.19023152828216552
I0415 23:37:15.296195 31272 trainer.py:139] Epoch[805/1500] loss: 0.19102828310595618
I0415 23:38:14.442201 31272 trainer.py:139] Epoch[806/1500] loss: 0.19034016105863782
I0415 23:39:14.144146 31272 trainer.py:139] Epoch[807/1500] loss: 0.1914526778459549
I0415 23:40:13.654931 31272 trainer.py:139] Epoch[808/1500] loss: 0.19129006299707624
I0415 23:41:13.304923 31272 trainer.py:139] Epoch[809/1500] loss: 0.19114720053142972
I0415 23:42:13.091042 31272 trainer.py:139] Epoch[810/1500] loss: 0.18986031936274633
I0415 23:43:12.488776 31272 trainer.py:139] Epoch[811/1500] loss: 0.1910299907128016
I0415 23:44:12.559763 31272 trainer.py:139] Epoch[812/1500] loss: 0.19154207150141397
I0415 23:45:11.951979 31272 trainer.py:139] Epoch[813/1500] loss: 0.19176801476213667
I0415 23:46:11.052705 31272 trainer.py:139] Epoch[814/1500] loss: 0.1917070127858056
I0415 23:47:10.939036 31272 trainer.py:139] Epoch[815/1500] loss: 0.19133657462067075
I0415 23:48:11.026254 31272 trainer.py:139] Epoch[816/1500] loss: 0.19125144090917376
I0415 23:49:10.992125 31272 trainer.py:139] Epoch[817/1500] loss: 0.19242566055721708
I0415 23:50:10.332091 31272 trainer.py:139] Epoch[818/1500] loss: 0.19247396111488344
I0415 23:51:09.599578 31272 trainer.py:139] Epoch[819/1500] loss: 0.191278086370892
I0415 23:52:09.108621 31272 trainer.py:139] Epoch[820/1500] loss: 0.19073633048269484
I0415 23:53:08.839980 31272 trainer.py:139] Epoch[821/1500] loss: 0.1913882236348258
I0415 23:54:08.105587 31272 trainer.py:139] Epoch[822/1500] loss: 0.19079439785745408
I0415 23:55:08.129656 31272 trainer.py:139] Epoch[823/1500] loss: 0.19119210945235357
I0415 23:56:08.334700 31272 trainer.py:139] Epoch[824/1500] loss: 0.19239872455596924
I0415 23:57:08.444931 31272 trainer.py:139] Epoch[825/1500] loss: 0.19105928129620023
I0415 23:58:08.095551 31272 trainer.py:139] Epoch[826/1500] loss: 0.19037768801053365
I0415 23:59:07.954668 31272 trainer.py:139] Epoch[827/1500] loss: 0.19089459955692292
I0416 00:00:07.843282 31272 trainer.py:139] Epoch[828/1500] loss: 0.1916327002313402
I0416 00:01:07.412432 31272 trainer.py:139] Epoch[829/1500] loss: 0.19050750109884473
I0416 00:02:07.052421 31272 trainer.py:139] Epoch[830/1500] loss: 0.19154271907276577
I0416 00:03:06.426788 31272 trainer.py:139] Epoch[831/1500] loss: 0.19100588268703886
I0416 00:04:05.959146 31272 trainer.py:139] Epoch[832/1500] loss: 0.1911963501903746
I0416 00:05:05.429584 31272 trainer.py:139] Epoch[833/1500] loss: 0.1909435036447313
I0416 00:06:04.821297 31272 trainer.py:139] Epoch[834/1500] loss: 0.1908471037944158
I0416 00:07:04.675487 31272 trainer.py:139] Epoch[835/1500] loss: 0.19163352224561903
I0416 00:08:04.300515 31272 trainer.py:139] Epoch[836/1500] loss: 0.19177439345253838
I0416 00:09:03.701792 31272 trainer.py:139] Epoch[837/1500] loss: 0.19063943763573965
I0416 00:10:02.497097 31272 trainer.py:139] Epoch[838/1500] loss: 0.19175594170888266
I0416 00:10:58.586455 31272 trainer.py:139] Epoch[839/1500] loss: 0.19090426875485314
I0416 00:11:54.736990 31272 trainer.py:139] Epoch[840/1500] loss: 0.19084728399912515
I0416 00:12:50.706489 31272 trainer.py:139] Epoch[841/1500] loss: 0.19100919716888004
I0416 00:13:47.171811 31272 trainer.py:139] Epoch[842/1500] loss: 0.19099381936921014
I0416 00:14:43.521200 31272 trainer.py:139] Epoch[843/1500] loss: 0.19181168999936846
I0416 00:15:39.673829 31272 trainer.py:139] Epoch[844/1500] loss: 0.19139834781487783
I0416 00:16:35.705176 31272 trainer.py:139] Epoch[845/1500] loss: 0.19090475175115798
I0416 00:17:31.874469 31272 trainer.py:139] Epoch[846/1500] loss: 0.19112470236089493
I0416 00:18:27.928789 31272 trainer.py:139] Epoch[847/1500] loss: 0.18975744552082485
I0416 00:19:22.306291 31272 trainer.py:139] Epoch[848/1500] loss: 0.19110871877935198
I0416 00:20:15.234092 31272 trainer.py:139] Epoch[849/1500] loss: 0.19098267171117994
I0416 00:20:16.058335 31272 trainer.py:145] Test: {'precision': 0.20204507512520864, 'recall': 0.2860841369208262, 'hit_ratio': 0.913355592654424, 'ndcg': 0.32281895338320865}
I0416 00:21:08.721920 31272 trainer.py:139] Epoch[850/1500] loss: 0.19065449310673607
I0416 00:22:01.889750 31272 trainer.py:139] Epoch[851/1500] loss: 0.19070134388075935
I0416 00:22:54.559964 31272 trainer.py:139] Epoch[852/1500] loss: 0.19135522246360778
I0416 00:23:46.945146 31272 trainer.py:139] Epoch[853/1500] loss: 0.19094849977228376
I0416 00:24:35.763783 31272 trainer.py:139] Epoch[854/1500] loss: 0.19209538181622823
I0416 00:25:24.425401 31272 trainer.py:139] Epoch[855/1500] loss: 0.19083487060334947
I0416 00:26:12.777891 31272 trainer.py:139] Epoch[856/1500] loss: 0.19144081837601132
I0416 00:27:00.874990 31272 trainer.py:139] Epoch[857/1500] loss: 0.19099695212311216
I0416 00:27:49.332654 31272 trainer.py:139] Epoch[858/1500] loss: 0.1917187546359168
I0416 00:28:37.998785 31272 trainer.py:139] Epoch[859/1500] loss: 0.19129527297284868
I0416 00:29:26.654425 31272 trainer.py:139] Epoch[860/1500] loss: 0.19095754153198666
I0416 00:30:15.306395 31272 trainer.py:139] Epoch[861/1500] loss: 0.19165159748660193
I0416 00:31:03.686283 31272 trainer.py:139] Epoch[862/1500] loss: 0.191684274342325
I0416 00:31:52.361792 31272 trainer.py:139] Epoch[863/1500] loss: 0.1905660057730145
I0416 00:32:40.956428 31272 trainer.py:139] Epoch[864/1500] loss: 0.1921985212299559
I0416 00:33:29.632443 31272 trainer.py:139] Epoch[865/1500] loss: 0.19121457901265887
I0416 00:34:18.445324 31272 trainer.py:139] Epoch[866/1500] loss: 0.1899555594391293
I0416 00:35:05.310961 31272 trainer.py:139] Epoch[867/1500] loss: 0.19019836107889812
I0416 00:35:50.496587 31272 trainer.py:139] Epoch[868/1500] loss: 0.19022719972663454
I0416 00:36:36.222980 31272 trainer.py:139] Epoch[869/1500] loss: 0.1910931858751509
I0416 00:37:22.299857 31272 trainer.py:139] Epoch[870/1500] loss: 0.1908113666375478
I0416 00:38:07.553728 31272 trainer.py:139] Epoch[871/1500] loss: 0.1913460738129086
I0416 00:38:53.204698 31272 trainer.py:139] Epoch[872/1500] loss: 0.19117465714613596
I0416 00:39:38.387708 31272 trainer.py:139] Epoch[873/1500] loss: 0.19108636809719934
I0416 00:40:23.744450 31272 trainer.py:139] Epoch[874/1500] loss: 0.19072765085432264
I0416 00:41:09.358287 31272 trainer.py:139] Epoch[875/1500] loss: 0.19097820666101245
I0416 00:41:54.723704 31272 trainer.py:139] Epoch[876/1500] loss: 0.19141759627395205
I0416 00:42:40.303542 31272 trainer.py:139] Epoch[877/1500] loss: 0.19108841107951272
I0416 00:43:26.014503 31272 trainer.py:139] Epoch[878/1500] loss: 0.19085997727182177
I0416 00:44:11.435403 31272 trainer.py:139] Epoch[879/1500] loss: 0.19127237637837727
I0416 00:44:56.748097 31272 trainer.py:139] Epoch[880/1500] loss: 0.191373308300972
I0416 00:45:41.938084 31272 trainer.py:139] Epoch[881/1500] loss: 0.19038925455676184
I0416 00:46:27.147624 31272 trainer.py:139] Epoch[882/1500] loss: 0.19183744132518768
I0416 00:47:12.242940 31272 trainer.py:139] Epoch[883/1500] loss: 0.19128275798426733
I0416 00:47:57.651109 31272 trainer.py:139] Epoch[884/1500] loss: 0.1914488861295912
I0416 00:48:43.232299 31272 trainer.py:139] Epoch[885/1500] loss: 0.19238470408651565
I0416 00:49:28.783236 31272 trainer.py:139] Epoch[886/1500] loss: 0.1916724336809582
I0416 00:50:14.014294 31272 trainer.py:139] Epoch[887/1500] loss: 0.1910237803724077
I0416 00:50:59.446780 31272 trainer.py:139] Epoch[888/1500] loss: 0.19090596616268157
I0416 00:51:44.803050 31272 trainer.py:139] Epoch[889/1500] loss: 0.19150961445437537
I0416 00:52:30.200900 31272 trainer.py:139] Epoch[890/1500] loss: 0.19083375427458021
I0416 00:53:15.519625 31272 trainer.py:139] Epoch[891/1500] loss: 0.19122154672940572
I0416 00:54:01.035233 31272 trainer.py:139] Epoch[892/1500] loss: 0.19096890012423198
I0416 00:54:46.979962 31272 trainer.py:139] Epoch[893/1500] loss: 0.19093680242697397
I0416 00:55:32.494163 31272 trainer.py:139] Epoch[894/1500] loss: 0.1926756382650799
I0416 00:56:17.798026 31272 trainer.py:139] Epoch[895/1500] loss: 0.1915790037314097
I0416 00:57:03.137203 31272 trainer.py:139] Epoch[896/1500] loss: 0.19133397658665974
I0416 00:57:48.554133 31272 trainer.py:139] Epoch[897/1500] loss: 0.19064947492546505
I0416 00:58:33.866497 31272 trainer.py:139] Epoch[898/1500] loss: 0.1906867496172587
I0416 00:59:18.785198 31272 trainer.py:139] Epoch[899/1500] loss: 0.19020475725332897
I0416 00:59:19.439012 31272 trainer.py:145] Test: {'precision': 0.2014273789649416, 'recall': 0.2849336367428545, 'hit_ratio': 0.9118530884808014, 'ndcg': 0.31968964686977625}
I0416 01:00:04.722520 31272 trainer.py:139] Epoch[900/1500] loss: 0.19103453742133247
I0416 01:00:50.559176 31272 trainer.py:139] Epoch[901/1500] loss: 0.1903337456120385
I0416 01:01:36.014819 31272 trainer.py:139] Epoch[902/1500] loss: 0.19100410481293997
I0416 01:02:21.715081 31272 trainer.py:139] Epoch[903/1500] loss: 0.19167601082060073
I0416 01:03:06.990960 31272 trainer.py:139] Epoch[904/1500] loss: 0.19035744455125597
I0416 01:03:52.141377 31272 trainer.py:139] Epoch[905/1500] loss: 0.19127144985728795
I0416 01:04:37.552924 31272 trainer.py:139] Epoch[906/1500] loss: 0.18995756639374628
I0416 01:05:22.675192 31272 trainer.py:139] Epoch[907/1500] loss: 0.19063447296619415
I0416 01:06:07.823555 31272 trainer.py:139] Epoch[908/1500] loss: 0.19131014592117734
I0416 01:06:53.820700 31272 trainer.py:139] Epoch[909/1500] loss: 0.19061210228337183
I0416 01:07:39.416957 31272 trainer.py:139] Epoch[910/1500] loss: 0.19171404745843676
I0416 01:08:24.614044 31272 trainer.py:139] Epoch[911/1500] loss: 0.19126469214757283
I0416 01:09:10.015122 31272 trainer.py:139] Epoch[912/1500] loss: 0.19192205402586196
I0416 01:09:55.113509 31272 trainer.py:139] Epoch[913/1500] loss: 0.1912873061498006
I0416 01:10:40.480487 31272 trainer.py:139] Epoch[914/1500] loss: 0.19030787799093457
I0416 01:11:25.065253 31272 trainer.py:139] Epoch[915/1500] loss: 0.19166707429620955
I0416 01:12:08.092663 31272 trainer.py:139] Epoch[916/1500] loss: 0.19143565270635818
I0416 01:12:51.579984 31272 trainer.py:139] Epoch[917/1500] loss: 0.19145087136162653
I0416 01:13:34.933614 31272 trainer.py:139] Epoch[918/1500] loss: 0.19343579365147484
I0416 01:14:17.971508 31272 trainer.py:139] Epoch[919/1500] loss: 0.19107267379760742
I0416 01:15:00.928278 31272 trainer.py:139] Epoch[920/1500] loss: 0.19082204308774736
I0416 01:15:43.509795 31272 trainer.py:139] Epoch[921/1500] loss: 0.19085595462057325
I0416 01:16:26.449190 31272 trainer.py:139] Epoch[922/1500] loss: 0.19119634760750664
I0416 01:17:09.166397 31272 trainer.py:139] Epoch[923/1500] loss: 0.19110830068588258
I0416 01:17:51.892062 31272 trainer.py:139] Epoch[924/1500] loss: 0.19135945757230122
I0416 01:18:35.037037 31272 trainer.py:139] Epoch[925/1500] loss: 0.1910076751973894
I0416 01:19:18.335389 31272 trainer.py:139] Epoch[926/1500] loss: 0.19075528019004398
I0416 01:20:01.374919 31272 trainer.py:139] Epoch[927/1500] loss: 0.19052397900157506
I0416 01:20:44.294030 31272 trainer.py:139] Epoch[928/1500] loss: 0.19232672188017103
I0416 01:21:27.070421 31272 trainer.py:139] Epoch[929/1500] loss: 0.1911357765065299
I0416 01:22:09.823998 31272 trainer.py:139] Epoch[930/1500] loss: 0.1901889792415831
I0416 01:22:52.363942 31272 trainer.py:139] Epoch[931/1500] loss: 0.19190982513957552
I0416 01:23:34.923707 31272 trainer.py:139] Epoch[932/1500] loss: 0.1909066296286053
I0416 01:24:17.859890 31272 trainer.py:139] Epoch[933/1500] loss: 0.19104867822594113
I0416 01:25:01.142515 31272 trainer.py:139] Epoch[934/1500] loss: 0.190857808192571
I0416 01:25:44.185753 31272 trainer.py:139] Epoch[935/1500] loss: 0.1913146087858412
I0416 01:26:27.257376 31272 trainer.py:139] Epoch[936/1500] loss: 0.19126760330465103
I0416 01:27:09.912114 31272 trainer.py:139] Epoch[937/1500] loss: 0.19114574121104347
I0416 01:27:52.687055 31272 trainer.py:139] Epoch[938/1500] loss: 0.1911956187751558
I0416 01:28:35.578842 31272 trainer.py:139] Epoch[939/1500] loss: 0.1908319945467843
I0416 01:29:18.046775 31272 trainer.py:139] Epoch[940/1500] loss: 0.19168978485796187
I0416 01:30:00.807631 31272 trainer.py:139] Epoch[941/1500] loss: 0.191301216284434
I0416 01:30:44.042411 31272 trainer.py:139] Epoch[942/1500] loss: 0.1914378121826384
I0416 01:31:27.328650 31272 trainer.py:139] Epoch[943/1500] loss: 0.19070136739148033
I0416 01:32:10.464168 31272 trainer.py:139] Epoch[944/1500] loss: 0.19040042261282603
I0416 01:32:53.314864 31272 trainer.py:139] Epoch[945/1500] loss: 0.19054758641454908
I0416 01:33:36.181883 31272 trainer.py:139] Epoch[946/1500] loss: 0.1906538990471098
I0416 01:34:18.993654 31272 trainer.py:139] Epoch[947/1500] loss: 0.1909208877881368
I0416 01:35:01.562284 31272 trainer.py:139] Epoch[948/1500] loss: 0.19093311289946238
I0416 01:35:43.980848 31272 trainer.py:139] Epoch[949/1500] loss: 0.1916679443915685
I0416 01:35:44.551938 31272 trainer.py:145] Test: {'precision': 0.20209515859766272, 'recall': 0.2855367727595523, 'hit_ratio': 0.9143572621035059, 'ndcg': 0.3211976298854231}
I0416 01:36:27.834165 31272 trainer.py:139] Epoch[950/1500] loss: 0.19104246735572816
I0416 01:37:11.330576 31272 trainer.py:139] Epoch[951/1500] loss: 0.19182540694872538
I0416 01:37:54.366070 31272 trainer.py:139] Epoch[952/1500] loss: 0.1906686998075909
I0416 01:38:37.378614 31272 trainer.py:139] Epoch[953/1500] loss: 0.19085336552725898
I0416 01:39:20.208344 31272 trainer.py:139] Epoch[954/1500] loss: 0.19081713769170974
I0416 01:40:03.007824 31272 trainer.py:139] Epoch[955/1500] loss: 0.19098791109191046
I0416 01:40:45.782079 31272 trainer.py:139] Epoch[956/1500] loss: 0.19063946074909635
I0416 01:41:28.241034 31272 trainer.py:139] Epoch[957/1500] loss: 0.19139771865473854
I0416 01:42:10.693167 31272 trainer.py:139] Epoch[958/1500] loss: 0.19034457272953456
I0416 01:42:54.169991 31272 trainer.py:139] Epoch[959/1500] loss: 0.19018109573258293
I0416 01:43:37.741345 31272 trainer.py:139] Epoch[960/1500] loss: 0.19105715506606633
I0416 01:44:20.842878 31272 trainer.py:139] Epoch[961/1500] loss: 0.19093839698367648
I0416 01:45:03.637957 31272 trainer.py:139] Epoch[962/1500] loss: 0.1916952567630344
I0416 01:45:46.172749 31272 trainer.py:139] Epoch[963/1500] loss: 0.19140702611870236
I0416 01:46:28.912031 31272 trainer.py:139] Epoch[964/1500] loss: 0.1915345009167989
I0416 01:47:11.643962 31272 trainer.py:139] Epoch[965/1500] loss: 0.1918548360798094
I0416 01:47:54.170152 31272 trainer.py:139] Epoch[966/1500] loss: 0.19093876236014895
I0416 01:48:37.261296 31272 trainer.py:139] Epoch[967/1500] loss: 0.19063209036986034
I0416 01:49:20.672350 31272 trainer.py:139] Epoch[968/1500] loss: 0.19057742052608065
I0416 01:50:03.729776 31272 trainer.py:139] Epoch[969/1500] loss: 0.19096740199459925
I0416 01:50:46.575052 31272 trainer.py:139] Epoch[970/1500] loss: 0.19098030938042534
I0416 01:51:29.192957 31272 trainer.py:139] Epoch[971/1500] loss: 0.19131455229388342
I0416 01:52:12.203551 31272 trainer.py:139] Epoch[972/1500] loss: 0.1910253874460856
I0416 01:52:54.850409 31272 trainer.py:139] Epoch[973/1500] loss: 0.19097782909870148
I0416 01:53:37.318409 31272 trainer.py:139] Epoch[974/1500] loss: 0.19128958543141683
I0416 01:54:20.237576 31272 trainer.py:139] Epoch[975/1500] loss: 0.18974166684680516
I0416 01:55:03.584029 31272 trainer.py:139] Epoch[976/1500] loss: 0.1916217660241657
I0416 01:55:46.875595 31272 trainer.py:139] Epoch[977/1500] loss: 0.1906275255812539
I0416 01:56:29.895316 31272 trainer.py:139] Epoch[978/1500] loss: 0.19078424844476913
I0416 01:57:12.463779 31272 trainer.py:139] Epoch[979/1500] loss: 0.19058255308204228
I0416 01:57:55.066684 31272 trainer.py:139] Epoch[980/1500] loss: 0.19010757293966082
I0416 01:58:38.099172 31272 trainer.py:139] Epoch[981/1500] loss: 0.19179974714914957
I0416 01:59:20.701613 31272 trainer.py:139] Epoch[982/1500] loss: 0.190934043791559
I0416 02:00:03.191782 31272 trainer.py:139] Epoch[983/1500] loss: 0.19122836225562626
I0416 02:00:46.835742 31272 trainer.py:139] Epoch[984/1500] loss: 0.19070174747043186
I0416 02:01:30.090209 31272 trainer.py:139] Epoch[985/1500] loss: 0.189499804576238
I0416 02:02:13.102098 31272 trainer.py:139] Epoch[986/1500] loss: 0.19128723171022202
I0416 02:02:56.102078 31272 trainer.py:139] Epoch[987/1500] loss: 0.19155179308520423
I0416 02:03:38.631691 31272 trainer.py:139] Epoch[988/1500] loss: 0.19094252745310467
I0416 02:04:21.632210 31272 trainer.py:139] Epoch[989/1500] loss: 0.1908324740992652
I0416 02:05:04.393939 31272 trainer.py:139] Epoch[990/1500] loss: 0.19162927442126804
I0416 02:05:47.085104 31272 trainer.py:139] Epoch[991/1500] loss: 0.1911433180835512
I0416 02:06:30.476659 31272 trainer.py:139] Epoch[992/1500] loss: 0.1898421945836809
I0416 02:07:14.007110 31272 trainer.py:139] Epoch[993/1500] loss: 0.19084470768769582
I0416 02:07:57.057003 31272 trainer.py:139] Epoch[994/1500] loss: 0.19248909930388133
I0416 02:08:39.907934 31272 trainer.py:139] Epoch[995/1500] loss: 0.19099248124493493
I0416 02:09:22.535114 31272 trainer.py:139] Epoch[996/1500] loss: 0.19102047039402856
I0416 02:10:05.164222 31272 trainer.py:139] Epoch[997/1500] loss: 0.19143007384406197
I0416 02:10:47.939368 31272 trainer.py:139] Epoch[998/1500] loss: 0.19145358701546986
I0416 02:11:30.585916 31272 trainer.py:139] Epoch[999/1500] loss: 0.19184313191307917
I0416 02:11:31.173949 31272 trainer.py:145] Test: {'precision': 0.20207846410684474, 'recall': 0.28613631918983745, 'hit_ratio': 0.9136894824707846, 'ndcg': 0.32217234010888074}
I0416 02:12:14.038266 31272 trainer.py:139] Epoch[1000/1500] loss: 0.19081198162502713
I0416 02:12:57.467125 31272 trainer.py:139] Epoch[1001/1500] loss: 0.19128375775284237
I0416 02:13:40.789855 31272 trainer.py:139] Epoch[1002/1500] loss: 0.190065987639957
I0416 02:14:23.989160 31272 trainer.py:139] Epoch[1003/1500] loss: 0.1909914011425442
I0416 02:15:06.841140 31272 trainer.py:139] Epoch[1004/1500] loss: 0.19017431649896835
I0416 02:15:49.512195 31272 trainer.py:139] Epoch[1005/1500] loss: 0.19106820179356468
I0416 02:16:32.619950 31272 trainer.py:139] Epoch[1006/1500] loss: 0.191764787501759
I0416 02:17:15.278067 31272 trainer.py:139] Epoch[1007/1500] loss: 0.19137813448905944
I0416 02:17:58.245878 31272 trainer.py:139] Epoch[1008/1500] loss: 0.1909937498304579
I0416 02:18:41.577221 31272 trainer.py:139] Epoch[1009/1500] loss: 0.19166392220391168
I0416 02:19:24.908185 31272 trainer.py:139] Epoch[1010/1500] loss: 0.1910819196038776
I0416 02:20:07.871017 31272 trainer.py:139] Epoch[1011/1500] loss: 0.19082835588190292
I0416 02:20:50.729055 31272 trainer.py:139] Epoch[1012/1500] loss: 0.19052660120858086
I0416 02:21:33.356372 31272 trainer.py:139] Epoch[1013/1500] loss: 0.1903340764840444
I0416 02:22:16.282828 31272 trainer.py:139] Epoch[1014/1500] loss: 0.19132339285479652
I0416 02:22:59.020862 31272 trainer.py:139] Epoch[1015/1500] loss: 0.19070308142238193
I0416 02:23:41.563092 31272 trainer.py:139] Epoch[1016/1500] loss: 0.1899568518002828
I0416 02:24:24.376116 31272 trainer.py:139] Epoch[1017/1500] loss: 0.189946379131741
I0416 02:25:07.498075 31272 trainer.py:139] Epoch[1018/1500] loss: 0.19123607099056245
I0416 02:25:50.706996 31272 trainer.py:139] Epoch[1019/1500] loss: 0.19125722229480743
I0416 02:26:33.548887 31272 trainer.py:139] Epoch[1020/1500] loss: 0.19116373697916667
I0416 02:27:16.205007 31272 trainer.py:139] Epoch[1021/1500] loss: 0.19060836282041338
I0416 02:27:59.192287 31272 trainer.py:139] Epoch[1022/1500] loss: 0.19068950010670557
I0416 02:28:41.967244 31272 trainer.py:139] Epoch[1023/1500] loss: 0.19067378381888073
I0416 02:29:24.508924 31272 trainer.py:139] Epoch[1024/1500] loss: 0.1907699751191669
I0416 02:30:07.357746 31272 trainer.py:139] Epoch[1025/1500] loss: 0.19006039559841156
I0416 02:30:50.588996 31272 trainer.py:139] Epoch[1026/1500] loss: 0.1905526753928926
I0416 02:31:34.108470 31272 trainer.py:139] Epoch[1027/1500] loss: 0.19067995382679834
I0416 02:32:17.068298 31272 trainer.py:139] Epoch[1028/1500] loss: 0.19183772179815503
I0416 02:32:59.768368 31272 trainer.py:139] Epoch[1029/1500] loss: 0.19042620685365466
I0416 02:33:42.316460 31272 trainer.py:139] Epoch[1030/1500] loss: 0.1913572818040848
I0416 02:34:25.229321 31272 trainer.py:139] Epoch[1031/1500] loss: 0.19132075568040213
I0416 02:35:07.885020 31272 trainer.py:139] Epoch[1032/1500] loss: 0.19114296085304683
I0416 02:35:50.365306 31272 trainer.py:139] Epoch[1033/1500] loss: 0.19131415466467538
I0416 02:36:33.502403 31272 trainer.py:139] Epoch[1034/1500] loss: 0.19054979178640577
I0416 02:37:16.781104 31272 trainer.py:139] Epoch[1035/1500] loss: 0.19097125715679591
I0416 02:37:59.757996 31272 trainer.py:139] Epoch[1036/1500] loss: 0.19108673320876227
I0416 02:38:42.648586 31272 trainer.py:139] Epoch[1037/1500] loss: 0.19141567170619964
I0416 02:39:25.472333 31272 trainer.py:139] Epoch[1038/1500] loss: 0.1917261497841941
I0416 02:40:08.635618 31272 trainer.py:139] Epoch[1039/1500] loss: 0.19007416380776299
I0416 02:40:51.313542 31272 trainer.py:139] Epoch[1040/1500] loss: 0.19063549809985691
I0416 02:41:34.017381 31272 trainer.py:139] Epoch[1041/1500] loss: 0.1907037678692076
I0416 02:42:16.843906 31272 trainer.py:139] Epoch[1042/1500] loss: 0.19133733808994294
I0416 02:43:00.143907 31272 trainer.py:139] Epoch[1043/1500] loss: 0.19008546537823148
I0416 02:43:43.632834 31272 trainer.py:139] Epoch[1044/1500] loss: 0.19077678879102072
I0416 02:44:26.532922 31272 trainer.py:139] Epoch[1045/1500] loss: 0.19019745614793565
I0416 02:45:09.475598 31272 trainer.py:139] Epoch[1046/1500] loss: 0.19059560702906714
I0416 02:45:52.130509 31272 trainer.py:139] Epoch[1047/1500] loss: 0.19059689230389065
I0416 02:46:35.042796 31272 trainer.py:139] Epoch[1048/1500] loss: 0.19009980420271555
I0416 02:47:17.693763 31272 trainer.py:139] Epoch[1049/1500] loss: 0.1906202502383126
I0416 02:47:18.272826 31272 trainer.py:145] Test: {'precision': 0.20225375626043401, 'recall': 0.2860065866489096, 'hit_ratio': 0.913355592654424, 'ndcg': 0.3220230280522592}
I0416 02:48:00.986167 31272 trainer.py:139] Epoch[1050/1500] loss: 0.19136752042505475
I0416 02:48:44.323935 31272 trainer.py:139] Epoch[1051/1500] loss: 0.1907966140906016
I0416 02:49:27.704980 31272 trainer.py:139] Epoch[1052/1500] loss: 0.19097894814279345
I0416 02:50:10.760728 31272 trainer.py:139] Epoch[1053/1500] loss: 0.19065380917655098
I0416 02:50:53.525838 31272 trainer.py:139] Epoch[1054/1500] loss: 0.19184927317831252
I0416 02:51:36.121486 31272 trainer.py:139] Epoch[1055/1500] loss: 0.19082294748889075
I0416 02:52:19.132899 31272 trainer.py:139] Epoch[1056/1500] loss: 0.19061959107716878
I0416 02:53:01.702385 31272 trainer.py:139] Epoch[1057/1500] loss: 0.1901414469215605
I0416 02:53:44.452240 31272 trainer.py:139] Epoch[1058/1500] loss: 0.19036266969309912
I0416 02:54:27.560843 31272 trainer.py:139] Epoch[1059/1500] loss: 0.19096079998546175
I0416 02:55:11.125841 31272 trainer.py:139] Epoch[1060/1500] loss: 0.18988891137970818
I0416 02:55:55.052224 31272 trainer.py:139] Epoch[1061/1500] loss: 0.19180119223064845
I0416 02:56:38.081174 31272 trainer.py:139] Epoch[1062/1500] loss: 0.1911443265941408
I0416 02:57:20.902678 31272 trainer.py:139] Epoch[1063/1500] loss: 0.19085018826855554
I0416 02:58:03.696295 31272 trainer.py:139] Epoch[1064/1500] loss: 0.1916448308361901
I0416 02:58:46.622922 31272 trainer.py:139] Epoch[1065/1500] loss: 0.19022337032688988
I0416 02:59:29.650418 31272 trainer.py:139] Epoch[1066/1500] loss: 0.1919929301076465
I0416 03:00:12.755681 31272 trainer.py:139] Epoch[1067/1500] loss: 0.1905671966738171
I0416 03:00:56.137373 31272 trainer.py:139] Epoch[1068/1500] loss: 0.19129795021480983
I0416 03:01:39.537487 31272 trainer.py:139] Epoch[1069/1500] loss: 0.19122535559866163
I0416 03:02:22.489551 31272 trainer.py:139] Epoch[1070/1500] loss: 0.19010842283566792
I0416 03:03:05.397708 31272 trainer.py:139] Epoch[1071/1500] loss: 0.19050682478480868
I0416 03:03:48.027324 31272 trainer.py:139] Epoch[1072/1500] loss: 0.18937587102254233
I0416 03:04:30.843310 31272 trainer.py:139] Epoch[1073/1500] loss: 0.19113717059294383
I0416 03:05:13.639752 31272 trainer.py:139] Epoch[1074/1500] loss: 0.19080491463343302
I0416 03:05:56.624799 31272 trainer.py:139] Epoch[1075/1500] loss: 0.1914889266093572
I0416 03:06:40.007303 31272 trainer.py:139] Epoch[1076/1500] loss: 0.1915034356382158
I0416 03:07:23.414430 31272 trainer.py:139] Epoch[1077/1500] loss: 0.19040300289789835
I0416 03:08:06.492214 31272 trainer.py:139] Epoch[1078/1500] loss: 0.1904707697365019
I0416 03:08:49.524473 31272 trainer.py:139] Epoch[1079/1500] loss: 0.1907376445002026
I0416 03:09:32.151769 31272 trainer.py:139] Epoch[1080/1500] loss: 0.1914238151576784
I0416 03:10:14.861623 31272 trainer.py:139] Epoch[1081/1500] loss: 0.19137893690003288
I0416 03:10:57.558695 31272 trainer.py:139] Epoch[1082/1500] loss: 0.19068060484197405
I0416 03:11:40.139661 31272 trainer.py:139] Epoch[1083/1500] loss: 0.19026943100823296
I0416 03:12:23.075094 31272 trainer.py:139] Epoch[1084/1500] loss: 0.19014950666162703
I0416 03:13:06.491636 31272 trainer.py:139] Epoch[1085/1500] loss: 0.19009861846764883
I0416 03:13:49.646155 31272 trainer.py:139] Epoch[1086/1500] loss: 0.1902045671807395
I0416 03:14:32.611415 31272 trainer.py:139] Epoch[1087/1500] loss: 0.1909454349014494
I0416 03:15:15.375841 31272 trainer.py:139] Epoch[1088/1500] loss: 0.19086769276195104
I0416 03:15:57.939791 31272 trainer.py:139] Epoch[1089/1500] loss: 0.19021353012985653
I0416 03:16:40.610062 31272 trainer.py:139] Epoch[1090/1500] loss: 0.18997301836808522
I0416 03:17:24.934321 31272 trainer.py:139] Epoch[1091/1500] loss: 0.19039526959260306
I0416 03:18:07.657784 31272 trainer.py:139] Epoch[1092/1500] loss: 0.19109655333889855
I0416 03:18:51.146522 31272 trainer.py:139] Epoch[1093/1500] loss: 0.19104144010278915
I0416 03:19:34.357973 31272 trainer.py:139] Epoch[1094/1500] loss: 0.1907470839553409
I0416 03:20:17.036258 31272 trainer.py:139] Epoch[1095/1500] loss: 0.19033301340209113
I0416 03:20:59.454098 31272 trainer.py:139] Epoch[1096/1500] loss: 0.19088620788521238
I0416 03:21:41.703937 31272 trainer.py:139] Epoch[1097/1500] loss: 0.19105219079388513
I0416 03:22:24.489237 31272 trainer.py:139] Epoch[1098/1500] loss: 0.19127486765384674
I0416 03:23:06.784881 31272 trainer.py:139] Epoch[1099/1500] loss: 0.19082490887906817
I0416 03:23:07.347001 31272 trainer.py:145] Test: {'precision': 0.20268781302170277, 'recall': 0.28605071401002926, 'hit_ratio': 0.9145242070116861, 'ndcg': 0.3228386372233836}
I0416 03:23:49.602496 31272 trainer.py:139] Epoch[1100/1500] loss: 0.1905785224172804
I0416 03:24:32.574157 31272 trainer.py:139] Epoch[1101/1500] loss: 0.19118508948220148
I0416 03:25:15.576166 31272 trainer.py:139] Epoch[1102/1500] loss: 0.19161082559161716
I0416 03:25:58.239226 31272 trainer.py:139] Epoch[1103/1500] loss: 0.19064960916837057
I0416 03:26:40.830740 31272 trainer.py:139] Epoch[1104/1500] loss: 0.19102122604846955
I0416 03:27:23.139903 31272 trainer.py:139] Epoch[1105/1500] loss: 0.19061468323071798
I0416 03:28:05.496643 31272 trainer.py:139] Epoch[1106/1500] loss: 0.1906249084075292
I0416 03:28:47.983772 31272 trainer.py:139] Epoch[1107/1500] loss: 0.19093649294641282
I0416 03:29:30.244230 31272 trainer.py:139] Epoch[1108/1500] loss: 0.19098118265469868
I0416 03:30:12.817669 31272 trainer.py:139] Epoch[1109/1500] loss: 0.19029034561581082
I0416 03:30:55.758801 31272 trainer.py:139] Epoch[1110/1500] loss: 0.19070042504204643
I0416 03:31:38.911624 31272 trainer.py:139] Epoch[1111/1500] loss: 0.19056144727600946
I0416 03:32:21.896128 31272 trainer.py:139] Epoch[1112/1500] loss: 0.19077689170837403
I0416 03:33:04.589414 31272 trainer.py:139] Epoch[1113/1500] loss: 0.1900446386469735
I0416 03:33:47.394444 31272 trainer.py:139] Epoch[1114/1500] loss: 0.1900011858675215
I0416 03:34:30.248626 31272 trainer.py:139] Epoch[1115/1500] loss: 0.19142304301261903
I0416 03:35:12.860387 31272 trainer.py:139] Epoch[1116/1500] loss: 0.19098097450203366
I0416 03:35:56.166712 31272 trainer.py:139] Epoch[1117/1500] loss: 0.19034747686651018
I0416 03:36:39.531548 31272 trainer.py:139] Epoch[1118/1500] loss: 0.19087975521882375
I0416 03:37:22.956939 31272 trainer.py:139] Epoch[1119/1500] loss: 0.1908785734574
I0416 03:38:06.087544 31272 trainer.py:139] Epoch[1120/1500] loss: 0.19189021852281357
I0416 03:38:48.828497 31272 trainer.py:139] Epoch[1121/1500] loss: 0.19115166147549947
I0416 03:39:31.564378 31272 trainer.py:139] Epoch[1122/1500] loss: 0.19136665629016028
I0416 03:40:14.698383 31272 trainer.py:139] Epoch[1123/1500] loss: 0.19097624652915532
I0416 03:40:57.457609 31272 trainer.py:139] Epoch[1124/1500] loss: 0.19109772953722212
I0416 03:41:40.131614 31272 trainer.py:139] Epoch[1125/1500] loss: 0.19182506097687615
I0416 03:42:23.204467 31272 trainer.py:139] Epoch[1126/1500] loss: 0.19115101681815252
I0416 03:43:06.694555 31272 trainer.py:139] Epoch[1127/1500] loss: 0.19063823375436995
I0416 03:43:49.682795 31272 trainer.py:139] Epoch[1128/1500] loss: 0.1906240936120351
I0416 03:44:32.602030 31272 trainer.py:139] Epoch[1129/1500] loss: 0.1912382100025813
I0416 03:45:15.623023 31272 trainer.py:139] Epoch[1130/1500] loss: 0.19043578419420454
I0416 03:45:58.394259 31272 trainer.py:139] Epoch[1131/1500] loss: 0.19004017889499664
I0416 03:46:41.407460 31272 trainer.py:139] Epoch[1132/1500] loss: 0.1916830039024353
I0416 03:47:23.984353 31272 trainer.py:139] Epoch[1133/1500] loss: 0.19107684473196665
I0416 03:48:06.966526 31272 trainer.py:139] Epoch[1134/1500] loss: 0.19048055688540141
I0416 03:48:50.358789 31272 trainer.py:139] Epoch[1135/1500] loss: 0.19053611901071338
I0416 03:49:33.809944 31272 trainer.py:139] Epoch[1136/1500] loss: 0.19096537636386024
I0416 03:50:16.934952 31272 trainer.py:139] Epoch[1137/1500] loss: 0.19090232292811077
I0416 03:50:59.622758 31272 trainer.py:139] Epoch[1138/1500] loss: 0.1906686164273156
I0416 03:51:42.096014 31272 trainer.py:139] Epoch[1139/1500] loss: 0.19095177133878072
I0416 03:52:25.219112 31272 trainer.py:139] Epoch[1140/1500] loss: 0.1903918379545212
I0416 03:53:07.832398 31272 trainer.py:139] Epoch[1141/1500] loss: 0.19161180423365698
I0416 03:53:50.679645 31272 trainer.py:139] Epoch[1142/1500] loss: 0.19106794801023272
I0416 03:54:34.044850 31272 trainer.py:139] Epoch[1143/1500] loss: 0.19088281604978774
I0416 03:55:17.412198 31272 trainer.py:139] Epoch[1144/1500] loss: 0.19028093106216853
I0416 03:56:00.582577 31272 trainer.py:139] Epoch[1145/1500] loss: 0.1906829586956236
I0416 03:56:43.634338 31272 trainer.py:139] Epoch[1146/1500] loss: 0.19100438217322033
I0416 03:57:26.393508 31272 trainer.py:139] Epoch[1147/1500] loss: 0.1913366515106625
I0416 03:58:09.342620 31272 trainer.py:139] Epoch[1148/1500] loss: 0.19103676994641622
I0416 03:58:52.211066 31272 trainer.py:139] Epoch[1149/1500] loss: 0.18990568823284573
I0416 03:58:52.789132 31272 trainer.py:145] Test: {'precision': 0.20202838063439063, 'recall': 0.2861562275824643, 'hit_ratio': 0.9136894824707846, 'ndcg': 0.3224926636675012}
I0416 03:59:35.629545 31272 trainer.py:139] Epoch[1150/1500] loss: 0.18975311352146995
I0416 04:00:18.885833 31272 trainer.py:139] Epoch[1151/1500] loss: 0.19086644901169672
I0416 04:01:02.735328 31272 trainer.py:139] Epoch[1152/1500] loss: 0.19110231075021955
I0416 04:01:46.313422 31272 trainer.py:139] Epoch[1153/1500] loss: 0.19056288811895583
I0416 04:02:29.630328 31272 trainer.py:139] Epoch[1154/1500] loss: 0.19177796589003668
I0416 04:03:13.403887 31272 trainer.py:139] Epoch[1155/1500] loss: 0.18951373477776845
I0416 04:03:57.174676 31272 trainer.py:139] Epoch[1156/1500] loss: 0.1911400591664844
I0416 04:04:40.198665 31272 trainer.py:139] Epoch[1157/1500] loss: 0.1902158812681834
I0416 04:05:22.848054 31272 trainer.py:139] Epoch[1158/1500] loss: 0.19156280676523843
I0416 04:06:05.640462 31272 trainer.py:139] Epoch[1159/1500] loss: 0.1908221438858244
I0416 04:06:48.960526 31272 trainer.py:139] Epoch[1160/1500] loss: 0.19081373631954193
I0416 04:07:32.358402 31272 trainer.py:139] Epoch[1161/1500] loss: 0.19105909963448842
I0416 04:08:15.225401 31272 trainer.py:139] Epoch[1162/1500] loss: 0.19100299702750312
I0416 04:08:58.246503 31272 trainer.py:139] Epoch[1163/1500] loss: 0.19111072142918906
I0416 04:09:40.786149 31272 trainer.py:139] Epoch[1164/1500] loss: 0.1915030899312761
I0416 04:10:23.518479 31272 trainer.py:139] Epoch[1165/1500] loss: 0.18993423495027753
I0416 04:11:06.145316 31272 trainer.py:139] Epoch[1166/1500] loss: 0.19027543763319651
I0416 04:11:48.555337 31272 trainer.py:139] Epoch[1167/1500] loss: 0.19080162313249377
I0416 04:12:31.644843 31272 trainer.py:139] Epoch[1168/1500] loss: 0.19076506912708283
I0416 04:13:15.033771 31272 trainer.py:139] Epoch[1169/1500] loss: 0.19126916799280377
I0416 04:13:58.118279 31272 trainer.py:139] Epoch[1170/1500] loss: 0.19091307560602824
I0416 04:14:40.901259 31272 trainer.py:139] Epoch[1171/1500] loss: 0.1908469315369924
I0416 04:15:23.471900 31272 trainer.py:139] Epoch[1172/1500] loss: 0.1897555007537206
I0416 04:16:06.637979 31272 trainer.py:139] Epoch[1173/1500] loss: 0.1907824167278078
I0416 04:16:49.609024 31272 trainer.py:139] Epoch[1174/1500] loss: 0.19075030068556467
I0416 04:17:32.168945 31272 trainer.py:139] Epoch[1175/1500] loss: 0.19052346580558352
I0416 04:18:15.269157 31272 trainer.py:139] Epoch[1176/1500] loss: 0.190045548081398
I0416 04:18:58.566870 31272 trainer.py:139] Epoch[1177/1500] loss: 0.19100723683834075
I0416 04:19:41.718008 31272 trainer.py:139] Epoch[1178/1500] loss: 0.19067119863298204
I0416 04:20:24.623864 31272 trainer.py:139] Epoch[1179/1500] loss: 0.1901414989762836
I0416 04:21:07.377888 31272 trainer.py:139] Epoch[1180/1500] loss: 0.1913175709380044
I0416 04:21:50.125735 31272 trainer.py:139] Epoch[1181/1500] loss: 0.19109146998988258
I0416 04:22:32.965356 31272 trainer.py:139] Epoch[1182/1500] loss: 0.19057845267984602
I0416 04:23:15.456167 31272 trainer.py:139] Epoch[1183/1500] loss: 0.19166351543532478
I0416 04:23:58.121844 31272 trainer.py:139] Epoch[1184/1500] loss: 0.19172895934846665
I0416 04:24:41.389055 31272 trainer.py:139] Epoch[1185/1500] loss: 0.18893622120221457
I0416 04:25:24.722487 31272 trainer.py:139] Epoch[1186/1500] loss: 0.1912911072704527
I0416 04:26:07.910177 31272 trainer.py:139] Epoch[1187/1500] loss: 0.1892568638589647
I0416 04:26:50.876743 31272 trainer.py:139] Epoch[1188/1500] loss: 0.1910894669426812
I0416 04:27:33.487439 31272 trainer.py:139] Epoch[1189/1500] loss: 0.19145731687545775
I0416 04:28:16.363920 31272 trainer.py:139] Epoch[1190/1500] loss: 0.19170109020339118
I0416 04:28:59.389981 31272 trainer.py:139] Epoch[1191/1500] loss: 0.1914618910021252
I0416 04:29:41.954488 31272 trainer.py:139] Epoch[1192/1500] loss: 0.19064924167262184
I0416 04:30:25.025815 31272 trainer.py:139] Epoch[1193/1500] loss: 0.1904958626959059
I0416 04:31:08.709673 31272 trainer.py:139] Epoch[1194/1500] loss: 0.19034559309482574
I0416 04:31:52.099880 31272 trainer.py:139] Epoch[1195/1500] loss: 0.19102234303951263
I0416 04:32:35.360475 31272 trainer.py:139] Epoch[1196/1500] loss: 0.19136839244100784
I0416 04:33:18.437838 31272 trainer.py:139] Epoch[1197/1500] loss: 0.19115862468878428
I0416 04:34:01.739434 31272 trainer.py:139] Epoch[1198/1500] loss: 0.18954811182287004
I0416 04:34:44.699590 31272 trainer.py:139] Epoch[1199/1500] loss: 0.19184374378787147
I0416 04:34:45.276659 31272 trainer.py:145] Test: {'precision': 0.20245409015025043, 'recall': 0.28592471518920527, 'hit_ratio': 0.9145242070116861, 'ndcg': 0.32154682022301406}
I0416 04:35:27.922077 31272 trainer.py:139] Epoch[1200/1500] loss: 0.1910799667570326
I0416 04:36:10.831830 31272 trainer.py:139] Epoch[1201/1500] loss: 0.19079835202958847
I0416 04:36:54.442115 31272 trainer.py:139] Epoch[1202/1500] loss: 0.1904909912745158
I0416 04:37:37.784810 31272 trainer.py:139] Epoch[1203/1500] loss: 0.19143991702132754
I0416 04:38:20.959291 31272 trainer.py:139] Epoch[1204/1500] loss: 0.19073239028453826
I0416 04:39:03.844650 31272 trainer.py:139] Epoch[1205/1500] loss: 0.18984919759962293
I0416 04:39:46.541424 31272 trainer.py:139] Epoch[1206/1500] loss: 0.19148313522338867
I0416 04:40:29.482236 31272 trainer.py:139] Epoch[1207/1500] loss: 0.1897276759809918
I0416 04:41:12.215007 31272 trainer.py:139] Epoch[1208/1500] loss: 0.19039614856243134
I0416 04:41:54.927175 31272 trainer.py:139] Epoch[1209/1500] loss: 0.19108662406603497
I0416 04:42:38.140561 31272 trainer.py:139] Epoch[1210/1500] loss: 0.19022733807563783
I0416 04:43:21.229714 31272 trainer.py:139] Epoch[1211/1500] loss: 0.19088355428642698
I0416 04:44:04.629109 31272 trainer.py:139] Epoch[1212/1500] loss: 0.19051605416668785
I0416 04:44:47.670452 31272 trainer.py:139] Epoch[1213/1500] loss: 0.1905662233961953
I0416 04:45:30.433209 31272 trainer.py:139] Epoch[1214/1500] loss: 0.19086625317732492
I0416 04:46:13.345338 31272 trainer.py:139] Epoch[1215/1500] loss: 0.19008546902073753
I0416 04:46:56.185722 31272 trainer.py:139] Epoch[1216/1500] loss: 0.1894328753153483
I0416 04:47:38.811848 31272 trainer.py:139] Epoch[1217/1500] loss: 0.19088889393541547
I0416 04:48:21.659230 31272 trainer.py:139] Epoch[1218/1500] loss: 0.18992699556880527
I0416 04:49:04.902390 31272 trainer.py:139] Epoch[1219/1500] loss: 0.19138623853524525
I0416 04:49:48.346208 31272 trainer.py:139] Epoch[1220/1500] loss: 0.19077925966845619
I0416 04:50:31.125753 31272 trainer.py:139] Epoch[1221/1500] loss: 0.1906732091638777
I0416 04:51:13.957068 31272 trainer.py:139] Epoch[1222/1500] loss: 0.19032347407605912
I0416 04:51:56.620533 31272 trainer.py:139] Epoch[1223/1500] loss: 0.19033722486760882
I0416 04:52:39.592391 31272 trainer.py:139] Epoch[1224/1500] loss: 0.1912521806690428
I0416 04:53:22.169857 31272 trainer.py:139] Epoch[1225/1500] loss: 0.1905525396267573
I0416 04:54:05.313401 31272 trainer.py:139] Epoch[1226/1500] loss: 0.1901393125454585
I0416 04:54:48.630272 31272 trainer.py:139] Epoch[1227/1500] loss: 0.19053782297505273
I0416 04:55:31.909484 31272 trainer.py:139] Epoch[1228/1500] loss: 0.1906270879507065
I0416 04:56:14.870755 31272 trainer.py:139] Epoch[1229/1500] loss: 0.19153125292725035
I0416 04:56:57.814569 31272 trainer.py:139] Epoch[1230/1500] loss: 0.1910431322786543
I0416 04:57:40.366622 31272 trainer.py:139] Epoch[1231/1500] loss: 0.1910183741648992
I0416 04:58:23.321911 31272 trainer.py:139] Epoch[1232/1500] loss: 0.19133250137170155
I0416 04:59:06.177176 31272 trainer.py:139] Epoch[1233/1500] loss: 0.1910046429766549
I0416 04:59:48.679778 31272 trainer.py:139] Epoch[1234/1500] loss: 0.19198760277695126
I0416 05:00:31.655286 31272 trainer.py:139] Epoch[1235/1500] loss: 0.19087798131836786
I0416 05:01:14.784230 31272 trainer.py:139] Epoch[1236/1500] loss: 0.19170016374852922
I0416 05:01:57.580311 31272 trainer.py:139] Epoch[1237/1500] loss: 0.1909679397609499
I0416 05:02:40.609741 31272 trainer.py:139] Epoch[1238/1500] loss: 0.19150966703891753
I0416 05:03:23.217595 31272 trainer.py:139] Epoch[1239/1500] loss: 0.191527106695705
I0416 05:04:06.157436 31272 trainer.py:139] Epoch[1240/1500] loss: 0.19176882280243768
I0416 05:04:48.923491 31272 trainer.py:139] Epoch[1241/1500] loss: 0.19100430270036062
I0416 05:05:31.676180 31272 trainer.py:139] Epoch[1242/1500] loss: 0.19018357415994008
I0416 05:06:14.820791 31272 trainer.py:139] Epoch[1243/1500] loss: 0.19133752087752023
I0416 05:06:58.149915 31272 trainer.py:139] Epoch[1244/1500] loss: 0.19044000453419155
I0416 05:07:41.386471 31272 trainer.py:139] Epoch[1245/1500] loss: 0.19120028330220115
I0416 05:08:24.372517 31272 trainer.py:139] Epoch[1246/1500] loss: 0.19042234473758274
I0416 05:09:07.125941 31272 trainer.py:139] Epoch[1247/1500] loss: 0.1905210503604677
I0416 05:09:49.825515 31272 trainer.py:139] Epoch[1248/1500] loss: 0.19103892829683092
I0416 05:10:33.009471 31272 trainer.py:139] Epoch[1249/1500] loss: 0.19085267656379276
I0416 05:10:33.590527 31272 trainer.py:145] Test: {'precision': 0.2019699499165275, 'recall': 0.28604324457876806, 'hit_ratio': 0.9141903171953255, 'ndcg': 0.3228227001577295}
I0416 05:11:16.228944 31272 trainer.py:139] Epoch[1250/1500] loss: 0.19033653656641641
I0416 05:11:58.883919 31272 trainer.py:139] Epoch[1251/1500] loss: 0.19156497915585835
I0416 05:12:42.164548 31272 trainer.py:139] Epoch[1252/1500] loss: 0.19116263820065393
I0416 05:13:25.684234 31272 trainer.py:139] Epoch[1253/1500] loss: 0.18953611890474956
I0416 05:14:08.595470 31272 trainer.py:139] Epoch[1254/1500] loss: 0.19049878279368082
I0416 05:14:51.527193 31272 trainer.py:139] Epoch[1255/1500] loss: 0.19180388351281483
I0416 05:15:34.251184 31272 trainer.py:139] Epoch[1256/1500] loss: 0.18977877146667904
I0416 05:16:17.166347 31272 trainer.py:139] Epoch[1257/1500] loss: 0.1889644832081265
I0416 05:16:59.994782 31272 trainer.py:139] Epoch[1258/1500] loss: 0.18972883535756005
I0416 05:17:42.592597 31272 trainer.py:139] Epoch[1259/1500] loss: 0.19102738201618194
I0416 05:18:25.609697 31272 trainer.py:139] Epoch[1260/1500] loss: 0.19203794671429528
I0416 05:19:08.867546 31272 trainer.py:139] Epoch[1261/1500] loss: 0.1903334186474482
I0416 05:19:52.004784 31272 trainer.py:139] Epoch[1262/1500] loss: 0.19070233391390906
I0416 05:20:34.887620 31272 trainer.py:139] Epoch[1263/1500] loss: 0.19047171619203357
I0416 05:21:17.718609 31272 trainer.py:139] Epoch[1264/1500] loss: 0.1907367565896776
I0416 05:22:00.647868 31272 trainer.py:139] Epoch[1265/1500] loss: 0.19099505450990464
I0416 05:22:43.462635 31272 trainer.py:139] Epoch[1266/1500] loss: 0.19118454304006366
I0416 05:23:26.061125 31272 trainer.py:139] Epoch[1267/1500] loss: 0.18968787140316434
I0416 05:24:08.664012 31272 trainer.py:139] Epoch[1268/1500] loss: 0.19027846342987484
I0416 05:24:52.112858 31272 trainer.py:139] Epoch[1269/1500] loss: 0.1904080261124505
I0416 05:25:35.314461 31272 trainer.py:139] Epoch[1270/1500] loss: 0.19147427572144401
I0416 05:26:18.523908 31272 trainer.py:139] Epoch[1271/1500] loss: 0.19037800232569377
I0416 05:27:01.370454 31272 trainer.py:139] Epoch[1272/1500] loss: 0.19030260033077664
I0416 05:27:43.946107 31272 trainer.py:139] Epoch[1273/1500] loss: 0.19001234511534373
I0416 05:28:27.022444 31272 trainer.py:139] Epoch[1274/1500] loss: 0.19031424793932172
I0416 05:29:09.676304 31272 trainer.py:139] Epoch[1275/1500] loss: 0.19108038359218174
I0416 05:29:52.238180 31272 trainer.py:139] Epoch[1276/1500] loss: 0.1902244922187593
I0416 05:30:35.550455 31272 trainer.py:139] Epoch[1277/1500] loss: 0.19053369025389352
I0416 05:31:19.009872 31272 trainer.py:139] Epoch[1278/1500] loss: 0.1909633723894755
I0416 05:32:02.304030 31272 trainer.py:139] Epoch[1279/1500] loss: 0.19064837363031176
I0416 05:32:45.246919 31272 trainer.py:139] Epoch[1280/1500] loss: 0.19002919799751705
I0416 05:33:27.947937 31272 trainer.py:139] Epoch[1281/1500] loss: 0.1915274676349428
I0416 05:34:10.926113 31272 trainer.py:139] Epoch[1282/1500] loss: 0.191082198354933
I0416 05:34:53.842837 31272 trainer.py:139] Epoch[1283/1500] loss: 0.19085488087601132
I0416 05:35:36.400296 31272 trainer.py:139] Epoch[1284/1500] loss: 0.19061478217442832
I0416 05:36:19.546524 31272 trainer.py:139] Epoch[1285/1500] loss: 0.19112405571672653
I0416 05:37:02.932149 31272 trainer.py:139] Epoch[1286/1500] loss: 0.19077596849865383
I0416 05:37:46.153825 31272 trainer.py:139] Epoch[1287/1500] loss: 0.19108395675818127
I0416 05:38:29.394980 31272 trainer.py:139] Epoch[1288/1500] loss: 0.19026335292392307
I0416 05:39:12.023997 31272 trainer.py:139] Epoch[1289/1500] loss: 0.1903778999381595
I0416 05:39:54.788471 31272 trainer.py:139] Epoch[1290/1500] loss: 0.1912822695573171
I0416 05:40:37.686334 31272 trainer.py:139] Epoch[1291/1500] loss: 0.1906950088342031
I0416 05:41:20.440586 31272 trainer.py:139] Epoch[1292/1500] loss: 0.19059211353460948
I0416 05:42:03.099709 31272 trainer.py:139] Epoch[1293/1500] loss: 0.19160781549082861
I0416 05:42:46.425404 31272 trainer.py:139] Epoch[1294/1500] loss: 0.19012230886353387
I0416 05:43:29.867982 31272 trainer.py:139] Epoch[1295/1500] loss: 0.19045687721835242
I0416 05:44:13.312332 31272 trainer.py:139] Epoch[1296/1500] loss: 0.1904577315515942
I0416 05:44:56.145880 31272 trainer.py:139] Epoch[1297/1500] loss: 0.19011960446834564
I0416 05:45:38.874852 31272 trainer.py:139] Epoch[1298/1500] loss: 0.19027668310536278
I0416 05:46:21.700635 31272 trainer.py:139] Epoch[1299/1500] loss: 0.1910381187333001
I0416 05:46:22.283599 31272 trainer.py:145] Test: {'precision': 0.20165275459098492, 'recall': 0.2861961897133378, 'hit_ratio': 0.9138564273789649, 'ndcg': 0.3227701360109744}
I0416 05:47:04.986455 31272 trainer.py:139] Epoch[1300/1500] loss: 0.19134052607748245
I0416 05:47:47.636608 31272 trainer.py:139] Epoch[1301/1500] loss: 0.19093382179737092
I0416 05:48:30.823886 31272 trainer.py:139] Epoch[1302/1500] loss: 0.1895668625831604
I0416 05:49:14.074836 31272 trainer.py:139] Epoch[1303/1500] loss: 0.1902555607424842
I0416 05:49:57.126681 31272 trainer.py:139] Epoch[1304/1500] loss: 0.19076522482766045
I0416 05:50:39.967085 31272 trainer.py:139] Epoch[1305/1500] loss: 0.18925003780259025
I0416 05:51:22.748732 31272 trainer.py:139] Epoch[1306/1500] loss: 0.1903246357705858
I0416 05:52:05.686509 31272 trainer.py:139] Epoch[1307/1500] loss: 0.19127808378802405
I0416 05:52:48.456925 31272 trainer.py:139] Epoch[1308/1500] loss: 0.18974708000818888
I0416 05:53:30.958016 31272 trainer.py:139] Epoch[1309/1500] loss: 0.18999978330400255
I0416 05:54:14.037376 31272 trainer.py:139] Epoch[1310/1500] loss: 0.19030799958440991
I0416 05:54:57.285726 31272 trainer.py:139] Epoch[1311/1500] loss: 0.19150978691048093
I0416 05:55:40.830800 31272 trainer.py:139] Epoch[1312/1500] loss: 0.19109932177596622
I0416 05:56:23.927327 31272 trainer.py:139] Epoch[1313/1500] loss: 0.19071785125467514
I0416 05:57:06.707098 31272 trainer.py:139] Epoch[1314/1500] loss: 0.1912600855032603
I0416 05:57:49.204641 31272 trainer.py:139] Epoch[1315/1500] loss: 0.19020495739248064
I0416 05:58:32.196701 31272 trainer.py:139] Epoch[1316/1500] loss: 0.19014336089293163
I0416 05:59:14.879474 31272 trainer.py:139] Epoch[1317/1500] loss: 0.1911863358815511
I0416 05:59:57.443240 31272 trainer.py:139] Epoch[1318/1500] loss: 0.19018292115794289
I0416 06:00:40.618364 31272 trainer.py:139] Epoch[1319/1500] loss: 0.1905570752090878
I0416 06:01:24.318182 31272 trainer.py:139] Epoch[1320/1500] loss: 0.191077645222346
I0416 06:02:07.496861 31272 trainer.py:139] Epoch[1321/1500] loss: 0.19055611550807952
I0416 06:02:50.207706 31272 trainer.py:139] Epoch[1322/1500] loss: 0.1905381739139557
I0416 06:03:32.871681 31272 trainer.py:139] Epoch[1323/1500] loss: 0.1908040663268831
I0416 06:04:15.657528 31272 trainer.py:139] Epoch[1324/1500] loss: 0.19102440006203122
I0416 06:04:58.255807 31272 trainer.py:139] Epoch[1325/1500] loss: 0.1910295091734992
I0416 06:05:41.018198 31272 trainer.py:139] Epoch[1326/1500] loss: 0.1901412057214313
I0416 06:06:23.914027 31272 trainer.py:139] Epoch[1327/1500] loss: 0.19082830766836803
I0416 06:07:07.248077 31272 trainer.py:139] Epoch[1328/1500] loss: 0.19072209676106772
I0416 06:07:50.534716 31272 trainer.py:139] Epoch[1329/1500] loss: 0.19091587205727895
I0416 06:08:33.639769 31272 trainer.py:139] Epoch[1330/1500] loss: 0.19076769232749938
I0416 06:09:16.348218 31272 trainer.py:139] Epoch[1331/1500] loss: 0.1897525469462077
I0416 06:09:59.286917 31272 trainer.py:139] Epoch[1332/1500] loss: 0.1900368575255076
I0416 06:10:42.353137 31272 trainer.py:139] Epoch[1333/1500] loss: 0.19053955223825242
I0416 06:11:24.839881 31272 trainer.py:139] Epoch[1334/1500] loss: 0.19071930746237437
I0416 06:12:07.714445 31272 trainer.py:139] Epoch[1335/1500] loss: 0.19050800138049656
I0416 06:12:50.795680 31272 trainer.py:139] Epoch[1336/1500] loss: 0.18933013200759888
I0416 06:13:33.942353 31272 trainer.py:139] Epoch[1337/1500] loss: 0.19069320612483553
I0416 06:14:17.252856 31272 trainer.py:139] Epoch[1338/1500] loss: 0.19023021346992916
I0416 06:15:00.319641 31272 trainer.py:139] Epoch[1339/1500] loss: 0.19106916023625267
I0416 06:15:42.985183 31272 trainer.py:139] Epoch[1340/1500] loss: 0.1907011177142461
I0416 06:16:25.819766 31272 trainer.py:139] Epoch[1341/1500] loss: 0.18980493976010215
I0416 06:17:08.327606 31272 trainer.py:139] Epoch[1342/1500] loss: 0.19007744941446517
I0416 06:17:50.977355 31272 trainer.py:139] Epoch[1343/1500] loss: 0.19071963210900625
I0416 06:18:33.954941 31272 trainer.py:139] Epoch[1344/1500] loss: 0.1910543460316128
I0416 06:19:17.050555 31272 trainer.py:139] Epoch[1345/1500] loss: 0.19120997415648566
I0416 06:20:00.356441 31272 trainer.py:139] Epoch[1346/1500] loss: 0.19088995814323426
I0416 06:20:43.404245 31272 trainer.py:139] Epoch[1347/1500] loss: 0.18932158264848922
I0416 06:21:26.096884 31272 trainer.py:139] Epoch[1348/1500] loss: 0.19117663224538167
I0416 06:22:08.835299 31272 trainer.py:139] Epoch[1349/1500] loss: 0.19084900001684824
I0416 06:22:09.437283 31272 trainer.py:145] Test: {'precision': 0.20217028380634391, 'recall': 0.285749821528885, 'hit_ratio': 0.9146911519198665, 'ndcg': 0.3216221719961051}
I0416 06:22:52.174211 31272 trainer.py:139] Epoch[1350/1500] loss: 0.1899358630180359
I0416 06:23:34.826365 31272 trainer.py:139] Epoch[1351/1500] loss: 0.19151532789071402
I0416 06:24:17.534969 31272 trainer.py:139] Epoch[1352/1500] loss: 0.19104156812032064
I0416 06:25:00.853970 31272 trainer.py:139] Epoch[1353/1500] loss: 0.19050684286488426
I0416 06:25:43.962255 31272 trainer.py:139] Epoch[1354/1500] loss: 0.19067695611053043
I0416 06:26:27.223855 31272 trainer.py:139] Epoch[1355/1500] loss: 0.19033802429835
I0416 06:27:10.009847 31272 trainer.py:139] Epoch[1356/1500] loss: 0.19107931547694737
I0416 06:27:52.703983 31272 trainer.py:139] Epoch[1357/1500] loss: 0.1896405291557312
I0416 06:28:35.458893 31272 trainer.py:139] Epoch[1358/1500] loss: 0.19029118922021654
I0416 06:29:18.105063 31272 trainer.py:139] Epoch[1359/1500] loss: 0.18994499550925362
I0416 06:30:00.773183 31272 trainer.py:139] Epoch[1360/1500] loss: 0.18983807093567318
I0416 06:30:44.086099 31272 trainer.py:139] Epoch[1361/1500] loss: 0.1911409405204985
I0416 06:31:27.739348 31272 trainer.py:139] Epoch[1362/1500] loss: 0.19030056516329447
I0416 06:32:10.509397 31272 trainer.py:139] Epoch[1363/1500] loss: 0.19094778292708928
I0416 06:32:53.213489 31272 trainer.py:139] Epoch[1364/1500] loss: 0.19054170933034684
I0416 06:33:35.847200 31272 trainer.py:139] Epoch[1365/1500] loss: 0.19064060535695818
I0416 06:34:18.920685 31272 trainer.py:139] Epoch[1366/1500] loss: 0.19126090917322372
I0416 06:35:01.557575 31272 trainer.py:139] Epoch[1367/1500] loss: 0.191321556435691
I0416 06:35:44.042261 31272 trainer.py:139] Epoch[1368/1500] loss: 0.19008859826458824
I0416 06:36:27.079612 31272 trainer.py:139] Epoch[1369/1500] loss: 0.18966281818019018
I0416 06:37:10.413002 31272 trainer.py:139] Epoch[1370/1500] loss: 0.1895222333404753
I0416 06:37:53.483366 31272 trainer.py:139] Epoch[1371/1500] loss: 0.19077358225981395
I0416 06:38:36.189940 31272 trainer.py:139] Epoch[1372/1500] loss: 0.19006452514065636
I0416 06:39:19.024950 31272 trainer.py:139] Epoch[1373/1500] loss: 0.19094962947898442
I0416 06:40:01.840358 31272 trainer.py:139] Epoch[1374/1500] loss: 0.1905420316590203
I0416 06:40:44.656036 31272 trainer.py:139] Epoch[1375/1500] loss: 0.1904914304945204
I0416 06:41:27.373483 31272 trainer.py:139] Epoch[1376/1500] loss: 0.19093259692192077
I0416 06:42:10.361971 31272 trainer.py:139] Epoch[1377/1500] loss: 0.19064370804362826
I0416 06:42:54.014474 31272 trainer.py:139] Epoch[1378/1500] loss: 0.1913976162009769
I0416 06:43:37.130013 31272 trainer.py:139] Epoch[1379/1500] loss: 0.19091093785232968
I0416 06:44:20.153041 31272 trainer.py:139] Epoch[1380/1500] loss: 0.19090044054720137
I0416 06:45:02.899931 31272 trainer.py:139] Epoch[1381/1500] loss: 0.19086667974789936
I0416 06:45:45.597710 31272 trainer.py:139] Epoch[1382/1500] loss: 0.191100451681349
I0416 06:46:28.381682 31272 trainer.py:139] Epoch[1383/1500] loss: 0.19117549002170564
I0416 06:47:11.152517 31272 trainer.py:139] Epoch[1384/1500] loss: 0.1897911673784256
I0416 06:47:53.637107 31272 trainer.py:139] Epoch[1385/1500] loss: 0.19129468712541792
I0416 06:48:36.569647 31272 trainer.py:139] Epoch[1386/1500] loss: 0.19063247342904407
I0416 06:49:19.776724 31272 trainer.py:139] Epoch[1387/1500] loss: 0.19039164973629846
I0416 06:50:02.973698 31272 trainer.py:139] Epoch[1388/1500] loss: 0.19049854411019218
I0416 06:50:45.642954 31272 trainer.py:139] Epoch[1389/1500] loss: 0.1905882617500093
I0416 06:51:28.261522 31272 trainer.py:139] Epoch[1390/1500] loss: 0.19163624048233033
I0416 06:52:11.137872 31272 trainer.py:139] Epoch[1391/1500] loss: 0.19060024268097348
I0416 06:52:53.853217 31272 trainer.py:139] Epoch[1392/1500] loss: 0.190608705745803
I0416 06:53:36.499799 31272 trainer.py:139] Epoch[1393/1500] loss: 0.19098898973729875
I0416 06:54:19.691340 31272 trainer.py:139] Epoch[1394/1500] loss: 0.19005077375306023
I0416 06:55:03.241988 31272 trainer.py:139] Epoch[1395/1500] loss: 0.19128871275318993
I0416 06:55:46.667019 31272 trainer.py:139] Epoch[1396/1500] loss: 0.19004870918061997
I0416 06:56:29.645755 31272 trainer.py:139] Epoch[1397/1500] loss: 0.19008550531334348
I0416 06:57:12.270518 31272 trainer.py:139] Epoch[1398/1500] loss: 0.18971955193413628
I0416 06:57:55.090600 31272 trainer.py:139] Epoch[1399/1500] loss: 0.19128048042456308
I0416 06:57:55.664680 31272 trainer.py:145] Test: {'precision': 0.20229549248747913, 'recall': 0.28620536611520243, 'hit_ratio': 0.913355592654424, 'ndcg': 0.32386897739065746}
I0416 06:58:38.686300 31272 trainer.py:139] Epoch[1400/1500] loss: 0.1915411400794983
I0416 06:59:21.345527 31272 trainer.py:139] Epoch[1401/1500] loss: 0.1900420547856225
I0416 07:00:04.239570 31272 trainer.py:139] Epoch[1402/1500] loss: 0.19023153424263
I0416 07:00:47.502511 31272 trainer.py:139] Epoch[1403/1500] loss: 0.1907715928554535
I0416 07:01:31.122422 31272 trainer.py:139] Epoch[1404/1500] loss: 0.1909440506829156
I0416 07:02:14.335886 31272 trainer.py:139] Epoch[1405/1500] loss: 0.19068615012698703
I0416 07:02:56.861945 31272 trainer.py:139] Epoch[1406/1500] loss: 0.19101513187090555
I0416 07:03:39.374160 31272 trainer.py:139] Epoch[1407/1500] loss: 0.1901588698890474
I0416 07:04:22.209294 31272 trainer.py:139] Epoch[1408/1500] loss: 0.18966001960966322
I0416 07:05:04.909264 31272 trainer.py:139] Epoch[1409/1500] loss: 0.19153233759933047
I0416 07:05:47.762676 31272 trainer.py:139] Epoch[1410/1500] loss: 0.19003522442446816
I0416 07:06:30.966919 31272 trainer.py:139] Epoch[1411/1500] loss: 0.19127381225426993
I0416 07:07:14.549486 31272 trainer.py:139] Epoch[1412/1500] loss: 0.18955541054407757
I0416 07:07:57.954298 31272 trainer.py:139] Epoch[1413/1500] loss: 0.19023812625143263
I0416 07:08:40.562059 31272 trainer.py:139] Epoch[1414/1500] loss: 0.19170333511299556
I0416 07:09:23.239724 31272 trainer.py:139] Epoch[1415/1500] loss: 0.19014355301856994
I0416 07:10:06.047299 31272 trainer.py:139] Epoch[1416/1500] loss: 0.19078311423460642
I0416 07:10:49.051704 31272 trainer.py:139] Epoch[1417/1500] loss: 0.19024369769626193
I0416 07:11:31.577363 31272 trainer.py:139] Epoch[1418/1500] loss: 0.189749034775628
I0416 07:12:14.394936 31272 trainer.py:139] Epoch[1419/1500] loss: 0.1902050010363261
I0416 07:12:57.806475 31272 trainer.py:139] Epoch[1420/1500] loss: 0.1910380470752716
I0416 07:13:41.345572 31272 trainer.py:139] Epoch[1421/1500] loss: 0.19130475315782758
I0416 07:14:24.497810 31272 trainer.py:139] Epoch[1422/1500] loss: 0.19106893731488123
I0416 07:15:07.405573 31272 trainer.py:139] Epoch[1423/1500] loss: 0.18955164743794337
I0416 07:15:50.075339 31272 trainer.py:139] Epoch[1424/1500] loss: 0.19000047902266184
I0416 07:16:33.199991 31272 trainer.py:139] Epoch[1425/1500] loss: 0.19062033964527977
I0416 07:17:15.953931 31272 trainer.py:139] Epoch[1426/1500] loss: 0.19001930826240115
I0416 07:17:58.566886 31272 trainer.py:139] Epoch[1427/1500] loss: 0.1902270171377394
I0416 07:18:41.737815 31272 trainer.py:139] Epoch[1428/1500] loss: 0.19121519578827753
I0416 07:19:25.205300 31272 trainer.py:139] Epoch[1429/1500] loss: 0.19057879156536525
I0416 07:20:08.536055 31272 trainer.py:139] Epoch[1430/1500] loss: 0.19092168271541596
I0416 07:20:51.564461 31272 trainer.py:139] Epoch[1431/1500] loss: 0.18953505489561293
I0416 07:21:34.129267 31272 trainer.py:139] Epoch[1432/1500] loss: 0.1905621718035804
I0416 07:22:17.154364 31272 trainer.py:139] Epoch[1433/1500] loss: 0.1909036903248893
I0416 07:22:59.891573 31272 trainer.py:139] Epoch[1434/1500] loss: 0.19081488496727414
I0416 07:23:42.383900 31272 trainer.py:139] Epoch[1435/1500] loss: 0.19137484537230598
I0416 07:24:25.326596 31272 trainer.py:139] Epoch[1436/1500] loss: 0.19078527357843186
I0416 07:25:08.627475 31272 trainer.py:139] Epoch[1437/1500] loss: 0.19084670417838626
I0416 07:25:52.029132 31272 trainer.py:139] Epoch[1438/1500] loss: 0.1912640600734287
I0416 07:26:35.076397 31272 trainer.py:139] Epoch[1439/1500] loss: 0.1906615326801936
I0416 07:27:17.677699 31272 trainer.py:139] Epoch[1440/1500] loss: 0.1908093810081482
I0416 07:28:00.350691 31272 trainer.py:139] Epoch[1441/1500] loss: 0.1907946885956658
I0416 07:28:43.257939 31272 trainer.py:139] Epoch[1442/1500] loss: 0.19048108683692083
I0416 07:29:25.778071 31272 trainer.py:139] Epoch[1443/1500] loss: 0.19087243424521552
I0416 07:30:08.743139 31272 trainer.py:139] Epoch[1444/1500] loss: 0.1904979819059372
I0416 07:30:52.052058 31272 trainer.py:139] Epoch[1445/1500] loss: 0.18961141493585373
I0416 07:31:35.585451 31272 trainer.py:139] Epoch[1446/1500] loss: 0.19065795474582248
I0416 07:32:19.038718 31272 trainer.py:139] Epoch[1447/1500] loss: 0.19036357608106402
I0416 07:33:01.898162 31272 trainer.py:139] Epoch[1448/1500] loss: 0.1901012223958969
I0416 07:33:44.635806 31272 trainer.py:139] Epoch[1449/1500] loss: 0.19078504747814604
I0416 07:33:45.197925 31272 trainer.py:145] Test: {'precision': 0.20225375626043401, 'recall': 0.28563028314665756, 'hit_ratio': 0.9146911519198665, 'ndcg': 0.32103378423574475}
I0416 07:34:27.982690 31272 trainer.py:139] Epoch[1450/1500] loss: 0.19095093627770743
I0416 07:35:10.514770 31272 trainer.py:139] Epoch[1451/1500] loss: 0.19001677877373166
I0416 07:35:53.209249 31272 trainer.py:139] Epoch[1452/1500] loss: 0.19127716581026713
I0416 07:36:36.268964 31272 trainer.py:139] Epoch[1453/1500] loss: 0.19023155689239502
I0416 07:37:19.789254 31272 trainer.py:139] Epoch[1454/1500] loss: 0.18927096565564475
I0416 07:38:03.014832 31272 trainer.py:139] Epoch[1455/1500] loss: 0.1903950454129113
I0416 07:38:46.034422 31272 trainer.py:139] Epoch[1456/1500] loss: 0.19090405186017353
I0416 07:39:28.623276 31272 trainer.py:139] Epoch[1457/1500] loss: 0.18971582386228775
I0416 07:40:11.689690 31272 trainer.py:139] Epoch[1458/1500] loss: 0.19007449368635812
I0416 07:40:54.335169 31272 trainer.py:139] Epoch[1459/1500] loss: 0.19047821243604024
I0416 07:41:36.917795 31272 trainer.py:139] Epoch[1460/1500] loss: 0.19107609775331286
I0416 07:42:20.155301 31272 trainer.py:139] Epoch[1461/1500] loss: 0.19082096530331505
I0416 07:43:03.374064 31272 trainer.py:139] Epoch[1462/1500] loss: 0.19048364169067808
I0416 07:43:46.405023 31272 trainer.py:139] Epoch[1463/1500] loss: 0.1900280214018292
I0416 07:44:29.226273 31272 trainer.py:139] Epoch[1464/1500] loss: 0.19065282225608826
I0416 07:45:11.989346 31272 trainer.py:139] Epoch[1465/1500] loss: 0.19070462909009722
I0416 07:45:54.629460 31272 trainer.py:139] Epoch[1466/1500] loss: 0.19049391322665743
I0416 07:46:37.371667 31272 trainer.py:139] Epoch[1467/1500] loss: 0.19088235484229193
I0416 07:47:19.885987 31272 trainer.py:139] Epoch[1468/1500] loss: 0.1913356563780043
I0416 07:48:02.509384 31272 trainer.py:139] Epoch[1469/1500] loss: 0.19016264584329393
I0416 07:48:45.764010 31272 trainer.py:139] Epoch[1470/1500] loss: 0.19068303373124865
I0416 07:49:28.971466 31272 trainer.py:139] Epoch[1471/1500] loss: 0.190451909965939
I0416 07:50:12.064428 31272 trainer.py:139] Epoch[1472/1500] loss: 0.1905380657646391
I0416 07:50:54.989233 31272 trainer.py:139] Epoch[1473/1500] loss: 0.19020208179950715
I0416 07:51:37.704580 31272 trainer.py:139] Epoch[1474/1500] loss: 0.19078221533033582
I0416 07:52:20.944700 31272 trainer.py:139] Epoch[1475/1500] loss: 0.19087706002924176
I0416 07:53:03.665539 31272 trainer.py:139] Epoch[1476/1500] loss: 0.19078834255536398
I0416 07:53:46.196159 31272 trainer.py:139] Epoch[1477/1500] loss: 0.19000760396321614
I0416 07:54:29.423629 31272 trainer.py:139] Epoch[1478/1500] loss: 0.19141998443338606
I0416 07:55:12.736867 31272 trainer.py:139] Epoch[1479/1500] loss: 0.19096288601557412
I0416 07:55:56.073371 31272 trainer.py:139] Epoch[1480/1500] loss: 0.1900062165657679
I0416 07:56:39.067825 31272 trainer.py:139] Epoch[1481/1500] loss: 0.19136438760492536
I0416 07:57:21.734486 31272 trainer.py:139] Epoch[1482/1500] loss: 0.19056663082705605
I0416 07:58:04.717177 31272 trainer.py:139] Epoch[1483/1500] loss: 0.19009413798650107
I0416 07:58:47.758485 31272 trainer.py:139] Epoch[1484/1500] loss: 0.19126034471723768
I0416 07:59:30.463733 31272 trainer.py:139] Epoch[1485/1500] loss: 0.19093485361999935
I0416 08:00:13.351961 31272 trainer.py:139] Epoch[1486/1500] loss: 0.19073761489656235
I0416 08:00:56.852016 31272 trainer.py:139] Epoch[1487/1500] loss: 0.19092422041628096
I0416 08:01:40.421073 31272 trainer.py:139] Epoch[1488/1500] loss: 0.190792010890113
I0416 08:02:23.387963 31272 trainer.py:139] Epoch[1489/1500] loss: 0.19204569704002805
I0416 08:03:06.270421 31272 trainer.py:139] Epoch[1490/1500] loss: 0.1903514775964949
I0416 08:03:49.031121 31272 trainer.py:139] Epoch[1491/1500] loss: 0.19075952841175928
I0416 08:04:31.945857 31272 trainer.py:139] Epoch[1492/1500] loss: 0.1910664838552475
I0416 08:05:14.464485 31272 trainer.py:139] Epoch[1493/1500] loss: 0.19028278450171152
I0416 08:05:57.195890 31272 trainer.py:139] Epoch[1494/1500] loss: 0.19146977179580266
I0416 08:06:40.582072 31272 trainer.py:139] Epoch[1495/1500] loss: 0.19105533725685545
I0416 08:07:24.108235 31272 trainer.py:139] Epoch[1496/1500] loss: 0.19027132670084634
I0416 08:08:07.322605 31272 trainer.py:139] Epoch[1497/1500] loss: 0.1905692782666948
I0416 08:08:50.382091 31272 trainer.py:139] Epoch[1498/1500] loss: 0.19059315979480743
I0416 08:09:33.462526 31272 trainer.py:139] Epoch[1499/1500] loss: 0.19064976778295306
I0416 08:09:34.027636 31272 trainer.py:145] Test: {'precision': 0.20259599332220363, 'recall': 0.28514941064433736, 'hit_ratio': 0.9148580968280468, 'ndcg': 0.32116307888872037}
